{"meta":{"title":"扔掉笔记 ᐛ","subtitle":"dropNotes","description":null,"author":"beefyheisenberg","url":"https://beefyheisenberg.github.io","root":"/"},"pages":[{"title":"笔记分类","date":"2022-10-13T11:09:32.118Z","updated":"2022-10-13T11:09:32.105Z","comments":false,"path":"categories/index.html","permalink":"https://beefyheisenberg.github.io/categories/index.html","excerpt":"","text":""},{"title":"关于","date":"2023-09-30T10:08:02.783Z","updated":"2023-02-11T14:56:20.370Z","comments":false,"path":"about/index.html","permalink":"https://beefyheisenberg.github.io/about/index.html","excerpt":"","text":"《荒岛电台》 我的北方 面朝粗粝的旷野 我的南方 住在星星监狱 缮写室、黄金诗和卡尔达诺书"},{"title":"默认首页","date":"2022-10-13T10:07:59.444Z","updated":"2022-10-13T08:55:42.551Z","comments":false,"path":"index/index.html","permalink":"https://beefyheisenberg.github.io/index/index.html","excerpt":"","text":""},{"title":"笔记标签","date":"2022-10-13T11:09:55.093Z","updated":"2022-10-13T11:09:55.081Z","comments":false,"path":"tags/index.html","permalink":"https://beefyheisenberg.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"About-Scriptorium","slug":"About/About-Scriptorium","date":"2024-01-24T01:27:54.339Z","updated":"2024-01-24T01:27:54.340Z","comments":true,"path":"About/About-Scriptorium/","link":"","permalink":"https://beefyheisenberg.github.io/About/About-Scriptorium/","excerpt":"缮写室 黄金诗篇 卡尔达诺书","text":"缮写室 黄金诗篇 卡尔达诺书","categories":[{"name":"About","slug":"About","permalink":"https://beefyheisenberg.github.io/categories/About/"}],"tags":[]},{"title":"游戏《Rise-of-Kingdoms》中的历史人物","slug":"76.Games/游戏《Rise-of-Kingdoms》中的历史人物","date":"2024-01-24T01:27:54.324Z","updated":"2024-01-24T01:27:54.324Z","comments":true,"path":"76.Games/游戏《Rise-of-Kingdoms》中的历史人物/","link":"","permalink":"https://beefyheisenberg.github.io/76.Games/游戏《Rise-of-Kingdoms》中的历史人物/","excerpt":"Rise of Kingdoms （万国觉醒） 是一款 P2W（pay to win）游戏。 大西庇阿大西庇阿（前235年—前183年），全名为普布利乌斯·科尔内利乌斯·西庇阿。古罗马统帅和政治家。他是第二次布匿战争中罗马方面的主要将领之一，以在扎马战役中打败迦太基统帅汉尼拔而著称于世。由于西庇阿的胜利，罗马人以绝对有利的条件结束了第二次布匿战争。西庇阿因此得到他那著名的绰号：“阿非利加征服者”。 贝利萨留（Belisarius）贝利萨留（约505年～565年），又名贝利萨留斯，拜占庭帝国统帅、军事家。他一生当中的大多数战役是以少胜多。贝利萨留出生于色雷斯。早年任皇帝查士丁尼一世的侍卫。527年率军参加对波斯的战争。529年，升任禁卫军长官。530年，任德拉总督，击败4万波斯-阿拉伯联军，名声大振。532年，镇压君士坦丁堡的尼卡起义，解救被围困的皇帝。533～534年，仅率1万步兵和6000骑兵入侵北非，灭汪达尔-阿兰王国并俘其国王。回国后被授予执政官称号。535年，出征意大利的东哥特王国，登陆西西里岛。536年攻入意大利南部，随后北上占领罗马。540年，攻陷东哥特都城拉韦纳，俘东哥特王。曾经用“自己将政变”为计谋欺骗敌方获胜，结果因此受到查士丁尼一世的怀疑。562年，被指控参与谋反，被捕入狱。563年，获释。565年，去世，享年61岁。","text":"Rise of Kingdoms （万国觉醒） 是一款 P2W（pay to win）游戏。 大西庇阿大西庇阿（前235年—前183年），全名为普布利乌斯·科尔内利乌斯·西庇阿。古罗马统帅和政治家。他是第二次布匿战争中罗马方面的主要将领之一，以在扎马战役中打败迦太基统帅汉尼拔而著称于世。由于西庇阿的胜利，罗马人以绝对有利的条件结束了第二次布匿战争。西庇阿因此得到他那著名的绰号：“阿非利加征服者”。 贝利萨留（Belisarius）贝利萨留（约505年～565年），又名贝利萨留斯，拜占庭帝国统帅、军事家。他一生当中的大多数战役是以少胜多。贝利萨留出生于色雷斯。早年任皇帝查士丁尼一世的侍卫。527年率军参加对波斯的战争。529年，升任禁卫军长官。530年，任德拉总督，击败4万波斯-阿拉伯联军，名声大振。532年，镇压君士坦丁堡的尼卡起义，解救被围困的皇帝。533～534年，仅率1万步兵和6000骑兵入侵北非，灭汪达尔-阿兰王国并俘其国王。回国后被授予执政官称号。535年，出征意大利的东哥特王国，登陆西西里岛。536年攻入意大利南部，随后北上占领罗马。540年，攻陷东哥特都城拉韦纳，俘东哥特王。曾经用“自己将政变”为计谋欺骗敌方获胜，结果因此受到查士丁尼一世的怀疑。562年，被指控参与谋反，被捕入狱。563年，获释。565年，去世，享年61岁。 海尔曼英文名：Arminius阿米尼乌斯德语作Hermann赫尔曼 阿米尼乌斯，或称阿尔米尼乌斯，于公元前18年生于日耳曼尼亚，日耳曼部族切鲁西人(Cherusci)的首领。小被送往罗马当人质。长大后，他成为罗马辅助部队一队骑兵的首领。9年他大败罗马人，在条顿堡森林(Teutoburg Forest)歼灭普布利乌斯·昆克提尼乌斯·瓦卢斯(Publius Quinctilius Varus)的3个军团。15年他巧妙地抵挡了罗马发动的全面进攻，但在16年，他在安格里瓦尔瓦战役败给了罗马将领日尔曼尼库斯，17年与马科曼尼人(Marcomanni)国王马罗波都(Maroboduus)进行战斗。在取得胜利以後，他被日耳曼尼亚部落的对手首领下令暗杀。 条顿堡森林战役：公元9年9月，瓦卢斯带领十七、十八、十九三个军团从夏营返回东营过冬，连同辎重、家属共计逾两万两千人，阿米尼乌斯召集日耳曼各部落共同伏击罗马人，他施计引诱罗马人进入条顿堡森林，通过三场战斗，他歼灭了罗马人的3个军团，瓦卢斯自杀身亡。当奥古斯都得知瓦鲁斯及三个罗马军团全军覆没，便痛叫”Quintili Vare, legiones redde!” (‘Quintilius Varus, give me back my legions!’)“瓦鲁斯，把军团还给我！” 佩拉约佩拉约（西班牙语：Pelayo，拉丁语：Pelagius，约685年－737年）685年出生于西班牙，他建立了阿斯图里亚斯王国，从718年开始统治直到去世。他在科法敦加战役的胜利，被视为“收复失地运动”的起点，基督徒从摩尔人手中收复伊比利亚半岛，从他建立独立的基督教西班牙国家对抗摩尔人政权开始，但是并没有强力的证据证明他的目的是复兴过去的西班牙王国或者只是因为任何宗教渴望的刺激。 源义经 源义经（1159年—1189年6月15日），幼名牛若（うしわかまる）。日本传奇英雄，平安时代末期的名将。出身于河内源氏的武士，家系乃清和源氏其中一支，河内源氏的栋梁源赖信的后代。为源义朝的第九子，源赖朝之弟。源义经之父源义朝在平治之乱中为平清盛所败后，源义经在七岁时被送到京都鞍马寺学习，改名遮那王。之后投奔奥州，受到奥州藤原氏当主藤原秀衡的庇护。承治四年（1180年），源义经与同父异母的兄长源赖朝一齐举兵讨伐平家，在著名的战役源平合战中战功彪炳，威名显赫。但也因功高震主为源赖朝所猜忌，最终兄弟反目成仇。源赖朝得到后白河天皇的院宣后，在全国发布通缉命令追捕源义经。源义经在走投无路之下再度投靠藤原秀衡，藤原秀衡死后，其子藤原泰衡开始排挤源义经。文治五年（1189年），源赖朝亲自率兵讨伐平泉。迫于源赖朝之压力，藤原泰衡把枪口转向了源义经。源义经最后在衣川馆自尽。源义经为日本人所爱戴的传统英雄之一，而且由于其生涯富有传奇与悲剧的色彩，在许多故事、戏剧中都有关于他的描述，在许多神社中也奉祀著源义经。","categories":[{"name":"76.Games","slug":"76-Games","permalink":"https://beefyheisenberg.github.io/categories/76-Games/"}],"tags":[]},{"title":"Ingress Prime","slug":"76.Games/Ingress","date":"2024-01-24T01:27:54.318Z","updated":"2024-01-24T01:27:54.318Z","comments":true,"path":"76.Games/Ingress/","link":"","permalink":"https://beefyheisenberg.github.io/76.Games/Ingress/","excerpt":"介绍Ingress 是一款基于地理位置的大型多人侵入式虚拟现实游戏。 游戏的故事背景是一群欧洲科学家偶然发现某种神秘的能量 XM（Exotic Matter），这一能量的来源和用途无人知晓，研究人员认为可以开发并善用这能量，但另一方面却担心这样的能量会影响人们的思考甚至被能量本身奴役。 游戏中有两大主要阵营，这两大互相争夺主控权的全球性组织分别是“反抗军”和“启蒙军”。“启蒙军”（Enlightened，以绿色标示）阵营希望能接纳这股“神秘的能量XM”，并相信这股能量能赐予人类进步与改革，其追随者相信神秘的能量会催生影响重大的“启蒙运动”，使全人类进化。另一派“反抗军”（Resistance，以蓝色标示）阵营则奋力捍卫并守护仅存的人性，有些人认为他们对于变化或进步感到畏惧，但反抗军坚信这一切都是为了保护人类。游戏的玩家被称为特工（Agent），两个阵营互相角力，争夺控制真实世界中的地标性建筑或雕塑等Portal（译作“传送门”）。 游戏内容和真实世界的地理状况结合，游戏会透过手持装置的GPS、AGPS以及Wi-Fi资讯确认玩家的位置，而玩家可以透过游戏的扫描器（Scanner）界面看到自身周围的传送门、XM或物品。游戏地图上各处散落着白色亮点，代表XM所在的位置，玩家在接近XM时会自动收集，而对传送门进行任何操作均需耗用XM。传送门主要是各种建筑、雕塑、艺术品等，玩家需亲自持手机接近这些传送门，进行部署（Deploy）、入侵（Hack）、补充能量（Recharge）、发射XMP等动作。玩家在游戏中的目标是透过连接多个本阵营控制的传送门，建立控制场（Control Field），覆盖最多的“Mind Units（MUs）”。","text":"介绍Ingress 是一款基于地理位置的大型多人侵入式虚拟现实游戏。 游戏的故事背景是一群欧洲科学家偶然发现某种神秘的能量 XM（Exotic Matter），这一能量的来源和用途无人知晓，研究人员认为可以开发并善用这能量，但另一方面却担心这样的能量会影响人们的思考甚至被能量本身奴役。 游戏中有两大主要阵营，这两大互相争夺主控权的全球性组织分别是“反抗军”和“启蒙军”。“启蒙军”（Enlightened，以绿色标示）阵营希望能接纳这股“神秘的能量XM”，并相信这股能量能赐予人类进步与改革，其追随者相信神秘的能量会催生影响重大的“启蒙运动”，使全人类进化。另一派“反抗军”（Resistance，以蓝色标示）阵营则奋力捍卫并守护仅存的人性，有些人认为他们对于变化或进步感到畏惧，但反抗军坚信这一切都是为了保护人类。游戏的玩家被称为特工（Agent），两个阵营互相角力，争夺控制真实世界中的地标性建筑或雕塑等Portal（译作“传送门”）。 游戏内容和真实世界的地理状况结合，游戏会透过手持装置的GPS、AGPS以及Wi-Fi资讯确认玩家的位置，而玩家可以透过游戏的扫描器（Scanner）界面看到自身周围的传送门、XM或物品。游戏地图上各处散落着白色亮点，代表XM所在的位置，玩家在接近XM时会自动收集，而对传送门进行任何操作均需耗用XM。传送门主要是各种建筑、雕塑、艺术品等，玩家需亲自持手机接近这些传送门，进行部署（Deploy）、入侵（Hack）、补充能量（Recharge）、发射XMP等动作。玩家在游戏中的目标是透过连接多个本阵营控制的传送门，建立控制场（Control Field），覆盖最多的“Mind Units（MUs）”。 Ingress - 维基百科，自由的百科全书 Ingress维基 - 灰机wiki 术语表 · Ingress 中文游戏指南 教程 【Ingress Prime】真实游戏实况，给新人玩家的基础教程_哔哩哔哩_bilibili 新手攻略索引 – Ingress Resistance BeiJing 组织 Ingress Resistance BeiJing 世界地图 Intel 地图： https://intel.ingress.com/intel","categories":[{"name":"76.Games","slug":"76-Games","permalink":"https://beefyheisenberg.github.io/categories/76-Games/"}],"tags":[]},{"title":"自制榨果汁","slug":"74.Foods/自制榨果汁","date":"2024-01-24T01:27:54.314Z","updated":"2024-01-24T01:27:54.314Z","comments":true,"path":"74.Foods/自制榨果汁/","link":"","permalink":"https://beefyheisenberg.github.io/74.Foods/自制榨果汁/","excerpt":"","text":"@ref：知乎 《你曾榨出过最好喝的果蔬汁搭配是什么？ - 毛羽立的回答 - 知乎》 我在台湾交换时，学校门口的夜市有一个现打蔬果汁摊儿，永远排长队。有凤梨草莓猕猴桃汁，地瓜山药牛奶，木瓜鲜橙胡萝卜汁，红豆薏米牛奶……还有几种以颜色命名的蔬果汁，内容物我记不太清了，大致描述一下。 红色：草莓，蕃茄，西瓜，木瓜，莲雾，桃子 橙色：柠檬，甜橙，胡萝卜，芒果，南瓜，凤梨，柚子 绿色：小麦草，芭乐，芹菜，猕猴桃，芦荟，苦瓜 白色：香蕉，苹果，梨，薏仁，黄瓜，牛油果 黑色：葡萄，桑葚，黑布林，蓝莓","categories":[{"name":"74.Foods","slug":"74-Foods","permalink":"https://beefyheisenberg.github.io/categories/74-Foods/"}],"tags":[{"name":"吃喝的修养","slug":"吃喝的修养","permalink":"https://beefyheisenberg.github.io/tags/吃喝的修养/"}]},{"title":"午餐肉","slug":"74.Foods/午餐肉","date":"2024-01-24T01:27:54.310Z","updated":"2024-01-24T01:27:54.311Z","comments":true,"path":"74.Foods/午餐肉/","link":"","permalink":"https://beefyheisenberg.github.io/74.Foods/午餐肉/","excerpt":"@ref 豆瓣 《午餐肉爱好者的自我修养——顶级午餐肉指南》 新手入门： 梅林 中阶识货：长城白猪午餐肉 高阶吃货：德和云腿午餐肉 寻根觅祖：世棒午餐肉（SPAM）","text":"@ref 豆瓣 《午餐肉爱好者的自我修养——顶级午餐肉指南》 新手入门： 梅林 中阶识货：长城白猪午餐肉 高阶吃货：德和云腿午餐肉 寻根觅祖：世棒午餐肉（SPAM） 欧洲货才装B：丹麦三花午餐肉（Tuilp） @ref: 我们一不小心吃掉了15公斤午餐肉 - 知乎 上面提到的：梅林、长城 梅林：1949年上海解放后，梅林罐头食品厂股份有限公司先于1954年公私合营，由上海轻工业管理局主管，后于1956年成为地方工业部掌管的重点企业。1958年1月8日，《人民日报》发表社论《从梅林看全国》，掀起增产节约、反对浪费的高潮，在全国产生了很大的影响，同时也极大的促进和激发了梅林罐头食品厂的创造热情。于是，梅林厂“双革”创奇迹，竞赛掀热潮，罐头品种增加到200余种。1960年10月1日，地处虹桥路808号的梅林罐头食品厂移至军工路224号，并将拥有较好制罐生产基础和技术实力的上海益民食品二厂的职工、设备全部并入。 长城：1953年，苏联首次从我国进口水果罐头。当时，总公司尚无主管罐头业务的机构，而由主管水果业务的吴成章同志承办。1954年，我国对苏联出口罐头数量大增，有猪、牛、羊、家禽、水果、蔬菜等十多个品种。 1954年，我国首次对苏联出口猪肉罐头,是按我国传统口味生产的红烧猪肉，年底，李瑞征副经理去苏联谈判，苏联方面提出红烧肉不适合苏联人民的口味，不久苏联方面派罐头专家来试制清蒸猪肉；捷克派罐头专家试制原汁猪肉、午餐肉；民主德国派罐头专家试制浓汁猪肉（又称古拉许），这些品种基本上都是生猪肉装罐，不加酱油、白糖等调味品，原汁原味。当时，生产对苏联出口的罐头厂，都有苏联罐头专家驻厂或巡回检查验收才能发货。 对苏联、东欧出口罐头，统一使用长城牌商标，由总公司统一对外签订供货合同下达各地执行。对资出口罐头由上海、天津、广州、汕头、南宁、福州、厦门、青岛、大连等口岸公司对外经营。每个口岸都有一个或两个专用商标。上海梅林牌、绿叶牌，天津长城牌，广州、汕头天坛牌、珠江牌，南宁象山牌，福州、厦门水仙花牌，青岛飞轮牌、牡丹牌，大连红梅牌。有些品种如红烧猪肉、红烧扣肉、红烧牛肉、红烧鸡、红烧鸭、菠萝、桔子等，几个口岸交叉经营。 @ref： 忆五十年代我国的罐头生产和出口 - 知乎","categories":[{"name":"74.Foods","slug":"74-Foods","permalink":"https://beefyheisenberg.github.io/categories/74-Foods/"}],"tags":[{"name":"吃喝的修养","slug":"吃喝的修养","permalink":"https://beefyheisenberg.github.io/tags/吃喝的修养/"}]},{"title":"啤酒","slug":"74.Foods/啤酒","date":"2024-01-24T01:27:54.305Z","updated":"2024-01-24T01:27:54.305Z","comments":true,"path":"74.Foods/啤酒/","link":"","permalink":"https://beefyheisenberg.github.io/74.Foods/啤酒/","excerpt":"Cheers🍻！ 啤酒分类艾尔啤酒：或是人类最早的啤酒 艾尔（Ale），又称为顶部发酵（Top Fermentating）。使用该种方式发酵的啤酒，酵母位于啤酒液体顶部，通过表面大量聚集泡沫发酵。这种发酵方式适合温度高的环境，约16℃~24℃最佳，这样发酵的代谢产物能更多样。比如会产生酰类和酯类，这些物质极大地影响了啤酒风味，也是艾尔啤酒当中复杂香气的重要来源。最初的艾尔啤酒并不加入啤酒花，后来渐渐地人们发现，在发酵过程中加入啤酒花后，不但可以延长保存期，还可以增加啤酒的苦味和香味。如今，艾尔啤酒呈现琥珀色，外观透亮，泡沫丰富细腻，挂杯持久，香气丰富，麦芽香气、酯香、酒花香气平衡宜人。 在艾尔啤酒中，还有一些具体的细分，如淡色艾尔、IPA、APA、棕色艾尔、琥珀艾尔、烈性艾尔、小麦啤酒、波特、世涛等。 IPA（India Pale Ale）印度淡色艾尔： 最早是出现在印度的英国淡色艾尔啤酒。IPA啤酒为干型，呈深琥珀色，含大量酒花，口感偏苦，回味温醇，常带有热带水果味。 APA（ American Pale Ale）美式淡色艾尔：1980年11月美国的Sierra Nevada酒厂酿出了第一款实验性的美式淡色艾尔啤酒。APA啤酒的麦芽味相对较淡，苦味更明显，风味更浓郁，还常常带有一些柑橘水果的香气 波特啤酒（Porter）：是一种深色、麦芽味很浓、带点烘烤味道的艾尔啤酒。波特啤酒与棕色艾尔型啤酒不同，它更烈、酒体更丰富、颜色更深并带有更多的烘烤麦芽的味道。和艾尔啤酒的另一分支——世涛非常相似，都是黑色，都有咖啡、太妃糖、焦糖、大麦、燕麦、果仁等香气。 拉格啤酒：全世界占比90%的啤酒","text":"Cheers🍻！ 啤酒分类艾尔啤酒：或是人类最早的啤酒 艾尔（Ale），又称为顶部发酵（Top Fermentating）。使用该种方式发酵的啤酒，酵母位于啤酒液体顶部，通过表面大量聚集泡沫发酵。这种发酵方式适合温度高的环境，约16℃~24℃最佳，这样发酵的代谢产物能更多样。比如会产生酰类和酯类，这些物质极大地影响了啤酒风味，也是艾尔啤酒当中复杂香气的重要来源。最初的艾尔啤酒并不加入啤酒花，后来渐渐地人们发现，在发酵过程中加入啤酒花后，不但可以延长保存期，还可以增加啤酒的苦味和香味。如今，艾尔啤酒呈现琥珀色，外观透亮，泡沫丰富细腻，挂杯持久，香气丰富，麦芽香气、酯香、酒花香气平衡宜人。 在艾尔啤酒中，还有一些具体的细分，如淡色艾尔、IPA、APA、棕色艾尔、琥珀艾尔、烈性艾尔、小麦啤酒、波特、世涛等。 IPA（India Pale Ale）印度淡色艾尔： 最早是出现在印度的英国淡色艾尔啤酒。IPA啤酒为干型，呈深琥珀色，含大量酒花，口感偏苦，回味温醇，常带有热带水果味。 APA（ American Pale Ale）美式淡色艾尔：1980年11月美国的Sierra Nevada酒厂酿出了第一款实验性的美式淡色艾尔啤酒。APA啤酒的麦芽味相对较淡，苦味更明显，风味更浓郁，还常常带有一些柑橘水果的香气 波特啤酒（Porter）：是一种深色、麦芽味很浓、带点烘烤味道的艾尔啤酒。波特啤酒与棕色艾尔型啤酒不同，它更烈、酒体更丰富、颜色更深并带有更多的烘烤麦芽的味道。和艾尔啤酒的另一分支——世涛非常相似，都是黑色，都有咖啡、太妃糖、焦糖、大麦、燕麦、果仁等香气。 拉格啤酒：全世界占比90%的啤酒 拉格（Lager），又称为底部发酵（Bottom fermenting）。拉格啤酒发酵时，酵母在液体底部，发酵温度要求较低，酒精含量较低。由于酵母沉在发酵醪底部，酵母主要以单一的酒精代谢为主，所以拉格啤酒的口感更加简单，主要是大麦和小麦的原味。拉格啤酒也包括一些细分种类，如淡色拉格、深色拉格、皮尔森、博克等。 皮尔森：诞生于捷克，如今遍布全世界，属于淡色系的拉格啤酒，爽口清冽，有淡淡的啤酒花苦味。皮尔森采用下层发酵法，是用浅色麦芽苦味较重的啤酒花酿造的lager（拉格）啤酒，麦汁浓度最高不超过12.5度。 深色拉格：颜色范围覆盖至琥珀色到非常深的红棕色，酒精度一般在 4.5%-6% 之间，通常带有烘烤、可可豆和焦糖等风味，口感比较柔和饱满。德国黑啤就是大家比较熟知的深色拉格。 生啤熟啤：根据杀菌情况区分 生啤是指不经过传统高温杀菌的啤酒，这类啤酒中还含有活性酵母菌，一般保存时间不宜太长，通常为桶装，口感鲜美，营养丰富。 熟啤是经过灭菌处理的啤酒，保存时间较长。起初是通过巴氏（高温瞬时）灭菌，但会使啤酒伴随老熟的味道；随着啤酒酿造技术成熟，美国、日本及欧洲一些国家采用低温膜过滤以及冷杀菌，具有较长的保质期，一般选择瓶装或罐装。 精酿入门有什么可以当口粮的精酿啤酒？ - 知乎 精酿啤酒和国内普通啤酒有什么本质的区别？ - 知乎 精酿啤酒比流水线生产的工业啤酒更追求品质，原料、工艺的选择都以突出品质为前提，始终把啤酒的风味放在首位。 用料上，精酿啤酒不计成本采用精良的原料，大部分使用纯麦芽糖化，工业啤酒更多采用低成本原料，例如大米，糖浆，玉米、淀粉等代替麦芽。 原料使用上，传统的工艺要求啤酒只能使用四种原材料，麦芽、酒花、酵母、水，但随着社会发展，现在的精酿更加多样，也有添加果汁等原料。whatever，区别于工业啤酒的使用低成本的原料发酵，使用添加剂、浸膏等代替酒花。 精酿啤酒讲究创新，在基础的四种原料外，大胆地尝试新原料，加入了很多匪夷所思的东西，有的精酿啤酒也会采用玉米、淀粉这类原料，不过始终坚持不使用人工添加剂。所以两者的区别不在原料种类，而在于精酿更重视原料的天然，选择原料的目的是为了突出啤酒的风味，而工业啤酒是为了降低成本。 发酵方式上，精酿啤酒大多采用艾尔酵母，进行上层发酵。一些精酿啤酒也会采用拉格工艺（下发酵工艺）。所以不能把工艺当作区分二者的绝对标准。 酒精度和麦芽汁浓度区分不可靠，同保质期一样，精酿啤酒也有低酒精度和低麦芽汁浓度的，所以不能说所有的精酿啤酒酒精度和麦芽汁浓度都比普通啤酒高。","categories":[{"name":"74.Foods","slug":"74-Foods","permalink":"https://beefyheisenberg.github.io/categories/74-Foods/"}],"tags":[{"name":"吃喝的修养","slug":"吃喝的修养","permalink":"https://beefyheisenberg.github.io/tags/吃喝的修养/"}]},{"title":"家庭常备药品","slug":"73.Health-and-Medicine/家庭常备药品","date":"2024-01-24T01:27:54.300Z","updated":"2024-01-24T01:27:54.301Z","comments":true,"path":"73.Health-and-Medicine/家庭常备药品/","link":"","permalink":"https://beefyheisenberg.github.io/73.Health-and-Medicine/家庭常备药品/","excerpt":"家庭药箱中应有哪些常用药才能覆盖日常应急所需？根据家庭成员的构成，应主要覆盖内服药、外用药、特殊人群和辅助用品四大类别。 内服药常见的有感冒药、 解热镇痛药、止咳化痰药、止泻药、通便药、抗过敏药、助消化药七大类，一般不推荐储备抗菌类药物。外用药主要有外用消毒药，如75%乙醇（酒精）、碘伏等；其他外用药如云南白药、风油精等；创可贴、灭菌医用棉签、纱布、绷带等卫生材料也要备齐。家中如有特殊病患，还应按专科医师建议准备常用应急药物。如心血管疾病使用的硝酸甘油、阿司匹林，哮喘患者使用的硫酸沙丁胺醇气雾剂等。 感冒药： 可备酚麻美敏片、维C银翘片。感冒是自限性疾病，一般不用药物治疗，多休息、多喝热水也可以自愈，但服药可缓解症状，所以口服感冒药通常是家庭药箱的常见成员。需要留意的是，很多感冒药都含有相同成分，一定要仔细看好说明书，避免重复用药，严格按推荐的剂量和用法。使用中成药时最好能分清风热感冒和风寒感冒或流行性感冒，不同类型的感冒使用的药物也不同。 解热镇痛药：","text":"家庭药箱中应有哪些常用药才能覆盖日常应急所需？根据家庭成员的构成，应主要覆盖内服药、外用药、特殊人群和辅助用品四大类别。 内服药常见的有感冒药、 解热镇痛药、止咳化痰药、止泻药、通便药、抗过敏药、助消化药七大类，一般不推荐储备抗菌类药物。外用药主要有外用消毒药，如75%乙醇（酒精）、碘伏等；其他外用药如云南白药、风油精等；创可贴、灭菌医用棉签、纱布、绷带等卫生材料也要备齐。家中如有特殊病患，还应按专科医师建议准备常用应急药物。如心血管疾病使用的硝酸甘油、阿司匹林，哮喘患者使用的硫酸沙丁胺醇气雾剂等。 感冒药： 可备酚麻美敏片、维C银翘片。感冒是自限性疾病，一般不用药物治疗，多休息、多喝热水也可以自愈，但服药可缓解症状，所以口服感冒药通常是家庭药箱的常见成员。需要留意的是，很多感冒药都含有相同成分，一定要仔细看好说明书，避免重复用药，严格按推荐的剂量和用法。使用中成药时最好能分清风热感冒和风寒感冒或流行性感冒，不同类型的感冒使用的药物也不同。 解热镇痛药： 常见的有布洛芬混悬液、对乙酰氨基芬片。该类药物主要用于缓解感冒后发热、头痛、关节痛等症状。有胃病、消化道溃疡病史的人要慎用，疼痛症状明显加重或出现新的疼痛症状，以及连续用药三天不能缓解的，要咨询医生或药师。这两种药物均有儿童剂型可供选择。 止咳化痰药： 可备氢溴酸右美沙芬片、蛇胆川贝枇杷膏；化痰药物可以选择盐酸氨溴索片、乙酰半胱氨酸颗粒等。针对干咳，一般会使用中枢性镇咳药，目前，唯一一种非处方中枢性镇咳药是氢溴酸右美沙芬，市售有糖浆剂和片剂。 止泻药： 可备口服补液盐散、蒙脱石散。前者能预防和纠正腹泻导致的脱水；后者是高效消化道黏膜保护剂，具有改善肠道的吸收和分泌功能，能有效阻止病原微生物的攻击。不过腹泻最好在发病初期到医院筛查病因，这样才能有的放矢。 通便药： 可选乳果糖。它不被人体吸收，通过刺激结肠蠕动，缓解便秘，尤其适宜老年人、孕产妇、儿童及术后便秘者。应注意，便秘不应单纯依赖药物治疗，还要从改变生活方式改良饮食习惯入手。 抗过敏药： 如氯雷他定，属于抗组胺类抗过敏药，适用于皮肤过敏、食物及药物过敏等。氯雷他定除了有片剂外，还有儿童使用的糖浆剂和滴剂。 助消化药： 如多酶片、健胃消食片等。 家庭备药注意四大原则： 第一，根据家庭人员的组成和健康状况备药，注意老人、小孩与孕妇的用药；严禁混入家庭成员过敏的药物； 第二，选择不良反应较少的非处方药（OTC药）； 第三，选择疗效稳定、用法简单的药物，如口服药、外用药等。 第四，选择常见病、多发病用药。家庭备药一般只是作为应急或方便，无需面面俱到。 @ref: http://baby.sina.com.cn/health/mmjk/hzbhy/2018-05-08/doc-ifyuwqfa7628610.shtml","categories":[{"name":"73.Health-and-Medicine","slug":"73-Health-and-Medicine","permalink":"https://beefyheisenberg.github.io/categories/73-Health-and-Medicine/"}],"tags":[{"name":"药物指南","slug":"药物指南","permalink":"https://beefyheisenberg.github.io/tags/药物指南/"}]},{"title":"中医药黑名单","slug":"73.Health-and-Medicine/中医药黑名单","date":"2024-01-24T01:27:54.296Z","updated":"2024-01-24T01:27:54.297Z","comments":true,"path":"73.Health-and-Medicine/中医药黑名单/","link":"","permalink":"https://beefyheisenberg.github.io/73.Health-and-Medicine/中医药黑名单/","excerpt":"马兜铃酸/细辛&amp;关木通&amp;鱼腥草 致病：马兜铃酸及其进入人体后代谢出来的马兜铃内酰胺1型会导致马兜铃酸肾病 药材： 细辛(马兜铃科) 关木通(马兜铃科) 青木香 广防己 鱼腥草(折耳根)：目前被认为有强致癌性的是马兜铃酸I，而折耳根（鱼腥草）中含的则是马兜铃内酰胺-BII、马兜铃内酰胺-AII和马兜铃内酰胺-FII（总0.016g/kg）。鱼腥草不是马兜铃科的植物，但是其含有马兜铃酸在人体代谢后的产物内酰胺 成品： 当归四逆加吴茱萸生姜汤 龙胆泻肝丸 各类凉茶 参考： 鱼腥草（折耳根）会导致马兜铃肾病，甚至肾衰吗？ - 知乎 砷化物/雄黄 药材： 雄黄：四硫化四砷 成品： 牛黄解毒片：牛黄解毒片的成分有牛黄、雄黄、石膏、大黄、黄芩、桔梗、冰片和甘草 参考： 牛黄解毒片中的雄黄会导致中毒么？ - 知乎 重金属/朱砂","text":"马兜铃酸/细辛&amp;关木通&amp;鱼腥草 致病：马兜铃酸及其进入人体后代谢出来的马兜铃内酰胺1型会导致马兜铃酸肾病 药材： 细辛(马兜铃科) 关木通(马兜铃科) 青木香 广防己 鱼腥草(折耳根)：目前被认为有强致癌性的是马兜铃酸I，而折耳根（鱼腥草）中含的则是马兜铃内酰胺-BII、马兜铃内酰胺-AII和马兜铃内酰胺-FII（总0.016g/kg）。鱼腥草不是马兜铃科的植物，但是其含有马兜铃酸在人体代谢后的产物内酰胺 成品： 当归四逆加吴茱萸生姜汤 龙胆泻肝丸 各类凉茶 参考： 鱼腥草（折耳根）会导致马兜铃肾病，甚至肾衰吗？ - 知乎 砷化物/雄黄 药材： 雄黄：四硫化四砷 成品： 牛黄解毒片：牛黄解毒片的成分有牛黄、雄黄、石膏、大黄、黄芩、桔梗、冰片和甘草 参考： 牛黄解毒片中的雄黄会导致中毒么？ - 知乎 重金属/朱砂 成分：硫化汞 成品：兰州牛黄清心丸 生物碱/乌头碱 致病：乌头类中药主要毒性成分是乌头碱等生物碱，人口服乌头碱3-5mg可使人致死。乌头碱主要损害循环系统及中枢神经系统，其对循环系统的损害主要是导致各种心律失常。 药材： 附子：为毛茛科植物，母根叫乌头，为镇痉剂，冶风庳，风湿神经痛。侧根（子根）入药，叫附子。 草乌 川乌 成品： 云南白药 参考： 云南白药中的毒药 - 丁香园 乌头类草药：处处带毒，防不胜防 卫生署中医药规管办公室 生物碱/番木鳖碱 致病：番木鳖碱（士的宁，strychnine）其口服中毒剂量成人一般为5～10 mg，口服致死量为30 mg。士的宁对整个中枢神经系统有兴奋作用。马钱子中毒的早期症状为头痛，头晕、恶心、呕吐、焦虑、烦躁不安及轻度抽搐，继之出现全身抽搐、感觉器官敏感性增高、牙关紧闭、痉笑、角弓反张、吞咽和呼吸困难。患者通常死于呼吸骤停。 药材： 马钱子：马钱子是马钱科植物马钱的干燥成熟种子。马钱子含有多种生物碱，主要为番木鳖碱（士的宁，strychnine）和马钱子碱。别名有番木鳖、乌鸦眼、苦实、马前、牛银等 黄连素长教训了！一颗黄连素片害我差点断送职业生涯 蚕豆病是一种遗传性溶血性疾病，本质是红细胞葡萄糖-6-磷酸脱氢酶（G6PD）缺乏症的一种表现类型，这类病人可能因为食用蚕豆或服用特定药物诱发溶血反应，严重时可出现黄疸，甚至危及生命。 黄连素片（盐酸小檗碱片）就是蚕豆病的禁用药之一，这个药可能会导致蚕豆病病人溶血 黄连是一种常用的中药，不仅“治病”，还能“防病”。例如我国某些地区有给新生儿喂黄连的习俗，认为可以“去胎毒”。由于国内药物不良反应的监测与上报均不完善，我们很难得到黄连中毒及不良反应的全面信息，但新生儿因喂黄连导致中毒，产生溶血、胃肠道反应乃至致死的事件，却时有耳闻。黄连并不会对所有新生儿或成人都产生毒性，而是针对某些特定人群。遗传的原因使这些人体内缺少一种酶，即葡萄糖-6-磷酸脱氢酶，简称G6PD。缺少这种酶的人，体内无法产生足够的NADPH，而NADPH又是抗氧化剂GSH循环使用的必须物质。简言之，缺少G6PD，人体就不能产生足够的抗氧化剂，容易受到氧自由基的损伤。人体中氧含量最丰富的细胞是专门携带氧的红细胞，而红细胞只能靠GSH来抗氧化。当体内氧化剂突然增多时，红细胞就会产生大量的氧自由基。正常人可以自体清除氧自由基，但缺少G6PD的人则不能，红细胞会受自由基损伤而大量破坏，也就是溶血反应。人会头痛、全身不适、高热、肾功能衰竭，严重者可致死。历史上记载这种病多见于蚕豆产地，大多因吃新鲜蚕豆而诱发，所以又叫蚕豆病。中国人缺乏G6PD的很多，尤其是南方人群，据报道发病率最高的广东省可达8.7%。而给新生儿喂黄连的也以南方居多。因为历史的原因，这类习俗也传到了东南亚。因为“疗效”没有任何依据，却会有溶血的风险，在上世纪70年代，新加坡就禁用了黄连。2016年新加坡解除了黄连禁令，但仍然禁止给婴儿、G6PD酶素缺乏症患者、孕妇和哺乳期妇女使用。美国则在上世纪90年代禁用了含黄连的膳食补充剂。 参考： 黄连翻案为哪般？ - 知乎","categories":[{"name":"73.Health-and-Medicine","slug":"73-Health-and-Medicine","permalink":"https://beefyheisenberg.github.io/categories/73-Health-and-Medicine/"}],"tags":[{"name":"药物指南","slug":"药物指南","permalink":"https://beefyheisenberg.github.io/tags/药物指南/"}]},{"title":"饮食健康.升糖指数（GI）","slug":"73.Health-and-Medicine/饮食健康.升糖指数（GI）","date":"2024-01-24T01:27:54.287Z","updated":"2024-01-24T01:27:54.288Z","comments":true,"path":"73.Health-and-Medicine/饮食健康.升糖指数（GI）/","link":"","permalink":"https://beefyheisenberg.github.io/73.Health-and-Medicine/饮食健康.升糖指数（GI）/","excerpt":"","text":"GI (Glycemic index / 升糖指数)：GI越高意味着食物转化成血糖的时间越短。 为何高碳水食物导致犯困：碳水化合物含量较高且升糖指数较高的，会迅速导致血糖升高从而导致大量胰岛素的分泌。胰岛素让一种特别的氨基酸—色氨酸进入大脑，而色氨酸在大脑中会转变成血清素导致人们犯困。 食物升糖指数： 高GI食物： 白面包，白米，红薯，白薯 低GI食物： 黑豆，lentil，鹰嘴豆，芝麻，花生，瓜子，核桃，腰果，糙粮，蘑菇等","categories":[{"name":"73.Health-and-Medicine","slug":"73-Health-and-Medicine","permalink":"https://beefyheisenberg.github.io/categories/73-Health-and-Medicine/"}],"tags":[{"name":"饮食健康","slug":"饮食健康","permalink":"https://beefyheisenberg.github.io/tags/饮食健康/"}]},{"title":"饮食健康.高嘌呤食物","slug":"73.Health-and-Medicine/饮食健康.高嘌呤食物","date":"2024-01-24T01:27:54.283Z","updated":"2024-01-24T01:27:54.283Z","comments":true,"path":"73.Health-and-Medicine/饮食健康.高嘌呤食物/","link":"","permalink":"https://beefyheisenberg.github.io/73.Health-and-Medicine/饮食健康.高嘌呤食物/","excerpt":"","text":"▶ 嘌呤： 有机化合物，分子式C5H4N4,无色结晶，在人体内嘌呤氧化而变成尿酸。人体尿酸过高就会引起痛风。 ▶ 食物含量(单位 100g食物/mg嘌呤)： 低嘌呤（小于50毫克）： 五谷类（米、麦、高梁、玉米、马铃薯） 蛋类（鸡蛋、鸭蛋） 奶制品（牛奶、奶酪） 水果 中等嘌呤（50~150毫克）： 肉类：鸡肉、猪肉、牛肉、羊肉、鱼100~150mg、虾80~130mg 豆类：黑豆、绿豆、红豆、花豆、碗豆 高嘌呤： 海产：紫菜270mg、 动物内脏： 鸭肝300mg、牛肝233mg、牛肾200mg、胰脏825mg 肉汤：160-400mg @ref: 嘌呤食物_百度百科","categories":[{"name":"73.Health-and-Medicine","slug":"73-Health-and-Medicine","permalink":"https://beefyheisenberg.github.io/categories/73-Health-and-Medicine/"}],"tags":[{"name":"饮食健康","slug":"饮食健康","permalink":"https://beefyheisenberg.github.io/tags/饮食健康/"}]},{"title":"饮食健康.生酮饮食","slug":"73.Health-and-Medicine/饮食健康.生酮饮食","date":"2024-01-24T01:27:54.279Z","updated":"2024-01-24T01:27:54.279Z","comments":true,"path":"73.Health-and-Medicine/饮食健康.生酮饮食/","link":"","permalink":"https://beefyheisenberg.github.io/73.Health-and-Medicine/饮食健康.生酮饮食/","excerpt":"生酮饮食▶ 生酮饮食：大幅降低碳水化合物比例，蛋白质比例不变，空缺出来的部分就靠脂肪类填补。 生酮饮食（ketogenic diet，或简称keto diet）指的是脂肪含量多、蛋白质含量中低、碳水化合物含量极低的食物。这类食物给人体带来酮症（ketosis），从而导致了酮类（ketones）分子的形成。当人体因缺少碳水化合物而被迫燃烧脂肪以补充能量时，上述过程就会发生。 「生酮」是指一个令身体产「生」「酮」体的过程。由于摄取极低量的碳水化合物，促使肝糖用尽，身体便会开始燃烧脂肪，继而产生称为「酮体」的代谢物。 医学上曾经主用于治疗儿童的困难控制型癫痫；正常情况下，碳水化合物经人体吸收后会转化为葡萄糖运往身体各处及供给能量，尤其是用于维持大脑运作。然而由于生酮饮食中只摄取少量的低碳水化合物，肝脏便会将脂肪转换为脂肪酸和酮体。酮体运到脑部取代葡萄糖成为能量来源。当血液中酮体含量达到一定程度时，即为酮症，能缓和癫痫的频繁发作。","text":"生酮饮食▶ 生酮饮食：大幅降低碳水化合物比例，蛋白质比例不变，空缺出来的部分就靠脂肪类填补。 生酮饮食（ketogenic diet，或简称keto diet）指的是脂肪含量多、蛋白质含量中低、碳水化合物含量极低的食物。这类食物给人体带来酮症（ketosis），从而导致了酮类（ketones）分子的形成。当人体因缺少碳水化合物而被迫燃烧脂肪以补充能量时，上述过程就会发生。 「生酮」是指一个令身体产「生」「酮」体的过程。由于摄取极低量的碳水化合物，促使肝糖用尽，身体便会开始燃烧脂肪，继而产生称为「酮体」的代谢物。 医学上曾经主用于治疗儿童的困难控制型癫痫；正常情况下，碳水化合物经人体吸收后会转化为葡萄糖运往身体各处及供给能量，尤其是用于维持大脑运作。然而由于生酮饮食中只摄取少量的低碳水化合物，肝脏便会将脂肪转换为脂肪酸和酮体。酮体运到脑部取代葡萄糖成为能量来源。当血液中酮体含量达到一定程度时，即为酮症，能缓和癫痫的频繁发作。 如何安排三餐一份生酮食谱需要人们严格执行膳食计划，其中包括：像培根、多脂奶油和黄油等高脂肪食物，与此同时，还要严格限制如淀粉类蔬菜的摄入，包括：番薯、全谷物以及某些特定的水果。这种饮食习惯上的巨大改变会导致呕吐、消化不良、无意识的体重减轻以及风险增高的营养不良的现象。 每日热量 = 5%碳水 + 25%蛋白质 + 70%脂肪 在进行生酮饮食时，碳水化合物应只占总热量的5%！生酮饮食餐单的比例限定每天碳水化合物的摄取量少于50克，从而降低胰岛素的分泌量，减少胰岛素阻抗的程度，更能稳定体重。 蛋白质提供20%到25%的热量 依靠脂肪提供约70%到75%剩下最大部分的热量。 三餐示例: 早餐: 煎鸡蛋 咖啡或热茶中加入一大已融化的奶油、椰子油或中链脂肪酸油来作为生酮饮品 午餐: 鸡肉沙拉, 搭配 初榨橄榄油、牛油果油或以这些油品来制作的沙律酱 晚餐: 煎三文鱼 阿特金斯饮食法阿特金斯饮食法 - 维基百科，自由的百科全书 阿特金斯饮食法（英语：Atkins diet）是美国医生罗伯特·阿特金斯（Robert Atkins）创造的一种颇具争议的减肥饮食方法，其要求完全不吃碳水化合物，而可以吃高蛋白的食品，即不吃任何淀粉类、高糖分的食品，而多吃肉类、鱼。其核心是控制碳水化合物的摄入量，类似生酮饮食，从而将人体从消耗碳水化合物的代谢转化成以消耗脂肪为主的代谢模式。[1][2]阿特金斯饮食法被认为属于“食物盲从”，只有薄弱的证据支撑其在减肥方面的有效性。多吃高蛋白质食物会增加肾的负担，所以该方法并不适合有肾脏病的人使用（多数国家的肾脏疾病患病率超过10%，而且许多轻微的肾脏疾病患者并不自知）。 阿特金斯和生酮哪个好，有什么区别？阿特金斯减肥法会不会也让身体进入生酮期？ - 知乎","categories":[{"name":"73.Health-and-Medicine","slug":"73-Health-and-Medicine","permalink":"https://beefyheisenberg.github.io/categories/73-Health-and-Medicine/"}],"tags":[{"name":"饮食健康","slug":"饮食健康","permalink":"https://beefyheisenberg.github.io/tags/饮食健康/"}]},{"title":"饮食健康.IBS（肠易激综合征）","slug":"73.Health-and-Medicine/饮食健康.IBS（肠易激综合征）","date":"2024-01-24T01:27:54.275Z","updated":"2024-01-24T01:27:54.275Z","comments":true,"path":"73.Health-and-Medicine/饮食健康.IBS（肠易激综合征）/","link":"","permalink":"https://beefyheisenberg.github.io/73.Health-and-Medicine/饮食健康.IBS（肠易激综合征）/","excerpt":"肠易激综合征（irritable bowel syndrome，IBS） “喝了冰冻饮料就会拉肚子” “紧张一点会有腹痛感” “吃了某些‘寒气’食物就会拉肚子” “肚子痛然后马上就像上厕所” 压力、紧张也会导致： 一有压力就胃痛，肠易激综合征如何解决？ 什么引起：腹泻由FODMAP（Fermentable Oligo-, Di-, Mono-saccharides And Polyols，可发酵的寡糖，二糖，单糖和多元醇）引起，FODMAP包括： Fructose：果糖 Lactose：乳糖 Mannitol：甘露糖醇 Sorbitol：山梨糖醇 GOS：低聚半乳糖 Fructan：果聚糖 为什么FODMAP等糖类引起腹泻： 无法被小肠吸收的短链碳水化合物（被称为FODMAP）会将进入大肠，大肠内细菌会迅速发酵FODMAP并产生过量气体。 大量水分和过量气体导致肠道过分扩展，肠壁因扩张而过分延伸，肠壁上高度连接的神经会马上向大脑传输疼痛信号。于是人就会出现腹痛、腹泻。 IBS患者不能吃什么：高FODMAP的食物 Furctose 果糖： 蜂蜜 Lactos 乳糖： 牛奶 Mannitol 甘露糖醇/Sorbitol 山梨糖醇： 雪梨、桃子、苹果 GOS 低聚半乳糖/Fructan 果聚糖：小麦、黑麦、洋葱、大蒜、豆类 IBS患者吃什么：低FODMAP的食物可以降低IBS症状，燕麦、香蕉、少量芒果、少量北杏仁是符合低FODMAP的食物 麦片：避免添加奶粉和糖的麦片 图1: FODMAP糖类 和 引起腹泻的原因 识别生活中常见的高/低FODMAP食物：注意! 面粉(面包,馒头,面)是高FODMAP, 米饭是低FODMAP食物","text":"肠易激综合征（irritable bowel syndrome，IBS） “喝了冰冻饮料就会拉肚子” “紧张一点会有腹痛感” “吃了某些‘寒气’食物就会拉肚子” “肚子痛然后马上就像上厕所” 压力、紧张也会导致： 一有压力就胃痛，肠易激综合征如何解决？ 什么引起：腹泻由FODMAP（Fermentable Oligo-, Di-, Mono-saccharides And Polyols，可发酵的寡糖，二糖，单糖和多元醇）引起，FODMAP包括： Fructose：果糖 Lactose：乳糖 Mannitol：甘露糖醇 Sorbitol：山梨糖醇 GOS：低聚半乳糖 Fructan：果聚糖 为什么FODMAP等糖类引起腹泻： 无法被小肠吸收的短链碳水化合物（被称为FODMAP）会将进入大肠，大肠内细菌会迅速发酵FODMAP并产生过量气体。 大量水分和过量气体导致肠道过分扩展，肠壁因扩张而过分延伸，肠壁上高度连接的神经会马上向大脑传输疼痛信号。于是人就会出现腹痛、腹泻。 IBS患者不能吃什么：高FODMAP的食物 Furctose 果糖： 蜂蜜 Lactos 乳糖： 牛奶 Mannitol 甘露糖醇/Sorbitol 山梨糖醇： 雪梨、桃子、苹果 GOS 低聚半乳糖/Fructan 果聚糖：小麦、黑麦、洋葱、大蒜、豆类 IBS患者吃什么：低FODMAP的食物可以降低IBS症状，燕麦、香蕉、少量芒果、少量北杏仁是符合低FODMAP的食物 麦片：避免添加奶粉和糖的麦片 图1: FODMAP糖类 和 引起腹泻的原因 识别生活中常见的高/低FODMAP食物：注意! 面粉(面包,馒头,面)是高FODMAP, 米饭是低FODMAP食物 @ref： 经常肚子痛拉肚子？你很可能患有IBS - 知乎","categories":[{"name":"73.Health-and-Medicine","slug":"73-Health-and-Medicine","permalink":"https://beefyheisenberg.github.io/categories/73-Health-and-Medicine/"}],"tags":[{"name":"饮食健康","slug":"饮食健康","permalink":"https://beefyheisenberg.github.io/tags/饮食健康/"}]},{"title":"如何在 2 分钟内入睡","slug":"73.Health-and-Medicine/如何在 2 分钟内入睡","date":"2024-01-24T01:27:54.268Z","updated":"2024-01-24T01:27:54.268Z","comments":true,"path":"73.Health-and-Medicine/如何在 2 分钟内入睡/","link":"","permalink":"https://beefyheisenberg.github.io/73.Health-and-Medicine/如何在 2 分钟内入睡/","excerpt":"在二战那几年，美军意识到了一个问题：由于空中作战的巨大压力，许多飞行员都存在着应激反应，这让他们身体虚弱，不堪负重。从而犯下一系列致命的错误，无意击中友军飞机或者自己的误操作而受伤。 为了阻止飞行员和飞机的损失，海军少尉 Bud Winter 开始研究测试一种可以训练的放松方法，以便飞行员能够减压，提高反应速度，增加注意力减少恐惧。 战前 Winter 是一个成功的大学橄榄球和田径教练，他与心理学教授一起合作，帮助运动员在高压下放松并取得更好的表现。 他将睡眠定义为「身心放松的状态」。第一步是身体放松，第二步是心理放松。","text":"在二战那几年，美军意识到了一个问题：由于空中作战的巨大压力，许多飞行员都存在着应激反应，这让他们身体虚弱，不堪负重。从而犯下一系列致命的错误，无意击中友军飞机或者自己的误操作而受伤。 为了阻止飞行员和飞机的损失，海军少尉 Bud Winter 开始研究测试一种可以训练的放松方法，以便飞行员能够减压，提高反应速度，增加注意力减少恐惧。 战前 Winter 是一个成功的大学橄榄球和田径教练，他与心理学教授一起合作，帮助运动员在高压下放松并取得更好的表现。 他将睡眠定义为「身心放松的状态」。第一步是身体放松，第二步是心理放松。 如何身体放松？在「Relax and Win」一书中，Winter 写到了为战斗飞行员开发的这套入睡技术，战后用于运动员身上也特别奏效，他列出明确的步骤，教运动员如何放松： 坐在你的椅子上，两脚放在地板上。膝盖分开，手在膝盖内侧无力耷拉着。现在，闭上眼睛，放下下巴，直到它落在你的胸前。 有规律地、缓慢地深呼吸。让额头的皱纹都出现再舒展开，放松你的头皮。放松脸部其余肌肉，放松你的舌头和嘴唇，就像你在河边看到的鳟鱼那样嘴一开一合，缓慢呼吸。 现在来处理一下眼部八块肌肉。闭眼的同时，眼睛在眼窝中随意翻动，没有什么重点，就是上下左右翻动就行，缓慢呼吸。 现在，把肩膀放的尽可能低，就算你认为很低了，但是让它们更低。感受脖子后面的肌肉，当你觉得已经很放松了，尝试着让它们再进一步。 现在放松你的胸部。深吸一口气，屏住，呼气并吹出你所有的紧张情绪。让你的胸部瘪下去，想象在椅子上，自己是一直笨重的水母。缓慢呼吸，呼气时，释放越来越多的紧张情绪。 现在关注手臂。放松右二头肌，右前臂也一样，然后右手，手指。然后在左臂重复，且保持缓慢呼吸。 你的上半身已经放松了，感觉温暖而愉快，感觉良好，幸福感侵入身体。 现在该下半身了，先右大腿肌肉，想象着肉挂在机构上，放松。然后是小腿肌肉，在之后是右脚踝和脚部肌肉。告诉自己，右腿没骨头。在左腿重复。感觉自己就是椅子上的一堆肉。 目前，我们身心放松，或者你觉得如此。为了保险，我们深呼吸三次，呼出最后的紧张，一次，呼，两次，呼，三次，呼~~~ 如果你无法感觉自己身体的松弛，以及水母般的感受，请尝试拉紧肌肉，然后使之放松。 如果遵从上述步骤，你可以达到一个很好地放松水平。Winter 建议，在任何压力大的时候尝试这个练习，可以很好的放松，减压，提高专注力，促成更好的决策。 这只是第一步，身体的放松，下一步精神的放松可以「跨越门槛进入深度、轻松的睡眠」。 如何精神放松Winter 认为，一旦你身体放松了，只要头脑十秒钟内没有任何活跃的想法，你就会睡着。快速入睡的关键就在于「停止你脑中奔腾的想法」，你必须停止反思当天的遗憾、忧虑、问题。 Winter 特别警告，不要有任何运动的想法：现代研究证实了，只要我们在脑海中想象身体运动，相关肌肉会处于激活状态。所以，当你试图入睡的时候，积极活跃的想法可能导致肌肉紧张并抑制睡眠。 所以，如果你想用最沉默的思考来填满你的脑袋，Winter 有三个建议，这里有任何一条都可以帮助你，只需要选一个就行，如果不行就选另一个： 幻想这是一个温暖的春日，而且你正躺在一个非常宁静的湖上独木舟的里。你正在仰望蓝天与云朵，浮动的云彩。不要有任何其他想法。只要专注于个画面十秒钟。 想象你正躺在一个黑色天鹅绒大床上，而且房子的其他地方全都是黑色的，专注这个画面十秒钟。 第三个窍门，在脑海中说「不要想、不要想、不要想。。。」，持续十秒钟，消除其他想法。 @ref: Fall Asleep Fast — In 2 Minutes or Less | Art of Manliness","categories":[{"name":"73.Health-and-Medicine","slug":"73-Health-and-Medicine","permalink":"https://beefyheisenberg.github.io/categories/73-Health-and-Medicine/"}],"tags":[]},{"title":"Fitness-and-Gym指南","slug":"73.Health-and-Medicine/Fitness-and-Gym指南","date":"2024-01-24T01:27:54.263Z","updated":"2024-01-24T01:27:54.263Z","comments":true,"path":"73.Health-and-Medicine/Fitness-and-Gym指南/","link":"","permalink":"https://beefyheisenberg.github.io/73.Health-and-Medicine/Fitness-and-Gym指南/","excerpt":"健身房-器械力竭和组间休息 每组力竭的话和组间休息时间怎么安排？ - 知乎什么是组间间歇？假设我们锻炼一个部位采用abcd四个动作，我们首先使用a动作，一般采用递增的重量连续做四组，a动作四组之间的休息时间即为组间间歇时间。还有一种情况是a动作四组结束之后与b动作之间的休息时间，同样b动作结束后连接c动作的时间。正确的组间间歇：你可以通过带一个秒表或者一款心率表去健身房，通过这两块表来控制组间间歇时间，组间间歇一般在0s—90s之间（除硬拉，深蹲等大重量动作），并且时间越短越好。 [Gym]颈前正握下拉","text":"健身房-器械力竭和组间休息 每组力竭的话和组间休息时间怎么安排？ - 知乎什么是组间间歇？假设我们锻炼一个部位采用abcd四个动作，我们首先使用a动作，一般采用递增的重量连续做四组，a动作四组之间的休息时间即为组间间歇时间。还有一种情况是a动作四组结束之后与b动作之间的休息时间，同样b动作结束后连接c动作的时间。正确的组间间歇：你可以通过带一个秒表或者一款心率表去健身房，通过这两块表来控制组间间歇时间，组间间歇一般在0s—90s之间（除硬拉，深蹲等大重量动作），并且时间越短越好。 [Gym]颈前正握下拉 [Gym]宽握引体向上 使用哑铃进行练习哑铃7天训练-飞特那斯全身哑铃7天训练方案，适合所有人，家庭训练必备 - 知乎 哑铃7天训练时间表第1天，背+肩：00：00-03：11第2天，胸+肩：03：12-06：28第3天，休息：06：28-06：30第4天，二头+三头：06：30-11：18第5天，三角肌：11：18-13：40第6天，臀腿+小腿：13:40-16：33第7天，休息:16：33-16：35 Day 1（背+肩） 哑铃训练动作参考单臂哑铃划船 坐姿臂弯举 哑铃颈后臂屈伸 哑铃推举/侧平举","categories":[{"name":"73.Health-and-Medicine","slug":"73-Health-and-Medicine","permalink":"https://beefyheisenberg.github.io/categories/73-Health-and-Medicine/"}],"tags":[{"name":"Gym","slug":"Gym","permalink":"https://beefyheisenberg.github.io/tags/Gym/"},{"name":"健身房","slug":"健身房","permalink":"https://beefyheisenberg.github.io/tags/健身房/"}]},{"title":"贝叶斯公式","slug":"72.Math-and-Logic/贝叶斯公式","date":"2024-01-24T01:27:54.259Z","updated":"2024-01-24T01:27:54.259Z","comments":true,"path":"72.Math-and-Logic/贝叶斯公式/","link":"","permalink":"https://beefyheisenberg.github.io/72.Math-and-Logic/贝叶斯公式/","excerpt":"","text":"➤ 贝叶斯公式 P(A|B)是B发生的情况下, A发生的可能性, 贝叶斯公式:$$ P(A|B) = P(B|A)*P(A)/P(B) $$ @ref: Think Bayes - 我所理解的贝叶斯定理 - 知乎","categories":[{"name":"72.Math-and-Logic","slug":"72-Math-and-Logic","permalink":"https://beefyheisenberg.github.io/categories/72-Math-and-Logic/"}],"tags":[]},{"title":"傅里叶变换","slug":"72.Math-and-Logic/傅里叶变换","date":"2024-01-24T01:27:54.255Z","updated":"2024-01-24T01:27:54.255Z","comments":true,"path":"72.Math-and-Logic/傅里叶变换/","link":"","permalink":"https://beefyheisenberg.github.io/72.Math-and-Logic/傅里叶变换/","excerpt":"➤ 傅里叶变换 傅里叶级数: 任何周期函数, 都可以看做不同振幅,不同相位的正弦波的叠加 图: 周期函数 → N个正弦波叠加 上图从频域看… 频域的x/y轴物理意义是? 即傅里叶级数的频谱 上图频域里的离散信号, 如果无限接近连续.. 频域的相位谱 傅里叶级数: (时域)周期连续 → (频域)非周期离散 傅里叶变换: (时域)非周期连续→ (频域)非周期连续 虚数: 虚数i也即-1的平方根, 乘以虚数可以理解为: 旋转 欧拉公式: $$ e^(ix) = cos(x) + isin(x) $$ @ref: 傅里叶分析之掐死教程（完整版）更新于2014.06.06 - 知乎","text":"➤ 傅里叶变换 傅里叶级数: 任何周期函数, 都可以看做不同振幅,不同相位的正弦波的叠加 图: 周期函数 → N个正弦波叠加 上图从频域看… 频域的x/y轴物理意义是? 即傅里叶级数的频谱 上图频域里的离散信号, 如果无限接近连续.. 频域的相位谱 傅里叶级数: (时域)周期连续 → (频域)非周期离散 傅里叶变换: (时域)非周期连续→ (频域)非周期连续 虚数: 虚数i也即-1的平方根, 乘以虚数可以理解为: 旋转 欧拉公式: $$ e^(ix) = cos(x) + isin(x) $$ @ref: 傅里叶分析之掐死教程（完整版）更新于2014.06.06 - 知乎","categories":[{"name":"72.Math-and-Logic","slug":"72-Math-and-Logic","permalink":"https://beefyheisenberg.github.io/categories/72-Math-and-Logic/"}],"tags":[]},{"title":"博弈论","slug":"72.Math-and-Logic/博弈论","date":"2024-01-24T01:27:54.248Z","updated":"2024-01-24T01:27:54.248Z","comments":true,"path":"72.Math-and-Logic/博弈论/","link":"","permalink":"https://beefyheisenberg.github.io/72.Math-and-Logic/博弈论/","excerpt":"博弈论相关概念 纳什均衡 囚徒困境 重复博弈 大众定理 信息 帕累托最优 零和博弈 非零和博弈 微分包含式 拍卖博弈 帕累托最优帕累托最优 也称为帕累托效率（Pareto Efficiency）、帕雷托最佳配置，是博弈论中的重要概念，并且在经济学， 工程学和社会科学中有着广泛的应用。 帕累托最优是指资源分配的一种理想状态，假定固有的一群人和可分配的资源，从一种分配状态到另一种状态的变化中，在没有使任何人境况变坏的前提下，使得至少一个人变得更好，这就是帕累托改进或帕累托最优化。帕累托最优的状态就是不可能再有更多的帕累托改进的余地；换句话说，帕累托改进是达到帕累托最优的路径和方法。帕累托最优是公平与效率的“理想王国”。 帕累托最优回答的是效率问题。从社会福利角度出发，用效率来评价总体经济运行有其合理性，因为如果资源配置未达到帕累托最优，那么，总有一些人能改善境况而没有人会受损，也就是说，社会福利总量肯定能上升，那么通过一种恰当的分配或补偿措施，能使所有人的境况都有所改善。[1] 举例1：假设现在有两个人，甲和乙，分10块蛋糕，并且两个人都喜欢吃蛋糕。10块蛋糕无论在两个人之间如何分配，都是帕累托最优，因为你想让某一个人拥有更大利益的唯一办法是从另一个人手里拿走蛋糕，导致的结果是那个被拿走蛋糕的人利益受损","text":"博弈论相关概念 纳什均衡 囚徒困境 重复博弈 大众定理 信息 帕累托最优 零和博弈 非零和博弈 微分包含式 拍卖博弈 帕累托最优帕累托最优 也称为帕累托效率（Pareto Efficiency）、帕雷托最佳配置，是博弈论中的重要概念，并且在经济学， 工程学和社会科学中有着广泛的应用。 帕累托最优是指资源分配的一种理想状态，假定固有的一群人和可分配的资源，从一种分配状态到另一种状态的变化中，在没有使任何人境况变坏的前提下，使得至少一个人变得更好，这就是帕累托改进或帕累托最优化。帕累托最优的状态就是不可能再有更多的帕累托改进的余地；换句话说，帕累托改进是达到帕累托最优的路径和方法。帕累托最优是公平与效率的“理想王国”。 帕累托最优回答的是效率问题。从社会福利角度出发，用效率来评价总体经济运行有其合理性，因为如果资源配置未达到帕累托最优，那么，总有一些人能改善境况而没有人会受损，也就是说，社会福利总量肯定能上升，那么通过一种恰当的分配或补偿措施，能使所有人的境况都有所改善。[1] 举例1：假设现在有两个人，甲和乙，分10块蛋糕，并且两个人都喜欢吃蛋糕。10块蛋糕无论在两个人之间如何分配，都是帕累托最优，因为你想让某一个人拥有更大利益的唯一办法是从另一个人手里拿走蛋糕，导致的结果是那个被拿走蛋糕的人利益受损 纳什均衡纳什均衡 是指博弈中这样的局面，又称为非合作博弈均衡，对于每个参与者来说，只要其他人不改变策略，这个参与者就无法改善自己的状况。纳什证明了在每个参与者都只有有限种策略选择并允许混合策略的前提下，纳什均衡定存在。以两家公司的价格大战为例，价格大战存在着两败俱伤的可能，在对方不改变价格的条件下既不能提价，否则会进一步丧失市场;也不能降价,因为会出现赔本甩卖。于是两家公司可以改变原先的利益格局，通过谈判寻求新的利益评估分摊方案。相互作用的经济主体假定其他主体所选择的战略为既定时，选择自己的最优战略的状态，也就是纳什均衡。 举例1：1950年，由就职于兰德公司的梅里尔·弗勒德和梅尔文·德雷希尔拟定出相关困境的理论，后来由顾问艾伯特·塔克以囚徒方式阐述，并命名为“囚徒困境”。经典的囚徒困境如下： 警方逮捕甲、乙两名嫌疑犯，但没有足够证据指控二人有罪。于是警方分开囚禁嫌疑犯，分别和二人见面，并向双方提供以下相同的选择： 若一人认罪并作证检控对方（相关术语称“背叛”对方），而对方保持沉默，此人将即时获释，沉默者将判监10年。 若二人都保持沉默（相关术语称互相“合作”），则二人同样判监半年。 若二人都互相检举（互相“背叛”），则二人同样判监5年。 解说： 如同博弈论的其他例证，囚徒困境假定每个参与者（即“囚徒”）都是利己的，即都寻求最大自身利益，而不关心另一参与者的利益。参与者某一策略所得利益，如果在任何情况下都比其他策略要低的话，此策略称为“严格劣势”，理性的参与者绝不会选择。另外，没有任何其他力量干预个人决策，参与者可完全按照自己意愿选择策略。 囚徒到底应该选择哪一项策略，才能将自己个人的刑期缩至最短？两名囚徒由于隔绝监禁，并不知道对方选择；而即使他们能交谈，还是未必能够尽信对方不会反口。就个人的理性选择而言，检举背叛对方所得刑期，总比沉默要来得低。试设想困境中两名理性囚徒会如何作出选择： 若对方沉默、我背叛会让我获释，所以会选择背叛。 若对方背叛指控我，我也要指控对方才能得到较低的刑期，所以也是会选择背叛。 二人面对的情况一样，所以二人的理性思考都会得出相同的结论——选择背叛。背叛是两种策略之中的支配性策略。因此，这场博弈中唯一可能达到的纳什均衡，就是双方参与者都背叛对方，结果二人同样服刑5年。 这场博弈的纳什均衡，显然不是顾及团体利益的帕累托最优解决方案。以全体利益而言，如果两个参与者都合作保持沉默，两人都只会被判刑半年，总体利益更高，结果也比两人背叛对方、判刑5年的情况较佳。但根据以上假设，二人均为理性的个人，且只追求自己个人利益。均衡状况会是两个囚徒都选择背叛，结果二人判监均比合作为高，总体利益较合作为低。这就是“困境”所在。例子有效地证明了：非零和博弈中，帕累托最优和纳什均衡是互相冲突的。","categories":[{"name":"72.Math-and-Logic","slug":"72-Math-and-Logic","permalink":"https://beefyheisenberg.github.io/categories/72-Math-and-Logic/"}],"tags":[]},{"title":"天文学101","slug":"71.Science-and-Tech/天文学101","date":"2024-01-24T01:27:54.244Z","updated":"2024-01-24T01:27:54.244Z","comments":true,"path":"71.Science-and-Tech/天文学101/","link":"","permalink":"https://beefyheisenberg.github.io/71.Science-and-Tech/天文学101/","excerpt":"@tag: #入门101 #天文学 恒星生命周期 太阳会死亡吗？红巨星、中子星和黑洞等都是哪来的？李永乐老师讲恒星演化 - YouTube 恒星演化: 初始: 星际云(氢, 氦) 原恒星: (氢 -&gt; 氦) 主序星阶段(恒星壮年) 不是所有的原恒星都能变成恒星, 质量不够的原恒星-&gt;褐矮星(不是恒星) 介于0.08太阳质量 ~ 0.5太阳质量, 原恒星-&gt;红矮星, 红矮星上发生的聚变 氢 -&gt; 氦 介于0.5太阳质量 ~ 8太阳质量之间: 原恒星-&gt;黄矮星(太阳), 发生的聚变 氢 -&gt; 氦 -&gt; 碳 大于8太阳质量: 原恒星-&gt;蓝色恒星, 质量越大的恒星寿命越短, 发生的聚变 氢 -&gt; 氦 -&gt; 碳 -&gt; 铁","text":"@tag: #入门101 #天文学 恒星生命周期 太阳会死亡吗？红巨星、中子星和黑洞等都是哪来的？李永乐老师讲恒星演化 - YouTube 恒星演化: 初始: 星际云(氢, 氦) 原恒星: (氢 -&gt; 氦) 主序星阶段(恒星壮年) 不是所有的原恒星都能变成恒星, 质量不够的原恒星-&gt;褐矮星(不是恒星) 介于0.08太阳质量 ~ 0.5太阳质量, 原恒星-&gt;红矮星, 红矮星上发生的聚变 氢 -&gt; 氦 介于0.5太阳质量 ~ 8太阳质量之间: 原恒星-&gt;黄矮星(太阳), 发生的聚变 氢 -&gt; 氦 -&gt; 碳 大于8太阳质量: 原恒星-&gt;蓝色恒星, 质量越大的恒星寿命越短, 发生的聚变 氢 -&gt; 氦 -&gt; 碳 -&gt; 铁 由于主序星阶段, 质量降低, 聚变变强, 导致膨胀,黄矮星(太阳) -&gt; 红巨星(半径非常大) -&gt; 外围物质抛洒形成星云, 核心收缩形成白矮星, 最后阶段 白矮星(质量不够无法形成黑洞) -&gt; 黑矮星;蓝色恒星 -&gt; 红超巨星(半径非常大) -&gt; 超新星爆发(宋朝记录的超新星爆发-&gt;蟹状星云) -&gt; 核心收缩后 -&gt; 变成中子星, 如果蓝色恒星的质量更大, 超新星爆炸后, 核心坍塌变成黑洞 恒星质量(由小到大)，在生命末期，分别会形成白矮星、中子星、黑洞 黑洞 参考: 黑洞 - 维基百科，自由的百科全书 黑洞（英语：black hole）是根据广义相对论所推论、在宇宙空间中存在的一种质量相当大的天体和星体（并非是一般认知的“洞”概念）。黑洞是由质量足够大的恒星在核聚变反应的燃料耗尽后发生引力坍缩而形成。黑洞的质量是如此之大，它产生的引力场是如此之强，以致于大量可测物质和辐射都无法逃逸，就连传播速度极快的光子也逃逸不出来。由于类似热力学上完全不反射光线的黑体，故名黑洞。[1]在黑洞的周围，是一个无法侦测的事件视界，标志着无法返回的临界点[2]，而在黑洞中心有一个密度趋近于无限的奇点。","categories":[{"name":"71.Science-and-Tech","slug":"71-Science-and-Tech","permalink":"https://beefyheisenberg.github.io/categories/71-Science-and-Tech/"}],"tags":[]},{"title":"Цесаревич (броненосец)","slug":"66.History-and-Politics/Цесаревич (броненосец)","date":"2024-01-24T01:27:54.240Z","updated":"2024-01-24T01:27:54.240Z","comments":true,"path":"66.History-and-Politics/Цесаревич (броненосец)/","link":"","permalink":"https://beefyheisenberg.github.io/66.History-and-Politics/Цесаревич (броненосец)/","excerpt":"Цесаревич皇太子号战列舰，又译太子号，俄语：Цесаревич）是俄罗斯帝国海军向法国订购的前无畏舰，先后参加了日俄战争和第一次世界大战。本舰所参与的战斗中最著名的是在黄海海战中作为俄国太平洋舰队旅顺分舰队旗舰，交战中舰桥因为受到日军一发炮弹命中，舰队指挥机构瘫痪，从而导致俄国舰队突围失败。本舰虽受重创，依旧趁夜逃脱日军封锁前往胶洲湾，在当地受到德国当局扣押直到战争结束。战后皇太子号返回俄国，加入波罗的海舰队，参加了一战。1917年俄国国内动荡时，舰上水兵发生哗变并参加了革命，舰名也随之更改为公民号（俄语：Гражданин）。@Ref：皇太子号战列舰 - 维基百科，自由的百科全书 模型制作参考 【图片】long time no see先来个小船，皇太子1904，基本直做，换master炮管和船坞木甲板【模型船吧】_百度贴吧 【战舰】“迅速突围，驶往海参崴！ ”- 鏖战黄海的皇太子号战列舰-搜狐","text":"Цесаревич皇太子号战列舰，又译太子号，俄语：Цесаревич）是俄罗斯帝国海军向法国订购的前无畏舰，先后参加了日俄战争和第一次世界大战。本舰所参与的战斗中最著名的是在黄海海战中作为俄国太平洋舰队旅顺分舰队旗舰，交战中舰桥因为受到日军一发炮弹命中，舰队指挥机构瘫痪，从而导致俄国舰队突围失败。本舰虽受重创，依旧趁夜逃脱日军封锁前往胶洲湾，在当地受到德国当局扣押直到战争结束。战后皇太子号返回俄国，加入波罗的海舰队，参加了一战。1917年俄国国内动荡时，舰上水兵发生哗变并参加了革命，舰名也随之更改为公民号（俄语：Гражданин）。@Ref：皇太子号战列舰 - 维基百科，自由的百科全书 模型制作参考 【图片】long time no see先来个小船，皇太子1904，基本直做，换master炮管和船坞木甲板【模型船吧】_百度贴吧 【战舰】“迅速突围，驶往海参崴！ ”- 鏖战黄海的皇太子号战列舰-搜狐 历史涂装考证 ① 配色表（1917） @Ref: https://www.aliexpress.com/item/32414131136.html ② 1917 @Ref: http://thegreatcanadianmodelbuilderswebpage.blogspot.com/2015/08/tsesarevich-1917.html ③ 1917 @Ref: 俄罗斯海军”皇太子”号战列舰1904年 05338-1/350系列-小号手 TRUMPETER 未完工的皇太子Ohlife：2020.8.3《酱油皇太子》 想搞模型的心思又蠢蠢欲动了，动机可能如下： 给小时候圆梦，给小时候的爱好画个句号（毕竟这是个消耗精力，还透支健康的事儿），或者… 为了让房间里的书桌看起来不那么空荡荡（？？？）然后花了大概一个周日的下午开始挑选船模，三大俗（大和、首相、密苏里）首先排除。还是模型店客服给推荐的皇太子，搜了一下这艘前无畏舰的资料，发现还挺有意思： 日俄战争前被给予厚望在沙俄太平洋分舰队担任旗舰，日俄战争是个不怎么光彩的战历，日俄战争结束后得以返回波罗的海舰队，但主力地位不保。整个一战之前，经常无所事事的独自在海上巡弋，孤独王子的名号也这样而来。二月革命后两次易主，彻底沦为冷板凳队员，直到被除籍拆解。突然觉得，这不挺像我嘛。 所以就买买买了 1899在法国土伦造船厂开始建造（舰名：Кронпри́нц） 1901年匆匆下水，船厂一直在测试，期间问题不断，航速不达标、主炮供弹系统都出现过问题。 1903年交付俄方（当时还叫俄罗斯帝国），太子回国报到的旅程也是几经周折，途中主机三度故障。途径意大利、希腊、斯里兰卡、印尼、新加坡，终于在12月达到旅顺港。加入沙俄太平洋分舰队担任旗舰。 1904日俄战争爆发，沙俄太平洋舰队决定从旅顺突围驶回海参崴。途中遭遇xx拦截，黄海海战爆发。皇太子重创三笠，随后受损被迫驶向胶州湾。 1906战争结束，皇太子返回俄国，加入波罗的海舰队。一战爆发前，皇太子号战舰经常无所事事地独自在海上巡逻，舰上的水兵把这艘经常独来独去的军舰开玩笑地称为“孤独的王子”。 1914一战斗爆发，主力地位被更先进的“彼得罗巴甫洛夫斯克”替代。然后“皇太子”号就一直被用于在波罗的海同德国人周旋，它时常在没有任何军舰掩护的情况下孤独地单舰在海上巡弋 1917二月革命后，沙俄政府倒台，皇太子站在了临时政府一边，改名为“公民号”（Гражданин），临时政府倒台后，被编入苏维埃红海军。由于“皇太子”号从技术上说已经过时，它一直没有得到完全修复，苏维埃政府对它也不重视，所以这位“孤独的王子”就一直独自静悄悄停泊在港湾里。 1925年，在血腥的俄国内战即将结束之际， 这位“孤独的王子”也走到了它“一生”的尽头，它退出了红海军现役，接着被卖掉拆成小块回炉，支援社会主义建设。","categories":[{"name":"66.History-and-Politics","slug":"66-History-and-Politics","permalink":"https://beefyheisenberg.github.io/categories/66-History-and-Politics/"}],"tags":[{"name":"大舰巨炮","slug":"大舰巨炮","permalink":"https://beefyheisenberg.github.io/tags/大舰巨炮/"}]},{"title":"伯罗奔尼撒战争","slug":"66.History-and-Politics/伯罗奔尼撒战争","date":"2024-01-24T01:27:54.235Z","updated":"2024-01-24T01:27:54.235Z","comments":true,"path":"66.History-and-Politics/伯罗奔尼撒战争/","link":"","permalink":"https://beefyheisenberg.github.io/66.History-and-Politics/伯罗奔尼撒战争/","excerpt":"伯罗奔尼撒战争是以雅典为首的提洛同盟与以斯巴达为首的伯罗奔尼撒联盟之间的一场战争。这场战争从公元前431年一直持续到公元前404年，期间双方曾几度停战，最终斯巴达一方获得胜利，但也付出了巨大的代价。 这场战争标志着古希腊黄金时代的终结，从政治、经济、文化、社会心理风气等改变了希腊的各个城邦。几乎所有希腊的城邦参加了这场战争，其战场几乎涉及整个当时的希腊世界。在现代西方研究者中也有人称这场战争为“古代世界大战”。 这场战争不但对古希腊的历史走向影响深远，而且对历史学本身也具有重要的意义，这场战争是第一次被历史学家记录下来的史实：希腊历史学家修昔底德在他的《伯罗奔尼撒战争史》中详细记录了当时的事件，该纪录到公元前411年冬中止。修昔底德分析了这场战争的原因和背景，他的分析对欧洲的历史学具有先驱作用。修昔底德死后，色诺芬在他的《希腊史》中延续修昔底德的工作，记录公元前411年之后的事件。 修昔底德是雅典人，他从雅典人的角度出发将其著作命名为《伯罗奔尼撒战争史》，而当时的伯罗奔尼撒人称这场战争为雅典战争。 雅典的修昔底德纪录伯罗奔尼撒人与雅典人之间的战争。他在战争爆发时开始他的纪录，他当时想到这场战争可能是非常重要的，可能比此前的战争都有历史意义。他这样想因为战争双方使用它们所有的手段，而其它的希腊城市迟早参加这场战争。这场战争深刻影响希腊和一部分野蛮人，可以说这场战争影响整个人类社会。——修昔底德","text":"伯罗奔尼撒战争是以雅典为首的提洛同盟与以斯巴达为首的伯罗奔尼撒联盟之间的一场战争。这场战争从公元前431年一直持续到公元前404年，期间双方曾几度停战，最终斯巴达一方获得胜利，但也付出了巨大的代价。 这场战争标志着古希腊黄金时代的终结，从政治、经济、文化、社会心理风气等改变了希腊的各个城邦。几乎所有希腊的城邦参加了这场战争，其战场几乎涉及整个当时的希腊世界。在现代西方研究者中也有人称这场战争为“古代世界大战”。 这场战争不但对古希腊的历史走向影响深远，而且对历史学本身也具有重要的意义，这场战争是第一次被历史学家记录下来的史实：希腊历史学家修昔底德在他的《伯罗奔尼撒战争史》中详细记录了当时的事件，该纪录到公元前411年冬中止。修昔底德分析了这场战争的原因和背景，他的分析对欧洲的历史学具有先驱作用。修昔底德死后，色诺芬在他的《希腊史》中延续修昔底德的工作，记录公元前411年之后的事件。 修昔底德是雅典人，他从雅典人的角度出发将其著作命名为《伯罗奔尼撒战争史》，而当时的伯罗奔尼撒人称这场战争为雅典战争。 雅典的修昔底德纪录伯罗奔尼撒人与雅典人之间的战争。他在战争爆发时开始他的纪录，他当时想到这场战争可能是非常重要的，可能比此前的战争都有历史意义。他这样想因为战争双方使用它们所有的手段，而其它的希腊城市迟早参加这场战争。这场战争深刻影响希腊和一部分野蛮人，可以说这场战争影响整个人类社会。——修昔底德 战前的情况雅典奉行民主制，而斯巴达奉行贵族寡头制。双方在希波战争中并肩作战击败了波斯人的入侵，但战后双方的矛盾逐渐显现。雅典因为海外贸易和藩属国的贡赋，实力日益强盛，其政治影响力对外扩张。以雅典为首的提洛同盟与以斯巴达为首的伯罗奔尼撒联盟的利益和意识形态对抗逐渐升级。 雅典此时正处于其文化的顶峰，哲学家有苏格拉底、柏拉图，剧作家有索福克勒斯、欧里庇得斯等。其政治结构是雅典式民主社会（与今天的民主社会不同，当时的雅典的公民必须是男性，父母双方都是雅典公民——战争后期为了补充公民数量不足，改为父母一方是公民即可——，还有财产要求），意识形态倾向于商业从业者和城市居民的利益。斯巴达的政治结构是贵族寡头制，意识形态相对保守，重视农业、轻视商业，外交上亲其他城邦的贵族寡头集团。因此，民主派当政的城邦一般都亲雅典，而寡头派当政的城邦一般都亲斯巴达。斯巴达战胜后立刻在雅典引入了寡头政治。","categories":[{"name":"66.History-and-Politics","slug":"66-History-and-Politics","permalink":"https://beefyheisenberg.github.io/categories/66-History-and-Politics/"}],"tags":[{"name":"世界历史","slug":"世界历史","permalink":"https://beefyheisenberg.github.io/tags/世界历史/"}]},{"title":"通古斯大爆炸","slug":"66.History-and-Politics/通古斯大爆炸","date":"2024-01-24T01:27:54.230Z","updated":"2024-01-24T01:27:54.231Z","comments":true,"path":"66.History-and-Politics/通古斯大爆炸/","link":"","permalink":"https://beefyheisenberg.github.io/66.History-and-Politics/通古斯大爆炸/","excerpt":"通古斯大爆炸 - 维基百科，自由的百科全书通古斯大爆炸（俄语：Тунгусский метеорит）是1908年6月30日上午7时17分（格林威治标准时间1908年6月30日0:17）发生在现今俄罗斯西伯利亚克拉斯诺亚尔斯克边疆区（原埃文基自治区）上空的陨石空爆事件。爆炸发生于通古斯河附近、贝加尔湖西北方 800 公里处，北纬 60.55 度，东经 101.57 度，当时估计爆炸威力相当于 2 千万吨 TNT 炸药，超过 2,150 平方公里内的 8 千万棵树焚毁倒下。 由于通古斯地区过于偏远，当时只有少数科学家对这个爆炸事件感兴趣。就算当时有任何对这地区的调查，那些记录也很可能在接下来的混乱时代——第一次世界大战、俄国革命和俄国内战中遗失。 现存对此地区最早的调查是于事件发生几乎 20 年后进行的。1921 年，苏联科学院的矿物学家列昂尼德·库利克到达通古斯河地区，并在这个地区调查当时陨石撞击的确切地点。尽管他们从未访问过爆炸发生的中央地区，但许多的当地记载使库里克相信爆炸是由巨大的陨石撞击引起的。他用陨石上的铁可能有助于苏联发展工业的理由，说服苏联政府对科学调查队给予资金。 1927 年，库利克的调查队在当地埃文基猎人的帮助下终于找到爆炸区域的中心。让他们惊讶的是，没有发现任何陨石坑。烧焦枯死的树横跨大约 50 公里。少数靠近爆炸中心的树没有倾倒，它们的树枝和树皮则被脱去。倾倒的树则是向爆炸中心相反的方向倾倒。 接下来 10 年，有另外 3 支队伍被派到这一地区。库利克发现有一个小沼泽可能是陨石坑，但在排光其中的水后，他在底部发现一些树木残枝，所以确定那不是陨石坑。1938 年，库利克又找人来航拍整个区域，显示树是以一个像蝴蝶的巨大形状倾倒，然而他仍然没有发现任何陨石坑。","text":"通古斯大爆炸 - 维基百科，自由的百科全书通古斯大爆炸（俄语：Тунгусский метеорит）是1908年6月30日上午7时17分（格林威治标准时间1908年6月30日0:17）发生在现今俄罗斯西伯利亚克拉斯诺亚尔斯克边疆区（原埃文基自治区）上空的陨石空爆事件。爆炸发生于通古斯河附近、贝加尔湖西北方 800 公里处，北纬 60.55 度，东经 101.57 度，当时估计爆炸威力相当于 2 千万吨 TNT 炸药，超过 2,150 平方公里内的 8 千万棵树焚毁倒下。 由于通古斯地区过于偏远，当时只有少数科学家对这个爆炸事件感兴趣。就算当时有任何对这地区的调查，那些记录也很可能在接下来的混乱时代——第一次世界大战、俄国革命和俄国内战中遗失。 现存对此地区最早的调查是于事件发生几乎 20 年后进行的。1921 年，苏联科学院的矿物学家列昂尼德·库利克到达通古斯河地区，并在这个地区调查当时陨石撞击的确切地点。尽管他们从未访问过爆炸发生的中央地区，但许多的当地记载使库里克相信爆炸是由巨大的陨石撞击引起的。他用陨石上的铁可能有助于苏联发展工业的理由，说服苏联政府对科学调查队给予资金。 1927 年，库利克的调查队在当地埃文基猎人的帮助下终于找到爆炸区域的中心。让他们惊讶的是，没有发现任何陨石坑。烧焦枯死的树横跨大约 50 公里。少数靠近爆炸中心的树没有倾倒，它们的树枝和树皮则被脱去。倾倒的树则是向爆炸中心相反的方向倾倒。 接下来 10 年，有另外 3 支队伍被派到这一地区。库利克发现有一个小沼泽可能是陨石坑，但在排光其中的水后，他在底部发现一些树木残枝，所以确定那不是陨石坑。1938 年，库利克又找人来航拍整个区域，显示树是以一个像蝴蝶的巨大形状倾倒，然而他仍然没有发现任何陨石坑。 在 1930 年，英国天文学者弗朗西斯·约翰·威尔士·惠普尔指通古斯天体很可能是一个小彗星。由于彗星主要由冰与尘埃所组成，在撞击爆炸后就已经蒸发殆尽，所以没有留下一般石质天体会留下的陨石。而且，彗星说也解释了为何通古斯大爆炸后周边地区夜如白昼的现象，这可能是彗尾残留在高空的冰、尘颗粒反射阳光照亮夜空的结果。这一理论在 1960 年代也普遍获得苏联的通古斯调查员所接受。","categories":[{"name":"66.History-and-Politics","slug":"66-History-and-Politics","permalink":"https://beefyheisenberg.github.io/categories/66-History-and-Politics/"}],"tags":[]},{"title":"修昔底德陷阱","slug":"66.History-and-Politics/修昔底德陷阱","date":"2024-01-24T01:27:54.226Z","updated":"2024-01-24T01:27:54.226Z","comments":true,"path":"66.History-and-Politics/修昔底德陷阱/","link":"","permalink":"https://beefyheisenberg.github.io/66.History-and-Politics/修昔底德陷阱/","excerpt":"修昔底德陷阱最早是格雷厄姆·艾利森在2012年在金融时报上发表的一篇探讨中美之间潜在冲突文章中提出的。文章引用了伯罗奔尼撒战争史的一段话︰ 正是因为雅典的崛起引致斯巴达的恐惧，最终使战争不可避免。 格雷厄姆·艾利森在其著作《注定的一战》(英语：Destined For War)中进一步阐述，用这个术语描述当时快速崛起的大国雅典，挑战现有强国斯巴达国际霸主的地位时，战争最后无可避免地爆发。他认为“中美两国目前正处于通往战争冲突的进程中”。 该术语描述了这样一种理论，即当一个大国的霸权地位受到新兴大国的威胁时，两个大国之间很可能发生战争。用格雷厄姆艾利森的话来说： 修昔底德陷阱指的是当一个快速崛起的大国威胁了现有的霸主时，便自然会发生不可避免的混乱……当一个崛起的大国威胁要取代现有霸主地位时，由此产生的结构性压力使暴力冲突成为必然。","text":"修昔底德陷阱最早是格雷厄姆·艾利森在2012年在金融时报上发表的一篇探讨中美之间潜在冲突文章中提出的。文章引用了伯罗奔尼撒战争史的一段话︰ 正是因为雅典的崛起引致斯巴达的恐惧，最终使战争不可避免。 格雷厄姆·艾利森在其著作《注定的一战》(英语：Destined For War)中进一步阐述，用这个术语描述当时快速崛起的大国雅典，挑战现有强国斯巴达国际霸主的地位时，战争最后无可避免地爆发。他认为“中美两国目前正处于通往战争冲突的进程中”。 该术语描述了这样一种理论，即当一个大国的霸权地位受到新兴大国的威胁时，两个大国之间很可能发生战争。用格雷厄姆艾利森的话来说： 修昔底德陷阱指的是当一个快速崛起的大国威胁了现有的霸主时，便自然会发生不可避免的混乱……当一个崛起的大国威胁要取代现有霸主地位时，由此产生的结构性压力使暴力冲突成为必然。 为了证明这一理论，格雷厄姆·艾利森引用了哈佛大学贝尔弗科学与国际事务中心的一项研究，该研究结果表明：在过去500年的历史发展中，新兴强国与既有强国爆发的16次冲突中，其中12次导致了战争。 @ref: 1930s世界往事：发展与安全","categories":[{"name":"66.History-and-Politics","slug":"66-History-and-Politics","permalink":"https://beefyheisenberg.github.io/categories/66-History-and-Politics/"}],"tags":[]},{"title":"迦太基文明","slug":"66.History-and-Politics/迦太基文明","date":"2024-01-24T01:27:54.219Z","updated":"2024-01-24T01:27:54.220Z","comments":true,"path":"66.History-and-Politics/迦太基文明/","link":"","permalink":"https://beefyheisenberg.github.io/66.History-and-Politics/迦太基文明/","excerpt":"迦太基（腓尼基人建立的古国）迦太基一词在腓尼基语中读作“Qart-ḥadašt” ，意思是「新的城市」，其早期居民为迦南城市泰尔（Tyre或譯為推羅）的移民。在古羅馬文獻中，迦太基也被稱為「布匿」（拉丁語：Punici）。 前8世紀，腓尼基人在北非建立迦太基城，當時迦太基城還只是腓尼基城邦泰爾（Tyer）的海外殖民地。前650年，脫離泰爾獨立，建立城市國家古迦太基。 據考證，前814年，腓尼基人蘇爾王國（位於現今黎巴嫩南部西南海岸）的狄多公主（Dido）因其兄庇格瑪里翁（Pygmalion）在國王死後，排斥公主而獨攬大權。為免遭迫害，狄多帶著財寶與僕人飄洋過海，在突尼斯灣登陸。她向柏柏人部落首領馬西塔尼求借一張牛皮之地棲身，得到應允；於是她便把一張牛皮切成一根根細條，然後把細牛皮連在一起，在緊靠海邊的山丘上圍起一塊地皮，建起了迦太基城。故而迦太基的卫城又叫柏萨，意为“一张牛皮”。 古迦太基强势时疆土遼闊，勢力最大曾囊括今天北非沿岸、今西班牙中部、科西嘉島、薩丁尼亞島、西西里島和馬爾他島，首都迦太基富極一時，其基礎是農業与商業，在外貿易居民善航海与貿易，在國內居民又是出色的農民，很早就出現了奴隸佔有制莊園，因此在當時地中海地區成為最有活力的經濟強國。","text":"迦太基（腓尼基人建立的古国）迦太基一词在腓尼基语中读作“Qart-ḥadašt” ，意思是「新的城市」，其早期居民为迦南城市泰尔（Tyre或譯為推羅）的移民。在古羅馬文獻中，迦太基也被稱為「布匿」（拉丁語：Punici）。 前8世紀，腓尼基人在北非建立迦太基城，當時迦太基城還只是腓尼基城邦泰爾（Tyer）的海外殖民地。前650年，脫離泰爾獨立，建立城市國家古迦太基。 據考證，前814年，腓尼基人蘇爾王國（位於現今黎巴嫩南部西南海岸）的狄多公主（Dido）因其兄庇格瑪里翁（Pygmalion）在國王死後，排斥公主而獨攬大權。為免遭迫害，狄多帶著財寶與僕人飄洋過海，在突尼斯灣登陸。她向柏柏人部落首領馬西塔尼求借一張牛皮之地棲身，得到應允；於是她便把一張牛皮切成一根根細條，然後把細牛皮連在一起，在緊靠海邊的山丘上圍起一塊地皮，建起了迦太基城。故而迦太基的卫城又叫柏萨，意为“一张牛皮”。 古迦太基强势时疆土遼闊，勢力最大曾囊括今天北非沿岸、今西班牙中部、科西嘉島、薩丁尼亞島、西西里島和馬爾他島，首都迦太基富極一時，其基礎是農業与商業，在外貿易居民善航海与貿易，在國內居民又是出色的農民，很早就出現了奴隸佔有制莊園，因此在當時地中海地區成為最有活力的經濟強國。 迦太基主要是貴族寡頭式掌權，其中商業奴隸主與農業奴隸主這兩個統治階級間則往往有利害衝突，這造成了日後與羅馬作戰時出現和戰不定的問題。[2]而最高行政官員有兩名，稱為蘇菲特，每年選舉產生，但選民限於富有的迦太基人，不過這兩位蘇菲特沒有兵權。迦太基與羅馬一樣，設有元老院，由300人組成。元老院擁有立法權和決策權，成員任期終身。並設有公民大會，但權力有限。此外，亦設有百人會議，共有成員104人，負責監察和作出審判。 大約在前8世紀 - 前6世紀，迦太基開始向非洲內陸擴展，並控制了北非的大部份腓尼基人殖民地。與此同時，迦太基亦向西地中海進發，佔領了伊比利亚半岛南部海岸及其附近島嶼，前654年征服了西西里島西部及撒丁島，前535年奪取科西嘉島等，開始稱霸西地中海，與希臘分別控制著地中海的西東兩邊。古迦太基曾與古希臘爭奪地中海霸權，後又與古羅馬爭奪霸權。最後因為在三次布匿戰爭中均被羅馬共和國打敗，並於前146年滅亡。 vs 希臘从前6世紀開始，迦太基開始與欲染指地中海西部的希臘人發生衝突。大約在前535年，迦太基人聯合伊特拉斯坎人，在科西嘉島近岸打敗了其中一支希臘人的艦隊。但是在前480年，敘拉古的領主格隆和阿克拉加斯的領主特隆所統率的希臘軍隊卻在西西里島大敗迦太基的軍隊。此後百年間，迦太基與希臘為了爭霸地中海而紛爭不斷。 直到前4世紀初，希臘在經歷伯羅奔尼撒戰爭後元氣大傷，開始停止在西西里殖民。而在希臘的皮洛士於西西里為希臘城邦作出最後一次對抗迦太基的戰事後，迦太基與希臘的紛爭大致告一段落。但取而代之的，卻是與更可怕的對手――羅馬所發生的戰爭。 vs 羅馬前264～前146年，迦太基與羅馬發生了3次戰爭，史稱布匿战争。 第一次布匿战争（前264年-前241年），主要是在地中海上的海战。开始在西西里岛交战，接着罗马进攻迦太基本土，迦太基被打败。 第二次布匿战争（前218年-前201年），三个中最著名的战争。迦太基主帅汉尼拔率6万大军穿过阿尔卑斯山，入侵罗马。罗马则出兵马赛切断汉尼拔的补给，此时迦太基国内矛盾激发，汉尼拔回军驰援，罗马乘机进攻迦太基本土。迦太基战败，丧失全部海外领地，交出舰船，并向罗马赔款。 第三次布匿战争（前149年-前146年），这是一场罗马以强凌弱的侵略战争。罗马主动进攻，长期围困迦太基城，迦太基不甘被进攻，于是奋起作战。可惜最后迦太基战败惨遭屠城，领土成为罗马的一个省份——阿非利加行省。布匿战争的结果是迦太基被灭，迦太基城也被夷为平地，罗马争得了地中海西部的霸权。 古迦太基滅亡之後，羅馬軍隊摧毀了迦太基城。後來在迦太基城原址附近建立新城，並成為羅馬的阿非利加行省。439年汪達爾人佔領迦太基，成為汪达尔-阿兰王国的首都（@link 汪达尔人）。533年成為东罗马帝國的屬地，並成為東羅馬帝國重要文化中心。7世紀因阿拉伯帝國的崛起引發的戰亂而被徹底廢棄。","categories":[{"name":"66.History-and-Politics","slug":"66-History-and-Politics","permalink":"https://beefyheisenberg.github.io/categories/66-History-and-Politics/"}],"tags":[{"name":"世界历史","slug":"世界历史","permalink":"https://beefyheisenberg.github.io/tags/世界历史/"}]},{"title":"闪米特人","slug":"66.History-and-Politics/闪米特人","date":"2024-01-24T01:27:54.212Z","updated":"2024-01-24T01:27:54.213Z","comments":true,"path":"66.History-and-Politics/闪米特人/","link":"","permalink":"https://beefyheisenberg.github.io/66.History-and-Politics/闪米特人/","excerpt":"闪米特人（阿拉伯文：ساميون，拉丁文：samium；德文：Semiten）词汇由德国人，冯施洛泽（August Ludwig von Schlözer），在 1781 年提出，用来指代民族语属亚非语系—闪米特语族人群，灵感来自《圣经》诺亚的长子 Shem（闪）。 闪米特人不是单一民族，而是包含了母语属性有关联的群体民族，并且这些民族的亲疏关系尚不明确。 苏美尔文明是闪米特人终结的吗？苏美尔人与闪米特人的恩怨纠葛 - 知乎 闪米特人的历史十分久远，至公元前 30 世纪初，按语言明显地分为东、西两大支。 东闪米特，按现代分类法，此支称“闪米特北支”。东闪米特人生活在两河流域的北部，操阿卡德语，在与苏美尔人接触中吸收、融化了对方的语言。自公元前三千二百年至公元初，其代表为阿卡德人、巴比伦人、亚述人。 西支闪米特人又分三个分支：西北支（现称闪米特北中支）、中支（现称闪米特南中支）、南支（现称闪米特南支）。 西北支（现称闪米特北中支），系指分布在巴勒斯坦、叙利亚、美索不达米亚北部的各民族，最早的代表为阿摩里特人、迦南人、乌加里特人，约在公元前二千年后，有腓尼基人、犹太人、阿拉米人、莫阿比特人、亚奥迪人等。 中支（现称闪米特南中支）约在公元前二千年至前一千年，其代表为利希亚尼特人、萨姆德人等，随后统一共称阿拉伯人，阿拉伯人是闪米特人最年轻的一支，起源于阿拉伯半岛。七世纪随着伊斯兰教的兴起，开始了闪米特人的一次大迁移。 南支（现称闪米特南支）分布在阿拉伯半岛的南部，阿拉伯半岛，可能是闪米特人的摇篮，闪米特人在这个地方成长之后，迁移到肥沃的新月地区（即伊拉克、叙利亚、黎巴嫩、巴勒斯坦和约旦），后来就成为历史上的巴比伦人、亚述人、腓尼基人和希伯来人。","text":"闪米特人（阿拉伯文：ساميون，拉丁文：samium；德文：Semiten）词汇由德国人，冯施洛泽（August Ludwig von Schlözer），在 1781 年提出，用来指代民族语属亚非语系—闪米特语族人群，灵感来自《圣经》诺亚的长子 Shem（闪）。 闪米特人不是单一民族，而是包含了母语属性有关联的群体民族，并且这些民族的亲疏关系尚不明确。 苏美尔文明是闪米特人终结的吗？苏美尔人与闪米特人的恩怨纠葛 - 知乎 闪米特人的历史十分久远，至公元前 30 世纪初，按语言明显地分为东、西两大支。 东闪米特，按现代分类法，此支称“闪米特北支”。东闪米特人生活在两河流域的北部，操阿卡德语，在与苏美尔人接触中吸收、融化了对方的语言。自公元前三千二百年至公元初，其代表为阿卡德人、巴比伦人、亚述人。 西支闪米特人又分三个分支：西北支（现称闪米特北中支）、中支（现称闪米特南中支）、南支（现称闪米特南支）。 西北支（现称闪米特北中支），系指分布在巴勒斯坦、叙利亚、美索不达米亚北部的各民族，最早的代表为阿摩里特人、迦南人、乌加里特人，约在公元前二千年后，有腓尼基人、犹太人、阿拉米人、莫阿比特人、亚奥迪人等。 中支（现称闪米特南中支）约在公元前二千年至前一千年，其代表为利希亚尼特人、萨姆德人等，随后统一共称阿拉伯人，阿拉伯人是闪米特人最年轻的一支，起源于阿拉伯半岛。七世纪随着伊斯兰教的兴起，开始了闪米特人的一次大迁移。 南支（现称闪米特南支）分布在阿拉伯半岛的南部，阿拉伯半岛，可能是闪米特人的摇篮，闪米特人在这个地方成长之后，迁移到肥沃的新月地区（即伊拉克、叙利亚、黎巴嫩、巴勒斯坦和约旦），后来就成为历史上的巴比伦人、亚述人、腓尼基人和希伯来人。 布匿人（英语：Punics），指北非历史上的一个源于迦太基的讲 西闪米特语的民族，他们是腓尼基移民和北非的柏柏尔人原住民融合产生。不像其他的腓尼基人，除了沿海据点，布匿人控制了北非内陆和跨撒哈拉贸易，并在当地建立了地主贵族政治统治。 @link: 迦太基文明 在考古学和语言学方面，“布匿”用来指代源于迦太基的希腊化及后期文化和腓尼基语中一种不同于腓尼基人起源城市泰尔的迦太基方言。","categories":[{"name":"66.History-and-Politics","slug":"66-History-and-Politics","permalink":"https://beefyheisenberg.github.io/categories/66-History-and-Politics/"}],"tags":[{"name":"世界历史","slug":"世界历史","permalink":"https://beefyheisenberg.github.io/tags/世界历史/"}]},{"title":"汪达尔人","slug":"66.History-and-Politics/汪达尔人","date":"2024-01-24T01:27:54.205Z","updated":"2024-01-24T01:27:54.205Z","comments":true,"path":"66.History-and-Politics/汪达尔人/","link":"","permalink":"https://beefyheisenberg.github.io/66.History-and-Politics/汪达尔人/","excerpt":"词源：汪达尔人（Vandals）的名字会被联想到瑞典州份“Vendel”，可能源自原始日耳曼语动词 wand-（改变/流浪）或日耳曼神话人物“Aurvandil”（耀亮的流浪者；黎明流浪者，长庚），或名为“光明的汪达尔”的日耳曼神明。 Vandals 亦即英文中“财产破坏”（vandalism）一词由来 汪达尔人（Vandals）是古代一个东日耳曼部族，在民族大迁徙中于 429 年占领今北非突尼斯一带，建立了汪达尔王国。公元 455 年，他们从海上出发，并于 6 月 2 日洗劫了罗马城。 公元 533 年，东罗马帝国名将贝利萨留讨伐汪达尔人（@link 东罗马），大获全胜并毁灭了汪达尔王国，将其重新纳入帝国疆土。汪达尔王国的亡国之君盖利默则被押解到君士坦丁堡，退隐度过余生。汪达尔人曾在 554 年发动过一次武装叛乱，亦被帝国派兵迅速镇压。此后大部分汪达尔人被陆续押解到帝国各境为奴，而少部分人则分散在帝国军中服役。如此这般，汪达尔人不仅丧失了自己的国家，而且作为一个民族自此之后也消失得无影无踪。 @link： 汪达尔人——财富和艺术的毁灭者，转瞬即逝的历史过客","text":"词源：汪达尔人（Vandals）的名字会被联想到瑞典州份“Vendel”，可能源自原始日耳曼语动词 wand-（改变/流浪）或日耳曼神话人物“Aurvandil”（耀亮的流浪者；黎明流浪者，长庚），或名为“光明的汪达尔”的日耳曼神明。 Vandals 亦即英文中“财产破坏”（vandalism）一词由来 汪达尔人（Vandals）是古代一个东日耳曼部族，在民族大迁徙中于 429 年占领今北非突尼斯一带，建立了汪达尔王国。公元 455 年，他们从海上出发，并于 6 月 2 日洗劫了罗马城。 公元 533 年，东罗马帝国名将贝利萨留讨伐汪达尔人（@link 东罗马），大获全胜并毁灭了汪达尔王国，将其重新纳入帝国疆土。汪达尔王国的亡国之君盖利默则被押解到君士坦丁堡，退隐度过余生。汪达尔人曾在 554 年发动过一次武装叛乱，亦被帝国派兵迅速镇压。此后大部分汪达尔人被陆续押解到帝国各境为奴，而少部分人则分散在帝国军中服役。如此这般，汪达尔人不仅丧失了自己的国家，而且作为一个民族自此之后也消失得无影无踪。 @link： 汪达尔人——财富和艺术的毁灭者，转瞬即逝的历史过客","categories":[{"name":"66.History-and-Politics","slug":"66-History-and-Politics","permalink":"https://beefyheisenberg.github.io/categories/66-History-and-Politics/"}],"tags":[{"name":"欧洲历史","slug":"欧洲历史","permalink":"https://beefyheisenberg.github.io/tags/欧洲历史/"}]},{"title":"大舰巨炮-近代海战史","slug":"66.History-and-Politics/大舰巨炮-近代海战史","date":"2024-01-24T01:27:54.200Z","updated":"2024-01-24T01:27:54.200Z","comments":true,"path":"66.History-and-Politics/大舰巨炮-近代海战史/","link":"","permalink":"https://beefyheisenberg.github.io/66.History-and-Politics/大舰巨炮-近代海战史/","excerpt":"多铆蒸钢，大舰巨炮。亿万炮塔，亿万荣光！ 海战史 1805-特拉法尔加海战 - 维基百科，自由的百科全书 1894-黄海海战 (1894年) - 维基百科，自由的百科全书) 1905-对马海峡海战 - 维基百科，自由的百科全书 1916-日德兰海战 - 维基百科，自由的百科全书 1941-珍珠港事件 - 维基百科，自由的百科全书 1942-珊瑚海海战 - 维基百科，自由的百科全书 1942-中途岛海战 - 维基百科，自由的百科全书 1944-莱特湾海战 - 维基百科，自由的百科全书 陈列馆 铁甲舰、前无畏舰、无畏舰、超无畏舰有啥区别？又是如何演化的？ @link: 阿金科特号战列舰- 维基百科，自由的百科全书 多铆蒸刚的图腾——阿金库尔号战舰传奇 - 知乎 胡德号战列巡洋舰 - 维基百科，自由的百科全书 沙恩霍斯特号战列舰 - 维基百科，自由的百科全书 纳尔逊号战舰 - 维基百科，自由的百科全书 罗德尼号战舰 - 维基百科，自由的百科全书 威尔士亲王号战列舰 - 维基百科，自由的百科全书 二战美军经典驱逐舰拉菲号 战巡金刚杂谈（一） - 知乎 战巡/战舰金刚杂谈（二） - 知乎 雪風號驅逐艦 - 维基百科，自由的百科全书 二战日本沉没的大中型水面舰艇 - 知乎","text":"多铆蒸钢，大舰巨炮。亿万炮塔，亿万荣光！ 海战史 1805-特拉法尔加海战 - 维基百科，自由的百科全书 1894-黄海海战 (1894年) - 维基百科，自由的百科全书) 1905-对马海峡海战 - 维基百科，自由的百科全书 1916-日德兰海战 - 维基百科，自由的百科全书 1941-珍珠港事件 - 维基百科，自由的百科全书 1942-珊瑚海海战 - 维基百科，自由的百科全书 1942-中途岛海战 - 维基百科，自由的百科全书 1944-莱特湾海战 - 维基百科，自由的百科全书 陈列馆 铁甲舰、前无畏舰、无畏舰、超无畏舰有啥区别？又是如何演化的？ @link: 阿金科特号战列舰- 维基百科，自由的百科全书 多铆蒸刚的图腾——阿金库尔号战舰传奇 - 知乎 胡德号战列巡洋舰 - 维基百科，自由的百科全书 沙恩霍斯特号战列舰 - 维基百科，自由的百科全书 纳尔逊号战舰 - 维基百科，自由的百科全书 罗德尼号战舰 - 维基百科，自由的百科全书 威尔士亲王号战列舰 - 维基百科，自由的百科全书 二战美军经典驱逐舰拉菲号 战巡金刚杂谈（一） - 知乎 战巡/战舰金刚杂谈（二） - 知乎 雪風號驅逐艦 - 维基百科，自由的百科全书 二战日本沉没的大中型水面舰艇 - 知乎","categories":[{"name":"66.History-and-Politics","slug":"66-History-and-Politics","permalink":"https://beefyheisenberg.github.io/categories/66-History-and-Politics/"}],"tags":[{"name":"大舰巨炮","slug":"大舰巨炮","permalink":"https://beefyheisenberg.github.io/tags/大舰巨炮/"}]},{"title":"东罗马","slug":"66.History-and-Politics/东罗马","date":"2024-01-24T01:27:54.195Z","updated":"2024-01-24T01:27:54.195Z","comments":true,"path":"66.History-and-Politics/东罗马/","link":"","permalink":"https://beefyheisenberg.github.io/66.History-and-Politics/东罗马/","excerpt":"东罗马帝国是罗马帝国于公元286年实行东西分治后，于原帝国东部（相对于西部的西罗马帝国）分离出的政权；其被当时的西欧世界视为有别于古罗马的新政权，故其灭亡后西欧学界普遍称之为拜占庭帝国。然而其国祚一千余年期间仍自称罗马帝国（拉丁语：Imperium Romanum；希腊语：Βασιλεία Ρωμαίων；中古希腊语：Βασιλεία Ῥωμαίων 转写：Basileía Rhōmaíōn）、公民皆自认为罗马人（中古希腊语：Ῥωμαῖοι 转写：Rhōmaîoi），而非“拜占庭人”或“希腊人”。 东罗马帝国共历经12个王朝及93位皇帝，首都为新罗马（拉丁语：Nova Roma；希腊语：Νέα Ρώμη，即君士坦丁堡）。其疆域在11个世纪中不断变动。色雷斯、希腊和小亚细亚西部是帝国的核心地区；今日的土耳其、希腊、保加利亚、北马其顿、阿尔巴尼亚从4世纪至13世纪是帝国领土的主要组成部分；意大利和原南斯拉夫的大部、伊比利亚半岛南部、叙利亚、巴勒斯坦、埃及、利比亚、突尼斯、今阿特拉斯山脉以北的阿尔及利亚和今天摩洛哥的丹吉尔也在7世纪之前曾是帝国的国土。 关于帝国的起始纪年，历史学界仍存有争议，最根本的原因还是因为东罗马帝国虽然文化上有变化，但名义上就是原罗马帝国存续下来的政权。主流观点之一认为，330年君士坦丁大帝建立新罗马、罗马帝国政治中心东移，是东罗马帝国开始的标志。另一主流观点认为，395年最后一位统治整个罗马帝国的皇帝狄奥多西一世的去世，标志东罗马帝国的开始。[3]德国东罗马学者斯坦因以戴克里先皇帝即位（284年；这位皇帝首次将罗马帝国分为东西两半分治）为东罗马帝国的起始纪年。其他观点分别以476年（西罗马帝国灭亡）、527年（查士丁尼一世登基）、7世纪（希腊化开始）和8世纪（希腊化完成）为东罗马帝国起始的标志。 东罗马帝国本为罗马帝国的东半部，较为崇尚希腊文化。在中世纪还未到来以前，靠近拜占庭故地的希腊地区罗马行省便是以希腊语占主导地位，而罗马公民的身份吸引了当地希腊族裔——讲希腊语的罗马公民以自己身为罗马人而自豪，“Romaioi（罗马人）”这个词成为描述罗马帝国中讲希腊语的人口的含义[2]。与西罗马帝国分裂后，更逐渐发展为以希腊文化、希腊语和及后的东正教为立国基础，在620年，希拉克略皇帝首次让希腊语取代拉丁语，成为帝国的官方语言，使得东罗马帝国成为不同于古罗马和西罗马帝国的国家。在476年西罗马帝国灭亡前和神圣罗马帝国成立后，这个帝国就被外人称为“东罗马帝国”加以区分，尽管其正式国号仍延续着古罗马帝国时期的国号。直到1557年德意志历史学家赫罗尼姆斯·沃尔夫为了区分其帝国的古罗马时期及神圣罗马帝国而引入了“拜占庭帝国”作为称呼，并被现代史学上所使用。 1204年4月13日，东罗马帝国首都君士坦丁堡曾被第四次十字军东征攻陷和劫掠，直到1261年才被东罗马帝国的流亡政权尼西亚帝国收复。然而虽收复首都，但国力与版图自此再也无法从战争的浩劫下恢复。1453年5月29日，来自小亚细亚的奥斯曼帝国攻陷了其首都君士坦丁堡，末代皇帝君士坦丁十一世在巷战中殉国，历时一千余年的东罗马帝国就此灭亡，国祚达1480年的罗马帝国也正式终结。在许多历史学家眼中，东罗马帝国的覆灭也被视作中世纪的结束和近代早期的开端。","text":"东罗马帝国是罗马帝国于公元286年实行东西分治后，于原帝国东部（相对于西部的西罗马帝国）分离出的政权；其被当时的西欧世界视为有别于古罗马的新政权，故其灭亡后西欧学界普遍称之为拜占庭帝国。然而其国祚一千余年期间仍自称罗马帝国（拉丁语：Imperium Romanum；希腊语：Βασιλεία Ρωμαίων；中古希腊语：Βασιλεία Ῥωμαίων 转写：Basileía Rhōmaíōn）、公民皆自认为罗马人（中古希腊语：Ῥωμαῖοι 转写：Rhōmaîoi），而非“拜占庭人”或“希腊人”。 东罗马帝国共历经12个王朝及93位皇帝，首都为新罗马（拉丁语：Nova Roma；希腊语：Νέα Ρώμη，即君士坦丁堡）。其疆域在11个世纪中不断变动。色雷斯、希腊和小亚细亚西部是帝国的核心地区；今日的土耳其、希腊、保加利亚、北马其顿、阿尔巴尼亚从4世纪至13世纪是帝国领土的主要组成部分；意大利和原南斯拉夫的大部、伊比利亚半岛南部、叙利亚、巴勒斯坦、埃及、利比亚、突尼斯、今阿特拉斯山脉以北的阿尔及利亚和今天摩洛哥的丹吉尔也在7世纪之前曾是帝国的国土。 关于帝国的起始纪年，历史学界仍存有争议，最根本的原因还是因为东罗马帝国虽然文化上有变化，但名义上就是原罗马帝国存续下来的政权。主流观点之一认为，330年君士坦丁大帝建立新罗马、罗马帝国政治中心东移，是东罗马帝国开始的标志。另一主流观点认为，395年最后一位统治整个罗马帝国的皇帝狄奥多西一世的去世，标志东罗马帝国的开始。[3]德国东罗马学者斯坦因以戴克里先皇帝即位（284年；这位皇帝首次将罗马帝国分为东西两半分治）为东罗马帝国的起始纪年。其他观点分别以476年（西罗马帝国灭亡）、527年（查士丁尼一世登基）、7世纪（希腊化开始）和8世纪（希腊化完成）为东罗马帝国起始的标志。 东罗马帝国本为罗马帝国的东半部，较为崇尚希腊文化。在中世纪还未到来以前，靠近拜占庭故地的希腊地区罗马行省便是以希腊语占主导地位，而罗马公民的身份吸引了当地希腊族裔——讲希腊语的罗马公民以自己身为罗马人而自豪，“Romaioi（罗马人）”这个词成为描述罗马帝国中讲希腊语的人口的含义[2]。与西罗马帝国分裂后，更逐渐发展为以希腊文化、希腊语和及后的东正教为立国基础，在620年，希拉克略皇帝首次让希腊语取代拉丁语，成为帝国的官方语言，使得东罗马帝国成为不同于古罗马和西罗马帝国的国家。在476年西罗马帝国灭亡前和神圣罗马帝国成立后，这个帝国就被外人称为“东罗马帝国”加以区分，尽管其正式国号仍延续着古罗马帝国时期的国号。直到1557年德意志历史学家赫罗尼姆斯·沃尔夫为了区分其帝国的古罗马时期及神圣罗马帝国而引入了“拜占庭帝国”作为称呼，并被现代史学上所使用。 1204年4月13日，东罗马帝国首都君士坦丁堡曾被第四次十字军东征攻陷和劫掠，直到1261年才被东罗马帝国的流亡政权尼西亚帝国收复。然而虽收复首都，但国力与版图自此再也无法从战争的浩劫下恢复。1453年5月29日，来自小亚细亚的奥斯曼帝国攻陷了其首都君士坦丁堡，末代皇帝君士坦丁十一世在巷战中殉国，历时一千余年的东罗马帝国就此灭亡，国祚达1480年的罗马帝国也正式终结。在许多历史学家眼中，东罗马帝国的覆灭也被视作中世纪的结束和近代早期的开端。 时至今日，虽然东罗马帝国的文化和宗教在现代土耳其已经不复存在，但其对于今日的东欧各国有很大的影响。此外，帝国在其十一个世纪的悠久历史中所保存下来的古典希腊和罗马史料、著作，以及理性的哲学思想，也为中世纪欧洲突破天主教会神权束缚提供了最直接的动力。从地中海战争与贸易中的东西文明交流、东罗马帝国的遗民西迁，间接引发了意大利乃至整个西欧的文艺复兴运动。该运动的宗旨试图重塑罗马的辉煌文化，并深远地影响了人类历史。","categories":[{"name":"66.History-and-Politics","slug":"66-History-and-Politics","permalink":"https://beefyheisenberg.github.io/categories/66-History-and-Politics/"}],"tags":[{"name":"欧洲历史","slug":"欧洲历史","permalink":"https://beefyheisenberg.github.io/tags/欧洲历史/"}]},{"title":"Yeremenko","slug":"66.History-and-Politics/Yeremenko","date":"2024-01-24T01:27:54.191Z","updated":"2024-01-24T01:27:54.191Z","comments":true,"path":"66.History-and-Politics/Yeremenko/","link":"","permalink":"https://beefyheisenberg.github.io/66.History-and-Politics/Yeremenko/","excerpt":"关于一张照片 这张照片的拍摄者是 Max Vladimirovich Alpert（Макс Влади́мирович А́льперт），Max Alpert 后来回忆拍摄于 1941——1943 年间，对照片中军装进行分析后发现不同于 M43 式军装，所以应该也不是 1943 年拍摄。作者并不知道照片中人物的信息，但并不能就此认为照片中信息为宣传系统的杜撰——战争时期苏联并未将其宣传为“牺牲的政治委员”，而只是单纯地描述为 Комбат。 直到战后第 29 年，原伏罗希洛夫格勒、现卢甘斯克地区一户家庭写信给作者，认为这是他们的家人 Oleksiy Hordiyovych Yeremenko（Єременко Олексій Гордійович），共青团真理报与作者和当地政府联系，通过战前照片对比，以及亲历战斗的当事人回忆，认为 Oleksiy Hordiyovych Yeremenko 是照片上的人。 Oleksiy Hordiyovych Yeremenko 当时是苏联第 18 军第 4 步兵师第 220 步兵团下属政治委员，1942 年 7 月 12 日在伏罗希洛夫格勒地区霍罗舍村带领部队反攻时阵亡。 两名健在的这场战斗的参与者——隶属于第 285 师的 Vasily Sevastianovich 中校，以及同属于第 220 步兵团并在后来接替 Yeremenko 政委职务的 Alexander Matvajevich Makarov 少校接受了共青团真理报、伏罗希洛夫格勒地区政府和 Yeremenko 家人的质询和联合调查，各自独立描述了当时的情况并相互印证。而最具决定性的证据来自拍摄者 Max Vladimirovich Alpert 本人——1942 年 7 月，他正是在伏罗希洛夫格勒地区进行战地摄影。相关调查结果发表于苏联 1987 年 11 月《科学与生活》杂志。苏联政府在调查结束后向 Yeremenko 的家人发布了更新后的阵亡通知。","text":"关于一张照片 这张照片的拍摄者是 Max Vladimirovich Alpert（Макс Влади́мирович А́льперт），Max Alpert 后来回忆拍摄于 1941——1943 年间，对照片中军装进行分析后发现不同于 M43 式军装，所以应该也不是 1943 年拍摄。作者并不知道照片中人物的信息，但并不能就此认为照片中信息为宣传系统的杜撰——战争时期苏联并未将其宣传为“牺牲的政治委员”，而只是单纯地描述为 Комбат。 直到战后第 29 年，原伏罗希洛夫格勒、现卢甘斯克地区一户家庭写信给作者，认为这是他们的家人 Oleksiy Hordiyovych Yeremenko（Єременко Олексій Гордійович），共青团真理报与作者和当地政府联系，通过战前照片对比，以及亲历战斗的当事人回忆，认为 Oleksiy Hordiyovych Yeremenko 是照片上的人。 Oleksiy Hordiyovych Yeremenko 当时是苏联第 18 军第 4 步兵师第 220 步兵团下属政治委员，1942 年 7 月 12 日在伏罗希洛夫格勒地区霍罗舍村带领部队反攻时阵亡。 两名健在的这场战斗的参与者——隶属于第 285 师的 Vasily Sevastianovich 中校，以及同属于第 220 步兵团并在后来接替 Yeremenko 政委职务的 Alexander Matvajevich Makarov 少校接受了共青团真理报、伏罗希洛夫格勒地区政府和 Yeremenko 家人的质询和联合调查，各自独立描述了当时的情况并相互印证。而最具决定性的证据来自拍摄者 Max Vladimirovich Alpert 本人——1942 年 7 月，他正是在伏罗希洛夫格勒地区进行战地摄影。相关调查结果发表于苏联 1987 年 11 月《科学与生活》杂志。苏联政府在调查结束后向 Yeremenko 的家人发布了更新后的阵亡通知。 @ref: 政治委员- 维基百科，自由的百科全书 二战时期苏联的政委同志是一种什么存在? - 知乎 什么是政委，为何苏联红军有政委，而美军没有政委 @link [[../64.Novel-and-Poesy/夏伯阳与虚空]]","categories":[{"name":"66.History-and-Politics","slug":"66-History-and-Politics","permalink":"https://beefyheisenberg.github.io/categories/66-History-and-Politics/"}],"tags":[]},{"title":"02.中国历史时空图","slug":"66.History-and-Politics/02.中国历史时空图","date":"2024-01-24T01:27:54.186Z","updated":"2024-01-24T01:27:54.186Z","comments":true,"path":"66.History-and-Politics/02.中国历史时空图/","link":"","permalink":"https://beefyheisenberg.github.io/66.History-and-Politics/02.中国历史时空图/","excerpt":"","text":"","categories":[{"name":"66.History-and-Politics","slug":"66-History-and-Politics","permalink":"https://beefyheisenberg.github.io/categories/66-History-and-Politics/"}],"tags":[{"name":"中国历史","slug":"中国历史","permalink":"https://beefyheisenberg.github.io/tags/中国历史/"}]},{"title":"01.中国历史与世界历史对照表","slug":"66.History-and-Politics/01.中国历史与世界历史对照表","date":"2024-01-24T01:27:54.168Z","updated":"2024-01-24T01:27:54.181Z","comments":true,"path":"66.History-and-Politics/01.中国历史与世界历史对照表/","link":"","permalink":"https://beefyheisenberg.github.io/66.History-and-Politics/01.中国历史与世界历史对照表/","excerpt":"","text":"世界古代史(前4500年–1500年) 中国历史 世界历史 前3000-2000年传说中的黄帝、炎帝、颛琐、帝喾、尧、舜时代 约前4300-前3500年苏美尔地区出现原始的城市；约前3100年上埃及王美尼斯统一上下埃及；约前3000-前2600年爱琴海地区先后进入早期青铜时代；约前2500-前1750年印度河古文明时期，称为哈拉巴文化。 前2070年-1600年禹建立夏王朝 前1754年巴比伦国王统一两河流域，颁布《汉谟拉比法典》 前1600年-1046年成汤建立商朝，共传17代31王；前1300年盘庚迁都于殷，史称“盘庚中兴”；前1250年-1192年武丁在位59年，史称“武丁盛世”。 前1504-1450年埃及法老图特摩斯三世，跨西亚北非；前1250年希腊各邦以迈锡尼为首远征特洛伊城；约前1200年希腊语的多利亚人结束迈锡尼文明。 前1046年牧野之战武王建立周朝。前1043年周公摄政；前841年共和元年“国人暴动”（彘之乱）；前828年周宣王即位，在位46年，史称“宣王中兴”。 前1000-960年大卫王定都耶路撒冷，统一以色列和犹太国家；约前800年印度进入后吠陀时期，开始种姓制度。 前770年周平王迁都洛邑，史称东周 前776年第一届奥林匹克，希腊历史元年。 前651年葵丘会诸侯，齐桓公(前685)霸业达到顶峰；前634年晋文公在城濮之战大败楚军，称霸中原；前551孔子(前551-479年)出生 前594年梭伦任雅典首席执政官，实行改革；前586年新巴比伦攻下耶路撒冷，犹太国灭亡；前570-前495年毕达哥拉斯；前563年相传释迦牟尼(乔达摩·悉达多)出生 前537年楚晋联姻，晋楚百年争霸正式结束；前510年吴王阖闾攻占楚国郢都；前497年孔子开始周游列国；前482年吴王夫差北上黄池称霸；前481年齐国卿大夫田氏杀齐简公，“专齐之政” 前550年波斯王居鲁士灭米底，建立波斯帝国；前509年雅典执政官克里斯梯尼改革，民主政治建立；前509年罗马共和国建立，王政时代结束；前490年波希马拉松战役雅典将军以少胜多 前475-221年东周王朝开始进入战国时代；前473年吴国被卧薪尝胆的越王勾践灭亡；前403年三家分晋得到周天子的正式承认 前470-前399年苏格拉底；前462年伯利克里(前495-429年)改革，雅典民主鼎盛；前449年希波订立卡里阿斯和约，希波战争正式结束；前431-404年伯罗奔尼撒战争；前429-前347年柏拉图； 前356年秦孝公任用商鞅(前390-338年)变法；前341年在马陵之战，魏国由强转弱；前318年秦灭巴蜀；前307年赵武灵王实行军事改革“胡服骑射” 前384-前322年亚里士多德；前337年马其顿腓力二世召开全希腊会议，希腊城邦时代结束；前330年波斯被马其顿灭亡；前324年印度之旃陀罗笈多自立为王，孔雀王朝 前278年屈原(前340-278年)投汨罗江而死；前260年长平之战，四十余万赵军被歼，赵国元气大伤；前256年西周亡，周赧王去世，名义的周天子不复存在 ； 前273年阿育王即位，在位37年孔雀帝国极盛时期。佛教广泛传播，还派传教使者到邻国传教；前264年罗马与迦太基文明进行第一次布匿战争 前221年秦统一六国；前209年陈胜吴广起义；前209-174年匈奴冒顿单于杀父自立；前207年巨鹿之战，秦亡；翌年长达四年“楚汉争霸”开始 前219年罗马对迦太基宣战。第二次布匿战争开始；前209年罗马将军小西庇阿率海陆军攻陷迦太基城 前202年刘邦即皇帝位，汉朝建立，史称西汉；前180-157年-157年-141年文帝景帝在位，“文景之治” 前146年罗马开始确立在希腊的统治；前146年罗马克迦太基城，夷为平地 前141-87年刘彻即位，是为汉武帝；前138、前115年张骞出使西域，“丝绸之路”自此开通；前134年董仲舒提出“罢黜百家独尊儒术”主张；前119年汉将霍去病、卫青率军痛击匈奴，；前60年汉置西域都护，汉朝号令行于西域各国 前73年罗马爆发角斗士斯巴达克斯领导的奴隶大起义；前49年恺撒成为罗马独裁者。 8年12月王莽称帝，国号“新”(8-23年)，西汉灭亡 前27年屋大维被尊为“奥古斯都”，开始罗马帝国时代；公元元年耶稣(基督)诞生。 公元纪年分隔线 25年刘秀称帝，东汉王朝建立，定都洛阳；73年窦固败匈奴，班超出使西域；89年窦宪大破北匈奴 52年大月氏建立贵霜帝国；64年罗马城大火，皇帝尼禄乘机迫害基督教徒；77年罗马势力扩大到英格兰 97年西域都护班超派甘英出使大秦等国，到达波斯湾；105年蔡伦将改进造纸术奏报朝廷，闻名于后世。 132年犹太人起义反抗罗马被镇压，离开巴勒斯坦，流落各地 167年东汉“党锢之祸”；184年太平道教主张角发起“黄巾起义” 167年日尔曼部落突破多瑙河防线，侵入罗马边境。 200年官渡之战，曹操开始统一北方；208年孙刘联军“赤壁之战”大败魏军，三足鼎立之势成 212年皇帝卡拉卡拉颁布敕令，授予境内自由人罗马公民权 220年十月曹丕废汉献帝，称帝，国号魏。东汉亡；221年刘备在成都称帝；229年四月孙权称帝，后定都建业；263年魏大举攻蜀，后主刘禅投降，蜀汉亡国；265年十二月司马炎皇帝，建立晋朝；280年晋灭吴，统一全国。291-306年西晋八王之乱 227年萨珊王朝(227-651年)灭帕提亚；284年戴克里先被拥立为罗马皇帝，罗马帝国出现复兴；286年戴克里先建立“四帝共治制”，罗马的东西分治开始； 316年，匈奴刘曜围攻长安，晋愍帝出降，西晋灭亡；317年三月司马睿在建康称晋王，次年称帝，东晋自此始。 313年君士坦丁与莱西尼阿联合发表米兰敕令，基督教合法化；330年君士坦丁迁都拜占庭，改名君士坦丁堡（新罗马） 376年苻坚再灭前凉、代国，前秦统一了北方；383年苻坚亲率大军南下攻晋，败于淝水之战 380年旃陀罗·笈多二世(超日王)即位，笈多王朝进全盛期 386年拓跋珪建魏，史称北魏；399年法显出发西行，往天竺求经。 392年基督教被定为罗马国教；395年罗马皇帝狄奥多西把国土分给两个儿子，罗马帝国从此彻底分裂 420年六月刘裕称帝，史称刘宋，南朝自此始；439年北魏军灭北凉灭，十六国时期至此结束；446年北魏武帝禁佛教，诛沙门，毁经像 439年汪达尔人在北非建立汪达尔王国；449年日耳曼族盎格鲁·萨克森人、朱特人侵入不列颠；476年西罗马帝国灭亡。 479年萧道成废杀宋顺帝，称帝，史称南齐；493年北魏孝文帝从平城(大同)迁都洛阳 486年克洛维在高卢北部建法兰克王国，创墨洛温王；493-553年东哥特王国，东哥特人统一意大利半岛 502年萧衍在健康称帝，国号梁，是为梁武帝；503年新罗始定国号为“新罗”，国主正式称王 507年克洛维击败西哥特军，次年迁都巴黎；518年查士丁尼一世即位，529年拜占廷颁布《查士丁尼法典》 534年高欢进兵洛阳，立元善见为帝，迁都邺城，称东魏；535年魏文帝元宝炬在长安即位，史称西魏 531-579科斯洛埃斯一世在位，萨珊王朝进入全盛时期；532年耶稣诞生之年此时被倡议做为纪元之始 550年东魏高洋自立，史称北齐(550—577)；552年阿史那土门大败柔然，自称伊利可汗建突厥汗国；553年新罗进攻百济，获得汉江流域，疆域到达黄海；557年正月西魏宇文觉受禅称天王，史称北周(557—581)；557年梁大将陈霸先受禅称帝，国号陈(557—589)；577年北周灭北齐，统一北方；周武帝再次宣布灭佛 554年拜占廷占有全部意大利；563年波斯与突厥联合入侵嚈哒，历时五年，嚈哒灭亡；577年斯拉夫人渡多瑙河侵入色雷斯，成为巴尔干主要居民；579年意大利语渐代拉丁语。西班牙则拉丁语渐代替哥特语 581年北周外戚杨坚废帝自立，北周亡，隋朝建立；589年隋灭陈，统一全国 590年格里哥利一世即教皇位，从此确立教皇权威 606年始建进士科，典定科举制度；607年隋炀帝派遣朱宽等入海，到达流求(台湾)；610年开凿自京口至余杭的江南河，隋大运河全部告竣 603-628年波斯与拜占廷又开始长达20年的战争；606年印度戒日王即位，在位40年，统一北印度大部；610年穆罕默德约于此时开始传布伊斯兰教 618年炀帝死江都兵变，隋朝灭亡。李渊长安称帝，唐朝建立； 622年穆罕默德(570-632)从麦加出走迁往麦地那，伊斯兰历元年开始 626年“玄武门之变”李世民继位，贞观之治(627-649年)；629-645年玄奘(600～664)西行；630年日本派出第一个遣唐使；630败东突厥李世民被尊“天可汗”。640置安西都护府；641年文成公主嫁给吐蕃的松赞干布；646年日本大化改新 630年穆罕默德征服麦加；637年阿拉伯攻入波斯首都泰西封(巴格达)，占领伊拉克；638年占领耶鲁撒冷，640年征服整个叙利亚；642年波斯与阿拉伯决战败北。同年阿拉伯占领亚历山大城 657年唐朝平西突厥；663年百济-日本与唐-新罗联军“白江口之战”；668年唐朝灭亡高句丽。676年新罗统一朝鲜 651年波斯亡，阿拉伯正式与唐朝交往；655年船桅之役，拜占廷的海军优势受严重打击；661-750年阿拉伯倭马亚王朝，定都大马士革。 690年武则天称帝，改国号为“周”，史称武周；698年大祚荣在高句丽故地建立起震国，后封渤海国；705年敬珲和宰相张柬之等人发动政变，中宗李显复位；712年睿宗让位予唐玄宗，713-741年开元盛世。 711年阿拉伯征服西班牙的西哥特王国；732年受挫于法兰克查理·马特，阿拉伯在西欧的扩张止步；710—712年征服撒马尔罕、花拉子模；711—713年征服印度河流域的信德和南旁遮普 738年蒙舍诏首领皮罗阁建立南诏(738-937年)；744年李白(701-762)和杜甫(712-770)在洛阳结识 750-1258阿拔斯王朝(黑衣大食)，定都巴格达；750-850掀起百年翻译运动。阿拉伯文化顶盛。 751年怛罗斯之战，造纸术随被俘工匠传入西方；753年鉴真(687-763)东渡抵达日本，传律宗；755-763年唐朝发生安史之乱；780年德宗采纳杨炎建议，颁行两税法 751年丕平称王，建立加洛林王朝；754-756丕平征意大利，“丕平献土”教皇国成立；774年查理曼征服伦巴第王国；800年查理大帝(768-814)圣诞节在罗马加冕称帝 821年唐蕃会盟，在拉萨立《长庆会盟碑》；835年太和九年唐文宗“甘露之变”失败；874-884年王仙芝、黄巢领导唐末农民战争；881年黄巢在长安建立政权，国号“大齐”；902年郑买嗣灭南诏自立，改国号大长和 843年凡尔登条约，加洛林帝国一分为三；9世纪中叶诺曼人深入攻击西欧，西法兰克王室权威式微；870年墨尔森条约，东西法兰克瓜分中法兰克大部分领地；882年基辅罗斯公国建立；891年东法兰克对诺曼人取得决定性胜利。 907年后梁建立，唐朝灭亡，五代开始 902年阿拉伯人彻底征服西西里岛；909-1171北非法蒂玛王朝(黑衣大食)什叶派的大王朝；911年诺曼公国建立，并接受基督教；920年东法兰克改名德意志，930-980第一次向东方殖民。 916年阿保机建立契丹国；935年高丽灭亡新罗，重新统一朝鲜半岛；937段思平建立大理国；947年耶律德光南下灭后晋，改国号大辽；951郭威即帝位，建后周，灭后汉 960年陈桥兵变，赵匡胤黄袍加身，建立宋朝； 960年波兰国家建立 968丁部领称“大胜明皇帝”，国号“大瞿越”，越南创国；982年李继迁反宋自立；986年太宗“雍熙北伐”败北 962奥托大帝称意大利王，加冕称帝建神圣罗马帝国；988罗斯弗拉基米尔(978-1015)定国教东正教 1004年宋、辽澶渊之盟；1023年宋真宗时成都16家富户共同发行最早的纸币“交子”1038年元昊建立西夏 1017年克努特成为首个统一的英格兰国王，并继承丹、挪王位；1039-1056年亨利三世在位，神圣罗马帝国达到鼎盛；1054年基督教会分裂；1055年塞尔柱突厥人在巴格达建立素丹政权，哈里发成为附庸。 1069年王安石(1021-1086)开始变法；1085年哲宗赵煦继位 1066年法国诺曼底公爵威廉一世征服英格兰；1071年塞尔柱人在马拉兹古尔特之役重创拜占庭；1096-1099年第一次十字军东征 1115年阿骨打建立大金(1115-1234)；1125年金灭辽；1127年靖康之变，金灭北宋，赵构即位，史称南宋；1131耶律大石建立西辽；1141年宋金达成《绍兴和议》 1108-1137法王路易六世在位，统一进程开始起步，城市兴起；1130年诺曼人建立两西西里王国；1147年收复里斯本；1147年莫斯科建城；1147-1149年第二次十字军(德法联军)东征，遭突厥人重创 1164年宋孝宗改交趾郡为安南国；1192年源赖氏被任命为征夷大将军，开创镰仓幕府，史称镰仓时代(1192-1333) 1168年牛津大学建立；1187年萨拉丁收复耶路撒冷；1189-1192第三次十字军东征(萨拉丁 vs 狮心王、红胡子、腓力二世) 1206年成吉思汗铁木真(1206-1227)建蒙古国；1218年蒙古灭掉西辽政权；1219-1223成吉思汗首次西征；1227年蒙古灭西夏；1231年蒙古入侵高丽；1234年蒙宋联军攻破蔡州城，金国灭亡；1236-1241年拔都西征1240年攻占基辅直至多瑙河 1202-1204年第四次东征洗劫君士坦丁堡，建立拉丁帝国；1206年法王菲利普二世(1180-1223)剥夺英王在大陆领地；1215年“失地王”约翰(1199-1216)签订《英国大宪章》；1228-1229年腓特烈二世擅自第六次十字军东征；1230条顿骑士团侵占普鲁士 1252年旭烈兀西征；1258年攻占巴格达，灭阿拔斯王朝；1253年灭大理；1259年蒙哥卒于钓鱼城；1271年忽必烈定国号元(1271-1368年)；1275-1292威尼斯商人马可波罗到元朝和印度；1276年南宋投降；1279年南宋流亡朝亡于廷崖山海战；1281年(1274)忽必烈第两次入侵日本失败 1254-1273年神圣罗马帝国大空位时期；1261拉丁帝国终结，恢复了拜占廷帝国；1270路易九世第八次十字军东征突尼斯时死去；1284爱德华一世(1272-1307)彻底征服威尔士；1291年埃及夺取十字军在东方的最后据点；1295年英国“模范国会”召开 1333年后醍醐天皇推翻镰仓幕府，1336-1392南北朝时代；1337年伊儿汗国亡；1351年元末爆发红巾军大起义，刘福通、徐寿辉起兵。 14-15世纪欧洲资本主义萌芽；14-16世纪欧洲文艺复兴运动；1307但丁《神曲》；1337英法百年战争开始；1348欧洲开始爆发“黑死病”，人口锐减三分一 1368年朱元璋在应天府登基即位，建立明朝(1368-1644)，元顺帝北逃。同年大将徐达攻克大都，元朝覆亡 1378-1447罗马教会分裂，两教皇并存；1380年罗斯大败钦察汗国；1415亨利王子占领摩洛哥休达；1415-1580大航海时代；1429年贞德解奥尔良之围1436年法国收复巴黎；1436年德国约翰·古登堡发明活字印刷；1438哈布斯堡的阿尔伯特选为皇帝(1438-1806) 1392年李成桂篡位，国号朝鲜，史称李氏朝鲜；1392年足利义满迫南朝天皇让位，室町时代1392-1573；1399-1402年“靖难之役”朱棣即位；1405-1433年郑和七次下西洋；1421年明朝迁都北京，南京改为留都；1429年尚巴志统一琉球，开创第一尚氏王朝，都首里。 1449年“土木堡之变”；1457年夺门之变，英宗复位；1467年应仁之乱，日本战国时代(1467年—1573年)；1471年安南黎圣宗灭占城；1487-1505年明孝宗朱祐樘继位，史称为“弘治中兴”。 达·芬奇(1452-1519)米开朗基罗(1472-1564)拉斐尔(1483—1520)；1453年奥斯曼灭拜占庭。英法百年战争结束；1479阿拉贡斐迪南一世继卡斯提王，合并为西班牙；1480罗斯摆脱蒙古控制，1485统一东北罗斯；1487年迪亚士到达好望角 世界近现代史(1500年–至今) 中国历史 世界历史 1517果阿总督到广州请求通商未果，炮轰广州；1553年中葡停息干戈，1553-1557年葡人开始在澳居留；1555-1558年胡宗宪、戚继光(1528-1588)、俞大猷等接连重创倭寇；1565年西班牙征服菲律宾群岛；1566年为害已解放后东南倭患终于最后平息；1567年有限度的开放海禁，史称“隆庆开海”；1571年鞑靼部俺答汗受封顺义王；1572年神宗继位，张居正十年辅政，史称“万历中兴”；1578年李时珍经27年著成《本草纲目》；1590年织田信长的继承者丰臣秀吉完成统一；1592、1597年丰臣秀吉入侵朝鲜，中朝赢得最后胜利；1598年西班牙闯入广东；1601年荷兰炮舰首次开到广州。 1492年哥伦布初次航行到美洲；1497-1498年达加马开辟西欧到印度的新航路；1500年葡萄牙到达巴西；1510年攻占果阿，建立东方殖民地总部；1511年夺取马六甲；1517马丁-路德《九十五条论纲》发动宗教改革；1519-1522年麦哲伦第一次环球航行；1521西班牙征服阿兹特克；1532征服印加帝国；1528年苏里曼一世攻陷布达佩斯；1534《至尊法案》，英王成英教会最高领袖，正式与教廷决裂；1543哥白尼(1469-1492)《天体运行论》出版；1562-1594法国胡诺(加尔文派)战争，破坏性超百年战争；1566年“破坏圣像运动”，尼德兰革命爆发；1580年西班牙吞并葡萄牙；1581年(荷兰)联省共和国成立；1588年英国海军击败西班牙“无敌舰队”；1600年英国东印度公司建立 1603年德川家康在江户开创德川幕府(1603-1867)；1609年琉球受入侵萨摩藩的支配，形成中日两属的状态；1616年努尔哈赤建立后金；1619荷兰占领爪哇，1622据澎湖1624被逐转筑赤嵌城；1626北京王恭厂大爆炸（天启大爆炸）1628全国性大灾荒，陕西爆发大规模农民起义；1636年皇太极称帝，改国号为大清；1639-1641年松锦之战，关外辽东地区至此基本沦陷。 1603年詹姆斯一世继位，斯图亚特王朝开始；1607年伦敦公司在北美建立詹姆斯城；1608年法国在魏北克建立殖民据点；1618-1648欧洲三十年战争；1620年“五月花”号到达新英格兰；1632伽利略《两大宇宙体系的对话》 1644年李自成建立大顺政权，农民军攻占北京，明亡；1652年达赖五世入京，顺治帝赐予“达赖喇嘛”称号；1661-1662年郑成功收复台湾；1662年永历帝被吴三桂绞杀于昆明，南明灭亡。同年郑成功病逝于台湾，李定国病故于猛腊。 1640年英国资产阶级革命开始；1648年《威斯特伐利亚条约》，三十年战争结束，哈布斯堡霸权终结；1649年英国王查理一世被处死；1651年英国颁布《航海条例》，1652-1654第一次英荷战争；1660年英国斯图亚特王朝复辟 1669年康熙帝开始真正亲政；1673-1681年康熙平定以吴三桂为首的三藩叛乱；1683年施琅攻克澎湖，台湾归降。1684年清朝设台湾府；1688年-1697年平定准噶尔汗噶尔丹叛乱；1689年中俄签订《尼布楚条约》；1690年噶尔丹攻入内蒙，兵锋遥指北京，遭清军痛击；1691年对喀尔喀蒙古实行盟旗制度，正式从属中央政府 1661年路易十四(1643-1715)亲政；1683年奥斯曼被奥波联军击溃，扩张宣告终结；1686年俄波《永久和约》，确认乌克兰归俄；1687年《自然哲学的数学原理》发表，牛顿力学体系确立；1688年英国光荣革命，威廉三世入主，1689年通过《权利法案》；1689俄国彼得一世(彼得大帝，1672-1725)开始改革；1700-1721年俄瑞“北方战争” 1713年清朝廷封班禅“额尔德尼”；1718、1720年康熙两次派兵入藏击败准噶尔，并分兵驻藏；1722年清世宗雍正帝胤禛盛年登基；1726年清朝将“摊丁入亩”办法推行全国；1726年清朝对西南少数民族地区“改土归流”；1727年清廷正式设立驻藏大臣；1727年中俄签订《中俄布连斯奇条约》。 1701年普鲁士王国成立；1703年彼得一世建新都圣彼得堡；1707年英格兰苏格兰合并为“联合王国” 1735年清高宗乾隆帝弘历即位；1755、1757年两次出兵平定西北的准噶尔部；1759年第三次西北用兵平定新疆回部的“大小和卓叛乱”；1762年设伊犁将军，新疆完全置于清朝中央政府控制之下；1771年土尔扈特部重返祖国 1740-1786年腓特烈二世开明专制推重商主义，开普奥争霸；1756-1763年英法七年战争；1762叶卡捷琳娜二世通过政变登基1765-1790奥地利特雷西亚女皇和约瑟夫二世改革；1768年英国瓦特改良蒸汽机，第一次工业革命开始；1772年俄普奥第一次瓜分波兰；1774年北美第一届大陆会议在费城召开，1775年独立战争在莱克星顿打响，1776年7月4日《独立宣言》美国独立日；1776年亚当斯密《国富论》；1778伏尔泰和卢梭(1712-1778)去世；1787年美国《联邦宪法》次年生效；1789年华盛顿任第一任美国总统；1789年法国大革命爆发，同年《人权宣言》。 1791-1792年两次出征尼泊尔廓尔喀，制定《钦定西藏章程》；1796年乾隆帝禅位于清仁宗嘉庆帝颙琰，三年后逝世；1796年，川楚陕边境地区爆发的白莲教起义历时九载，波及川楚陕豫甘等省，使满清元气大伤；1813年北方天理教起义甚至在太监接应下冲进皇宫 1799年拿破仑发动雾月政变；1801年英国兼并爱尔兰；1803年美国购得路易斯安娜；1804年《拿破仑法典》，拿破仑加冕；1804年海地独立；1806年莱茵联邦成立，神圣罗马帝国解散。拿破仑封锁大陆；1812委、巴拉圭独立。1816阿根廷、1818智利、1821墨秘独立；1815滑铁卢战役。维也纳会议，维也纳体系确立。 1820年清宣宗道光皇帝旻宁继位。 1821-1829希腊独立战争；1822年巴西宣布独立；1823年“门罗宣言”；1834年德意志关税同盟成立；1836-1848英国宪章运动 1839年林则徐(1785-1850)虎门销烟；1840-1842年第一次鸦片战争，1841年英国占领香港；1842年中英《南京条约》；1851年金田起义1853年定都南京，建立太平天国；1853、1854年“黑船事件”马修·佩里准将两度叩关日本；1856年-1860年第二次鸦片战争；1858年《爱珲条约》《天津条约》的签订；1860年攻进北京，并洗劫圆明园；1860年《北京条约》的签订 1846-1848美墨战争。1847年加利福尼亚淘金热开始；1848欧洲革命（民族之春）。马克思发表《共产党宣言》；1849英国完全吞并旁遮普；1851年古巴宣布独立；1852年波拿巴建立第二帝国；1852年英国通过自由贸易原则；1853-1856年英法与俄克里米亚战争；1857-1859年印度民族起义1858年英国东印度公司解散；1859年达尔文《物种起源》发表；1859年意大利反奥独立战争开始 1861咸丰帝病死于承德避暑山庄，同年辛酉政变；1862法越《西贡条约》；1864年天京陷落、太平天国运动失败；1865年中亚浩罕汗国阿古柏侵入喀什，占据南疆；19世纪60到90年代洋务运动；1868年推翻德川幕府，明治维新，揭开日本近代历史。 1861年意大利王国成立；1861年俄罗斯农奴制改革；1861-1865年美国南北战争，1862林肯签署《黑奴解放宣言》；1864年普奥联军战胜丹麦。1866年普奥战争；1867年美国购得俄国阿拉斯加。1867年加拿大自治领成立；1868年美国首条横跨大陆的铁路正式通车 1871年沙俄派兵侵占伊犁地区；1872年洋务派企业轮船招商局。私办继昌隆缫丝厂创立；1881年曾纪泽与沙俄签订《中俄改订条约》；1883年-1885年中法战争；1884年新疆建省；1885年台湾建省；1885年朝鲜甲申政变；1888年英国入侵西藏；1894年美国檀香山成立兴中会；1894-1895年甲午中日战争；1895年中日《马关条约》签订；1897年德国租借胶州湾；俄国租借旅顺；1898年戊戌变法 19世纪70年代第二次工业革命开始；1870年普法战争；1870年意大利完成统一；1871年德意志帝国成立，威廉一世登基；1871年3－5月巴黎公社；1882年德意奥三国同盟形成；1885年柏林会议；1889年第二国际建立；1891年俄罗斯开始修建西伯利亚大铁路；1896年第一届现代奥运於希腊雅典举行；1898年美西战争，美占领古巴波多黎各菲律宾，正式侵并夏威夷；1899年英布战争(布尔战争)爆发 1900年义和团运动高潮,八国联军侵略中国；1901年《辛丑条约》签订；1905年中国同盟会成立；1908年光绪与慈禧太后先后去世；1910日本正式吞并朝鲜；1911年黄花岗起义、保路运动、武昌起义；1912年（民国元年）中华民国成立；1912年宣统帝退位清朝灭亡，中国二千多年的帝制结束；1913年二次革命；1915年新文化运动开始；1915年护国运动开始；1916年袁世凯恢复帝制失败；1917年张勋复辟失败；1917年护法运动开始；1919年5月4日五四爱国运动爆发；1921年7月中国共产党成立；1923年京汉铁路工人大罢工；1924中国国民党第一次全国代表大会；创立黄埔军校；1925年孙中山逝世；1925年上海五卅惨案、五卅反帝爱国运动爆发；1926年国民革命军出师北伐；1927年3月上海工人第三次武装起义胜利；1927年“四一二”、“七一五”反革命政变；1927年4月蒋介石在南京建立国民政府；1927年8月1日南昌起义；8月7日八七会议；1927年12月广州起义；1928年张学良宣布东北易帜；1931年九一八事变；1932年一.二八事变、十九陆军抗战1932年伪满洲国成立；1934年10月中央红军开始长征；1935年1月遵义会议；1935年中共中央发表八一宣言；1935年一二.九运动；1936年10月第二、四方面军达甘肃会宁等地，长征结束；1936年12月12日西安事变；1937年7月7日卢沟桥事变；1937年八一三事变凇沪会战；1937年平型关大捷；1937年12月南京沦陷；1938年台儿庄战役；1938年毛泽东发表《论持久战》；1940年3月汪精卫伪国民政府在南京成立；1940年百团大战；1941年皖南事变；1945年中国共产党第七次全国代表大会召开；1945年8月15日日本宣布投降；1945年重庆谈判；双十协定签字；1946年政治协商会议；1946年6月国共全面内战；1948年9月-1949年1月三大战役；1949年4月23日人民解放军解放南京；1949年9月中国人民政治协商会议第一次全体会议召开 20世纪初世界殖民体系最终形成；1900普朗克引入量子理论；1903年爱因斯坦提出相对论；1903怀特兄弟制成世界上第一架飞机；1903俄国社会民主工党第二次代表大会；1907英法俄协约的最后形成；1908通古斯大爆炸；1914－1918第一次世界大战，1918西班牙流感；1917.11.7(俄历10月25日)俄国十月社会主义革命；1918.11德国十一月革命爆发；1918－1922印度民族解放运动高涨；1919－1922土耳其凯末尔革命；1919.3匈牙利苏维埃共和国建立；1919共产国际建立；1919.1－6 巴黎和会；1921.11－1922.2华盛顿会议；1922.10墨索里尼在意大利上台；1922.12苏联成立；1923.10土耳其共和国成立；1924年苏联领导人列宁逝世；1925.10洛迦诺会议；1929－1933资本主义世界经济危机；1931年英国《威斯敏斯特法》，澳大利亚独立；1933.1希特勒在德国上台；1933.3罗斯福就任美国总统，实行新政；1935－1936埃塞俄比亚抗击意大利侵略的民族解放运动；1936－1939西班牙反对法西斯的民族革命战争；1938.9慕尼黑会议1939.8苏德互不侵犯条约；1939.9德国闪击波兰，随后英、法对德宣战，第二次世界大战全面爆发；1940.6法国投降；1940秋不列颠之战；1940.9德意日三国同盟条约签订；1941.6苏德战争爆发；1941.12太平洋战争爆发；1941秋大西洋宪章；1942初《联合国家宣言》形成反法西斯同盟；1942莫斯科保卫战；1942.6中途岛战役；1942.7－1943.2斯大林格勒战役；1943.12.1中美英发表《开罗宣言》；1943.11－12苏美英举行德黑兰会议；1944.6.6美英军队在诺曼底登陆，欧洲第二战场开辟；1945.2苏美英举行雅尔塔会议；1945.5.8德国签订无条件投降书；1945.9.2苏美英举行波茨坦会议日本签订无条件投降书；20世纪四五十年代第三次科技革命开始；1945.10联合国建立；1947美国提出杜鲁门主义；1947印巴分治：印度、巴基斯坦独立；1948以色列建国，第一次中东战争爆发；1948美国开始实施马歇尔计划 1949年10月1日中华人民共和国成立；1950年－1952年土地改革；1950年10月－1953年7月抗美援朝战争；1951年西藏的和平解放；1953-1956年三大改造；1953-1957年一五计划；1954年第一届人大，第一部宪法颁布；1956年中共八大召开；1958年大跃进、全民炼钢和人民公社化运动；1959年－1961年三年自然灾害；1962年中印边境自卫反击战；1964年中国第一颗原子弹爆炸成功；1966年-1976年文化大革命；1968年各地开始大规模知识青年上山下乡运动；1969年中苏爆发珍宝岛武装冲突；1970年中国第一颗人造卫星“东方红1号”成功发射；1971年中国恢复在联合国席位；1976文革结束，1977恢复高考；1978年十一届三中全会召开，改革开放开始；1979年对越自卫还击战；1980年四个经济特区的建立，平反文革的冤假错案；1985年城市改革，国有企业改革；1992年小平南方视察；1997年邓小平逝世，香港回归，十五大；1999年澳门回归 1949北大西洋公约组织建立；1950－1953朝鲜战争；1954《关于恢复印度支那和平的日内瓦协议》签字；1955亚非国家召开的万隆会议；1955华沙条约组织成立；1956波兰波兹南事件，匈牙利事件；1956第二次中东战争（苏伊士运河战争）；1957前苏联发射世界上第一颗人造地球卫星；1959古巴革命取得胜利；1960非洲有17个国家独立，这一年被称为“非洲独立年”；1961加加林成为第一个太空人；20世纪60年代初不结盟运动形成；20世纪60年代中期七十七国集团产生；1965-1973年美国发动越南战争；1967欧洲共同体成立；1972.2美国总统尼克松访华，上海公报发表；1973.1巴黎和平协约，越战结束；1979中美建交；1979年苏联入侵阿富汗；20世纪80年代末90年代初东欧剧变；1990.8-1991.2第一次海湾战争；1991.12月苏联解体；1992北美自由贸易区形成；1993欧洲联盟建立；1999科索沃战争，北约空袭南联盟；2008年：四川大地震；北京奥运会；美国次级贷款引发金融危机","categories":[{"name":"66.History-and-Politics","slug":"66-History-and-Politics","permalink":"https://beefyheisenberg.github.io/categories/66-History-and-Politics/"}],"tags":[{"name":"中国历史","slug":"中国历史","permalink":"https://beefyheisenberg.github.io/tags/中国历史/"},{"name":"世界历史","slug":"世界历史","permalink":"https://beefyheisenberg.github.io/tags/世界历史/"}]},{"title":"00.史前时代","slug":"66.History-and-Politics/00.史前时代","date":"2024-01-24T01:27:54.155Z","updated":"2024-01-24T01:27:54.155Z","comments":true,"path":"66.History-and-Politics/00.史前时代/","link":"","permalink":"https://beefyheisenberg.github.io/66.History-and-Politics/00.史前时代/","excerpt":"史前时代（prehistory） 一般是指人类出现到文字出现之前的时代，意即历史记载由于各地人类发明文字的时间都有不同，所以史前时代没有一个适用于各地的特定时间。不过，作为一个泛称，史前时代通常指公元前4000年以前的时期。举例，尚未发现文字记载的石器时代（前250万年－前4000年）是史前时代，青铜器时代（前4000年－各地不同时期完结）以后有文字记载之起就可称为信史时期。例如中国的五帝和夏朝就是史前时代，而商朝人则使用甲骨文和金文，甚至已经有“作册”等史官在竹简帛书上记载历史，故而中国从商朝开始就是信史。 广泛地说，史前时代可以追溯到自宇宙诞生以来至信史时期之前的整个时期，但实用上通常只用来描述自地球上有生命开始后的时期，甚至只描述类人生物出现后的时期。对于人类的史前时代的划分，史前史学家通常使用由丹麦考古学家克里斯蒂安·朱金森·汤姆森（Christian Jürgensen Thomsen 1788—1865）提出的“三代法”，根据人类对工具的使用程度将史前时代划分为三个时期，分别称为“石器时代”“青铜时代”和“铁器时代”。而研究人类出现前历史的学者则喜欢使用地质年代来划分时段。 古气候学邦德事件（英语：Bond event），又称1500年气候周期，是指北大西洋的冰筏活动，与全新世以来全球气候变化有关。目前已发生八起邦德活动，周期在1,000-1,500年之间","text":"史前时代（prehistory） 一般是指人类出现到文字出现之前的时代，意即历史记载由于各地人类发明文字的时间都有不同，所以史前时代没有一个适用于各地的特定时间。不过，作为一个泛称，史前时代通常指公元前4000年以前的时期。举例，尚未发现文字记载的石器时代（前250万年－前4000年）是史前时代，青铜器时代（前4000年－各地不同时期完结）以后有文字记载之起就可称为信史时期。例如中国的五帝和夏朝就是史前时代，而商朝人则使用甲骨文和金文，甚至已经有“作册”等史官在竹简帛书上记载历史，故而中国从商朝开始就是信史。 广泛地说，史前时代可以追溯到自宇宙诞生以来至信史时期之前的整个时期，但实用上通常只用来描述自地球上有生命开始后的时期，甚至只描述类人生物出现后的时期。对于人类的史前时代的划分，史前史学家通常使用由丹麦考古学家克里斯蒂安·朱金森·汤姆森（Christian Jürgensen Thomsen 1788—1865）提出的“三代法”，根据人类对工具的使用程度将史前时代划分为三个时期，分别称为“石器时代”“青铜时代”和“铁器时代”。而研究人类出现前历史的学者则喜欢使用地质年代来划分时段。 古气候学邦德事件（英语：Bond event），又称1500年气候周期，是指北大西洋的冰筏活动，与全新世以来全球气候变化有关。目前已发生八起邦德活动，周期在1,000-1,500年之间 新仙女木时期新仙女木事件 - 维基百科，自由的百科全书新仙女木事件，也称为克洛维斯彗星假说，是为解释末次冰期之后的新仙女木期的一个极具竞争性的科学假说。这个假设，科学家们还在争辩中。他们提出当时的气候变化是由于一颗或多颗彗星的撞击，或是其在空中的爆炸而引发了气候的变冷。 另一次可能的彗星撞击： 通古斯大爆炸 /通古斯大爆炸 新仙女木期 - 维基百科，自由的百科全书新仙女木期（Younger Dryas），是指距今 12800 年至 11500 年的一段持续 1300 年左右的冰期。在此之前地球一直处在温度逐渐升高的间冰期中，由于突然发生了新仙女木事件而导致全球气温骤降，北极冰川南侵。 这一时期的得名来自于欧洲北部仙女木属的一种植物，该物种本生活在寒带地区，而对格陵兰冰川的研究却发现，新仙女木期时在低纬度地区都能发现该物种的花粉，从而表明当时气候寒冷，该物种大肆南侵。","categories":[{"name":"66.History-and-Politics","slug":"66-History-and-Politics","permalink":"https://beefyheisenberg.github.io/categories/66-History-and-Politics/"}],"tags":[]},{"title":"电影和电视剧list","slug":"65.Music-and-Movies/电影list","date":"2024-01-24T01:27:54.148Z","updated":"2024-01-24T01:27:54.148Z","comments":true,"path":"65.Music-and-Movies/电影list/","link":"","permalink":"https://beefyheisenberg.github.io/65.Music-and-Movies/电影list/","excerpt":"","text":"★★★★★ 阳光灿烂的日子 少年派 地球最后的夜晚 她 / Her ★★★★ 两杆大烟枪 低俗小说 银翼杀手 绿皮书 头号玩家 失控玩家 永无止境 / Limitless 路边野餐 漫长的婚约 角斗士","categories":[{"name":"65.Movies","slug":"65-Movies","permalink":"https://beefyheisenberg.github.io/categories/65-Movies/"}],"tags":[{"name":"电影","slug":"电影","permalink":"https://beefyheisenberg.github.io/tags/电影/"}]},{"title":"电影和电视剧list","slug":"65.Movies/电影list","date":"2024-01-24T01:27:54.143Z","updated":"2024-01-24T01:27:54.143Z","comments":true,"path":"65.Movies/电影list/","link":"","permalink":"https://beefyheisenberg.github.io/65.Movies/电影list/","excerpt":"","text":"★★★★★ 阳光灿烂的日子 少年派 地球最后的夜晚 她 / Her ★★★★ 两杆大烟枪 低俗小说 银翼杀手 绿皮书 头号玩家 失控玩家 永无止境 / Limitless 路边野餐 漫长的婚约 角斗士","categories":[{"name":"65.Movies","slug":"65-Movies","permalink":"https://beefyheisenberg.github.io/categories/65-Movies/"}],"tags":[{"name":"电影","slug":"电影","permalink":"https://beefyheisenberg.github.io/tags/电影/"}]},{"title":"费奥多尔·陀思妥耶夫斯基","slug":"64.Novel-and-Poesy/陀思妥耶夫斯基","date":"2024-01-24T01:27:54.137Z","updated":"2024-01-24T01:27:54.137Z","comments":true,"path":"64.Novel-and-Poesy/陀思妥耶夫斯基/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/陀思妥耶夫斯基/","excerpt":"","text":"1821年在莫斯科出生于莫斯科一个贫穷的家庭，在七个孩子中排名老二。他的父亲是一名退休军医和彻彻底底的酒鬼。他的父母的家系是源自平斯克地区的立陶宛裔贵族。父亲工作的医院地处莫斯科的荒郊野岭，犯人公墓、精神病院和孤儿院便是仅有地标式建筑。这些景象给年纪尚小的陀思妥耶夫斯基留下了深刻的印象，对穷困者的怜悯深深刺痛着他的心灵。虽然父母不允许，年轻的陀思妥耶夫斯基还是喜欢去医院花园走走，看看那些晒太阳的病人，听他们讲故事。早年时透过童话故事及传说开始接触文学，也有涉猎俄罗斯及其他国家作者的作品。 1837年，陀思妥耶夫斯基的母亲过世，当时陀思妥耶夫斯基才15岁，同年他离开家，进入尼古拉耶夫军事工程学院就读。在彼得堡的军事工程学校期间，陀思妥耶夫斯基学习他于之不屑的数学。与此同时，他还涉猎了莎士比亚、帕斯卡尔、维克多·雨果的文学作品。 1839年父亲去世，死因不明。或许这个专制的父亲给了陀思妥耶夫斯基很大的影响，以至于他把父亲的形象搬到了《卡拉马佐夫兄弟》中的老卡拉马佐夫这个“邪恶而感情脆弱的小丑”父亲身上。 1840 年代陀思妥耶夫斯基结识了尼卡索夫，并在他的鼓励下开始写作。 1842 年，陀思妥耶夫斯基受命成为中尉，并在一年后从军事工程学校毕业。 1844 年他退伍后，陀思妥耶夫斯基开始了自己的专职写作生涯 1846年，25岁时第一本长篇小说《穷人》在出版，让他可以进入圣彼得堡的文学圈中。《穷人》连载于期刊《当代人》上，广获好评。据说杂志主编尼卡索夫在读完小说后兴奋地冲进俄罗斯文学评论家别林斯基的办公室，大叫：“又一个果戈理出现了！”。 1847 年，陀思妥耶夫斯基开始对空想社会主义感兴趣，参加了彼得拉舍夫斯基小组的革命活动。陀思妥耶夫斯基非常喜欢别林斯基这篇文章，并寻找到手抄本在小组上朗读。 1849年4月23日他因牵涉反对沙皇的革命活动而被捕，并于11月16日被判处死刑。在1849年12月22日行刑之前的一刻才改判成了流放西伯利亚。 1850年1月23日，陀思妥耶夫斯基被押送至西伯利亚鄂木斯克军事监狱，开始了四年的漫长苦役生涯。在西伯利亚他的思想发生了巨变，他将服苦役期间的感受和见闻记在了《西伯利亚笔记》中，里面的很多素材被写进了《死屋手记》和其他作品中。1854年他被释放，但是要求必须在西伯利亚服役。 1857年，他恢复了贵族身份，并于1858年升为少尉，从此可以有自己的时间来思考与写作。从假处决事件到西伯利亚服刑这十年时间是他人生主要的转折，他开始反省自己，笃信宗教。也正是在西伯利亚，他遇到了今后的妻子——玛丽亚·伊萨耶娃（Maria Dmitriyevna Isaeva）。 1860 年，陀思妥耶夫斯基返回圣彼得堡，次年发表了第一部长篇《被侮辱与被损害的》。这部作品可以被看作是他前后期的过渡作品，既有前期的对社会苦难人民的描写，又带有后期的宗教与哲学探讨。这段时间他文学上有所进展，但生活却连遭打击。1864 年他的妻子和兄长相继逝世，他还需要照顾兄长的家人，这使得他濒临破产。他希望通过赌博来还清债务，却欠下更多债，整个人陷入消沉之中。 1866 年他的代表作《罪与罚》出版，而另一部长篇离交稿一个月，还没有写。在朋友介绍下，他认识了速记学校的高材生安娜·斯尼特金娜，两人高效率的工作，一个月内完成了《赌徒》，于 1867 年出版。 1867年两人结婚，在安娜的鼓励与帮助下，他的生活才开始安定下来。 1868 年他完成了《白痴》，1872 年完成了《群魔》 1880 年他发表了《卡拉马佐夫兄弟》这部他后期最重要的作品。1881 年陀思妥耶夫斯基准备写作《卡拉马佐夫兄弟》第二部。 1881年死于肺气肿的出血，陀思妥耶夫斯基的最后一句话是，他引用了马太福音 3:14–15:“约翰想要拦住他，说，我当受你的浸，你反到我这里来么？耶稣回答说，你暂且容许我吧，因为我们理当这样尽全般的义。” 他的墓碑上刻着《新约》经文：“我实实在在的告诉你们，一粒麦子不落在地里死了，仍旧是一粒；若是死了，就结出许多子粒来。” Pain and suffering are always inevitable for a large intelligence and a deep heart. The really great men must, I think, have great sadness on earth. // 《罪与罚》 Life is now given to man at the cost of pain and fear. Here, they are blinded by this sometimes. Now man is not yet that man. There will be another, new person, happy and proud, and for him it wouldn’t matter the death-life. He who overcomes pain and fear will become God himself. There will not be that God any longer. // 《群魔》 “The awful thing is that beauty is mysterious as well as terrible. God and the devil are fighting there and the battlefield is the heart of man.” // 可怕的是，美既神秘又可怕。上帝和魔鬼在那里战斗，战场是人类的心脏 —— 《卡拉马佐夫兄弟》","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"俄罗斯","slug":"俄罗斯","permalink":"https://beefyheisenberg.github.io/tags/俄罗斯/"}]},{"title":"《托洛茨基自传》","slug":"64.Novel-and-Poesy/托洛茨基自传","date":"2024-01-24T01:27:54.131Z","updated":"2024-01-24T01:27:54.132Z","comments":true,"path":"64.Novel-and-Poesy/托洛茨基自传/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/托洛茨基自传/","excerpt":"- 不要当做符号而去寻找认同感- 如何处理 Ni-Fe的矛盾？- 是否也有受虚无主义、人生意义的影响- 对存在和价值的看法- 支持其不断斗志的是什么- 他提到的“马克思主义的世界观和思维方法”，是什么样的？ 生平： 列夫·达维多维奇·托洛茨基_百度百科 托洛茨基主义 - 维基百科，自由的百科全书 相关影视作品：","text":"- 不要当做符号而去寻找认同感- 如何处理 Ni-Fe的矛盾？- 是否也有受虚无主义、人生意义的影响- 对存在和价值的看法- 支持其不断斗志的是什么- 他提到的“马克思主义的世界观和思维方法”，是什么样的？ 生平： 列夫·达维多维奇·托洛茨基_百度百科 托洛茨基主义 - 维基百科，自由的百科全书 相关影视作品： 托洛茨基逝世八十年｜在“魔鬼学”与“神学”之外思想市场澎湃新闻-The Paper 相关书籍： 被背叛了的革命 (豆瓣)：三联书店，1963 托洛茨基反动言论摘录 (豆瓣) 人民出版社，1964 “不断革命”论 (豆瓣)：三联书店，1966 p3:我的童年不像小部分人那样，是阳光明媚的林中空地，也不像大多数人那样，是饥饿、暴力和委屈的黑暗洞穴。它是偏僻农村的小资产阶级家庭的灰色童年，那里的自然广袤而开阔，而习俗、眼界和兴趣却贫乏而狭隘。 p72：这个孩子不乏自我批评的精神，对自己甚至非常苛刻。对于自己的知识和性格特征都不满意，而且这种不满越到后来越厉害。对于自己说谎，他会恼羞成怒。他也随时都会因为没有读过被别人侃侃而谈的书籍而自责。这应当与自尊心密切相关，应当变得更优秀、更高尚、更博学的想法越来越频繁地让他心悸。他常常思考人的使命，尤其是自己的使命。 学生年代，我既没有政治观点，也缺乏具备政治观点的需要。但我无意识的种种追求都是属于反对派的。我对现存制度、不公平现象和专横暴虐深感憎恨。这种感觉从何而来？ … p77：“自我完善” 对我而言与其说是思想流派，不如说是精神成长的有机需要的时期，与八十年代的消极思想体系紧密相关的个人道德问题曾一度在我身上出现。然而，自我完善很快就遇到了世界观的问题，后者又引发了重要的抉择，是民粹主义还是马克思主义。 书注：自我完善，指“道德自我完善”，系托尔斯泰宗教道德哲学的重要组成部分 p78：生活已在我的意识里积起了对社会的严重抗议。它是什么呢？是对被侮辱者的同情和对不公平的愤怒。后一种情绪可能最为强烈。从很小开始，在我所有的日常生活的印象中，人与人的不平等便以极其粗暴和赤裸的方式表达出来，不公平往往是最厚颜无耻的，不受惩罚的，人的尊严处处遭受践踏。 p92：牢房宽大，但钉着粗铁条的窗户很小，而且封的严严实实，只能勉强透进光线。这是一种完全的、绝对的、暗无天日的孤独。…我没有换洗的衣服，三个月期间我都穿着那身衣服。我没有肥皂，监狱里的寄生虫快把我活活吃掉了。 我给自己立下规矩：每天沿着对角线走一千一百一十一步。我当时还不到十九岁，这是完完全全的与世隔绝。…无限的孤独感有时也会无情的噬咬我，这时我便异常坚决地用穿坏的鞋掌数出一千一百一十一步来。 p93：在敖德萨监狱的头几个月里，我没有收到过从外面送来的书，只能在监狱图书馆里寻找满足。那里的读物主要是陈年的保守历史杂志和宗教杂志。我孜孜不倦、如饥似渴地研读它们，了解了新旧时代所有教派和异端，东正教祈祷仪式的所有优点，反对天主教、新教、托尔斯泰主义和达尔文主义的最好证据。…对天堂及其内部结构和所处位置的详细探索总是以伤心的结尾收场：“天堂位置的准确标识并不存在” p94：神学杂志上刊登的有关共济会的文章引起了我的兴趣，这个奇怪的流派是从哪里来的呢？ p95：“思想不会从天而降” p101:…到流放时，马克思主义彻底成了我的基本世界观和思维方法。如今，流放中的我试图用自己掌握的观点去分析人类生活中所谓“永恒”的问题：爱情、死亡、友谊、乐观主义、悲观主义等等。在不同的时代不同的环境中，人的爱、情和希望各不相同。正如树木通过根须汲取土壤里的养分来供给花朵和果实一样，个人也在社会的经济基础中为自己的感情和思想——哪怕是最“崇高的”——吸收营养。 p146：1905年革命是国家生活、党的生活和我个人生活的转折，是走向成熟的转折。…在监狱里和流放中打下的理论基础以及在流亡生活中掌握的方法如今第一次直接在战斗中派上了用场，面对事情我觉得自己充满了信心。我知道它们的原理——至少我自己是这么认为的 p150：审判、流放、逃跑我躺在监狱的小床上，陶醉在书籍中，全身上下感到莫大的满足，就像美食家啜饮上好的葡萄酒或者吐纳浓香的雪茄一样。这是非常美好的时刻","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"托洛茨基","slug":"托洛茨基","permalink":"https://beefyheisenberg.github.io/tags/托洛茨基/"},{"name":"自传","slug":"自传","permalink":"https://beefyheisenberg.github.io/tags/自传/"}]},{"title":"夏伯阳与虚空","slug":"64.Novel-and-Poesy/夏伯阳与虚空","date":"2024-01-24T01:27:54.126Z","updated":"2024-01-24T01:27:54.127Z","comments":true,"path":"64.Novel-and-Poesy/夏伯阳与虚空/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/夏伯阳与虚空/","excerpt":"夏伯阳与虚空 (豆瓣) 《夏伯阳与虚空》艺术地反映了苏联解体后俄罗斯社会光怪陆离的现实生活。是俄罗斯当代最神秘，同时又是最受读者欢迎的作家维克多·佩列文的一部代表作。小说发表后在俄罗斯国内和国际上获得多项奖励，为作者带来世界性的声望。作者本人认为：“这是世界文学中第一部情节发生于绝对虚空中的作品。”故事发生在1919年夏伯阳所部的红军师中，同时又有当今时代虚空环境中的情节。小说主要主人公彼得·虚空是颓废派诗人、夏伯阳师的政委。而电影《夏伯阳》中的百战不殆的天才的红军师长夏伯阳在这部小说中却成了点缀时下生活的幽默人物。虚拟、虚空、虚幻，犹如一幅后现代主义的抽象画。但是，这位貌似遁世的严肃文学作家对于他的生于斯、长于斯的俄罗斯国家和俄罗斯人民的命运、前途的关切之情，却借助书的中主人公之口作了奇特的表述。 与他的《百事一代》、《昆虫的生活》等作品一样，《夏伯阳与虚空》并不注重结构，语言也十分随意，表现出某种梦魇式的支离破碎和荒唐无稽，其实这些特点本身也是俄罗斯过渡时期社会现实的反映。 这部严肃小说立意深沉，风格独特，是俄罗斯当代鲜见的一本好书。喜爱文学的读者，文学研究者和作家，在细心阅读这部作品时将会体会到不同寻常的感悟并得到富于教益的启迪。","text":"夏伯阳与虚空 (豆瓣) 《夏伯阳与虚空》艺术地反映了苏联解体后俄罗斯社会光怪陆离的现实生活。是俄罗斯当代最神秘，同时又是最受读者欢迎的作家维克多·佩列文的一部代表作。小说发表后在俄罗斯国内和国际上获得多项奖励，为作者带来世界性的声望。作者本人认为：“这是世界文学中第一部情节发生于绝对虚空中的作品。”故事发生在1919年夏伯阳所部的红军师中，同时又有当今时代虚空环境中的情节。小说主要主人公彼得·虚空是颓废派诗人、夏伯阳师的政委。而电影《夏伯阳》中的百战不殆的天才的红军师长夏伯阳在这部小说中却成了点缀时下生活的幽默人物。虚拟、虚空、虚幻，犹如一幅后现代主义的抽象画。但是，这位貌似遁世的严肃文学作家对于他的生于斯、长于斯的俄罗斯国家和俄罗斯人民的命运、前途的关切之情，却借助书的中主人公之口作了奇特的表述。 与他的《百事一代》、《昆虫的生活》等作品一样，《夏伯阳与虚空》并不注重结构，语言也十分随意，表现出某种梦魇式的支离破碎和荒唐无稽，其实这些特点本身也是俄罗斯过渡时期社会现实的反映。 这部严肃小说立意深沉，风格独特，是俄罗斯当代鲜见的一本好书。喜爱文学的读者，文学研究者和作家，在细心阅读这部作品时将会体会到不同寻常的感悟并得到富于教益的启迪。","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"俄罗斯","slug":"俄罗斯","permalink":"https://beefyheisenberg.github.io/tags/俄罗斯/"},{"name":"苏联","slug":"苏联","permalink":"https://beefyheisenberg.github.io/tags/苏联/"}]},{"title":"但丁《神曲》","slug":"64.Novel-and-Poesy/但丁《神曲》","date":"2024-01-24T01:27:54.121Z","updated":"2024-01-24T01:27:54.122Z","comments":true,"path":"64.Novel-and-Poesy/但丁《神曲》/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/但丁《神曲》/","excerpt":"但丁·阿利吉耶里（义大利语：Dante Alighieri，义大利语：[ˈdante aliˈɡjɛːri]，1265年－1321年9月14日）全名杜兰提·第·阿利吉耶罗·戴尔·阿利吉耶里，意大利中世纪诗人。他是现代意大利语的奠基者，也是欧洲文艺复兴时代的开拓人物。 名称的由来神曲（意大利语：Divina Commedia，英语：Divine Comedy） 但丁并没有为这部史诗给出明确的标题。在作品中但丁也只在《地狱篇》中提到过两次 Commedia 一词（意大利语，原意为喜剧），而 Divina（意大利意为：神圣）这一词则出自意大利著名文学家乔万尼·薄伽丘。如今，虽然在科学及文学的角度应该把这部著作称 Commedia，但 La Divina Commedia 一词还是依旧被广泛运用。","text":"但丁·阿利吉耶里（义大利语：Dante Alighieri，义大利语：[ˈdante aliˈɡjɛːri]，1265年－1321年9月14日）全名杜兰提·第·阿利吉耶罗·戴尔·阿利吉耶里，意大利中世纪诗人。他是现代意大利语的奠基者，也是欧洲文艺复兴时代的开拓人物。 名称的由来神曲（意大利语：Divina Commedia，英语：Divine Comedy） 但丁并没有为这部史诗给出明确的标题。在作品中但丁也只在《地狱篇》中提到过两次 Commedia 一词（意大利语，原意为喜剧），而 Divina（意大利意为：神圣）这一词则出自意大利著名文学家乔万尼·薄伽丘。如今，虽然在科学及文学的角度应该把这部著作称 Commedia，但 La Divina Commedia 一词还是依旧被广泛运用。 构成及语言的使用在中世纪，Commedia代表着一种游离于贵族与平民两者之间的一种风格。但丁一改通常一般中世纪的风格，以丰富的想象力、精深的神学、哲学修养和新颖的构思，将神曲以多层次、多色调的形象描绘。表达了诗人精辟而又抽象的哲学、神学观点，又赋予这些境界以巨大的真实性，奇而不诡，精微致深，使人如身临其境。 全诗为三部《地狱篇》《炼狱篇》《天堂篇》，每部33首，《地狱篇》最前面增加一首序诗，一共100首。诗句是三行一段，连锁押韵，各首长短大致相等，每部也基本相等。（地狱4720行；炼狱4755行；天堂4758行），每部都以“群星”（stelle）一词结束。 剧情 描述但丁在地狱（Inferno）、炼狱 （Purgatorio）及天堂（Paradiso）游历的经过，一开始是由古罗马诗人维吉尔引导，后来是由他的心上人贝缇丽彩·坡提纳里引导 但丁在《神曲》中所描寫的地獄（中）、煉獄（右下）和天堂（右上） 圖/取自wikipedia： 但丁以第一人称记述自己35岁时（人生的中途）误入一座黑暗的森林（象征罪恶），在一座小山脚下，有三只猛兽拦住去路，一只豹（象征欺骗或恶意），一只狮子（象征野心），一只母狼（象征贪婪），有一种说法是说它们分别象征佛罗伦萨当时的情况、法国国王和罗马教皇。他在呼救时出现了古罗马诗人维吉尔的灵魂，对他说：“你不能战胜这三只野兽，我指示你另一条路径。”维吉尔带着但丁走过了地狱、炼狱。最后由但丁暗恋的情人贝缇丽彩·波尔蒂纳陪他前去天堂。 他描述的世界，地狱是一个大漏斗，中心在耶路撒冷，从上到下逐渐缩小，越向下所控制的灵魂罪恶越深重，直到地心，是魔王撒但掌握漏斗顶端，他们从魔王的尾巴爬过地心，另一面是炼狱。炼狱如同一座高山，在耶路撒冷相对的地球另一面海中，灵魂在这里忏悔涤罪，山分七层代表七宗罪，每上升一层就会消除一种罪过，直到山顶就可以升入天堂。天堂分为九层，越往上的灵魂越高尚，直到越过九重天，才是真正的天堂，圣母和所有得救的灵魂所在，经圣母允许，才能一窥圣三位一体的上帝。 但丁在旅途中遇到许多名人的灵魂并与之交谈，包括历史上好的坏的许多著名人物，他将自己钦佩和厌恶的人物分别纳入各个部位，甚至他痛恨的教皇及一些佛罗伦萨人全打入地狱。有些详细情况《圣经》中并没有记载，是他自己发明的，但也符合逻辑。其中也包括许多他对神学问题的见解，系统地阐述了他对世界的看法。 地狱篇（Inferno） 地狱形似一个上宽下窄的漏斗，共9层。第一层是灵薄狱，生于基督之前，未能接受洗礼的古代异教徒，在这里等候上帝的审判。在其余8层，罪人的灵魂按生前所犯的罪孽（贪色、贪食、贪婪、愤怒、信奉邪教、强奸、欺诈、背叛），分别接受不同的严酷刑罚。 地狱之门上的铭刻：“这里直通悲惨之城，由我这里直通无尽之苦，这里直通堕落众生． ． ．我永存不朽，我之前，万象未形，只有永恒的事物存在，来者啊！快将一切希望扬弃!”（Inferno III 1-9） 地狱过道：无作为者的亡魂在此受苦受难，他们跟随著一面永远无法停止的无主旗帜四处飘荡，一边受可怕的牛虻和马蜂叮蜇。其中包含撒旦成为叛天使时没有表达鲜明立场的天使。以及教皇策肋定五世 这时将目光放远一点，看见大河河畔聚集著无数亡魂，这条河名为阿刻戎河（Acheron），亦名苦难之河、祸川。船伕卡戎（Charon）在此将安葬的亡魂送到对岸的冥府。 I.灵薄狱：未受洗者，“他们没有犯罪‧‧‧他们生时基督教未立，无从向你所信仰者回归，有欲望而无希望，郁郁不乐但没有痛苦。” 另外还特别提到那些：“才能超卓，却要在地狱边境徘徊”者，有诗人荷马、贺拉斯、奥维德、卢克莱修、维吉尔；有英雄，例如与阿基里斯齐名的特洛伊王子赫克托耳、伊利亚德中的埃涅阿斯和尤里乌斯·凯撒；也有哲人，像柏拉图、苏格拉底、亚里斯多德…等，其他才能超卓者还有希波克拉底、欧几里得、西塞罗、托勒密…。接著但丁和维吉尔来到第一层和第二层的交界，并见到冥界的判官米诺斯（Minos），生前为克里特国王-（希腊神话中所提），执法严明，死后因而成为冥界判官。他的面前，亡魂一个个听候裁夺，依罪孽轻重发配，被米诺斯的尾巴掷入深处。 II.纵欲：“地狱的飓风吹刮不已，用狂暴的威力鞭戮阴魂。”在此见到诸多英雄美人如：爱上埃涅阿斯的迦太基女王狄多、埃及艳后克丽奥佩脱拉 、海伦与帕里斯、阿基里斯、崔斯坦与伊索德． ． ．。最后看见保罗与法兰西斯卡，“他们一起，在风中似乎飞的轻灵而悠游。”，并且听法兰西斯卡讲述这个凄美的悲剧。 - “爱欲，不容被爱者不去施爱。猛然借此人魅力将我掳住。你看，他现在仍不肯把我放开。爱欲，把我们引向同一条死路。”（Inferno V 103-106）- “有一天，我们一起看书消遣，读到兰斯洛如何遭爱情桎梏，那时，我们在一起毫无疑惧。那个故事，好几次使我们抬头相望，因而视线交错，使我们面色泛红忽变。不过，把我们征服的只有一处。那一刻，就决定了我们的命运。当我们读到那微笑的嘴唇，如何为她的情人所吻。他，我永恒的伴侣，向我靠拢。全身震颤著，亲吻我的嘴唇。”（Inferno V 127-136） III.暴食：守卫为凯洛贝罗斯（Cerberus），地狱三头犬。神话中职责为看守冥府之门不让活人进入。触犯此罪的人将受寒冷且滂沱不绝的凶雨、冰雹、与污水暴淋，于臭气肆虐的恶泥中痛苦翻滚。 IV.贪婪：守卫者为财神普鲁托斯（Plutus）（并非希腊神话中的冥神黑帝斯，常有人把他与古罗马时期的普鲁托混淆，普鲁在拉丁文及希腊文中，皆有富有的意思，因此到了古罗马时期，普鲁托也拥有掌管财富的神职。），传说宙斯为了让他施财时不分善恶而将他双眼弄瞎。贪婪分为挥霍与吝啬，两种人推著巨石互撞，重复到永远。 V.愤怒：两人来到第五层，看见一道无名的涌泉，其源头为斯堤克斯河（Styx）（也名为冥河，并非日本那条），又作悔恨之河、誓川。在希腊神话里，众神常在此河立誓，违反誓约者将九年无法说话。愤怒分暴怒与愠怒；前者刑罚为相互肉搏，撕咬皮肉；后者浸在黑沼斯提克斯河下发不出声音。前进间，两人来到狄斯之城（或译狄斯之墙，The walls of Dis）外，看见斯堤克斯河引渡的船伕弗勒古阿斯（Phlegyas）驾著小船而来，两人登船，越过斯提克斯泥沼，来到狄斯城墙外，却遭到复仇女神和蛇发女妖梅杜莎的阻挡，幸有天使降临，并为他们以神之棒将城门开启。 VI.异端：进入狄斯之城后，但丁和维吉尔来到了地狱的第六层，在这里异端者将站立在坟墓中，下肢受烈火灼烧的刑罚。其中有古希腊哲学家伊比鸠鲁，因不相信灵魂不灭之说，主张灵魂随肉体见灭，与基督教义相悖，受中世纪神学家圣奥古斯丁猛烈抨击，故在此被打入异端。 VII.施暴：守卫为米诺陶洛斯（Minotaur），克里特岛的牛头怪。第七层暴力之罪依施暴对象的不同分三圈，分别是对他人，杀人犯和掳掠者；对自身，自杀者和败家者；对上帝、自然及技艺，渎神者、鸡奸者和放高利贷者。以对上帝、自然和技艺者施暴的罪孽为最深重。 VIII. 欺诈：Malebolge，共有十囊，淫媒、谄谀者、神棍、预言者、污吏、伪君子、盗贼、献诈者、挑拨离间者、作伪者。 IX.背叛者：分为四界，该隐界：出卖亲属者；安忒诺耳界：出卖祖国（所属团体）者；多利梅界：出卖客人者；犹大界：出卖恩人者。犹大、布鲁图、卡西乌斯分别为撒旦的三张嘴啃咬。 炼狱篇（Purgatorio） 炼狱共7级，加上净界山和地上乐园，共9层。生前犯有罪过，但程度较轻，已经悔悟的灵魂，按人类7大罪过（傲慢、嫉妒、愤怒、懒惰、贪婪、暴食、色欲），分别在这里修炼洗过，而后一层层升向光明和天堂。在净界山顶的地上乐园，维吉尔隐退，贝德利采出现。 净界山下海岸 环山平地圈 诸王的花谷 净界之门 第一层:涤除傲慢 第二层:涤除嫉妒 第三层:涤除愤怒 第四层:涤除懒惰 第五层:洗涤贪婪 第六层:惩罚暴食 第七层:涤除色欲 伊甸园（地上乐园） 天堂篇（Paradiso）贝缇丽彩责备但丁迷误在罪恶的森林，希望他忏悔，并让他观看表示教堂种种腐败的幻景，饮用忘川水，以遗忘过去的过失，获取新生。随后，贝缇丽彩引导但丁游历天堂九重天。这里是幸福的灵魂的归宿；他们是行善者、虔诚的教士、立功德者、哲学家和神学家、殉教者、正直的君主、修道者、基督和众天使。在九重天之上的天府，但丁得见上帝之面，但上帝的形象如电光之一闪，迅即消失，于是幻象和《神曲》也戛然而止。 贝缇丽彩·波蒂纳里（义大利语：Beatrice di Folco Portinari；发音：/be.aˈtriːtʃe/，1266年－1290年）是一位佛罗伦萨女士，是但丁诗中的灵感，也因此而著名。贝缇丽彩是但丁《新生》的主要创作灵感。同时在《神曲》的最后作为他的向导出现，在那里她接替拉丁诗人维吉尔成为新的向导，因为作为一个异教徒，维吉尔无法进入天堂。她是幸福和爱的化身，正如她的名字那样，自然的成为了但丁的向导。 @ref: https://zh.wikipedia.org/zh-hans/%E7%A5%9E%E6%9B%B2 阴曹地府“旅游指南” | 机核 GCORES","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"欧洲","slug":"欧洲","permalink":"https://beefyheisenberg.github.io/tags/欧洲/"},{"name":"意大利","slug":"意大利","permalink":"https://beefyheisenberg.github.io/tags/意大利/"},{"name":"文艺复兴","slug":"文艺复兴","permalink":"https://beefyheisenberg.github.io/tags/文艺复兴/"}]},{"title":"奇异的旅行","slug":"64.Novel-and-Poesy/奇异的旅行","date":"2024-01-24T01:27:54.116Z","updated":"2024-01-24T01:27:54.116Z","comments":true,"path":"64.Novel-and-Poesy/奇异的旅行/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/奇异的旅行/","excerpt":"","text":"奇异的旅行 —— 儒勒·凡尔纳的作品集： 气球上的五星期 （1863） 地心游记 （1864） 从地球到月球) （1865） 哈特拉斯船长历险记 （1866） 格兰特船长的儿女 （1867–68） 海底两万里 （1869–70） 环绕月球 （1870） 漂浮的城市 （1871） 南部非洲探险 （1872） 飘逝的半岛 （1873） 八十天环游地球 （1873） 神秘岛 “神秘岛 (小说)”) （1874–75） 大臣号遇难者 （1875） 沙皇的邮件 （1876） 太阳系历险记 （1877） 美丽的地下世界 （1877） 十五岁的小船长 （1878） 蓓根的五亿法郎 （1879） 一个中国人在中国的遭遇 （1879） 蒸汽屋 （1880） 亚马逊漂流记 （1881） 史班瑟岛 （1882） 绿光&amp;action=edit&amp;redlink=1 “绿光 (小说)（页面不存在）”) （1882） 环游黑海历险记 （1883） 南方之星 （1884） 烽火岛 （1884） 桑道夫伯爵 （1885） 一张彩票 （1886） 征服者罗比尔 （1886） 北方反对南方 （1887） 法兰西之路 （1887） 十五少年漂流记 （1888） 无名之家 （1889） 北冰洋的幻想 （1889） 奇特旅行记 （1890） 布兰尼肯夫人 （1891） 喀尔巴阡古堡 （1892） 特派记者：篷巴拉克历险记 （1892） 小把戏 （1893） 昂蒂费尔师傅奇遇记 （1894） 机器岛 （1895） 迎着三色旗 （1896） 奥兰情游 （1896） 极地司芬克斯 （1897） 壮丽的奥里诺科河 （1898） 一个怪人的遗嘱 （1899） 第二祖国 （1900） 空中村落 （1901） 圣—埃诺克号历险记 （1901） 基普兄弟 （1902） 旅行基金 （1903） 利沃尼惨案 （1904） 主宰世界的人 （1904） 大海入侵 （1905）","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[]},{"title":"维特根斯坦-战时笔记","slug":"64.Novel-and-Poesy/维特根斯坦-战时笔记","date":"2024-01-24T01:27:54.110Z","updated":"2024-01-24T01:27:54.111Z","comments":true,"path":"64.Novel-and-Poesy/维特根斯坦-战时笔记/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/维特根斯坦-战时笔记/","excerpt":"仅《战时笔记》的私人部分 14.8.15船上的船员是一群猪！没有任何志向，令人难以置信地粗俗、愚蠢、邪恶，因此以下说法自然不成立：一项共同的伟大事业必然使人变得高尚 14.9.2几乎完全没有感性上的要求，以前我总是想象着是在与一个朋友交谈，但是几乎没有这样的事了 14.9.12我总是一再地在心中对自己说托尔斯泰的如下一段话：一个人从肉体上说是软弱无力的，但是经由精神他成为自由的 14.9.15削土豆皮之于我就如同磨镜片之于斯宾莎诺一样","text":"仅《战时笔记》的私人部分 14.8.15船上的船员是一群猪！没有任何志向，令人难以置信地粗俗、愚蠢、邪恶，因此以下说法自然不成立：一项共同的伟大事业必然使人变得高尚 14.9.2几乎完全没有感性上的要求，以前我总是想象着是在与一个朋友交谈，但是几乎没有这样的事了 14.9.12我总是一再地在心中对自己说托尔斯泰的如下一段话：一个人从肉体上说是软弱无力的，但是经由精神他成为自由的 14.9.15削土豆皮之于我就如同磨镜片之于斯宾莎诺一样 《笔记》中反复提到的：感性上的需求、打飞机、工作（志愿兵的工作是？）——“工作了一些时间”，“今天几乎没有工作”、还没有获得那个‘综览’ 这里的综览跟其他学者所谓的“综观”是同一概念。综观的视角是维特根斯坦1930年代以后最为核心的观念。为了阐释综观理念，维特根斯坦大概描绘了三种综观式的“表现方式”弗雷泽在《金枝》中提出的“发展的假设”、歌德的“原初样式”以及他自己主张的“综观式的表现”。（楼巍，2016；马耶夏克，2017）“综观式的表现”指的就是“让更多的材料处于同一平面，全面而公平地编排材料，观察它们之间的联系和区别，而不在其背后构造额外的理论和解释….这一表现方法的主要目的并非让表现的对象变清楚，而是让思考者自身变得清楚并消除哲学疑惑。” @ref: 论“中期”维特根斯坦“治疗型”哲学的两种解读 | Redian新闻","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"维特根斯坦","slug":"维特根斯坦","permalink":"https://beefyheisenberg.github.io/tags/维特根斯坦/"}]},{"title":"安东·契诃夫","slug":"64.Novel-and-Poesy/契诃夫","date":"2024-01-24T01:27:54.099Z","updated":"2024-01-24T01:27:54.100Z","comments":true,"path":"64.Novel-and-Poesy/契诃夫/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/契诃夫/","excerpt":"《海鸥》1896 《海鸥》由契诃夫创作，讲述的是在一个乡村的美丽的湖滨，有一位少女妮娜，她幻想着舞台、荣誉、爱情、幸福，一个初学写作的青年特里勃列夫爱上了她。特里勃列夫的母亲是一个名演员，她带着名作家果林一块来到自己哥哥庄园里休养。随后，妮娜狂热地爱上了果林。而果林却是一个轻浮的人，他玩厌了妮娜后，给她留下个孩子，然后抛弃了她。但生活的磨难并没有把妮娜打垮，最终她成为了一个好演员，面对事业成功的妮娜，一事无成的特里勃列夫在绝望中开枪自杀。 可是你我的灵魂呢，却没有可以接触之点。我爱你，由于苦恼，我在家里坐不住。我每天来回走十二里路，跑来看你，而我所遇到的只是你那种表示无能为力的冷淡。这是很可以理解的。我没有财产，家里人口又多……谁也不会嫁给一个连自己都没得吃的男人啊 人，狮子，鹰和鹧鸪，长着犄角的鹿，鹅，蜘蛛，居住在水中的无言的鱼，海盘车，和一切肉眼所看不见的生灵——总之，一切生命，一切，一切，都在完成它们凄惨的变化历程之后绝迹了……到现在，大地已经有千万年不再负荷着任何一个活的东西了，可怜的月亮徒然点着它的明灯。草地上，清晨不再扬起鹭鸶的长鸣，菩提树里再也听不见小金虫的低吟了。只有寒冷、空虚、凄凉。","text":"《海鸥》1896 《海鸥》由契诃夫创作，讲述的是在一个乡村的美丽的湖滨，有一位少女妮娜，她幻想着舞台、荣誉、爱情、幸福，一个初学写作的青年特里勃列夫爱上了她。特里勃列夫的母亲是一个名演员，她带着名作家果林一块来到自己哥哥庄园里休养。随后，妮娜狂热地爱上了果林。而果林却是一个轻浮的人，他玩厌了妮娜后，给她留下个孩子，然后抛弃了她。但生活的磨难并没有把妮娜打垮，最终她成为了一个好演员，面对事业成功的妮娜，一事无成的特里勃列夫在绝望中开枪自杀。 可是你我的灵魂呢，却没有可以接触之点。我爱你，由于苦恼，我在家里坐不住。我每天来回走十二里路，跑来看你，而我所遇到的只是你那种表示无能为力的冷淡。这是很可以理解的。我没有财产，家里人口又多……谁也不会嫁给一个连自己都没得吃的男人啊 人，狮子，鹰和鹧鸪，长着犄角的鹿，鹅，蜘蛛，居住在水中的无言的鱼，海盘车，和一切肉眼所看不见的生灵——总之，一切生命，一切，一切，都在完成它们凄惨的变化历程之后绝迹了……到现在，大地已经有千万年不再负荷着任何一个活的东西了，可怜的月亮徒然点着它的明灯。草地上，清晨不再扬起鹭鸶的长鸣，菩提树里再也听不见小金虫的低吟了。只有寒冷、空虚、凄凉。 我孤独啊。每隔一百年，我才张嘴说话一次，可是，我的声音在空漠中凄凉地回响着，没有人听……而你们呢，惨白的火光啊，也不听听我的声音……沼泽里的腐水，靠近黎明时分，就把你们分娩出来，你们于是没有思想地、没有意志地、没有生命的脉搏地一直漂泊到黄昏。那个不朽的物质力量之父，撒旦，生怕你们重新获得生命，立刻就对你们，像对顽石和流水一样，不断地进行着原子的点化，于是，你们就永无休止地变化着。整个的宇宙里，除了精神，没有一样是固定的，不变的。 我，就像被投进空虚而深邃的井里的一个俘虏一般，不知道自己到了什么地方，也不知道会遭遇到什么。但是，只有一件事情我是很清楚的，就是，在和撒旦，一切物质力量之主的一场残酷的斗争中，我会战胜，而且，在我胜利以后，物质和精神将会融化成为完美和谐的一体，而宇宙的自由将会开始统治一切。但是那个情景的实现，只能是一点一点的，必须经过千千万万年，等到月亮、灿烂的天狼星和大地都化成尘埃以后啊……在那以前，一切将只有恐怖…… 4月份去看了一场戏剧，《西部片 True West》的中文版，地点在在将台西路的文心华策，片场在拽马咖啡酒吧里，没有舞台，表演者和观众没有距离，很不一样的观看体验。我的身后是道具柜，上面有一沓发黄的稿纸，上面的文字读起来很有意思。 我以为这可能是出自某个编剧之手，后来问了Google才知道，这是契科夫的《海鸥》","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"俄罗斯","slug":"俄罗斯","permalink":"https://beefyheisenberg.github.io/tags/俄罗斯/"},{"name":"小说摘录","slug":"小说摘录","permalink":"https://beefyheisenberg.github.io/tags/小说摘录/"},{"name":"契科夫","slug":"契科夫","permalink":"https://beefyheisenberg.github.io/tags/契科夫/"},{"name":"话剧","slug":"话剧","permalink":"https://beefyheisenberg.github.io/tags/话剧/"}]},{"title":"纪伯伦-《先知》","slug":"64.Novel-and-Poesy/纪伯伦-先知","date":"2024-01-24T01:27:54.094Z","updated":"2024-01-24T01:27:54.095Z","comments":true,"path":"64.Novel-and-Poesy/纪伯伦-先知/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/纪伯伦-先知/","excerpt":"目录： 船的到来 The Coming of the Ship 爱 Love 婚姻 Marriage 孩子 Children 施予 Giving 饮食 Eating &amp; Drinking 工作 Work 哀乐 Joy &amp; Sorrow 居室 Houses 衣服 Clothes 买卖 Buying &amp; Selling 罪与罚 Crime &amp; Punishment 法律 Laws 自由 Freedom 理性与热情 Reason &amp; Passion 苦痛 Pain 自知 Self-Knowledge 教授 Teaching 友谊 Friendship 谈话 Talking 时光 Time 善恶 Good &amp; Evil 祈祷 Prayer 逸乐 Pleasure 美 Beauty 宗教 Religion 死 Death 言别 The Farewell 友谊一个青年说，请给我友谊。他回答说：你的朋友是你的有回答的需求。他是你用爱播种、用感谢收获的田地。他是你的饮食，也是你的火炉。因为你饥渴地奔向他，你向他寻求平安。当你的朋友向你倾吐胸臆的时候，你不要怕说出心中的“否”，也不要瞒住你心中的“可”。当他静默的时候，你的心仍然要倾听他的心；因为在友谊里，不用言语，一切的思想，一切的愿望，一切的希翼，都在无声的欢乐中发生而共享了。当你与朋友分离的时候，不要忧伤；因为你感到他的最可爱之点，当他不在时愈见清晰，正如登山者从平原望山峰，也加倍分明。愿除了寻求心灵的加深之外友谊没有别的目的。因为那只寻求着要泄露自身的神秘的爱，不算是爱，只算是一个撒下的网，只网住一些无益的东西。","text":"目录： 船的到来 The Coming of the Ship 爱 Love 婚姻 Marriage 孩子 Children 施予 Giving 饮食 Eating &amp; Drinking 工作 Work 哀乐 Joy &amp; Sorrow 居室 Houses 衣服 Clothes 买卖 Buying &amp; Selling 罪与罚 Crime &amp; Punishment 法律 Laws 自由 Freedom 理性与热情 Reason &amp; Passion 苦痛 Pain 自知 Self-Knowledge 教授 Teaching 友谊 Friendship 谈话 Talking 时光 Time 善恶 Good &amp; Evil 祈祷 Prayer 逸乐 Pleasure 美 Beauty 宗教 Religion 死 Death 言别 The Farewell 友谊一个青年说，请给我友谊。他回答说：你的朋友是你的有回答的需求。他是你用爱播种、用感谢收获的田地。他是你的饮食，也是你的火炉。因为你饥渴地奔向他，你向他寻求平安。当你的朋友向你倾吐胸臆的时候，你不要怕说出心中的“否”，也不要瞒住你心中的“可”。当他静默的时候，你的心仍然要倾听他的心；因为在友谊里，不用言语，一切的思想，一切的愿望，一切的希翼，都在无声的欢乐中发生而共享了。当你与朋友分离的时候，不要忧伤；因为你感到他的最可爱之点，当他不在时愈见清晰，正如登山者从平原望山峰，也加倍分明。愿除了寻求心灵的加深之外友谊没有别的目的。因为那只寻求着要泄露自身的神秘的爱，不算是爱，只算是一个撒下的网，只网住一些无益的东西。 工作你工作为的是要与大地和大地的精神一同前进。因为惰逸使你成为一个时代的生客，一个生命大队中的落伍者，这大队是庄严的，高傲而服从的，向着无穷前进的。在你工作的时候，你是一管笛，从你心中吹出时光的微语，变成音乐。你们谁肯做一根芦管，在万物合唱的时候，你独痴呆无声呢？你们常听人说，工作是祸殃，劳动是不幸。我却对你们说，你们工作的时候，你们完成了大地深远的梦之一部，他指示你那梦是从何时开头的。而你劳动不息的时候，你确实爱了生命。在工作里爱了生命，就是通彻了生命最深的秘密。你们也听见人说，生命是黑暗的，在你疲劳之中，你附和了那疲劳的人所说的话。我说生命的确是黑暗的，除非有了激励；一切的激励都是盲目的，除非有了知识；一切知识都是徒然的，除非是有了工作；一切工作都是空虚的，除非是有了爱。当你仁爱地工作的时候，你便与自己、与人类、与上帝连系为一。工作是眼能看见的爱。倘若你不是欢乐地而是厌恶地工作，那还不如撤下工作，坐在大殿的门边，去乞求那些欢乐工作的人的周济。倘若你无精打采地烤着面包，你烤成的面包是苦的，只能救半个人的饥饿。你若是怨望地压榨着葡萄酒，你的怨望，在酒里滴下了毒液。倘若你能像天使一般地唱，却不爱唱，你把人们能听到白昼和黑夜的声音的耳朵都塞住了。 婚姻你们一块儿出生，也要永远合一。在死的羽翼隔绝你们的岁月的时候，你们也要合一。噫，连在静默地忆想上帝之时，你们也要合一。不过在你们合一之中，要有间隙。让天风在你们中间舞荡。彼此相爱，但不要做成爱的锁链。只让他在你们灵魂的沙岸中间，做一个流动的海。彼此斟满了杯，却不要在同一杯中啜饮。彼此递赠着面包，却不要在同一块上取食。快乐在一处独舞，却仍让彼此静独，连琴上的那些弦子也是单独的，虽然他们在同一的音调中颤动。彼此赠献你们的心，却不要互相保留。因为只有生命的手，才能把持你们的心。要站在一处，却不要太密迩，因为殿里的柱子，也是分立在两旁，橡树和松柏，也不在彼此的树荫中生长。 孩子你们的孩子，都不是你们的孩子。乃是“生命”为自己所渴望的儿女。他们是凭借你们而来，却不是从你们而来，他们虽和你们同在，却不属于你们。你们可以给他们以爱，却不可以给他们以思想。因为他们有自己的思想。你们可以荫庇他们的身体，却不能荫庇他们的灵魂，因为他们的灵魂，是住在明日的宅中，那是你们在梦中也不能想见的。你们可以努力去模仿他们，却不能使他们来像你们。因为生命是不能倒行的，也不与昨日一同停留。你们是弓，你们的孩子是从弦上发出的生命的箭矢。那射者在无穷之中看定的目标，也用神力将你们引满，使他的箭矢迅速而遥远地射了出去。让你们在射者手中的弯曲成为喜乐吧；因为他爱那飞出的箭，也爱那静止的弓。 时光你要测量那不可量、不能量的时间。你要按照时辰与季候来调节你的举止，引导你的精神。你要把时光当作一条溪水，你要坐在岸边，看他流逝。但那在你里面无时间性的我，却觉悟到生命的无穷。也知道昨日只是今日的回忆，而明日只是今日的梦想。那你里面歌唱着、默想着，仍住在那第一刻在太空散步群星的圈子里。你们中间谁不感到他的爱的能力是无穷的呢？又有谁不感到那爱虽是无穷，却是在他本身的心中绕行，不是从这爱的思念移到那爱的思念，也不是从这爱的行为移到那爱的行为么？而且时光岂不是也像爱，是不可分析，没有间隙的么？但若是在你的意思里，你定要把时光分成季候，那就让每一季候围绕住其他的季候。也让今日用回忆拥抱过去，用希望拥抱着将来。","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"诗歌","slug":"诗歌","permalink":"https://beefyheisenberg.github.io/tags/诗歌/"},{"name":"纪伯伦","slug":"纪伯伦","permalink":"https://beefyheisenberg.github.io/tags/纪伯伦/"}]},{"title":"S01.博尔赫斯","slug":"64.Novel-and-Poesy/S01.博尔赫斯","date":"2024-01-24T01:27:54.088Z","updated":"2024-01-24T01:27:54.089Z","comments":true,"path":"64.Novel-and-Poesy/S01.博尔赫斯/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/S01.博尔赫斯/","excerpt":"豪尔赫·路易斯·博尔赫斯（Jorge Luis Borges） - 维基百科，自由的百科全书 我用什么才能留住你（1934）What can I hold you with?我用什么才能留住你? I offer you lean streets, desperate sunsets, the moon of the jagged suburbs.我给你一无所有的街道 毫无希望的日落 荒郊野岭的月光 I offer you the bitterness of a man who has looked long and long at the lonely moon.我给你那遥望孤月已经许久之人的悲伤","text":"豪尔赫·路易斯·博尔赫斯（Jorge Luis Borges） - 维基百科，自由的百科全书 我用什么才能留住你（1934）What can I hold you with?我用什么才能留住你? I offer you lean streets, desperate sunsets, the moon of the jagged suburbs.我给你一无所有的街道 毫无希望的日落 荒郊野岭的月光 I offer you the bitterness of a man who has looked long and long at the lonely moon.我给你那遥望孤月已经许久之人的悲伤 I offer you my ancestors, my dead men, the ghosts that living men have honoured in bronze: my father’s father killed in the frontier of Buenos Aires, two bullets through his lungs, bearded and dead, wrapped by his soldiers in the hide of a cow; my mother’s grandfather –just twentyfour– heading a charge of three hundred men in Peru, now ghosts on vanished horses.我给你我已死去的先辈他们的亡灵被后人用青铜殉葬:我的祖父在布宜诺斯艾利斯边境阵亡两颗子弹射穿了他的胸膛浓密的胡须陪伴他的遗容战友用牛皮将他的尸体裹藏我母亲那二十四岁的的祖父率领三百名士兵在秘鲁驰行如今也成了随战马消散的幽灵 I offer you whatever insight my books may hold, whatever manliness or humour my life.我给你我书中所含的一切洞明我给你我命中的一切气概或幽默 I offer you the loyalty of a man who has never been loyal.我给你一个从未忠贞过的人的至死不渝 I offer you that kernel of myself that I have saved, somehow –the central heart that deals not in words, traffics not with dreams, and is untouched by time, by joy, by adversities.我给你我设法留存的魂灵—-不用辞藻应付的内心 不靠出卖梦想而交易而这绝不会被时间 被喜悦 被逆境触及 I offer you the memory of a yellow rose seen at sunset, years before you were born.我给你有关在你出生前几年的黄昏中看到的那朵黄玫瑰的记忆 I offer you explanations of yourself, theories about yourself, authentic and surprising news of yourself.我给你你对自己的解释 涉及你自己的理论 和有关你自己的令人意外的真相 I can give you my loneliness, my darkness, the hunger of my heart; I am trying to bribe you with uncertainty, with danger, with defeat.我亦能给你我的寂寞 我的黑暗 我心的饥渴; 我正试图用困惑、危险、失败来打动你 这首诗于1934年所作，收录在《另一个，同一个》（1964），诗本身是 《献给贝阿特丽斯•比维洛尼•韦伯斯特•德布尔里奇》的节选。 关于天赐的诗——天堂应该是图书馆的模样上帝同时给我书籍和黑夜，这可真是一个绝妙的讽刺，我这样形容他的精心杰作，且莫当成是抱怨或者指斥。他让一双失去光明的眼睛主宰起这卷册浩繁的城池，可是，这双眼睛只能浏览那藏梦阁里面的荒唐篇什，算是曙光对其追寻的赏赐。白昼徒然奉献的无数典籍，就像那些毁于亚历山大的晦涩难懂的手稿一般玄秘。 有位国王傍着泉水和花园忍渴受饥，那盲目的图书馆雄伟幽深，我在其间奔忙却漫无目的。百科辞书、地图册、东方和西方、世纪更迭、朝代兴亡、经典、宇宙及宇宙起源学说，尽数陈列，却对我没有用场。 我心里一直都在暗暗设想，天堂应该是图书馆的模样","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"拉美","slug":"拉美","permalink":"https://beefyheisenberg.github.io/tags/拉美/"},{"name":"诗歌","slug":"诗歌","permalink":"https://beefyheisenberg.github.io/tags/诗歌/"}]},{"title":"R02.阿赫玛托娃","slug":"64.Novel-and-Poesy/R02.阿赫玛托娃","date":"2024-01-24T01:27:54.083Z","updated":"2024-01-24T01:27:54.083Z","comments":true,"path":"64.Novel-and-Poesy/R02.阿赫玛托娃/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/R02.阿赫玛托娃/","excerpt":"缪斯深夜，我等着她的来临，好像我的生命十分危险。什么荣誉，什么青春，什么自由，都摆在这位手持诗笛的可爱客人面前。 她来了！她撩开披巾，仔细看了看我。我对她说：“是你给但丁口授了地狱篇？”她回答：“是我。” 致缪斯","text":"缪斯深夜，我等着她的来临，好像我的生命十分危险。什么荣誉，什么青春，什么自由，都摆在这位手持诗笛的可爱客人面前。 她来了！她撩开披巾，仔细看了看我。我对她说：“是你给但丁口授了地狱篇？”她回答：“是我。” 致缪斯缪斯姐姐望了我一眼，她的目光清澈又晶莹。她还夺走了我的金戒指，我的第一件春日的礼品。 缪斯！你看世人是多么幸福——无论是少女、少妇，还是寡妇……我宁愿在尘寰中死去，也强似遭受这种幸福的桎梏。 尽管我也会去采撷那一朵稚嫩的雏菊；但在这人世间我命定要忍受每一次失恋的痛苦。 伴着窗前的烛光燃到清晨，我内心并不思念任何人，我并不想、并不想、并不想知道世人怎样把别的少女亲吻。 明天的镜子面前，我将受到嘲讽：“你的目光既不清澈，又不晶莹……”那我要轻声地回答：“是缪斯夺去了上帝赐予的礼品。” 没有英雄人物的叙事诗null 黄昏null 北方哀歌根本没有玫瑰色的童年……没有雀斑、没有小熊、没有玩具，没有慈祥的姑姑，也没可怕的叔叔，甚至小河碎石中间也没有朋友。我从小就觉得自己是某人的梦，某人的呓语，或者是某人镜中的身影，没有名字，没有血肉，没有发生过什么事情，我已经晓得了我应当犯的种种罪行。于是我，像梦游者迈动脚步，踏入人生，使人生为之一怔：它在我面前变成草原一片，成了当年普罗塞尔平娜在这儿散步的地方，两扇大门突然在我这个无亲无故、笨手笨脚的人的面前敞开，人们从门里走了出来，口中喊道：“她来了，她本人来了！”我惊奇地望着他们，心里想：“他们疯了！”他们越是赞美我，越是夸奖我，我就越觉得在世界上生活可怕，我就越想从梦中苏醒过来。我知道，像我这样的人，在牢房里，在坟墓中，在疯人院，在一切应当觉醒的地方，应付出百倍代价，可是却长期忍受着幸福的煎熬。 这里，我们全是酒鬼和荡妇，我们在一起多么郁闷！连壁画上的鲜花和小鸟也在思念流动的云彩。 你抽着一管黑色的烟斗，缭绕的烟雾那样神奇。我穿着狭窄的衬裙，让身材显得更加俏丽。 几扇小窗永远被钉死，是担心雾淞，抑或是雷电？你那机敏的眼睛如同一对警惕的猫眼。 啊，我的心多么忧伤！莫非在等待死期的来临？那个如今正在跳舞的女人，她命中注定要下地狱。 在人们的亲近中存在隐秘的界限，爱慕和激情也不能将它跨越，――哪怕嘴唇在不安的寂静里相互融合，哪怕心灵由于爱情而一片片碎裂。 友谊在此软弱无力，崇高与炽热的幸福填充了岁月，灵魂是自由的，不懂得情欲那迟缓的慵懒。 它的追求者丧失理智，而它的占有者却因此苦恼不堪……如今，你该明白，为什么我的心脏不在你的手掌下跳动。","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"俄罗斯","slug":"俄罗斯","permalink":"https://beefyheisenberg.github.io/tags/俄罗斯/"},{"name":"苏联","slug":"苏联","permalink":"https://beefyheisenberg.github.io/tags/苏联/"},{"name":"诗歌","slug":"诗歌","permalink":"https://beefyheisenberg.github.io/tags/诗歌/"}]},{"title":"R01.安魂曲","slug":"64.Novel-and-Poesy/R01.安魂曲","date":"2024-01-24T01:27:54.078Z","updated":"2024-01-24T01:27:54.079Z","comments":true,"path":"64.Novel-and-Poesy/R01.安魂曲/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/R01.安魂曲/","excerpt":"《安魂曲》是俄罗斯诗人阿赫玛托娃的作品。这首由十四首小诗组成的抒情长诗，是女诗人一生中最重要的作品之一，同时也是苏联诗歌史上不可多得的杰作之一。女诗人借这首长诗是在未曾平反的岁月里为悼念那些在30年代肃反扩大化中被冤屈而死的所有无辜者。 @ref https://baike.baidu.com/item/%E5%AE%89%E9%AD%82%E6%9B%B2/1664156 献 词 在这哀痛面前高山会低头，滔滔的江水也会静止不流，但重重牢门依然紧紧地关闭，门后是“苦役犯阴暗的炕头”，还有那致人死命的哀愁。和风究竟为谁轻轻吹拂，夕阳究竟给谁舒开眉头——对此我们概不知晓，我们到处听见的声音只是钥匙在门锁上刺耳的转动，还有士兵的皮靴声声沉重。我们像赶晨祷一样早起，穿过变得野性的都城，在那儿聚集，比死人还缺乏生气，太阳低低，涅瓦河雾气濛濛，然而希望却在远方歌唱。宣告判决……当即泪水夺眶，我已经远离了一切人，仿佛有一种挖心般的剧痛，仿佛是被粗野地推倒在地，可依然前行……步履蹒跚……孤孤单单。在那两年险恶时光中的女难友们，如今又都流落在何处何方？她们有什么幻觉，在那西伯利亚的暴风雪中？她们又仿佛看到了什么，在那月亮圆圆的时候？我把惜别的情意送到她们心头。 （1940.3.）","text":"《安魂曲》是俄罗斯诗人阿赫玛托娃的作品。这首由十四首小诗组成的抒情长诗，是女诗人一生中最重要的作品之一，同时也是苏联诗歌史上不可多得的杰作之一。女诗人借这首长诗是在未曾平反的岁月里为悼念那些在30年代肃反扩大化中被冤屈而死的所有无辜者。 @ref https://baike.baidu.com/item/%E5%AE%89%E9%AD%82%E6%9B%B2/1664156 献 词 在这哀痛面前高山会低头，滔滔的江水也会静止不流，但重重牢门依然紧紧地关闭，门后是“苦役犯阴暗的炕头”，还有那致人死命的哀愁。和风究竟为谁轻轻吹拂，夕阳究竟给谁舒开眉头——对此我们概不知晓，我们到处听见的声音只是钥匙在门锁上刺耳的转动，还有士兵的皮靴声声沉重。我们像赶晨祷一样早起，穿过变得野性的都城，在那儿聚集，比死人还缺乏生气，太阳低低，涅瓦河雾气濛濛，然而希望却在远方歌唱。宣告判决……当即泪水夺眶，我已经远离了一切人，仿佛有一种挖心般的剧痛，仿佛是被粗野地推倒在地，可依然前行……步履蹒跚……孤孤单单。在那两年险恶时光中的女难友们，如今又都流落在何处何方？她们有什么幻觉，在那西伯利亚的暴风雪中？她们又仿佛看到了什么，在那月亮圆圆的时候？我把惜别的情意送到她们心头。 （1940.3.） 序曲 这事情发生的时候，唯有死人才会高兴，高兴他获得了安宁。列宁格勒像多余的废物，在自己的监狱周围彷徨，被判罪的人走着，成队成行，苦难的折磨使他们神情癫狂，火车的汽笛短促地把离情别绪吟唱。在沾满鲜血的皮靴下，在囚车黑色的轮胎下，无辜的罗斯在痛苦挣扎，死亡的星辰高悬在我们头上。 你被带走正是黎明时分，我跟在你的身后，像送殡一样。小儿女在狭窄的房内啼哭，神龛前是一支滴泪的烛光。圣像在你双唇上留下一丝凉意，临终的冷汗在你的额角上流淌……不能忘啊不能忘！——我要像弓箭手的妻子那样，哭倒在克里姆林塔楼之旁。 （1935.秋.莫斯科） 静静的顿河静静地流，昏黄的月色照入楼。 昏黄的月色歪戴着帽，走进屋来照见人身影。 这个女人身染疾病，这个女人孤苦伶仃。 丈夫已去儿入狱，请为我祈祷上帝。 不，这并不是我，这是受苦受难的另一个。假如是我怎能忍受，那简直是祸从天落，让黑色的呢绒将它遮住，让人们拿走所有的灯火……只留下茫茫夜色。 你是爱取笑别人的人，你是所有朋友的宠儿，你是皇村开心的犯戒者，如今要让你明白，你一生的境遇又将如何——你要站在克列斯特铁窗旁边，排在三百号，手托探监的物品，滴下你滚滚的热泪，烤化新年的冰层。像监狱的那株白杨摇曳，无声无息——而大墙里有多少无辜的生命在死去…… （1938） 我高声哀号十七个月，千呼万唤你回家，我匍伏在刽子手的脚下，我的儿子啊，你使我担惊受怕。一切似乎都永远黑白颠倒，现在我已无法分得一点不差，谁个是人，谁个是兽，死刑究竟还要等待多久。只有摇炉散香之声，还有鲜花团团簇簇，脚印一个又一个，伸向某个茫然不知的去处。一颗巨大的星星以行将毁灭相威胁直眉瞪眼地把我看住。 （1939） 一周一周轻轻掠过。发生了什么，总是一片迷茫，儿子啊，他们日夜盯着你如何进入牢房，他们又以怎样的凶恶目光像鹰隼一样把你张望。说着你那高高的十字架，议论着你的死亡。 （1939.春.） 判决 巨石般的词句压向我一息尚存的胸膛，没什么，我已经有了准备，无论怎样我都能承当。今天我有很多事要做，我要让记忆断根绝蒂，我要使心灵变成石头，我要把生活重新学习。可是……夏日炎炎的噪音，好像过节在我窗前声声不断。我早已预感会有这晴朗的一天，和那空空荡荡的房间。 （1934.夏.喷泉居） 致死神 你迟早要来——为何不是现在？我非常艰难地将你等待。我熄灯灭火为你把门敞开，你是如此普通，又是这般奇怪。随便你采用什么形式进来，是像一枚浸过毒汁的炮弹落下，或是像手持哑铃的惯匪偷偷地进来，或是化作伤寒的烟雾散开。还是带着熟悉到令人恶心的你编造出来的谎言——让我在天蓝色的帽子上方看见房管员那吓得苍白的脸。如今这一切对我都无所谓。叶尼塞河波涛滚滚，北极星亮光熠熠。心爱者双眸中那蓝色的火花遮蔽住最后的畏惧。 （1939.8.19.喷泉居） 疯狂已用一侧翅膀把心灵的一半遮住，灌我以灼热的酒浆招引我走向黑色的深谷。 我心中非常清楚我该把胜利让给它，倾听着自己的呓语，似乎是他人的胡话。 （无论我如何哀求，不管我怎样恳求）它也不肯点头应允我把任何东西带走：无论是儿子恐惧的眼神——那麻木不仁的痛苦，还是那雷雨临头的日子，和那监狱相会的时候。无论是亲爱者双手留下的凉意，无论是那动人心弦的菩提树荫，还是那最后慰藉的话语——从远方传来的轻微声音。 （1940.5.4.） 钉十字架 “母亲，不要为我哭泣，我还呆在棺材里。” I 天使高歌赞颂伟大的时刻，而苍穹却溶化在烈火之中。我对父亲说：“为什么把我遗弃！”而对母亲说：“啊，不要为我哭泣……” II 马格达利娜捶胸痛哭， 心爱的门徒化作了石头， 而母亲默默伫立的地方， 却无人敢把目光相投。 尾声 I 我知道，我的容颜是怎样的消瘦，眼睑下闪现着何等的惊忧，痛苦是如何在双颊上描绘出粗硬的楔形纹皱，满头浅灰色和浓黑色的卷发如何突然变得白发满头，微笑在柔顺的双唇上枯萎，恐惧之情在干笑声中颤抖。我不是只为我一个人祈祷，而是为了所有的那些人们，他们同我一起站在耀眼的红墙下，无论是冬日的严寒还是七月的酷暑。 II 举哀的时刻又已临近。我看着，听着，感觉着你们： 既有那位被人扶到窗口的女人，也有那位不能踏上故土的女性， 还有那位摇着头的女子是多么美丽，她曾经说过：“来这就像回到家里。” 我本想把她们的名字一一说出。无奈名单已被夺去，无从得悉。 我为她们织就一块宽大的裹尸布，用偷偷听到的她们的只言片语。 我随时随地都把她们回忆，哪怕新的灾难临头也不会忘记， 即使我历尽磨难的嘴被堵住，亿万人民也会用我的呼喊抗议， 在我命丧黄泉之日的前夕，就让他们对我这样致悼念之意。 如果有朝一日在这个国家里，有人想为我把纪念碑竖立， 但只有在这样一个条件之下，我同意以此来纪念胜利—— 不要立在我出生的海边，我与大海已经断绝联系， 不要立在皇村花园朝思暮想的树桩旁，因为令人心碎的影子在那里把我寻觅， 把它立在我站过三百小时的地方，在那里门栓从来不曾为我开启。 因为在获得解脱的死亡之中，我害怕会把黑色囚车的嘶鸣忘记。 我害怕忘却那令人可憎的牢门关闭声，和那老妇人如负伤野兽般的哀泣。 要让那不会转动的青铜眼帘，流下溶化的雪水，像泪水滴滴， 让监狱的鸽子到远方去飞翔，让船只在涅瓦河上静静地游弋。 （1940.3.） 解析豆瓣地址安魂曲 (豆瓣) @link: R02.阿赫玛托娃","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"俄罗斯","slug":"俄罗斯","permalink":"https://beefyheisenberg.github.io/tags/俄罗斯/"},{"name":"苏联","slug":"苏联","permalink":"https://beefyheisenberg.github.io/tags/苏联/"},{"name":"诗歌","slug":"诗歌","permalink":"https://beefyheisenberg.github.io/tags/诗歌/"}]},{"title":"魔兽世界系列","slug":"64.Novel-and-Poesy/G01.魔兽世界系列","date":"2024-01-24T01:27:54.072Z","updated":"2024-01-24T01:27:54.074Z","comments":true,"path":"64.Novel-and-Poesy/G01.魔兽世界系列/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/G01.魔兽世界系列/","excerpt":"《最后的守护者》 最后的守护者原著:Jeff Grubb 翻译:麦德三世(主要翻译) 第一章 卡拉赞最后他们到了卡德加的住处。这里离那个宴会厅不是很远。“自己收拾一下吧，”摩洛斯 把手上的灯笼递给卡德加，“厕所在最里面。床下有个夜壶。好了以后到下面的厨房来一趟。 库克会给你热点菜的。”","text":"《最后的守护者》 最后的守护者原著:Jeff Grubb 翻译:麦德三世(主要翻译) 第一章 卡拉赞最后他们到了卡德加的住处。这里离那个宴会厅不是很远。“自己收拾一下吧，”摩洛斯 把手上的灯笼递给卡德加，“厕所在最里面。床下有个夜壶。好了以后到下面的厨房来一趟。 库克会给你热点菜的。” 卡德加的房间是契形的，更适合做修道院僧侣的悔过室(小黑屋 )而不是法师的。一边 墙边靠着一个狭窄的床，对面墙边则靠着一个同样狭窄的桌子，桌上有个空架子。另有一间 用来放东西的壁橱。卡德加都没打开自己的背包，直接将其扔进了壁橱，然后踱到同样奉行苗条主义的窗边。 窗户是镶铅条细薄玻璃，架在正中的转轴上。卡德加缓缓地推开半边窗，窗底凝固的润滑油像软泥一样被扯开。 这里的视点依然处于塔上非常高的位置，在双月的照耀下，塔周围的群山显得灰暗和裸露。从这个高度望出去，卡德加发现这里以前显然是座巨大的环形山，由于一直受到岁月的风化才变成如今这样。难道说某座大山被人从此地像拔蛀牙一样拔走了?还是因为周围的山生长太快，而中间的山几乎不生长，结果留下怎么一块神奇的地方? 卡德加怀疑麦迪文的母亲从太古时代就呆在这里了，亲眼看着大陆的升起、沉没，或是甚至经历过开天辟地。即使是以一个法师的标准来说，八百年也太长太长了。即便是活两百年，按教科书上所说，大部分的人类法师也都已经虚弱得像张薄纸一样，一碰就死了。七百五十五岁然后还生了个孩子!卡德加摇了摇自己的脑袋，怀疑麦迪文是不是在耍他? 卡德加脱下他的旅行斗篷，然后看了那间“最里面”的设施— —它们都很朴素。但还是有一大缸冷水、一个脸盆和一面失去了光泽的优质镜子。卡德加想试着用一个镜面法术来加 热那些水，不过最后还是决定由它去。 缸里的水质不错，卡德加换了套干净点的衣服后觉得舒服多了——一件舒适的及膝衬衫和一条健身裤。差不多可以动身了。他从行包里拿出一把小型餐刀 ，考虑了一会儿，将其塞入了一边靴筒里。 他回到走廊，才想起自己并不知道厨房在哪。兽栏那边好像不出产食物，因此厨房肯定是安排在塔里的。很可能在底层或者一二层，以便于用泵汲水。而且一定要很容易到达宴会厅，就算这个宴会厅可能不常用。 卡德加轻易的就摸索到了回到宴会厅楼座的路，但是他还得找到自己想象中的那个七歪八拐通往厨房的楼梯。于是他就得在宴会厅的数个出口中作出选择。卡德加选了看起来最有可能的一个，结果发现是条死路——只有一条走廊，末端就是一个没其它出口的空屋，和他 自己那间很像。他又选了一条路，结果类似。 第三次选择将这个年轻人带入了一场的战斗的中心地带。","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"小说摘录","slug":"小说摘录","permalink":"https://beefyheisenberg.github.io/tags/小说摘录/"},{"name":"魔兽世界","slug":"魔兽世界","permalink":"https://beefyheisenberg.github.io/tags/魔兽世界/"},{"name":"游戏","slug":"游戏","permalink":"https://beefyheisenberg.github.io/tags/游戏/"}]},{"title":"F03.加缪札记","slug":"64.Novel-and-Poesy/F03.加缪札记","date":"2024-01-24T01:27:54.068Z","updated":"2024-01-24T01:27:54.068Z","comments":true,"path":"64.Novel-and-Poesy/F03.加缪札记/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/F03.加缪札记/","excerpt":"《Carnets》, 1935-1951What gives value to travel is fear. It is the fact that, at a certain moment, when we are so far from our own country … we are seized by a vague fear, and an instinctive desire to go back to the protection of old habits … this is why we should not say that we travel for pleasure. There is no pleasure in traveling, and I look upon it more as an occasion for spiritual testing … Pleasure takes us away from ourselves in the same way as distraction, in Pascal’s use of the word, takes us away from God. Travel, which is like a greater and a graver science, brings us back to ourselves. 译：旅行中最有价值的部分是恐惧。旅行者远离了家乡，一种模糊的恐惧感随之而来，他本能的渴望旧环境。正是在恐惧中，你变得敏感，外界的轻微的变动都令你颤抖不已，你的内心再度充满疑问，要探询自身存在的意义。人类的所有知识、情感、精神世界，不都因这追问而起？ https://www.goodreads.com/quotes/898728-what-gives-value-to-travel-is-fear-it-is-the 关于本书","text":"《Carnets》, 1935-1951What gives value to travel is fear. It is the fact that, at a certain moment, when we are so far from our own country … we are seized by a vague fear, and an instinctive desire to go back to the protection of old habits … this is why we should not say that we travel for pleasure. There is no pleasure in traveling, and I look upon it more as an occasion for spiritual testing … Pleasure takes us away from ourselves in the same way as distraction, in Pascal’s use of the word, takes us away from God. Travel, which is like a greater and a graver science, brings us back to ourselves. 译：旅行中最有价值的部分是恐惧。旅行者远离了家乡，一种模糊的恐惧感随之而来，他本能的渴望旧环境。正是在恐惧中，你变得敏感，外界的轻微的变动都令你颤抖不已，你的内心再度充满疑问，要探询自身存在的意义。人类的所有知识、情感、精神世界，不都因这追问而起？ https://www.goodreads.com/quotes/898728-what-gives-value-to-travel-is-fear-it-is-the 关于本书国内版本卡繆札記. III (豆瓣)/ 黄馨慧译： 《卡謬札記》分為三卷，是1935年5月至1959年12月卡謬親自撰寫的最後書信、札記、隨筆，是了解世紀大師的經典代表作。 第一卷是卡繆自一九三五年五月至一九四二年二月的札記，是了解卡繆其人和思想不可或缺的典籍，也是理解其作品的重要關鍵，他在札記中寫下他的讀書雜感以及寫作構思的方式，其中有動人的哲學的思維。 《卡繆札記》的前二卷（一九三五－一九五一）在作者去世後不久即出版。但當年還有未曝光的筆記，正是第三卷的內容。 第三卷可看到《夏天》、《墮落》和《放逐與王國》的源起。我們也看到了作者對《反抗者》所掀起的激烈論戰如何反應。還有許多關於數個未及完成的寫作計畫：譬如一個寫茱莉‧萊比納斯的劇本，或是一個將浮士德和唐璜兩主題合而為一的劇本，當然，更有他已著手進行的《第一個人》。 卡繆在最後這幾本筆記中，較諸之前筆記寫下了更多他私人生活中的重要事件：希臘旅行、阿爾及利亞戰爭之慘烈，獲諾貝爾獎。這些筆記剛開始只是卡繆的寫作工具，到後來卻更像是他的日記。","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"加缪","slug":"加缪","permalink":"https://beefyheisenberg.github.io/tags/加缪/"},{"name":"小说摘录","slug":"小说摘录","permalink":"https://beefyheisenberg.github.io/tags/小说摘录/"},{"name":"法国","slug":"法国","permalink":"https://beefyheisenberg.github.io/tags/法国/"}]},{"title":"F02.夏天集","slug":"64.Novel-and-Poesy/F02.夏天集","date":"2024-01-24T01:27:54.063Z","updated":"2024-01-24T01:27:54.063Z","comments":true,"path":"64.Novel-and-Poesy/F02.夏天集/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/F02.夏天集/","excerpt":"《蒂巴萨的婚礼》《Noces à Tipasa》1936 - 19371 走了几步，苦艾的气味就呛得我们喉咙难受。他那灰色的绒毛盖满了无际的废墟。它的精华在热气中蒸腾，从地上到天上弥漫着一片慷慨的酒气，天都为之摇晃了。我们迎着爱情和欲望走去。我们不寻求什么教训，也不寻求人们向伟大所要求的那种苦涩的哲学。阳光之外，亲吻之外，原野的香气之外，一切对我们来说都微不足道。 对于我，我不想一个人独自来到这里。我经常和我喜欢的那些人一起来，我在他们脸上看到了明媚的微笑。这里，我把秩序和节制留给别人去说。这是自然的大放纵，这是大海的大放纵，我整个儿地被抓住了。 我在这里明白了什么是光荣，那就是无节制的爱的权利。在这个世界上只有一种爱情。抱紧一个女人的躯体，这也是把从天空降下的大海的那种奇特的快乐留在自己身上。刚才，当我想扑向一丛苦艾，让它的芬芳进入我的身体时，我应该不顾一切偏见地意识到，我正在完成一桩真理，这既是太阳的真理，也是我的死亡的真理。从某种意义上说，我在这里玩耍的，正是我的生命，这生命散发着火热的石头的气味，充满了大海和刚刚开始鸣叫的蝉的叹息。","text":"《蒂巴萨的婚礼》《Noces à Tipasa》1936 - 19371 走了几步，苦艾的气味就呛得我们喉咙难受。他那灰色的绒毛盖满了无际的废墟。它的精华在热气中蒸腾，从地上到天上弥漫着一片慷慨的酒气，天都为之摇晃了。我们迎着爱情和欲望走去。我们不寻求什么教训，也不寻求人们向伟大所要求的那种苦涩的哲学。阳光之外，亲吻之外，原野的香气之外，一切对我们来说都微不足道。 对于我，我不想一个人独自来到这里。我经常和我喜欢的那些人一起来，我在他们脸上看到了明媚的微笑。这里，我把秩序和节制留给别人去说。这是自然的大放纵，这是大海的大放纵，我整个儿地被抓住了。 我在这里明白了什么是光荣，那就是无节制的爱的权利。在这个世界上只有一种爱情。抱紧一个女人的躯体，这也是把从天空降下的大海的那种奇特的快乐留在自己身上。刚才，当我想扑向一丛苦艾，让它的芬芳进入我的身体时，我应该不顾一切偏见地意识到，我正在完成一桩真理，这既是太阳的真理，也是我的死亡的真理。从某种意义上说，我在这里玩耍的，正是我的生命，这生命散发着火热的石头的气味，充满了大海和刚刚开始鸣叫的蝉的叹息。 《重返蒂巴萨》《Retour à Tipasa》19592 正午，我站在半沙半土的山坡上，望着大海。山坡上长满了天芥菜，那一片片的天芥菜，仿佛近几个月激浪退下时留下的水沫。大海这时已筋疲力尽，翻腾不动了。我消除了两种干渴，这两种干渴是不能长久欺骗的，除非一个人变得冷酷无情。这两种干渴就是美和赞叹。因为惟有不被爱才是厄运，惟有不爱才是不幸。今天，我们大家都死于这种不幸；因为鲜血和仇恨使心失去血肉，对于正义的长久要求耗尽了爱，而正义却恰恰产生于爱。我们生活在喧嚣中，在这喧嚣中，爱是不可能的，而只有正义也是不够的；因此，欧洲憎恨白昼，只知道给自己以不义。但是，为了不使正义变得萎缩，变成一枚果肉干而涩的橙子，我在蒂巴萨重新认识到，必须在自己身上保留一种新鲜和一股快乐的源泉，使之不受污损，必须钟爱逃脱了不义的白昼，必须怀着这种争得来的光明投入战斗。我在这里重新发现了过去的美和一片年轻的天空，我掂量着我的运气，终于明白了，在我们的疯狂肆虐的那些年里，对于这一片天空的回忆从未离开过我。是这回忆最终使我不绝望。我一直清楚蒂巴萨的废墟比我们的工地和瓦砾都年轻。在这里，世界每天都在一片常新的光明中重新开始。啊，光明！这是古代戏剧中所有人物面对着命运发出的呼喊。这最后的依靠也是我们的依靠，我现在明白了。在隆冬，我终于知道了，我身上有一个不可战胜的夏天。 1.https://fr.wikipedia.org/wiki/Noces_(Albert_Camus) ↩2.https://www.arts.chula.ac.th/doc/pr/2.pdf ↩","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"加缪","slug":"加缪","permalink":"https://beefyheisenberg.github.io/tags/加缪/"},{"name":"小说摘录","slug":"小说摘录","permalink":"https://beefyheisenberg.github.io/tags/小说摘录/"},{"name":"法国","slug":"法国","permalink":"https://beefyheisenberg.github.io/tags/法国/"}]},{"title":"F01.西西弗神话","slug":"64.Novel-and-Poesy/F01.西西弗神话","date":"2024-01-24T01:27:54.057Z","updated":"2024-01-24T01:27:54.057Z","comments":true,"path":"64.Novel-and-Poesy/F01.西西弗神话/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/F01.西西弗神话/","excerpt":"","text":"真正严肃的哲学问题只有一个，那便是自杀。判断人生值不值得活，等于回答哲学的根本问题。 西西弗斯告诉我们，最高的虔诚是否认诸神并且搬动石头，他也认为一切都是美好的。这个从此没有主宰的世界对她来讲既不是荒漠，也不是沃土。这块巨石上的每一颗粒，这黑夜笼罩的高山上的每一颗矿砂对西西弗斯一人都是一个世界。他爬上山顶的斗争本身就足以使一个人心里感到充实。应该认为，西西弗斯是幸福的。","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"加缪","slug":"加缪","permalink":"https://beefyheisenberg.github.io/tags/加缪/"},{"name":"小说摘录","slug":"小说摘录","permalink":"https://beefyheisenberg.github.io/tags/小说摘录/"},{"name":"法国","slug":"法国","permalink":"https://beefyheisenberg.github.io/tags/法国/"}]},{"title":"D02.里尔克诗选","slug":"64.Novel-and-Poesy/D02.里尔克诗选","date":"2024-01-24T01:27:54.053Z","updated":"2024-01-24T01:27:54.053Z","comments":true,"path":"64.Novel-and-Poesy/D02.里尔克诗选/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/D02.里尔克诗选/","excerpt":"杜伊诺哀歌 (豆瓣) 《Duino Elegies》第一首哀歌1912年起稿于杜伊诺城堡，经历长久的等待之后，在1922年的穆佐城堡，里尔克于八天之内完成了整部诗集。十首哀歌构成了一个整体，直观合而为一的生与死。诗人本人称《杜伊诺哀歌》是“奇迹”和“恩典”。 《哀歌之一》","text":"杜伊诺哀歌 (豆瓣) 《Duino Elegies》第一首哀歌1912年起稿于杜伊诺城堡，经历长久的等待之后，在1922年的穆佐城堡，里尔克于八天之内完成了整部诗集。十首哀歌构成了一个整体，直观合而为一的生与死。诗人本人称《杜伊诺哀歌》是“奇迹”和“恩典”。 《哀歌之一》如果我叫喊，谁将在天使的序列中听到我？即使他们之中有一位突然把我拥到他胸前，我也将在他那更强大的存在的力量中消失。因为美不是什么而是我们刚好可以承受的恐怖的开始，而我们之所以这样赞许它是因为它安详地不屑于毁灭我们。每一位天使都是可怕的。因此我抑制自己，吞下深处黑暗的呜咽的叫声。啊，我们需要时可以求助于谁？不是天使，不是人；就连那些知道的野兽也意识到在这个被解释的世界我们并不感到很安全。也许仍有某棵树留在斜坡上，供我们日夜观看，仍有为我们留下的昨天的散步和对于一个习惯的长期效忠，这习惯一旦跟我们住下便不愿离开。哦，还有黑夜，那黑夜，当一阵充满无限空间的风啃起我们的脸。黑夜为了谁而不留下——这想望已久的、温和的、不报幻想的存在，这颗孤寂的心与它相会是如此痛苦。难道情人们就更容易些吗？但是他们继续利用彼此来隐藏各自的命运。难道你还不知道吗？将你怀中的虚空抛进我们呼吸的空间；也许鸟儿们会带着更热情的飞翔感到这扩大的空气。","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"诗歌","slug":"诗歌","permalink":"https://beefyheisenberg.github.io/tags/诗歌/"},{"name":"里尔克","slug":"里尔克","permalink":"https://beefyheisenberg.github.io/tags/里尔克/"}]},{"title":"D01.给青年诗人的信","slug":"64.Novel-and-Poesy/D01.给青年诗人的信","date":"2024-01-24T01:27:54.048Z","updated":"2024-01-24T01:27:54.049Z","comments":true,"path":"64.Novel-and-Poesy/D01.给青年诗人的信/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/D01.给青年诗人的信/","excerpt":"1902年，青年卡卜斯就读于维也纳新城陆军学校，还未满二十岁，他已经感受到了职业带来的压力。像任何一个处在人生转折时期的年轻人一样，卡卜斯对于未来的人生充满疑虑，而眼下更要紧的，是如何处理职业道路与个人意趣之间的矛盾。在私人生活中，他爱好读书，也尝试写作，一次偶然的机会，他了解到自己所喜爱的诗人里尔克年轻时也有过一段和自己相似的遭遇——在陆军学校读书，喜欢寂寞，忍受着宿舍生活的压抑……而如今，他已经是一名成熟的诗人，这让卡布斯倍感宽慰。他立即决定把自己的诗寄给里尔克看，同时附上一封信，向前辈坦言自己内心的动荡。 很快，卡卜斯收到了回信。此后的五年间，二人持续保持着通讯，在一来一往的信件中，里尔克不仅对创作和诗艺提出了深度的见解，对于文学领域之外一切与人生有关的话题，他也毫无保留地向这位身处困顿中的青年人告知自身的经验，希望他能够更加耐心地对待成长中的苦闷，追求生活的真意。里尔克或许未曾想过，这些信件会在日后集结成册，传递给一代又一代的青年人。如今，《给青年诗人的十封信》已是世界范围内的经典之作，它所面对的受众远不只是渴望成为诗人的青年，而是所有徘徊在审美、信仰、寂寞、爱与真理的边缘，尚未将深度和意义赋予生活的人们。 第四封信这里周围是伟大的田野，从海上吹来阵阵的风，这里我觉得，那些问题与情感在它们的深处自有它们本来的生命，没有人能够给你解答；因为就是最好的字句也要失去真意，如果它们要解释那最轻妙、几乎不可言说的事物。 …","text":"1902年，青年卡卜斯就读于维也纳新城陆军学校，还未满二十岁，他已经感受到了职业带来的压力。像任何一个处在人生转折时期的年轻人一样，卡卜斯对于未来的人生充满疑虑，而眼下更要紧的，是如何处理职业道路与个人意趣之间的矛盾。在私人生活中，他爱好读书，也尝试写作，一次偶然的机会，他了解到自己所喜爱的诗人里尔克年轻时也有过一段和自己相似的遭遇——在陆军学校读书，喜欢寂寞，忍受着宿舍生活的压抑……而如今，他已经是一名成熟的诗人，这让卡布斯倍感宽慰。他立即决定把自己的诗寄给里尔克看，同时附上一封信，向前辈坦言自己内心的动荡。 很快，卡卜斯收到了回信。此后的五年间，二人持续保持着通讯，在一来一往的信件中，里尔克不仅对创作和诗艺提出了深度的见解，对于文学领域之外一切与人生有关的话题，他也毫无保留地向这位身处困顿中的青年人告知自身的经验，希望他能够更加耐心地对待成长中的苦闷，追求生活的真意。里尔克或许未曾想过，这些信件会在日后集结成册，传递给一代又一代的青年人。如今，《给青年诗人的十封信》已是世界范围内的经典之作，它所面对的受众远不只是渴望成为诗人的青年，而是所有徘徊在审美、信仰、寂寞、爱与真理的边缘，尚未将深度和意义赋予生活的人们。 第四封信这里周围是伟大的田野，从海上吹来阵阵的风，这里我觉得，那些问题与情感在它们的深处自有它们本来的生命，没有人能够给你解答；因为就是最好的字句也要失去真意，如果它们要解释那最轻妙、几乎不可言说的事物。 … 身体的快感是一种官感的体验，与净洁的观赏或是一个甜美的果实放在我们舌上的净洁的感觉没有什么不同；它是我们所应得的丰富而无穷的经验，是一种对于世界的领悟，是一切领悟的丰富与光华。 我们感受身体的快感并不是坏事；所不好的是：几乎一切人都错用了、浪费了这种经验，把它放在生活疲倦的地方当作刺激，当作疏散，而不当作向着顶点的聚精会神。就是饮食，也有许多人使之失去本意：一方面是“不足”，另一方面是“过度”，都搅浑了这个需要的明朗；同样搅混的，是那些生命借以自新的一切深的、单纯的需要。","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"诗歌","slug":"诗歌","permalink":"https://beefyheisenberg.github.io/tags/诗歌/"},{"name":"里尔克","slug":"里尔克","permalink":"https://beefyheisenberg.github.io/tags/里尔克/"}]},{"title":"C14.动物凶猛","slug":"64.Novel-and-Poesy/C14.动物凶猛","date":"2024-01-24T01:27:54.044Z","updated":"2024-01-24T01:27:54.044Z","comments":true,"path":"64.Novel-and-Poesy/C14.动物凶猛/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/C14.动物凶猛/","excerpt":"","text":"我羡慕那些来自乡村的孩子，他们的记忆里总有一个回味无穷的故乡，尽管这故乡其实可能是个贫困凋敝毫无诗意的僻壤，但只要他们乐意，便可以尽情地遐想自己丢失殆尽的某些东西仍可靠地寄存在那个一无所知的故乡，从而自我原宥和自我慰藉。 那时侯，好像永远是夏天，太阳总是有空出来伴随着我，阳光充足，太亮，使得眼前一阵阵发黑。","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"小说摘录","slug":"小说摘录","permalink":"https://beefyheisenberg.github.io/tags/小说摘录/"}]},{"title":"C13.现代诗","slug":"64.Novel-and-Poesy/C13.现代诗","date":"2024-01-24T01:27:54.039Z","updated":"2024-01-24T01:27:54.040Z","comments":true,"path":"64.Novel-and-Poesy/C13.现代诗/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/C13.现代诗/","excerpt":"《镜中》只要想起一生中后悔的事梅花便落了下来比如看她游泳到河的另一岸比如登上一株松木梯子 危险的事固然美丽不如看她骑马归来面颊温暖，羞惭。低下头，回答着皇帝一面镜子永远等候她让她坐到镜中常坐的地方望着窗外，只要想起一生中后悔的事梅花便落满了南山 关于抑郁症的治疗现在，我只需把胸中的钝痛精细分辨命名、加注、锁入正确的屉格：哪些眼泪是为受苦的父亲而流，哪些为染霜的爱，又有哪些仅仅出于颤栗，为这永恒广漠、无动于衷的星星监狱里我们所有人的处境。假如每种精微的裂痛都能如烦恼于唯识宗，找到自己不偏不倚的位置如罪业于但丁的漏斗，它们将变得可以承受。","text":"《镜中》只要想起一生中后悔的事梅花便落了下来比如看她游泳到河的另一岸比如登上一株松木梯子 危险的事固然美丽不如看她骑马归来面颊温暖，羞惭。低下头，回答着皇帝一面镜子永远等候她让她坐到镜中常坐的地方望着窗外，只要想起一生中后悔的事梅花便落满了南山 关于抑郁症的治疗现在，我只需把胸中的钝痛精细分辨命名、加注、锁入正确的屉格：哪些眼泪是为受苦的父亲而流，哪些为染霜的爱，又有哪些仅仅出于颤栗，为这永恒广漠、无动于衷的星星监狱里我们所有人的处境。假如每种精微的裂痛都能如烦恼于唯识宗，找到自己不偏不倚的位置如罪业于但丁的漏斗，它们将变得可以承受。 每种我不屑、不愿、不能倾诉的苦痛都将郁结成棕色、橄榄色、水银色的香料在时光的圣水瓶里酝酿一种奇迹。修辞术在受难的心前隐遁无踪，言语尽是轻浮，假如不是为了自救铺陈不可饶恕。假如可以带粉笔进入迷宫，以纯蓝标记每一处通往灾祸的岔口：“我到过这儿必将永不再受诱”，它们将变得可以承受。 假如我尝过的每种汞与砷能使你免于读懂这首诗——它们将变得可以承受小病号。 灵泊灵泊寒冷，我知道。夏日末梢，我见到一名隐士隐士和他金红的狐狸獭白的猫，壁炉上涡旋的马蜂油亮的葫芦，扎人的蓑衣隐士的家中感觉不到寒冷我们坐在花园里饮酒被爬山虎吞噬的山墙不断落下生脆的枯叶，湿润的蜗壳，半截壁虎一只老鼠在近处翻检熟悉的宝物我们坐在花园中，直到秋日的苹果纷纷滚落我的肩头直到白葡萄失去麝香，梨失去她寒碜的红直到我成全预言只身落入灵泊好冷啊，这儿没有可以踩实的土让我种一棵酸枣，回旋的雾淞染蓝了一切，密密匝匝似负冲的水墨灵泊里没有奇行的巨人，狼的眼珠，蝙蝠的尖喙没有苦苦呼救的人，甚至没有灵魂受苦幽蓝的轻霾折叠着自身，掠过沙漠松针掠过雪原燃烧的褶皱，透视阻挠的云朵而它们也认了罪，跌下来，晒作罂粟壳，被踩扁发出崎岖的玻璃声；我光脚踏过云田脸在雨衣里涨得通红，我精确地踩了又踩身后是一畦装满鱼化石的脚印，我朝山阴走去看见老鼠匆匆把脸藏进蔓蓉树冠灵泊寒冷每个知道秘密的人都应该保持沉默。 布鲁斯我用左边肘窝想念巴黎，用肚脐，用盘突的脊柱用胛骨间柔软的凹陷，我用十二指肠想念巴黎我抵达前，巴黎是一船内脏缤纷的锦鲤我被逐后，她是一屋子尖刀，一罐动脉，一井手影我想念她的暴雨，当光之霰弹射向双偶咖啡馆的玻璃顶我想念她的午后，当坏人们掸着烟灰等待天堂开演，而我是最坏一个我想念她藤蔓的夜，当我被绞成浆果而时光成酒我要跪下舔她梦的钢弦我要晃动一只蔚蓝的小舟直到它载满淫棍，疯子和纵火犯要它痛饮塞纳河水直到桅杆上升，处决着鹳鸟，捣毁黄道的驿站为猎户座重新布棋，我用锁骨想念每列洞穿我的旧地铁我想念因为我被禁止诉说吗，像那些深深嵌入生命的麻绳碾磨出潋滟的碧玺，划出爱情一般空幻的光弧吗？我知道在巴黎，所有的庆典都绝不可逆，地狱只能再现一次在巴黎，爱神的名字在气球中浪笑，宇宙娼妇扔掉阉人的风镐，在穹顶卷刃，在月食圆心与日珥摔跤。 布鲁斯2 （天狼星）是谁吃了我的白日梦是你吗，天狼星——吞掉我的钢琴，啃断琴凳小腿，嘎吱嘎吱细嚼着白键，配三个黑键，活泼地怨诉地，嚼碎了爱欲的手指饼先要把琴谱舔湿，让它一页一页透明地映出南国薄荷园，深谙归途的雀鸟，轻盈滑水的独角仙然后伸出舌头，如歌地幽默地，环绕琴槌根部打圈你会看到那儿升起了蓝紫色星星，小小的古尔德扑捉着跌倒着，那笑脸你早看腻，对不对，天狼星？所以还要吞下我的弓，我的蜜蜡松香，我的GDAE还有指板，还有琴马，还有F孔下我曾用来填满自己的桃符和谶语，友谊和阴茎，航海图与竹蜻蜓我从没有像今天这么满，这么紧绷，这么含泪欲滴，请把我请把我一点不留地吃完吧！我的河童恋人发间怒生仙人球他不喜欢弦乐，不爱拿螳螂开玩笑，更痛恨艾瑞克·萨梯我们的孩子终夜下着蛇梯棋，像三只下楼梯的荧光梨悲怆地坚定地，向我习得落子无悔的本领我必须找到我的老花镜，找到壁炉里的鱼罐头这是他承诺的奖励。我用门牙撬罐头，庄严地生气勃勃地，渐强地，渐强地——这黑压压的蜂群是什么，莫非我释放了地狱？瞧你都干了什么，哦天狼星！！ 致未婚夫在半光的清晨，我睁开含雾的眼睛：白如极地的窗棂沙沙游走的4B铅笔—— 坐在地上、轻咬下唇的你，表情专注得让我害羞了。一千零一回，你笔端互为镜相的我微微启口，露出小圆牙齿，渴慕远方 眼中没有航标；手臂耷拉于床沿，折断的桅杆般伸向你：我知它凝白丰润，适合红麝串以及浮世春宫，一切易凋零而不可惜之事 被你的画框固定。我们从此各自把前尘扫除干净吗？旧相片、旧礼物，删订吻的蛛网编年史；说声“是”多么简单，惟它通向的 不止是婚姻。在半光的黄昏我栽下一株酸枣你在枝头点缀一捧翠鸟，无拘束点水滑翔的奥秘在禽类的脚胫，缕缕看不见的银丝线 深入酸枣树底，根茎与卷须疾涌的幽旅：时光总比地名、寓言总比写实可靠吗？当你噙下我口中的海盐 在我们半是雨水、半是帆影的新居里。 在托尔金墓前其实霍比特人和侏儒是你来不及装罐的手工蜂蜜对吧，养蜂人冷灼的清晨也挖空铜壶上歌唱的苹果，延宕他满有恩泽的噩梦 你溯回的香蕉船，泊在正被云朵拭去刻度的牛津运河的钟面，黄水仙在舱顶狎着炊烟石臼爱石杵，就入定成一酒窝青苔的弥勒像 在岸边，铁锈信箱含着铁锁，为你不定期的夜巡它已九次咬破了舌根；你的书架透过舷窗翻动我：几本洛布丛书，诗体《埃达》，古英语修辞字典 蜷成虫洞的泛黄地图，《奥菲爵士》的译稿摊开至奥菲离开安全树荫的那一页，地下王国的壁龛里瓶中胎儿且吞吐珠光：如果一间藏书室不能顺水漂流 瞪羚还会爱上松鼠吗？恐霉的不是怪兽与批评家而我从未醒着跟随你，穿过默顿学院叹息的黄墙平躺在安全的驳船，商议六分仪座的航向，此时索隆 也会是软心肠的臂状星云呢，在银河幽黯的齿缝间他汇拢所有结构稳固的星座，为一个灵光永不消逝咕噜也可安睡其中的圆圈；填补黑洞的精灵以三色堇 演绎圣三一，把它抛在墓石上，我的掌心渴望着荆棘：“贝伦，贝伦，”千万雪珠在墓穴里深沉而温柔地滚动“路西恩。”我假装聆听着宇宙中原谅一切的回声。 --2013. 4","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"诗歌","slug":"诗歌","permalink":"https://beefyheisenberg.github.io/tags/诗歌/"}]},{"title":"C12.贾樟柯电影手记","slug":"64.Novel-and-Poesy/C12.贾樟柯电影手记","date":"2024-01-24T01:27:54.035Z","updated":"2024-01-24T01:27:54.035Z","comments":true,"path":"64.Novel-and-Poesy/C12.贾樟柯电影手记/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/C12.贾樟柯电影手记/","excerpt":"陌生之地总会带给我精神的穿越：回到过去，去到未来。沉入地心，或飞向太空。短暂的出走会让我和自己固有的生活告别。离开熟悉的朋友，离开说来说去好多年的话题，离开自己的专业，离开自己深信不疑的精神系统……出走是自我叛逆的契机，让自己流动起来，悬浮起来，倒置起来，让自己颠覆自己。 窗外，夜幕将要降临北京，这座过于喧嚣的城市，无法迎接幽冷的月光。我突然想远行，乘着夜幕去到山西任意一个小城。那里城池千年，一定明月高挂。我知道我是想写东西了，在办公室找了一摞信纸，十几只用惯了的粗黑墨笔，决定到大同去。 每次旅行都能激活我的想象，灵感像是藏着的野性，你必须将自己放虎归山。","text":"陌生之地总会带给我精神的穿越：回到过去，去到未来。沉入地心，或飞向太空。短暂的出走会让我和自己固有的生活告别。离开熟悉的朋友，离开说来说去好多年的话题，离开自己的专业，离开自己深信不疑的精神系统……出走是自我叛逆的契机，让自己流动起来，悬浮起来，倒置起来，让自己颠覆自己。 窗外，夜幕将要降临北京，这座过于喧嚣的城市，无法迎接幽冷的月光。我突然想远行，乘着夜幕去到山西任意一个小城。那里城池千年，一定明月高挂。我知道我是想写东西了，在办公室找了一摞信纸，十几只用惯了的粗黑墨笔，决定到大同去。 每次旅行都能激活我的想象，灵感像是藏着的野性，你必须将自己放虎归山。 加缪对旅行的感受： F03.加缪札记 [[../62.Psychology/《存在主义心理治疗》读书笔记]] / 第三部《孤独》：“我们周围是一个由熟悉的事物和制度所构成的稳定世界，一个所有物体和个体都彼此多重连接的世界。我们被平静地诱导入一种熟悉的、亲切的归属感”","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"小说摘录","slug":"小说摘录","permalink":"https://beefyheisenberg.github.io/tags/小说摘录/"}]},{"title":"C11.我与地坛","slug":"64.Novel-and-Poesy/C11.我与地坛","date":"2024-01-24T01:27:54.030Z","updated":"2024-01-24T01:27:54.031Z","comments":true,"path":"64.Novel-and-Poesy/C11.我与地坛/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/C11.我与地坛/","excerpt":"","text":"它等待我出生，然后又等待我活到最狂妄的年龄上忽地残废了双腿。四百多年里，它一面剥蚀了古殿檐头浮夸的琉璃，淡褪了门壁上炫耀的朱红，坍圮了一段段高墙又散落了玉砌雕栏，祭坛四周的老柏树愈见苍幽，到处的野草荒藤也都茂盛得自在坦荡。这时候想必我是该来了。十五年前的一个下午，我摇着轮椅进入园中，它为一个失魂落魄的人把一切都准备好了。那时，太阳循着亘古不变的路途正越来越大，也越红。在满园弥漫的沉静光芒中，一个人更容易看到时间，并看见自己的身影。自从那个下午我无意中进了这园子，就再没长久地离开过它。我一下子就理解了它的意图。正如我在一篇小说中所说的：“在人口密聚的城市里，有这样一个宁静的去处，像是上帝的苦心安排。”","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"小说摘录","slug":"小说摘录","permalink":"https://beefyheisenberg.github.io/tags/小说摘录/"}]},{"title":"C10.陆文夫-美食家","slug":"64.Novel-and-Poesy/C10.陆文夫-美食家","date":"2024-01-24T01:27:54.026Z","updated":"2024-01-24T01:27:54.027Z","comments":true,"path":"64.Novel-and-Poesy/C10.陆文夫-美食家/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/C10.陆文夫-美食家/","excerpt":"美食家(1) 朱自冶起得很早，睡懒觉倒是与他无缘，因为他的肠胃到时便会蠕动，准确得和闹钟差不多。眼睛一睁，他的头脑里便跳出一个念头：“快到朱鸿兴去吃头汤面！”这句话需要作一点讲解，否则的话只有苏州人，或者是只有苏州的中老年人才懂，其余的人很难理解其中的诱惑力。 那时候，苏州有一家出名的面店叫作朱鸿兴，如今还开设在怡园的对面。至于朱鸿兴都有哪许多花式面点，如何美味等等我都不交待了，食谱里都有，算不了稀奇，只想把其中的吃法交待几笔。吃还有什么吃法吗？有的。同样的一碗面，各自都有不同的吃法，美食家对此是颇有研究的。比如说你向朱鸿兴的店堂里一坐：“喂（那时不叫同志）！来一碗××面。”跑堂的稍许一顿，跟着便大声叫喊：“来哉，××面一碗。”那跑堂的为什么要稍许一顿呢，他是在等待你吩咐吃法：硬面，烂面，宽汤，紧汤，拌面；重青（多放蒜叶），免青（不要放蒜叶），重油（多放点油），清淡点（少放油），重面轻浇（面多些，浇头少点），重浇轻面（浇头多，面少点），过桥——浇头不能盖在面碗上，要放在另外的一只盘子里，吃的时候用筷子搛过来，好像是通过一顶石拱桥才跑到你嘴里……如果是朱自冶向朱鸿兴的店堂里一坐，你就会听见那跑堂的喊出一连串的切口：“来哉，清炒虾仁一碗，要宽汤、重青，重浇要过桥，硬点！” 吃喝小引(2) 叫花子的头头把手一扬，叫花子们呼啦一声散开，我这个手提竹篮，倚门而立，饥肠辘辘的特殊叫花子便到了朱自冶的面前。这个叫花子所以特殊，是因为他知道一点地理历史，自由平等，还读过三民主义；他反对好吃，还懂得人的尊严。当叫花子呼啦一声散开而把我烘托出来的时候，我满腔怒火，汗颜满面，恨不得要把手中的竹篮向朱自冶砸过去！可是我得忍气吞声地从朱自冶的手中接过钞票，按照他的吩咐到陆稿荐去买酱肉，到马咏斋去买野味，到五芳斋去买五香小排骨，到采芝斋去买虾子鲞鱼，到某某老头家去买糟鹅，到玄妙观里去买油汆臭豆腐干，到那些鬼才知道的地方去把鬼才知道的风味小吃寻觅…… 美食家(24)","text":"美食家(1) 朱自冶起得很早，睡懒觉倒是与他无缘，因为他的肠胃到时便会蠕动，准确得和闹钟差不多。眼睛一睁，他的头脑里便跳出一个念头：“快到朱鸿兴去吃头汤面！”这句话需要作一点讲解，否则的话只有苏州人，或者是只有苏州的中老年人才懂，其余的人很难理解其中的诱惑力。 那时候，苏州有一家出名的面店叫作朱鸿兴，如今还开设在怡园的对面。至于朱鸿兴都有哪许多花式面点，如何美味等等我都不交待了，食谱里都有，算不了稀奇，只想把其中的吃法交待几笔。吃还有什么吃法吗？有的。同样的一碗面，各自都有不同的吃法，美食家对此是颇有研究的。比如说你向朱鸿兴的店堂里一坐：“喂（那时不叫同志）！来一碗××面。”跑堂的稍许一顿，跟着便大声叫喊：“来哉，××面一碗。”那跑堂的为什么要稍许一顿呢，他是在等待你吩咐吃法：硬面，烂面，宽汤，紧汤，拌面；重青（多放蒜叶），免青（不要放蒜叶），重油（多放点油），清淡点（少放油），重面轻浇（面多些，浇头少点），重浇轻面（浇头多，面少点），过桥——浇头不能盖在面碗上，要放在另外的一只盘子里，吃的时候用筷子搛过来，好像是通过一顶石拱桥才跑到你嘴里……如果是朱自冶向朱鸿兴的店堂里一坐，你就会听见那跑堂的喊出一连串的切口：“来哉，清炒虾仁一碗，要宽汤、重青，重浇要过桥，硬点！” 吃喝小引(2) 叫花子的头头把手一扬，叫花子们呼啦一声散开，我这个手提竹篮，倚门而立，饥肠辘辘的特殊叫花子便到了朱自冶的面前。这个叫花子所以特殊，是因为他知道一点地理历史，自由平等，还读过三民主义；他反对好吃，还懂得人的尊严。当叫花子呼啦一声散开而把我烘托出来的时候，我满腔怒火，汗颜满面，恨不得要把手中的竹篮向朱自冶砸过去！可是我得忍气吞声地从朱自冶的手中接过钞票，按照他的吩咐到陆稿荐去买酱肉，到马咏斋去买野味，到五芳斋去买五香小排骨，到采芝斋去买虾子鲞鱼，到某某老头家去买糟鹅，到玄妙观里去买油汆臭豆腐干，到那些鬼才知道的地方去把鬼才知道的风味小吃寻觅…… 美食家(24) 杨中宝来了，是由他的孙子陪同来的。他先把我们的店里里外外看了一遍，不停地点头叫好，说是和过去简直不能比。特别是那宽大的厨房，冰箱，排气风扇，炊事用具，雪白的灶头，他当年在交际处也没有这种条件。我把所有菜单都请他过目，他看得十分仔细。 杨中宝开讲的时候，全店上下都来了，把个小会场挤得满满的。我请他解放思想，放开来讲，多讲缺点。可是杨中宝讲得很有分寸，入情入理： “我看了，你们工作得蛮好。要说苏州的名菜，你们差不多全有了，烧得也好。缺点是原料不足和卖得太多引起的。这事很难办，现在吃得起的人太多，十块八块全不在乎。据讲有些名菜你们连听也没有听见过，这也难怪，一种菜往往会有很多名字。比如说苏州的‘天下第一菜’，听起来很吓人，其实就是锅巴汤……” 下面轰地一声笑起来了。 “就是锅巴汤，你们的菜单上天天有。有些名菜你们应该知道，但是不能入菜单，大量供应有困难。比如说鲃肺汤，那是用鲃鱼的肺做的。鲃鱼很小，肺也只有蚕豆瓣那么大，到哪里去找大量的鲃鱼呢？其实那鲃肺也没有什么吃头，主要是靠高汤、辅料，还得多放点味精在里面。鲃肺汤所以出名，那是因为国民党的元老于右任到木渎的石家饭店吃了一顿，吃后写了一首诗，诗中写道：‘老桂开花天下香，看花走遍太湖旁；归舟木渎犹堪记，多谢石家鲃肺汤。’从此石家饭店出了名，鲃肺汤也有了名气。有些名菜一半儿是靠怪，一半儿是靠吹。” … 随着这一声叫喊夕大家的眼睛都看住池塘的南面，自古君子远庖厨也，厨房和书房隔着一池碧水。 电影开幕了：孔碧霞的女儿，那个十分标致的姑娘手捧托盘，隐约出现在竹木之间，几隐几现便到了石板桥的桥头。她步态轻盈，婀娜多姿，桥上的人夕水中的影，手中的盘，盘中的菜，一阵轻风似的向吃客们飘来，象现代仙女从月宫饭店中翩跹而来重该死的朱自冶竟然导演出这么个美妙的镜头，即使那托盘中是装的一盆窝窝头，你也会以为那窝窝头是来自仿膳，慈禧太后吃过的！ 托盘里当然不是窝窝头，盖钵揭开以后，使人十分惊奇，竟然是十只通红的番茄装在雪白的瓷盘里。我也楞住了，按照苏州菜的程式，开头应该是热炒。什么炒鸡丁，炒鱼片，炒虾仁等等的，从来没见过用西红柿开头篁这西红柿是算菜还是算水果呢？ 朱自冶故作镇静，把一只只的西红柿分进各人的碟子里，然后象变戏法似的叫一声“开！”立即揭去西红柿的上盖：清炒虾仁都装在番茄里！ 人们兴趣盎然，纷纷揭盖。 朱自冶介绍了：“一般的炒虾仁大家常吃，没啥稀奇。几十年来这炒虾仁除掉在选料与火候上下功夫以外，就再也没有其它的发展。近年来也有用番茄酱炒虾仁的，但那味道太浓，有西菜味。如今把虾仁装在番茄里面，不仅是好看，请大家自品。注意，番茄是只碗，不要连碗都吃下去。” 我只得佩服了，若干年来我也曾盼望着多给人们炒几盘虾仁，却没有想到把虾仁装在番茄里。秋天的番茄很值钱，丢掉多可惜，我真想连碗都吃下去。","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"小说摘录","slug":"小说摘录","permalink":"https://beefyheisenberg.github.io/tags/小说摘录/"},{"name":"苏州","slug":"苏州","permalink":"https://beefyheisenberg.github.io/tags/苏州/"}]},{"title":"C05绿毛水怪","slug":"64.Novel-and-Poesy/C05.绿毛水怪","date":"2024-01-24T01:27:54.022Z","updated":"2024-01-24T01:27:54.023Z","comments":true,"path":"64.Novel-and-Poesy/C05.绿毛水怪/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/C05.绿毛水怪/","excerpt":"豆瓣链接： 绿毛水怪 (豆瓣) 我在荒岛上迎接黎明我在荒岛上迎接黎明。太阳初升时，忽然有十万支金喇叭齐鸣。阳光穿过透明的空气，在喑蓝色的天空飞过。在黑暗尚未褪去的海面上燃烧着十万支蜡烛。我听见天地之间钟声响了，然后十万支金喇叭又一次齐鸣。我忽然泪下如雨，但是我心底在欢歌。有一柄有弹性的长剑从我胸中穿过，带来了剧痛似的巨大感。这是我一生最美好的时刻，我站在那一个门坎上，从此我将和永恒连结起。……因为确确实实地知道我已经胜利，所以那些燃烧的字句就在我眼前出现，在我耳中轰鸣。这是一首胜利之歌，音韵铿锵，犹如一支乐曲。我摸着水湿过的衣袋，找到了人家送我划玻璃的那片硬质合金。于是我用有力的笔迹把我的诗刻在石壁上，这是我的胜利纪念碑。在这孤零零的石岛上到处是风化石，只有这一片坚硬而光滑的石壁。我用我的诗把它刻满，又把字迹加深，为了使它在这人迹罕到的地方永久存在。 我小的时候，常有一种冰凉的恐怖使我从睡梦中惊醒，我久久地凝视着黑夜。我不明白我为什么会死。到我死时，一切感觉都会停止，我会消失在一片混沌之中。我害怕毫无感觉，宁愿有一种感觉会永久存在。哪怕它是疼。","text":"豆瓣链接： 绿毛水怪 (豆瓣) 我在荒岛上迎接黎明我在荒岛上迎接黎明。太阳初升时，忽然有十万支金喇叭齐鸣。阳光穿过透明的空气，在喑蓝色的天空飞过。在黑暗尚未褪去的海面上燃烧着十万支蜡烛。我听见天地之间钟声响了，然后十万支金喇叭又一次齐鸣。我忽然泪下如雨，但是我心底在欢歌。有一柄有弹性的长剑从我胸中穿过，带来了剧痛似的巨大感。这是我一生最美好的时刻，我站在那一个门坎上，从此我将和永恒连结起。……因为确确实实地知道我已经胜利，所以那些燃烧的字句就在我眼前出现，在我耳中轰鸣。这是一首胜利之歌，音韵铿锵，犹如一支乐曲。我摸着水湿过的衣袋，找到了人家送我划玻璃的那片硬质合金。于是我用有力的笔迹把我的诗刻在石壁上，这是我的胜利纪念碑。在这孤零零的石岛上到处是风化石，只有这一片坚硬而光滑的石壁。我用我的诗把它刻满，又把字迹加深，为了使它在这人迹罕到的地方永久存在。 我小的时候，常有一种冰凉的恐怖使我从睡梦中惊醒，我久久地凝视着黑夜。我不明白我为什么会死。到我死时，一切感觉都会停止，我会消失在一片混沌之中。我害怕毫无感觉，宁愿有一种感觉会永久存在。哪怕它是疼。 长大了一点的时候，我开始苦苦思索。我知道宇宙和永恒是无限的，而我自己和一切人一样都是有限的。我非常非常不喜欢这个对比，老想把它否定掉。于是我开始思考是否有一种比人和人类都更伟大的意义。想明白了从人的角度看来这种意义是不存在的以后，我面前就出现了一片寂寞的大海。人们所做的一切不过是些死前的游戏…… 在冥想之中长大了以后，我开始喜欢诗。我读过很多诗，其中有一些是真正的好诗。好诗描述过的事情各不相同，韵律也变化无常，但是都有一点相同的东西。它有一种水晶般的光辉，好像是来自星星……真希望能永远读下去，打破这个寂寞的大海。我希望自己能写这样的诗。我希望自已也是一颗星星：如果我会发光，就不必害怕黑暗。如果我自己是那么美好，那么一切恐惧就可以烟消云散。于是我开始存下了一点希望——如果我能做到，那么我就战胜了寂寞的命运。但是我好久好久没有动笔写，我不敢拿那么重大的希望去冒险。如果我写出来糟不可言，那么一切都完了。 我十七岁到南方去插队。旱季里，那儿的天空是蓝湛湛的，站在小竹楼里往四下看，四外的竹林翠绿而又苗条。天上的云彩又洁白又丰腴，缓缓地浮过。我觉得应该试一试。 开始时候像初恋一样神秘，我想避开别人来试试我自己。午夜时分，我从床上溜下来，听着别人的鼻息，悄悄地走到窗前去，在皎洁的月光下坐着想。似乎有一些感受、一些模糊不清的字句，不知写下来是什么样的。在月光下，我用自来水笔在一面镜子上写。写出的字句幼稚得可怕。我涂了又写，写了又涂，直到把镜子涂成暗蓝色，把手指和手掌全涂成蓝色才罢手。回到床上，我哭了。这好像是一个更可怕的噩梦。 后来我在痛苦中写下去，写了很久很久，我的本子上出很多歪诗、臭诗，这很能刺激我写下去。到写满了三十个笔记时，我得了一场大病，出院以后弱得像一只瘦猫。正午时分，蹲下又站起来，四周的一切就变成绿色的。 我病退回北京，住在街道上借来的一间小屋里。在北京借到很多书，我读了很多文艺理论，从亚利士多德到苏联比西莫夫，试着从理性分析中找到一条通向目标的道路，结果一无所成。 那时候我穷得发疯，老盼着在地上捡到钱。我是姑姑养大的，可是她早几年死了。工作迟迟没有着落，又不好意思找同学借钱。我转起各种念头，但是我绝对不能偷。我做不出来。想当临时工，可是户口手续拖着办不完。剩下的只有捡破烂一条路了。 在天黑以后，我拿了一条破麻袋走向垃圾站。我站在垃圾堆上却弯不下来。这也许需要从小受熏陶，或者饿得更厉害些。我拎着空麻袋走开时却碰上一位姑娘从这儿走过。我和她只有一面之识，可她却再三盘问我。我编不出谎来，只好照实招了。 她几乎哭了出来，非要到我住的地方去看看不可。在那儿，我把我的事情都告诉她了。那一天我很不痛快，就告诉她准备把一切都放弃。她把我写过的东西看了一遍之后，指出有三首无可争议的好诗。她说事情也许不像我想的那么糕。但是我无论如何也想不起那三首诗是怎么写出来的了。我还不是一个源泉，一个发光体，那么什么也安慰不了我。 后来她常到我这儿来，我把写的都给她看，因为她独具慧眼，很能分出好坏来。她聪明又漂亮。后来我们把这些都放下，开始谈起恋爱来，晚上在路灯的暗影里接吻。过了三个月她要回插队的老家去，我也跟她去了。 在大海边上，有一个小村镇。这儿是公社的所在地，她在公社当广播员，把我安排在公社中学代课。 她有三间大瓦房，盖在村外的小山坡上，背朝着大海，四面不靠人家，连院墙都没有，从陆上吹来的风毫无阻碍地吹着门窗。她很需要有人做伴，于是我也住进那座房子，对外说我是她的表哥，盖这座房子用了我家的钱。人家根本不信，不过也不来管我们的闲事。我们亲密无间，但是没感到有什么必要去登记结婚。我住在东边屋里，晚上常常睡不着觉在门口坐着，她也常来陪我坐。我们有很多时候来谈论，有很多次谈到我。看来写诗对我是一个不堪的重负，可是这已经是一件不可更改的事情了。我必须在这条路上走到底。我必须追求这种能力，必须永远努力下去。我的敌手就是我自己，我要它美好到使我满意的程度。她希望我能斗争到底。她喜欢的就是人能做到不可能做到的事情，她的一切希望就系之于此。如果没有不可能的事情，那么一切都好办了。 我不断地试下去，写过无数的坏诗。偶尔也写过几个美好的句子，但是没有使她真正满意的一篇。我好像老在一个贫乏的圈子里转来转去，爬不出去。我找过各种各样的客观与主观原因，可是一点帮助也没有。她说我应该从原地朝前跨一步，可是我动弹不得。 我就这么过了好几年。有时挎着她的手到海边去散步时我想：“算了吧！我也算是幸福的了。她是多么好的伴侣。也许满足了就会幸福。”可是我安静不下来。我的脑子总是在想那个渺茫的目标。我常常看到那个寂寞的大海。如果我停下来，那么就是寂寞，不如试下去。 昨天早上，校长让我带十几个学生去赶大潮。我们分两批到大海中间的沙滩上去挖牡蛎，准备拿回去卖给供销社，给学校增加一点收入。下午第一批学生上船以后，忽然起了一阵大风，风是从陆上吹来的。这时潮水已经涨到平了沙滩，浪花逐渐大起来，把沙洲上的沙子全掀了起来。如果把我们打到海里，学生们会淹死，我也可能淹死，淹不死也要进监狱。我让学生们拉住我的腰带，推着我与大浪对抗。我身高一米九○，体重一百八十斤，如果浪卷不走我，学生们也会安全。 小船来接我们时，浪高得几乎要把我浮起来，一浮起来我们就完了。小船不敢靠近，怕在沙滩上搁浅，就绕到下风处，我把学生一个一个从浪峰上推出去，让他们漂到船上去。最后一个学生会一点水，我和他一起浮起来时，他一个狗刨动作正刨在我下巴上，打得我晕了几秒钟，醒过来时几乎灌饱了。我再浮上水面，小船已经离得很远。我喊了一声，他们没有听见，我又随浪沉下去。再浮到浪时，小船已经摇走，他们一定以为我淹死了。 我在海里挣扎了很久，陆地在天边消失了。我一个劲地往海底沉，因为我比重太大，很不容易浮起来。大海要淹死我。可是我碰上了一条没浆的小船在海里乱漂。我爬上船去，随它漂去。我晕得一塌糊涂，吐了个天翻地覆。天黑以后，风停了。我看见这座大海之中的小孤岛，就游了上来。 我在荒岛上迎接黎明，我听到了金喇叭的声音。在这个荒岛上，我写出了一生中第一首从源泉涌出来的诗，我把它刻在了石上。 在我的四周都是海，闪着金光，然后闪着银光，天空从浅红变作天蓝。海面上看不见一条船。在这小岛顶上有一座玩具一样的龙王庙。也许人们不会来救我，我还要回到海里，试着自己游回岸上去，但是我并不害怕。我不觉得饿，还可以支持很久。我既可以等待，也可以游泳。现在我愿意等待。于是我叉手于胸站在小岛顶上。我感到自豪，因为我取得了第一个胜利，我毫不怀疑胜利是会接踵而至的。我做到了第一件做不到的事情，我也可以接着做下去。我喜欢我的诗，因为我知道它是真正美好的，它身上有无可争辩的光辉。我也喜欢我自己造出的我自己，我对他满意了。 有一只小船在天边出现，一个白色的小点，然后又像一只白天鹅。我站在山顶上，把衬衫脱下来挥舞。是她，独自划着一条白色的救生艇，是从海军炮校的游泳场搞来的。她在船上挥着手。我到岸边去接她。 她哭着拥抱我，说在海上找了我一夜。人们都相信我已经淹死了，但是她不相信我会死。我把她引到那块石头前，让她看我写的诗。她默默地看了很久，然后向我要那片硬质合金，要把我的名字刻上去。可是我不让她刻。我不需要刻上我的名字。名字对我无关紧要。我不希望人们知道我的名字，因为我的胜利是属于我的。","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"小说摘录","slug":"小说摘录","permalink":"https://beefyheisenberg.github.io/tags/小说摘录/"}]},{"title":"C04白银时代","slug":"64.Novel-and-Poesy/C04.白银时代","date":"2024-01-24T01:27:54.018Z","updated":"2024-01-24T01:27:54.018Z","comments":true,"path":"64.Novel-and-Poesy/C04.白银时代/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/C04.白银时代/","excerpt":"第一章大学二年级时有一节热力学课，老师在讲台上说道：“将来的世界是银子的。” 第十六章在花店里，有个穿黑皮短裙的女孩子对我挤眉弄眼，我没理她。后来她又跟我走了一路，一直追到停车场，在我身后说些带挑逗意味的疯话……最后，她终于拦住我的车门，说道：大叔，别假正经了——你到底是不是只鸭？我闷声喝道：滚蛋！把她撵走了。这种女孩子从小就不学好，功课都是零分，中学毕业就开始工作；和我们不是一路人。然后我坐在方向盘后面咳声叹气，想着“棕色的”从来就没有注意过我。要是她肯注意我，和我闲聊几句，起码能省下几道数学题。她解题的速度太快，现有的数学题不够用了。 未来世界","text":"第一章大学二年级时有一节热力学课，老师在讲台上说道：“将来的世界是银子的。” 第十六章在花店里，有个穿黑皮短裙的女孩子对我挤眉弄眼，我没理她。后来她又跟我走了一路，一直追到停车场，在我身后说些带挑逗意味的疯话……最后，她终于拦住我的车门，说道：大叔，别假正经了——你到底是不是只鸭？我闷声喝道：滚蛋！把她撵走了。这种女孩子从小就不学好，功课都是零分，中学毕业就开始工作；和我们不是一路人。然后我坐在方向盘后面咳声叹气，想着“棕色的”从来就没有注意过我。要是她肯注意我，和我闲聊几句，起码能省下几道数学题。她解题的速度太快，现有的数学题不够用了。 未来世界我舅舅上个世纪（20世纪）末生活在世界上。有件事我们大家都知道：在中国，历史以三十年为极限，我们不可能知道三十年以前的事。我舅舅比我大了三十多岁，所以他的事我就不大知道——更正确的说法是不该知道。他留下了一大堆的笔记、相片，除此之外，我还记得他的样子。他是个肤色黝黑的大个子，年轻时头发很多，老了就秃了。他们那个时候的事情，我们知道的只是：当时烧煤，烧得整个天空乌烟障气，而且大多数人骑车上班。 … 每个星期天，他都要到我们家来吃饭。我的物理老师也常来吃饭，她就住在我们家前面的那栋楼，在家里我叫她小姚阿姨。这位小姚阿姨当时三十岁刚出头，离了婚，人长得非常漂亮，每次她在我家里上过厕所后，我都要抢进去，坐在带有她体温的马桶上，心花怒放。 … 夏天我们到河边去游泳时，我只顾从小姚阿姨的游泳衣缝往里看——那东西实在严实，但也不是无隙可钻，尤其是她刚从水里出来时——所以很少到水里去，以致被晒塌了好几层皮，像鬼一样的黑。小姚阿姨却晒不黑，只会被晒红。她觉得皮肤有点痒时，就跳到水里去，然后水淋淋地上来，在太阳底下接着晒。这个过程使人想到了烹调书上的烤肉法，烤得滋滋响或者起了泡，就要拿出来刷层油或者是糖色。她就这么反复泡制自己的皮肉，终于在夏天快结束时，使腿的正面带上了一点黄色。我对这些不感兴趣，只想看到她从水里出来时背带松驰，从泳衣的上端露出两小块乳房，如果看到了就鼓掌欢呼。这使她每次上岸都要在肩上提一把。提了以后游泳衣就会松驰下来，连乳头的印子都没有了，这当然是和我过不去的举动。她走到我身边时，总要拧我一把，说道：小坏蛋，早晚我要宰了你。","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"小说摘录","slug":"小说摘录","permalink":"https://beefyheisenberg.github.io/tags/小说摘录/"}]},{"title":"C03黑铁时代","slug":"64.Novel-and-Poesy/C03.黑铁时代","date":"2024-01-24T01:27:54.014Z","updated":"2024-01-24T01:27:54.014Z","comments":true,"path":"64.Novel-and-Poesy/C03.黑铁时代/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/C03.黑铁时代/","excerpt":"第四章2010年我住在北戴河，住在一片柴油燃烧的烟云之下。冬天的太阳出来以后，我看到的是一片棕色的风景。这种风景你在照片和电视上都看不到，因为现在每一个镜头的前面都加了蓝色的滤光片。这是上级规定的。这种风景只能用肉眼看见。假如将来有一天，上级规定每个人都必须戴蓝色眼镜的话，就再没有人能看到这样的风景。天会像上个世纪一样的蓝。领导上很可能会做这样的规定，因为这样一来，困扰我们的污染问题就不存在了。在我过四十八岁生日那一天早上，我像往日一样去上班。这一天就像我这一辈子度过的每一天一样，并不特别好，也不特别坏。我选择这一天开始我的日记，起初也没有什么特别的寓意。只是在时隔半年，我在整理这些日记时，才发现它是一系列变化的开始。所以我在这一天开始记日记，恐怕也不全是无意的了。 有关数盲症，我还知道这样一些事：它只在壮年男子身上发作，而且患这种病的人都是做技术工作的。官方对它的解释是：这是一种职业病，是过度劳累造成的，所以数盲症患者总能得到很好的待遇。这一点叫人垂涎欲滴，而且心服口服。数盲者不能按行阅读，只能听汇报；不能辩向，只能乘专车；除了当领导还能当什么？这是正面的说法。反面的说法是：官方宣布的症状谁知是真是假。数盲清正廉洁，从来没有数盲贪赃枉法（不识数的人不可能贪），更没有人以权谋私，任何人都服气。这也是正面说法。反面的说法是他们用不着贪赃枉法，只要拿领导分内的就够多了。正面的说法是领导上的待遇并不超过工作需要，反面的说法是超过了好几百倍；所以应该算算账。为此要有一种计数法、一种记账法、一种逻辑，对数盲和非数盲通用，但又不可能。有位外国的学者说，数盲实质上是不进位，只要是工作用了无穷进制计数法。这种算法我们学不会。假如你就这一点对数盲发牢骚，他就笑眯眯地安慰你说：你们用的二进制、十进制我们也不会嘛。大家各有所长，都是工作需要。 现在要说明的是，北戴河是华北一座新兴的科技城市，它之所以是科技城市，是因为技术部设在这里。王二是技术部的老大哥，也就是常务副部长。这是未患数盲症的人所能担任的最高职务，是一种类似工头的角色。有时他把自己叫做“王二”，有时把自己叫做“我”；但从来不把自己叫做“老大哥”，这个称呼是专供别人使用的。 第五章","text":"第四章2010年我住在北戴河，住在一片柴油燃烧的烟云之下。冬天的太阳出来以后，我看到的是一片棕色的风景。这种风景你在照片和电视上都看不到，因为现在每一个镜头的前面都加了蓝色的滤光片。这是上级规定的。这种风景只能用肉眼看见。假如将来有一天，上级规定每个人都必须戴蓝色眼镜的话，就再没有人能看到这样的风景。天会像上个世纪一样的蓝。领导上很可能会做这样的规定，因为这样一来，困扰我们的污染问题就不存在了。在我过四十八岁生日那一天早上，我像往日一样去上班。这一天就像我这一辈子度过的每一天一样，并不特别好，也不特别坏。我选择这一天开始我的日记，起初也没有什么特别的寓意。只是在时隔半年，我在整理这些日记时，才发现它是一系列变化的开始。所以我在这一天开始记日记，恐怕也不全是无意的了。 有关数盲症，我还知道这样一些事：它只在壮年男子身上发作，而且患这种病的人都是做技术工作的。官方对它的解释是：这是一种职业病，是过度劳累造成的，所以数盲症患者总能得到很好的待遇。这一点叫人垂涎欲滴，而且心服口服。数盲者不能按行阅读，只能听汇报；不能辩向，只能乘专车；除了当领导还能当什么？这是正面的说法。反面的说法是：官方宣布的症状谁知是真是假。数盲清正廉洁，从来没有数盲贪赃枉法（不识数的人不可能贪），更没有人以权谋私，任何人都服气。这也是正面说法。反面的说法是他们用不着贪赃枉法，只要拿领导分内的就够多了。正面的说法是领导上的待遇并不超过工作需要，反面的说法是超过了好几百倍；所以应该算算账。为此要有一种计数法、一种记账法、一种逻辑，对数盲和非数盲通用，但又不可能。有位外国的学者说，数盲实质上是不进位，只要是工作用了无穷进制计数法。这种算法我们学不会。假如你就这一点对数盲发牢骚，他就笑眯眯地安慰你说：你们用的二进制、十进制我们也不会嘛。大家各有所长，都是工作需要。 现在要说明的是，北戴河是华北一座新兴的科技城市，它之所以是科技城市，是因为技术部设在这里。王二是技术部的老大哥，也就是常务副部长。这是未患数盲症的人所能担任的最高职务，是一种类似工头的角色。有时他把自己叫做“王二”，有时把自己叫做“我”；但从来不把自己叫做“老大哥”，这个称呼是专供别人使用的。 第五章我设计的柴油机没有爆炸过——这种东西不会爆炸，除非你在气缸里放上雷管，而那种爆炸就不是我的责任了——我去砸碱是另有理由。大概是在十年以前吧，就像天外来客一样，技术部里来了一个归国留学生，学工程的博士。当然了，在他看来我们都是垃圾，我们的设计都是犯罪，我们听了也都服气。然后他就当了老大哥，我下台了。这使我很高兴。就是现在，谁要肯替我当这个老大哥，就是我的大恩人。他一到部里来，大家都觉得自己活着纯属多余，当然也不肯干活；因此就把他累得要死。 除了设计工作，他还给我们开课，从普通物理到数字电路全讲。听课的寥寥无几，但我总是去听的。我从他那里学了不少东西，所以才能设计柴油机，速校里学的东西只够设计蒸汽机——过去我设计的动力机械就是蒸汽机，装到汽车上，把道路轧出深深的车辙——后来我和他发生了技术路线上的争论——他主张大胆借鉴新技术，一步跨入二十一世纪；我主张主要借鉴二十世纪前期的技术，先走进二十世纪再说，理由如下：你别看我们这些人是垃圾，底下的人更是垃圾。提高技术水平要一步步一米这本是两个非数盲之间的争论，争着争着，数盲就介入了，把我定为右倾机会主义路线头子，送到湖边去砸碱。有个女孩子毅然站了出来——她就是我前妻。砸了两年，提前被接了回来。这是因为好多人得了数盲症（包括那位留学生），部里缺人，又把我调回来当老大哥。这位留学生当了我们部长，隔三差五到部里来转转，见了我就放些臭屁：老大哥，以前的事你要正确对待呀！我就说：正确对待！部长，我爱你！搂住就给他个kiss。其实不是kiss，而是借机把鼻涕抹到他脸上。他一转身我就伸脚钩他的腿。谁要是被碱水泡过两年，准会和我一样。 有关砸碱的事，需要补充一下。当你用十字镐敲到厚厚的碱层上时，碱渣飞溅，必须注意别让它迸进眼睛里。这是因为碱的烧伤有渗透性，会把眼睛烧瞎。你最好戴保护眼镜，但是谁也不会给你这种眼镜（你只能自己做），也不会告诉你这件事（你只能自己知道），所以有好多人把眼睛烧瞎了——有人瞎一只眼，有人瞎两只眼。瞎了两只眼的人就可放心大胆地不戴眼镜砸碱，因为再没有眼睛可瞎了。 红毛衣的事后来是这样的：小孙判下来之后，我们部里该派个人看守他——这种事一般是轮班去的，而且总是我排第一班。这一回她站了出来，自告奋勇去基层锻炼。我前妻当年也是这样的，开完了宣判会，大义凛然地走到我面前，喝道：王犯，把手伸出来！","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"小说摘录","slug":"小说摘录","permalink":"https://beefyheisenberg.github.io/tags/小说摘录/"}]},{"title":"C02青铜时代","slug":"64.Novel-and-Poesy/C02.青铜时代","date":"2024-01-24T01:27:54.009Z","updated":"2024-01-24T01:27:54.010Z","comments":true,"path":"64.Novel-and-Poesy/C02.青铜时代/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/C02.青铜时代/","excerpt":"序 万寿寺我终于有了勇气来谈谈我在文学上的师承。小时候，有一次我哥哥给我念过查良铮先生译的《青铜骑士》： 我爱你，彼得建造的大城我爱你庄严、匀整的面容涅瓦河的流水多么庄严大理石平铺在它的两岸……他还告诉我说，这是雍容华贵的英雄体诗，是最好的文字。相比之下，另一位先生译的《青铜骑士》就不够好：我爱你彼得的营造我爱你庄严的外貌……现在我明白，后一位先生准是东北人，他的译诗带有二人转的调子，和查先生的译诗相比，高下立判。那一年我十五岁，就懂得了什么样的文字才能叫作好。 第一章 万寿寺莫迪阿诺在《暗店街》里写道：“我的过去一片朦胧……”。这本书就放在窗台上，是本小册子，黑黄两色的封面，纸很糙，清晨微红色的阳光正照在它身上。病房里住了很多病人，不知它是谁的。我观察了很久，觉得它像是件无主之物，把它拿到手里来看；但心中惕惕，随时准备把它还回去。过了很久也没人来要，我就把它据为己有。过了一会儿，我才骤然领悟到：这本书原来是我的。这世界上原来还有属于我的东西──说起来平淡无奇，但我确实没想到。病房里弥漫着水果味、米饭味、汗臭味，还有煮熟的芹菜味。在这个拥挤、闭塞、气味很坏的地方，我迎来了黎明。我的过去一片朦胧…… 病房里有一面很大的玻璃窗。每天早上，阳光穿过不平整的窗玻璃，在对面墙上留下火红的水平条纹；躺在这样的光线里，有如漂浮在溶岩之中。本来，我躺在这张红彤彤的床上，看那本书，感到心满意足。事情忽然急转而下，大夫找我去，说道，你可以出院了。医院缺少床位，多少病人该住院却进不来──听他的意思，好像我该为此负责似的。我想要告诉他，我是出于无奈（别人用汽车撞了我的头）才住到这里的，但他不像要听我说话的样子，所以只好就这样了。","text":"序 万寿寺我终于有了勇气来谈谈我在文学上的师承。小时候，有一次我哥哥给我念过查良铮先生译的《青铜骑士》： 我爱你，彼得建造的大城我爱你庄严、匀整的面容涅瓦河的流水多么庄严大理石平铺在它的两岸……他还告诉我说，这是雍容华贵的英雄体诗，是最好的文字。相比之下，另一位先生译的《青铜骑士》就不够好：我爱你彼得的营造我爱你庄严的外貌……现在我明白，后一位先生准是东北人，他的译诗带有二人转的调子，和查先生的译诗相比，高下立判。那一年我十五岁，就懂得了什么样的文字才能叫作好。 第一章 万寿寺莫迪阿诺在《暗店街》里写道：“我的过去一片朦胧……”。这本书就放在窗台上，是本小册子，黑黄两色的封面，纸很糙，清晨微红色的阳光正照在它身上。病房里住了很多病人，不知它是谁的。我观察了很久，觉得它像是件无主之物，把它拿到手里来看；但心中惕惕，随时准备把它还回去。过了很久也没人来要，我就把它据为己有。过了一会儿，我才骤然领悟到：这本书原来是我的。这世界上原来还有属于我的东西──说起来平淡无奇，但我确实没想到。病房里弥漫着水果味、米饭味、汗臭味，还有煮熟的芹菜味。在这个拥挤、闭塞、气味很坏的地方，我迎来了黎明。我的过去一片朦胧…… 病房里有一面很大的玻璃窗。每天早上，阳光穿过不平整的窗玻璃，在对面墙上留下火红的水平条纹；躺在这样的光线里，有如漂浮在溶岩之中。本来，我躺在这张红彤彤的床上，看那本书，感到心满意足。事情忽然急转而下，大夫找我去，说道，你可以出院了。医院缺少床位，多少病人该住院却进不来──听他的意思，好像我该为此负责似的。我想要告诉他，我是出于无奈（别人用汽车撞了我的头）才住到这里的，但他不像要听我说话的样子，所以只好就这样了。 此后，我来到大街上，推着一辆崭新的自行车，不知该到哪里去。一种巨大的恐慌，就如一团灰雾，笼罩着我──这团雾像个巨大的灰毛老鼠，骑在我头上，早晨城里也有一层雾，空气很坏，我自己也带着医院里的馊味。我总觉得空气应该是清新的，弥漫着苦涩的花香──如此看来，《暗店街》还在我脑中作祟…… 莫迪阿诺的主人公失去了记忆。毫无疑问，我现在就是失去了记忆。和他不同的是，我有张工作证，上面有工作单位的地址。循着这个线索，我来到了“西郊万寿寺”的门前。门洞上方有“敕造万寿寺”的字样，而我又不是和尚……这座寺院已经彻底破旧了，房檐下的檩条百孔千疮，成了雨燕筑巢的地方，燕子屎把房前屋后都变成了白色的地带，只在门前留下了黑色的通道。这个地带对人来说是个禁区。不管谁走到里面，所有的燕巢边上都会出现燕子的屁股，然后他就在缤纷的燕粪里，变成一个面粉工人，燕子粪的样子和挤出的儿童牙膏类似。院子里有几棵白皮松，还有几棵老得不成样子的柏树。这一切似曾相识……我总觉得上班的地点不该这样的老旧。顺便说一句，工作证上并无家庭住址，假如有的话，我会回家去的，我对家更感兴趣……万寿寺门前的泥地里混杂着砖石，掘地三尺也未必能挖干净。我在寺门前巡逡了很久，心里忐忑不安，进退两难。直到有一个胖胖的女人经过。她从我身边走过时抛下了一句：进来呀，愣着干啥。这几天我总在愣着，没觉得有什么不对。但既然别人这么说，愣着显然是不对的。于是我就进去了。 出院以前，我把《暗店街》放在厕所的抽水马桶边上。根据我的狭隘经验，人坐在这个地方才有最强的阅读欲望。现在我后悔了，想要回医院去取。但转念一想，又打消了这个主意。把一本读过的书留给别人，本是做了一件善事；但我很怀疑自己真有这么善良。本来我在医院里住得好好的，就是因为看了这本书，才遇到现在的灾难。我对别的丧失记忆的人有种强烈的愿望，想让他们也倒点霉──丧失了记忆又不自知，那才是人生最快乐的时光…… 对于眼前这座灰蒙蒙的城市，我的看法是：我既可以生活在这里，也可以生活在别处；可以生活在眼前这座水泥城里，走在水泥的大道上，呼吸着尘雾；也可以生活在一座石头城市里，走在一条龟背似的石头大街上，呼吸着路边的紫丁香。在我眼前的，既可以是这层白内障似的、磨砂灯泡似的空气，也可以是黑色透明的、像鬼火一样流动着的空气。人可以迈开腿走路，也可以乘风而去。也许你觉得这样想是没有道理的，但你不曾失去过记忆──在我衣服口袋里，有一张工作证，棕色的塑料皮上烙着一层布纹。里面有个男人在黑白相片里往外看着。说实在的，我不知道他是谁。但是，既然出现在我口袋里，除我之外，大概也不会是别人了。也许，就是这张证件注定了我必须生活在此时此地。 早上，我从医院出来，进了万寿寺，踏着满地枯黄的松针，走进了配殿。我真想把鞋脱下来，用赤脚亲近这些松针。古老的榆树，矮小的冬青丛，都让我感到似曾相识；令人遗憾的是，这里有股可疑的气味，于茅厕相似，让人不想多闻。配殿里有个隔出来的小房间，房间里有张桌子，桌子上堆着写在旧稿纸上的手稿。这些东西带着熟悉的气息迎面而来──过去的我带着重重叠叠的身影，飘扬在空中。用不着别人告诉我，我就知道，这是我的房间、我的桌子、我的手稿。这是因为，除了穿在身上的灰色衣服，这世界上总该有些属于我的东西──除了有些东西，还要有地方吃饭，有地方睡觉，这些在目前都不要紧。目前最要紧的是，有个容身的地方。坐在桌子后面，我心里安定多了。我面前还放了一个故事。除了开始阅读，我别无选择了。 “晚唐时，薛嵩在湘西当节度使。前往驻地时，带去了他的铁枪”。故事就这样开始了。这个故事用黑墨水写在我面前的稿纸上，笔迹坚挺有力。着种纸是稻草做的，呈棕黄色，稍稍一折就会断裂，散发着轻微的霉味。我面前的桌子上有不少这样的纸，卷成一捆捆的，用橡皮筋扎住。随手打开一卷，恰恰是故事的开始。走进万寿寺之前，我没想到会有这么多故事。可以写几个字来对照一下，然后就可认定是不是我写了这些故事。但我觉得没有必要。在医院里醒来时，我左手的食指和中指上，都有黑色的墨迹。这说明我一直用黑墨水来写字。在我桌子上，有一个笔筒，里面放满了蘸水钢笔，笔尖朝上，像一丛龙舌兰的样子；笔筒边上放着一瓶中华牌绘图墨水。坐在这个桌子面前，我想道：假如我不是这个故事的作者，也不会有别人了；虽然我一点不记得这个故事。这些稿子放在这里，就如医院窗台上的《暗店街》。假如我不来认领，就永无人来认领。这世界之所以会有无主的东西，就因为有人失去了记忆。 手稿上写道：盛夏时节，在湘西的红土丘陵上，是一片萧杀景象；草木凋零，不是因为秋风的摧残，却是因为酷暑。此时山坡上的野草是一片黄色，就连水边的野芋头的三片叶子，都分向三个方向倒下来；空气好像热水迎面浇来。山坡上还刮着干热的风。把一只杀好去毛的鸡皮上涂上盐，用竹杆挑到风里去吹上半天，晚上再在牛粪火里烤烤，就可以吃了。这种鸡有一种臭烘烘的香气。除了风，吃腐肉的鸟也在天上飞，因为死尸的臭味在酷热中上升，在高空可以闻到。除了鸟，还有吃大粪的蜣螂，它们一反常态，嗡嗡地飞了起来，在山坡上寻找臭味。除了蜣螂，还有薛嵩，他手持铁枪，出来挑柴禾。其它的生灵都躲在树林里纳凉。远远看去，被烤热的空气在翻腾，好像一锅透明的粥，这片山坡就在粥里煮着──这故事开始时就是这样。 第十五章虽然记忆已经恢复，我有了一个属于自己的故事，但我还想回到长安城里──这已经成为一种积习。一个人只拥有此生此世是不够的，他还应该拥有诗意的世界。对我来说，这个世界在长安城里。我最终走进了自己的屋子──那座湖心的水榭，在四面微白的纸壁中间，黑沉沉的一片睁大红色的眼睛──火盆在屋子里散发着酸溜溜的炭味儿。而房外，则是一片沉重的涛声，这种声音带着湿透了的雪花的重量──水在搅着雪，雪又在搅着水，最后搅成了一锅粥。我在黑暗里坐下，揭开火盆的盖子，乌黑的炭块之间伸长了红蓝两色的火焰。在腿下的毡子上，满是打了捆的纸张，有坚韧的羊皮纸，也有柔软的高丽纸。纸张中间是我的铺盖卷。我没有点灯，也没有打开铺盖，就在杂乱之中躺下，眼睛绝望地看着黑暗。这是因为，明天早上，我就要走上前往湘西风凰寨的不归路。薛嵩要到那里和红线汇合，我要回到万寿寺和白衣女人汇合。长安城里的一切已经结束。一切都在无可挽回地走向庸俗。 第十六章 红拂夜奔李靖、红拂、虬髯公世称风尘三侠，隋朝末年，他们三人都在洛阳城里住过。大隋朝的人说，洛阳城是古往今来最伟大的城市；但唐朝的人又说，长安是古往今来最伟大的城市；宋朝的人说，汴梁是古往今来最伟大的城市；所以很难搞清到底哪里是古往今来最伟大的城市。洛阳城是泥土筑成的筑城的。土是用远处运来的最纯净的黄土，放到笼屉里蒸软后… 第二十七章你不能从人群里认出我来的，尽管你知道我头发灰白，一年四季总穿灰色的衣服。现在每天我都到系里去上班，在我的办公桌上故了一个老式的墨水池，那东西看上去像个眼镜，左边的一个墨水瓶里是红墨水，右面一个是蓝墨水，中间的凹槽里放了好多蘸水笔尖。每天早上我来时，都要仔细把笔尖挑选一遍，把磨秃了的笔尖拣出来，包在一张纸里扔进废纸篓；然后戴上老花镜批阅学生的作业。这些学生是加州伯克利教的。批完之后我把这些作业本拿到对面他的办公桌上，然后看教科书的校样，到十一点钟我到厕所去洗手准备回家——有人在洗手池上放了一撮洗衣粉，用它可以去掉手上的墨水渍。我就是这样一天天老下去了。从这个样子你决看不出我每天每夜每小时每一分钟都在想入非非，怀念着十七岁时见到的紫色天空，岸边长满绿色芦苇的河流，还有我的马兄弟。我本来不是这样，是装成这样的。你不可能从一个削瘦、憔悴的数学教师身上看到这些。有关人随时在想些什么，我只知道一个例子，就是我自己，别人不可能把一切都告诉我。所以我只好推己及人。在统计学上可以证明，以一个例子的样本来推论无限总体，这种方法十分之坏。安妮·弗兰克就犯了这种错误，从自己是善良的推出了所有的人都是善良的，虽然这份善良被深藏在心里，这个推论简直是黑色幽默。但是在这件事上没有别的方法了。到目前为止，没有一件事能让我相信我是对的，就是人生来有趣。过去有趣，渴望有趣，内心有趣却假装无趣。也没有一件事能证明我是错的，让我相信人生来无趣，过去无趣现在也无趣，不喜欢有趣的事而且表里如一。所以到目前为止，我只能强忍着绝望活在世界上。 全书完一个人只拥有此生此世是不够的，他还应该拥有诗意的世界。","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"小说摘录","slug":"小说摘录","permalink":"https://beefyheisenberg.github.io/tags/小说摘录/"}]},{"title":"C01黄金时代","slug":"64.Novel-and-Poesy/C01.黄金时代","date":"2024-01-24T01:27:54.004Z","updated":"2024-01-24T01:27:54.004Z","comments":true,"path":"64.Novel-and-Poesy/C01.黄金时代/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/C01.黄金时代/","excerpt":"第二章我二十一岁时，正在云南插队。陈清扬当时二十六岁，就在我插队的地方当医生。我在山下十四队，她在山上十五队。 … 当然，我对此有不同的意见，在我看来，这东西无比重要，就如我之存在本身。天色微微向晚，天上飘着懒洋洋的云彩。下半截沉在黑暗里，上半截仍浮在阳光中。那一天我二十一岁，在我一生的黄金时代。我有好多奢望。我想爱，想吃，还想在一瞬间变成天上半明半暗的云。后来我才知道，生活就是个缓慢受锤的过程，人一天天老下去，奢望也一天天消失，最后变得像挨了锤的牛一样。可是我过二十一岁生日时没有预见到这一点。我觉得自己会永远生猛下去，什么也锤不了我。 第十七章 革命时期的爱情","text":"第二章我二十一岁时，正在云南插队。陈清扬当时二十六岁，就在我插队的地方当医生。我在山下十四队，她在山上十五队。 … 当然，我对此有不同的意见，在我看来，这东西无比重要，就如我之存在本身。天色微微向晚，天上飘着懒洋洋的云彩。下半截沉在黑暗里，上半截仍浮在阳光中。那一天我二十一岁，在我一生的黄金时代。我有好多奢望。我想爱，想吃，还想在一瞬间变成天上半明半暗的云。后来我才知道，生活就是个缓慢受锤的过程，人一天天老下去，奢望也一天天消失，最后变得像挨了锤的牛一样。可是我过二十一岁生日时没有预见到这一点。我觉得自己会永远生猛下去，什么也锤不了我。 第十七章 革命时期的爱情《序》这是一本关于性爱的书。性爱受到了自身力量的推动，但自发地做一件事在有的时候是不许可的，这就使事情变得非常的复杂。举例言之，颐和园在我家北面，假如没有北这个方向的话，我就只好向南走，越过南极和北极，行程四万余公里到达那里。我要说的是：人们的确可以牵强附会地解释一切，包括性爱在内。故而性爱也可以有最不可信的理由。 王二年轻时在北京一家豆腐厂里当过工人。那地方是个大杂院，人家说过去是某省的会馆。这就是说，当北京城是一座灰砖围起的城池时，有一批某个省的官商人等凑了一些钱，盖了这个院子，给进京考试的举人们住。这件事太久远了。它是一座细砖细瓦的灰色院子，非常的老旧了；原来大概有过高高的门楼，门前有过下马石栓马桩一类的东西，后来没有了，只有一座水泥门桩的铁栅栏门，门里面有条短短的马路，供运豆腐的汽车出入。马路边上有一溜铁皮搭的车棚子，工人们上班时把自行车放在里面。棚子的尽头有个红砖砌的小房子，不论春夏秋冬里面气味恶劣，不论黑夜白天里面点着长明灯，那里是个厕所。有一段时间有人在里面的墙上画裸体画，人家说是王二画的。 王二在豆腐厂里当工人时，北京冬天的烟雾是紫红色的，这是因为这座城里有上百万个小煤炉，喷出带有二氧化硫的煤烟来。当阳光艰难地透过这种煤烟时，就把别的颜色留在天顶上了。这种颜色和他小时候见过的烟雾很近似。对于颜色，王二有特别好的记忆力。但是不管你信也好，不信也罢，他居然是个色盲。早知道自己是个色盲，他也不去学画，这样可以给自己省去不少的麻烦。 第二十二章有关那位姓颜色的女大学生，有一点需要补充的地方，那就是在我清醒的时候，也觉得她挺麻烦的。比方说，我正在五楼顶上和一伙人汗流浃背地布置滚木檑石，准备把进犯者通通砸死，忽听她在二楼叫我，就急星火撩地跑了去。你猜是叫我干啥罢——叫我吃面条。我留在这楼里，破坏了自己的房子，出卖了自己家的利益，还长了一身虱子，就是为了吃这种没油没盐盛在茶缸里的面条吗？我对她很反感，觉得她婆婆妈妈的。但这是我清醒时候的事。到了我睡着，或是自以为睡着了的时候，就和她拥抱，接吻，用双手爱抚她的乳房。干这种事时，她老掐我的胳膊，第二天胳臂上青印累累。这说明这样的事发生过。但是不管她怎么掐，我都没有醒来。除了没有醒，别的事都和醒着时一样。比方说，过道里点了一盏马灯，灯光一会儿红，一会黄，游移不定。地下有好多草垫子，给人一种建筑工地的印象。我一点没觉得是在我住了十几年的家里。姓颜色的大学生嘴里有一股奶油软糖的味道。她乳罩左边有四个扣子，解起来麻烦无比。在那方寸之地集中的扣子比我全身剩下的扣子还多，这说明女人简直是不能沾。我已经决定把这当一场梦，不管她怎么掐，都不肯醒来。这件事我没有告诉X海鹰，任凭她怎么问。我觉得把这种事告诉她不适宜。 … 我和姓颜色的大学生爬地沟到海淀镇去买大饼，那些地沟是砖头砌成，顶上盖着水泥板。从里面用灯光照着时，那些砖头重重叠叠，仿佛要向里面压下来。那是一段不近的路。我们俩都戴了涂胶的手套，姓颜色的大学生膝盖上还套了田径队员练腿时绑的砂袋——当然，袋里的铁砂倒掉了。我告诉她说，进了地沟就要像狗一样爬，口袋里的东西都要掏出来，否则会丢掉。她就把钱拿出来，塞到乳罩里，以免爬掉了。然后我们下到地沟里，开始爬了。我嘴里叼着马灯，爬起来膝盖不着地而且很快，这种技术也不是练了一年两年。姓颜色的大学生跟在后面，看来她爬地沟还有点天份，能跟上我。爬了一段，姓颜色的大学生忽然坐在地下，说：“小叭狗！！”，就哈哈地笑起来了。 第二十三章X海鹰带我到她家里去那一天，天幕是深黄色的，正午时分就比黄昏时还要昏暗。我跟在她的车轮后面跑过洒满了黄土的马路——那时候马路上总是洒满了地铁工地运土车上落下的土，那种地下挖出来的黄土纯净绵软，带有糯性。天上也在落这样的土。我以为就要起一场飞砂走石的大风，但是跑着跑着天空就晴朗了，也没有起这样的风。我穿着油污的工作服，一面跑一面唱着西洋歌剧——东一句西一句，想起哪句唱哪句。现在我想起当年的样子来，觉得自己实在是惊世骇俗。路上的行人看到我匆匆跑过，就仔细看我一眼。但是我没有把这些投来的目光放在心上。 第四十三章 2015上个世纪渤海边上有个大碱厂，生产红三角牌纯碱，因而赫赫有名。现在经过芦台一带，还能看到海边有一大片灰蒙蒙的厂房。因为氨碱法耗电太多，电力又不足，碱厂已经停了工，所需的碱现在要从盐碱地上刨来。这项工作十分艰苦，好在还有一些犯了错误的人需要改造思想，可以让他们去干。除此之外，还需要有些没犯错误的人押送他们，这就是这个故事的前因。我舅舅现在还活着，会有什么样的后果还很难说。总而言之，我舅舅在盐碱地上刨碱，小舅妈押着他。刨碱的地方离芦台不很远。 每次我路过芦台，都能看到碱厂青白的空壳子厂房。无数海鸟从门窗留下的大洞里飞进飞出，遮天盖地。废了的碱厂成了个大鸟窝，还有些剃秃瓢拴脚镣的人在窝里出入，带着铲子和手推车。这说明艰苦的工作不仅是刨碱，还有铲鸟粪。听说鸟粪除了做肥料，还能做食品的添加剂。当然，要经过加工，直接吃可不行。…我舅舅在碱场劳改时，每天都要去砸碱。据他后来说，当时的情形是这样的：他穿了一件蓝大衣，里面填了再生毛，拖着那副大脚镣，肩上扛了十字镐，在白花花的碱滩上走。那地方的风很是厉害，太阳光也很厉害，假如不戴个墨镜，就会得雪盲，碱层和雪一样反光。如前所述，我舅舅没有墨镜，就闭着眼睛走。小舅妈跟在后面，身穿呢子制服，足蹬高统皮靴，腰束武装带，显得很是英勇。她把大檐帽的带子放下来，扣在下巴上。走了一阵子，她说：站住，王犯！这儿没人了，把脚镣开了罢。我舅舅蹲下去拧脚镣，并且说：报告管教，拧不动，螺丝锈住了！小舅妈说：笨蛋！我舅舅说：这能怪我吗？又是盐又是碱的。他的意思是说，又是盐又是碱，铁器很快就会锈。小舅妈说：往上撒尿，湿了好拧。我舅舅说他没有尿。其实他是有洁癖，不想拧尿湿的罗丝。小舅妈犹豫了一阵说：其实我倒有尿棗算了，往前走。我舅舅站起身来，扛住十字镐，接着走。在雪白的碱滩上，除了稀疏的枯黄芦苇什么都没有。走着走着小舅妈又叫我舅舅站住，她解下武装带挂在我舅舅脖子上，走向一丛芦苇，在那里蹲下来尿尿。然后他们又继续往前走，此时我舅舅不但扛着镐头，脖子上还有一条武装带、一支手枪、一根警棍，走起路来东歪西倒，完全是一副怪模样。后来，我舅舅找到了一片碱厚的地方，把蓝大衣脱掉铺在地上，把武装带放在旁边，就走开，挥动十字镐砸碱。小舅妈绕着他嘎吱嘎吱地走了很多圈，手里掂着那根警棍。然后她站住，从左边衣袋里掏出一条红丝巾，束在脖子上，从右衣袋里掏出一副墨镜戴上，走到蓝大衣旁边，脱掉所有的衣服，躺在蓝大衣上面，摊开白晰的身体，开始日光浴。 过了不久，那个白晰的身体就变得红扑扑的了。与此同时，我舅舅迎着冷风，流着清水鼻涕，挥着十字镐，在砸碱。有时小舅妈懒洋洋地喊一声：王犯！","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"小说摘录","slug":"小说摘录","permalink":"https://beefyheisenberg.github.io/tags/小说摘录/"}]},{"title":"为什么我们仰望星空会震撼","slug":"63.Culture-and-Arts/为什么我们仰望星空会震撼","date":"2024-01-24T01:27:53.999Z","updated":"2024-01-24T01:27:53.999Z","comments":true,"path":"63.Culture-and-Arts/为什么我们仰望星空会震撼/","link":"","permalink":"https://beefyheisenberg.github.io/63.Culture-and-Arts/为什么我们仰望星空会震撼/","excerpt":"@ref: 为什么我们仰望星空会震撼｜混乱博物馆 - 知乎 康德在《纯粹理性批判》的结语中说：「有两种东西越经常反复思想，就给人灌注了时时更新、与日俱增的惊赞和敬畏：头上的星空和内心的道德律。」的确，当我们在夜晚置身旷野，仰望星空，就会有一种让人眩晕的、不真实的震撼感。 这可能与深渊恐惧症（Bathophobia）、巨物恐惧症（Megalophobia）等一系列恐惧症（Phobia）有所关联。 特定性恐惧症（Specific Phobia）是常见的心理学现象，它是由特定物体或情景引发的恐惧症状，这与原始的恐惧具有相同的反射机理： 当眼睛捕捉到危险的信号，并传递给大脑中的杏仁核，就会激发恐惧感，启动一种被称为「战斗或逃跑反应」的心理机制：肾上腺素水平提高，心跳加快，头皮发麻、胃部不适，甚至眩晕、呕吐，此时，要么快速逃离，要么拼死一搏。","text":"@ref: 为什么我们仰望星空会震撼｜混乱博物馆 - 知乎 康德在《纯粹理性批判》的结语中说：「有两种东西越经常反复思想，就给人灌注了时时更新、与日俱增的惊赞和敬畏：头上的星空和内心的道德律。」的确，当我们在夜晚置身旷野，仰望星空，就会有一种让人眩晕的、不真实的震撼感。 这可能与深渊恐惧症（Bathophobia）、巨物恐惧症（Megalophobia）等一系列恐惧症（Phobia）有所关联。 特定性恐惧症（Specific Phobia）是常见的心理学现象，它是由特定物体或情景引发的恐惧症状，这与原始的恐惧具有相同的反射机理： 当眼睛捕捉到危险的信号，并传递给大脑中的杏仁核，就会激发恐惧感，启动一种被称为「战斗或逃跑反应」的心理机制：肾上腺素水平提高，心跳加快，头皮发麻、胃部不适，甚至眩晕、呕吐，此时，要么快速逃离，要么拼死一搏。 恐惧是人类在长久的演化之中，为了适应复杂的自然环境形成的一种本能，它提高了人类面对强大威胁的反应速度，利于我们的生存。 人类的安全感，建立在自己熟悉的、符合经验认知的基础之上，而身处不符合自己经验的环境或周围出现这样的事物，则会引发不安、恐慌和警觉，这是一种长期演化形成的保护机制。 我们即使对宇宙的真实尺度一无所知，但我们只要抬起头，就能直观感受到几乎占据了整个视域的星空，是个完全在我们经验之外的时空。我们对星空的恐惧和震撼，归根到底，是我们的日常与我们头顶上的“真实”之间的冲突。 《缮写室》中提到 agora，旷野恐惧症（agoraphobia）的词源 @link: [[../64.Novel-and-Poesy/《缮写室》 Quick-view]] [[../53.Photograph/使用谷歌街景进行街拍]] 中也提到摄影师 Jacqui Kenny 是一位“Agoraphobic Traveller” （这里的‘agoraphobia’翻译成了‘广场恐惧症’） 对于星空，那种感觉究竟是是「恐惧」还是「震撼」？ —— 也许如里尔克所说：美恰好是我们刚好可以承受的恐怖的开端，@link: [[../64.Novel-and-Poesy/D02.里尔克诗选]]","categories":[{"name":"63.Culture-and-Arts","slug":"63-Culture-and-Arts","permalink":"https://beefyheisenberg.github.io/categories/63-Culture-and-Arts/"}],"tags":[]},{"title":"阿连德的大数据乌托邦","slug":"63.Culture-and-Arts/阿连德的大数据乌托邦","date":"2024-01-24T01:27:53.995Z","updated":"2024-01-24T01:27:53.995Z","comments":true,"path":"63.Culture-and-Arts/阿连德的大数据乌托邦/","link":"","permalink":"https://beefyheisenberg.github.io/63.Culture-and-Arts/阿连德的大数据乌托邦/","excerpt":"@link: 赛博朋克 Wiki：赛博协同控制工程@ref: 赛博协同控制工程 - Wikiwand 赛博协同控制工程（英文：Project Cybersyn，简称：Cybersyn或Synco）是智利总统萨尔瓦多·阿连德在1971 - 1973年任期内建设的一项计算机网络工程，用于构建分布式决策支持系统，以支持国民经济的管理。该项目由四个模块组成：经济模拟器、确认工厂生产情况的定制软件、控制室和连接至一台主机的全国电报机网络。","text":"@link: 赛博朋克 Wiki：赛博协同控制工程@ref: 赛博协同控制工程 - Wikiwand 赛博协同控制工程（英文：Project Cybersyn，简称：Cybersyn或Synco）是智利总统萨尔瓦多·阿连德在1971 - 1973年任期内建设的一项计算机网络工程，用于构建分布式决策支持系统，以支持国民经济的管理。该项目由四个模块组成：经济模拟器、确认工厂生产情况的定制软件、控制室和连接至一台主机的全国电报机网络。 赛博协同控制工程基于可行性系统模型（英语：Viable system model）和神经网络方法进行设计，并采用当时的先进技术：包括国有企业中的电报机网络，可用于与圣地亚哥的政府进行信息收发,和用于监视生产指标的统计模型软件可近乎实时的接收实地采集的信息，如原材料供应和工人旷工等，并向工人事先发出预警。情况严重的情况下，系统也会向中央政府发出预警。政府同样也会将数据输入经济模拟软件（CHECO, CHilean ECOnomic simulator的缩写），以预测经济决议的可能结果。管理者可在控制室（Opsroom）观看经济数据，对紧急情况制定合理应对措施，并在预警情况利用电报机网络向企业和工厂发送指导建议。 赛博协同控制工程的首席架构师是英国运筹学家斯塔福德·比尔（英语：Stafford Beer），该系统体现了他在工业管理中的组织控制论概念。其主要目标之一是将工业企业的决策权下放到工人中，以便发展工厂的自我监管。 1973年9月11日的军事政变后，赛博协同控制工程被废弃，其控制室也被摧毁。 王洪喆：阿连德的大数据乌托邦 ——智利互联网考古王洪喆：阿连德的大数据乌托邦 一九七二年十二月三十日，智利总统萨尔瓦多·阿连德视察了位于首都圣地亚哥的一间未来主义格调操作室。它似乎更像是库布里克电影中的场景，而不像是一个南美洲国家政府在经济战争中的指挥中心。在这间充满七十年代现代主义美学的六角形房间里，智利全国的经济数据经由电传机网络（telex）汇聚于此。而控制论（cybernetics）——一门试图构建生物、机器和社会系统之间共性的战后通信和控制科学，将帮助阿连德实现他承诺给这个国家带来的社会主义变革。它的创造者预计，政府的工业管理者将根据国家经济活动的实时数据和宏观视图做出快速决策，进而通往对整个社会主义国家生产生活的民主管理。这就是“赛博协同工程”（Project Cybersyn）——曾经真实存在于二十世纪历史中的“大数据”社会主义乌托邦——一个来自南美洲的控制论互联网革命。历经十年的寻访与写作，伊登·梅迪纳（Eden Medina）以开创性的著作《控制论革命者》，让这段少为人知的历史重见天日。 为了达成在内忧外患中完成工业国有化和经济增长的紧迫目标，阿连德任命了年轻的财政和技术官费尔南多·弗洛雷斯（Fernando Flores）实验新的管理办法。在阅读了斯塔福德·比尔的著作后，弗洛雷斯发现比尔的控制论思想跟智利的民主社会主义方案之间存在高度的亲缘性。二十世纪六十年代，比尔在英国致力于改造大型工厂中传统的中央到部门层层传达、指令式的管理理念。从控制论的稳态（homeostasis）类比出发，比尔将企业视为一个各部门之间协同的有机体，而管理的目标是对有机体的状态进行实时监控，只在必要时给出干预。 … 那么，技术人员如何尝试将政治价值观注入技术人造物之中呢？首先，比尔希望在工厂经理和国家计划部门之间建立一种诚实而负责的关系。他认为，联网汇聚的统计概况将使得管理者难以伪造生产数据，不像苏联的工厂管理者在完成计划的压力下篡改记录。联网系统会使得异常立即显现，促使进一步调查。不过，比尔限制了系统收集的生产指标数量，这一方面防止计算机的信息过载，但更重要的是可防止国家事无巨细的微观干预和权力滥用，保证企业一定的自主性。这与苏联几乎在同一时期试图构建的全国经济控制论系统相区别。苏联控制论学者的愿景，是通过对各项经济指标的穷尽以达到模型的精确模拟和生产调节的全知全能。因此，比尔认为赛博协同的设定区分了智利和苏联的社会主义。 其次，赛博协同的反馈设计试图找到基层自主性和“全国一盘棋”之间的平衡点。例如，当系统检测到生产异常时，中央操作室将同时向计划部门和工厂管理者预警。政府会给工厂经理和工人们一个有限的时间窗口来查找和解决潜在问题。由此，企业在合理的程度上保持了自主性。如果相关企业和个人无法在这段时间内解决问题，政府再介入干预。这种干预将限制工厂的自主性，但是比尔认为这对于保持整个经济系统的稳定性是必不可少的。 最后，系统的设计反映了阿连德提高就业水平的承诺，这是政府计划的一个关键部分。计算机通常与工厂自动化相关联，在提高生产率水平的同时也使得企业减少其劳动力。而赛博协同将以不导致失业的方式使用计算机，它不急于指向自动化，而是帮助工厂和政府利用现有的人力和物力提高工业生产率。","categories":[{"name":"63.Culture-and-Arts","slug":"63-Culture-and-Arts","permalink":"https://beefyheisenberg.github.io/categories/63-Culture-and-Arts/"}],"tags":[{"name":"拉美","slug":"拉美","permalink":"https://beefyheisenberg.github.io/tags/拉美/"},{"name":"赛博朋克","slug":"赛博朋克","permalink":"https://beefyheisenberg.github.io/tags/赛博朋克/"},{"name":"智利","slug":"智利","permalink":"https://beefyheisenberg.github.io/tags/智利/"}]},{"title":"神奇故事的历史根源","slug":"63.Culture-and-Arts/神奇故事的历史根源","date":"2024-01-24T01:27:53.991Z","updated":"2024-01-24T01:27:53.991Z","comments":true,"path":"63.Culture-and-Arts/神奇故事的历史根源/","link":"","permalink":"https://beefyheisenberg.github.io/63.Culture-and-Arts/神奇故事的历史根源/","excerpt":"","text":"神奇故事的历史根源 (豆瓣) 弗拉基米尔·雅可夫列维奇·普罗普（Владимир Яковлевич Пропп，1895—1970），俄罗斯著名民间文艺学家，开启结构主义时代理论灵感的大师和先驱者。他在民间创作研究领域开辟了独具特色的研究方向和方法，享有世界性的声誉，在语言学、文艺学、历史学、考古 学、符号学等诸多民俗学以外的领域也产生了深远影响。颇为神奇的是，人们发现，普罗普的研究结论在多种现代大众文化的叙事领域也相当有效。代表论著有《故事形态学》《神奇故事的历史根源》《俄罗斯故事论》等。","categories":[{"name":"63.Culture-and-Arts","slug":"63-Culture-and-Arts","permalink":"https://beefyheisenberg.github.io/categories/63-Culture-and-Arts/"}],"tags":[]},{"title":"核文化：怪核（Weirdcore）、梦核（Dreamcore）...","slug":"63.Culture-and-Arts/梦核、怪核、旧核","date":"2024-01-24T01:27:53.986Z","updated":"2024-01-24T01:27:53.986Z","comments":true,"path":"63.Culture-and-Arts/梦核、怪核、旧核/","link":"","permalink":"https://beefyheisenberg.github.io/63.Culture-and-Arts/梦核、怪核、旧核/","excerpt":"核“核（core）”这个词，其实是个现代音乐术语，最初是一种更躁动原始版本的朋克音乐“硬核”，后来这种音乐向重金属发展，成了传统金属党不太瞧得上的金属核，并演变出无数衍生：死核、技术核、情绪核……所以你可以把“核”看作是，偏主流的亚文化中，指代“风格”的同义词。 怪核与延伸的‘核’文化怪核（英文：Weirdcore） 是一种网络美学和艺术行为，使用低质量摄影及或数字图形为中心。这些图形及数字图形被构建及编辑以传达混乱、迷失方向、疏远、怀旧或厌世的感觉。从视觉上看，它受到旧互联网上共享图像的总体外观和感觉的强烈影响，大约是从 90 年代末到 2010 年代中期。业余编辑、原始数字图形、低保真摄影和图像压缩是怪核图像中最常见的一些元素。 梦核（Dreamcore）是一种互联网美学意象，也可以说是一种数字艺术创作的类别，许多人将它认定为怪核艺术（Weirdcore）的分支。 怪核在Aesthetics Wiki 上被定义为通过低质量的照片或数字图像编辑，给人带来混乱、迷失、疏离、怀旧、无能感的网络美学和艺术行为。","text":"核“核（core）”这个词，其实是个现代音乐术语，最初是一种更躁动原始版本的朋克音乐“硬核”，后来这种音乐向重金属发展，成了传统金属党不太瞧得上的金属核，并演变出无数衍生：死核、技术核、情绪核……所以你可以把“核”看作是，偏主流的亚文化中，指代“风格”的同义词。 怪核与延伸的‘核’文化怪核（英文：Weirdcore） 是一种网络美学和艺术行为，使用低质量摄影及或数字图形为中心。这些图形及数字图形被构建及编辑以传达混乱、迷失方向、疏远、怀旧或厌世的感觉。从视觉上看，它受到旧互联网上共享图像的总体外观和感觉的强烈影响，大约是从 90 年代末到 2010 年代中期。业余编辑、原始数字图形、低保真摄影和图像压缩是怪核图像中最常见的一些元素。 梦核（Dreamcore）是一种互联网美学意象，也可以说是一种数字艺术创作的类别，许多人将它认定为怪核艺术（Weirdcore）的分支。 怪核在Aesthetics Wiki 上被定义为通过低质量的照片或数字图像编辑，给人带来混乱、迷失、疏离、怀旧、无能感的网络美学和艺术行为。 阈限空间（Liminal Spaces）： 阈限空间：当代都市里的虚幻乡愁 | 机核 GCORES “阈限空间” 一种人类恐惧的临界状态 _ 游民星空 GamerSky.com 旧核（Nostalgia Core）： 其他的核：雨核、乡核、池核 Reference@link: 怀旧、阈限空间与现代意识 | 机核 GCORES 梦核、怪核、后室：年轻人的赛博朋克噩梦_腾讯新闻 经过本土网红化的怪核梦核，终于因为太过火被出警了 - 知乎","categories":[{"name":"63.Culture-and-Arts","slug":"63-Culture-and-Arts","permalink":"https://beefyheisenberg.github.io/categories/63-Culture-and-Arts/"}],"tags":[{"name":"奇怪的东西","slug":"奇怪的东西","permalink":"https://beefyheisenberg.github.io/tags/奇怪的东西/"},{"name":"亚文化","slug":"亚文化","permalink":"https://beefyheisenberg.github.io/tags/亚文化/"},{"name":"流行文化","slug":"流行文化","permalink":"https://beefyheisenberg.github.io/tags/流行文化/"}]},{"title":"科幻的朋克们","slug":"63.Culture-and-Arts/科幻的朋克们","date":"2024-01-24T01:27:53.982Z","updated":"2024-01-24T01:27:53.982Z","comments":true,"path":"63.Culture-and-Arts/科幻的朋克们/","link":"","permalink":"https://beefyheisenberg.github.io/63.Culture-and-Arts/科幻的朋克们/","excerpt":"@todo: 【亚文化美学编年史】Cyberpop｜Post-rock｜Y2K 1990-2000年亚文化词汇科普（上）_哔哩哔哩_bilibili 【亚文化科普篇01】朋克？摇滚？原宿风？ Gal系·PUNK·LOLITA｜15分钟带你看完一部亚比服饰极简史_哔哩哔哩_bilibili 时间是个浑圆：梳理“复古未来主义” | 机核 GCORES 复古未来主义（英语：Retro-futurism）是指当代艺术中对早期的未来主义设计风格的模仿。 前文提到复古未来主义包含的类型：赛博朋克、蒸汽朋克、柴油朋克和甚至是一些没有公认中文译名的类型：atompunk、raygun gothic ……","text":"@todo: 【亚文化美学编年史】Cyberpop｜Post-rock｜Y2K 1990-2000年亚文化词汇科普（上）_哔哩哔哩_bilibili 【亚文化科普篇01】朋克？摇滚？原宿风？ Gal系·PUNK·LOLITA｜15分钟带你看完一部亚比服饰极简史_哔哩哔哩_bilibili 时间是个浑圆：梳理“复古未来主义” | 机核 GCORES 复古未来主义（英语：Retro-futurism）是指当代艺术中对早期的未来主义设计风格的模仿。 前文提到复古未来主义包含的类型：赛博朋克、蒸汽朋克、柴油朋克和甚至是一些没有公认中文译名的类型：atompunk、raygun gothic …… 如果你以为这就是复古未来主义的全部，哪你真是太小看复古未来主义的生命力了。哪怕如今信息高度碎片化，文化渐渐 显露出后现代的特征，这个名为复古未来主义的幽灵也能在互联网中显现出全新的表征，它便是以Vaporwave（蒸汽波）、Synthwave（合成器浪潮）、chillwave、futer funk（未来放克）“等风格为代表的新复古浪潮。 “蒸 汽 波”多么熟悉的词啊，它以“互联网最合适的形式”病毒一般在互联网传播。 这种由网络模因发展成为的艺术运动，从它的视觉元素（粉红和粉绿色、80年代商场的中古希腊雕像、80年代大众传媒中的商品广告、棕榈树、早期电脑绘制的3D空间、日文…）来看就是一种“回忆”，对80、90年代强胜的美国、日本流行文化与城市景观的回忆，对早期赛博朋克美学的回忆。这就像早期的复古未来主义对黄金时代科幻美学的回忆，就像蒸汽朋克就维多利亚时代美学的回忆，柴油朋克对二战时期美学的回忆。 如果这还不足以说服你，让我们来看看与蒸汽波牢牢捆绑的Futer Funk（未 来 放 克）。它的主要表现形式为：基于日本曾经流行的音乐风格City pop进行采样、重构，搭配日本卡通形象。将“过时”回炉重造为“新潮”，制造一种“怀念”，怀念一个从未去过的泡沫经济时代日本，保留“为什么现在是这样，而不是过去想象的那般美好”的质问。 什么是故障艺术 (Glitch Art)？ - 知乎 顾名思义，Glitch art 就是“故障艺术”。 Glitch这个词的意思就是“失灵；短时脉冲波干扰”，可以理解成一种自动或人为的bug。但是Glitch art不一定是只限制于数码环境中的，在analog art里出现的机械、或人为干扰产生的故障都可以被归为“故障艺术”；但重要的一点是，这不止是一种故障的呈现和表现，还应该是一种基于“故障”的审美创作，所以Glitch art也可以是看做是“美化故障”，或者通过“故障”完成审美活动的创作手段。 都有哪些科幻朋克？ 赛博朋克 蒸汽朋克( Steampunk)：齿轮、钟表、压力阀、护目镜、礼服、热气球、发条 /《爱死机》中的《狩猎愉快》——东方蒸汽朋克/ 柴油朋克(Dieselpunk)：二战、神秘主义、柴油动力、钢铁、管道、废土与后启示录背景、炮塔 原子朋克(Atompunk)：冷战、原子技术、喷气技术和太空技术、核动力（核动力坦克、核动力火车）、共产主义苏维埃和未来主义建筑 真空管朋克(晶体管朋克)(Transistorpunk)：冷战、特定的60年代美式审美风格、镀铬技术、真空管、二代计算机、原子能 /Rick’s Portal Gun…？/ 生物朋克(Biopunk) 纳米朋克(Nanopunk) 其他：万物皆可朋克，Nowpunk、Solarpunk…. 到带有奇幻色彩的 Elfpunk、Mythpunk @ref: Cyberpunk 衍生物 - Wikipedia 科幻朋克大盘点 - 知乎 （一）原子朋克冷战为背景，原子能及火箭技术发展为科技基础的美学形式及复古未来主义。原子朋克风格下的世界，核能技术得到高度发展与应用，人们的生活条件逐渐向好，建筑、服饰、交通工具等要素色彩鲜艳且视觉上十分干净，只是战争与毁灭的威胁时刻存在，社会结构普遍呈现出极端化的反乌托邦风格。 50、60年代对未来交通方式和载具的想象： 电影：《潜行者》（Сталкер），1979 ，塔可夫斯基，其蓝本为前苏联科幻作家斯特鲁伽茨基兄弟创作的原著小说《路边野餐》 游戏：《原子之心》（Atomic Heart）：设定在平行时空下20世纪50年代的苏联，二战期间开发出的机器人和其他先进技术帮助苏联走上巅峰。这是一个理想化的乌托邦世界：社会和谐，环境优美；城市井然有序，阳光洒落在公园和城镇广场；科技发达，日常生活充满自动化，人类向太空发起冲击……生活看似完美无瑕，符合我们当今世界的期望。但随着这个理想世界的阴暗面逐渐显现，苏联的未来会走向何方？ 建筑：The Presidium of Russian Academy of Sciences、the Palace of Soviet、Palace of Ceremonies… // @link: Arch.建筑（苏联） 相关： 藏在「原子朋克」中的拓荒精神 | 机核 GCORES Atompunk | Aesthetics Wiki | Fandom Steam 上的Atomic Heart 《新裤子 我们是自动的 》专辑MV （二）晶体管朋克@todo （三）蒸汽朋克@todo","categories":[{"name":"63.Culture-and-Arts","slug":"63-Culture-and-Arts","permalink":"https://beefyheisenberg.github.io/categories/63-Culture-and-Arts/"}],"tags":[{"name":"原子朋克","slug":"原子朋克","permalink":"https://beefyheisenberg.github.io/tags/原子朋克/"},{"name":"奇怪的东西","slug":"奇怪的东西","permalink":"https://beefyheisenberg.github.io/tags/奇怪的东西/"},{"name":"亚文化","slug":"亚文化","permalink":"https://beefyheisenberg.github.io/tags/亚文化/"},{"name":"复古未来主义","slug":"复古未来主义","permalink":"https://beefyheisenberg.github.io/tags/复古未来主义/"},{"name":"赛博朋克","slug":"赛博朋克","permalink":"https://beefyheisenberg.github.io/tags/赛博朋克/"},{"name":"蒸汽波","slug":"蒸汽波","permalink":"https://beefyheisenberg.github.io/tags/蒸汽波/"},{"name":"故障艺术","slug":"故障艺术","permalink":"https://beefyheisenberg.github.io/tags/故障艺术/"}]},{"title":"现代主义文学","slug":"63.Culture-and-Arts/现代主义文学","date":"2024-01-24T01:27:53.978Z","updated":"2024-01-24T01:27:53.978Z","comments":true,"path":"63.Culture-and-Arts/现代主义文学/","link":"","permalink":"https://beefyheisenberg.github.io/63.Culture-and-Arts/现代主义文学/","excerpt":"现代主义文学 https://baike.baidu.com/item/现代主义文学 魔幻现实: 魔幻现实主义是通过“魔法”所产生的幻景来表达生活现实的一种创作方法。魔幻是途径，表现生活现实是目的。用魔幻的东西将现实隐去，展示给读者的是一个循环往复的、主观时间和客观时间相混合、主客观事物的空间失去界限的世界。艺术上则在现实描绘中引入大量超自然因素，奇迹、幻觉、梦境甚至鬼魂形象出现于小说情节中，时序关系常被打乱，叙述富于跳跃性，有时场面带有象征色彩，显示出鲜明的地狱和民族特点。它堪称是“移植”和“寻根”相结合的成功范例。它既是对现实的深刻开掘，又是对历史的严肃反思；既有对本大陆传统文化的寻本探源，又有对欧美现代主义的广泛吸收。 马尔克斯：《百年孤独》 超现实: 20年代兴起于法国，它由达达主义发展而来。1919达达派诗人：布勒东(创始人)发表了第一个《超现实主义宣言、阿拉贡（《共产党人》，社会主义现实主义作品，反法西斯）、艾吕雅。他们认为文学不是再现现实，而是要表现“超现实”，即由“梦幻与现实转化成的绝对现实”，是现实与非现实两种要素的统一物。在内容上为了描绘超现实，他们反对逻辑推理的思维活动，推崇潜意识和梦，甚至让文学成为梦幻、潜意识乃至精神错乱的产物。强调梦幻、贬斥理性，成为其美学的重要标志。他们主张写人的潜意识、梦境，写事物的巧合，并提出“自动写作法”来作为表现上述内容的创作方法。 象征主义: 象征主义具有鲜明的特征：创造病态的“美”；表现内心的“最高真实”；运用象征暗示；在幻觉中构筑意象；用音乐性来增加冥想效应。它发展了前期象征主义的艺术特点，反对肤浅的抒情和直露的说教，主张情与理的统一，通过象征暗示、意象隐喻、自由联想和语言的音乐性去表现理念世界的美和无限性。 叶芝：《驶向拜占庭》 英国T·S·艾略特：《荒原》（1922） 表现主义: 抽象化；变形；面具的运用；时空的真幻错杂；注重声光效果；象征和荒诞的手法。其理论纲领是“艺术是表现不是再现”，主张文学不应再现客观现实，而应表现人的主观精神和内在激情，表现透过表象所把握到的事物的本质，对事物外在形态的精确描绘毫无意义。其诗歌情绪炽烈、雄辩，追求力度，抒情方式夸张，常采用浓缩的诗句。戏剧和小说常采用抽象的象征手法表现深刻的哲理和主题。 卡夫卡： 《城堡》（1915）、《变形记》（1915） 意识流: 它以象征暗示、内心独白、自由联想等意识流的创作方法为主要特征，在本世纪20—30年代英、美、法等国形成一个颇为壮观的现代主义文学流派。意识流小说家所运用的艺术手法各有侧重，但艺术特征是共同的：“作家退出小说”；情节淡化；大量的内心独白和自由联想；时空交替和心理时间；象征暗示和对比联想；语言使用上的创新和变异。 爱尔兰的乔伊斯：《都柏林人》、《青年艺术家的肖像》 英国的伍尔芙：《墙上的斑点》、《到灯塔去》 法国的普鲁斯特：《追忆似水年华》 达达主义: 现代西方文艺流派。第一次世界大战期间产生于瑞士，1915年来自罗马尼亚的法国诗人斯当·查拉为首的艺术小集体，在苏黎世的咖啡馆里以随手翻到的词语“达达”命名，即是指纯粹出于偶然，没有任何意义，什么也不是。对文化传统、现实生活、艺术规律采取极端反叛的态度，反映了第一次世界大战期间欧洲青年一代中的一部分人的苦闷心理和寻找出路的状态。 存在主义: 存在主义文学在存在主义哲学基础上产生，它是以文学的形式宣传存在主义哲学思想。其特征是理性多于形象；核心是“存在先于本质”、“世界是荒谬的”，“人生是痛苦的和自由选择”，只有通过自由选择寻找生存之路。“荒谬”和“痛苦”是存在主义文学的基本主题。世界是荒谬的，人生是痛苦的，一方面描写资本主义世界的荒诞性，另一方面表现人的不幸与毁灭，以及孤独、失望、恐惧的思想情绪。 (文化中的)现代主义: 现代主义（Modernism） 解构主义: 解构主义","text":"现代主义文学 https://baike.baidu.com/item/现代主义文学 魔幻现实: 魔幻现实主义是通过“魔法”所产生的幻景来表达生活现实的一种创作方法。魔幻是途径，表现生活现实是目的。用魔幻的东西将现实隐去，展示给读者的是一个循环往复的、主观时间和客观时间相混合、主客观事物的空间失去界限的世界。艺术上则在现实描绘中引入大量超自然因素，奇迹、幻觉、梦境甚至鬼魂形象出现于小说情节中，时序关系常被打乱，叙述富于跳跃性，有时场面带有象征色彩，显示出鲜明的地狱和民族特点。它堪称是“移植”和“寻根”相结合的成功范例。它既是对现实的深刻开掘，又是对历史的严肃反思；既有对本大陆传统文化的寻本探源，又有对欧美现代主义的广泛吸收。 马尔克斯：《百年孤独》 超现实: 20年代兴起于法国，它由达达主义发展而来。1919达达派诗人：布勒东(创始人)发表了第一个《超现实主义宣言、阿拉贡（《共产党人》，社会主义现实主义作品，反法西斯）、艾吕雅。他们认为文学不是再现现实，而是要表现“超现实”，即由“梦幻与现实转化成的绝对现实”，是现实与非现实两种要素的统一物。在内容上为了描绘超现实，他们反对逻辑推理的思维活动，推崇潜意识和梦，甚至让文学成为梦幻、潜意识乃至精神错乱的产物。强调梦幻、贬斥理性，成为其美学的重要标志。他们主张写人的潜意识、梦境，写事物的巧合，并提出“自动写作法”来作为表现上述内容的创作方法。 象征主义: 象征主义具有鲜明的特征：创造病态的“美”；表现内心的“最高真实”；运用象征暗示；在幻觉中构筑意象；用音乐性来增加冥想效应。它发展了前期象征主义的艺术特点，反对肤浅的抒情和直露的说教，主张情与理的统一，通过象征暗示、意象隐喻、自由联想和语言的音乐性去表现理念世界的美和无限性。 叶芝：《驶向拜占庭》 英国T·S·艾略特：《荒原》（1922） 表现主义: 抽象化；变形；面具的运用；时空的真幻错杂；注重声光效果；象征和荒诞的手法。其理论纲领是“艺术是表现不是再现”，主张文学不应再现客观现实，而应表现人的主观精神和内在激情，表现透过表象所把握到的事物的本质，对事物外在形态的精确描绘毫无意义。其诗歌情绪炽烈、雄辩，追求力度，抒情方式夸张，常采用浓缩的诗句。戏剧和小说常采用抽象的象征手法表现深刻的哲理和主题。 卡夫卡： 《城堡》（1915）、《变形记》（1915） 意识流: 它以象征暗示、内心独白、自由联想等意识流的创作方法为主要特征，在本世纪20—30年代英、美、法等国形成一个颇为壮观的现代主义文学流派。意识流小说家所运用的艺术手法各有侧重，但艺术特征是共同的：“作家退出小说”；情节淡化；大量的内心独白和自由联想；时空交替和心理时间；象征暗示和对比联想；语言使用上的创新和变异。 爱尔兰的乔伊斯：《都柏林人》、《青年艺术家的肖像》 英国的伍尔芙：《墙上的斑点》、《到灯塔去》 法国的普鲁斯特：《追忆似水年华》 达达主义: 现代西方文艺流派。第一次世界大战期间产生于瑞士，1915年来自罗马尼亚的法国诗人斯当·查拉为首的艺术小集体，在苏黎世的咖啡馆里以随手翻到的词语“达达”命名，即是指纯粹出于偶然，没有任何意义，什么也不是。对文化传统、现实生活、艺术规律采取极端反叛的态度，反映了第一次世界大战期间欧洲青年一代中的一部分人的苦闷心理和寻找出路的状态。 存在主义: 存在主义文学在存在主义哲学基础上产生，它是以文学的形式宣传存在主义哲学思想。其特征是理性多于形象；核心是“存在先于本质”、“世界是荒谬的”，“人生是痛苦的和自由选择”，只有通过自由选择寻找生存之路。“荒谬”和“痛苦”是存在主义文学的基本主题。世界是荒谬的，人生是痛苦的，一方面描写资本主义世界的荒诞性，另一方面表现人的不幸与毁灭，以及孤独、失望、恐惧的思想情绪。 (文化中的)现代主义: 现代主义（Modernism） 解构主义: 解构主义","categories":[{"name":"63.Culture-and-Arts","slug":"63-Culture-and-Arts","permalink":"https://beefyheisenberg.github.io/categories/63-Culture-and-Arts/"}],"tags":[]},{"title":"现代主义(Modernism)","slug":"63.Culture-and-Arts/现代主义（Modernism）","date":"2024-01-24T01:27:53.974Z","updated":"2024-01-24T01:27:53.974Z","comments":true,"path":"63.Culture-and-Arts/现代主义（Modernism）/","link":"","permalink":"https://beefyheisenberg.github.io/63.Culture-and-Arts/现代主义（Modernism）/","excerpt":"","text":"现代主义与现代艺术 - 知乎 Live ＊什么是 Modernism （现代主义），现代主义与我们所说的「现代」有啥不同？ ＊现代主义都表现在哪几个方面？ ＊如何理解现代主义艺术的思想根基？佛洛依德＋尼采＝世界都疯了 ＊现代主义艺术的重要作品：毕加索，杜尚，波丘尼，未来主义里的「声音诗歌」 ＊人类走入后现代时期，怀疑主义中产生的当代艺术","categories":[{"name":"63.Culture-and-Arts","slug":"63-Culture-and-Arts","permalink":"https://beefyheisenberg.github.io/categories/63-Culture-and-Arts/"}],"tags":[]},{"title":"有趣的符号","slug":"63.Culture-and-Arts/有趣的符号","date":"2024-01-24T01:27:53.968Z","updated":"2024-01-24T01:27:53.969Z","comments":true,"path":"63.Culture-and-Arts/有趣的符号/","link":"","permalink":"https://beefyheisenberg.github.io/63.Culture-and-Arts/有趣的符号/","excerpt":"有趣的符号@inbox： 宗教神秘学符号扫盲 - 知乎 潘洛斯三角","text":"有趣的符号@inbox： 宗教神秘学符号扫盲 - 知乎 潘洛斯三角彭罗斯三角（Penrose triangle）是不可能物体中的一种。最早是由瑞典艺术家Oscar Reutersvärd在1934年制作。英国数学家罗杰·彭罗斯（Roger Penrose）及其父亲莱昂内尔·彭罗斯设计及推广，并在1958年2月份的《英国心理学月刊》（British Journal of Psychology）中发表，称之为“最纯粹形式的不可能”。 潘洛斯阶梯 莫比乌斯环(mobius)莫比乌斯带（德语：Möbiusband），又译梅比斯环、莫比乌斯环或麦比乌斯带，是一种只有一个面（表面）和一条边界的曲面，也是一种重要的拓扑学结构。它是由德国数学家、天文学家莫比乌斯和约翰·李斯丁在1858年独立发现的。这个结构可以用一个纸带旋转半圈再把两端粘上之后轻而易举地制作出来。事实上有两种不同的莫比乌斯带镜像，他们相互对称。如果把纸带顺时针旋转再粘贴，就会形成一个右手性的莫比乌斯带，反之亦类似。 克莱因瓶在数学领域中，克莱因瓶（德语：Kleinsche Flasche）是指一种无定向性的平面，比如二维平面，就没有“内部”和“外部”之分。克莱因瓶最初的概念提出是由德国数学家费利克斯·克莱因提出的。克莱因瓶和莫比乌斯带非常相像。 要想像克莱因瓶的结构，可先试想一个底部镂空的红酒瓶。现在延长其颈部，向外扭曲后伸进瓶子的内部，再与底部的洞相连接。 衔尾蛇@todo","categories":[{"name":"63.Culture-and-Arts","slug":"63-Culture-and-Arts","permalink":"https://beefyheisenberg.github.io/categories/63-Culture-and-Arts/"}],"tags":[{"name":"奇怪的东西","slug":"奇怪的东西","permalink":"https://beefyheisenberg.github.io/tags/奇怪的东西/"}]},{"title":"赛博朋克","slug":"63.Culture-and-Arts/赛博朋克","date":"2024-01-24T01:27:53.959Z","updated":"2024-01-24T01:27:53.959Z","comments":true,"path":"63.Culture-and-Arts/赛博朋克/","link":"","permalink":"https://beefyheisenberg.github.io/63.Culture-and-Arts/赛博朋克/","excerpt":"赛博朋克（Cyberpunk）是“控制论”（Cybernetics）与“朋克”（Punk）的结合词，以信息技术为主体的科幻故事之分支。故事背景大都建立于“低端生活与高等科技的结合”（combination of low-life and high tech），通常拥有先进的科技，再与一定程度崩坏的社会结构做对比；剧情框架通常关于社会秩序受到某财团或秘密组织的高度控制，而角色利用其中的漏洞做出了某种突破。 赛博朋克很大程度上诞生于1960至1970年代的新浪潮科幻运动。当时的菲利普·狄克、罗杰·泽拉兹尼、J·G·巴拉德、菲利普·荷塞·法默和哈兰·艾里森等作家回避了早期科幻小说的乌托邦倾向，尝试描绘一个在毒品文化、科技以及性革命的冲击下所带来的新世界。 简单地说，赛博朋克就是一个拥挤、阴暗、冰冷但技术发达的反乌托邦。定下这一系列调性的，是小说家威廉·吉布森在1984年创作的那本被誉为“赛博朋克圣经”的《神经漫游者》。 赛博朋克的情节通常以人工智能、黑客和巨型企业有关的冲突为主轴。场景倾向设在地球上不远的未来，设定通常是后工业的反乌托邦。赛博朋克的风格主线，就是反映出科技高度发展的人类文明，与脆弱渺小的人类个体之间的强烈反差。 “待人如待鼠，所有对鼠的措施都可以同等地施加给人。闭上眼拒绝思考并不能使这个惨不忍睹的画面消失。这就是赛博朋克。”「布鲁斯·斯特林」","text":"赛博朋克（Cyberpunk）是“控制论”（Cybernetics）与“朋克”（Punk）的结合词，以信息技术为主体的科幻故事之分支。故事背景大都建立于“低端生活与高等科技的结合”（combination of low-life and high tech），通常拥有先进的科技，再与一定程度崩坏的社会结构做对比；剧情框架通常关于社会秩序受到某财团或秘密组织的高度控制，而角色利用其中的漏洞做出了某种突破。 赛博朋克很大程度上诞生于1960至1970年代的新浪潮科幻运动。当时的菲利普·狄克、罗杰·泽拉兹尼、J·G·巴拉德、菲利普·荷塞·法默和哈兰·艾里森等作家回避了早期科幻小说的乌托邦倾向，尝试描绘一个在毒品文化、科技以及性革命的冲击下所带来的新世界。 简单地说，赛博朋克就是一个拥挤、阴暗、冰冷但技术发达的反乌托邦。定下这一系列调性的，是小说家威廉·吉布森在1984年创作的那本被誉为“赛博朋克圣经”的《神经漫游者》。 赛博朋克的情节通常以人工智能、黑客和巨型企业有关的冲突为主轴。场景倾向设在地球上不远的未来，设定通常是后工业的反乌托邦。赛博朋克的风格主线，就是反映出科技高度发展的人类文明，与脆弱渺小的人类个体之间的强烈反差。 “待人如待鼠，所有对鼠的措施都可以同等地施加给人。闭上眼拒绝思考并不能使这个惨不忍睹的画面消失。这就是赛博朋克。”「布鲁斯·斯特林」 在赛博朋克文学中，大多故事发生在网络上、数码空间中。现实和虚拟现实之间的界线很模糊。此流派经常使用人脑和电脑的直接连接。赛博朋克文学有着强烈的反乌托邦和悲观主义色彩。他们通常将视角放在未来科技高度发达的大时代下底层小人物上，描写太平盛世表象下社会的腐朽与人性的堕落，对未来做出悲观的预言。但也是在这阴暗的角落将会诞生怀有希望的英雄。 文学 &amp; 影视作品 1984年威廉·吉布森发表的代表性处女作《神经漫游者》，吸取了朋克文化和早期的黑客文化，确认了赛博朋克的作为一门科幻类别的地位。 1982年大友克洋的系列漫画《亚基拉》，其后1988年改编成的动漫电影使得这门科幻类别普及开来。 电影《攻壳机动队》（2017年3月，改编自日本漫画家士郎正宗于1989年首次连载的日本漫画作品） 电影《银翼杀手2049》（2017年，对应1982年原版电影的续集） 电影《阿丽塔：战斗天使》（2019年，改编自1990年发布的同名日本漫画） 电子游戏《赛博朋克2077》（2020年，改编自R. Talsorian Games于1988年发布的同名桌面角色扮演游戏） 赛博朋克的中常见元素 数字空间（cyberspace），指的是哲学和电脑领域中的一个抽象概念。最先由科幻小说家威廉·吉布森在《全息玫瑰碎片》里提出，并且得以在《神经漫游者》里得到细化丰富，如黑客空间中的矩阵世界便是一个很经典的例子。 虚拟现实，是利用电脑模拟产生一个三维空间的虚拟世界，提供用户关于视觉等感官的模拟，让用户感觉仿佛身历其境，可以即时、没有限制地观察三维空间内的事物。 人工智能（Artificial Intelligence） 控制论（Cybernetics）与仿生人（Androids）：控制论是探索调节系统的跨学科研究， 它用于研究控制系统的结构、局限和发展。这一论说的提出者，美国电子工程专家诺伯特·维纳在1948年将控制论定义为“以机器中的控制与调节原理、以及将其类比到生物体或社会组织体后的控制原理为对象的科学研究。” 换句话说，这是关于人、动物和机器如何相互控制和通信的科学研究。仿生人（Androids）是一种旨在模仿人类外观和行为的机器人（robot），尤其特指具有和人类相似肌体的种类。 半机器人——赛博格（英文：Cyborg），也就是义体人类、生化电子人，用机械替换人体的一部分、联接大脑与机械的赛博格系统。不同于仿生学、生物机器人或仿生人。通常这样做的目的是借由人工科技来增加或强化生物体的能力。比如为自己替换一双电子眼以达到超强视力、为自己更换一双机械臂以增强力量的人群都可以算作是生化人。 超大型企业（Megacorporation），这些公司通常实力雄厚到能够左右一整个国家的命运。高等科技导致财富和武力流向科技型寡头企业，社会群落不再以国家和地区划分，而是全都笼罩在由信息技术控制的巨大网络之下。 亚洲元素，很奇妙的是，赛博朋克故事都发生在亚洲。相对性地来说，每个人对不熟悉的文明会因为好奇而显得有趣，《银翼杀手2049》里的城市就是根据日本涩谷来建模的。 贫民窟和都市，已经拆掉的九龙城寨据说是所有赛博朋克迷和创作者心中的圣地。0.026平方公里的空间里挤了4万人，相当于每个人的居住面积只有一张床这么大。然而在九龙城寨的不远处就是繁华的维港以及停满了波音747的启德机场，两者交织在一起碰撞出一种神奇的美感。 赛博朋克的魅力赛博朋克的精神内核是基于人类进化新形态的哲学思考，以及对社会未来的悲观预见。 “赛博意象可以提示一条走出二元论——我们以此来向自己解释自己的身体和工具——的迷宫的途径。这是一个关于有力的异端异质语言，而不是关于一种共同语言的梦想，这意味建构和破坏机器、身份、范畴、关系、空间、故事。“「多娜·哈尔威」它的迷人之处在于它具有社会学意义和哲学意义，这样有深度和广度的世界观，还和人类本身息息相关，能产生强烈的精神共鸣。 赛博朋克、香港、九龙城香港为何成为赛博朋克的概念圣地？ 表——香港与赛博朋克在视觉特征上的契合 里——香港与赛博朋克在精神概念上的契合 一个猜想——对东方的好奇 @ref： 论香港为何成为赛博朋克的概念圣地——从《攻壳机动队》说起 - 知乎 探寻赛博朋克的视觉元素根源——解密“九龙城寨”-迷失攻略组 Noer - 哔哩哔哩","categories":[{"name":"63.Culture-and-Arts","slug":"63-Culture-and-Arts","permalink":"https://beefyheisenberg.github.io/categories/63-Culture-and-Arts/"}],"tags":[{"name":"亚文化","slug":"亚文化","permalink":"https://beefyheisenberg.github.io/tags/亚文化/"},{"name":"流行文化","slug":"流行文化","permalink":"https://beefyheisenberg.github.io/tags/流行文化/"},{"name":"赛博朋克","slug":"赛博朋克","permalink":"https://beefyheisenberg.github.io/tags/赛博朋克/"}]},{"title":"解构主义","slug":"63.Culture-and-Arts/解构主义","date":"2024-01-24T01:27:53.954Z","updated":"2024-01-24T01:27:53.954Z","comments":true,"path":"63.Culture-and-Arts/解构主义/","link":"","permalink":"https://beefyheisenberg.github.io/63.Culture-and-Arts/解构主义/","excerpt":"解构主义 - 维基百科，自由的百科全书 如何简单地理解与区分解构主义与结构主义？ - Partfolio的回答 - 知乎https://www.zhihu.com/question/19631505/answer/906425529 要了解结构主义，我们首先要知道它反对的是什么—-即“结构主义”。上世纪中期的法国，形成了一股结构主义（Constructionsim）潮流。结构主义的共同倾向在于试图把我研究对象的内在逻辑结构，从深层的结构分析中找出对象的意义。通俗的来说，就是将一切事物总结和归类，并为之确定一个中心。 解构在后现代的语境中实际上已经逐渐被通俗化为反对先有的一切框架并在此基础上提出质疑的一种方法论和批判精神，同时他的核心也在于反对二元对立论，这也是为什么解构能在服装设计和各个领域如此受追捧的原因。","text":"解构主义 - 维基百科，自由的百科全书 如何简单地理解与区分解构主义与结构主义？ - Partfolio的回答 - 知乎https://www.zhihu.com/question/19631505/answer/906425529 要了解结构主义，我们首先要知道它反对的是什么—-即“结构主义”。上世纪中期的法国，形成了一股结构主义（Constructionsim）潮流。结构主义的共同倾向在于试图把我研究对象的内在逻辑结构，从深层的结构分析中找出对象的意义。通俗的来说，就是将一切事物总结和归类，并为之确定一个中心。 解构在后现代的语境中实际上已经逐渐被通俗化为反对先有的一切框架并在此基础上提出质疑的一种方法论和批判精神，同时他的核心也在于反对二元对立论，这也是为什么解构能在服装设计和各个领域如此受追捧的原因。 LGBTQ运动其实也是在逐渐解构性别二元对立论，让所有人都知道，这世界不仅只有男人和女人，也不是所有感情都是异性相吸。然而其实许多人误解了解构主义。“其实，解构主义不是一种新的建筑风格，也不是一种反建筑或社会的先锋运动。 它既不遵循“规则”，也不是为了获得特定的美学，又不是反对社会困境的反叛。 它是释放形式和体量的无限可能性。” 在解构主义的思想诞生的十几年后，就出现了以杜尚为代表的达达主义艺术流派。1915年到1922年一群艺术家，在瑞士集结，以一种无政府主义的，荒诞的，非理性的，自我主义的，杂乱无章的，反传统的，随意形式的表现形式，来反对世界大战的毫无意义的暴力，否定不可信的政府。 他们认为政府是不可信的，社会是不可信的，历史是不可信的，甚至语言也是不可信的。强调个人主义，虚无主义1，他们的诗歌没有语言，只有语气词；他们的艺术是用现成的产品贴出来的或者是印刷品。这就是达达—-它反对一切形式的权威，反对一切规律性的规律，唯一可以相信的就是恒变，随机性，调侃性是它的表现手法。其中的佼佼者杜尚展出了一件惊动整个世界的作品《泉》。 1.[[../61.Philosophy/13.虚无主义]] ↩","categories":[{"name":"63.Culture-and-Arts","slug":"63-Culture-and-Arts","permalink":"https://beefyheisenberg.github.io/categories/63-Culture-and-Arts/"}],"tags":[]},{"title":"绘画流派","slug":"63.Culture-and-Arts/绘画流派","date":"2024-01-24T01:27:53.949Z","updated":"2024-01-24T01:27:53.950Z","comments":true,"path":"63.Culture-and-Arts/绘画流派/","link":"","permalink":"https://beefyheisenberg.github.io/63.Culture-and-Arts/绘画流派/","excerpt":"","text":"▶ 印象派:https://zh.wikipedia.org/wiki/%E5%8D%B0%E8%B1%A1%E6%B4%BE印象派（法语：Impressionnisme），是指于1860年代法国开展的一种艺术运动或一种画风。印象派的命名源自于莫奈于1874年的画作《印象·日出》，遭到学院派的攻击，并被评论家路易·乐华挖苦是“印象派”（起源）。印象派画作常见的特色是笔触未经修饰而显见，构图宽广无边，尤其着重于光影的改变、对时间的印象，并以生活中的平凡事物做为描绘对象。著名的艺术家有莫内、马内、窦加、雷诺阿等，其中塞尚后开创了后印象派。","categories":[{"name":"63.Culture-and-Arts","slug":"63-Culture-and-Arts","permalink":"https://beefyheisenberg.github.io/categories/63-Culture-and-Arts/"}],"tags":[]},{"title":"蒸汽波","slug":"63.Culture-and-Arts/蒸汽波","date":"2024-01-24T01:27:53.945Z","updated":"2024-01-24T01:27:53.945Z","comments":true,"path":"63.Culture-and-Arts/蒸汽波/","link":"","permalink":"https://beefyheisenberg.github.io/63.Culture-and-Arts/蒸汽波/","excerpt":"What’s 蒸汽波(Vaporwave)蒸气波 - 维基百科，自由的百科全书 蒸气波（英语：Vaporwave）是一种电子音乐和视觉艺术类型，出现于2010年初的互联网社区，随后逐渐从网络模因发展成为了艺术运动。这类作品侧重于20世纪80年代、90年代的美国、日本流行文化元素，包括城市生活、购物中心、商业广告、电子游戏、科技和早期互联网等，也受到赛博朋克科幻的影响。其音乐大量使用同时代的沙发音乐、滑顺爵士乐、电梯音乐等商业音乐作为素材，进行采样和编辑。《Vice》的米歇尔·洛克（Michelle Lhooq）表示，即使蒸气波的素材来自“糟糕”、“垃圾”的商业音乐，但蒸气波并不是为了模仿或者重新创作商业音乐，而是把商业音乐变成“更性感”的合成音乐。参与者将蒸气波的风格称为“美学”，为了与自身风格一致，常使用全角字符写作ＡＥＳＴＨＥＴＩＣＳ。 蒸气波表现出了对资本主义、消费主义和全球化一种模棱两可的反思。一方面，有评论者认为蒸气波是反资本主义和反消费主义的，以反讽的手法对其进行批判；同时也有评论认为，蒸气波体现出对昔日繁荣社会的怀旧情怀，表现出复古未来主义。而个人电脑和影音娱乐等科技元素，唤起了人们的文化记忆，以及昔日乌托邦主义远景破灭的叹息；而《布鲁克林铁路》杂志的一篇评论则表示，蒸气波表达了对当下政治失败和社会异化的不满，但与朋克摇滚的那种“原始的能量”相比，蒸气波则侧重于被动的接受，表现出失落和委靡不振的情绪。","text":"What’s 蒸汽波(Vaporwave)蒸气波 - 维基百科，自由的百科全书 蒸气波（英语：Vaporwave）是一种电子音乐和视觉艺术类型，出现于2010年初的互联网社区，随后逐渐从网络模因发展成为了艺术运动。这类作品侧重于20世纪80年代、90年代的美国、日本流行文化元素，包括城市生活、购物中心、商业广告、电子游戏、科技和早期互联网等，也受到赛博朋克科幻的影响。其音乐大量使用同时代的沙发音乐、滑顺爵士乐、电梯音乐等商业音乐作为素材，进行采样和编辑。《Vice》的米歇尔·洛克（Michelle Lhooq）表示，即使蒸气波的素材来自“糟糕”、“垃圾”的商业音乐，但蒸气波并不是为了模仿或者重新创作商业音乐，而是把商业音乐变成“更性感”的合成音乐。参与者将蒸气波的风格称为“美学”，为了与自身风格一致，常使用全角字符写作ＡＥＳＴＨＥＴＩＣＳ。 蒸气波表现出了对资本主义、消费主义和全球化一种模棱两可的反思。一方面，有评论者认为蒸气波是反资本主义和反消费主义的，以反讽的手法对其进行批判；同时也有评论认为，蒸气波体现出对昔日繁荣社会的怀旧情怀，表现出复古未来主义。而个人电脑和影音娱乐等科技元素，唤起了人们的文化记忆，以及昔日乌托邦主义远景破灭的叹息；而《布鲁克林铁路》杂志的一篇评论则表示，蒸气波表达了对当下政治失败和社会异化的不满，但与朋克摇滚的那种“原始的能量”相比，蒸气波则侧重于被动的接受，表现出失落和委靡不振的情绪。 蒸汽波_百度百科：“是一种受cyberpunk文化影响很深的online microscenes” // @link: 赛博朋克 Vapor：水汽、水蒸气；无实质之物、自夸者；幻想；蒸汽浪潮。 Vaporwave兴起于2010年初期，2014~2015年几乎达到全盛时期，关于vaporwave的音乐创制和艺术作品开始崭露头角，已经衍生出一系列的子文化和周边产品，具有大量多样性和模糊性的亚风格类别和信息传达。vaporwave既是批评和讽刺后工业时代的消费主义社会，80年代的雅皮士文化，同时那种低保真音质和Album Art也展现出了好奇与迷恋的怀旧感。 在蒸汽波的元素中，运用最多的有：海豚、像素风、大卫等各种石膏像、故障艺术、椰子树、棕榈树、旧window弹窗、赛博朋克、绚丽的色彩、油漆桶色彩等复古视觉元素。 视觉元素蒸汽波与赛博朋克有什么关联？ - 知乎既然谈到关联，基本上就要往这种审美风格的文化内涵上靠拢了。 赛博朋克的文化内涵和背景是后资本主义时代。寡头经济，财富高度集中，形成永久性的财富阶级，科技超高但统治阶级漠视庞大的底层人的生活。硬要说的话，赛博朋克的审美元素是从北欧风，工业风上面一脉相承过来的。 蒸汽波是这个年代去怀念泡沫年代的一种符号。怀念的本体，其实是city pop风格，泡沫都市。但是因为有怀念这个过程在，city pop变得不再是最合适描述泡沫都市的风格了，而是蒸汽波。也就是说，city pop是那个年代的现在时，而蒸汽波是那个年代的过去时。个人对于审美风格的成因理解。因为思想过程会对审美元素进行适当加工和扭曲。 总的来说，赛博朋克是未来，而蒸汽波是过去。 这两种风格我都写了文章： 《审美2020》- 赛博朋克 - 蒸汽姬的文章 - 知乎 https://zhuanlan.zhihu.com/p/355480559 《审美2020》- 蒸汽波 - 蒸汽姬的文章 - 知乎 https://zhuanlan.zhihu.com/p/355480339 lofi，jazzhiphop，蒸汽波应该如何区分? - 知乎lofi指的是刻意去追求低音质，模拟磁带/低采样率/失真效果。jazz hip-hop和蒸汽波可以是lofi的，由于这二者采样的来源会有lofi的成分，有些选择把低音质的美学放大了而已；但lofi不尽然是以上两种，比如说outsider house（例子：Ross From Friends）。 jazz hip-hop，实际上就是指以爵士乐、放克、灵歌等等你听着就很黑人的音乐为主要采样源和音乐灵感的嘻哈音乐，是爵士和嘻哈的融合产物。素材上跟vaporwave有重合之处，但是蒸汽波可能还有city pop等等上世纪后期的流行曲风。并且，jazz hip-hop的形式还是嘻哈音乐，听节奏就听得出来。 vaporwave（蒸汽波）发展到现在，已经从一个网络梗变成一种美学了，而且主要是一种美学。其内核可以说是一种（虚幻的）怀旧，主要手法是对过去的流行事物进行放大，扭曲和拼贴。蒸汽波现在有很多种形式，比如融合了disco和house成分的future funk，还有放大了lounge成分的mallsoft，但总的来说其美学跟jazz hip-hop是不一致的。jazz hip-hop可能更偏向于一种流畅自由的感觉，可以有lofi的怀旧感，但不会直接指向某一个文化符号。蒸汽波则是怀旧、超现实感、城市文化记忆、消费主义、早期互联网、90年代资本主义世界、经典赛博朋克等一大团属于过去的幻觉的当代改造。也就是说，还是要多听。","categories":[{"name":"63.Culture-and-Arts","slug":"63-Culture-and-Arts","permalink":"https://beefyheisenberg.github.io/categories/63-Culture-and-Arts/"}],"tags":[{"name":"亚文化","slug":"亚文化","permalink":"https://beefyheisenberg.github.io/tags/亚文化/"},{"name":"流行文化","slug":"流行文化","permalink":"https://beefyheisenberg.github.io/tags/流行文化/"},{"name":"蒸汽波","slug":"蒸汽波","permalink":"https://beefyheisenberg.github.io/tags/蒸汽波/"},{"name":"大卫","slug":"大卫","permalink":"https://beefyheisenberg.github.io/tags/大卫/"},{"name":"日本","slug":"日本","permalink":"https://beefyheisenberg.github.io/tags/日本/"},{"name":"昭和时代","slug":"昭和时代","permalink":"https://beefyheisenberg.github.io/tags/昭和时代/"}]},{"title":"克苏鲁","slug":"63.Culture-and-Arts/克苏鲁","date":"2024-01-24T01:27:53.938Z","updated":"2024-01-24T01:27:53.939Z","comments":true,"path":"63.Culture-and-Arts/克苏鲁/","link":"","permalink":"https://beefyheisenberg.github.io/63.Culture-and-Arts/克苏鲁/","excerpt":"克苏鲁体系克苏鲁神话 - 维基百科，自由的百科全书：克苏鲁神话（英语：Cthulhu Mythos）是以霍华德·菲利普斯·洛夫克拉夫特的小说世界为基础，并由与他同时代的记者及门徒奥古斯特·威廉·德雷斯整理洛夫克拉夫特及其他作者的设定、思路创造的架空神话体系。其名克苏鲁来源于洛夫克拉夫特的短篇小说《克苏鲁的呼唤》，该文最初发表在1928年的《诡丽幻谭》上。 理查德·L·蒂尔尼后来提出了一个理论，将德雷斯神话与洛夫克拉夫特神话的作品区分开来，并建立了现代神话学的基调。被称为洛夫克拉夫特式恐怖的作品类型经常使用到克苏鲁神话的元素。 来自深海的呼唤——简述克苏鲁神话体系 - 知乎 什么是“克苏鲁式恐惧”？对克苏鲁神话体系的探讨与个人观点 | 机核 GCORES 如何写一篇克苏鲁风格的故事？ - 知乎 Dreamlands","text":"克苏鲁体系克苏鲁神话 - 维基百科，自由的百科全书：克苏鲁神话（英语：Cthulhu Mythos）是以霍华德·菲利普斯·洛夫克拉夫特的小说世界为基础，并由与他同时代的记者及门徒奥古斯特·威廉·德雷斯整理洛夫克拉夫特及其他作者的设定、思路创造的架空神话体系。其名克苏鲁来源于洛夫克拉夫特的短篇小说《克苏鲁的呼唤》，该文最初发表在1928年的《诡丽幻谭》上。 理查德·L·蒂尔尼后来提出了一个理论，将德雷斯神话与洛夫克拉夫特神话的作品区分开来，并建立了现代神话学的基调。被称为洛夫克拉夫特式恐怖的作品类型经常使用到克苏鲁神话的元素。 来自深海的呼唤——简述克苏鲁神话体系 - 知乎 什么是“克苏鲁式恐惧”？对克苏鲁神话体系的探讨与个人观点 | 机核 GCORES 如何写一篇克苏鲁风格的故事？ - 知乎 Dreamlands幻梦境（Dreamlands、Dream Cycle）是由霍华德·菲利普·洛夫克拉夫特所创作的一系列幻想小说中的虚构世界[1]。其重要的构成元素在其发表于1926年的长篇小说《梦寻秘境卡达斯》有详细的描写 幻梦境 - 维基百科，自由的百科全书 克苏鲁神话观光指南，幻梦境_哔哩哔哩_bilibili 克苏鲁世界导游：幻梦境 | 克苏鲁公社 伦道夫·卡特洛夫克拉夫特的作品中登场的虚构人物，于《伦道夫·卡特的供述》首次登场。此角色有不少特质都与作者洛夫克拉夫特十分近似，故被认为原型就是洛夫克拉夫特本人。","categories":[{"name":"63.Culture-and-Arts","slug":"63-Culture-and-Arts","permalink":"https://beefyheisenberg.github.io/categories/63-Culture-and-Arts/"}],"tags":[{"name":"奇怪的东西","slug":"奇怪的东西","permalink":"https://beefyheisenberg.github.io/tags/奇怪的东西/"},{"name":"克苏鲁","slug":"克苏鲁","permalink":"https://beefyheisenberg.github.io/tags/克苏鲁/"},{"name":"亚文化","slug":"亚文化","permalink":"https://beefyheisenberg.github.io/tags/亚文化/"}]},{"title":"希腊神话-缪斯","slug":"63.Culture-and-Arts/缪斯","date":"2024-01-24T01:27:53.933Z","updated":"2024-01-24T01:27:53.933Z","comments":true,"path":"63.Culture-and-Arts/缪斯/","link":"","permalink":"https://beefyheisenberg.github.io/63.Culture-and-Arts/缪斯/","excerpt":"缪斯是希腊神话主司艺术与科学的九位古老文艺女神的总称。她们代表了通过传统的音乐和舞蹈、即时代流传下来的诗歌所表达出来的神话传说。她们原本是守护赫利孔山泉水的水仙，属于宁芙的范畴。后来人们将奥林匹斯神系的阿波罗设立为她们的首领。缪斯女神常常出现在众神或英雄们的聚会，轻歌曼舞，一展风采，为聚会带来不少的愉悦与欢乐。 缪斯即是艺术的代表，也是艺术本身（英语中music，音乐，一词来自缪斯）。在希腊人掌握文字以前，缪斯也是学习的代表和神。泰勒斯所写的第一本希腊的天文学书籍就是以诗的体裁写的，许多苏格拉底以前的哲学书的体裁也是诗体。柏拉图和毕达哥拉斯都认为哲学是艺术（μουσική）的一部分。希罗多德将他写的《历史》的每一卷以一个不同的缪斯命名。 在文学作品中，缪斯常常是叙述者的身份，而作者本人不过是记录者。赫西俄德（Hesiod）被称为“希腊训谕诗之父”，他经常去缪斯的居住地赫利孔山（Helicon），他称有一天放羊时，缪斯给予他写诗的本领，告诉他诸神的故事，于是他写下了《神谱》。 根据《神谱》，缪斯是宙斯与记忆女神谟涅摩叙涅（Mnemosyne）的九个发束金带的女儿。她们最开始是赫利孔山的泉水仙女，有一匹长有双翼的白马相伴，这匹马是马神珀伽索斯（Pegasus），为美杜莎与海神波塞冬所生。据说当珀伽索斯踏过赫利孔山的土地时，圣泉喷涌而出，其中一眼是希波克里尼灵感泉（Hippocrene），可使饮用之人写出美妙的诗句。","text":"缪斯是希腊神话主司艺术与科学的九位古老文艺女神的总称。她们代表了通过传统的音乐和舞蹈、即时代流传下来的诗歌所表达出来的神话传说。她们原本是守护赫利孔山泉水的水仙，属于宁芙的范畴。后来人们将奥林匹斯神系的阿波罗设立为她们的首领。缪斯女神常常出现在众神或英雄们的聚会，轻歌曼舞，一展风采，为聚会带来不少的愉悦与欢乐。 缪斯即是艺术的代表，也是艺术本身（英语中music，音乐，一词来自缪斯）。在希腊人掌握文字以前，缪斯也是学习的代表和神。泰勒斯所写的第一本希腊的天文学书籍就是以诗的体裁写的，许多苏格拉底以前的哲学书的体裁也是诗体。柏拉图和毕达哥拉斯都认为哲学是艺术（μουσική）的一部分。希罗多德将他写的《历史》的每一卷以一个不同的缪斯命名。 在文学作品中，缪斯常常是叙述者的身份，而作者本人不过是记录者。赫西俄德（Hesiod）被称为“希腊训谕诗之父”，他经常去缪斯的居住地赫利孔山（Helicon），他称有一天放羊时，缪斯给予他写诗的本领，告诉他诸神的故事，于是他写下了《神谱》。 根据《神谱》，缪斯是宙斯与记忆女神谟涅摩叙涅（Mnemosyne）的九个发束金带的女儿。她们最开始是赫利孔山的泉水仙女，有一匹长有双翼的白马相伴，这匹马是马神珀伽索斯（Pegasus），为美杜莎与海神波塞冬所生。据说当珀伽索斯踏过赫利孔山的土地时，圣泉喷涌而出，其中一眼是希波克里尼灵感泉（Hippocrene），可使饮用之人写出美妙的诗句。 缪斯能歌善舞，其后代也都继承了艺术天赋，擅弹七弦琴的俄耳甫斯和歌声美妙的海妖塞壬都是缪斯的子女。塞壬曾与缪斯进行歌唱比赛，最终塞壬惨败，被缪斯拔光了羽毛，从而失去了翅膀无法飞翔，缪斯用塞壬的翅膀编织成了象征自己胜利的王冠。此外，还有一位叫塔米里斯（Thamyris）的歌手向缪斯发起歌唱挑战落败，缪斯惩罚他的狂傲使他失明，还收回他写诗和弹奏七弦琴的才华，可见人类的才华都是缪斯赐予的，她可以给予，也可以收回。 Muses vs. Sirens： Marble sarcophagus with the contest between the Muses and the Sirens, 3rd quarter of 3rd century A.D. Roman. Marble, Pentelic, 21 3/4 x 77 1/4 x 22 1/2 in. (55.3 x 196.2 x 57.2 cm). The Metropolitan Museum of Art, New York, Purchase, Rogers Fund, 1910 (10.104) 古希腊有很多神殿供诗人向缪斯祈求灵感，神庙中陈列着与缪斯相关的艺术品，这就是博物馆（museum）的起源。英语单词museum由muse（缪斯）和表示“场所”的后缀-um组成，本意就是“缪斯的神殿”。此外，英语单词music（音乐）和mosaic（马赛克）也来自缪斯，本意分别是“art of the Muses”（缪斯的艺术）和“work of the Muses”（缪斯的作品）。 关于缪斯的人数有众多说法，最早只有三位缪斯，是三位一体的老一辈诗歌女神，但比较经典常见的说法还是九位，九位缪斯女神司管着不同领域，艺术作品中的形象各不相同。 @ref: https://zhuanlan.zhihu.com/p/359919585 缪斯（文艺） - 涅墨西斯（复仇）- 摩伊赖（命运） - 比亚（暴力） - 克拉托斯（力量） - 厄洛斯（爱）- 忒弥斯（正义） - 墨提斯（智慧） - 塔那托斯（死亡） - 许普诺斯（睡眠） @link: [[../64.Novel-and-Poesy/R02.阿赫玛托娃]] / 致缪斯","categories":[{"name":"63.Culture-and-Arts","slug":"63-Culture-and-Arts","permalink":"https://beefyheisenberg.github.io/categories/63-Culture-and-Arts/"}],"tags":[{"name":"希腊神话","slug":"希腊神话","permalink":"https://beefyheisenberg.github.io/tags/希腊神话/"}]},{"title":"SCP","slug":"63.Culture-and-Arts/SCP","date":"2024-01-24T01:27:53.929Z","updated":"2024-01-24T01:27:53.929Z","comments":true,"path":"63.Culture-and-Arts/SCP/","link":"","permalink":"https://beefyheisenberg.github.io/63.Culture-and-Arts/SCP/","excerpt":"SCP基金会是一个虚构的特工组织，作为同名互联网接龙小说创作项目中的主要要素。在该虚构宇宙中，SCP基金会是一个跨国秘密组织，负责搜寻并收容各种具有异常属性的个体、地点或物体（统称为“异常”），其宗旨为“控制”（Secure），“收容”（Contain），“保护”（Protect）。在现实世界中，SCP基金会是一个基于网站社区的协同写作小说项目，其文章包含多种类型的元素和风格，如科学幻想、都市奇幻和恐怖小说。 YouTube上的SCP介绍：SCP Explained - Story &amp; Animation - YouTube 机核网-SCP故事集：素未谋面的无数作者共同创作的神秘组织：SCP 基金会专题 | 机核 GCORES","text":"SCP基金会是一个虚构的特工组织，作为同名互联网接龙小说创作项目中的主要要素。在该虚构宇宙中，SCP基金会是一个跨国秘密组织，负责搜寻并收容各种具有异常属性的个体、地点或物体（统称为“异常”），其宗旨为“控制”（Secure），“收容”（Contain），“保护”（Protect）。在现实世界中，SCP基金会是一个基于网站社区的协同写作小说项目，其文章包含多种类型的元素和风格，如科学幻想、都市奇幻和恐怖小说。 YouTube上的SCP介绍：SCP Explained - Story &amp; Animation - YouTube 机核网-SCP故事集：素未谋面的无数作者共同创作的神秘组织：SCP 基金会专题 | 机核 GCORES 影视作品： SCP: OVERLORD - YouTube：Overlord is a 2020 short film directed by Stephen Hancock and written by Evan Murr set within the SCP Foundation lore SCP: OVERLORD | Behind the Scenes - YouTube：幕后花絮 SCP: Dollhouse - YouTube 起源2007年，一个ID为“Moto42”的网友在美国匿名论坛4chan上发布了一篇帖子，以机密档案的形式虚构了SCP基金会这个组织，并添加了SCP的第一篇档案：SCP-173。这篇档案描述了一个危险神秘生物…… @ref: SCP：一个去中心化的文学故事 - 雪球","categories":[{"name":"63.Culture-and-Arts","slug":"63-Culture-and-Arts","permalink":"https://beefyheisenberg.github.io/categories/63-Culture-and-Arts/"}],"tags":[{"name":"奇怪的东西","slug":"奇怪的东西","permalink":"https://beefyheisenberg.github.io/tags/奇怪的东西/"}]},{"title":"EDC","slug":"63.Culture-and-Arts/EDC","date":"2024-01-24T01:27:53.925Z","updated":"2024-01-24T01:27:53.925Z","comments":true,"path":"63.Culture-and-Arts/EDC/","link":"","permalink":"https://beefyheisenberg.github.io/63.Culture-and-Arts/EDC/","excerpt":"","text":"@ref： EDC变迁史：从生存工具到手机一统江湖 | 机核 GCORES EDC，即Everyday Carry，指那些需要我们每天携带的装备。就算你没听过这个缩写，也一定在社交网络上看过那种把手机、太阳镜、钱包等包内物品整齐摆在桌面上的俯拍照片。早期的EDC更多指代一些实用的随身工具，但观察近几年社交网络上的分享你会发现，如今的EDC基本上变成了“手机+其他”的组合，而这个“其他”，也越来越多地变成了手机的附属品，比如充电器、移动电源、无线耳机等。由于智能手机和移动互联网的普及，手机已经成为这个时代最成功的EDC。与此同时，手机对其他工具的消化和整合，也正在让EDC的概念变得单一，甚至接近消亡。 EDC的概念随着社交网络的普及而变得流行起来，但它的内核最早可以追溯到冷战时期。早期的EDC，形式上更像是一种“求生包”。冷战下的不安全感，催生了一批生存主义者（survivalists）。这些人希望通过提早准备生存装备和提升个人生存能力来增加自己在危机环境下的存活率。他们对刀具、绳索和手电等生存装备进行了深入研究，期望组合出最合理的求生包，便于在危机时刻能够随身携带。","categories":[{"name":"63.Culture-and-Arts","slug":"63-Culture-and-Arts","permalink":"https://beefyheisenberg.github.io/categories/63-Culture-and-Arts/"}],"tags":[{"name":"奇怪的东西","slug":"奇怪的东西","permalink":"https://beefyheisenberg.github.io/tags/奇怪的东西/"}]},{"title":"City Walk / Urban Walk","slug":"63.Culture-and-Arts/City Walk","date":"2024-01-24T01:27:53.920Z","updated":"2024-01-24T01:27:53.921Z","comments":true,"path":"63.Culture-and-Arts/City Walk/","link":"","permalink":"https://beefyheisenberg.github.io/63.Culture-and-Arts/City Walk/","excerpt":"==参考：与我同行：日常的构成 -《WALK WITH ME: COMPOSITION OF THE ORDINARY》, Petra Johnson[Germany]== 链接：(PDF) 城市研究 Urban Studies 与我同行:日常的构成 walk with me: Composition of the ordinary 佩雀[德国] Petra Johnson[Germany] 情感(Affect),是用来描述一种好奇的体验以及随之而来的能量。“情感是一种紧张气氛,一种敬畏、或兴奋、或平静的情绪,”人类地理学家约翰怀利(JohnWylie)这样写道。我们对日常环境的体验是真实的吗?空间激发了我们怎样的情绪? 与佩雀·约翰逊同行,重新发现习以为常的日常空间。这是佩雀在几个生活过的国家—德国、英国和中国—城市里进行的一个行为艺术项目。走路探索城市、本地人与陌生人之间的对话、地图的绘制,采用这些方法来挑战大众心理对环境已有的认知,激发新的情绪。这些项目成为一系列平台,承载日常空间带来的共情体验。随着越来越多的人参与同行,新的元素加入进来,走路产生了新的场所与形态。 于是，这个女孩通过与其同行的陌生人，实际上重新认识了这条她熟悉的路线。这样的一种体验让我想起舞蹈家乔纳森阿佩尔的描述，她认为这世界是“我的认知和其他人的认知的综合”。","text":"==参考：与我同行：日常的构成 -《WALK WITH ME: COMPOSITION OF THE ORDINARY》, Petra Johnson[Germany]== 链接：(PDF) 城市研究 Urban Studies 与我同行:日常的构成 walk with me: Composition of the ordinary 佩雀[德国] Petra Johnson[Germany] 情感(Affect),是用来描述一种好奇的体验以及随之而来的能量。“情感是一种紧张气氛,一种敬畏、或兴奋、或平静的情绪,”人类地理学家约翰怀利(JohnWylie)这样写道。我们对日常环境的体验是真实的吗?空间激发了我们怎样的情绪? 与佩雀·约翰逊同行,重新发现习以为常的日常空间。这是佩雀在几个生活过的国家—德国、英国和中国—城市里进行的一个行为艺术项目。走路探索城市、本地人与陌生人之间的对话、地图的绘制,采用这些方法来挑战大众心理对环境已有的认知,激发新的情绪。这些项目成为一系列平台,承载日常空间带来的共情体验。随着越来越多的人参与同行,新的元素加入进来,走路产生了新的场所与形态。 于是，这个女孩通过与其同行的陌生人，实际上重新认识了这条她熟悉的路线。这样的一种体验让我想起舞蹈家乔纳森阿佩尔的描述，她认为这世界是“我的认知和其他人的认知的综合”。 需要一种介质来重现这种体验，这一介质正是“分歧”（Divergence）。于连认为，分歧并非来自于身份的差别，而是在丧失了语言和多元性之后的有限空间（Liminal Space）。 在 2002 年到 2006 年间我来到中国工作和生活。在这里，我开始不断重复地走一条固定的路线。我完全无法理解中文，但这却解放了我的视线。在行走的过程中，我的眼睛自由地在窗台上、凹凸不平的地面上、干裂的土壤上漂移。我的耳朵识别了一些熟悉的音效，那是我在伯明翰听现代派音乐时曾经听到过的单调的声音—我人生中第一次听见了平凡马路上人们日常生活产生的声音。 我在日常生活中发现了复杂的声调光谱。这样的体验就构成了完成我艺术品的新介质。此外我还体会到了一种强烈的矛盾，我过去从媒体中被动获得的对中国的认知与我的亲眼所见之间存在如此巨大的鸿沟。当进入这种分歧的状态后，观察事物的角度就从一种“迥异的状态”转变为“保持距离”，于是“日常”就在我心中激发了好奇、敬畏和平静：也就是所谓的情感（Affect） 于是我问自己：如何制造产生这种情感的环境呢？ 后来我又自学了社会雕塑的技法，尝试了非物质的融入形态，比如“主动倾听”、“密切跟踪”以及“内外世界之连接”等等。 我首先定义了三种行走的形式：觅食、游行及漫步。我从每个形式中汲取一个方面，形成一种设计方法论，让我的项目拥有三重要素：一，路径中散布着等距的插入点；二，不断出现的提示；三，静止点，或岛屿。 路径和插入点。我首先在谷歌地图上找到一条路径，然后自己先去尝试行走。我靠着直觉、好奇以及当地人的建议漫步，这样一来，一条充满生气的道路就变成了我的共同作者。我要首先熟悉路线，并将行走时间控制在 60 分钟（只有科隆是 70 分钟），估计好了距离之后，我把这些距离等分成 15 分，然后在其中定下 14 个点。在我的行走项目中，插入点的设置就启发了很多不可预期的对话。 因为过去背井离乡的经历，我学会了一种如何在陌生环境里自处的技能，通过每天完成一个小任务的方式，我在新环境里漫步，找到可以用一句话概括的情感。 我的同伴会写下他们观察到的东西然后撕下那一页，交回给我，然后我给出第二个纸条。这些提示按照以下的次序被交到同伴手中。这些提示来自于斯图尔特的文章“日常的情感 ”。 1，日常的构成。观察一个日常行为：谁在做什么？2，列出一个不安的瞬间；3 ，观察一项善意的行为；4，你觉得在哪里感到不自在？5，记下一些不太正确的事情；6，观察一下聚集的人群：他们在做什么？7，记录正在产生的欲望；8，描述一个你看见的正在等待的人；9，如何判断今天是星期几？10，感受距离：下一个“岛屿”在哪里？11，你有点累了感到需要休息，有什么回应了你的需求？12 ，你正要遭遇的人里面，你比较认同哪个 ？13，在你的认知和感受之间存在某种差异，能指出一项吗？14，指出一个令你不安/兴奋的瞬间；15，描述一个焦虑的瞬间。 静止点和岛屿。尽管插入点和静止点在“与我同行”中重合，但他们实际上代表了场所的不同特征。静物或岛屿是在空间中感受到的特定场所，而插入点是在时间中感受。 结论一直以来，我的研究目标是为了微调人们对某件事情的共同认知。对于那些我们参与其中的事件，我需要创造一个能够再次呈现该事件的过程，并以此来反思我们的价值观。我使用的材料是情感和经验。 @link: [[../54.Trips-and-Exploration/CN.上海#徒步路线]]","categories":[{"name":"63.Culture-and-Arts","slug":"63-Culture-and-Arts","permalink":"https://beefyheisenberg.github.io/categories/63-Culture-and-Arts/"}],"tags":[]},{"title":"北京建筑上的大屋顶","slug":"63.Culture-and-Arts/Arch.北京建筑上的大屋顶","date":"2024-01-24T01:27:53.915Z","updated":"2024-01-24T01:27:53.916Z","comments":true,"path":"63.Culture-and-Arts/Arch.北京建筑上的大屋顶/","link":"","permalink":"https://beefyheisenberg.github.io/63.Culture-and-Arts/Arch.北京建筑上的大屋顶/","excerpt":"为什么北京很多房子上，总要加个这样的「大屋顶」？ - 知乎/这算不算一种“反-批判地域性主义”？@link: Arch.批判地域性主义/ 1895 年甲午战争战败之后，清廷上下积极提倡洋化。清末所有的衙署都建成了西洋风格，民间在 1900 年后建的商业铺面也都热衷西洋装饰。 中式传统民居更是被贬得一无是处。1905 年《汉口日报》一篇文章将中西住房做了一番对比称：「（中国民居）入其室则黑暗世界；而西人洋楼高矗，窗闼洞开，足以收纳空气……比之华民住屋，真有天堂地狱之分。」","text":"为什么北京很多房子上，总要加个这样的「大屋顶」？ - 知乎/这算不算一种“反-批判地域性主义”？@link: Arch.批判地域性主义/ 1895 年甲午战争战败之后，清廷上下积极提倡洋化。清末所有的衙署都建成了西洋风格，民间在 1900 年后建的商业铺面也都热衷西洋装饰。 中式传统民居更是被贬得一无是处。1905 年《汉口日报》一篇文章将中西住房做了一番对比称：「（中国民居）入其室则黑暗世界；而西人洋楼高矗，窗闼洞开，足以收纳空气……比之华民住屋，真有天堂地狱之分。」 这种情况并没有持续太久。中式民居虽然永堕「地狱」，但殿堂式建筑的「大屋顶」不久就时来运转，第一次世界大战爆发后，中国人在战火连天的欧洲面前重拾自信，社会精英们脱下西服，换回了长衫马褂。 中国人民的文化自信，很快刮到了建筑领域。 1930 年前后，国民政府定都南京后，在建筑上大力推崇「中国固有之形式」，给西式建筑增加中式大屋顶的重任，也就交到了中国建筑师手里。 直到抗战爆发前，国民政府主持修造了中山陵等一大批政府机关和公共事业建筑，大多都采用了西式建筑结构加「大屋顶」的形式。 不过，虽然「大屋顶」有官方加持，在南京等地声势浩大且波及北京，但在当时建筑界，就已不乏质疑之声。 著名建筑学家梁思成认为，「大屋顶」建筑在理论和设计建造方面都存在明显的缺陷，「均注重外形的摹仿，而不顾中外结构之异同处，所采用的四角翘起的中国式屋顶，勉强生硬的加在一座洋楼上，其上下结构划然不同旨趣」。 在梁思成看来，中国古代建筑的优点在于其梁架式结构，与现代建筑的框架结构有很多异曲同工之处，并且「每个部分莫不是内部结构坦率的表现」，合乎现代建筑设计原则。生硬采用钢筋混凝土去模仿木构架建筑的具体形态，破坏了中式建筑的真趣味，是最不聪明的借鉴手法。 同时，梁思成还指出，给近现代西式建筑强行加大屋顶在经济并不划算，「糜费侈大」，不适应当时中国贫弱的基本国情。 直到 1949 年后，梁思成等人的在「大屋顶」问题上仍然态度顽固。1950 年 1 月，梁还在营建学研究会上强调：「（大屋顶建筑）不伦不类，犹如一个穿西装的洋人，头戴红缕帽，胸前挂一块缙子，脚上穿一双朝靴，自己以为是一个中国人！」 不过，随着苏联专家的到来，梁思成们很快投降了。 「要像爱女朋友那样爱民族形式」 50 年代初，大批苏联援华专家来到中国，其中也包括市政与建筑专家。 在当时特殊的政治环境下，苏联专家们理所当然地把持了中国建筑界的话语权，他们传达给中方的信息相当明确：采用民族形式才是社会主义建筑，坚决与资产阶级的现代主义建筑划清界限。 苏联专家们的意见，代表了苏联最高领袖的意见。早在 1935 年，在斯大林亲自指导下，苏联公布了《改建莫斯科市总计划的决议》，指出要以「民族形式」表达「社会主义的内容」。 随后设立的苏联建筑科学院，更明确表示要对「资产阶级的」现代主义建筑流派进行「歼灭性打击」。 这种环境下锻炼出来的苏联援华专家，当然执着于「民族形式」。如苏联专家维拉索夫就表示，他「看见上海就愤怒」，因为上海遍地西洋式建筑，缺乏民族风格，「很不进步」。另一位在清华大学指导建筑教学的专家阿谢普可夫，则要求学生「要像爱女朋友那样爱民族形式」。 至于中国建筑的民族风格是什么样的，苏联专家们也早已成竹在胸。1949 年 9 月，苏联市政专家组组长阿布拉莫夫第一次见到中方人员时，就专门嘱咐北京建筑要搞成西直门那样的「民族形式」，怕中方人员不懂，还在纸上勾画了一个箭楼的轮廓。 中共对苏联专家的意见深表认同，《人民日报》对建筑学界提出要求，在首都建设的建筑设计上「必须批判和克服资本主义的设计思想，学习社会主义的设计思想，特别是向苏联专家学习」。 从 1951 年开始，以梁思成为首的北京建筑学界开展了多次自我批判，「痛悔过去误信了割断历史的建筑理论」，将一贯认可的「国际主义」建筑和现代主义建筑风格都视为反动的、代表资产阶级的、世界主义的体现。 即便如此，北京建筑界还是对到底应该如何发扬民族风格表示了疑虑：「创造我们的新建筑。这是一个极难的问题。老实说，我们全国的营建工作者恐怕没有一个人知道怎样去做。」 1952 年建成的「四部一会」大楼，几个大屋顶共花费 30 多万元 1952 年建成的地安门机关宿舍大楼，顶部 6 个亭子的工料造价达 54.6 万元 「梁思成路线」被打倒后，北京的建筑风格问题并未得出答案：不加装饰的现代风格是「资本主义」，加「大屋顶」又是「封建复古主义」，到底该盖什么样的房子？ 答案在 1958 年揭晓。 为庆祝国庆十周年，展现建国伟大成就，北京决定建设一批庆典建筑，即「十大建筑」。高层明确指示，重大建筑仍要采用「民族形式」，因此大屋顶建筑仍占很大的比例，如民族文化宫、全国农业展览馆、北京火车站等。其他建筑也或多或少带有传统装饰元素。","categories":[{"name":"63.Culture-and-Arts","slug":"63-Culture-and-Arts","permalink":"https://beefyheisenberg.github.io/categories/63-Culture-and-Arts/"}],"tags":[{"name":"北京","slug":"北京","permalink":"https://beefyheisenberg.github.io/tags/北京/"},{"name":"建筑","slug":"建筑","permalink":"https://beefyheisenberg.github.io/tags/建筑/"}]},{"title":"Arch.批判地域性主义","slug":"63.Culture-and-Arts/Arch.批判地域性主义","date":"2024-01-24T01:27:53.911Z","updated":"2024-01-24T01:27:53.912Z","comments":true,"path":"63.Culture-and-Arts/Arch.批判地域性主义/","link":"","permalink":"https://beefyheisenberg.github.io/63.Culture-and-Arts/Arch.批判地域性主义/","excerpt":"","text":"批判地域性主义(Critical Regionalism)是一个建筑学词汇，指一种利用建筑物所在的地理文脉(Geographical context)信息反对现代建筑中出现的没有归属性(Identity)和无位置感(Placelessness)的理论态度。 再评批判性地域主义：在地建筑 | ArchDaily 批判地域性主义_百度百科","categories":[{"name":"63.Culture-and-Arts","slug":"63-Culture-and-Arts","permalink":"https://beefyheisenberg.github.io/categories/63-Culture-and-Arts/"}],"tags":[{"name":"建筑","slug":"建筑","permalink":"https://beefyheisenberg.github.io/tags/建筑/"}]},{"title":"Arch-建筑（苏联）","slug":"63.Culture-and-Arts/Arch.建筑（苏联）","date":"2024-01-24T01:27:53.907Z","updated":"2024-01-24T01:27:53.907Z","comments":true,"path":"63.Culture-and-Arts/Arch.建筑（苏联）/","link":"","permalink":"https://beefyheisenberg.github.io/63.Culture-and-Arts/Arch.建筑（苏联）/","excerpt":"原文： 苏联迷恋的未来主义建筑 - by MacroGuy Druzhba Sanatorium，“友谊疗养院”， 1985，乌克兰克里米亚 这个疗养院建在乌克兰的雅尔塔（Yalta，学过中学历史都听过这个地方吧）的海边，像一个飞碟停在一根大柱子上面，现在就是个休闲娱乐场所。 Ministry of Highways，1975，格鲁吉亚第比利斯 这是前苏联的一个标识化的未来主义建筑，在格鲁吉亚的首都Tbilisi（第比利斯），当初修建了是为了当他们高速公路部（一个政府部门）的办公大楼的。建筑师就是当时的高速路部长Giorgi Chakhava。设计就是为了让建筑更少量地接触地面，阳光可以从更多的角度照射进窗子。在苏联解体后这个建筑物被废弃了十几年，后来被格鲁吉亚银行（Bank of Georgia，就是一个商业银行，不是央行）买了下来，内部装修全部重新做了一遍。现在就是这个银行的总部大楼了。 Palace of Ceremonies, 1985, Tbilisi，格鲁吉亚 这又是一个修建在格鲁吉亚首都第比利斯的后现代建筑，被叫做“典礼宫殿”。这种建筑故意被造成有教堂的特征，因为它起的作用就是教堂该有的功能，比如婚礼，孩子出生庆祝，等等。但有个严格的要求便是，只有非基督徒才能使用这个地方。这栋建筑便是苏联对无神论主张的一种态度。 House of Soviet，1970开建，一直未完工，俄罗斯 这个栋烂尾楼是苏联的粗野主义（Brutalist style）的一个典范。这栋楼在俄罗斯的飞地Kaliningrad（加里宁格勒，在立陶宛和波兰之间），而且所在这片地非常出名，就是在Königsberg castle（哥尼斯堡城堡）原址上修建出来的。因为哥尼斯堡城堡在二战时被炸得几乎不能复原，所以直接拆了，原址基础上修了这么一个怪物。 Circle houses of Moscow, 1972，俄罗斯 这栋楼是为了献给1980年莫斯科奥运会而修建的，当时设计的是5个环，但修了一个环之后发现财力完全跟不上，就只好停了。但好的地方是，至少把这个圆给修完了。 Institute of Robotics and Technical Cybernetics，1968，俄罗斯 在俄罗斯圣彼得堡的国家机器人研究院，这个研究院的主攻方向就是太空船和军用机器人，因为形状奇特，在当地被人叫做“白色郁金香”。这个地方属于军事重地，所以这个建筑物很难靠近，更不可能有无人机之类的飞过去看。 Space Arches，1983，格鲁吉亚 第比利斯的“玫瑰革命广场”（命名于2003年在格鲁吉亚发生的一场革命，在这一年对于格鲁吉亚才算真正意义上结束了前苏联的统治，虽然那个时候前苏联已经消失了十多年了）上的后现代建筑拱门显得非常奇幻。在拱门前面有个很大的广场，一直延伸到Kura river的岸边。但很可惜，后来整个拱门在2005年因为政局改变，这种象征前苏联思想的产物会成为首当其中被毁掉的建筑。 Grodno Drama Theater，1984，白俄罗斯 Grodno是白俄罗斯与波兰边界的一个小城市，这里修建的剧院中心在当地绝对是异类。它坐落在尼曼河边，像一座发狂的堡垒一样。 Hotel Salute, 1984，乌克兰基辅 乌克兰的“致敬酒店”（我也不知道有官方的翻译没，我自己就是这么叫的）便矗立在基辅市中心。","text":"原文： 苏联迷恋的未来主义建筑 - by MacroGuy Druzhba Sanatorium，“友谊疗养院”， 1985，乌克兰克里米亚 这个疗养院建在乌克兰的雅尔塔（Yalta，学过中学历史都听过这个地方吧）的海边，像一个飞碟停在一根大柱子上面，现在就是个休闲娱乐场所。 Ministry of Highways，1975，格鲁吉亚第比利斯 这是前苏联的一个标识化的未来主义建筑，在格鲁吉亚的首都Tbilisi（第比利斯），当初修建了是为了当他们高速公路部（一个政府部门）的办公大楼的。建筑师就是当时的高速路部长Giorgi Chakhava。设计就是为了让建筑更少量地接触地面，阳光可以从更多的角度照射进窗子。在苏联解体后这个建筑物被废弃了十几年，后来被格鲁吉亚银行（Bank of Georgia，就是一个商业银行，不是央行）买了下来，内部装修全部重新做了一遍。现在就是这个银行的总部大楼了。 Palace of Ceremonies, 1985, Tbilisi，格鲁吉亚 这又是一个修建在格鲁吉亚首都第比利斯的后现代建筑，被叫做“典礼宫殿”。这种建筑故意被造成有教堂的特征，因为它起的作用就是教堂该有的功能，比如婚礼，孩子出生庆祝，等等。但有个严格的要求便是，只有非基督徒才能使用这个地方。这栋建筑便是苏联对无神论主张的一种态度。 House of Soviet，1970开建，一直未完工，俄罗斯 这个栋烂尾楼是苏联的粗野主义（Brutalist style）的一个典范。这栋楼在俄罗斯的飞地Kaliningrad（加里宁格勒，在立陶宛和波兰之间），而且所在这片地非常出名，就是在Königsberg castle（哥尼斯堡城堡）原址上修建出来的。因为哥尼斯堡城堡在二战时被炸得几乎不能复原，所以直接拆了，原址基础上修了这么一个怪物。 Circle houses of Moscow, 1972，俄罗斯 这栋楼是为了献给1980年莫斯科奥运会而修建的，当时设计的是5个环，但修了一个环之后发现财力完全跟不上，就只好停了。但好的地方是，至少把这个圆给修完了。 Institute of Robotics and Technical Cybernetics，1968，俄罗斯 在俄罗斯圣彼得堡的国家机器人研究院，这个研究院的主攻方向就是太空船和军用机器人，因为形状奇特，在当地被人叫做“白色郁金香”。这个地方属于军事重地，所以这个建筑物很难靠近，更不可能有无人机之类的飞过去看。 Space Arches，1983，格鲁吉亚 第比利斯的“玫瑰革命广场”（命名于2003年在格鲁吉亚发生的一场革命，在这一年对于格鲁吉亚才算真正意义上结束了前苏联的统治，虽然那个时候前苏联已经消失了十多年了）上的后现代建筑拱门显得非常奇幻。在拱门前面有个很大的广场，一直延伸到Kura river的岸边。但很可惜，后来整个拱门在2005年因为政局改变，这种象征前苏联思想的产物会成为首当其中被毁掉的建筑。 Grodno Drama Theater，1984，白俄罗斯 Grodno是白俄罗斯与波兰边界的一个小城市，这里修建的剧院中心在当地绝对是异类。它坐落在尼曼河边，像一座发狂的堡垒一样。 Hotel Salute, 1984，乌克兰基辅 乌克兰的“致敬酒店”（我也不知道有官方的翻译没，我自己就是这么叫的）便矗立在基辅市中心。 The Presidium of Russian Academy of Sciences，1994，俄罗斯这栋楼是俄罗斯国家科学院，坐落在莫斯科，修了将近二十年，在1994年才完工。在顶部有玻璃与金属所构成的装饰，当地人都把这个栋楼的顶部叫做“金色大脑”。 Housing complex，1976，格鲁吉亚窗子被做成半圆的样子特别有未来主义的风格，再加上斑驳苍凉的水泥石墙，这些建筑显得特别有工业质感。 the Palace of Soviet，未修建，设计于上世纪30年代当时设计这栋楼的时候，目的在于让这栋楼成为整个苏联的行政管理中心，所以叫它“苏联宫殿”，当时设计了有100层楼，高度有将近495米（现在上海环球金融中心高达492米，是世界第七高的摩天楼），可以想象野心有多大。 苏联之所以喜欢修这么多未来主义的建筑其实是因为在上世纪20到30年代受到意大利未来主义思潮的影响，再加上苏联在这时才建立，百业待兴。同时国家意志展现了疯狂的强势面，在这种环境下，苏联的诗人，艺术家到建筑师都对未来充满了极大的期待，因为大家都从没见过一个国家能这么高度的中央集权，集中全国的资源来办一件事情。 我们可以看一下苏联在上世纪70年代，也就是修建以上建筑物的年代，是怎么憧憬未来的。 这是停车场，车辆全部被运到钢架之上悬挂。 未来的航运与陆地交通体系。","categories":[{"name":"63.Culture-and-Arts","slug":"63-Culture-and-Arts","permalink":"https://beefyheisenberg.github.io/categories/63-Culture-and-Arts/"}],"tags":[{"name":"俄罗斯","slug":"俄罗斯","permalink":"https://beefyheisenberg.github.io/tags/俄罗斯/"},{"name":"建筑","slug":"建筑","permalink":"https://beefyheisenberg.github.io/tags/建筑/"},{"name":"苏联","slug":"苏联","permalink":"https://beefyheisenberg.github.io/tags/苏联/"},{"name":"原子朋克","slug":"原子朋克","permalink":"https://beefyheisenberg.github.io/tags/原子朋克/"}]},{"title":"Arch-建筑（欧洲）","slug":"63.Culture-and-Arts/Arch.建筑（欧洲）","date":"2024-01-24T01:27:53.902Z","updated":"2024-01-24T01:27:53.902Z","comments":true,"path":"63.Culture-and-Arts/Arch.建筑（欧洲）/","link":"","permalink":"https://beefyheisenberg.github.io/63.Culture-and-Arts/Arch.建筑（欧洲）/","excerpt":"古希腊与古罗马建筑第一个区别：古罗马神殿只有正面一个台阶入口，其他方向都是高出地面数米的基底。而古希腊则把神殿的基底都修成台阶，让人可以从四面八方进入。 也许背后的原因在于古希腊人对神祇的看法并不像古罗马人那样具有完备的仪式感与疏离感。神祇对于古希腊人来说更加亲密，更容易敬拜。 第二个区别：古罗马很注重神殿正面入口的建造，会花大量精力在正面的雕塑与造型上面。而且背面和部分侧面往往是用墙封闭起来的。 前面三种柱式是古希腊用的，古罗马时期又创造了后面两种，但是他们仍然也使用前面三种。","text":"古希腊与古罗马建筑第一个区别：古罗马神殿只有正面一个台阶入口，其他方向都是高出地面数米的基底。而古希腊则把神殿的基底都修成台阶，让人可以从四面八方进入。 也许背后的原因在于古希腊人对神祇的看法并不像古罗马人那样具有完备的仪式感与疏离感。神祇对于古希腊人来说更加亲密，更容易敬拜。 第二个区别：古罗马很注重神殿正面入口的建造，会花大量精力在正面的雕塑与造型上面。而且背面和部分侧面往往是用墙封闭起来的。 前面三种柱式是古希腊用的，古罗马时期又创造了后面两种，但是他们仍然也使用前面三种。 拜占庭风格建筑内部无支撑的圆形穹顶。穹隅和角拱是拜占庭建筑工程技术的标志，它们使得这种样式得益可能并且大量普及。 哥特风格尖塔高耸、尖形拱门、大窗户及绘有圣经故事的彩色大玻璃。设计中利用十字拱、飞券、修长的立柱，营造出轻盈修长的飞天感。 飞扶壁（英语：Flying buttresses）是一种起支撑作用的建筑结构部件，凌空跨越下层附属空间（如走道、小祈祷室等）连接到顶部高墙上肋架券的起脚部位，用于平衡肋架拱顶（英语：Rib vault）对墙面的侧向推力。 飞扶壁： 巴洛克风格17~18世纪在意大利文艺复兴建筑基础上发展起来的一种建筑和装饰风格。其特点是外形自由，追求动感，喜好富丽的装饰、雕刻和强烈的色彩，常用穿插的曲面和椭圆形空间来表现自由的思想和营造神秘的气氛。 巴洛克（Baroque）此字源于西班牙语及葡萄牙语的“变形的珍珠”(—barroco)。作为形容词，此字有“俗丽凌乱”意。欧洲人最初用这个词指“缺乏古典主义均衡特性的作品”，它原是18世纪崇尚古典艺术的人们，对17世纪不同于文艺复兴风格的一个带贬义的称呼，现今这个词已失去了原有的贬义，仅指17世纪风行于欧洲的一种艺术风格。 巴洛克建筑风格特征： 1、它有豪华的特色，它既有宗教的特色又有享乐主义的色彩； // 建筑的正面有很复杂的雕塑，不再严格使用对称原则 2、它有着浓重的宗教色彩，宗教题材在巴洛克艺术中占有主导的地位； 3、大多数巴洛克的艺术家有远离生活和时代的倾向，如在一些天顶画中，人的形象变得微不足道，如同是一些花纹 Ref https://zhuanlan.zhihu.com/p/51293458 https://www.bunbo.com.cn/news/architecture/2012/italy.html 附：希腊石柱古希腊最主要的大型建筑是神庙。那时人们信奉的是多神教，各行各业个地方都有自己的守护神。希腊神庙的建筑特点是广泛地运用石柱。因此基石、柱子和盖在他上面的檐部的处理，基本上决定了神庙的外貌。列柱之美即建筑美学的具体体现。古代希腊人创造了多立克、爱奥尼亚、科林斯3种石柱形态。 多立克柱式——是较为朴实庄重的一种柱式，为多里安人所创造的。他的柱身比例较为粗短，柱的下端直接置于石台上，不加另外基座。柱的顶端是由一扁圆形垫石托着一块厚实的方形石板，再与上面的楣梁连接，整个柱形朴素、稳重、坚固。著名的雅典卫城的帕提农神庙即采用的是多立克柱式。 爱奥尼亚柱式——由小亚细亚沿海的伊奥尼亚人所创造的。他的柱身修长，垂直线纹精细。柱的底部加上了圆形基座，柱的顶端加了涡卷形装饰。整个柱式优美、轻灵、典雅。广泛出现在古希腊的大量建筑中，如雅典卫城的俄瑞克忒翁神庙。 科林斯柱式——出现较晚，流行于希腊化时期，最初为科林斯人所创造而得名。这种柱式是从爱奥尼亚式变化而成，所不同的是柱顶端的一对漩涡形纹没有了，代之以繁密重迭的卷叶形装饰，更显的精致华美。科林斯柱式最初用于建筑内部，到希腊化后期和罗马时期才更多地用于大型建筑。雅典的宙斯神庙采用的正是科林斯柱式。","categories":[{"name":"63.Culture-and-Arts","slug":"63-Culture-and-Arts","permalink":"https://beefyheisenberg.github.io/categories/63-Culture-and-Arts/"}],"tags":[{"name":"建筑","slug":"建筑","permalink":"https://beefyheisenberg.github.io/tags/建筑/"},{"name":"希腊","slug":"希腊","permalink":"https://beefyheisenberg.github.io/tags/希腊/"},{"name":"罗马","slug":"罗马","permalink":"https://beefyheisenberg.github.io/tags/罗马/"}]},{"title":"Arch.建筑风格","slug":"63.Culture-and-Arts/Arch.建筑风格","date":"2024-01-24T01:27:53.897Z","updated":"2024-01-24T01:27:53.898Z","comments":true,"path":"63.Culture-and-Arts/Arch.建筑风格/","link":"","permalink":"https://beefyheisenberg.github.io/63.Culture-and-Arts/Arch.建筑风格/","excerpt":"","text":"解构主义建筑 Brutalist style / 粗野主义 Brutalist architecture - Wikipedia","categories":[{"name":"63.Culture-and-Arts","slug":"63-Culture-and-Arts","permalink":"https://beefyheisenberg.github.io/categories/63-Culture-and-Arts/"}],"tags":[]},{"title":"《存在主义心理治疗》读书笔记","slug":"62.Psychology/《存在主义心理治疗》读书笔记","date":"2024-01-24T01:27:53.893Z","updated":"2024-01-24T01:27:53.894Z","comments":true,"path":"62.Psychology/《存在主义心理治疗》读书笔记/","link":"","permalink":"https://beefyheisenberg.github.io/62.Psychology/《存在主义心理治疗》读书笔记/","excerpt":"《存在主义心理治疗》读书笔记本书围绕欧文·亚隆提出的四个“生命的终极关怀”展开：Existential Psychotherapy - by Irvin D. Yalom Organized around what Yalom identifies as the four “ultimate concerns of life” — death, freedom, isolation, and meaninglessness—the book takes up the meaning of each existential concern and the type of conflict that springs from our confrontation with each. He shows how these concerns are manifest in personality and psychopathology, and how treatment can be helped by our knowledge of them. 《导论》p6 一种动力性心理治疗：个体的心理动力学包括了在其内部运转的多种无意识和意识的力量、动机以及恐惧。如果我们提问，哪些力量（还有恐惧和动机）处于冲突之中？内在意识和无意识之间的斗争的内容是什么？就是在这个关键点上，存在主义治理与其他动力性治疗分道扬镳，关于在个体内部互相作用的驱力、动机和恐惧，存在主义治理有完全不同的观点。","text":"《存在主义心理治疗》读书笔记本书围绕欧文·亚隆提出的四个“生命的终极关怀”展开：Existential Psychotherapy - by Irvin D. Yalom Organized around what Yalom identifies as the four “ultimate concerns of life” — death, freedom, isolation, and meaninglessness—the book takes up the meaning of each existential concern and the type of conflict that springs from our confrontation with each. He shows how these concerns are manifest in personality and psychopathology, and how treatment can be helped by our knowledge of them. 《导论》p6 一种动力性心理治疗：个体的心理动力学包括了在其内部运转的多种无意识和意识的力量、动机以及恐惧。如果我们提问，哪些力量（还有恐惧和动机）处于冲突之中？内在意识和无意识之间的斗争的内容是什么？就是在这个关键点上，存在主义治理与其他动力性治疗分道扬镳，关于在个体内部互相作用的驱力、动机和恐惧，存在主义治理有完全不同的观点。 p7 弗洛伊德派心理动力学：个体面临的冲突有多个层面：两种对立的本能（自我本能和力比多，或者后期理论中的叫法，爱欲和死欲1）；本能与环境要求的冲突，本能与内化了的环境要求相冲突——也就是与超我冲突。为本能所驱动的个体就这样处于与这个世界的战争之中，因为这个世界阻碍着与生俱来的攻击欲望和性欲望的满足。 p8 存在主义心理动力学：从充斥着我们每个人经验世界的日常琐事中抽离出来，给自己以独处、沉默、时间以及自由。如果我们能够清除或者“囊括”日常生活，如果我们对于自己在世界上的处境，对于我们的存在、我们的界限、我们的潜力进行深刻的反思，如果我们深入到所有层面的最底层，我们必然会面对存在的既定事实，面对“深度结构”，我之后将称之为“终极关怀”。这些反思过程常常为某些紧急体验所催化。这些常被称作“边缘”或者“临界”状态，包括如下体验：面对自己的死亡、面临某些重大不可逆转的决定或者某些深具意义的图式在眼前崩塌。生命的四个终极关怀：死亡、自由、孤独和无意义。个体与这些生命真相的正面交锋，构成了存在主义动力性冲突的内容 死亡。斯宾诺莎的话来说：“每一事物都在尽力维持自身是的存在”，而存在的一个核心冲突是，面对死亡必然性的意识与继续生存下去的愿望之间的张力。 自由。一般来说我们都认为自由是一个毋庸置疑的积极概念。在存在的意义上，自由意味着外部结构的空白，自由在这种含义上，带有一种可怕的暗示：它意味着我们所站立的地方并不坚实——什么都没有，是空的，无底深渊。存在主义一个关键的动力性冲突就是，我们无根基的处境与我们对根基与结构的渴望之间的冲突。 存在性孤独。无论我们之间变得有多么亲密无间，仍然存在一个最终无法逾越的鸿沟；我们每个人都是独自一人进入这种存在，同时也注定要独自离开。一方面是我们对自身绝对孤独的意识，另一方面是对接触、保护的渴望，以及成为一个更大整体一部分的愿望，存在性冲突就是这两个方面之间的张力。 无意义。一个人创造出来的意义是否坚强到令其能容忍生活？人类这种寻找意义的生物，却被投入到本身毫无意义的宇宙之中。于是，存在的动力性冲突便从进退维谷的境地中滋生出来。 p11：弗洛伊德的心理动力学是以发展为基础，跟“根本”和“原始”应该按照时间顺序来理解，都是“最初”的同义词。举例来说，焦虑的根本来源被认为是最早的性心理灾难：分离和阉割。存在主义动力学并未执着于发展模型。人们没有理由认为“根本的”和“最初的”是同样的概念。要从存在主义的观点做深层的探索，并不意外着探索过去，而是意味着拂调日常的担忧，深刻的思索个人的存在处境，这意味着跳出时间之外来思索，思索我们的双脚和立足之间的关系，思索我们的意识与周围空间之间的关系，这并非意味着思考我们以何种方式成为现在的样子，而是思考我们到底是什么样子 p24：存在主义在了解人类时，尽力避免采用主体与客体的二分法，存在主义立场挑战了传统的笛卡尔式世界观，后者是由客体和感知这些客体的主体所构成。存在主义越过主体-客体的分割，不把人看作是可以在适当环境下感知外在现实的主体，而将人视为参与构建现实的观察者。海德格总是谈到人类是“此在”（dasein），da意味“那里”，指的是人在那里、是一个被组成的客体（经验自我）这一事实，但此人同时也组成了世界（先验自我），“此在”的人既赋予事物意义，同时又感知这意义。 第一部《死亡》@todo 第二部《自由》@ingp227对于哲学家来说，“自由”具有广阔的个体、社会、道德和政治含义 并且这个议题是极其富有争议性的：关于自由和因果的哲学论战两千多年来从未止歇。几个世纪以来，绝对自由的概念总会引发激烈的反对，因为它总与主流的世界观相违背：最初，它与宗教信仰相对立，然后与科学因果法则冲突，之后与黑格尔的历史进步观（历史的发展是有进步、有意义的）或者马克思或弗洛伊德的决定论相违背。 在第六章-责任，我将探讨个体创造自身生活的自由；在第七章-意志，我将探讨个体欲望、选择和行动的自由，已经对于心理治疗最重要的自由——改变的自由 第六章 责任p231：海德格把个体称为“此在”（并不是“我” 或“一个人” 或“自我” 或“一个人类”）。这样称呼是有特别原因的，他希望永远强调人类存在的双重性：个体在“那里”，但同时个体也构建了什么是“那里”。自我是二合一的，它是一个经验自我（一个客观自我，那个在那儿的某物，世界中的一个客体）；它又是一个先验（构建性）自我，构建了自身和世界，也就是为自己的身体和时间负有责任。这种角度下的责任是必然与自由彼此纠结的。除非个体可以自由地将世界以任意多种方式构建，否则责任的概念就没有意义。 p232：萨特： …我对我做的和我所忽略的负有责任 /萨特的存在主义强调人有自主选择的权利，同时对自己的选择负责/ /为什么和自由相对立，如果人只有自由的选择但不为此负责，这里不用道德来谴责，但至少不负责的行为不是存在主义者/ p233：存在性孤独远远超越了一般的社会性孤独，这不仅仅是与他人相分隔的孤独，也是与世界相分隔的孤独 第三部《孤独》p377：…存在孤独被一层又一层世界的加工品所隐藏，每一层都包含了个人和集体的意义。我们只体验到了一个寻常的世界，一个由日常生活和“他们”构成的世界，我们周围是一个由熟悉的事物和制度所构成的稳定世界，一个所有物体和个体都彼此多重连接的世界。我们被平静地诱导入一种熟悉的、亲切的归属感。那极度空旷和孤独的原始世界被无声地深深掩埋了，只有在噩梦或者幻想中才会偶然发出短暂的声音。 我相信每个有自省能力的个体都会体验到过这样的时刻：一种陌生感浮现出来，所有的意义从事物上剥落，符号彻底瓦解，个体从那“熟悉”的安全锚上脱离，加缪在一篇早期作品中描述过这样的时刻，当时他身处一个陌生国度的酒店房间： … 这段可能来自加缪早期作品 [[../64.Novel-and-Poesy/F03.加缪札记]] p378：海德格用“不自在”来指代人失去了在世界中的熟悉感的状态，当人完全专注于表象世界，对自己的存在处境失去接触时，海德格称这个人处于“日常”或者“陷入”的模式里。海德格在《存在与时间》的另一段说过，当人从“对世界的沉溺”中被带回，事物的意义被剥除时，就会因面对世界的孤寂、无情和虚无而焦虑。因此，当我们面对虚无，就会感到终极的恐惧。在面对虚无时，没有什么事或人可以帮助我们，就在这个时刻我们最完整地体验到了存在的孤独。 熟悉感的丧失不只牵涉具体的事物，其他可以提供结构和稳定性的事物，包括角色、价值观、原则、规则、伦理都可以以类似的方式被剥离其意义。 罗素在自传序言写的《What I have lived for》之一是“对爱情的渴望”，寻求爱情的动机他也写了“因为爱情解除孤寂——那是一颗震颤的心，在世界的边缘，俯瞰那冰冷死寂、深不可测的深渊。” 提到的“深渊”，可能也是描写“存在性孤独”的 毅然地承受：海德格的“向死而在”，Being towards death @link: [[../61.Philosophy/05b.海德格《存在与时间》]] 当意识到“个体的存在”可以被一分为二：「世界是世界，我是我」，这种情况下，个体有机会接触到那个“完整的存在孤独”，同时也体会面对“世界的孤寂、无情和虚无”。 死亡是种特殊的状态，因为死亡最接近将“个体与世界”完全分离的状态。所以，如果一个人可以勇敢地直面“世界是世界，我是我”这一冷酷的事实，那么似乎可以等同于，他也可以平淡地直面“死亡”，也就是迈向 海德格所说的“向死而生”的状态/生活态度的第一步。 在真正走入“向死而生”的过程中，个体在承认了“我与世界之间”的隔阂是客观存在的（仅仅看到or承认这点还不够，因为还没有做到“而生”）情况下，但仍然选择投入到生活里、仍然选择去同他人/世界建立关系、着手自身的筹划… 这说明个体进入了一种完全不同于日常之人[^the_they]的状态，同时个体对“我与世界”之间的联系也会有不同的理解。但那这种“明知…却…”的动力是？ 对此，第四部分会讨论 加缪、萨特、马斯洛对“为什么人要追寻意义”的观点 第四部分《无意义感》： 世界不提供意义，但个体（我们）可以选择是否要给自己创造一个。但这些创造出来的“意义” ，它们总是同“个体之外的这个世界”所关联。如果只关注到“我和世界的分离”，那是难以有“主动地给自己创造意义”的行为动机的。 p382：人如何保护自己远离终极孤独的恐惧呢？人可以接纳一部分孤独，勇敢地（用海德格的话是“毅然地”）承受它，至于剩余的孤独，人会试图放弃单一性，进入与他人的关系中，所以，用以对抗孤独的恐惧的主要力量就是关系。如果我们承认自己的存在是孤独的，并且毅然地面对孤独，我们就能够真正的去爱他人。最好的关系是个体以彼此无所求的方式建立关系。 无所求的爱：实际是有所求的，或许这种方式要求的更多… 潜在的要求便是：对方同自己一样觉察到 &amp; 承认了“存在性孤独” … 达到或者靠近了海德格所说的本真（authentic）状态，在这种前提下，才有条件建立无所求的爱的关系 p388：马斯洛的基本主张之一是，人的基本动机或者是指向“匮乏”，或者是指向“成长”。以成长为动机的个体和以匮乏为动机的个体有着不同类型的人际关系。 p390：弗洛姆的出发点是 人类最根本的关怀是存在孤独，对孤独的觉察是“所有焦虑的来源”，我们主要的心理任务，就是克服分离感。弗洛姆讨论了几种对于这个问题的解决办法：创造性活动（艺术家和材料以及作品的结合）、迷醉的状态（宗教、性、药物引发的状态）、遵从（团体的习俗和信仰），所有以上解决方案都有其缺陷：与创造性作品结合并不是人际的，迷醉的融合是短暂的；遵从带来的融合只是表面的融合。因此它们都是对存在问题的不完整回答。完整答案在于达成人际的融合 p401 存在孤独与人际心理：如果我们无法发展能够让我们面对存在孤独的内心力量、自我价值感、认同感，无法接受事物本来的面貌、接纳焦虑的话，我们就会用间接的方式来寻求安全感。 活在他人眼中。需要别人确认才觉得自己活着的人必然会逃避孤独，完全独自一人会让人太过接近存在孤独带来的焦虑感。 融合。人也可以借着与某物融合，比如某个团体、使命、国家、项目，摆脱孤独的自我感。人类的“普世冲突”是人想要成为独立的个体，但成为个体又需要忍受孤独。处理这种冲突的最常见模式是否认：个体先建造融合的幻想，也就是对自己说“我并不孤独，我是他人的一部分”。这样个体弱化了自我的边界，变成了比自己优越的另一个人或群体的一部分。融合以消除自我觉察这种极端的方式消除孤独感。 性和孤独。性的诱惑…是抵御对自由的意识和焦虑的强大堡垒，因为我们在性的魔力下，根本意识不到我们建构了自己的世界。…我们不觉得是自己选择或创造了性欲，它好像在我们之外，有着自己的力量，好像“比生活更有力量” 第四部《无意义感》p447：存在主义理念把世界看作是偶然的，也就是任何事情都可能是另外一副样子。人构成了自身、自己的世界以及在这个世界中自身所处的情境。不存在“意义”。在宇宙中没有宏大的设计，没有指导生活的原则，除非个体自己创造这些原则。因此，最根本的问题变成了：需要意义的个体如何在一个没有意义的世界中找到意义？ p452 《西西弗神话》：加缪用“荒谬”这个词来形容人在世上的基本情境，即寻求超越和意义的人类却生活在一个没有意义的世界中的困境。我们是道德的生灵，我们要求世界提供一个道德评判的基础，也就是一个具有价值蓝图的意义系统。但是世界不能提供这样一个基础，它对我们的期望无动于衷。人类的渴望和世界的冷漠之间的张力构成了加缪所说的“荒谬”的人类处境。 在更早期的作品《西西弗神话》中，加缪探索了他的虚无主义和伦理要求之间的冲突，并逐步发展出一种全新的、世俗的、人道主义的个人意义观点。他提出我们通过珍爱自己“绝望的深夜”建立新的生命意义，通过直面无意义的“漩涡”达到英勇的虚无主义的姿态。作为个人只有通过有尊严地面对荒谬，才能够获得意义。“没有什么可以媲美人类的尊严”；世界本身的无意义要通过反抗来超越，这是一种对自身处境的高傲反抗 。“蔑视可以征服任何命运” 加缪 —— 英勇的虚无主义 p454 《苍蝇》2：俄瑞斯忒斯脱离了自己过去的意义体系，进入了他自身的无意义危机中——“我原本一直感觉到某种温暖有生命的东西，就像一种友好的存在。这种东西逝去了。多么空虚，无尽的空虚”。在这个时刻，俄瑞斯忒斯在他的生命中做出了和萨特相同的一跃，不是跃入信念，而是跃入“参与”、跃入行动。他告别了追求舒适和安全的理想，以非凡的勇气，开始对新目标的追逐。之后，俄瑞斯忒斯为了反抗宙斯，决定杀死埃癸斯托斯。他那时的宣言显示了明确的目的感，他选择了正义、自由和尊严，他知道生命中什么是“正确的”： “帮助人民从你邪恶的影响中解脱，这是正当的，让人民恢复作为人的尊严，这是正确的事” 为什么要实现这些意义？萨特没有回答这个问题。俄瑞斯忒斯只是简单的说：“我想要归属”；服务他人、恢复人的尊严、拥抱自由“是正确的事情”；每个人必须找到自己的路，我必须踏上旅途以便找到正在等候的、完全实现了自我的俄瑞斯忒斯。 萨特：近似武断的 “必须找到”、“正确的事” p457：..列举一些能够给人提供生活目的感的世俗活动，支持这些活动的理由，也是萨特支持俄瑞斯忒斯的理由。它们看起来是正确的、美好的；它们提供内在的满足，而不需要别的动机来支持：利他、创造、体验（享乐主义）、自我实现、自我超越 p463：自我实现。另一种个人意义的来源是相信人类必须力争实现自我，人们应该献身于实现自己的潜能。早在公元前4世纪，亚里士多德就提出因果目的观——有关内在定局的学说，他认为每一个物体或生命的真正结果或目的都是成就和实现其自身的存在，因此橡树籽长成橡树实现自己，婴儿则完全长成自我实现的成人3。 马斯洛认为人有着向成长和人格整合的倾向4：“人类的构造迫使他走向越来越完全的存在，也就是大多数人所说的美好价值，走向平静、仁慈、勇敢、诚实、爱、无私和善良”。他回答了“我们为什么而活着”的问题，他认为我们活着是为了实现自己的潜能，他也回答了“我们该怎么活”的问题，他认为美好的价值本质上已经存在于个体内心，如果人信任自己的本来智慧，就能够直觉地发现这些价值。 马斯洛：自我完善，完整人格 p465：自我超越。前面提到的两种意义（自我实现和享乐），是与自我相关的，而其他几种意义反映出超越自身的利益，为某种外在于或“高于”自己的事务而努力的渴望。西方思想的一个传统是不要暗语非自我超越性的生命意义。布伯5提出，人必须追问如下问题：“我寻找适合自己的特殊道路是为了什么？我整合自己的生命是为了什么？答案是：不是为了自我”。个体从自己开始是为了忘记自己，让自己沉浸在世界中。一个人了解自己是为了不要将全副心神贯注在自己身上。 自我超越（Personal Mastery）“自我超越”是由維克多·弗蘭克(Viktor Emil Frankl)提出的一個概念,他認為人真正追求的不是自我實現而是超越自我的生活意義。 p490：意义的意义之一就是降低焦虑，意义的存在能够减轻人在面对缺乏规律和结构的人生和世界时所产生的焦虑。我们需要意义，还有另一个重要的理由，一旦一种意义感产生，价值观也会随之产生，反过来价值观能够强化人的意义感。人类对整体的知觉框架的需要以及对作为行为基础的价值体系的需要，形成了我们寻找生命意义的纯粹理由。但是一般说来，意义相关的问题并不纯粹，其他非意义的问题会附加于其上，从而混淆意义的问题。 p507：退后一步观看生活，但如果这一步迈得过大，就潜在着某种有害的东西。当我们从生活中抽离，成为疏离的旁观者时，所有事情就变得无关紧要。这个位置被哲学家称之为“银河”或者“星云之眼”的视角。从这个位置来看，我们和其他所有的生物变得渺小而愚蠢，我们只是无数生命形态的一种。生命中的种种行为变得荒谬。那丰富、充满体验的片刻在时间的无限延展中变得微不足道。我们感到自己是渺小的尘埃，生命的全部也不过是弹指一挥。这种宇宙视角使治疗师面临一个难以处理的问题，一方面，他的逻辑无懈可击。自我观察、跳出自身视角、从远处看自己的能力是人类最有价值的特质之一。人之所以为人正因为如此。在绝大多数情况下，一个更广阔和全面的视角通常能让观察者更客观，但另一方面这个视角又让生命的活力枯竭。哲学的悲观主义传统，就是这种宇宙观点的衍生物。难怪叔本华的结论是：“没有任何事情值得我们去努力、付出和奋斗…所有美好的事情都是虚幻，世界终结了，破产了，仿佛一场无法支付起自身开销的生意”6。 首先，宇宙视角必然会导致叔本华所说的“没有什么真正重要，因而生命不值得一活”的观点，这其中的逻辑实际站不住脚，如果没什么真正重要，那么“没什么真正重要”也并不重要。 纳戈尔7认为，采用宇宙视角，是人类最高等的、最珍贵的、最有趣的特质，它并不会让我们痛苦，除非我们自己造成痛苦。让宇宙视角对我们产生如此沉重的影响，暴露了我们不能够真正意识到这种视角本身并不重要的现实。纳戈尔指出，我们必须真正理解宇宙视角，同时必须了解采用这种视角是人类的长处，这样我才能重新回归荒的、充满反讽的生活之中，而不是陷入绝望。凡事“无关紧要”的宇宙视角所带来的绝望下实际掩藏的是“至关重要”。例如叔本华认为没有任何事情是重要的，可许多事情对他来说是很重要的，譬如说服别人相信没有任何事情是重要的，反对黑格尔的思想体系，积极写作直到生命结束，从事哲学思考而不是自杀。// 心疼叔本华一秒😆 首先，肯定了“宇宙视角”的客观性：宇宙视角来自于人的自省和换位思考能力，通过这种视角再次审视、考察自身，这种能力是可贵的、难得的。 但如果向后一步退的太多，退了几万光年，这就成为了“万物皆渺小”的宇宙视角，这是“绝对理性”带来的观点， 什么才是“有意义”的？ —— 你自己说了算，个体可以选择是否主动创造意义，但这种“决定创造一个意义的觉悟”，是理性所无能为力的，因为理性只能承认绝对的虚无。 如亚隆伯格所说，如果要在世俗中寻找有意义的事物，需要转向人类非理性的视角：“它们看起来是正确的、美好的；它们提供内在的满足，而不需要别的动机来支持：利他、创造、体验（享乐主义）、自我实现、自我超越”， 其他维基百科上的Existential therapy 1.弗洛伊德相信人类由互相冲突的两种欲望所驱动：爱欲（生存本能）与死欲（死亡本能）。弗洛伊德所说的爱欲，包含所有创造性、及产生生命的驱力。死欲代表一切有生之物内在的冲动，欲回归至平静状态，甚至最终回到不再存在。 ↩2.《苍蝇》（1943）是萨特根据古希腊神话故事改编的一部存在主义悲剧。作者借用这出浓郁的古代神话悲剧的诗意，艺术地破除了人对自然之谜的惶惑感，传递出人能战胜“上帝”，自由选择生活道路的现代意识。 ↩3.实现性原理 Principle of Actuality，是亚里士多德哲学的重要思想 https://terms.naer.edu.tw/detail/1313066/ ↩4.马斯洛：《动机与人格》 ↩5.马丁·布伯 （Martin Buber，1878年2月8日－1965年6月13日） ↩6.A. Schopenhauer，cited in The Encyclopedia of Philosophy，Vol IV，ed. Paul Edwards (1923–2004) ↩7.T. Nagel: Mortal Questions[^the_they]: 海德格尔所说的人人（the they，也有译作庸众），是指此有（Dasein）在日常生活中的存在方式，它的特征是：在意差距，屈从别人（subservient），要求平均（averageness）和压平自己（levelling down oneself） ↩","categories":[{"name":"62.Psychology","slug":"62-Psychology","permalink":"https://beefyheisenberg.github.io/categories/62-Psychology/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://beefyheisenberg.github.io/tags/哲学/"},{"name":"存在主义","slug":"存在主义","permalink":"https://beefyheisenberg.github.io/tags/存在主义/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://beefyheisenberg.github.io/tags/读书笔记/"}]},{"title":"神经递质与情绪","slug":"62.Psychology/神经递质（多巴胺-内啡肽-血清素）","date":"2024-01-24T01:27:53.889Z","updated":"2024-01-24T01:27:53.889Z","comments":true,"path":"62.Psychology/神经递质（多巴胺-内啡肽-血清素）/","link":"","permalink":"https://beefyheisenberg.github.io/62.Psychology/神经递质（多巴胺-内啡肽-血清素）/","excerpt":"多巴胺一直以来，各种媒体都把多巴胺描述成人类愉悦感的来源，多巴胺意味着快乐，是大脑感到幸福的根源。各种文章把多巴胺形容成生活值得一过的终极意义所在，也是我们享受每一个快乐时刻的本质，每一个人企图通过药物、运动、食物、性或者地位来追求的高潮体验。但是事实上，脑科学研究真正告诉我们的是，多巴胺并不是媒体所渲染的快乐分子，或者快乐的根源。 多巴胺的作用其实非常简单。对于多巴胺的准确的本质描述，一个是多巴胺作用于我们的奖赏系统，让我们产生欲望；另外一个作用是，让大脑预期奖赏，从而指导相应的行为。简单的来说，多巴胺的作用，就是“让你想要”，和让你选择能得到更多奖励的行为。多巴胺和快乐，其实关系并不大。 就像高晓松说的：很多人分不清理想和欲望。理想就是当你想它时，你是快乐的；欲望就是当你想它时，你是痛苦的。这个欲望，就是多巴胺的分泌。 由此引出多巴胺的副作用——成瘾的痛苦：以手机成瘾症为例，我们很多时候只是在不停的点开“下一条”，即使很累也舍不得放开。这就是多巴胺的奖励机制在告诉你，“下一条会很爽”，当你强迫自己放下手机，你会觉得很焦虑，多巴胺只是让我们对下一个充满期待而已。","text":"多巴胺一直以来，各种媒体都把多巴胺描述成人类愉悦感的来源，多巴胺意味着快乐，是大脑感到幸福的根源。各种文章把多巴胺形容成生活值得一过的终极意义所在，也是我们享受每一个快乐时刻的本质，每一个人企图通过药物、运动、食物、性或者地位来追求的高潮体验。但是事实上，脑科学研究真正告诉我们的是，多巴胺并不是媒体所渲染的快乐分子，或者快乐的根源。 多巴胺的作用其实非常简单。对于多巴胺的准确的本质描述，一个是多巴胺作用于我们的奖赏系统，让我们产生欲望；另外一个作用是，让大脑预期奖赏，从而指导相应的行为。简单的来说，多巴胺的作用，就是“让你想要”，和让你选择能得到更多奖励的行为。多巴胺和快乐，其实关系并不大。 就像高晓松说的：很多人分不清理想和欲望。理想就是当你想它时，你是快乐的；欲望就是当你想它时，你是痛苦的。这个欲望，就是多巴胺的分泌。 由此引出多巴胺的副作用——成瘾的痛苦：以手机成瘾症为例，我们很多时候只是在不停的点开“下一条”，即使很累也舍不得放开。这就是多巴胺的奖励机制在告诉你，“下一条会很爽”，当你强迫自己放下手机，你会觉得很焦虑，多巴胺只是让我们对下一个充满期待而已。 成瘾（英语：Addiction）是指一种重复性的强迫行为，即使这些行为已知可能造成不良后果的情形下，仍然被持续重复。这种行为可能因中枢神经系统功能失调造成，重复这些行为也可以反过来造成神经功能受损——Wikipedia在奖励机制中，内啡肽，脑啡肽，内源性大麻素等属于“胡萝卜”型，而多巴胺则属于“大棒”型。前三者给人们带来的是获得后的满足感，而多巴胺给人带来的则是获得前的饥渴感。动物其实都很懒得，“大棒”让动物保持想要吃到胡萝卜应该有的高度兴奋的精神状态（别以为兴奋就是快乐！你被食肉动物追杀的时候就非常兴奋） @ref: 多巴胺等于快乐吗？ 内啡肽内啡肽（endorphin）亦称安多芬或脑内啡，是一种内成性（脑下垂体分泌）的类吗啡生物化学合成物激素。它能与吗啡受体结合，产生跟吗啡、鸦片剂一样有止痛和欣快感。等同天然的镇痛剂。利用药物可增加脑内啡的分泌效果。内啡肽类似于是成就感，内心宁静。 内腓肽可以帮助人保持年轻快乐的状态，所以内腓肽也被称之为“快感荷尔蒙”或者“年轻荷尔蒙”。 内啡肽的化学结构和一种药物很像，这种药物叫做吗啡。吗啡最早是在1803-1805年间，由德国化学家 Friedrich Sertürner 将其从鸦片中分离得出。因吗啡及其衍生物具有强效的镇定作用，如今多在临床上用于对极度疼痛的治疗（比如癌症末期的疼痛）。相比于人工提取的吗啡，内啡肽则是我们大脑中一种天然的镇痛剂，因为其在大脑中可激活阿片受体，帮助我们把不适感降到最低。当我们大笑的时候，大脑就会分泌内啡肽。在进行长时间的有氧运动时，同样也会有内啡肽的产生。内啡肽还有一个更棒的作用，即让我们产生愉悦和幸福的感觉。 诺贝尔奖金获得者罗杰．吉尔曼发现，人体产生内啡肽最多的区域以及内啡肽受体最集中的区域，居然就是学习和记忆的相关区域，因此内啡肽可以提高学习成绩，加深记忆。腓肽能够调整不良情绪，调动神经内分泌系统，提高免疫力，缓解疼痛。内腓肽的激发下，人能顺利入梦，消除失眠症，并使人的身心处于轻松愉悦的状态中，让免疫系统实力得以强化。 内腓肽可以对抗疼痛、振奋精神、缓解抑郁;还能让我们可以抵抗哀伤，创造力勃发，提高工作效率等等; 充满爱心和光明感，积极向上，愿意和周围的人交流勾通。 @ref: 脑内啡和鸦片素，大笑和有氧运动产生的镇痛贴 血清素血清素（又称5-羟色胺和血清胺，简称为5-HT） 功能：血清素是一种抑制性神经递质，最早于血清中发现，广泛存在于哺乳动物组织中，在大脑皮层质及神经突触内含量很高。在外周组织，血清素是一种强血管收缩剂和平滑肌收缩刺激剂。血清素还能增强记忆力，并能保护神经元免受“兴奋神经毒素”的损害。如谷氨酸即对受损的神经细胞有很大的毒性，因此充足的血清素能在老化过程中防止脑损害发生。 它更广为人知的作用是它在积极情绪中所起的重要作用。医学上已经广泛运用血清素来进行抑郁症等的治疗，例如著名的百忧解(Prozac)和佐洛夫特(Zoloft)等处方抗抑郁药，都是在通过增加血清素水平来对症状发挥缓解作用。 缺乏症状：很多健康问题与大脑血清素水准低有关。造成血清素减少的原因有很多，包括压力、缺乏睡眠、营养不良和缺乏锻炼等。在降低到需要数量以下时，人们就会出现注意力集中困难等问题，会间接影响个人计划和组织能力。这种情况还经常伴随压力和厌倦感，如果血清素水准进一步下降，还会引起忧郁。 其他一些与大脑血清素水准降低有关的问题还包括易怒、焦虑、疲劳、慢性疼痛和焦躁不安等。如果不采取预防措施，这些问题会随时间推移而恶化，并最终引起强迫症、慢性疲劳综合征、关节炎、纤维肌痛和轻躁狂忧郁症等疾病。患者可能会出现不必要的侵略行为和情绪波动。血清素水准较低的人群更容易发生忧郁、冲动行为、酗酒、自杀、攻击及暴力行为，科学家甚至通过改变实验动物脑内血清素水准，使他们更具有攻击性。 产生：我们身体内的血清素是怎样产生的？这是一个让人吃惊的答案：尽管血清素几乎总是与大脑功能、情绪和心理健康相关，但是，我们95%的血清素却是在肠道中制造的！研究人员尚不清楚为什么肠内有如此多的血清素活性。但是血清素的确促进了肠道与大脑之间的交流。 为什么会缺乏血清素？根据《为什么我的大脑不工作？》一书的作者Datis Kharrazian博士的观点，血清素缺乏是导致血清素含量低的原因，比如长期使用SSRIs（选择性血清素再摄取抑制剂）、血糖失衡、肾上腺疲劳、营养不良、激素失衡和避孕药可能是导致血清素缺乏的原因，但更常见的是不健康的生活习惯，如不良饮食、过度压力、人造甜味剂、酒精或咖啡因，以及缺少阳光照射等等","categories":[{"name":"62.Psychology","slug":"62-Psychology","permalink":"https://beefyheisenberg.github.io/categories/62-Psychology/"}],"tags":[]},{"title":"认知偏误","slug":"62.Psychology/认知偏误","date":"2024-01-24T01:27:53.884Z","updated":"2024-01-24T01:27:53.885Z","comments":true,"path":"62.Psychology/认知偏误/","link":"","permalink":"https://beefyheisenberg.github.io/62.Psychology/认知偏误/","excerpt":"写给PM的认知偏差手册，产品设计常见误区：认知偏差-产品经理知识手册_飞书 概念认知偏误（Cognitive bias），或作认知偏差、认知偏见等，是一种在判断中偏离规范（norm，哲学术语）或理性的系统模式。个人根据他们对输入的感知创造他们自己的“主观现实”。个人对现实的建构，而不是客观输入，可能会决定他们在世界上的行为。因此，认知偏差有时可能会导致知觉扭曲、不准确的判断、不合逻辑的解释或广义上的非理性（英语：irrationality）。 尽管这种误解看起来像是失常，但偏见可以帮助人类找到共同点和捷径，以帮助处理生活中的常见情况。一些认知偏差大概是适应性的。认知偏差可能会导致在特定情况下采取更有效的行动。此外，允许认知偏差可以实现更快的决策，当及时性比准确性更有价值时，这可能是可取的，如启发法所示。其他认知偏差是人类处理能力极限的“副产品”，是由于缺乏适当的心理机制（有限理性）、个人体质和生物状态的影响（参见体化认知），或仅仅是由于处理资讯能力的极限。","text":"写给PM的认知偏差手册，产品设计常见误区：认知偏差-产品经理知识手册_飞书 概念认知偏误（Cognitive bias），或作认知偏差、认知偏见等，是一种在判断中偏离规范（norm，哲学术语）或理性的系统模式。个人根据他们对输入的感知创造他们自己的“主观现实”。个人对现实的建构，而不是客观输入，可能会决定他们在世界上的行为。因此，认知偏差有时可能会导致知觉扭曲、不准确的判断、不合逻辑的解释或广义上的非理性（英语：irrationality）。 尽管这种误解看起来像是失常，但偏见可以帮助人类找到共同点和捷径，以帮助处理生活中的常见情况。一些认知偏差大概是适应性的。认知偏差可能会导致在特定情况下采取更有效的行动。此外，允许认知偏差可以实现更快的决策，当及时性比准确性更有价值时，这可能是可取的，如启发法所示。其他认知偏差是人类处理能力极限的“副产品”，是由于缺乏适当的心理机制（有限理性）、个人体质和生物状态的影响（参见体化认知），或仅仅是由于处理资讯能力的极限。 在认知科学、社会心理学和行为经济学的人类判断和决策研究的过去累积中，已经确定了一系列不断发展的认知偏差。 尽管大多该些偏见的现实已被可重复（reproducible）的研究证实，关于如何对这些偏见进行分类或如何解释它们经常存在争议。一些认知偏差的几个理论原因是已知的，这些偏差通过其共同的生成机制，例如嘈杂的信息处理（noisy information-processing）提供了对偏差的分类。 Gerd Gigerenzer 曾批评将认知偏见视为判断错误，并倾向于将其解释为与逻辑思维的理性偏差。解释包括信息处理规则（information-processing rules，或称心理捷径 mental shortcuts），称为启发式，大脑用来产生决定或判断。偏见有多种形式，表现为认知（“冷”）偏见，例如心理噪音（mental noise），或动机（“热”）偏见，例如当信念被一厢情愿扭曲时。两种效果可以同时存在。 关于这些偏见中的一些是否被视为无用或非理性（irrational），或者它们是否会导致有用的态度或行为，也存在争议。例如在结识他人时，人们倾向于提出引导性问题，这些问题似乎偏向于确认他们对这个人的假设。然而，这种确认偏差也被认为是社交技巧（social skill）的一个例子。一种与他人建立联系的方式 常见认知偏误决策、信念与行为偏误列表： 不明确性效应或厌恶不明确 Ambiguity effect 决策时倾向避开资讯不足的选项 后见之明偏误 Hindsight bias 又称“我早就知道了”、“马后炮”、“事后诸葛”。在事情发生或发展后，以为自己事前就能预测其发生与发展 可获性层叠 Availability cascade 一件事越常被公开谈论，就越加相信其真确性（类似“三人成虎” 锚定效应 Anchoring effect; Focalism 为不熟悉事物估值时，会把熟悉的类似事物或不久前接触到的无关数值当做“锚”（经验），估出来的数值会大大倾向“锚” 韵律当理由效应 Rhyme as reason effect 认为有韵律的语句比较有道理。（押韵） 舒适区效应 Comfort zone effect 对于过去常用的方案（舒适圈），高估效益或成功机会；对于过去少用的方案，低估效益或成功机会。 人类中心思维 Anthropocentric thinking 在孩童身上观察到的一种倾向，以人类当作类比来推测其他不熟悉的生物现象（拟人化）。或是反过来认为人所具有的特征是其他动物都没有的。 移情隔阂 Empathy gap 情感冷淡时，低估他人情感的强烈程度；情感强烈时，高估他人情感的强烈程度 逆火效应 Backfire effect 遇上与自身信念抵触的观点或证据时，除非它们足以完全摧毁原信念，否则会忽略或反驳它们，原信念反而更加强化 敌对媒体效应 Hostile media effect 对于立场与自己不同的媒体，总认为它们有偏见、不客观 从众效应 Bandwagon effect 倾向做很多人做的事或相信很多人相信的事（社会心理学中人受社会所影响） 啦啦队效应 Cheerleader effect 处在优秀的团体会比单独看起来更优秀 相合性偏误 Congruence bias 直接检验假设，却没想到要检验其他可能的假设 保守倾向 (贝叶斯) Conservatism (Bayesian) 新证据出现时，对既有信念的修正幅度不足 知识的诅咒 Curse of knowledge 懂得多的人非常难以懂得少的人的角度思考问 幸存者偏差 Survivorship bias 专注于从某个过程中存活下来的人或事寻找弱点意欲补强，却忽略了最大的弱点更可能在未存活的人或事之中。 既视感 Déjà vu 对某些事物有强烈的熟悉感，似乎曾经接触过，且能预先想到接下来会发生什么事 本质主义 Essentialism 认为人与事物有一些不可或缺的本质，并据此为它们分类，其他的分类方式是错误的 功能固着 Functional fixedness 受物品的一般用途局限，无法想到用特别的方式利用物品。（无法跳脱框架） 框架效应 Framing effect 同一资讯以不同方式呈现方式会带来不同想法，例如“有十分之九的存活率”和“有十分之一的死亡率”。 巴纳姆效应 Forer effect; Barnum effect 人们会把他们认为是为自己量身定做的人格描述评价为高度准确，而这些描述往往十分模糊及普遍，能放诸四海皆准适用于很多人。 资讯偏误 Information bias 倾向寻求更多资讯以做出决策，即使寻求的资讯对决策没有帮助 错觉相关 Illusory correlation 认为两件事应该有关系时，便会在检视经验与数据时觉得它们经常一起发生，即使它们一起发生纯粹是随机现象 沉没成本谬误或不理性增值 Sunk cost fallacy; Irrational escalation 由于先前已在某事上投资很多，即使新证据显示那是不好的选择，仍倾向于加重投资。 多看效应或单纯接触效应 Mere exposure effect 对熟悉的人与事产生过多的好感 忽略可能性 Neglect of probability 对于不确定的事，无法准确评估其发生机率，不是完全无视，便是过份高估 自制偏误 Restraint bias 高估自己对诱惑的自制力。 购后合理化 Post-purchase rationalization 购买后把之前的购买决定合理化，即使买下的产品太过昂贵或发现瑕疵。 对抗心理或抗拒心理 Reactance 他人要求做或不做某事时，有做相反事的冲动，尤其这要求对自由、自主造成威胁时。 更多: https://zh.wikipedia.org/zh-hans/%E8%AA%8D%E7%9F%A5%E5%81%8F%E8%AA%A4%E5%88%97%E8%A1%A8","categories":[{"name":"62.Psychology","slug":"62-Psychology","permalink":"https://beefyheisenberg.github.io/categories/62-Psychology/"}],"tags":[{"name":"认知偏误","slug":"认知偏误","permalink":"https://beefyheisenberg.github.io/tags/认知偏误/"},{"name":"幸存者偏差","slug":"幸存者偏差","permalink":"https://beefyheisenberg.github.io/tags/幸存者偏差/"},{"name":"巴纳姆效应","slug":"巴纳姆效应","permalink":"https://beefyheisenberg.github.io/tags/巴纳姆效应/"},{"name":"知识的诅咒","slug":"知识的诅咒","permalink":"https://beefyheisenberg.github.io/tags/知识的诅咒/"}]},{"title":"弗洛伊德","slug":"62.Psychology/弗洛伊德","date":"2024-01-24T01:27:53.880Z","updated":"2024-01-24T01:27:53.880Z","comments":true,"path":"62.Psychology/弗洛伊德/","link":"","permalink":"https://beefyheisenberg.github.io/62.Psychology/弗洛伊德/","excerpt":"简介西格蒙德·弗洛伊德（Sigmund Freud，1856—1939），奥地利心理学家、精神分析学家、哲学家，精神分析学的创始人。 他著有《梦的解析》、《性学三论》、《图腾与禁忌》等，提出了“潜意识”、“自我”、“本我”、“超我”、“伊底帕斯情结”、“欲力”、“心理防卫机制”等概念，被世人誉为“精神分析之父”。 科学哲学家卡尔·波普认为一切合理的科学理论，均具备证伪的可能，但弗洛伊德的心理学理论永远不可被证伪，因此不具备科学性。阿道夫·格伦鲍姆在《精神分析学基础》（The Foundations of Psychoanalysis，1984）中说波普的说法并不对，因为很多弗洛伊德的理论是可以从经验上证明的。罗杰·史克鲁顿在《性欲》（Sexual Desire，1986）一书中说弗洛伊德的抑制理论等确实是可以被证实的。但他仍然认为精神分析学太过于依赖隐喻，并非真正的科学。 20世纪中期以后，至少在美国精神病学家们开始逐渐减弱对心理分析学的关注。它在人文领域仍然是非常常见的理论，但在精神病学研究领域有被边缘化的趋势。","text":"简介西格蒙德·弗洛伊德（Sigmund Freud，1856—1939），奥地利心理学家、精神分析学家、哲学家，精神分析学的创始人。 他著有《梦的解析》、《性学三论》、《图腾与禁忌》等，提出了“潜意识”、“自我”、“本我”、“超我”、“伊底帕斯情结”、“欲力”、“心理防卫机制”等概念，被世人誉为“精神分析之父”。 科学哲学家卡尔·波普认为一切合理的科学理论，均具备证伪的可能，但弗洛伊德的心理学理论永远不可被证伪，因此不具备科学性。阿道夫·格伦鲍姆在《精神分析学基础》（The Foundations of Psychoanalysis，1984）中说波普的说法并不对，因为很多弗洛伊德的理论是可以从经验上证明的。罗杰·史克鲁顿在《性欲》（Sexual Desire，1986）一书中说弗洛伊德的抑制理论等确实是可以被证实的。但他仍然认为精神分析学太过于依赖隐喻，并非真正的科学。 20世纪中期以后，至少在美国精神病学家们开始逐渐减弱对心理分析学的关注。它在人文领域仍然是非常常见的理论，但在精神病学研究领域有被边缘化的趋势。 理论简介 人格：弗洛伊德认为人格或人的精神主要分成三个部分，即本我、自我与超我。“本我”（id，完全潜意识，不受主观意识的控制）代表欲望，受意识遏抑。“自我”（ego，大部分有意识）负责处理现实世界的事情。“超我”（super-ego，部分有意识）是良知或内在的道德判断。他的这一理论也叫做“冰山理论”。 @link 本我、自我与超我 - 维基百科，自由的百科全书 术语“本我”（id）、“自我”（ego）和“超我”（super-ego）并非弗洛伊德本人所创，而是其翻译家詹姆斯·斯特拉奇（James Strachey）的拉丁化翻译。弗洛伊德本人所写的“das Es”、 “das Ich”、和“das Über-Ich”——分别直译为“它”、“我”和“超越-我”。 梦：佛洛伊德认为“梦是一种在现实中实现不了和受压抑的愿望的满足”。梦是一种潜意识的活动，由于人的心理防卫机制压抑人的本我愿望，被压抑的愿望在潜意识的活动中并不会直接表达于梦中，而是通过扭曲变作为象征的形式出现，故梦都是象征的。佛洛伊德认为梦是由“显梦”（manifest dream-content）及“隐梦”（latent dream-thought）所组成的。前者乃梦的表面形式，像经过扭曲与伪装的“密码”，以表现隐梦。 潜意识：佛洛伊德的理论核心之一为潜意识。19世纪西方主流思潮为实证论，相信人可取得关于自身及其所处环境之真实认知，并以明智判断予以掌握。弗洛伊德则认为自由意志本为幻念，人无法全然意识到自我。弗洛伊德提出了意识的层次之说，“在表层之下”另有思绪运作。弗洛伊德称梦为“通往潜意识之王道”，提供参与潜意识生活的最佳入径。弗洛伊德《梦的解析》中论证潜意识的存在。 性心理发展：弗洛伊德相信个体原欲的发展，如升华概念所示，为不断转换客体。人生来即属“多相变态”（polymorphously perverse），任何客体都可能成为快感之源。随不同发展阶段，人会固著于特定欲望客体——初为口欲期（如婴儿因哺乳产生的快感），继之以肛欲期（如小儿控制肠道产生之快感），随之为性器期（phallic stage），随后是潜伏期（latency stage），而最后性器官成熟后就会达到生殖期（genital stage）。孩童接著经历固著性欲于母亲之时期，即所谓恋母情结，但因此欲望有著禁忌的本质，必须予以压抑。 生死驱力：弗洛伊德相信人类由互相冲突的两种欲望所驱动：爱欲（生存本能）与死欲（死亡本能）。弗洛伊德所说的爱欲，包含所有创造性、及产生生命的驱力。死欲代表一切有生之物内在的冲动，欲回归至平静状态，甚至最终回到不再存在。佛洛伊德提出死欲的时间要比爱欲晚，他在1920年的《超越快乐原则》中首次提出死欲。// @link @ 《存在主义心理治疗》读书笔记 “弗洛伊德派心理动力学与存在主义心理动力学的不同之处” 宗教：他在《图腾与禁忌》一书中提出男孩生命早期对母亲抱有性欲，此恋母情结为普遍存在的现象。父亲有保护部落的能力，因此男性爱慕他，但也同时因父亲与众母亲的关系而嫉妒他。儿子们了解独力无法击败领导者父亲，故合力予以杀害，之后以祭仪宴飨形式啖之，借此将父亲的力量纳入己身。然而众子之后背负的罪恶感，也使其强化对父亲的回忆，并予以祭拜。部落内也由此产生乱伦与婚姻的禁忌，并以象征性的动物牺牲取代人祭。 @ref: https://zh.wikipedia.org/zh-hans/%E8%A5%BF%E6%A0%BC%E8%92%99%E5%BE%B7%C2%B7%E5%BC%97%E6%B4%9B%E4%BC%8A%E5%BE%B7#%E7%90%86%E8%AB%96 《陀思妥耶夫斯基和弑父者》@ref: https://www.psychspace.com/psych/viewnews-13490 本文是弗洛伊德以精神分析的观点和方法阐释俄国大作家陀思妥耶夫斯基（Dostoevsky，1821—1881）文艺创作的一篇心理美学的论文。弗洛伊德认为，陀思妥耶夫斯基的《卡拉马佐夫兄弟》是俄狄浦斯情结（或称“恋母情结”）的弑父动机与赎罪欲在文学上的再现，也是陀思妥耶夫斯基的癫痫症和神经症发作在艺术上的投射。进而他指出，西方文学史上的三部“杰作”（《俄狄浦斯王》、《哈姆雷特》、《卡马拉佐夫兄弟》）均以弑父者为其同一主题，其弑父行为动机都是与情敌去争夺一个女人。弗洛伊德坚持，潜意识的情杀动机与严重罪疚感的癫痫症和神经症，既是创作文艺作品的重要起因，又是理解西方文艺“杰作”的一把钥匙。 // @link [[../64.Novel-and-Poesy/陀思妥耶夫斯基|陀思妥耶夫斯基]]","categories":[{"name":"62.Psychology","slug":"62-Psychology","permalink":"https://beefyheisenberg.github.io/categories/62-Psychology/"}],"tags":[{"name":"心理学","slug":"心理学","permalink":"https://beefyheisenberg.github.io/tags/心理学/"},{"name":"弗洛伊德","slug":"弗洛伊德","permalink":"https://beefyheisenberg.github.io/tags/弗洛伊德/"}]},{"title":"卡特尔16PF","slug":"62.Psychology/卡特尔16PF","date":"2024-01-24T01:27:53.876Z","updated":"2024-01-24T01:27:53.876Z","comments":true,"path":"62.Psychology/卡特尔16PF/","link":"","permalink":"https://beefyheisenberg.github.io/62.Psychology/卡特尔16PF/","excerpt":"","text":"卡特尔16PF（Cattell’s 16 Personality Factor，简称16PF），十六种人格因子 十六种人格因素的含义如下：","categories":[{"name":"62.Psychology","slug":"62-Psychology","permalink":"https://beefyheisenberg.github.io/categories/62-Psychology/"}],"tags":[{"name":"心理学","slug":"心理学","permalink":"https://beefyheisenberg.github.io/tags/心理学/"},{"name":"心理测评","slug":"心理测评","permalink":"https://beefyheisenberg.github.io/tags/心理测评/"}]},{"title":"盖洛普-克里夫顿优势","slug":"62.Psychology/盖洛普-克里夫顿优势","date":"2024-01-24T01:27:53.871Z","updated":"2024-01-24T01:27:53.871Z","comments":true,"path":"62.Psychology/盖洛普-克里夫顿优势/","link":"","permalink":"https://beefyheisenberg.github.io/62.Psychology/盖洛普-克里夫顿优势/","excerpt":"总览 优势1-5搜集","text":"总览 优势1-5搜集 战略 交往 思维 排难 优势5-10@todo 待整理","categories":[{"name":"62.Psychology","slug":"62-Psychology","permalink":"https://beefyheisenberg.github.io/categories/62-Psychology/"}],"tags":[{"name":"心理学","slug":"心理学","permalink":"https://beefyheisenberg.github.io/tags/心理学/"},{"name":"心理测评","slug":"心理测评","permalink":"https://beefyheisenberg.github.io/tags/心理测评/"}]},{"title":"荣格","slug":"62.Psychology/荣格","date":"2024-01-24T01:27:53.866Z","updated":"2024-01-24T01:27:53.866Z","comments":true,"path":"62.Psychology/荣格/","link":"","permalink":"https://beefyheisenberg.github.io/62.Psychology/荣格/","excerpt":"卡尔·古斯塔夫·荣格（Carl Gustav Jung，1875—1961） @ref:卡尔·荣格 - 维基百科，自由的百科全书 1895年－1900年，荣格在巴塞尔大学学习医学，随后在苏黎世伯格尔茨利精神病院谋得助理医师职位，在布鲁勒手下实习。荣格1905年任苏黎世大学精神病学讲师，后来辞去职务自己开业。荣格对弗洛伊德1900年出版的《梦的解析》很感兴趣，与之通讯，参加了弗洛伊德的精神分析运动，共同创立了一个国际精神分析学会，并任第一届主席，后因两人的学说产生分歧而决裂。由于此决裂弗洛伊德将荣格的名字一笔勾消。 @link 弗洛伊德 主要思想概述 情节（complex）：情结是个人无意识中的成份 complex一语是由Theodor Ziehen于1898年所创，由荣格在与佛洛伊德合作的时期发扬光大。荣格将complex形容为“无意识之中的一个结”。可以将情结想成一群无意识感觉与信念形成的结。这个结可以间接侦测，而表现的行为则很难理解。荣格在职业生涯早期就找到证明情结存在的证据。1910年代他在词汇关联测验中注意到受试者的行为模式暗示著此人的无意识感觉与信念。 情结有很多种，但是任何情结的核心都是一个共通的经验模式，称为原型（archetype）。荣格理论与佛洛伊德理论的关键差异是：荣格认为人类心理由好几种情结构成，而且许多情结彼此形成二元对立。佛洛伊德认为恋母情结（伊底帕斯情结）是普遍共通的，也就是所有儿童都面对伊底帕斯情结带来的发展挑战。而伊底帕斯情结也是绝大部分心理疾病的中心。随著荣格与佛洛伊德决裂，两方代表的理论也分歧了。 集体潜意识（collective unconscious），又译作“集体无意识”，指人类祖先进化过程中，集体经验心灵底层的精神沉积物，处于人类精神的最低层，为人类所普遍拥有。荣格认为在潜意识中有个人潜意识及集体潜意识。他考察非洲及美洲等地原始人类的宗教、神话、传说、童话、与梦并比较西方人与东方人的宗教、神话、传说、童话、与梦，发现许多共同的原型而得到的结论。荣格认为集体潜意识是人格中最深刻、最有力的部分，它是几千年来人类祖先经验的积累所形成的一种遗传倾向。这些遗传倾向被称为原型。各种原型在梦、幻觉、幻想、神经症中无意识地表现出来。相对于弗洛伊德的无神论顷向，荣格认为集体潜意识中充满了神的形象。 力比多（libido）：与弗洛伊德认为欲力是纯粹性的潜力不同，荣格认为力比多是普遍的生命力，除表现在生长及生殖方面外，也表现于其他活动（荣格和弗洛伊德的分歧依然基于力比多是性的或者是非性的）。","text":"卡尔·古斯塔夫·荣格（Carl Gustav Jung，1875—1961） @ref:卡尔·荣格 - 维基百科，自由的百科全书 1895年－1900年，荣格在巴塞尔大学学习医学，随后在苏黎世伯格尔茨利精神病院谋得助理医师职位，在布鲁勒手下实习。荣格1905年任苏黎世大学精神病学讲师，后来辞去职务自己开业。荣格对弗洛伊德1900年出版的《梦的解析》很感兴趣，与之通讯，参加了弗洛伊德的精神分析运动，共同创立了一个国际精神分析学会，并任第一届主席，后因两人的学说产生分歧而决裂。由于此决裂弗洛伊德将荣格的名字一笔勾消。 @link 弗洛伊德 主要思想概述 情节（complex）：情结是个人无意识中的成份 complex一语是由Theodor Ziehen于1898年所创，由荣格在与佛洛伊德合作的时期发扬光大。荣格将complex形容为“无意识之中的一个结”。可以将情结想成一群无意识感觉与信念形成的结。这个结可以间接侦测，而表现的行为则很难理解。荣格在职业生涯早期就找到证明情结存在的证据。1910年代他在词汇关联测验中注意到受试者的行为模式暗示著此人的无意识感觉与信念。 情结有很多种，但是任何情结的核心都是一个共通的经验模式，称为原型（archetype）。荣格理论与佛洛伊德理论的关键差异是：荣格认为人类心理由好几种情结构成，而且许多情结彼此形成二元对立。佛洛伊德认为恋母情结（伊底帕斯情结）是普遍共通的，也就是所有儿童都面对伊底帕斯情结带来的发展挑战。而伊底帕斯情结也是绝大部分心理疾病的中心。随著荣格与佛洛伊德决裂，两方代表的理论也分歧了。 集体潜意识（collective unconscious），又译作“集体无意识”，指人类祖先进化过程中，集体经验心灵底层的精神沉积物，处于人类精神的最低层，为人类所普遍拥有。荣格认为在潜意识中有个人潜意识及集体潜意识。他考察非洲及美洲等地原始人类的宗教、神话、传说、童话、与梦并比较西方人与东方人的宗教、神话、传说、童话、与梦，发现许多共同的原型而得到的结论。荣格认为集体潜意识是人格中最深刻、最有力的部分，它是几千年来人类祖先经验的积累所形成的一种遗传倾向。这些遗传倾向被称为原型。各种原型在梦、幻觉、幻想、神经症中无意识地表现出来。相对于弗洛伊德的无神论顷向，荣格认为集体潜意识中充满了神的形象。 力比多（libido）：与弗洛伊德认为欲力是纯粹性的潜力不同，荣格认为力比多是普遍的生命力，除表现在生长及生殖方面外，也表现于其他活动（荣格和弗洛伊德的分歧依然基于力比多是性的或者是非性的）。 原型（archetype）：原型是 集体潜意识 中荣格所发现人类不分地域与文化的共同象征。 阿尼玛（anima）：男人潜意识中的女性性格，只有一个。阿尼玛也是男人心目中女人的形象。当男人对女人有一见钟情的感觉时，他可能是将他心目中阿尼玛的形象投射在这女人身上。 阿尼玛斯（animus）：女人潜意识中的男性性格，可有多个。 自性化（Individuation 或译个体化是心灵成长的目标，也就是自我的实现（Self Realization）。其方法为融合有意识的自我与无意识中的阴影与阿尼玛或是阿尼玛斯让自我实现。 人格面具（persona） 是人们在他人眼中表现出的形象，通常是社会和公众期许的形象。指我们如何向世界、向外界展示自我（ego）。它的作用是保护自我免受负面形象的影响。在发展过程中，孩子们知道他们必须以某种方式行事，以符合社会的期望和规范。人格面具发展成一个社交面具，允许人们适应周围的世界并适应他们生活的社会。 阴影（shadow） 是一个由性和生活本能组成的原型。影子作为无意识思想的一部分存在，由压抑的思想、弱点、欲望和本能组成。阴影是我们尝试适应文化规范和期望的结果，正是这种原型包含了所有不仅对社会不可接受的事物，而且也包含了个人的个人道德和价值观念，它可能包括诸如嫉妒、贪婪、偏见、仇恨和侵略等事情，这个原型通常被描述为心灵的黑暗面，代表荒谬，混乱和未知。 自性化发展 自性化（individuation） 或自性化过程，是荣格分析心理学中的特别术语，也是其核心性的概念。你若是问荣格心理分析家们一个问题，心理分析的目的到底是什么，那么得到的最多的答案，恐怕就是自性化了。 荣格用自性化这一概念，所要表达的是这样一种过程：一个人最终成为他自己，成为一种整合性的，不可分割的，但又不同于他人的发展过程。安德鲁?塞缪斯（Andrew Samuels）在其《荣格心理分析评论词典》中，在比较了自性化与自性（self）、意识自我（ego）和原型（archetype）以及意识性（consciousness）和潜意识（unconscious）等概念的关系与整合意义之后说，“自性化过程是围绕以自性为人格核心的一种整合过程。换句话说，使一个人能够意识到他或她在哪些方面具有独特性，同时又是一个普普通通的男女。” 从荣格 1921 年出版的《心理类型》一书中，我们可以看到其最初对于自性化定义的表达。其基本的特征是： 自性化过程的目的，是人格的完善与发展； 自性化接受和包含与集体的关系，也即它不是在一种孤立状态发生的； 自性化包含着与社会规范的某种程度的对立，社会规范并不具有绝对的有效性。 @ref: 自性化发展的理论 - 心理学空间","categories":[{"name":"62.Psychology","slug":"62-Psychology","permalink":"https://beefyheisenberg.github.io/categories/62-Psychology/"}],"tags":[{"name":"心理学","slug":"心理学","permalink":"https://beefyheisenberg.github.io/tags/心理学/"},{"name":"MBTI","slug":"MBTI","permalink":"https://beefyheisenberg.github.io/tags/MBTI/"},{"name":"弗洛伊德","slug":"弗洛伊德","permalink":"https://beefyheisenberg.github.io/tags/弗洛伊德/"},{"name":"荣格","slug":"荣格","permalink":"https://beefyheisenberg.github.io/tags/荣格/"}]},{"title":"MBTI各种类型兼容关系","slug":"62.Psychology/MBTI各种类型兼容关系","date":"2024-01-24T01:27:53.862Z","updated":"2024-01-24T01:27:53.862Z","comments":true,"path":"62.Psychology/MBTI各种类型兼容关系/","link":"","permalink":"https://beefyheisenberg.github.io/62.Psychology/MBTI各种类型兼容关系/","excerpt":"@ref: 16种性格兼容关系图 下图为思想相容性，红色代表思想或价值观最不相容，蓝色代表最佳相容，不过不相容不代表不能相处。蓝色应该也指最佳拍档、最佳工作伙伴。(貌似是工作中的关系) 下图: 橘色为不喜欢，绿色为喜欢","text":"@ref: 16种性格兼容关系图 下图为思想相容性，红色代表思想或价值观最不相容，蓝色代表最佳相容，不过不相容不代表不能相处。蓝色应该也指最佳拍档、最佳工作伙伴。(貌似是工作中的关系) 下图: 橘色为不喜欢，绿色为喜欢 【因为Socionics 和MTBI有微妙不同，此图对MBTI分法不能互通，如果条件是J和P的话倒是可以参考，比如INFJ和INFP的拟恒关系，管制关系和受益关系也非常奇妙。】这方面的问题请关注Socionics小组的翻译 http://www.douban.com/group/tmxk/,原图出处 http://www.socionics.com/rel/relcht.htm 由 Yoli提供的翻译:","categories":[{"name":"62.Psychology","slug":"62-Psychology","permalink":"https://beefyheisenberg.github.io/categories/62-Psychology/"}],"tags":[{"name":"心理学","slug":"心理学","permalink":"https://beefyheisenberg.github.io/tags/心理学/"},{"name":"心理测评","slug":"心理测评","permalink":"https://beefyheisenberg.github.io/tags/心理测评/"},{"name":"MBTI","slug":"MBTI","permalink":"https://beefyheisenberg.github.io/tags/MBTI/"}]},{"title":"MBTI人格类型之INFJ","slug":"62.Psychology/MBTI人格类型之INFJ","date":"2024-01-24T01:27:53.858Z","updated":"2024-01-24T01:27:53.858Z","comments":true,"path":"62.Psychology/MBTI人格类型之INFJ/","link":"","permalink":"https://beefyheisenberg.github.io/62.Psychology/MBTI人格类型之INFJ/","excerpt":"MBTI偏好MBTI通过以下偏好将人们归类： 如何集中注意力或他们的能量来源（外向性或内向性） 如何接受讯息（感觉或直觉） 主要靠什么作出决定（情感或思考） 如何对待外在的世界（判断或理解） 因为运用他们在这些领域的偏好，人们发展出了荣格和迈尔斯所说的人格类型。这根本的人格是来自四种偏好的动态交互作用，同时也有外在环境的影响以及个人的倾向。人们比较可能在他们的人格类型基础上发展习惯、举止和态度。 I——内倾相对于外倾。INFJ倾向于宁静和有所保留。于社交中，他们消耗能量（同样的情况下，外倾者获得能量）。 N——直觉相对于感觉。相比关心具体事物，INFJ更加关心于抽象事物。他们更倾向于关注整体而不是细节，关注未来的可能性而非最切近的现实。 F——感情相对于理性。INFJ通常认为个人偏好高于客观标准。在做决定的时候，他们通常更侧重于人情世故而非逻辑。 J——判断相对于理解。INFJ倾向于计划他们的活动，并早早地作出决定。他们从可预见性得到掌控之感，在同一方面理解型的人可能看起来被限制。","text":"MBTI偏好MBTI通过以下偏好将人们归类： 如何集中注意力或他们的能量来源（外向性或内向性） 如何接受讯息（感觉或直觉） 主要靠什么作出决定（情感或思考） 如何对待外在的世界（判断或理解） 因为运用他们在这些领域的偏好，人们发展出了荣格和迈尔斯所说的人格类型。这根本的人格是来自四种偏好的动态交互作用，同时也有外在环境的影响以及个人的倾向。人们比较可能在他们的人格类型基础上发展习惯、举止和态度。 I——内倾相对于外倾。INFJ倾向于宁静和有所保留。于社交中，他们消耗能量（同样的情况下，外倾者获得能量）。 N——直觉相对于感觉。相比关心具体事物，INFJ更加关心于抽象事物。他们更倾向于关注整体而不是细节，关注未来的可能性而非最切近的现实。 F——感情相对于理性。INFJ通常认为个人偏好高于客观标准。在做决定的时候，他们通常更侧重于人情世故而非逻辑。 J——判断相对于理解。INFJ倾向于计划他们的活动，并早早地作出决定。他们从可预见性得到掌控之感，在同一方面理解型的人可能看起来被限制。 @ref: INFJ - 维基百科，自由的百科全书 认知功能（Cognitive Functions） &amp; 人格成长（一）主要功能分析INFJ的主要认知功能：Ni-Fe-Ti-Se，隐藏功能：Ne-Fi-Te-Si 主要功能 Ni：主导功能（这是我们最值得信赖和最常使用的功能，通常是相当成熟完善的） 有Ni的人最好发展出他们的Fe（对于INFJ）或者Te（对于INTJ）功能。如果一个Ni使用者“太活在自己的脑袋里”的话，就会对事件产生不切实际或者虚构的诠释；拒绝新的体验经历会导致Ni变得越来越不准确。Fe和Te更多地处理观察外部世界。 要充分地了解INFJ，就必须理解他们的主导功能「内向直觉(Ni)」——作为一种感知功能的含义所在。也就是说，在内心深处，INFJ其实远没有表面看上去那么严肃（对比来看：ENFJ由于其主导功能是判断功能，所以反而要更严肃）。INFJ的内心世界被描述为有趣的、富有想象力的、丰富多彩的、孩子气的和大胆的。他们喜欢玩弄思想、观点、理论、图像、符号和隐喻。INFJ通常能看到每个人身上的两面性。他们不仅能看到——其他人都能看到的——表面的部分，更重要的是，「内向直觉(Ni)」的功能使得他们对人有一种更深层次的判断——能穿透表面、揭露隐藏的动机和意图。因此，INFJ经常觉得他们比那些人自己更透彻地了解他们。“直觉”通常被认为是一种潜意识的过程。它常常与更有意识的“理性思考”形成对比。因为“直觉”通常与“无意识”联系在一起，因此人们通常认为它具有某种神奇的品质，能够迅速地提供某种全面的答案或是解决方案——“从天而降一般”。“直觉”的核心特征之一是它整合信息的能力，它对“模式”和“相似性”敏感，能够快速地发现不同数据之间的联系。通过观察所有事物的联系，识别出普遍的规律和结构。由于Ni功能提供给INFJ的信息与大多数人所说的“潜意识的运作”有着更为密切的联系，因此，INFJ的日常生活中也经常会有一种梦幻般的特质。对于INFJ来说，他们清醒状态和睡眠状态之间的区别就更少了。有时，甚至会很难将梦与现实区分开来，这也使得噩梦对INFJ来说更让人不安。正因如此，许多INJ，包括荣格自己，都觉得“梦的分析”是如此的重要和有趣。 辅助功能 Fe：辅助功能（当主导功能内倾时，外倾的辅助功能是我们与外界打交道的方式） Fe寻找社会上的联系，并用礼貌、体贴、得体的举止营造和谐的沟通。Fe对他人明确（或暗示）的需求作出回应，甚至可能会制造内在自我需求和欲望的冲突来满足别人； INFJ将Fe作为辅助功能。作为所有功能中最具人际作用的功能，Fe功能可以调查和改善人际关系、提升士气。与其他的FJ类型一样，INFJ也致力于在人际环境中培养“良好的情感”。为了调查别人的感受，Fe功能帮助INFJ去读懂别人的情感表达和肢体语言。他们喜欢花时间在有意义的谈话中，这使得他们能够同时发挥到他们的主导功能「内向直觉(Ni)」以及辅助功能「外向情感(Fe)」。“对话”提供了INFJ帮助和启发他人的机会。而且由于他们的健谈（某些情况下），INFJ还常常会被误认为是性格外向的人。有趣的是，在感知和理解自己的情感方面，INFJ往往还更困难一些。这是由于他们的感觉功能Fe是外在的(也就是外向的），而不是内在的。不像INFP，它的感觉功能是内向的(Fi)。INFJ没有独立管理自己情绪的能力，在内部，他们用直觉(Ni)和思考(Ti)处理问题，因此，当INFJ发现自己处于繁重的情感压力之下，他们常常求助于他人。假设INFJ在成长过程中没有受到严格的监察，那么他们通常是乐于分享他们的感受和观点的。事实上，只要有合适的机会，INFJ经常会详细地讨论他们的感受和直觉。与FP型所不同的是，FP型通常更喜欢对话的形式，而INFJ倾向于独白，这允许他们在某个主题上完全充实自己的想法。INFJ的Fe功能在“亲密的人”和“陌生人”中的表现是有所不同的。在更大的群体中，INFJ似乎一直都能努力营造愉快、良好的情感氛围。在亲密关系中，INFJ却通常用他们的Fe功能进行更坦率和直接的抱怨。对INFJ来说，通过他们的Fe功能表达自己对他们的心理健康重要。即使这样做并不能为他们提供立即解决问题的方法，但一旦他们表达了自己的情感，他们也往往会感觉好一些——能够意识到这一点对于INFJ的伴侣或朋友来说非常重要。虽然并不是要寻找别人来解决问题，但INFJ确实非常重视情感的支持、同情和安慰。如果没有这样的出口，INFJ就会开始感到孤独和沮丧，转而求助于自己内心的幻想世界作为逃避的手段。虽然“幻想”在短期内看起来很有帮助，但它却使得现实世界变得更加难以忍受，并使现有的生活挫折更加恶化。即使并不到EFJ那样的程度，但INFJ也可以是热情的、欢迎的、忠诚的、给予的和自我牺牲的。但同时，作为内向型人格，INFJ常常需要独处的时间来给自己充电。这将是一个持续一生的struggle——在平衡自我的需求和满足他人的欲望之间的struggle。 第三功能 Ti：第三功能（为我们提供了恢复自我的途径。是配角的替补，并经常与配角共同协作） Ti寻求精确，比如表达一个概念最合适的词。它注意到事物本质之间微不足道的差别，然后将它们分析并归类。Ti细查一个问题的每一面，寻找解决问题最不费力、风险最小的方法。它用模型甄别出逻辑上的不一致。 对INFJ来说，Ti是第三功能，它被用来对Fe功能的判断进行逻辑审查和打磨。Ti可以帮助INFJ更具批判性、分析性地思考，可以帮助检查INFJ的Ni-Fe功能，帮助他们辨别他们的想法要怎样去适应于现有的类别和知识框架。Ti功能帮助INFJ添加了一种在他们早期发展阶段并不显著的“逻辑元素”。例如，在一个宗教家庭长大的INFJ可能会直觉性地用童年的信仰来解读自己的见解，但当他开始发展自己的Ti功能后，他会开始学会质疑，会想是否要用心理学的知识去解读它。INFJ可能认为Ti功能存在的一个负面因素是它会导致“自我怀疑”的倾向。随着Ti功能对其Ni功能洞察力的反对，INFJ会暂时不再信任他们曾经最珍视和最常用的认知方式——他们的直觉。对任何人的成长而言，这都不会是一件容易的事情。但随着时间的推移，INFJ会逐渐在他们的Ni功能和Ti功能之间达成一种健康的平衡，他们会直觉性地知道如何去运用他们的Ti功能，而又不破坏他们的直觉。 劣势功能 Se：劣势功能（龙套演员通常在我们中年以前并未发展。我们通常是先遇到它在跟我们捣乱，作为我们的内心的命令、恐惧及其他负面情绪出现。一旦我们学会去信赖并发展它，龙套演员能够成为平衡我们生活的桥梁，连通我们的目标、灵感、理想） Se集中于当下的、物质的世界所带来的体验和感觉。以对当下周遭事情的敏锐察觉，它带来关于前方的相对事实和细节，而且可能导致自发的行动。 做为INFJ的第四功能（或者叫“缺失功能”），Se是一种外向的感知功能。一般来说，这种次一级的感知功能使得INFJ对生活的具体细节或现实要素并不敏感。当他们的Se功能从周围世界里获取了大量的感官数据后，这些信息却经过INFJ的Ni功能进行抽象和整合，因此相较于周围环境的细节，INFJ更倾向于体验到一种整体的“印象”。他们有一个对人和事物大致的概念（或直觉），例如这个人精神健康或不健康。尽管在涉及到整体印象时，INFJ通常都是专家，但他们太过于忽略外部的特征和细节(Se)。Se功能更在意事物的外在表象，与此相对的「内向直觉(Ni)」的功能更关注深层次的“性质”和“本源”。例如：即使INJ在某种程度上也会关心外表，但他们更在意事物的内在质量和工艺，确保事物是实质性的、精心制作的、至少是符合他们自己“Ni-Se”品味的。 Se是infj的劣势功能，此功能也可以称为阿尼玛或阿尼姆斯。荣格认为每个人心中都有人格的阴影面(男性心里有 一个女性自我原型叫做阿尼玛anima,女性心里有一个男性原型叫做阿尼姆斯animus),作为怎么发展都发展不好的劣势功能，投射于外界就是最容易一见钟情的异性类型。所谓的一见钟情， 钟的不过是自己而已。 总的来说，infj对 Se的人又爱又怕(因为劣势功能容易失控)，不过Se型人可以带着infj更加入世，增加生活的实感，还能使infj找到自己的阴影面，补充人格的完整性。 隐藏功能：后来的人格类型研究者（特别是琳达·V·贝伦斯）[22]在这个降序排列中添加了四个附加功能。这些功能被称为隐藏功能，因为一个人并不自然地倾向于它们，但在压力之下它们也会浮现。对INFJ来说，这些隐藏功能是： 外倾直觉（Ne） Ne寻找并解释隐含意义，用“如果”开头的问题来探索选择，允许多种可能性共存。这种想象中的游戏把直觉和来自多种不同来源的经验结合在一起成为新的，这可能成为行动的催化剂。 内倾情感（Fi） Fi过滤讯息，这种过滤的基础是缘于标准（经常是无形的）形成的判断。Fi时常协调价值观。在各种情形下，它天生地和微妙的差别相合，并知道什么是对什么是错。 外倾思考（Te） Te组织、安排环境和想法，好成功达成目标。Te寻求行动、事件和结论的合理解释，并试图找到逻辑的错误和序列中的间隔。 内倾感觉（Si） Si收集关于当下的数据，然后把它们和过去的经验比较，这过程有时候随着记忆唤起与之关联的感觉，就好像再体验一遍过去。为寻求保护那些熟悉的东西，Si回溯历史，用以形成对未来的期望和目标。 （二）成长和功能发展正如所有类型一样，INFJ的人格发展包括三个阶段。这些阶段的发展过程大致相当于“功能类型”的排序过程，Ni功能是第一个发展的功能，以此类推是Fe功能，Ti功能和Se功能。但正如我们所看到的那样，第四功能Se是一种特殊的情况。 • 阶段一（孩童期）：第一功能和次要功能，通常是自孩提时代就开始尝试使用的功能，也是每个类型相对运用最熟练的 在早期的生活中，INFJ的性格特征完全受他们Ni功能的发展所支配。同时，尽管他们是内向型人格，但也会表现出辅助功能Fe的重要特征——Fe可以作为一个有效的外向型工具来帮助INFJ探索外部世界。 Ni-Fe功能一起主导了INFJ“做出判断”和“表达见解”的模式与方法。INFJ尤其擅长阅读和评估他人，包括评估他们的隐藏动机。 由于Ni是一种感知功能，因此在发展的过程中， INFJ其实不应该被看作是一个封闭状态。然而，当他们处在第一阶段（孩童期）时，却又常常会显得过于固执己见或思想封闭。在这一阶段，即使他们的判断是非常准确的，但他们也可能并不知道如何在恰当的时机、以恰当的方式去表达这些判断和观点。 • 阶段二（青少年期－30s）：第四功能（Se）先于第三功能（Ti）浮现，这可能是源自“主导功能疲劳”，但这个年龄段的第四功能，往往是“错误抉择的罪魁祸首” 一旦［主导功能Ni］训练到了一定的强度和支配地位，INFJ的第四功能Se便会开始进入到INFJ的视线中，并逐渐扮演起更有影响力的角色。这可能会让人困惑，因为在功能类型排序中，第四功能Se并不是下一个首当其冲就待开发的功能。而第四功能Se的过度影响还来源于它与主导功能Ni之间的冲突性（主导功能疲劳，dominant function fatigue）。正如我们在其他地方所讨论过的那样，第四功能Se是导致不明智的“职业选择”和“关系决策”的罪魁祸首。可是不幸的是，这一功能的影响力在INFJ的第二阶段正好达到顶峰，而这一阶段又正是INFJ需要在职业生涯和人际关系中做出重要决定的关键时期。 除了第四功能Se开始越来越多的存在并发挥影响力之外，INFJ也开始用他们的第三功能Ti来开拓和打磨他们的判断，他们的Ti功能会反复地核对和提炼他们在Ni-Fe功能下的判断结论。随着INFJ开发他们的Ti功能，他们也变得更有兴趣去探索他们的第四功能Se。 • 阶段三（30s，40s，及以后）：通向“完整人格”的道路 这一阶段是很多人终其一生也未曾达到或完成的阶段。其特征是试图理解和整合第三功能和第四功能。通过将这些无意识的功能引入到有意识的光芒中，我们可以更好地想象我们通向“完整”的道路。而做到这一点需要我们去理解这些功能是如何在我们的人格中表现出来的，并且越来越意识到我们的“无意识行为模式”。一旦这些无意识的行为模式显现出来，它们就可以被更健康的思想和行为所引导。决定和行为都将变得越来越明智和有意识，最终产生持久的满足感和完整性。 对INFJ来说，第三阶段的个人成长需要更深入地探索他们的第三功能Ti和第四功能Se的本质以及它们之间富有挑战性的关系。 通常发展不够完全的INFJ可能会认为并不需要开发他们的Ti功能。因为他们的 Ni-Fe功能配对已经能为他们提供一套关于真理的坚定信念，因此，再采取额外的步骤去发展Ti功能似乎是不必要的事情。然而，随着时间的推移和逐渐成熟，INFJ会越来越适应他们的Ti功能，并认识到它的内在价值。 生命是一场对“精神灵性发展整合”的持续追求。而从人格型上说，这需要找到方法去成功地整合自己的功能类型。在四个功能中，第四功能——有时称为遗失的、被抑制的功能——是最难探寻和整合的。因为它很大程度上是无意识的，因此所有人格型都很难理解到“第四功能”的本质。 如果没有第四功能，我们终归实现不了精神上的整体性和统一性。我们都直觉性地知道，每一种人格型最终都在努力地整合其第四功能，即便是在宗教和文学神话中，这种探索也一直是非常重要的（例如：寻找“乐土”或“圣杯”），然而不幸的是，追求、甚至说去整合第四功能是一件相当困难的事情。这样做通常会导致主导功能和第四功能之间长年累月的角逐斗争（就如第二阶段发展的那样)，几乎没有人能在没有痛苦和煎熬的情况下解决这件事情。 （三）艰难的完美主义者： 在面对自己时，INFJ也是完美主义者。甚至他们对自己会比对别人要严苛得多，他们的Fe功能使得他们更愿意去原谅别人的过错和缺点。但由于他们认为自己是“知道得更多”的人，所以没办法对自己给予同样的宽厚。他们会认为，如果他们自己不能完美地展示他们的道德理想，那么他们又怎能合理去期望他人呢？就像耶稣所说的那样：“凡被给予的人，都将被要求；凡被委以重任的人，会有更多的要求。” @ref: MBTI人格系列翻译整理①—— INFJ圣人型-Rina’s 01：作为主导功能，Ni在INFJ的幼年就初见端倪。小时候的INFJ会表现出比其他孩子更好的理解领悟能力，以及Ni喜欢想象力带来的快乐。 在Ni的高速发展时期，会极力想要霸占个体的注意力，抑制其他辅助功能，尤其是同为感知功能的Se。这是原理上Se是INFJ的劣势功能的原因，个体会非常喜欢沉浸在自己的世界，忽视外界的声音，忽略客观事实。Se的发展缺失，也给个体后期成长受阻埋下了伏笔。他们终将面对发展劣势功能的人生课题，这是后话。 Ni是INFJ快乐和能量的源泉，也是根据地。未来INFJ会以此为中心发展其它辅助功能，并会在受伤虚弱时逃回来疗伤、获取能量补给。 02：当INFJ与外界互动时，使用的是第二功能Fe外向情感。严格说，是个体选择主导功能Ni+第二功能Fe，决定了他向完整的INFJ类型发展。 大部分INFJ年幼时，在人际上都经历过三种境遇： ① Ni主导功能过于霸道，阻碍其他功能发展。表现为INFJ非常内向，沉溺于自己内心世界的安全区内。但Fe能感知到他人对自己的情感需求，认为自己有义务做点什么来满足对方。这时的INFJ表现为心怀友善，但有些害羞或害怕，不愿主动与人交流互动，但内心是自责的。 ② Fe获得良性发展，INFJ会积极友善地与他人进行情感互动，非常温柔体贴，善解人意。这时的INFJ会非常乖巧，会主动表达对父母的爱意，热情回应别人的情感交流，对世界充满友好和美妙的期待。 ③ Fe过度发展，INFJ会过于考虑别人的感受，讨好他人而失去自我：如果我做这件事，会不会让别人伤心，我怎样才能让所有人满意……这会给INFJ做决策造成阻碍，在人情中难以自拔。并且在Ti初步发展之时，INFJ经常在“我认为怎么做最合理”和“别人希望我怎么做”之间产生自我矛盾，非常纠结。不成熟的INFJ通常的选择是委屈自己顺从他人意愿，因为他们对自身道德要求极高，不允许自己有任何自私的表现。 从“Ni-Fe”的角度来看INFJ的人际相处： INFJ喜欢被认为是友好和善的，但INFJ的无限包容往往只存在于浅交。其实他们内心非常严肃且挑剔，走近INFJ内心的人会认为他们如此冷漠。 Ni洞悉人际关系的本质，但Fe要求人际关系的和谐，INFJ想的是，即便我能看透险恶，又何必说出来伤害那些简单快乐的人呢？INFJ的面具，终究是用于保护对方。所以INFJ学会尽可能深地隐藏真实想法。很多人觉得走不进INFJ的内心，总有种距离感，猜度INFJ表里不一。 Ni-Fe的组合有道德洁癖的倾向，他们习惯解读自己和他人的内心活动，当扫描到内心深处的自私和欲望，会立马警觉。如果这自私和欲望来自自己，INFJ会马上纠正自己的心态；如果是别人的，INFJ深知利己是人的本性，会“慈悲地原谅”他，继续与他做朋友，但最高限度是熟人而不是知己。 03：INFJ的第三功能Ti开始快速发展，通常需要一个契机。Ti是为了平衡第二功能Fe而存在的，它是替补队员，顾名思义，它会在必要时替代Fe来做理性分析。 04：不得不说INFJ的劣势功能Se，是很多年轻的INFJ迈不过去的一道坎。Se是在外部世界的体验感受，是活在当下与环境的互动。 Se不足还体现在事务的执行力并不强。表现为INFJ喜欢帮别人，但主要是帮对方找出解决难题的出路，而不是在别人忙不过来时打下手。初入社会，INFJ可能会被认为眼高手低，如果事业上不如意，INFJ也会质疑自己的能力是否能实现理想，甚至质疑理想是否不过是幻想。 人格发展不完善、劣势功能发展不足，还体现在无法掌控劣势功能的报复式崛起。Se的一个表现是享乐主义，INFJ并不觉得享受生活是一件多么有意义的事，认为自己应当从这种动物本性超脱出来。诚然，他们不会把金钱、美食、美色当做毕生所求，却非常有可能把它们当做发泄情绪的出口。INFJ有可能受到压力和打击后，吃喝无度，贪恋美色，生活堕落奢靡，又会因自己无力抵制本性的贪婪懒惰而羞愧，责难自己和恢复元气的过程是非常耗能又浪费生命的。 @ref: 详解INFJ由幼稚到成熟的性格动态发展过程 INFJ的「Ni-Ti loop」何谓“一三循环”？每种MBTI人格类型有4个认知功能，其中主导功能+第三功能是同向的（都是e或者都是i向），在特定外部环境刺激下，有可能进入一三功能循环，也即过度使用 同方向的第一和第三功能，而完全忽视了 相反方向的第二功能，故进入“一三循环”是一种不健康的状态。 例如，INFP/ISTJ一三功能即Fi-Si循环（相关性：回避型人格障碍），ENFP/ESTJ一三功能即Ne-Te循环（相关性：边缘性人格障碍），INTJ/ISFP一三功能即Ni-Fi循环（相关性：偏执型人格障碍），INFJ/ISTP一三功能即Ni-Ti循环（相关性：类精神分裂症人格障碍）； INFJ的负面循环？7分钟带你了解INFJ的Ni-Ti loop_bilibili 谁能介绍一下mbti中的一三功能循环？ - 知乎","categories":[{"name":"62.Psychology","slug":"62-Psychology","permalink":"https://beefyheisenberg.github.io/categories/62-Psychology/"}],"tags":[{"name":"心理学","slug":"心理学","permalink":"https://beefyheisenberg.github.io/tags/心理学/"},{"name":"心理测评","slug":"心理测评","permalink":"https://beefyheisenberg.github.io/tags/心理测评/"},{"name":"MBTI","slug":"MBTI","permalink":"https://beefyheisenberg.github.io/tags/MBTI/"}]},{"title":"MBTI","slug":"62.Psychology/MBTI笔记","date":"2024-01-24T01:27:53.852Z","updated":"2024-01-24T01:27:53.854Z","comments":true,"path":"62.Psychology/MBTI笔记/","link":"","permalink":"https://beefyheisenberg.github.io/62.Psychology/MBTI笔记/","excerpt":"在人格类型学中，迈尔斯-布里格斯性格分类指标（英语：Myers-Briggs Type Indicator，简称MBTI）是一种内省的自我报告问卷，表明人们在如何看待世界和做出决定方面存在不同的心理偏好。该测试试图为四个类别中的每一个分配一个值：内向（I）或外向（E），感觉（S）或直觉（N），思考或感觉，以及判断或感知。从每个类别中抽取一个字母来产生四个字母的测试结果。 MBTI的起源和发展(1) 荣格: 《心理类型》, 《心理学》。荣格八维最初的概念来源于荣格的著作《心理类型》（Psychological Types）1921，被收录在《荣格文集》第六卷中。 《心理类型》阐述了荣格的心理类型理论。在这本书里，荣格提出意识具有四种功能：两种非理性功能，即知觉（Sensation）和直觉；两种理性功能，即思维和情感。 荣格认为意识具有理性和非理性两面，他在自传中曾说：”心灵的钟摆往返于理智与非理智之间，而不是正确与谬误之间”。意识的四种功能又受到两种态度，即外向性与内向性的影响。荣格提出，占主导地位的功能和占主导地位的态度共同构成了意识的特点，而占次要地位的功能或态度则处于被压抑的状态并构成了无意识的特点。","text":"在人格类型学中，迈尔斯-布里格斯性格分类指标（英语：Myers-Briggs Type Indicator，简称MBTI）是一种内省的自我报告问卷，表明人们在如何看待世界和做出决定方面存在不同的心理偏好。该测试试图为四个类别中的每一个分配一个值：内向（I）或外向（E），感觉（S）或直觉（N），思考或感觉，以及判断或感知。从每个类别中抽取一个字母来产生四个字母的测试结果。 MBTI的起源和发展(1) 荣格: 《心理类型》, 《心理学》。荣格八维最初的概念来源于荣格的著作《心理类型》（Psychological Types）1921，被收录在《荣格文集》第六卷中。 《心理类型》阐述了荣格的心理类型理论。在这本书里，荣格提出意识具有四种功能：两种非理性功能，即知觉（Sensation）和直觉；两种理性功能，即思维和情感。 荣格认为意识具有理性和非理性两面，他在自传中曾说：”心灵的钟摆往返于理智与非理智之间，而不是正确与谬误之间”。意识的四种功能又受到两种态度，即外向性与内向性的影响。荣格提出，占主导地位的功能和占主导地位的态度共同构成了意识的特点，而占次要地位的功能或态度则处于被压抑的状态并构成了无意识的特点。 态度类型 由个体对客体的态度进行区分，分为内向型和外向型（I/E) 功能类型 根据判断性和知觉性分为4种，判断功能包括思维和情感（T/F），知觉功能包括感觉和直觉（S/N），其中判断功能反映了我们如何做决定，知觉功能反映了我们如何收集信息。 四种功能 和 两种态度 一共可以组合出八种心理类型： 外倾知觉/内倾知觉（Extraverted sensation / Introverted sensation） 外倾直觉/内倾直觉（Extraverted intuition / Introverted intuition） 外倾思维/内倾思维（Extraverted thinking / Introverted thinking） 外倾情感/内倾情感（Extraverted feeling / Introverted feeling） @link: 荣格 (2) MBTI: 也即迈尔斯-布里格斯性格分类法, （英语：Myers-Briggs Type Indicator，简称MBTI）是性格分类理论模型的一种，其基本理论是根据瑞士心理分析家卡尔·荣格于1921年所出版的书籍《心理类型》。最先的研究者是美国心理学家凯瑟琳·布里格斯及其女儿伊莎贝尔·迈尔斯（Isabel Myers）。 伊莎贝尔·迈尔斯对内向的概念特别着迷，她将自己打成INFP。然而，她觉得这本书对普通大众来说太复杂了，因此她试图组织荣格的认知功能，使其更容易理解。《Briggs Myers Type Indicator Handbook》 was published in 1944 (3) 凯尔西气质:美国心理学家大卫·凯尔西（David West Keirsey），在最受欢迎的出版书籍《请理解我》（1978）中，大卫·凯尔西设计了一种自我评估的性格问卷，称为“凯尔西的气质分类法” （Keirsey Temperament Sorter）。凯尔西用柏拉图著作中的典型人物类型，构造了以下四种气质，并与MBTI做了对应： NT - 理性者 Rational NF - 理想主义者 Idealist SP - 技艺者 Artisan SJ - 护卫者 Guardian (4) 现代：使用荣格八维包装过的各类心理/职场/社交测试 … 16Personality: Soul : 星球 MBTI模型（四维度） • “外向”与“内向”: 发泄及获得心灵能量的方向。 外向型（E，Extroverts）外向型会偏向从与外部事物的交流促进心灵能量的流动。外倾的人倾向于将注意力和精力投注在外部世界，外在的人，外在的物，外在的环境等。 内向型（I，Introverts）内向型会偏向从自身思索、内省的过程促进心灵能量的流动。内倾的人则相反，较为关注自我的内部状况，如内心情感、思想。两种类型的个体在自己偏好的世界里会感觉自在、充满活力，而到相反的世界里则会不安、疲惫。 • “实感”与“直觉”: 泛指人们认识世界、处理资讯的方法。 实感型（S，Sensing）喜欢着眼于当前事物，惯于先使用五感来感受世界。S（实感型）型的人关注的是事实本身，注重事物细节。结论；感觉型的人信赖五官听到、看到、闻到、感觉到、尝到的实实在在、有形有据的事实和信息。 直觉型（N，Intuition）关注具体事物背后的意义、以及不同概念之间的联系，着重可能性及预感，从潜意识及事物间的关联来理解世界。N（直觉型）型的人注重的是基于事实背后的含义、关系和抽象结论。 私下里直觉N型的人认为感觉S型的人为世俗所束缚又缺乏想像力，而感觉型的人觉得直觉型的人不切实际 • “情感”与“思考”: 情感及思考是下决定时内心挣扎所侧重的方向，并配合以上的能量走向。 情感型（F，Feeling）比起事情的逻辑更重视于人的感受。F（情感型）型的人常从自我的价值观念出发，变通地贯彻规章制度，做出一些自己认定是对的决策，比较关注决策可能给他人带来的情绪体验，人情味较多。 思考型（T，Thinking）比起人的感受更重视于事情的逻辑。T（思考型）型的人则比较注重依据客观事实的分析，一以贯之、一视同仁地贯彻规章制度，不太习惯根据人情因素变通，哪怕做出的决定并不令人舒服。 • “判断”与“感知”: 世界观及生活模式 判断型（J，Judging）倾向于以结构化的方式认识世界，井然有序及有组织的生活，而且喜欢安顿一切事物。在处事方式上，判断型的人目的性较强，一板一眼，他们喜欢有计划、有条理的世界，更愿意以比较有序的方式生活。 感知型（P，Perceiving）则倾向于以非结构化的方式认识世界，始终开放选择机会，自然发生及弹性的生活。知觉型的人好奇性、适宜性强，他们会不断关注新的信息，喜欢变化，也会考虑许多可能的变化因素，更愿意以比较灵活、随意、开放的方式生活。 要注意的是，判断（Judging）并不等同决断（Judgmental，包含主观及冲动的意思），而感知（Perceiving）亦不解作知觉（Perceptive，指对感觉作出反应的程度）。判断型人(J)比知觉型人(P)更专注，而且更加容易接受一件事的终止。 J主导的人很少会错过截止日期或者约会迟到。知觉型人更加乐天，通常会同时进行好几个项目，对于截止日期也会随便一点。当在做重大决策比如买车时，知觉型人更享受收集信息，对比商品的部分，但是一旦做出决定又会有点不安心－担心是否需要做更多的调查。判断型的人则会更高兴车已经买了和款也付了。 你到底是 J 还是 P1.你是 J 还是 P 指的只是你外在的表现（outward presentation).他指明了你的第一个外倾功能是外倾的判断功能（即 Fe 或 Te），还是外倾的感知功能（即 Ne 或 Se）。记住你的第一个外倾功能可以是主要功能（对于外向者来说）或者是辅助功能（对于内向者来说） 2.如果你是个外向者，那么你的主要功能的特性跟你的 J-P 指代的功能相同。比如 ENTP 的主要功能 Ne 是个感知功能。这样 ENTP 就是一个 P 型而且主要功能是感知的类型。 3.如果你是个内向者，那么你的主要功能的特性跟你的 J-P 指代的功能相反。比如 INFJ 的主要功能 Ni 是个感知功能，但是 INFJ 是个 J 型，因为他们的第一个外倾功能 Fe 是个判断功能。也就是说即使 INFJ 是以感知为主要功能，他们还是被归类为 J 型。 4.P 型向外感知而且适应性好。然而，他们不一定是凌乱，无组织，总是迟到…的拖延症患者（特别是 IP）。尽管通过对个人与其功能的更详细的分析，这些特性（指前一句中的那些形容词）可以得到很好的解释，但是我们不能仅仅通过一个人个性的末尾字母是 J 还是Ｐ那样自负地预言 5.J 型对外是坚定的，直接的，固执己见的。然而，他们不一定是那么整洁，干净，有组织，神经质…（特别是 IJ）。实际上，作为一个内向的感知者，IJ 们内心可能开放随性，虽然从外表上看不是那么明显。 @ref: https://www.douban.com/note/491203863/?_i=5030516Ffclj2I,5037766A8LpzFZ 16种人格类型 有用的链接： 你是否因为自己的人格类型而产生偏见 如何操纵，哦不对，吸引不同类型的人（潘多拉魔盒打开了） 给16种人格的一句话建议 国外对16种人格的Stereotype（毒舌版） 八维认知功能 ps. 大部分MBTI的资料中，“八维功能”写为 “Cognitive Functions”，有些资料也写作 “Mental Processes” 在各个类型里，认知或心理的四种组合：感觉、直觉、思考与情感会被分配成不同次序。此类缩写是一种快捷方式来描出这种内向与外向稍为不同的次序，需要记住的是，首末字母是导引出中间两个字母的主要先后的。本条目之认知功能表便动态地列出了每种类型。 若然首字母是“E”，例如ESTJ，那么其优势主导便是外向。下一步骤便须找出中间适用哪两个字母。假如最后字母为“P”，在此例子中，第二个字母会成为主导，即认知功能“感觉型（Sensing）”；若是“J”便会成为第三字母，在此例子是“T”，思考型（Thinking）。因此，我们能够指出ESTJ的第一或主导功能是外向思考（Te），其次便是内向感觉（Si）。第三位乃辅助的相反，在此例子中是外向直觉（Ne），最下位则为内向情感（Fi） 若然首字母是“I”，例如INFP，那么其优势主导便是内向。得悉最后指明哪个是外向功能的字母，便能找出中间适用的两个字母。在找出中间适用哪两个字母时，使用的原则，正好与外向的原则相反，假如最后字母为“J”，在此例子中，第二个字母会成为主导，即认知功能“直觉型（Intuition）”；若是“P”便会是第三字母成为主导，在此例子是“F”，情感型（Feeling）。因此，我们能够指出INFP的第一或主导功能是内向情感（Fi），其次便是外向直觉（Ne）。第三位乃辅助的相反，在此例子中是内向感觉（Si），最下位则为外向思考（Te） 按照如上的组合方式，认知功能有8个： Ni（内倾直觉）：抽象思维，收敛 Ne（外倾直觉）：抽象思维，发散 Ti（内倾思考）：事物内部运行原理，着重于逻辑框架的建立 Te（外倾思考）：理解与整理外部世界，着重于结果导向 Si（外倾感觉）：传统，经验主义 Se（外倾感觉）：体验，活在当下 Fi（内倾情感）：我的感受是什么样的？ Fe（外倾情感）：对方感受是怎么样的？ 每种功能的详细说明，参考： 内倾直觉Ni内倾直觉处理通过内部的直觉分析来理解世界的运转。Ni依赖对于一个情况的第六感与直觉来理解。Ni不看那些眼睛看得到的东西。Ni会形成一个事物如何运转的内部地图和框架。 外向直觉NeNe处理对于外部世界的经验和各种可能性的感知。Ne显示了生活中所有的事情都有内在联系，使用者可以通过不同的多元观点看待这个世界。 内倾思考Ti使用Ti的人想要以逻辑思维来弄清这个世界。他们对于这个世界如何运转组织起一个内部框架，并通过人生经历和实践不断地修正这个框架。内倾思考者的目标是创造出一个知识的网络，在这个网络里所有的事物都互相联系着。 Te外倾思考外倾思考主要用于理解与整理外部世界。Te想要全部的事情都有逻辑意义，对于没有结果的事情缺乏耐心。Te想要控制周围的环境，如果不能塑造自己周围的外部世界，他们会感觉很失落。外倾思考者们以逻辑和顺序来看待任务。 Si内向感受内向感受首先是来处理回忆过去发生事情事实和细节。 Si使用者拥有非常好的记忆力，能够精确地回忆起往事的点滴。 Si使用者相信过去是非常好的未来指向标，并运用这点来做决策。内向感受是以传统和惯例为导向的。他们谨遵传统礼仪。 Se 外倾感觉外倾感觉主要处理当下外部世界的经历和感知。Se看，闻，听，感觉和触摸外部世界发生的一切。他们不断地接受新的经历，审时度势周遭的环境。Se们活在当下。他们在刺激的新经历下茁壮成长。他们是典型的运动员，喜欢向世界展示自己的才能。他们同时也很有审美眼光，对喜欢享受精致的生活。 内向情感FiFi是与感觉和信仰有关的功能。 不像外向情感Fe，Fe对外界环境和他人的情感做出反应， 而Fi处理道德和他人真正的信仰。相比较Fi更复杂也更有深度。Fi的使用者通常会以寻找个人的价值为目标，比如我是谁？ 我到底想要什么？ 他们理想中的状态是他们所做的事和个人的价值观一致。他们想要一个忠于自己理想的生活。 Fe外倾情感外倾情感处理理解他人情感与当下的感觉。Fe很注意他人的感受，可以轻易察觉到他人当前的感受。Fe可以很快估量当前环境的氛围，也很擅长改变这种氛围，不管是变得更愉快或者更悲伤。Fe喜欢帮助他人。他们喜欢帮忙，支持与鼓励。 虽然内倾思考（Ti）和外倾思考（Te）都是T（Think），但因为方向（e和i）的不同，导致它们的工作方式也是不同的。下图分别描述了 Ti-Te、Ni-Ne、Si-Se、Fi-Fe 四组 同类但不同向的功能 工作的差异性： Ne 和 Ni 之间的关系与他们认知方式 外倾直觉 Ne，开放又好奇，总是随时准备着探索，吸收新鲜的概念；内倾直觉 Ni，带着他们精化的理论，总是随时准备着供应信息。而接下来呈现的则是一种相对来说可预测的模式，即 Ne 和 Ni 类型的互动模式，这个模式在他们经历直觉力量的最高点与源自外倾与内倾不同方向性的沮丧而产生。 只要 Ni 能够通过提供新信息给 Ne 来吸引他们的兴趣，那两者之间的互动就能够朝正面的方向前进，双方共勉互补（通常以一问一答的形式，即 Ne 问出问题，Ni 提供答案）。这种情况可以无限下去直到以下任何一种情况发生：1）Ne 问出了一个 Ni 无法回答的问题。或者 2）Ni 持续挖掘一个理论过于深入，Ne 觉得无聊或失去了兴趣。 在这些情况下，直觉的预见性似乎不是投射力量的对手（power of projection）。 @ref: https://www.douban.com/note/512683391/?_i=5030913Ffclj2I,5037773A8LpzFZ 八维功能的次序和角色（一）人格类型的 阳面 （Primary Processes） 我们首要运用的四种功能。不同的功能会在我们生命中的不同阶段出现与发展。在不同的阶段，我们会更活跃地应用对应的功能，并发现可以几乎毫不费力地应用它。我们会发现自己的兴趣逐渐转移，从过去吸引我们的事物上移开。 主角（主导功能）/Leading Role（Dominant）－主导功能通常是我们在童年期即已发展出的功能。我们会倾向于首先运用它，指望它来解决我们的问题，帮助我们成功。这是我们最值得信赖和最常使用的功能，通常是相当成熟完善的。尽管多数情况下我们是在自然而然、毫不费力地运用它，我们也可以更有意识地去掌控它。运用主导功能所需投入的精力极少。正如电影中的主角所起的作用那样，主导功能的运用能够令我们摆脱困境。然而，有时我们也会过分依赖主导功能，变得过于傲慢自大。此时它主要起消极作用。 配角（辅助功能）/Supporting Role（Auxiliary）－辅助功能帮助我们自身的作用正如我们帮助他人。一旦我们能够熟练地运用主导功能，让作为配角的辅助功能来发挥作用会让我们更感舒适。当状况良好时，恰似合适的家庭环境有利于孩子成长。若状况不佳，则可能是主角过于强大而使得配角不能很好地发展，而非起到促进作用。当主导功能外倾时，对应的辅助功能是内倾的。当主导功能内倾时，外倾的辅助功能是我们与外界打交道的方式，会是活跃而易于被觉察的。 替补队员（第三功能）/Relief Role（Tertiary）－替补队员为我们提供了恢复自我的途径。是配角的替补，并经常与配角共同协作。在我们年轻时，若不是情非得已，配角不能很好地完成任务，可能并不会有力地运用它。通常，在成人初期我们会被替补队员的活动吸引。第三功能通常是我们发挥创造力的途径，会在我们像孩童般嬉戏时出现。在最糟的情况下，这是我们表现出幼稚行为时运用的功能。此时它稳定性不佳，会令我们自己与其他人偏离常轨。 龙套演员（劣势功能或第四功能）/Aspirational（Inferior）－龙套演员通常在我们中年以前并未发展。我们通常是先遇到它在跟我们捣乱，作为我们的内心的命令、恐惧及其他负面情绪出现。此类恐惧是劣势功能在发挥作用的体现，而我们常常在此时并不会成熟地去对待它。在龙套演员登场时，我们常常要投入相当多的精力——即使是在我们掌握了调配它的技能以后。一旦我们学会去信赖并发展它，龙套演员能够成为平衡我们生活的桥梁，连通我们的目标、灵感、理想。 （二）人格类型的阴面（Shadow Processes）：剩下的四种功能，处在我们意识的边缘，常常隐身在黑暗中，不会主动出现。它们常常会带给我们负面影响，然而，若我们愿意，同样可以将它们纳入觉知中，发挥它们的积极作用。 对手（第五功能）/Opposing Role－对手通常是让我们感到棘手的——无论何事发生，都拒绝“加入”我方阵营。我们或许可以通过有意让它上场来发展它，但通常可能并不会给它太多的戏份，要让它发挥自如也得投入我们更多的精力。从积极方面来讲，对手是主角的影子，它的存在是对主角的丰富，帮助我们更持久地追求目标。 批评家（第六功能）/Critical Role－批评家使我们能够找出弱点，打压别人。当别人运用它来对付我们时，我们就知道它是咋起作用的了。这一位常常在我们遭遇重大危机、顶着极大压力时，才登台表演。若我们愿意，可以让它继续留在台上。若要发挥它的积极作用，我们必须学会欣赏它，留一席之地给它。如此，它会拥有神奇的品质，带给我们深刻的智慧洞见。 骗子（第七功能）/Deceiving Role－ 骗子会愚弄我们，让我们以为某些事情是重要的或值得关注的。它的意见通常被认为是不可信或不值得被关注的，若我们当真了，倒是会形成错觉或做出错误的决定。此时我们会发现自己陷入两难境地，左右皆非。尽管如此，它也有积极面，能以滑稽来助我们减压，教我们自嘲。如此，它可以为我们服务，在我们恢复精力时发挥作用。 魔鬼（第八功能）/Devilish Role－魔鬼通常不干好事儿。当它出现时，可能会让我们自毁毁人。受它影响作出的行动（或不作为）往往会令我们事后悔恨。通常，我们并不知道如何有意使用它，感觉它多半是在我们毫无觉察的情况下突然爆发的。话虽这么说，若我们心胸够宽广，魔鬼也可以改变阵营，倒戈投诚。这时它会成为有创造性的力量，带来新生——恰似将柠檬榨成柠檬汁，使我们不必抱怨柠檬的酸涩。 完善的自我(The Developed Self)要知道，我们有能力运用所有这些功能并熟练掌握它们。熟能生巧。在生活中，我们会主要倾向于发展人格类型中的阳面。但环境可能会强化它，也可能会阻碍它的发展。因此，即使是人格类型完全相同的人，在各自不同的成长道路中，他们的功能发展也会有相当大的差别。 在我们有意识地情况下识别运用这些功能，比起我们无意中让它们出现，要容易得多。若我们有足够的能力去运用一个尚不熟悉的功能，我们也可以很自然地享受这个过程。若是能力不到，觉知力不够，则多半会受功能的消极面影响，反而怪罪说它其实在任何地方都毫无价值。 @ref: MBTI八种功能对人格的影响 An Introduction to the Shadow Functions - Psychology Junkie 16中人格类型，认知功能组合顺序： @ref: MBTI八种功能对人格的影响 - Yoli Inés - 豆瓣 16种人格类型的成长不同人格类型成长过程中认知功能的发展和互相影响，豆瓣防404传送门: MBTI人格系列翻译整理①—— INFJ圣人型-Rina’s MBTI人格系列翻译整理②—— INTJ专家型-Rina’s MBTI人格系列翻译整理④—— INFP哲学家型-Rina’s MBTI人格系列翻译整理⑦—— INTP学者型-Rina’s MBTI人格系列翻译整理⑧—— ENTP发明家型-Rina’s 各类型见的兼容关系=&gt; MBTI各种类型兼容关系 16personalities 模型中的 A &amp; T来自 https://www.16personalities.com/ch/%E6%A8%A1%E5%9E%8B 坚决型的人情绪稳定，冷静，放松，不会过度忧虑。（-A，意Assertive） 动荡型的人容易难为情，在乎形象，追求成功，完美主义。（-T，意Turbulent） Our last scale, Identity, affects all others, showing how confident we are in our abilities and decisions. In a way, it acts as an internal sensor, reacting to the input we get from the environment – for instance, success or failure, feedback from other people, pressure caused by unexpected events and so on. Mind and Identity scales are the alpha and the omega of our model, acting like an external shell that we wear in all our interactions with the outside world – we discuss all four possible combinations of these traits in the “Strategies” section of our main theoretical article, but in this one, let’s take a look at what the Identity scale looks like. Assertive (-A) individuals are self-assured, even-tempered and resistant to stress. They refuse to worry too much and do not push themselves too hard when it comes to achieving goals. Similarly, they are unlikely to spend much time thinking about their past actions or choices – according to Assertive types, what’s done is done and there is little point in analyzing it. Not surprisingly, people with this trait report more satisfaction with their lives and they also feel more confident in their abilities to handle challenging and unexpected situations. In contrast, individuals with Turbulent (-T) identity are self-conscious and sensitive to stress. They experience a wide range of emotions and tend to be success-driven, perfectionistic and eager to improve. They are also more willing to change jobs if they feel stuck in their current one and to spend time thinking about the direction in which their life is going. However, while the Assertive variant may seem more positive on the surface, that is not always the case – for instance, Turbulent individuals perform better in certain roles as they push themselves to achieve superior results, while Assertive ones do not care about the outcome that much. Always feeling the need to do more, to have more, and to be more, Turbulent types often forget how exhausting that can be to both themselves and the people around them – but it is entirely possible that this desire to always push themselves just a little further helps many Turbulent types to achieve what they seek to achieve. 策略:策略层显示我们做事和实现目标时所倾向的方式。共有四种策略： • 自信独立者（内向型和坚定型 [I___-A]型）:自信的个人主义者喜欢独自做事，与请教别人相比会选择相信自己的技能和直觉。他们知道自己擅长什么并非常自信。这些人格类型者认为责任和自信是非常重要的价值。他们不太在意别人的意见而更喜欢依靠自己。 • 掌控旁人者（外向型和坚定型 [E___-A]型）:掌控旁人者们喜欢社会交往，常拥有高超的交流技巧，在社会活动中和需要依赖或指挥他人的情况下如鱼得水，这种类型的人对自己的能力很自信，表达观点时从不犹豫。在社会中扮演积极角色，能够驾驭他人对他们来说很重要。然而他们不大在乎别人对自己的看法。 • 不断进取者（内向型和动荡型 [I___-T]型）:不断进取者是安静而独立的人们。他们完美主义追求成功，常常花很多时间和努力来确保工作结果尽善尽美。人如其名，不断进取者的奉献精神让他们成绩突出，然而他们常对自己的表现过分忧虑。 • 社会交往者（外向型和动荡型 [E___-T]型）:最后一种策略被善于社交，精力充沛，追求成功的人所运用。社交活动者们停不下来，完美主义，感情容易大起大落。他们的好奇和努力工作的心态通常会使他们成绩突出，其中很敏感的人也不例外。运用这种策略的人格类型通常非常在意别人的看法；他们重视社会地位，无论做什么都想成功。 INFJ-T vs INFJ-A匆忙的机翻：INFJ-T-vs-INFJ-A 批评与争议MBTI在业界和网络心理测验中非常流行，但在心理学界饱受批评，现在学界已不使用，心理测量专家罗伯特‧霍根（Robert Hogan）说“大多数人格心理学家把MBTI视为比较复杂的幸运饼干”。MBTI存在的问题包括： 性格偏好与职业的关联性 没有证据指出特定性格的人适合从事特定的职业。 二分法的问题 分类中两极的性格应为互斥（不为互斥）但有时却是独立的（例如“理性”和“情感”可以并存），而不同轴向的性格应该独立，有时却有相关（例如“理解”和“情感”都有助于观察别人的情绪）。(思维过程本身就是个各种感觉混合的认知功能表过程，参考认知功能表，这个没问题) 用语 MBTI 的用语被批评为“很模糊和笼统”，任何行为都可以放到任何一种人格里而“放诸四海皆准”，故 MBTI 类型的描述为“巴纳姆效应”。 但有相反观点认为，各个 MBTI 类型的描述都是独特而准确阐释其大概的意思。 在上述基础下，创造凯尔西气质分类法的大卫·凯尔西将 MBTI 类型的定义延伸，加上了“气质”的分类从而细分 MBTI 类型在“语文应用”“知识领域”“教育范畴”等等的分别。 缺乏客观性 MBTI 学说的准确性完全依赖参与者为内省的自我报告评估提供诚实而且客观的答案，社会期望或过于夸张的反应会影响其准确度。比如如果测试者害怕评估结果会为其带来损失，测试者会倾向提供符合测试者期望而非基于个人意愿的选择。 虽然 MBTI 类似于一些心理学理论，但它被批评为伪科学，并没有在有关学术研究领域获广泛承认。该指标显示出重大的科学（心理统计学）缺陷，主要包括： 测验效度不理想（即没有测量到其测量目标，没有预测能力或没有可以概括的项目）； 信度不理想（同一个人在不同情境下获得不同结果）； 测量不独立的类别（已注意到一些二分特征相互关联）； 不全面（由于缺少神经质） MBTI 中使用的四个量表，与五大性格特质（BigFive）之中的四个有一定的相关性，后者更为不同领域普遍接受。 参考@ref: Myers–Briggs Type Indicator - Wikipedia 迈尔斯-布里格斯性格分类法 - 维基百科，自由的百科全书 心理学学术界是怎样看待 MBTI 的？ - 知乎 谁能介绍一下mbti中的一三功能循环？ - 知乎 mbti各类型通常有哪些气质（给他人的第一印象）？ - 知乎 在现实生活中最不受欢迎、评价最低的mbti类型是什么？ - 知乎","categories":[{"name":"62.Psychology","slug":"62-Psychology","permalink":"https://beefyheisenberg.github.io/categories/62-Psychology/"}],"tags":[{"name":"心理学","slug":"心理学","permalink":"https://beefyheisenberg.github.io/tags/心理学/"},{"name":"心理测评","slug":"心理测评","permalink":"https://beefyheisenberg.github.io/tags/心理测评/"},{"name":"MBTI","slug":"MBTI","permalink":"https://beefyheisenberg.github.io/tags/MBTI/"}]},{"title":"INFJ-T-vs-INFJ-A","slug":"62.Psychology/INFJ-T-vs-INFJ-A","date":"2024-01-24T01:27:53.848Z","updated":"2024-01-24T01:27:53.848Z","comments":true,"path":"62.Psychology/INFJ-T-vs-INFJ-A/","link":"","permalink":"https://beefyheisenberg.github.io/62.Psychology/INFJ-T-vs-INFJ-A/","excerpt":"-a 和 -t 的解释: MBTI笔记 infj-a 和 infj-t 的区别： 1、面对压力的心态不同 infj-a 型的人在压力面前会更容易保持一种松弛的状态，他们相对比较自信，认为自己可以找到有效的方法，来管理生活中出现的压力。 infj-t 型的人面对挫折与压力的时候，会更容易质疑自己，对于压力的来源也会比较敏感。 2、面对他人的感受不同","text":"-a 和 -t 的解释: MBTI笔记 infj-a 和 infj-t 的区别： 1、面对压力的心态不同 infj-a 型的人在压力面前会更容易保持一种松弛的状态，他们相对比较自信，认为自己可以找到有效的方法，来管理生活中出现的压力。 infj-t 型的人面对挫折与压力的时候，会更容易质疑自己，对于压力的来源也会比较敏感。 2、面对他人的感受不同 infj-a 型的人会考虑其他人的感受，但并不会过度的参与到其他人的问题之中。 infj-t 型的人对事情的卷入程度会更深，他们对待其他人会比较投入，很容易代入自己的感情，想要帮对方做决定。他们的同理心很强。 3、对生活的掌控感不同 infj-a 型的人被不公正的对待或者被其他人的问题所困扰时，他们更有可能保护自己的权益，做出比较理智的行为，找回生活的掌控感。 infj-t 型的人更容易被周围的人或事所困扰，他们很容易陷入别人的问题之中，从而缺少对生活的主导权。 4、对他人的依赖程度不同 infj-a 型的人不会轻易的把自己的价值依附于他人的评价之中，他们喜欢有自己的个人空间，喜欢保持人格独立。 infj-t 型的人很依赖其他人的评价，他们追求其他人的认可，喜欢把自我价值建立在他人的评价上。但是取悦所有人是一件很困难的事情，会让人迷失自我，停止成长的脚步。 5、对变化的态度不同 infj-a 型的人更有可能接受生活中突如其来的变化，也更容易接受跟自己思想差异很大的其他人。他们富有冒险精神，喜欢刺激。 Infj-t 型的人比较能接受合理范围之内的改变，如果超出他的阈值，他会很难适应。他追求生活的控制感，不愿意承担太大的风险。 6、对错误的态度不同 infj-a 型的人对于犯的错误不太上心，他们不会过于纠结于过往的错误与遗憾，但是如果不吸取经验教训，很难得到真正意义上的成长。 infj-t 型的人经常对做过的事情感到后悔，他们会不断的进行自我反思，也愿意做出改变。 Assertive Advocate (INFJ-A) vs. Turbulent Advocate (INFJ-T)匆忙的机翻，原文:Assertive Advocate (INFJ-A) vs. Turbulent Advocate (INFJ-T) | 16Personalities 虽然自信（INFJ-A）和动荡（INFJ-T）倡导者可能更相似而不是不同，但他们的身份人格特质在两者之间提供了一些细微的差异。它在很大程度上影响了每个人思考，行动和回应他们世界的方式。 自信的倡导者更有可能自信和放松。动荡的倡导者可能会更多地质疑自己，并且通常对压力源更敏感。要了解有关自信和湍流身份之间的一般差异的更多信息，请访问其概述页面。 74%的自信倡导者认为他们有效地管理了生活中的压力，而动荡的倡导者则为28%。 动荡和自信的倡导者和他们生活中的人们所有倡导者个人主要通过他们的感受过滤它们来决定事情，他们的决定往往反映了他们对道德的价值。他们如何看待人们以及他们正在经历的事情是他们性格类型的一个决定性因素。但是，与自信的倡导者相比，动荡的倡导者可能会将同情他人的同情心提高一个档次。 动荡的倡导者经常让他们的激情带领他们取得伟大的成就。这些因素是由于他们对生活中人民的尊重以及对道德和理想主义问题的关心而推动的。他们可能会过度卷入他人的问题。这种参与甚至可能产生一种超同理心，这些人格与他们寻求帮助的人过于认同。 如果动荡的倡导者变得投入，然后无法达到他们认为应该达到的程度，那么动荡的自我批评可能会过于严厉。他们可能会陷入沉思，陷入忧虑和遗憾的痛苦泥潭。 75%的动荡倡导者表示，他们很容易在任何地方看到困难，而自信倡导者的这一比例为42%。 除此之外，动荡的倡导者更愿意夸大困扰他们或伤害他们所关心的人的事情的影响。具有这种性格类型的人经常将事情解释为比实际情况糟糕得多。但这种夸张很少是故意的或不诚实的。这更多地反映了他们对事物持有更多负面看法的倾向。它可以真正反映他们的信仰。但是，即使它来自一个好地方，放大问题也会给已经困难的情况增加不必要的压力和强度。 当自信的倡导者被不公正、不平等或他人的问题所困扰时，他们更有可能以充满希望的方式做出回应。他们可能同样关注任何令人不安的担忧和人类的困难，但他们拒绝被它们所强调。 35%的动荡倡导者认为他们处于控制之中，即使事情出了问题，相比之下，72%的自信倡导者 这并不意味着这些个性没有真正的投入，或者他们不在乎。除了烦恼之外，还有很多方法可以引起人们对他人困境的兴趣。 自信的倡导者在与他人交往时比他们的同行更有可能保持均匀的情感龙骨。与其花很多时间思考一些人可能遭受的痛苦和不幸，这些性格类型更有可能从可能导致更积极未来的计划和愿景的角度来思考。他们可以像《动荡的倡导者》一样强烈地想象好东西的出现，就像《动荡的倡导者》一样，想象他们的担忧和遗憾。 但这种乐观情绪有时会产生负面结果。通过玫瑰色眼镜生活并不总是能促进清晰的视力。自信的倡导者可能会对需要解决的合法重要问题不屑一顾，而是选择专注于更光明的事情。在这些情况下，他们可能会忽略基本任务。动荡的倡导者更有可能在自信的倡导者之前很久就发现这些事情。 动荡和自信的倡导者都倾向于提升他们的朋友，他们爱上的人，甚至他们的同事。这些性格通常认为是他们所重视和同意的人中最好的。他们可能不那么善待那些违背他们的对错感或看起来是假的。 然而，两者之间有一个区别：自信的倡导者通过一个过滤器来看待事物，这个过滤器重视人性，并希望在他们的生活中拥有人（在有限的内向剂量内）。相比之下，动荡的倡导者更有可能超越仅仅想要人们的生活。这些性格更愿意为他人着想，也更受别人对他们的看法的影响。这种对他人的需求和他们的意见可以帮助他们与他人建立深厚的联系，并允许他们在需要时更好地合作。 38%的动荡倡导者发现在没有事先咨询任何人的情况下做出重要决定很容易，而自信倡导者的这一比例为71%。 然而，与动荡的倡导者不同，自信的倡导者并没有受到他人意见的深刻影响 - 也许有时对他们不利。这使得这些人物能够以独立和简化的方式接近他们生活中的各种任务。 73%的动荡倡导者感到有压力达到某个标准（例如，家庭，汽车，工资），而42%的自信倡导者 但是，这种独立性在什么时候演变成傲慢呢？所有内向型人格类型都喜欢独处——或者，至多在一小群精心挑选的人中间。也就是说，自信的倡导者可以夸大独狼的角色。这些自信的个人主义者可以变得如此独立，以至于他们忘记了他人的需求和愿望。 动荡的倡导者可以走另一条路 - 不断寻求认可，扼杀他们的个性，并在等待所有重要人物善意地看待他们的行动和想法时挫败他们的努力。取悦每个人是生活中难得的成就，追求它让很多人停滞不前。 93%的动荡倡导者经常害怕被其他人拒绝，而自信倡导者的这一比例为52%。 改变，后悔，倡导身份差异由于他们共同的评判人格特质，这两种类型的倡导者都更喜欢常规和可预测性。两人都不是特别喜欢被惊讶。 然而，自信的倡导者更有可能接受事件中不寻常的转变，他们更容易接受非正统的想法和人。他们往往比动荡的同龄人更具冒险精神 - 可能是因为他们的信心。 动荡的倡导者，作为他们寻求持续改进的一部分，可能会接受变革，但只有在合理范围内。具有这种性格类型的人喜欢对它有一些控制权，并保证它在正确的时刻是正确的变化。他们可能比自信的同行承担更少的风险。 87%的动荡倡导者发现很难不让压力事件对他们产生负面影响，相比之下，自信倡导者的这一比例为47%。 倡导者都对过去有着深刻的敬意。他们倾向于深刻而热情地记住事情在他们生活中展开的方式。他们从过去的日子里为未来收集教训。然而，当他们的过去是艰难的时，自信的倡导者就不会那么为遗憾而烦恼，而动荡的倡导者可能会紧紧抓住这种失望和失误的记忆。 86%的动荡倡导者经常感到后悔，而自信倡导者的这一比例为48%。 遗憾可以给动荡的倡导者的未来行为带来积极或消极的影响：积极的，如果他们有动力弥补过去的失误;消极地，如果这些人格陷入内疚或愤怒。如果他们认为自己伤害了别人，这可能会特别具有破坏性。 因为后悔不会对他们产生太大的影响，所以自信的倡导者可能不那么有动力去纠正过去的错误。如果他们能把失败视为不重要，他们可能不会学到通过反复试验来最好地教授的关键课程。这可能会让这些人格比他们想要的更频繁地重复他们的错误。 89%的动荡倡导者经常发现自己纠结于过去的错误，而自信倡导者的这一比例为61%。 差异摘要这两种性格类型都关心其他人，但自信的倡导者可能会更有希望，而动荡的倡导者则专注于问题的困难部分。动荡的倡导者往往受到他们的担忧和担忧的推动，这些可以用来取得重大进展。自信和动荡的倡导者都可能陷入生活的戏剧性事件中，但那些动荡的人可能会受到更多的影响。压力和遗憾对自信倡导者的影响较小，但这不应该与他们的不关心相混淆。因为他们的遗憾更重于他们，动荡的倡导者比自信的倡导者更有可能从他们的错误中吸取教训。自信的倡导者比动荡的倡导者受他人意见的影响要小。但是，太少或过多地关注别人的意见，也有其自身的困难。自信的倡导者更有可能在他们的生活中想要人，而动荡的倡导者可能会觉得他们在生活中需要人。相同但不同 - 这就是我们在单一人格类型中探索自信和动荡身份时发现的。对于倡导者来说，这意味着他们有着同样的激情，对他人的同样关心，同样的秩序感，以及对是非的相同程度的信念。 然而，这也意味着每种人格类型对隐喻玻璃都有不同的看法。是半满还是半空？他们在多大程度上对其他人和事件做出反应，以及他们在多大程度上向前迈进？这都是自我探索之旅的一部分。 你是个INFJ-T?湍流倡导者（INFJ-T）具有令人难以置信的学习和成长能力，但他们并不总是认识到自己的真正潜力。这就是为什么我们制作了《动荡的倡导者》的超能力：成为最好的自己——不改变你是谁。 如果你是一个动荡的倡导者，动荡的倡导者超能力将赋予你放弃自我批评并拥抱你真正是谁的能力。一路上，你会改变你的心态，改善你的人际关系，追求你的梦想，所有这些都是通过利用你最大的优势 - 你一直内在的优势。","categories":[{"name":"62.Psychology","slug":"62-Psychology","permalink":"https://beefyheisenberg.github.io/categories/62-Psychology/"}],"tags":[{"name":"心理学","slug":"心理学","permalink":"https://beefyheisenberg.github.io/tags/心理学/"},{"name":"心理测评","slug":"心理测评","permalink":"https://beefyheisenberg.github.io/tags/心理测评/"},{"name":"MBTI","slug":"MBTI","permalink":"https://beefyheisenberg.github.io/tags/MBTI/"}]},{"title":"Gallup（盖洛普） and MBTI 评测的联系","slug":"62.Psychology/Gallup-and-MBTI","date":"2024-01-24T01:27:53.843Z","updated":"2024-01-24T01:27:53.843Z","comments":true,"path":"62.Psychology/Gallup-and-MBTI/","link":"","permalink":"https://beefyheisenberg.github.io/62.Psychology/Gallup-and-MBTI/","excerpt":"https://www.gallup.com/cliftonstrengths/en/250133/compare-mbti-myers-briggs-cliftonstrengths.aspx 已故盖洛普资深科学家菲尔·斯通，哈佛大学前任心理学教授，研究了 MBTI 和 克利夫顿StrengthsFinder（盖洛普-克里夫顿优势）之间的关系。斯通过他的206个学生进行了这两项完整的评估。研究表明两者之间的评估某些预期的相关性。 例如，如果克利夫顿StrengthsFinder显示，“分析”是你五大主题之一，MBTI第三维度你就可能属于内倾思考（Ti）或者外倾思考（Te）。如果体谅是你的五大主题之一，你MBTI第二维度很可能是感觉型（Fi 或 Fe）。同样，如果你有纪律，你就可能是MBTI第四维度是判断型（J）。 斯通的学生反馈克利夫顿 StrengthsFinder既更适用，比 MBTI更准确。 打个比方：想象一下，一个房子有好几个的房间。 MBTI表示，其中一个是最舒适的居住的房间。克利夫顿StrengthsFinder则代表的家具，设备，装饰，房间内的其他细节，从而帮助我们理解个人独特的天生的能力。无论是MBTI和克利夫顿StrengthsFinder都能揭示个性有价值的信息，都可以帮助个人与组织的战略发展。","text":"https://www.gallup.com/cliftonstrengths/en/250133/compare-mbti-myers-briggs-cliftonstrengths.aspx 已故盖洛普资深科学家菲尔·斯通，哈佛大学前任心理学教授，研究了 MBTI 和 克利夫顿StrengthsFinder（盖洛普-克里夫顿优势）之间的关系。斯通过他的206个学生进行了这两项完整的评估。研究表明两者之间的评估某些预期的相关性。 例如，如果克利夫顿StrengthsFinder显示，“分析”是你五大主题之一，MBTI第三维度你就可能属于内倾思考（Ti）或者外倾思考（Te）。如果体谅是你的五大主题之一，你MBTI第二维度很可能是感觉型（Fi 或 Fe）。同样，如果你有纪律，你就可能是MBTI第四维度是判断型（J）。 斯通的学生反馈克利夫顿 StrengthsFinder既更适用，比 MBTI更准确。 打个比方：想象一下，一个房子有好几个的房间。 MBTI表示，其中一个是最舒适的居住的房间。克利夫顿StrengthsFinder则代表的家具，设备，装饰，房间内的其他细节，从而帮助我们理解个人独特的天生的能力。无论是MBTI和克利夫顿StrengthsFinder都能揭示个性有价值的信息，都可以帮助个人与组织的战略发展。 原文： Gallup Senior Scientist Phil Stone, a psychology professor at Harvard, examined the relationship between Myers-Briggs and the CliftonStrengths assessment. Stone had 206 of his students complete assessments through both instruments. The study showed some expected correlations between the two assessments. For example, if the CliftonStrengths assessment shows that Analytical is one of your Top 5 areas of talent, MBTI is likely to identify you as Thinking. If Empathy is in your Top 5 (CliftonStrengths), you are likely to be Feeling (MBTI). Likewise, if Discipline is in your Top 5 (CliftonStrengths), you’re probably also Judging (MBTI). Stone’s work depicts the accuracy of the two assessments for defining a person’s innate natural thoughts, feelings and behaviors. Now let’s take a closer look at the applicability of each. Imagine a house and the rooms within it. MBTI indicates the room in which an individual is most comfortable residing. The CliftonStrengths assessment represents the furnishings, functional pieces, decorations and other details inside that room, helping us understand the individual’s unique innate abilities. Said differently, MBTI is the ZIP code, and CliftonStrengths puts you in front of the door.","categories":[{"name":"62.Psychology","slug":"62-Psychology","permalink":"https://beefyheisenberg.github.io/categories/62-Psychology/"}],"tags":[{"name":"心理学","slug":"心理学","permalink":"https://beefyheisenberg.github.io/tags/心理学/"},{"name":"心理测评","slug":"心理测评","permalink":"https://beefyheisenberg.github.io/tags/心理测评/"},{"name":"MBTI","slug":"MBTI","permalink":"https://beefyheisenberg.github.io/tags/MBTI/"},{"name":"克利夫顿优势","slug":"克利夫顿优势","permalink":"https://beefyheisenberg.github.io/tags/克利夫顿优势/"}]},{"title":"Big Five 笔记","slug":"62.Psychology/BigFive","date":"2024-01-24T01:27:53.838Z","updated":"2024-01-24T01:27:53.838Z","comments":true,"path":"62.Psychology/BigFive/","link":"","permalink":"https://beefyheisenberg.github.io/62.Psychology/BigFive/","excerpt":"What’s Big Five人格结构五因素模型（Big Five Structure，Five-Factor Model) 或译为大五人格模型 OCEAN：人格结构中的五个因素后来被称为“大五”（big five），强调该人格模型中每一维度的广泛性。这五个维度因素是神经质（N）、外倾性（E）、经验开放性（O）、宜人性（A）和认真性（C）。 OCEAN量表得出五因素模型的一个很重要的方法就是基于问卷研究。科斯塔（Costa1）等人根据对16PF2的因素分析和自己的理论构想编制了测验五因素的NEO—P1人格量表（NEO—PI Five-Factor Inventory）。该量表包括300个项目，被试在五点量表（从完全同意到完全不同意）上指出每个句子表示他们自身特点的程度。除了五个因素上的得分，被试还有为每个维度量表设置的六个测量特质水平的层面量表得分，这些层面量表提供了有关大五因素的每个因素内的行为的更大区分性。有关人格大五特质因素和相关特征见下表。","text":"What’s Big Five人格结构五因素模型（Big Five Structure，Five-Factor Model) 或译为大五人格模型 OCEAN：人格结构中的五个因素后来被称为“大五”（big five），强调该人格模型中每一维度的广泛性。这五个维度因素是神经质（N）、外倾性（E）、经验开放性（O）、宜人性（A）和认真性（C）。 OCEAN量表得出五因素模型的一个很重要的方法就是基于问卷研究。科斯塔（Costa1）等人根据对16PF2的因素分析和自己的理论构想编制了测验五因素的NEO—P1人格量表（NEO—PI Five-Factor Inventory）。该量表包括300个项目，被试在五点量表（从完全同意到完全不同意）上指出每个句子表示他们自身特点的程度。除了五个因素上的得分，被试还有为每个维度量表设置的六个测量特质水平的层面量表得分，这些层面量表提供了有关大五因素的每个因素内的行为的更大区分性。有关人格大五特质因素和相关特征见下表。 1.10.7: Paul Costa and Robert McCrae and the Five-Factor Model of Personality - Social Sci LibreTexts ↩2.卡特尔16PF（Cattell’s 16 Personality Factor，简称16PF）=&gt; 卡特尔16PF ↩","categories":[{"name":"62.Psychology","slug":"62-Psychology","permalink":"https://beefyheisenberg.github.io/categories/62-Psychology/"}],"tags":[{"name":"心理学","slug":"心理学","permalink":"https://beefyheisenberg.github.io/tags/心理学/"},{"name":"心理测评","slug":"心理测评","permalink":"https://beefyheisenberg.github.io/tags/心理测评/"}]},{"title":"Alpha-Beta-Sigma","slug":"62.Psychology/Alpha-Beta-Sigma","date":"2024-01-24T01:27:53.832Z","updated":"2024-01-24T01:27:53.832Z","comments":true,"path":"62.Psychology/Alpha-Beta-Sigma/","link":"","permalink":"https://beefyheisenberg.github.io/62.Psychology/Alpha-Beta-Sigma/","excerpt":"Wikipedia：Alpha、Beta、Sigma阿尔法男性和贝塔男性，或简称阿尔法和贝塔，是男性的 伪科学术语，源自行为学中阿尔法和贝塔动物的名称。它们也可以与其他性别一起使用，例如女性，或者另外使用希腊字母表的其他字母（例如欧米茄）。这些术语来描述人类的普及受到了科学家的广泛批评。 在 1990 年代之前，这些术语几乎只用于动物行为学，特别是关于与雌性的交配特权，保持领地的能力以及其牛群或羊群中食物消费的等级。在动物行为学中，贝塔是指从属于社会等级中更高等级成员的动物，因此不得不等待进食，交配的机会更少或可以忽略不计。 在 1982 年出版的《黑猩猩政治：类人猿的权力与性》一书中，灵长类动物学家和动物行为学家弗兰斯·德瓦尔（Frans de Waal）表示，他对黑猩猩殖民地的观察可能适用于人类的互动。包括《芝加哥论坛报》在内的一些评论讨论了它与人类权力等级制度的相似之处。在 1990 年代初期，一些媒体开始使用阿尔法一词来指代人类，特别是那些在商业上表现出色的“男子气概”男人。记者杰西·辛格尔（Jesse Singal）在《纽约》杂志上撰文，将公众对这些术语的认识归因于 1999 年《时代》杂志的一篇文章，该文章描述了当时担任总统候选人阿尔·戈尔顾问的娜奥米·沃尔夫（Naomi Wolf）的观点：“沃尔夫在内部辩称，戈尔是一个’贝塔男性’，在公众将他视为顶级狗之前，他需要在椭圆形办公室接受’阿尔法男性’。辛格尔还称赞尼尔·施特劳斯（Neil Strauss）2005 年出版的关于皮卡艺术的畅销书《游戏》（The Game），将阿尔法男性作为一种理想来推广。","text":"Wikipedia：Alpha、Beta、Sigma阿尔法男性和贝塔男性，或简称阿尔法和贝塔，是男性的 伪科学术语，源自行为学中阿尔法和贝塔动物的名称。它们也可以与其他性别一起使用，例如女性，或者另外使用希腊字母表的其他字母（例如欧米茄）。这些术语来描述人类的普及受到了科学家的广泛批评。 在 1990 年代之前，这些术语几乎只用于动物行为学，特别是关于与雌性的交配特权，保持领地的能力以及其牛群或羊群中食物消费的等级。在动物行为学中，贝塔是指从属于社会等级中更高等级成员的动物，因此不得不等待进食，交配的机会更少或可以忽略不计。 在 1982 年出版的《黑猩猩政治：类人猿的权力与性》一书中，灵长类动物学家和动物行为学家弗兰斯·德瓦尔（Frans de Waal）表示，他对黑猩猩殖民地的观察可能适用于人类的互动。包括《芝加哥论坛报》在内的一些评论讨论了它与人类权力等级制度的相似之处。在 1990 年代初期，一些媒体开始使用阿尔法一词来指代人类，特别是那些在商业上表现出色的“男子气概”男人。记者杰西·辛格尔（Jesse Singal）在《纽约》杂志上撰文，将公众对这些术语的认识归因于 1999 年《时代》杂志的一篇文章，该文章描述了当时担任总统候选人阿尔·戈尔顾问的娜奥米·沃尔夫（Naomi Wolf）的观点：“沃尔夫在内部辩称，戈尔是一个’贝塔男性’，在公众将他视为顶级狗之前，他需要在椭圆形办公室接受’阿尔法男性’。辛格尔还称赞尼尔·施特劳斯（Neil Strauss）2005 年出版的关于皮卡艺术的畅销书《游戏》（The Game），将阿尔法男性作为一种理想来推广。 西格玛男性是一个网络俚语和伪科学术语，用于描述男性。这个词在 2010 年代末和 2020 年代初在互联网文化中获得了突出的地位，并激发了许多模因、涂鸦和视频。 Delta 男性、Gamma 男性和 Omega男性这两个术语被认为是社会等级中的第三、第四和最低类型的男性。 @ref: Alpha and beta male - Wikipedia Sigma male - Wikipedia 性格特征:你属于哪一种?(Alpha, Beta, Omega, Gamma，或 Sigma)阿尔法男性：最大的特点 雄性领袖 是对自己和对他人的领导力的信心。他们通常对他人很有吸引力，善于交际，富有魅力。阿尔法男性喜欢领导群体，自然会晋升到权力位置。阿尔法男性往往担任领导职务，是领导者，拥有崇高的军事生涯，并成为政治家。 西格玛男： 西格玛男人往往聪明、狡猾，在体制外玩耍以获得他们生活中想要的东西。他们擅长说服和跳出框框思考。她们与雄性领袖最大的区别在于，她们不寻求别人的认可，也不在意别人对自己的看法。 泽塔男： Zeta 人是独立的思想家，忠于自己，不会为社会而改变。他们深知自己是谁，在任何情况下都采取一致的行动和内部指导的心态。他们忠于自己，不会卷入运动或群体思维。 贝塔男： 贝塔型男性善良且尊重他人。他们具有出色的社交能力，并且由于他们轻松的生活方式而受到人们的喜爱。他们通常对他人开放且友善，因为他们希望受到喜爱和赞赏。他们在人际关系方面具有很高的社交智商。 伽玛男： 伽玛人是富有冒险精神和有趣的个性。他们追求生活的满足高于一切。他们相信快速将金钱转化为体验和充实的生活。他们非常有自我意识，并且能够理解他人的感受。 欧米茄男： 欧米茄男人很自信，对人气竞赛毫不在意。他们往往非常聪明，做事都是为了自己的内在价值，不需要别人的外部认可或认可。他们非常注重智力和学习。 三角洲男性： 三角洲男性非常内向，往往安静且善于自我反省。他们很可能是那种在社会等级中向上、向下或脱离的人格类型。这些人主要在世界上从事真正的工作。 # 男性性格的七种类型：你是哪种类型的男人？！ “阿尔法男”真的更受欢迎吗？ - 知乎","categories":[{"name":"62.Psychology","slug":"62-Psychology","permalink":"https://beefyheisenberg.github.io/categories/62-Psychology/"}],"tags":[]},{"title":"情绪管理","slug":"62.Psychology/05.情绪管理","date":"2024-01-24T01:27:53.827Z","updated":"2024-01-24T01:27:53.827Z","comments":true,"path":"62.Psychology/05.情绪管理/","link":"","permalink":"https://beefyheisenberg.github.io/62.Psychology/05.情绪管理/","excerpt":"@ref 怎样进行良好的情绪管理？ - 知乎 ABCDE情绪管理: 心理学家阿尔伯特.艾利斯提出的情绪反应的ABC模式。 A（Activating Event）——事件或情境 B（Beliefs）——你对这个事情或情境抱有的信念（即你的态度，想法，评价，解释） C（Consequences）——结果：情绪结果（比如焦虑），行为结果（比如攻击），生理结果（如心悸，手脚冰凉） C中出现的不良反应(激怒/抱怨..) 出在你对事情的判断上。","text":"@ref 怎样进行良好的情绪管理？ - 知乎 ABCDE情绪管理: 心理学家阿尔伯特.艾利斯提出的情绪反应的ABC模式。 A（Activating Event）——事件或情境 B（Beliefs）——你对这个事情或情境抱有的信念（即你的态度，想法，评价，解释） C（Consequences）——结果：情绪结果（比如焦虑），行为结果（比如攻击），生理结果（如心悸，手脚冰凉） C中出现的不良反应(激怒/抱怨..) 出在你对事情的判断上。 一些常见的思维习惯/思维模式会使你对情况出现误判，从而导致坏心情，并再接再厉地影响你解决问题的能力。那么，找到并处理这些错误的想法，重新修订你的判断与结论，就可以帮助我们从自己给自己设下的圈套中走出来，所以，我们在ABC的基础上，再加上D（Disputing）和E（Effective Rational Beliefs）两个步骤，即： D——找出你通常使用的那些有可能会误导你，使你得出不准确结论或判断的错误的思维模式。 E——找到新的有效办法，来帮助我们解决我们面对的问题。 @ref: 如何对抗负面情绪？ - 知乎 积极心理学兴起之前，心理学是病理式的，是“治问题”的科学。这种“治问题”的思维随着心理学在大众群体中的普及，已经根深蒂固到每个人的内心了。有了消极情绪，就来问，怎么办。 塞里格曼在20世纪末掀起了积极心理学的潮流，怎么对抗负面情绪?过去心理学会告诉你，寻找负面情绪的根源然后去解决。但是，这种治疗式的思维，让我们在过去的半个多世纪，抑郁症患者没有减少，反而大幅度增加了。 现在心理学会告诉你，不要对抗负面情绪。 研究发现，积极情绪和消极情绪是独立的两个维度，对抗消极情绪，或者说“解决问题”，并不能带来积极的正面的情绪，负面消极的减少了，最多也只能回到“0”状态。这也就是为什么，过去“消极心理学”，并没有给人们带来主观幸福感的上升，甚至连负面的，例如抑郁症的减少都没有达到。 所以，负面情绪是不用对抗的，过去半个世纪的经验告诉我们，对抗消极只会让你更消极。我很喜欢动机老师这个答案来支持这个观点：为什么心理咨询要把接纳自己作为一件很重要的事去强调？ Fredrickson（2002）提出了“积极情绪的扩展建构理论”（the broaden-and-build theory of positive emotions）： 所以，当积极正向的情绪出来的时候，它自然会扩大你的心理应对资源，久而久之，你的消极负面的情绪，你就能够去应对了。 看喜剧片，这对你来说能够创造积极体验，很好，但是不够（你自己也觉得不够）。这里就区分两种积极体验： 感官愉悦（sensory pleasure）：这是积极情绪体验的一种重要形式，指机体消除内部紧张力之后的一种主观体验，是人感觉器官放松的结果。它属于感觉类的体验。例如，你目前正在运用的策略，看电影看喜剧片，它刺激你的感觉，让人放松感觉器官，从而享受到感官愉悦。这种方式很好，也很重要。 心理享受（psychological pleasure）：指个体打破了某种固有的自我平衡，超越了个体自身的原有状态，例如艺术家在创造艺术作品。类似于马斯洛所说的高峰体验。它属于知觉类的体验。它的影响效果时间更长，更深刻。这点上需要你去探索。 因为心理享受是知觉类的体验，因此它的产生必须要有个体的认知评价为先导，即要把握对象对自我的意义。所以，去寻找生活中，对你最有意义的人、事、物。去改变你的生活优先权（life priority）。将重要的，对你更有意义的事情先做，这里推荐采铜老师的答案供指导：你有什么相见恨晚的知识想推荐给年轻人？不要因为暂时看不到事情的长期收益，而放弃不去做；而只做短期收益高，但半衰期短的事情（例如，你现在在做的看喜剧片。当然要做，但是不能仅仅只做这种事。） 所以，通过积极情绪的扩建理论，我们的观点是：短期收益高的事情带来感官愉悦，我们需要去做，不时的去放松自己；而长期收益高，但短期看不到效果的事情，我们也要去做，它会在某些时刻带给你心理享受，让你在应对生活中的困扰时，有更多的心理应对资源。 至于你如果要追问，如何找到提高心理享受的办法。我就没有办法回答你了。因为它属于知觉类体验，要知道每个人对于同一件事情的知觉都是不同，它依赖于对于事件意义的评价。所以这件事情上你要自己探寻。","categories":[{"name":"62.Psychology","slug":"62-Psychology","permalink":"https://beefyheisenberg.github.io/categories/62-Psychology/"}],"tags":[{"name":"心理学","slug":"心理学","permalink":"https://beefyheisenberg.github.io/tags/心理学/"}]},{"title":"黑暗三角特质","slug":"62.Psychology/03c.黑暗三角特质","date":"2024-01-24T01:27:53.820Z","updated":"2024-01-24T01:27:53.820Z","comments":true,"path":"62.Psychology/03c.黑暗三角特质/","link":"","permalink":"https://beefyheisenberg.github.io/62.Psychology/03c.黑暗三角特质/","excerpt":"@ref: 渣男为什么总有人爱 跟这有关的是一种叫做黑暗三角（Dark Triad）的特质，它有点类似于中文语境中的“腹黑”。如果用我们常用的语言捕捉一下，大概是一种“高冷、自恋、冲动、善于欺骗、情绪波动小、冷酷无情”的特质。 自恋 马基雅维利主义 精神病态 ➤ 自恋（Narcissism）: 精神分析学派较早关注自恋的人格心理学意义, 弗洛伊德将其视为一种人格障碍, 属于临床和变态心理学研究的领域, Kohut认为自恋是普通人人性的一部分, 从而将自恋引入人格和社会心理学。亚临床阶段的自恋(subclinicalnarcissism)一般具有以下特征: 自我中心、爱慕虚荣、自我吹嘘、支配性、优越感、傲慢无礼和自以为是。 ➤ 马基雅维利主义（Machiavellianism）: 在心理和行为上一般表现为: 冷酷无情、擅长操纵、阴谋算计、实用主义、注重结果和忽视道德。=&gt; [[../61.Philosophy/11.马基雅维利主义]]","text":"@ref: 渣男为什么总有人爱 跟这有关的是一种叫做黑暗三角（Dark Triad）的特质，它有点类似于中文语境中的“腹黑”。如果用我们常用的语言捕捉一下，大概是一种“高冷、自恋、冲动、善于欺骗、情绪波动小、冷酷无情”的特质。 自恋 马基雅维利主义 精神病态 ➤ 自恋（Narcissism）: 精神分析学派较早关注自恋的人格心理学意义, 弗洛伊德将其视为一种人格障碍, 属于临床和变态心理学研究的领域, Kohut认为自恋是普通人人性的一部分, 从而将自恋引入人格和社会心理学。亚临床阶段的自恋(subclinicalnarcissism)一般具有以下特征: 自我中心、爱慕虚荣、自我吹嘘、支配性、优越感、傲慢无礼和自以为是。 ➤ 马基雅维利主义（Machiavellianism）: 在心理和行为上一般表现为: 冷酷无情、擅长操纵、阴谋算计、实用主义、注重结果和忽视道德。=&gt; [[../61.Philosophy/11.马基雅维利主义]] ➤ 精神病态（Psychpath）: 最初被定义为一种以反社会心理和行为为特征的人格障碍(Hare, 1991),虽未被收入美国精神疾病诊断和统计手册(DSM-Ⅳ), 精神病态一直被认为是反社会行为的预测指标(Harpur, Hart &amp; Hare, 1994), 对精神病态的早期研究主要局限在临床和变态心理学范围内, 被试主要是罪犯和精神病人。随着研究深入,Hare、Lilienfeld 和Andrews对上述刻板印象提出异议, 在他们看来亚临床阶段的精神病态(subclinical psychopathy)更像是一种人格特质, 精神病态者(psychopaths)并非个个都是病人或罪犯, 正常人也有病态心理和病态行为。由此, 精神病态成为人格心理学的研究对象, 被试逐渐扩展到普通人群。作为人格特质, 精神病态在行为上一般表现为: 行为冲动、寻求刺激、缺乏共情、缺乏责任感、缺乏焦虑。=&gt; 03b.人格障碍 由于在研究中，拥有其中一个特质的人，通常又会或多或少地拥有其他一到两个特质的特征，所以才将三个特质合并建立黑暗三角特质进行了研究","categories":[{"name":"62.Psychology","slug":"62-Psychology","permalink":"https://beefyheisenberg.github.io/categories/62-Psychology/"}],"tags":[{"name":"心理学","slug":"心理学","permalink":"https://beefyheisenberg.github.io/tags/心理学/"}]},{"title":"人格障碍","slug":"62.Psychology/03b.人格障碍","date":"2024-01-24T01:27:53.815Z","updated":"2024-01-24T01:27:53.815Z","comments":true,"path":"62.Psychology/03b.人格障碍/","link":"","permalink":"https://beefyheisenberg.github.io/62.Psychology/03b.人格障碍/","excerpt":"人格障碍人格障碍，或人格（性格）疾患／异常／违常（Personality disorders）。是精神疾病中，对于一群特定拥有长期而僵化思想及行为病患的分类。这类疾患常可因其人格和行为的问题而导致社会功能的障碍。人格违常是据美国精神医学学会所定，这类疾患的表现是跨文化和国界的。它们被定义成发病期至少要能追溯到成长期早期或更早。要能符合人格违常诊断的最低标准是疾患本身必须已干扰到个人、社会、或职业功能。 A型 （奇怪型或异常型疾患） 妄想型人格违常 孤僻型人格违常 精神分裂型人格违常 B型 （戏剧型或情感型疾患） 反社会人格违常 边缘型人格违常 戏剧化人格违常 自恋型人格违常 C型 （焦虑型或恐惧型疾患） 畏惧型人格违常 依赖型人格违常 强迫型人格违常 回避型人格障碍因为害怕在别人面前丢脸，此类患者经常选择可独立完成工作的职业，以降低与人社交的机会。有些患者会幻想与他人拥有完美、被爱和被别人接受的关系，不过因他们觉得自己不值得拥有这些关系，所以并不主动去追求。他们只有在确信不会被拒绝的情况下才愿意与人建立关系，并只关注自己的缺点，经常贬低自我。","text":"人格障碍人格障碍，或人格（性格）疾患／异常／违常（Personality disorders）。是精神疾病中，对于一群特定拥有长期而僵化思想及行为病患的分类。这类疾患常可因其人格和行为的问题而导致社会功能的障碍。人格违常是据美国精神医学学会所定，这类疾患的表现是跨文化和国界的。它们被定义成发病期至少要能追溯到成长期早期或更早。要能符合人格违常诊断的最低标准是疾患本身必须已干扰到个人、社会、或职业功能。 A型 （奇怪型或异常型疾患） 妄想型人格违常 孤僻型人格违常 精神分裂型人格违常 B型 （戏剧型或情感型疾患） 反社会人格违常 边缘型人格违常 戏剧化人格违常 自恋型人格违常 C型 （焦虑型或恐惧型疾患） 畏惧型人格违常 依赖型人格违常 强迫型人格违常 回避型人格障碍因为害怕在别人面前丢脸，此类患者经常选择可独立完成工作的职业，以降低与人社交的机会。有些患者会幻想与他人拥有完美、被爱和被别人接受的关系，不过因他们觉得自己不值得拥有这些关系，所以并不主动去追求。他们只有在确信不会被拒绝的情况下才愿意与人建立关系，并只关注自己的缺点，经常贬低自我。 ICD‐10指出APD的特征包括： 泛化的紧张感与忧虑 相信自己在社交上笨拙，没有吸引力或不如别人 在社交场合过分担心会被人指责或拒绝 除非肯定受人欢迎否则不肯与他人打交道 出于维护躯体安全感的需要，在生活风格上有许多限制 由于担心批评、指责或拒绝，回避那些与人密切交往的社交或职业活动。 依赖型人格美国精神疾病诊断与统计手册（DSM-IV-TR）中收录了依赖型人格障碍的诊断标准。它提出的特点是一种普遍的、过分的想要被照料的需求而导致了顺从和依从于他人并害怕分离的心理状态。并且在成年早期开始发生，存在于多种社会背景下。 需要具备以下列出的至少三条特性： 鼓励或是允许别人为自己人生中绝大多数的重要事件做决定； 相比所依赖的人的需要，将自己的需要置于次要的位置，并且过分地顺从于所依赖人的意愿； 甚至不愿意向自己所依赖的人提出合理的要求； 因为害怕没有能力照顾好自己，独处时会觉得不自在或无助； 被先占观念困扰：害怕被亲密关系中的他人抛弃，或是被独自留下需要照顾自己； 在没有他人极多的建议和保证的情况下，没有足够的能力做日常决定。 分裂型人格障碍其特征在于对社会联系缺乏兴趣，倾向于独立生活、沉默寡言和感情淡漠。受影响者可能无法和他人形成健康的依赖关系，也可能会描绘出丰富的幻想世界。","categories":[{"name":"62.Psychology","slug":"62-Psychology","permalink":"https://beefyheisenberg.github.io/categories/62-Psychology/"}],"tags":[{"name":"心理学","slug":"心理学","permalink":"https://beefyheisenberg.github.io/tags/心理学/"}]},{"title":"心理学效应","slug":"62.Psychology/03a.心理学效应","date":"2024-01-24T01:27:53.811Z","updated":"2024-01-24T01:27:53.811Z","comments":true,"path":"62.Psychology/03a.心理学效应/","link":"","permalink":"https://beefyheisenberg.github.io/62.Psychology/03a.心理学效应/","excerpt":"心理学效应巴纳姆效应巴纳姆效应（Barnum effect，是 Paul Meehl 为表对费尼尔司·泰勒·巴纳姆的敬意而命名，又称巴南效应、弗拉效应（英语：Forer effect））是一种心理现象：人很容易相信一个笼统的一般性的人格描述，并认为它特别适合自己并准确地揭示了自己的人格特点，而这些描述往往十分模糊及普遍，以致能够放诸四海皆准适用于很多人身上。 巴纳姆效应能够对于为何不少伪科学如占星学、占卜或心理测验等被普遍接受提供一个不十分完全的解释。 自我实现预言","text":"心理学效应巴纳姆效应巴纳姆效应（Barnum effect，是 Paul Meehl 为表对费尼尔司·泰勒·巴纳姆的敬意而命名，又称巴南效应、弗拉效应（英语：Forer effect））是一种心理现象：人很容易相信一个笼统的一般性的人格描述，并认为它特别适合自己并准确地揭示了自己的人格特点，而这些描述往往十分模糊及普遍，以致能够放诸四海皆准适用于很多人身上。 巴纳姆效应能够对于为何不少伪科学如占星学、占卜或心理测验等被普遍接受提供一个不十分完全的解释。 自我实现预言自证预言（英语：Self-fulfilling prophecy；又称“自我应验预言”或“自我实现预言”），是由美国社会学家罗伯特·金·莫顿提出的一种社会心理学现象，是指人们先入为主的判断，无论其正确与否，都将或多或少的影响到人们的行为，以至于这个判断最后真的实现。[1]通俗的说，自证预言就是我们总会在不经意间使我们自己的预言成为现实。信念和行为之间的正反馈被认为是自我应验预言成真的主要原因。虽然此类预言的例子可以一直追溯到古希腊和古印度时期的文学作品，然而“自证预言”这个名称直到20世纪才由著名社会学家罗伯特·金·莫顿提出，并对它的结构和推论作了比较系统化的定义。莫顿在他的著作《社会理论和社会结构》中对自我应验预言作了如下阐述[2]：自我应验预言是一种能够唤起新的行为的预言，并且该行为使得本来错误的概念变成了正确。吸引力法则被视为是自证预言的一种。 这一理论最著名的实验出自1968年Rosenthal博士与Jacobson博士所完成。首先，他们给一所中学的所有学生进行智商测试，然后告诉老师一些学生的智商非常高，让老师相信这些学生在来年的学习成绩中将会飞跃成长。但事实上这些所谓的“高智商”的学生非真的高智商，而是随机抽取。因此，他们智商不见得比其余学生还高。随后的实验结果惊人：那些被老师认为“高智商”的学生（事实跟其余学生的智商一样）在来年的学习成绩确实突飞猛进。科学家认为原因有可能是： 1. 老师的期望值在不知不觉中给了这些“高智商”学生更多的感情投入 2. 给了更多学习资料和让他们研究艰深的学习内容 3. 对于“高智商”学生的学习，老师在不自觉中给了更多的反馈 4. 老师在不自觉中给了这些学生在课堂中活跃的机会。 @ref:自证预言 | 我为什么忍不住把事情往最坏的方面想？ - 知乎","categories":[{"name":"62.Psychology","slug":"62-Psychology","permalink":"https://beefyheisenberg.github.io/categories/62-Psychology/"}],"tags":[{"name":"心理学","slug":"心理学","permalink":"https://beefyheisenberg.github.io/tags/心理学/"}]},{"title":"社会心理学","slug":"62.Psychology/03.社会心理学","date":"2024-01-24T01:27:53.803Z","updated":"2024-01-24T01:27:53.803Z","comments":true,"path":"62.Psychology/03.社会心理学/","link":"","permalink":"https://beefyheisenberg.github.io/62.Psychology/03.社会心理学/","excerpt":"社会心理学社会心理学是从跟社会的关联研究人属的心理学和社会学的学问领域。被个人内过程的研究，对人过程的研究，集体内过程的研究，集合现象的研究等分类。而心理学家则认为，社会心理学是一门在社会情景下，以人的心理行为活动为研究对象，以实证方法为手段，基于心理学、社会学相关理论的社会科学。 内在现象自我概念自我概念是指人们对自我的一切信念的一个术语。","text":"社会心理学社会心理学是从跟社会的关联研究人属的心理学和社会学的学问领域。被个人内过程的研究，对人过程的研究，集体内过程的研究，集合现象的研究等分类。而心理学家则认为，社会心理学是一门在社会情景下，以人的心理行为活动为研究对象，以实证方法为手段，基于心理学、社会学相关理论的社会科学。 内在现象自我概念自我概念是指人们对自我的一切信念的一个术语。 =&gt; 03a.心理学效应 态度在社会心理学领域，态度被定义为是被学习的，是一个人、一件物品、一个地方或者事件的整体评估，影响着人的思想和行动。更简单的来说，态度是赞成或反对、喜好或厌恶的基本表达，或如本所说，喜欢和不喜欢。例子包括喜欢巧克力冰淇淋，或赞同特定政党的价值观。 说服近年来，说服这个话题受到了广泛的关注。说服是一种积极的方式去影响或指引他人更倾向于某种态度，思想或行为通过理性或情绪化的方式。说服更依赖于“呼吁”，而不是压力或强迫。已经发现了许多影响说服过程的变量;这些通常在五个主要类别中出现:“谁”说“什么”和“谁”和“如何”。 社会认知社会认知是一个现在正不断发展的社会心理学领域，它研究人们如何感知、思考以及记住他人的信息。很多研究都基于人们对(他人)不同于非社会目标的看法。 人际现象社会影响社会影响是一个包罗万象的术语，用来描述人们对彼此影响作用。它被认为是社会心理学的一个基本价值，与对态度和说服的研究有很大的重叠。社会影响的三个主要方面包括:从众、顺从和服从。社会影响也与群体动力学的研究密切相关，因为在社会群体中，多数决原则都是最强的。 人际吸引是与他人在情感之间互相亲密的状态，一种人关系关系的肯定形式，按照吸引程度，可分成亲合、喜欢和爱情。首先亲合是低层次的人际吸引，喜欢是中等程度的吸引，爱情是最强烈的吸引形式。","categories":[{"name":"62.Psychology","slug":"62-Psychology","permalink":"https://beefyheisenberg.github.io/categories/62-Psychology/"}],"tags":[{"name":"心理学","slug":"心理学","permalink":"https://beefyheisenberg.github.io/tags/心理学/"},{"name":"社会心理学","slug":"社会心理学","permalink":"https://beefyheisenberg.github.io/tags/社会心理学/"}]},{"title":"现代心理学史","slug":"62.Psychology/02.现代心理学史","date":"2024-01-24T01:27:53.798Z","updated":"2024-01-24T01:27:53.798Z","comments":true,"path":"62.Psychology/02.现代心理学史/","link":"","permalink":"https://beefyheisenberg.github.io/62.Psychology/02.现代心理学史/","excerpt":"现代心理学史概述@ref: 心理学史 - 维基百科，自由的百科全书 现代心理学一般认为是起始于十九世纪末冯特的构造主义，历经精神分析、行为主义等，一直到近期的认知主义，然而在行为主义盛行时被抵制的理性主义随着认知科学的进步而再度兴起，之前因技术问题而无法深入探讨的内在认知历程再度受到重视。 现代心理学早期由冯特（Wilhelm Wundt）于德国莱比锡大学创立首间心理学实验室而兴起，及后首位美国心理学家威廉·詹姆士编写美国首本心理学教科书《心理学原理》，以及鼓吹将心理学专业化的斯坦利·霍尔于1887年创办了《美国心理学杂志》（American Journal of Psychology）及于1892年担任第一届的美国心理学会会长后，心理学开始在美国发展。而德国其后则发展出由马科斯·韦特墨所创立的格式塔学派，又称为完形心理学。奥地利精神科医生弗洛伊德于二十世纪初凭其临床治疗经验中所创立的精神分析学亦对后来心理学发展具有深远影响，尤其是在心理治疗方面。","text":"现代心理学史概述@ref: 心理学史 - 维基百科，自由的百科全书 现代心理学一般认为是起始于十九世纪末冯特的构造主义，历经精神分析、行为主义等，一直到近期的认知主义，然而在行为主义盛行时被抵制的理性主义随着认知科学的进步而再度兴起，之前因技术问题而无法深入探讨的内在认知历程再度受到重视。 现代心理学早期由冯特（Wilhelm Wundt）于德国莱比锡大学创立首间心理学实验室而兴起，及后首位美国心理学家威廉·詹姆士编写美国首本心理学教科书《心理学原理》，以及鼓吹将心理学专业化的斯坦利·霍尔于1887年创办了《美国心理学杂志》（American Journal of Psychology）及于1892年担任第一届的美国心理学会会长后，心理学开始在美国发展。而德国其后则发展出由马科斯·韦特墨所创立的格式塔学派，又称为完形心理学。奥地利精神科医生弗洛伊德于二十世纪初凭其临床治疗经验中所创立的精神分析学亦对后来心理学发展具有深远影响，尤其是在心理治疗方面。 二十世纪早期的自然科学偏向机械式宇宙观，因此当时的心理学家提出行为主义的研究方法，并认为不应探讨意识这种无法量化且模糊不清的议题，其行为主义深受当时的学界风气支持，且借由行为主义方法得来的资料远比精神分析方法得来的资料有说服力，而精神分析因其研究方法有太多的问题，且太过于主观的判定，导致大多数的心理学家都急于与精神分析划清关系，并不断强调心理学不是研究意识的学问。行为学派的代表心理学家包括伊万·巴甫洛夫、约翰·华生、史金纳等。 行为主义盛行其间的心理学派，除了行为主义与精神分析外，还有从[[../61.Philosophy/05.存在主义]]延申出来的存在心理学并进一步于二十世纪六零年代演变出人本主义，被称为除行为学派和精神分析以外，心理学上的“第三势力”。人本主义的代表人物包括：卡尔·罗哲斯和亚伯拉罕·马斯洛等。 二十世纪六、七十年代起，随着医疗科技和实验方的进步，例如EEG（脑电图）和MRI（磁共振成像）等技术的出现，为认知心理学、脑神经心理学等研究领域带来高速的发展。另一方面， 03.社会心理学 承继完形心理学的基础，以及二次大战后的社会需要，亦成为了心理学研究上的一股新势力。 社会心理学的代表人物包括：库尔特·勒温、菲腊·津巴多、所罗门·阿希等。 以上的学派都对现代心理学有深浅不一的影响，有些学派的理论内容可能已被推翻而只剩下一些名词还被延用于心理学之中，有些学派的理念随着科技的发展再度受到重视，因此心理学史是由不断的尝试错误与修正所累积下来的历史。 科学心理学 心理学作为一门独立的学科是开始于1874年，那一年，德国的生理学家威廉·冯特发表两册的心理学教科书——《生理心理学的原理》（Principles of Physiological Psychology）——，在序言里大胆宣称：“要建立一个新的科学领域”；冯特也因此被称为“心理学之父”。 1875年，莱比锡大学聘冯特为教授；1879年，他在莱比锡大学建立世界第一个专门的心理实验室，吸引了来自世界各地的学生。 10余年后，也就是1890年代，美国各大学风起云涌地仿效此举，建立数十座心理学实验室，尤其1892这一年就成立了20座，这一年也是美国心理学会的成立年。通常将1874年作为科学心理学诞生的时间，这一时间比许多自然科学脱离哲学而形成独立学科的时间为晚。冯特也是第一个把自己称为心理学家的人。其他早期而重要的心理学家包括艾宾浩斯等。 构造主义 德国心理学家威廉·冯特被认为是将实验引入心理学研究的人，被誉为“实验心理学之父”。冯特着重于将心理分解成为基本的元素，这是由于当时化学的进步，后者在分析物质元素与结构上取得突破。虽然冯特自己不是构造主义者，他的学生爱德华·B·铁钦纳成为了构造主义的思想家，与机能主义者对立。 机能主义 机能主义相对于结构主义而生，并受到美国哲学家、科学家、心理学家威廉·詹姆士影响颇多。詹姆士认为心理学应该有实用价值，心理学家应该找到有益于人的科学方式。 其它19世纪的杰出人物有德国心理学家赫尔曼·艾宾浩斯，他是研究记忆实验的先驱，在柏林洪堡大学创立了学习与遗忘的量化模型。苏俄心理学家伊万·彼得罗维奇·巴甫洛夫，他在对狗进行实验时发现了“古典制约”，并将其应用与人类。 自二十世纪50年代起，冯特、詹姆士、艾宾浩斯与其他实验心理学家们所发展的实验技术方向更加趋向研究认知——关注信息以及信息处理——最终演化为认知科学中的一部分。 精神分析 精神分析学是一种研究意识、解释经历的方法；是一种关于人类行为的理论系统；是一种针对心理、情绪的治疗方法，特别是对潜意识中的冲突进行心理治疗。弗洛伊德的精神分析中的很多理论基于解释法、内省法以及临床观察。精神分析法广为流传，因为它的研究对象涉及性别、压抑、心理发展中的潜意识等。这些问题在当时都被列为社会禁忌，弗洛伊德则提供了催化剂，使得问题可以在正式社交中得以公开讨论。在临床上，弗洛伊德是自由联想的先驱，他对释梦治疗也很有研究。 弗洛伊德对瑞士精神科医师卡尔·荣格的影响很大，后者的分析心理学与深度心理学互补。 精神分析及其治疗受到诸多人士的批评，到二十世纪末，美国高等院校心理学院变得更加倾向于实证主义，将弗洛伊德理论边缘化 @link: 荣格 行为主义 在整个20世纪的上半叶，行为主义学派支配了当时的心理学，其主张心理学是：“寻求理解特定的环境刺激如何控制特定类型的行为”。其主张心理学应分析先行的环境条件，即在行为之前出现、而且为一个机体产生反应或抑制反应提供活动场所的条件。因此，他们把行为反应看做是机体理解、预测和控制的行为，并因此做出相应的结果。基于对实验和变量的严格控制和强调，行为主义学对后来的心理学研究有着重要的影响。其代表人物为史金纳，然而其对于内在的认知历程是存而不论，近期流行的认知主义则是重视之前忽视的内在认知历程，代表人物有皮亚杰、米勒、西蒙等。 当今世界主要的心理学学派有五大观点，每一个观点都强调行为及心理过程的不同方面。其主要包括神经心理学、精神分析学、行为主义心理学、人本主义心理学、认知心理学 人本主义 二十世纪50年代，在行为主义与精神分析的影响下，人本心理学应育而生。应用现象学、交互主体性、第一人称视角，人本主义试图捕捉整个人——而不是人格或认知的一部分。人本主义心理学关注人类独特问题的基础，例如个人的自由意志、成长、自我实现、认同、死亡、孤独、自由与意义。人本过程的特点在于它关注主观臆想、拒绝宿命、着重成长的积极性而不是病理因素。 一些人本学派的奠基人，如美国心理学家亚伯拉罕·马斯洛，创立了需求层次理论；卡尔·罗哲斯，创立了个人中心治疗。在此之后，正面心理学剖析了人本主义，对其更进一步的科学分析。 存在主义 在二十世纪50到60年代，美国原精神分析学家罗洛·梅在德国哲学家马丁·海德格尔、丹麦哲学家索伦·奥贝·克尔凯郭尔的影响下，走上了心理学存在主义之路。这包括存在心理治疗。 存在主义心理学不同于其它人本学派，即人性中立视角、对焦虑的积极观点等。存在主义心理学注重于人文主题，如死亡、自由意志、意义，并认为意义可以被神话、或是讲述方式改变。对于死亡及未来的真实性，通常会鼓励人们接受自由意志，尽管令人焦虑。 @link: [[../61.Philosophy/05.存在主义|05.存在主义]] [[../61.Philosophy/05a.此在的本真-海德格的存在主义|05a.此在的本真-海德格的存在主义]] [[../61.Philosophy/05b.海德格《存在与时间》|05b.海德格《存在与时间》]] 《存在主义心理治疗》读书笔记 认知主义&amp;认知心理学认知心理学（cognitive psychology），20 世纪 50 年代中期在西方兴起的一种心理学思潮和研究方向。广义指研究人类的高级心理过程，主要是认识过程，如注意、知觉、表象、记忆、创造性、问题解决、言语和思维等。狭义相当于当代的信息加工心理学。即采用信息加工观点研究认知过程。 从1950至1960年代间才发展出来的，到70年代成为西方心理学的主要流派。1956年被认为是认知心理学史上的重要年份。这一年几项心理学研究都体现了心理学的信息加工观点。如 Chomsky 的语言理论和纽厄尔（Alan Newell）和西蒙（Herbert Alexander simon）的“通用问题解决者”模型。“认知心理学”第一次在出版物出现是在1967年 Ulrich Neisser 的新书。而唐纳德·布罗德本特于1958年出版的《知觉与传播》一书则为认知心理学取向立下了重要基础。此后，认知心理取向的重点便在唐纳德·布罗德本特所指出的认知的讯息处理模式–一种以心智处理来思考与推理的模式。因此，思考与推理在人类大脑中的运作便像电脑软件在电脑里运作相似。认知心理学理论时常谈到输入、表征、计算或处理，以及输出等概念。 认知主义心理学派研究心理活动，包括解决问题、知觉、记忆、学习等。作为认知科学的一部分，这个心理学分支与其它学科有密切联系，包括神经科学、哲学、语言学等。 诺姆·乔姆斯基在批评行为学概念中的“刺激”、“相应”、“强化”时，触发了一场心理学“认知革命”。乔姆斯基辩称这种观点会以一种肤浅、模糊的方式应用到复杂的人类行为中，特别是在语言习得的领域上。有一种假定认为人类天生拥有一种“内在的”语言习得机能，然而对于行为主义来说，这个问题在于所有行为，包括语言在内，都必须通过学习和强化来获得。社会学习理论家，如阿尔波特·班杜拉称儿童的生活环境有助于行为的改良。 与此同时，技术进步帮助人们重拾被行为主义抛弃的心理活动与表述，如认知等。英国神经科学家查尔斯·斯科特·谢灵顿爵士与加拿大心理学家唐纳德·赫布应用实验总结了心理现象与人脑结构、功能之间的联系。计算机科学与人工智能的兴起，使得人类信息处理时常与机械信息处理相互类比。对认知的研究被应用于二战，用以理解武器操作。在二十世纪晚期，认知主义成为心理学的统领范式，认知心理学成为了流行分支。 认知心理学认为隐蔽的心理活动应该使用科学的方式进行研究，心理学家创立了两种概念：阈下刺激物与内隐记忆，对应精神分析的潜意识或行为学的偶然形成行为。行为主义元素与认知心理学被整合成为认知行为疗法的基础。这种心理治疗由美国心理学家阿尔伯特·艾利斯和精神病学家亚伦·T·贝克创立而成。认知心理学与其它学科，如精神哲学、计算机科学、神经科学，一道被归入的上层学科认知科学。 @ref: 心理学 - 维基百科，自由的百科全书","categories":[{"name":"62.Psychology","slug":"62-Psychology","permalink":"https://beefyheisenberg.github.io/categories/62-Psychology/"}],"tags":[{"name":"心理学","slug":"心理学","permalink":"https://beefyheisenberg.github.io/tags/心理学/"}]},{"title":"心理学分支","slug":"62.Psychology/01.心理学分支","date":"2024-01-24T01:27:53.794Z","updated":"2024-01-24T01:27:53.794Z","comments":true,"path":"62.Psychology/01.心理学分支/","link":"","permalink":"https://beefyheisenberg.github.io/62.Psychology/01.心理学分支/","excerpt":"心理学分支@todo待整理: https://zh.wikipedia.org/wiki/%E5%BF%83%E7%90%86%E5%AD%A6#%E5%88%86%E6%94%AF 临床心理学临床心理学的研究与应用包括理解、预防、缓解心理痛苦与紊乱，促进心理健康和个人成长。虽然临床心理学家也会参与研究、教学、咨询、出庭作证、程序编订与管理，但该分支的中心是心理测评与治疗。 认知心理学","text":"心理学分支@todo待整理: https://zh.wikipedia.org/wiki/%E5%BF%83%E7%90%86%E5%AD%A6#%E5%88%86%E6%94%AF 临床心理学临床心理学的研究与应用包括理解、预防、缓解心理痛苦与紊乱，促进心理健康和个人成长。虽然临床心理学家也会参与研究、教学、咨询、出庭作证、程序编订与管理，但该分支的中心是心理测评与治疗。 认知心理学认知心理学研究心理活动中的认知。知觉、注意、理智、思维、解题、记忆、学习、语言、情绪都在它的研究领域之中。经典认知心理学与认知主义学派有相互联系，根据机能主义与实验心理学，认知主义支持心理信息处理模型。 在更广域的层面上，认知科学是一种跨学科范畴，包括认知心理学、认知神经科学、人工智能、语言学、人机互动、计算神经科学、数理逻辑与人类学。计算机常被用于模拟这类实验现象。 计算机模拟为研究思维的功能组织提供了工具，神经系统科学则为大脑活动提供了度量衡。 发展心理学发展心理学着重于人类意志在毕生当中的发展过程，试图理解人们在世界中如何意识、理解、行动，并且研究这些现象是如何随着年龄而改变的。这些研究可能会着重于认知、感情、道德、社交、神经的发展。研究人员在探究儿童案例时使用一系列特殊的方式，以使得观察在自然的环境中进行，或是干脆与他们在实验中进行互动。这些实验常常以游戏或是活动的方式呈现，既好玩，又有科学意义；研究人员甚至设计出非常灵巧的方式以研究婴儿的心理活动。在研究儿童心理之余，发展心理学家也会研究人类毕生的老化过程，特别是在某些时段的快速转变（例如青少年和老年）。发展心理学家设计了一整套心理学理论来支持他们的研究。如原”生家庭理论”","categories":[{"name":"62.Psychology","slug":"62-Psychology","permalink":"https://beefyheisenberg.github.io/categories/62-Psychology/"}],"tags":[{"name":"心理学","slug":"心理学","permalink":"https://beefyheisenberg.github.io/tags/心理学/"}]},{"title":"哲学家普遍赞同什么观点？（PhilPapers Survey 2020）zz","slug":"61.Philosophy/哲学家普遍赞同什么观点？（PhilPapers-Survey-2020）","date":"2024-01-24T01:27:53.788Z","updated":"2024-01-24T01:27:53.789Z","comments":true,"path":"61.Philosophy/哲学家普遍赞同什么观点？（PhilPapers-Survey-2020）/","link":"","permalink":"https://beefyheisenberg.github.io/61.Philosophy/哲学家普遍赞同什么观点？（PhilPapers-Survey-2020）/","excerpt":"Philpapers Survey 2020@ref: 哲学家普遍赞同什么观点？（PhilPapers Suvery 2020) - 知乎 如何评价2020 Philpapers Survey的结果？ - 知乎 https://survey2020.philpeople.org/ 摘自 https://zhuanlan.zhihu.com/p/428768169","text":"Philpapers Survey 2020@ref: 哲学家普遍赞同什么观点？（PhilPapers Suvery 2020) - 知乎 如何评价2020 Philpapers Survey的结果？ - 知乎 https://survey2020.philpeople.org/ 摘自 https://zhuanlan.zhihu.com/p/428768169 就在昨天，Philpapers Survey 2020的结果终于出来了！PhilPaper 采访了全球各地1785位职业哲学家100个哲学问题（回应量前五的是美国859人、英国163人、加拿大127人、德国89人和澳大利亚59人）。让我们来看一看他们对一部分问题的回应吧！对原文感兴趣的直接点击注解11 注意，（1）所有下文的百分比涵盖两种情况，要么哲学家接受该观点（accept）要么哲学家倾向于接受该观点（lean towards）（2）我只挑了我感兴趣或者我对该话题有了解的问题进行翻译（3）非分析哲学专业读者请注意，哲学中通常对很多词语的理解和我们平常理解不太一样，甚至区别很大（4）本调查的问题大多是分析哲学问题，而分析哲学是说英语国家的主流，所以为了有参考性，英语国家的必然会多一些（5）至于为何没有询问其它非分析哲学问题，编者首先指出确实很多职业哲学家对这一点表达了不满，他们的回应大概是他们尝试创作了一些非分析哲学的问题，但是写出来后发现擅长的人太少了以至于无法保证数据的可参考性。他们说，对于这点，他们很对不起大家，下次会努力的2（6）职业哲学家是指读完哲学博士并且大多在校执教（7）我在翻译时并没查中文是如何翻译这些词的，具体请对照英文翻译，谢谢！ 先验知识（a priori knowledge） 认同：72.67% 不认同18.47% 美学价值（aesthetic value） 客观的43.53% 主观的40.59% 哲学的目的（the aim of philosophy） 真理&amp;知识42.18% 理解55.79% 智慧31.17% 幸福12.65% 善或公正22.70% 分析性和综合性的区分（analytic and synthetic） 有62.48% 没有25.78% 快感机器（experience machine就是说，有一台机器一旦你进去就不能出来了，它能让你感受到一切你想要的美好的感受，而且你进去后你根本不知道自己在这个机器中） 进入35.72% 不进入50.52% 世界的存在（external world） 唯心主义（idealism大致是乔治·贝克莱【George Berkeley】那种）6.63% 怀疑主义（skepticism）5.44% 非怀疑实在主义（non-skeptical realism）79.54% 哪种对世界存在怀疑论（external-world skepticism）的回应是最有说服力的？（Response to external-world skepticism (which is strongest?)） 溯因推理（abductive）22.13% 情境主义式回应（contextualist）10.74% 信条派回应（dogmatist）13.43% 认知外在论回应（epistemic externalist）18.90% 语义外在论（semantic externalist）8.38% 务实回应（pragmatic）22.77% 自由意志（free will） 相容论（compatibilism）59.16% 自由主义（libertarianism）18.83% 没有自由意志11.21% 性别（gender） 生理的（biological）29.04% 心理的（psychological）21.54% 社会的（social）63.10% 不是真实的（unreal）4.23% 上帝 神论18.93% 无神论66.95% 知识 经验主义（empiricism）43.90% 理性主义（rationalism）33.51% 自然法则（laws of nature） 休谟论（Humean）31.27% 非休谟论54.31% 生命的意义 主观的33.04% 客观的32.06% 不存在16.12% 心灵内容（mental content） 内在论（internalism）26.35% 外在论（externalism）58.12% 元伦理（meta-ethics） 道德实在论（moral realism）62.07% 道德非实在论26.12% 元伦理理论 非自然实在论（non-naturalism）26.56% 自然实在论（naturalist realism）31.64% 构成主义（constructivism）20.80% 抒发论（expressivism）10.64% 错误论（error theory）5.27% 元哲学（meta-philosophy，大概是研究哲学时我们的前提条件是否应该符合科学） 自然主义（naturalism）50.16% 非自然主义31.12% 心灵（mind） 物理主义（physicalism）51.93% 非物理主义32.08% 道德评价（moral judgement） 认知论（ cognitivism）69.25% 非认知论（non-cognitivism）20.72% 道德动力（moral motivation） 内在论41.01% 外在论39.33% Newcomb’s problem（你参加了一个游戏，在你面前摆着两个非透明的箱子，箱子甲里面有一千元，而箱子乙中有一百万元。假设在你进入房间做决定之前，有一台准确率接近100%的机器会预测你将要做出的选择。如果它认为你只会拿箱子乙，那么箱子乙中的一百万就会原封不动的放在那里；可是如果它预测你会两个箱子都拿走，箱子乙中的一百万就会被取出。我们应该怎么做？） 拿箱子乙31.19% 拿两个箱子39.03% 规范伦理（normative ethics） 道义论（deontology康德类似的道德论）32.05% 结果论（consequentialism）30.56% 德性论（virtue ethics）36.99% 个人同一性（personal identity） 生理论（比如拥有同一个大脑）19.07% 心理论（比如记忆的延续）43.65% 额外观点论（比如有灵魂further-fact view）14.86% 哲学进程（philosophical progress） 没有进步3.83% 有一点46.59% 很多41.69% 种族（race） 生理的18.68% 社会的63.43% 不真实的15.04% 科学 科学实在论（scientific realism）72.35% 科学非实在论15.04% 传送器（就是从地球扫描你的身体的全部信息，再将这些信息传送到比如火星，火星再根据这些信息用当地的材料复制出一个你，同时，地球会将被扫描信息的那个人毁灭） 你存活了下来35.24% 你死了40.06% 真理 对应（correspondence）51.37% 压缩（deflationary）24.53% 认知（epistemic）10.16% 知识的概念（analysis of knowledge） 有依据真信念（justified true beliefs）23.61% 其它理论32.20% 无法分析（no analysis）30.63% 死刑 道德上允许17.74% 道德上不允许75.13% 意识（consciousness） 二元论（dualism）21.96% 抹杀论（eliminativism）4.51% 功能论（functionalism）33.04% 恒等论（identity theory，比如，你的行为就是你大脑的xx神经运动）13.33% 人类基因改良 道德上允许64.21% 道德上不允许19.45% 休谟的观点 他是怀疑论者36.47% 他是自然主义者54.93% 永生 我要！44.92% 我才不要！41.33% 思想上传到电脑中 人死亡54.23% 人依然活着27.46% 有哲学知识么？ 没有3.60% 有一点32.52% 有很多56.22% 科学中是否存在人的价值（Values in science (is ideal scientific reasoning necessarily sensitive or insensitive to non-epistemic values?): necessarily value-free, necessarily value-laden, or can be either?） 必然不存在（necessarily value-free）17.69% 必然存在（necessarily value-laden）44.02% Wittgenstein 早期理论好24.61% 晚期理论好57.53% 政治哲学（Political philosophy） 社群主义（communitarianism）27.26% 平等主义（egalitarianism）44.05% 自由主义（libertarianism）13.40% 政治哲学中的方法 理想论（ideal theory）32.44% 非理想理论58.02% 政治 资本主义29.52% 社会主义53.02% （注意，对西方人来说，加拿大瑞典挪威等是他们首先想到的社会主义国家） 时间 A论27.25% B论38.20% 环境哲学 以人类为中心（anthropocentric）42.25% 不以人类中心50.67% 思考能力，下列的各组中是否有一些成员是有意识的？（Other minds (for which groups are some members conscious?)） 人类95.15% 猫88.55% 鱼65.29% 苍蝇34.52% 蚯蚓24.18% 植物7.23% 粒子2.01% 新生婴儿84.34% 目前的AI 3.39% 以后的AI 39.19% 后记我发现很多读者对实在论（realism）很多感到惊讶。比如像我们是否知道或者有依据相信世界存在、道德、自由意志、科学、自然定律等等都可以称之为实在论。我后来想了一下，感觉原因可能至少有两点。首先，或许一些读者对哲学的相关概念不是很理解。比如，道德实在论是元伦理的理论，和它相对的是道德非实在论。但是注意，道德非实在论和道德相对论是两个话题（至少普遍大多哲学家是这样想的）。道德实在论者照样可以是道德相对主义者（这样的人可以说，在这个文化中，将刚出生男孩的脚剁下来道德上是绝对错的；但是在另一个文化中这样做道德上是可以被允许的）；而道德非实在论者可以相信道德是绝对的（他们可以说，道德价值本身是不存在的，但是跺脚行为在任何文化任何时间都是坚决不能推崇的）。还有就是在西方分析哲学论文中，我们基本不会看见证明（prove/proof）一词，而只是给出合理的理由就好。这也是为什么有那么多实在论者，他们在乎的更多的是依据，我们是否有相信的道理，而不是排除所有出错的可能。 其次，我突然想起自己大一时也是怀疑这个怀疑那个的，记得大一到大二自己成天吆喝着自由意志不存在，或者我们没法知道世界存在。现在想想，是因为那是上哲学课时，老师只是在介绍问题，他们一般会花很久介绍为什么有哲学家认为自由意志不存在，贝克莱的唯心主义的论证是什么等等。而教授一般只会花一小部分时间解释其它哲学家是如何回应这些问题的。这就难免导致自己片面的理解这些哲学家的回应，忽略了哲学本身的复杂程度。这也是为什么国外哲学新生的常见现象是认为（1）人没有自由意志并且（2）道德是相对的，甚至对于（2）很多哲学家直接在学术论文中戏称“大一相对论者”（Freshman relativist）。我个人揣测也是如此，大家很多人都是读过为什么说人没有自由意志，或者为什么因果关系是休谟式的便就再没继续研究下去？ 当然，我这样揣测没有任何意图，只是好奇为何人们会对实在论很多而感到震惊。其实我个人本身在上文问题中至少有7-8个问题也都倾向于小众观点。 简单瞅了一眼问卷发起者的文章见注解33，下面是一些值得关注的信息，这些信息更适合哲学专业或者懂英语的人阅读，因为我并没有翻译，抱歉！ 参与者的年龄统计 见注解3原文21页 参与者性别统计 见注解3原文22页 参与者所在领域（philosophical traditions) 见注解3原文22页 参与者主要研究方向（Areas of specialization） 见注解3原文23页 参与者最认同哪位哲学家（most identified with） 见注解3文章的24页 亚里士多德 2. 休谟 3. 康德 4. 维特根斯坦 5. 大卫路易斯（David Lewis) 6. 威拉德·冯·奥曼·蒯因 7. 弗雷格 8 鲁道夫·卡尔纳普 9 罗素 10 柏拉图 14 马克思 和2009年的调查相比，变动最大的观点是 见注解3原文25页 参与2009年调查那批人在2020年调查变化幅度最大的观点是 见注解3文章25页 亚洲参与调查的哲学系（中国大学大家一眼了然，就不翻译了哈） 4 上下二图见注解4 参考1.https://survey2020.philpeople.org/ ↩2.Perhaps the most common objection to the 2020 survey was that the survey questions were strongly skewed to certain traditions and orientations in philosophy. Respondents from non-analytic philosophical traditions often reported feeling somewhat alienated by the questions, and even respondents from analytic traditions sometimes reported that the questions reflected a fairly traditional conception of philosophy that did not fully represent philosophy as it is done in 2020.We acknowledge these criticisms as reasonable. We made some attempt to find questions from non-analytic traditions, but it was difficult to find candidates that enough of our target group would be familiar with… We’re especially sorry for bringing about feelings of alienation. We will try harder next time. ↩3.https://philarchive.org/archive/BOUPOP-3 ↩4.https://survey2020.philpeople.org/survey/design/target-departments ↩","categories":[{"name":"61.Philosophy","slug":"61-Philosophy","permalink":"https://beefyheisenberg.github.io/categories/61-Philosophy/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://beefyheisenberg.github.io/tags/哲学/"},{"name":"哲学主义","slug":"哲学主义","permalink":"https://beefyheisenberg.github.io/tags/哲学主义/"}]},{"title":"叔本华和尼采的“意志”","slug":"61.Philosophy/叔本华和尼采的意志","date":"2024-01-24T01:27:53.783Z","updated":"2024-01-24T01:27:53.783Z","comments":true,"path":"61.Philosophy/叔本华和尼采的意志/","link":"","permalink":"https://beefyheisenberg.github.io/61.Philosophy/叔本华和尼采的意志/","excerpt":"叔本华的“意志”———— 《作为意志和表象的世界》（Die Welt als Wille und Vorstellung） 意志，（德语 Wille），人的一切行为是由意志活动和行为活动两方面构成的，在叔本华看来两者是具有同一性的。在叔本华看来，意志活动不是感性和知性，即思考过程的那种活动，因为这种活动属于表象，和物自体即意志无关。 意志只在行为活动中使自己现身，事实上它应该被理解为某种无法抑制的冲动，确切的说是盲目的冲动，某种非理性的欲求。我们所有的行为都是这种盲目的冲动，一切表象中的活动只是使我们感觉自由的假象。意志是一种不能被克服的东西，我们每一行为都是意志的现身。 叔本华的形而上学构建于两个基础概念之上：一是表象和意志虽然是同一的，并且共同构成世界，但意志是决定性的，任何表象都只是意志的客体化；二是意志永远表现为某种无法满足又无所不在的欲求。于是世界本质就是某种无法满足的欲求，所以从逻辑上说，它永不可能被满足。所以如果不能满足的欲求是某种痛苦，那么世界就无法摆脱其痛苦的本质。","text":"叔本华的“意志”———— 《作为意志和表象的世界》（Die Welt als Wille und Vorstellung） 意志，（德语 Wille），人的一切行为是由意志活动和行为活动两方面构成的，在叔本华看来两者是具有同一性的。在叔本华看来，意志活动不是感性和知性，即思考过程的那种活动，因为这种活动属于表象，和物自体即意志无关。 意志只在行为活动中使自己现身，事实上它应该被理解为某种无法抑制的冲动，确切的说是盲目的冲动，某种非理性的欲求。我们所有的行为都是这种盲目的冲动，一切表象中的活动只是使我们感觉自由的假象。意志是一种不能被克服的东西，我们每一行为都是意志的现身。 叔本华的形而上学构建于两个基础概念之上：一是表象和意志虽然是同一的，并且共同构成世界，但意志是决定性的，任何表象都只是意志的客体化；二是意志永远表现为某种无法满足又无所不在的欲求。于是世界本质就是某种无法满足的欲求，所以从逻辑上说，它永不可能被满足。所以如果不能满足的欲求是某种痛苦，那么世界就无法摆脱其痛苦的本质。 人的痛苦来自于意志（欲望）无法得到满足，所以叔本华提出的如何避免痛苦，是通过禁欲主义摆脱意志（欲望）。在《作为意志和表象的世界》一书第四部分中，叔本华提供了一种以禁欲主义的方式来找到希望的可能。他认为人只有在摆脱一种强烈的欲望冲动的时候才能获得其根本上的自由，只有打破意志对于行为本身的控制，才能获得某种幸福的可能。 且叔本华不赞同自杀，因为自杀行为正是肯定了生命意志本身的显现。 尼采的意志权力意志（Will to power，德语：Der Wille zur Macht）“权力意志”这种中译法有争议，因为这很容易让人连想到权力意志是种政治权谋或权力争斗的力量，但这是种误解。像刘昌元先生就建议译为“力量意志”。 权力意志是尼采在经过价值重估后提出来作为他的价值准则，权力意志是种最基本的驱力，曾被他用来解释物理上的变化、动植物的生长、繁殖、扩张等等，乃至于人类的心理、文化的现象。尼采认为这些背后都是由权力意志所推动的。 尼采早期受叔本华思想的影响，但在1878年出版《人性，太人性的》一书，以格言方式讨论从形而上学到宗教乃至于性别等各种议题，也是在这本书里尼采明确的抛弃瓦格纳和叔本华的哲学。","categories":[{"name":"61.Philosophy","slug":"61-Philosophy","permalink":"https://beefyheisenberg.github.io/categories/61-Philosophy/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://beefyheisenberg.github.io/tags/哲学/"},{"name":"虚无主义","slug":"虚无主义","permalink":"https://beefyheisenberg.github.io/tags/虚无主义/"},{"name":"叔本华","slug":"叔本华","permalink":"https://beefyheisenberg.github.io/tags/叔本华/"},{"name":"尼采","slug":"尼采","permalink":"https://beefyheisenberg.github.io/tags/尼采/"}]},{"title":"伊壁鸠鲁的享乐主义","slug":"61.Philosophy/伊壁鸠鲁的享乐主义","date":"2024-01-24T01:27:53.779Z","updated":"2024-01-24T01:27:53.779Z","comments":true,"path":"61.Philosophy/伊壁鸠鲁的享乐主义/","link":"","permalink":"https://beefyheisenberg.github.io/61.Philosophy/伊壁鸠鲁的享乐主义/","excerpt":"给美诺西斯（Menoeceus）的信中的一段话: 我们所谓的快乐是指身体无病痛，灵魂无搅扰，而不是通宵达旦的狂饮和寻欢作乐，也不是性爱，更不是在豪华的餐桌上享用山珍海味，满足口腹之欲的所谓快乐生活；快乐是一种清醒的理性，它探究我们所作一切选择的背后的根据，把可能给灵魂带来最大困扰的那些信仰抛弃（译文选自《致美诺西斯的信》）。 伊壁鸠鲁（Ἐπίκουρος，前341年—前270年）古希腊哲学家、伊壁鸠鲁学派的创始人。伊壁鸠鲁成功地发展了阿瑞斯提普斯的享乐主义，并将之与德谟克利特的原子论结合起来。他的学说的主要宗旨就是要达到不受干扰的宁静状态。 传说中该学派居于他的住房和庭院内，与外部世界完全隔绝，因此被人称为“花园哲学家”。据说在庭院的入口处有一块告示牌写着：“陌生人，你将在此过着舒适的生活。在这里享乐乃是至善之事。”","text":"给美诺西斯（Menoeceus）的信中的一段话: 我们所谓的快乐是指身体无病痛，灵魂无搅扰，而不是通宵达旦的狂饮和寻欢作乐，也不是性爱，更不是在豪华的餐桌上享用山珍海味，满足口腹之欲的所谓快乐生活；快乐是一种清醒的理性，它探究我们所作一切选择的背后的根据，把可能给灵魂带来最大困扰的那些信仰抛弃（译文选自《致美诺西斯的信》）。 伊壁鸠鲁（Ἐπίκουρος，前341年—前270年）古希腊哲学家、伊壁鸠鲁学派的创始人。伊壁鸠鲁成功地发展了阿瑞斯提普斯的享乐主义，并将之与德谟克利特的原子论结合起来。他的学说的主要宗旨就是要达到不受干扰的宁静状态。 传说中该学派居于他的住房和庭院内，与外部世界完全隔绝，因此被人称为“花园哲学家”。据说在庭院的入口处有一块告示牌写着：“陌生人，你将在此过着舒适的生活。在这里享乐乃是至善之事。” 伊壁鸠鲁的学说和苏格拉底及柏拉图最大的不同在于，前者强调远离责任和社会活动。伊壁鸠鲁认为，最大的善来自快乐，没有快乐就没有善。快乐包括肉体上的快乐，也包括精神上的快乐。而真正的快乐来自简单的生活，没有恐惧和焦虑。相较之下，追求财富、权力和名声只会带来痛苦和折磨。伊壁鸠鲁区分了动态的快乐和静态的快乐，前者是指正在满足一种欲望时产生的快乐（例如享用美食时的快乐），后者则指欲望得到满足后的平静之乐（例如饱餐一顿后的快乐），伊壁鸠鲁认为静态的快乐拥有优先的地位，它是“一种厌足状态中的麻醉般的狂喜”。伊壁鸠鲁又提出，享受平静之乐（ the peace of a tranquil mind）的障碍之一是对死亡的恐惧，且这种恐惧又被宗教信仰加剧：也就是说如果你招致神明的愤怒，你就会在来世受到严惩。但伊壁鸠鲁并不打算通过提出一种不朽的替代状态来对抗这种恐惧，而是试图解释死亡的本质。他首先提出，当我们死去时，我们对自己的死亡毫不知情，因为我们的意识（或我们的灵魂）在死亡时就不复存在。 同时，伊壁鸠鲁强调，在我们考量一个行动是否有趣时，我们必须同时考虑它所带来的副作用。在追求短暂快乐的同时，也必须考虑是否可能获得更大、更持久、更强烈的快乐。他还强调，肉体的快乐大部分是强加于我们的，而精神的快乐则可以被我们所支配，因此交朋友、欣赏艺术等也是一种乐趣。自我的欲望必须节制，平和的心境可以帮助我们忍受痛苦。伊壁鸠鲁认为当人不受任何痛苦折磨、欲望也都得到满足后，就会进入“毫无纷扰”（Ataraxia）的最高境界。 @ref: https://zh.m.wikipedia.org/zh-cn/%E4%BC%8A%E5%A3%81%E9%B8%A0%E9%B2%81","categories":[{"name":"61.Philosophy","slug":"61-Philosophy","permalink":"https://beefyheisenberg.github.io/categories/61-Philosophy/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://beefyheisenberg.github.io/tags/哲学/"},{"name":"哲学史","slug":"哲学史","permalink":"https://beefyheisenberg.github.io/tags/哲学史/"}]},{"title":"先验与后验","slug":"61.Philosophy/先验与后验","date":"2024-01-24T01:27:53.775Z","updated":"2024-01-24T01:27:53.775Z","comments":true,"path":"61.Philosophy/先验与后验/","link":"","permalink":"https://beefyheisenberg.github.io/61.Philosophy/先验与后验/","excerpt":"","text":"先验与后验先验与后验 - 维基百科，自由的百科全书 先验（a priori ；也译作 先天）在拉丁文中指“来自先前的东西”，或引申为“有经验之前”。近代西方传统中，认为先验指无需经验或先于经验获得的知识。它通常与后验知识相比较，后验指的是“有经验之后”，即”需要经验”。这一区分来自于中世纪逻辑所区分的两种论证，从原因到结果的论证称为“先验的”，而从结果到原因的论证称为“后验的”（a posteriori）。 认识论的基本问题之一是究竟是否存在任何重要的先验知识。通常来说，理性主义者相信存在先验知识，而经验主义者认为所有知识根本上源于某种经验（通常是外部经验），即便有先验知识在某种意义上也不重要。还有些经验主义者认为先验知识只是对语词意义的分析，而与世界无关。","categories":[{"name":"61.Philosophy","slug":"61-Philosophy","permalink":"https://beefyheisenberg.github.io/categories/61-Philosophy/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://beefyheisenberg.github.io/tags/哲学/"},{"name":"先验","slug":"先验","permalink":"https://beefyheisenberg.github.io/tags/先验/"}]},{"title":"什么是价值","slug":"61.Philosophy/什么是价值","date":"2024-01-24T01:27:53.767Z","updated":"2024-01-24T01:27:53.767Z","comments":true,"path":"61.Philosophy/什么是价值/","link":"","permalink":"https://beefyheisenberg.github.io/61.Philosophy/什么是价值/","excerpt":"@ref 哲学家如何理解「价值」，什么是「价值」? - 知乎 “价值”这个概念在不同的哲学分支中的含义也有所不同。这里我主要讲一下伦理学中的“价值”这一概念。简单来说，伦理学中的“价值”就是我们通常所说的“好”或者“善”（goodness）。当我们在说某件事物或某个行为是“好”的时候，我们其实就是在说它具有“价值”。 首先，根据其应用范围，价值可以分为“道德价值”（moral value）和“幸福价值”（prudential value）。1 道德价值: 道德价值主要应用于结果主义（consequentialism）。结果主义认为，一个事物的道德价值决定了我们应当如何对它进行道德评判，并以此来规范我们的行为。如果一个行为能够导致道德价值的增加，那么这个行为就是我们应该做的。相反，如果一个行为所造成的后果具有负面的道德价值，那么我们就不应当这样做。 不同的哲学家对道德价值的理解也不尽相同。比如，相对主义认为什么具有道德价值是由人或者文化所决定的；福利主义（welfarism）认为人（或动物）的幸福是唯一具有道德价值的东西；道德虚无主义（moral nihilism）认为道德价值不存在；G.E.Moore则认为道德价值存在，但是无法被精确定义。2","text":"@ref 哲学家如何理解「价值」，什么是「价值」? - 知乎 “价值”这个概念在不同的哲学分支中的含义也有所不同。这里我主要讲一下伦理学中的“价值”这一概念。简单来说，伦理学中的“价值”就是我们通常所说的“好”或者“善”（goodness）。当我们在说某件事物或某个行为是“好”的时候，我们其实就是在说它具有“价值”。 首先，根据其应用范围，价值可以分为“道德价值”（moral value）和“幸福价值”（prudential value）。1 道德价值: 道德价值主要应用于结果主义（consequentialism）。结果主义认为，一个事物的道德价值决定了我们应当如何对它进行道德评判，并以此来规范我们的行为。如果一个行为能够导致道德价值的增加，那么这个行为就是我们应该做的。相反，如果一个行为所造成的后果具有负面的道德价值，那么我们就不应当这样做。 不同的哲学家对道德价值的理解也不尽相同。比如，相对主义认为什么具有道德价值是由人或者文化所决定的；福利主义（welfarism）认为人（或动物）的幸福是唯一具有道德价值的东西；道德虚无主义（moral nihilism）认为道德价值不存在；G.E.Moore则认为道德价值存在，但是无法被精确定义。2 幸福价值: 与道德价值不同，幸福价值仅仅应用于对个体状况的讨论。如果一个事物对某个个体是好的，那么这个事物就对这个个体有着幸福价值。 关于幸福价值的理论主要有三种： 享乐主义（hedonism）：使个体快乐的东西就是对这个个体好的东西 欲望满足理论（desire stisfaction theory）：能够满足个体欲望的东西就是对这个个体好的东西 客观清单理论（objective list theory）：某些事物是具有客观的幸福价值的（比如：事业、友谊、孩子、教育、知识等）。 幸福价值并不会直接影响我们的道德判断，但是很多规范性理论（比如福利主义）会将幸福价值包含在道德价值之中，从而使幸福价值能够间接地影响我们的道德判断。比如，伦理利己主义（ethical egoism）认为道德价值就是一个人自身的幸福价值。 功利主义（utilitarianism）则认为所有具有感受能力的个体的幸福价值都是道德价值的一部分。也有一些理论认为幸福价值并不一定被道德价值所包含。比如目的论平等主义（telic egalitarianism）认为平等本身是具有道德价值的。因此即使平等会导致幸福价值的减少，我们也应当追求平等。 多元主义（pluralism）认为道德价值是由很多因素决定的，而幸福价值可能仅仅只是其中之一。 另外，我们还可以通过价值的来源将其分为“内在价值”（intrinsic value），“外在价值”（extrinsic value）或/和“工具价值”（instrumental value）。3 内在价值指的是一个事物本身所具有的价值。内在价值来源于事物的内在属性。 外在价值和工具价值则是一个事物由于和其他事物的联系而被赋予的价值。他们源于其他事物的内在价值。具体的可以参考这个回答：哲学上对内在价值（Intrinsic Value）的研究是什么样的？ 有关价值的更多的讨论可以参考： Value Theory Intrinsic vs. Extrinsic Value Well-Being 参考: 作者：王昱洲链接：https://www.zhihu.com/question/361851239/answer/945015231来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 1.“prudential value”直译为“审慎价值”。但是我感觉这个翻译并不能体现其含义，并且由于个这个概念与“幸福”（well-being）通常被放在一起理解，故译为“幸福价值”。 ↩2.Moore提出了著名的“开放问题论证”： 1. 如果X等同于“善”, 那么 “X真的是善的吗”这个问题就是无意义的. 2. “X真的是善的吗”这个问题不是无意义的。3. 因此，X不等同于“善” ↩3.“工具价值”通常被等同于“外在价值”。但是也有一些人认为存在非工具性的“外在价值”。 ↩","categories":[{"name":"61.Philosophy","slug":"61-Philosophy","permalink":"https://beefyheisenberg.github.io/categories/61-Philosophy/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://beefyheisenberg.github.io/tags/哲学/"},{"name":"价值","slug":"价值","permalink":"https://beefyheisenberg.github.io/tags/价值/"}]},{"title":"罗素《What I Have Lived For》","slug":"61.Philosophy/罗素《What I Have Lived For》","date":"2024-01-24T01:27:53.763Z","updated":"2024-01-24T01:27:53.763Z","comments":true,"path":"61.Philosophy/罗素《What I Have Lived For》/","link":"","permalink":"https://beefyheisenberg.github.io/61.Philosophy/罗素《What I Have Lived For》/","excerpt":"","text":"《我为什么而活着》是《罗素自传》的序言, 原文: What I Have Lived For Three passions, simple but overwhelmingly strong, have governed my life: the longing for love, the search for knowledge, and unbearable pity for the suffering of mankind. These passions, like great winds, have blown me hither and thither, in a wayward course, over a great ocean of anguish, reaching to the very verge of despair. I have sought love, first, because it brings ecstasy - ecstasy so great that I would often have sacrificed all the rest of life for a few hours of this joy. I have sought it, next, because it relieves loneliness–that terrible loneliness in which one shivering consciousness looks over the rim of the world into the cold unfathomable lifeless abyss. I have sought it finally, because in the union of love I have seen, in a mystic miniature, the prefiguring vision of the heaven that saints and poets have imagined. This is what I sought, and though it might seem too good for human life, this is what–at last–I have found. With equal passion I have sought knowledge. I have wished to understand the hearts of men. I have wished to know why the stars shine. And I have tried to apprehend the Pythagorean power by which number holds sway above the flux. A little of this, but not much, I have achieved. Love and knowledge, so far as they were possible, led upward toward the heavens. But always pity brought me back to earth. Echoes of cries of pain reverberate in my heart. Children in famine, victims tortured by oppressors, helpless old people a burden to their sons, and the whole world of loneliness, poverty, and pain make a mockery of what human life should be. I long to alleviate this evil, but I cannot, and I too suffer. This has been my life. I have found it worth living, and would gladly live it again if the chance were offered me. 翻译如下: 我为什么而活着 对爱情的渴望，对知识的追求，对人类苦难不可遏制的同情心，这三种纯洁但无比强烈的激情支配着我的一生。这三种激情，就像飓风一样，在深深的苦海上，肆意地把我吹来吹去，吹到濒临绝望的边缘。 我寻求爱情，首先因为爱情给我带来狂喜，它如此强烈，以致我经常愿意为了几小时的欢愉而牺牲生命中的其他一切。我寻求爱情，其次是因为爱情解除孤寂——那是一颗震颤的心，在世界的边缘，俯瞰那冰冷死寂、深不可测的深渊。我寻求爱情，最后是因为在爱情的结合中，我看到圣徒和诗人们所想象的天空景象的神秘缩影。这就是我所寻求的，虽然它对人生似乎过于美好，然而最终我还是得到了它。 我以同样的热情寻求知识，我希望了解人的心灵。我希望知道星星为什么闪闪发光，我试图理解毕达哥拉斯的思想威力，即数字支配着万物流转。这方面我获得一些成就，然而并不多。 爱情和知识，尽可能地把我引上天堂，但同情心总把我带回尘世。痛苦的呼号的回声在我心中回荡，饥饿的儿童，被压迫者折磨的受害者，被儿女视为可厌负担的无助的老人，以及充满孤寂、贫穷和痛苦的整个世界，都是对人类应有生活的嘲讽。我渴望减轻这些不幸，但是我无能为力，而且我自己也深受其害。 这就是我的一生，我觉得它值得活。如果有机会的话，我还乐意再活一次。","categories":[{"name":"61.Philosophy","slug":"61-Philosophy","permalink":"https://beefyheisenberg.github.io/categories/61-Philosophy/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://beefyheisenberg.github.io/tags/哲学/"},{"name":"存在主义","slug":"存在主义","permalink":"https://beefyheisenberg.github.io/tags/存在主义/"},{"name":"意义","slug":"意义","permalink":"https://beefyheisenberg.github.io/tags/意义/"}]},{"title":"现象学","slug":"61.Philosophy/现象学","date":"2024-01-24T01:27:53.759Z","updated":"2024-01-24T01:27:53.759Z","comments":true,"path":"61.Philosophy/现象学/","link":"","permalink":"https://beefyheisenberg.github.io/61.Philosophy/现象学/","excerpt":"现象学（英语：phenomenology，源自希腊语phainómenon，意为“显现的东西”；以及lógos，意为“研究”）是20世纪最重要的哲学流派之一，由德国哲学家胡塞尔正式创立。胡塞尔深受弗朗兹·布伦塔诺和伯纳德·波尔查诺两人的影响，认为每一表象都是某物的表象，意识也是某物的意识；同时也主张“真理自身”——即超越时空与个人之绝对、又普遍的客观存在者——的理念之存在，而提出对意识本质的研究，或描述先验的、绝对的认识之根本与法则；他称之为“现象学”。 现象学是对经验结构与意识结构的哲学性研究。作为一个哲学运动，现象学于二十世纪早期由埃德蒙德·胡塞尔创立，之后被他在德国的哥廷根大学和慕尼黑大学中的一派追随者发展壮大。在此之后现象学传播到法国、美国以及其他地区，并远超出了胡塞尔早期著作的语境。 @ref: 现象学 - 维基百科，自由的百科全书 相关书籍 胡塞尔现象学 (豆瓣)","text":"现象学（英语：phenomenology，源自希腊语phainómenon，意为“显现的东西”；以及lógos，意为“研究”）是20世纪最重要的哲学流派之一，由德国哲学家胡塞尔正式创立。胡塞尔深受弗朗兹·布伦塔诺和伯纳德·波尔查诺两人的影响，认为每一表象都是某物的表象，意识也是某物的意识；同时也主张“真理自身”——即超越时空与个人之绝对、又普遍的客观存在者——的理念之存在，而提出对意识本质的研究，或描述先验的、绝对的认识之根本与法则；他称之为“现象学”。 现象学是对经验结构与意识结构的哲学性研究。作为一个哲学运动，现象学于二十世纪早期由埃德蒙德·胡塞尔创立，之后被他在德国的哥廷根大学和慕尼黑大学中的一派追随者发展壮大。在此之后现象学传播到法国、美国以及其他地区，并远超出了胡塞尔早期著作的语境。 @ref: 现象学 - 维基百科，自由的百科全书 相关书籍 胡塞尔现象学 (豆瓣) 现象学导论 (豆瓣) 罗伯特·索科拉夫斯基，祖籍波兰，在比利时卢汶大学获得博士学位，现任美国天主教大学哲学教授。他是英美世界的著名现象学家。《斯坦福哲学百科全书》的“现象学”和“胡塞尔”条目列举了他的著作：《现象学导论》（剑桥大学出版社，2000 年）、《胡塞尔构造观念的形成》（ 海牙，尼伊霍夫出版社，1970 年）、《胡塞尔与现象学传统》（华盛顿，1988 年）。 本书作者陈述分为三个主要部分，在很大程度上结合了系统的和编年的视角。这个陈述大概遵循了胡塞尔思想的发展秩序，从早期对逻辑和意向性的分析开始，经过其成熟时期对还原和构成的先验哲学分析，到晚期对主体间性和生活世界的分析。 第一部分集中关注胡塞尔早期的意向性理论。 第二部分，说明了胡塞尔先验哲学里的主要元素。 最后也是最长的部分，转向一些胡塞尔更加具体的现象学分析。","categories":[{"name":"61.Philosophy","slug":"61-Philosophy","permalink":"https://beefyheisenberg.github.io/categories/61-Philosophy/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://beefyheisenberg.github.io/tags/哲学/"}]},{"title":"虚无主义","slug":"61.Philosophy/13.虚无主义","date":"2024-01-24T01:27:53.753Z","updated":"2024-01-24T01:27:53.753Z","comments":true,"path":"61.Philosophy/13.虚无主义/","link":"","permalink":"https://beefyheisenberg.github.io/61.Philosophy/13.虚无主义/","excerpt":"虚无主义 - 维基百科，自由的百科全书虚无主义（英语：Nihilism，源自拉丁语nihil）是一种哲学或佛学中的一系列观点，它拒绝人类存在的一般或基本方面，如客观真理、知识、道德、价值观或意义。不同的虚无主义立场持有不同的观点，即人类价值观是毫无根据的，生命没有意义，知识是不可能的，或者某些实体不存在或毫无意义。 虚无主义的学者可能认为它只是一个贴在各种不同哲学上的标签，或是一个由唯名论、怀疑主义和哲学悲观主义产生的独特历史概念，也可能来自基督教本身。当代对这一思想的理解很大程度上源于尼采的“虚无主义危机”，从中衍生出两个核心概念：更高价值的破坏和对生命肯定的反对。 在普遍使用中，该术语通常是指存在虚无主义的形式，根据这种形式，生命没有内在价值、意义或目的。虚无主义中的其他突出立场包括拒绝所有规范和伦理观点（道德虚无主义），拒绝所有社会和政治制度（政治虚无主义，英语：Political nihilism）；认为没有知识可以或确实存在的立场（认识论虚无主义，英语：Epistemological nihilism）；以及许多形而上学立场断言非抽象对象不存在（形而上学虚无主义，英语：Metaphysical nihilism）；复合对像不存在（分体虚无主义，英语：Mereological nihilism），甚至生命本身不存在。 不太正式的分类","text":"虚无主义 - 维基百科，自由的百科全书虚无主义（英语：Nihilism，源自拉丁语nihil）是一种哲学或佛学中的一系列观点，它拒绝人类存在的一般或基本方面，如客观真理、知识、道德、价值观或意义。不同的虚无主义立场持有不同的观点，即人类价值观是毫无根据的，生命没有意义，知识是不可能的，或者某些实体不存在或毫无意义。 虚无主义的学者可能认为它只是一个贴在各种不同哲学上的标签，或是一个由唯名论、怀疑主义和哲学悲观主义产生的独特历史概念，也可能来自基督教本身。当代对这一思想的理解很大程度上源于尼采的“虚无主义危机”，从中衍生出两个核心概念：更高价值的破坏和对生命肯定的反对。 在普遍使用中，该术语通常是指存在虚无主义的形式，根据这种形式，生命没有内在价值、意义或目的。虚无主义中的其他突出立场包括拒绝所有规范和伦理观点（道德虚无主义），拒绝所有社会和政治制度（政治虚无主义，英语：Political nihilism）；认为没有知识可以或确实存在的立场（认识论虚无主义，英语：Epistemological nihilism）；以及许多形而上学立场断言非抽象对象不存在（形而上学虚无主义，英语：Metaphysical nihilism）；复合对像不存在（分体虚无主义，英语：Mereological nihilism），甚至生命本身不存在。 不太正式的分类 哲学中的虚无主义：本体论虚无主义、认识论虚无主义 政治&amp;历史中的虚无主义： 否认历史的规律性，承认支流而否定主流，透过个别现象而否认本质，孤立的分析历史中的阶段错误而否定整体过程。 音乐&amp;文学中的虚无主义： 达达主义 朋克摇滚经常被认为对世界持有虚无主义和无政府主义看法。 网摘为什么《瑞克和莫蒂》里的瑞克很痛苦？ - 知乎 最容易支持虚无主义的mbti类型是什么？ - 知乎 Ti/Ni/Ne功能高度发展，Fi/Si/Se较弱的个体容易感受到虚无。总体来讲，虚无主义者中INTP、ENTP、INFJ、INTJ居多。 INFP型人格和虚无主义冲突吗？ - 知乎 从八维功能来看，INFP的第一功能Fi（内倾情感）是一个能够确立并不断加固个人价值体系，维持情感内循环“自给自足”从而无需与他人互动的功能。 Fi注重外物与“我”的联系，在探索外部世界时，会在外物与自我之间建立无数包含独特意义的情感纽带。 以下是Fi使用者面对新事物时，经常下意识思考的问题： “这件事给我带来了怎样的情绪体验？”“这一事物在我眼中是怎么样的，我会如何评价它呢？它是善是恶，是美是丑？是否能够被我内心的价值标准所接受呢？” 而这与虚无主义者惯常的思维模式有着较大差别。多数虚无主义者以Ti（内倾思考）为主导功能，力求以绝对旁观者的视角看待事物，以至于进入一种无我的状态。Ti又被称为溯源逻辑，擅长追本溯源，解剖出事物背后的一切逻辑节点并加以分析，最后得出一个精炼的普适性的模型。许多Ti使用者之所以会陷入虚无，正是因为Ti将一切事物都解构了，使得他们看清了许多真相——个人的存在有多么渺小；社会是如何不受人为控制而运作；道德和意义感不过是人虚构其上的产物；以及一个终将到来的万物寂灭的结局。发展到极端的Ti，便是一个如此反生物性的功能。它蔑视常人那套浮于表面的感知视角，不去看树在地面之上的那一部分，而是拼命挖掘出盘虬错节的树根，扔到主人面前说“这才是本质”。于是，它的主人只能一直凝视着那些丑陋可怖的树根，无法像常人那样再去欣赏树的美丽，这彻底摧毁了他们作为一个人的感知，让他们从此堕入虚无的深渊。 論INTJ的思維方式 - GetIt01 INFJ的虛無主義。INFJ的思維方式是從一個肯定命題推導另一個肯定命題，這種思維方式可以依據結論再次推導肯定命題，甚至可以依據新的結論再次推導肯定命題。然而，這種推導是無限的，INFJ不知道最後的結論是什麼，這導致INFJ常思考生活的最終意義卻找不到真正的結論。INFJ的虛無主義正是由於無法確認行為的最終意義的無意義感。INTJ的循環論也源於這種思維方式。如果未知的否定命題等同於另外一個肯定命題，那麼在形式上這種思維方式轉化為一個肯定的命題推導另一個肯定的命題（當然，真正運用這種思維方式的人格是INFJ人格，INTJ只是表明上運用），例如，大導致小，生導致死。這類命題可以結合為循環命題，例如大導致小，小導致大，生導致死，死導致生。道教的陰陽相生是典型的INTJ的話語。黑格爾認為哲學最終是一個圓圈，最原初的概念可通過不斷推導回到自身，這是典型的INTJ循環論。 从四个层次谈虚无主义和存在主义的区别 - 知乎 存在主义和虚无主义最大的区别在哪里？ - 知乎 寻找人生意义不要落入虚无的陷阱–理论-人民网 人生的意义，其实就是寻找、发现、创造、体现并传递意义。换句话说，人生本来是没有所谓先天定义的意义的。如果有，那只能说有生物进化上的意义，那就是物种的生存和繁殖。而人，不仅仅是生物的个体，更是社会，文化和精神的个体，我们肯定会有高于动物本性的智慧和理性，因此， 作为一个有积极人性的人，我们其实是用一生证明了自己的存在不是一种偶然；我们的一生也不是平淡无奇的等待死亡的过程。它一定要有特殊的属于我们自己的意义和价值的。 …… 如何让我们的年轻人在此时此刻找到人生的意义呢？我个人觉得，一个很重要同时又很简单的积极心理学的方法就是：让自己经常想一想， 我们在哪些时候、哪些地方，做哪些事情，会让我们产生旺盛的生命力的感觉，有什么值得我们感动，有什么事情值得我们留恋，什么事情让我们喜悦，什么事情让我们安定，什么事情让我们感兴趣，什么事情给我们希望，什么事情让我们敬仰，什么事情让我们热爱。凡是让我们能够体验到人世间最美好的积极心理体验的事情，都会让我们意识到生活的意义。因为，感情就是人生的意义之一。 除了积极的情绪体验之外，著名华裔心理学家王载宝还提出来我们可以在自己的成就、社会的接纳和尊严、精神和文化生活、亲情和友情、宗教体验、社会服务和贡献，以及幸福的体验（如福流）中发现意义。 因此，寻找和发现人生的意义不是一种抽象概念，不是宗教或者政治的宣传，它是我们的生活，是一个困惑、艰难，而后快乐、幸福的心路历程。当我们快乐的时候，我们的心理能量更充沛，思维更开放，生活的态度更积极，因此也更容易发现生命的意义。（作者系清华大学心理学系主任） 罗素的‘人生三动力’@link","categories":[{"name":"61.Philosophy","slug":"61-Philosophy","permalink":"https://beefyheisenberg.github.io/categories/61-Philosophy/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://beefyheisenberg.github.io/tags/哲学/"},{"name":"哲学主义","slug":"哲学主义","permalink":"https://beefyheisenberg.github.io/tags/哲学主义/"},{"name":"虚无主义","slug":"虚无主义","permalink":"https://beefyheisenberg.github.io/tags/虚无主义/"}]},{"title":"实用主义","slug":"61.Philosophy/12.实用主义","date":"2024-01-24T01:27:53.748Z","updated":"2024-01-24T01:27:53.748Z","comments":true,"path":"61.Philosophy/12.实用主义/","link":"","permalink":"https://beefyheisenberg.github.io/61.Philosophy/12.实用主义/","excerpt":"实用主义（英语：pragmatism，派生于希腊词πρᾶγμα（事物、实物）），又称实验主义、试验主义，是产生于19世纪70年代的现代哲学派别，认为人类的语言和思维具有局限性，无法完全反映真实世界，应把它当作解决问题的工具。在20世纪的美国成为一种主流思潮。对法律、政治、教育、社会、宗教和艺术的研究产生了很大的影响。 实用主义的根本纲领是把确定信念作为出发点，把采取行动当作主要手段，把获得实际效果当作最高目的。 实用主义者英文原名是Pragmatism，源出希腊文πρανμα，意思即是行为、行动。 而实用主义者对行为、行动的解释，关注行动是否能带来某种实际的效果，也就是关注直接的效用、利益，有用即是真理，无用即为谬误。 主要论点实用主义的主要论点是： 强调知识是控制现实的工具，现实是可以改变的； 强调实际经验是最重要的，原则和推理是次要的； 信仰和观念是否真实在于它们是否能带来实际效果； 真理是思想的有成就的活动； 理论只是对行为结果的假定总结，是一种工具，是否有价值取决于是否能使行动成功； 人对现实的解释，完全取决于现实对他的利益有什么效果； 强调行动优于教条，经验优于僵化的原则[1]； 主张概念的意义来自其结果，真理的意义来自于应证。[2]","text":"实用主义（英语：pragmatism，派生于希腊词πρᾶγμα（事物、实物）），又称实验主义、试验主义，是产生于19世纪70年代的现代哲学派别，认为人类的语言和思维具有局限性，无法完全反映真实世界，应把它当作解决问题的工具。在20世纪的美国成为一种主流思潮。对法律、政治、教育、社会、宗教和艺术的研究产生了很大的影响。 实用主义的根本纲领是把确定信念作为出发点，把采取行动当作主要手段，把获得实际效果当作最高目的。 实用主义者英文原名是Pragmatism，源出希腊文πρανμα，意思即是行为、行动。 而实用主义者对行为、行动的解释，关注行动是否能带来某种实际的效果，也就是关注直接的效用、利益，有用即是真理，无用即为谬误。 主要论点实用主义的主要论点是： 强调知识是控制现实的工具，现实是可以改变的； 强调实际经验是最重要的，原则和推理是次要的； 信仰和观念是否真实在于它们是否能带来实际效果； 真理是思想的有成就的活动； 理论只是对行为结果的假定总结，是一种工具，是否有价值取决于是否能使行动成功； 人对现实的解释，完全取决于现实对他的利益有什么效果； 强调行动优于教条，经验优于僵化的原则[1]； 主张概念的意义来自其结果，真理的意义来自于应证。[2] 在实用主义大旗下派生的分枝有“人本主义”、“工具主义”、“逻辑经验主义”、“神奇学派”、“逻辑学派”等。实用主义最初发生在英国和美国的哲学家中，在 20 世纪初，在美国发展成一种运动，并且蔓延到欧洲大陆。现在虽然已经不再是一种运动了，但仍然是一种非常有影响的思想体系，它把哲学从一种人生观的思想体系降为一种研究问题和澄清信息的批判方法，把知识解释为一种评价过程，以科学探索的逻辑作为人们处世待物的行为准则。 经典代表作品 《民主与教育》：约翰·杜威 (John Dewey，1859—1952） 《我们是怎么思维的》：约翰·杜威 (John Dewey，1859—1952） 《君王论》：意大利文艺复兴时期作家尼可洛·马基维利的政治论著，于1513年献给洛伦佐二世·德·美第奇，但此书在马基雅弗利死后第五年的1532年才公开出版。 11.马基雅维利主义 Reference https://zh.wikipedia.org/zh-hans/%E5%AE%9E%E7%94%A8%E4%B8%BB%E4%B9%89","categories":[{"name":"61.Philosophy","slug":"61-Philosophy","permalink":"https://beefyheisenberg.github.io/categories/61-Philosophy/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://beefyheisenberg.github.io/tags/哲学/"},{"name":"哲学主义","slug":"哲学主义","permalink":"https://beefyheisenberg.github.io/tags/哲学主义/"},{"name":"实用主义","slug":"实用主义","permalink":"https://beefyheisenberg.github.io/tags/实用主义/"}]},{"title":"马基雅维利主义","slug":"61.Philosophy/11.马基雅维利主义","date":"2024-01-24T01:27:53.744Z","updated":"2024-01-24T01:27:53.744Z","comments":true,"path":"61.Philosophy/11.马基雅维利主义/","link":"","permalink":"https://beefyheisenberg.github.io/61.Philosophy/11.马基雅维利主义/","excerpt":"马基雅维利和《君主论》尼古拉·马基雅维利（NiccolòMachiavelli，1469年5月23日—1527年6月22日）意大利政治思想家和历史学家，出身于佛罗伦萨的没落贵族家庭。他是意大利文艺复兴时期的重要人物，被称为近代政治学之父，是政治哲学大师，他所著的《君主论》（又作《君王论》）一书提出了现实主义的政治理论，其中“政治无道德”的权术思想，被人称为“马基雅维利主义”。另一著作《论李维》则提及了共和主义理论。 《君主论》在此书中马基雅维利阐述了一个君主（统治者）应该采用怎样的统治手段才能保住自己的政权。书中人性本恶的部分类似中国荀子、先秦法家思想，尤其在论证“君主应该不择手段达到目的”这一命题时，和韩非子继承申不害提出的“重术”观点不谋而合。马基雅维利所假设的人性本恶也反映出他认为必须使用残忍权力才能达成实际目标的主张。君主不该对于其臣民抱有完全的信赖和信任。 《论李维》","text":"马基雅维利和《君主论》尼古拉·马基雅维利（NiccolòMachiavelli，1469年5月23日—1527年6月22日）意大利政治思想家和历史学家，出身于佛罗伦萨的没落贵族家庭。他是意大利文艺复兴时期的重要人物，被称为近代政治学之父，是政治哲学大师，他所著的《君主论》（又作《君王论》）一书提出了现实主义的政治理论，其中“政治无道德”的权术思想，被人称为“马基雅维利主义”。另一著作《论李维》则提及了共和主义理论。 《君主论》在此书中马基雅维利阐述了一个君主（统治者）应该采用怎样的统治手段才能保住自己的政权。书中人性本恶的部分类似中国荀子、先秦法家思想，尤其在论证“君主应该不择手段达到目的”这一命题时，和韩非子继承申不害提出的“重术”观点不谋而合。马基雅维利所假设的人性本恶也反映出他认为必须使用残忍权力才能达成实际目标的主张。君主不该对于其臣民抱有完全的信赖和信任。 《论李维》《论李维》是对李维《罗马史》前十卷的研析，马基雅维利总结了一系列的历史教训，描述了共和国应该如何成立、架构，涵盖了对权力制衡、政治权力分立的好处、以及共和国比君主国优秀之处。在《论李维》一书中，马基雅维利的政治哲学初露端倪，对之后法国的卢梭产生了深远的影响。在《民约论》中，卢梭就多次引用了马基维利的著作。 马基雅维利主义 马基雅维利主义的弱点是什么？ - 知乎 马基雅维利主义 - MBA智库百科 四原则马基雅维利提出的管理原理是为了使君主能成功地管理一个国家，但同样也适用于管理其它组织，对管理思想的发展有相当大的影响。 (一)群众认可。所有的政府，其持续存在都依赖于群众的支持，即权力是自下而上的，而不是自上而下的。 (二)内聚力。要使国家能持续存在，必须要有内聚力。组织内聚力的一个关键因素是使人民确信他们可以信赖自己的君主，知道君主期望于他们的是什么——责任明确性原则。 (三)领导方法。领导者（或管理者）的类型有两种：一种是自然或天生型，另一种是后天获得领导技术的类型。 (四)生存意志。任何组织的主要目标之一是使自己存在下去。","categories":[{"name":"61.Philosophy","slug":"61-Philosophy","permalink":"https://beefyheisenberg.github.io/categories/61-Philosophy/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://beefyheisenberg.github.io/tags/哲学/"},{"name":"哲学主义","slug":"哲学主义","permalink":"https://beefyheisenberg.github.io/tags/哲学主义/"},{"name":"实用主义","slug":"实用主义","permalink":"https://beefyheisenberg.github.io/tags/实用主义/"},{"name":"马基雅维利主义","slug":"马基雅维利主义","permalink":"https://beefyheisenberg.github.io/tags/马基雅维利主义/"}]},{"title":"斯多葛主义","slug":"61.Philosophy/10.斯多葛主义","date":"2024-01-24T01:27:53.739Z","updated":"2024-01-24T01:27:53.740Z","comments":true,"path":"61.Philosophy/10.斯多葛主义/","link":"","permalink":"https://beefyheisenberg.github.io/61.Philosophy/10.斯多葛主义/","excerpt":"斯多葛主义（Stoicism） 是季蒂昂的芝诺（Zeno of Citium） 于公元前3世纪早期在雅典创立的希腊化哲学流派。该流派关注个人幸福与德性伦理，借助自身的世界观与逻辑体系，它主张德行的实践是达成幸福——享受一种道德的生活——的必要且充分条件。 在现代英语中，stoic 一词常用于形容某人无视痛苦、愉悦、悲伤、快乐等情绪。这种“压抑情感或保持耐心”的用法最初于1579年作为名词使用，于1596年开始作为形容词。与另一哲学术语“伊比鸠鲁主义”不同，斯坦福哲学百科全书指出，“英文形容词 stoical 与它的原始哲学意义没有显著差别”。 斯多葛主义认为，通往幸福的路途需实践枢德，并遵循自然。斯多葛主义最著名的教诲是“美德是唯一的善”，而那些外部事物，诸如健康、财富、愉悦等，本身不存在善与恶的区分（道德中性），而是“为美德行动提供材料”。 斯多葛主义与亚里士多德伦理学一起，为德性伦理学建立了基础。斯多葛主义认为，部分恶的情绪来源于个人的错误判断，它主张人们应当保有一种“遵循自然”作出“决断”的意愿。因此，斯多葛主义评判个人哲学的标准不是依据他的言论，而是取决于他的行动。为达成一种好的生活，人应当首先理解自然状态，因为一切事物都根植于自然。 在希腊化时代及罗马帝国，斯多葛主义成为了最流行的哲学流派。罗马帝国时期，1世纪时的大臣塞内卡、出身奴隶的爱比克泰德，以及2世纪罗马皇帝马尔库斯·奥列里乌斯，都是斯多葛派的代表学者，最后者著有《沉思录》。亚历山大城的希腊文法学家迪斯科洛斯也深受斯多葛派影响。 据吉尔伯特·默里所说，当时“几乎所有亚历山大大帝后的继业者……都自称是斯多葛主义者。”","text":"斯多葛主义（Stoicism） 是季蒂昂的芝诺（Zeno of Citium） 于公元前3世纪早期在雅典创立的希腊化哲学流派。该流派关注个人幸福与德性伦理，借助自身的世界观与逻辑体系，它主张德行的实践是达成幸福——享受一种道德的生活——的必要且充分条件。 在现代英语中，stoic 一词常用于形容某人无视痛苦、愉悦、悲伤、快乐等情绪。这种“压抑情感或保持耐心”的用法最初于1579年作为名词使用，于1596年开始作为形容词。与另一哲学术语“伊比鸠鲁主义”不同，斯坦福哲学百科全书指出，“英文形容词 stoical 与它的原始哲学意义没有显著差别”。 斯多葛主义认为，通往幸福的路途需实践枢德，并遵循自然。斯多葛主义最著名的教诲是“美德是唯一的善”，而那些外部事物，诸如健康、财富、愉悦等，本身不存在善与恶的区分（道德中性），而是“为美德行动提供材料”。 斯多葛主义与亚里士多德伦理学一起，为德性伦理学建立了基础。斯多葛主义认为，部分恶的情绪来源于个人的错误判断，它主张人们应当保有一种“遵循自然”作出“决断”的意愿。因此，斯多葛主义评判个人哲学的标准不是依据他的言论，而是取决于他的行动。为达成一种好的生活，人应当首先理解自然状态，因为一切事物都根植于自然。 在希腊化时代及罗马帝国，斯多葛主义成为了最流行的哲学流派。罗马帝国时期，1世纪时的大臣塞内卡、出身奴隶的爱比克泰德，以及2世纪罗马皇帝马尔库斯·奥列里乌斯，都是斯多葛派的代表学者，最后者著有《沉思录》。亚历山大城的希腊文法学家迪斯科洛斯也深受斯多葛派影响。 据吉尔伯特·默里所说，当时“几乎所有亚历山大大帝后的继业者……都自称是斯多葛主义者。” 古代斯多葛主义常受误解，因为它使用的术语的意义在现代语境下已经有很大变化。如今，“斯多葛”一词常用于表示“无情绪”状态，或无视痛苦，因为斯多葛伦理学告诫人们摆脱“激情”控制，遵循“理智”指导。但是斯多葛主义并非要求人们完全抛弃情绪，相反，它认为人们应当有意的转变情绪，将其引向禁欲主义（askēsis），只有在这种状态下，人才可更理智的作出决断，并保持内在清醒。自律的方法是逻辑、反省和专注，自我克制被分为自控、节制和谦逊。 基本思想： 斯多葛主义为宇宙提供了单一图景，它由逻辑观念、一元论物理以及自然主义伦理学构成。斯多葛主义者强调，人类知识的发展应当以道德为先，不过后世哲学最看重的是该学派的逻辑理论。 斯多葛主义主张自控以及面对困顿情绪时的坚毅。它认为人们应当致力成为一个无偏向的思考者，只有这样才能理解宇宙的因由（逻各斯/Logos）。 斯多葛哲学拥护决定论观点。信奉斯多葛主义的人会尝试修正自己的意志，使之与世界进程相一致，并仍保留有如爱比克泰德所说的“有病然而幸福，处于危险然而幸福，临于死亡然而幸福，颠沛流离然而幸福，含诟忍辱然而幸福”，因此他也便具备了“全然的幸福”，宇宙本身就与个人意志结合为了单一的决定论整体。这种观点被描述为“古典泛神论”，并在后来由荷兰哲学家斯宾诺莎接受与发展。 斯多葛派秉持泛神主义物质一元论，反对任何形式的二元论，特别是柏拉图的二元论、精神世界和物质世界的二元对立、灵魂与身体的二元对立，甚至理性与非理性的二元对立。斯多葛派认为，宇宙是单一的神圣实体，由神、人和自然共同组成。 斯多葛派认为世界有限而时间无限，世界不断起灭，其中发生的事件，每一次都会重演重现。个体小“我”只有踏进和通过永恒的时间，才能成为内在于世界整体的一部分。斯多葛派有一格言：“依照自然而生活”，“自然”即宇宙运行的律则，受理性支配。 斯多葛主义认为理智是获取知识的唯一途径，真理可借此与谬误区分——尽管在实践中，人们往往只能接近而无法完全达成真理。感官时刻接收外部世界的刺激，这些刺激从物体转到心灵，转移途中在心灵留下的印象即是想象（也称“感觉象”）。 古代斯多葛主义常受误解，因为它使用的术语的意义在现代语境下已经有很大变化。如今，“斯多葛”一词常用于表示“无情绪”状态，或无视痛苦，因为斯多葛伦理学告诫人们摆脱“激情”控制，遵循“理智”指导。但是斯多葛主义并非要求人们完全抛弃情绪，相反，它认为人们应当有意的转变情绪，将其引向禁欲主义（askēsis），只有在这种状态下，人才可更理智的作出决断，并保持内在清醒。自律的方法是逻辑、反省和专注，自我克制被分为自控、节制和谦逊。 对斯多葛主义而言，理智意味着使用逻辑，理解自然进程，也即内在于万物的逻各斯或普遍理智。依据理智与德性，即服从宇宙的神圣秩序，认识所有人类的共同理性与本质价值。 斯多葛派主张的四种枢德（阿睿提）源自柏拉图（《理想国》第四卷）： 智慧（希腊语：φρ?νησι? 或 σοφ?α，拉丁语：prudentia 或 sapientia）勇气（希腊语：ανδρε?α，拉丁语：fortitudo）正义（希腊语：δικαιοσ?νη，拉丁语：iustitia）节制（希腊语：σωφροσ?νη，拉丁语：temperantia） @tags: #幸福 #一元论 #禁欲主义 #逻辑","categories":[{"name":"61.Philosophy","slug":"61-Philosophy","permalink":"https://beefyheisenberg.github.io/categories/61-Philosophy/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://beefyheisenberg.github.io/tags/哲学/"},{"name":"哲学主义","slug":"哲学主义","permalink":"https://beefyheisenberg.github.io/tags/哲学主义/"},{"name":"斯多葛","slug":"斯多葛","permalink":"https://beefyheisenberg.github.io/tags/斯多葛/"}]},{"title":"05b.海德格《存在与时间》","slug":"61.Philosophy/05b.海德格《存在与时间》","date":"2024-01-24T01:27:53.734Z","updated":"2024-01-24T01:27:53.734Z","comments":true,"path":"61.Philosophy/05b.海德格《存在与时间》/","link":"","permalink":"https://beefyheisenberg.github.io/61.Philosophy/05b.海德格《存在与时间》/","excerpt":"存在与时间 (豆瓣) 存在与时间（2006 陈嘉映 / 王庆节 合译） - 原文摘录 此在的非本真状态并不意味着‘较少’存在或‘较低’存在。非本真状态反而可以是按照此在最充分的具体化情况而在此在的忙碌、激动、兴致、嗜好中规定此在。 @todo 待整理 “此在”的三层空间","text":"存在与时间 (豆瓣) 存在与时间（2006 陈嘉映 / 王庆节 合译） - 原文摘录 此在的非本真状态并不意味着‘较少’存在或‘较低’存在。非本真状态反而可以是按照此在最充分的具体化情况而在此在的忙碌、激动、兴致、嗜好中规定此在。 @todo 待整理 “此在”的三层空间摘自《一个等待与无用的民族：庄子与海德格尔的第二次转向》/第一章/1.2：《存在与时间》：在被抛与筹划之间 // 海德格的“三层空间”：// - 被抛的处境：沉沦、或以操持与烦生存于世// - 向着未来筹划：离开常人的沉沦// - 决断的到时：向死而在 《存在与时间》确立了这一系列新哲学话语的起点以及基本的结构—— 一个三层的基本“范型”。《存在与时间》也有一个基本的出发点：即只有“此在”（Dasein）追问存在本身的意义，其他存在者只是追问 存在者的存在者性或者存在者的整体，从而遗忘了存在本身，传统形而上学就是如此。只有“此在”通过生存的出离，去追问存在的意义，才能打开之间的场域。// ‘场域’指三层之间的空间，打开场域才能将周围-共在-自身区分开来 1.221.第一层是“被抛的处境”：人类被抛在一个三重世界之中，这是区分为“周围-共在-自身（um-mit-selbst-Welt）”的三重世界。“此在”被抛于世，因此可以从现象学区域本体论的方式区分为：周围世界——共在世界——自身世界。“此在”以 操心与烦1 的情调生存于世：周围世界是与自然生活环境相关的现存生活世界；共在世界主要是一些明确打交道的他人；自身世界则是“此在”追问存在而与其他存在者区分开来，尤其与常人区分开来。无论是烦神，还是烦忙，“此在”总是从被抛的世界中开始自身筹划。—— 在这个日常生活世界中，“此在”的生存出离拉开了与常人的距离，这是存在者的生存论差异所打开的间距或“之间”。 1.222.第二层是“筹划的敞开”：“此在”的自身理解与筹划，摆脱沉沦状态（某个主体的“自身理解”——“筹划”——“意义展开”——针对的则是“沉沦”状态，甚至是敌对状态）。“此在”要从常人状态区分开来，必须以“烦”为基本情调去进行主动的筹划2，这就是“此在”的意义理解与解释，建构一个本己的意义世界，这个阶段以“用具”（Zeug）的“使用”(Gebrauch)为生存论操作的重心，通过区分开生存论的“上手状态”（Zuhandenheit）与现存的“手前状态”，以现象学解释学的“作为”结构建构一个意义关联的世界（以解释学方式补充胡塞尔现象学noesis-noema的意向对象与意向活动），并且继续展开“烦”（或操心）的意义结构，才可能避免常人的沉沦（verfallen）[3]。“此在”的意义理解通过不同的言谈或沉默的倾听，或者携带朋友的声音，与常人相区分，并向着未来筹划。而不与之一道筹划的他者则成为对手或敌人，成为对峙或争辩的一方。—— 把这个筹划所赋予的意义世界与常人并不筹划的沉沦世界区分开来，形成存在论的差异或“间域”，它有待于敞开，并不现存地存在着，它来自于“此在”的生存筹划，才可能与常人的世界彻底区分开来，这需要斗争，需要争执，才可能打开此间域，让上升的继续上升，让沉沦的彻底沉沦，甚至被灭绝。 1.223.第三层是“决断的到时”：“此在”的生存筹划尽管敞开了空间，但要保持持续的敞开，要彻底与常人区分开来，形成决定性的事件，则必须决断，才可能实现自身的自身性，这是“时间性的到时”与“边缘域的构成与敞开”。“此在”向着未来筹划，必须进入更为彻底的出离状态，这是“此在”倾听良知召唤的无声之音，而产生“畏”的情调，通过“向死而在”4的先行，因为只有“死”才是“最为本己的、无所旁涉的、不可超越的、确知的、然而又是不确定的可能性[1]”（SZ: 309/367），甚至是“不可能的可能性”。“此在”才成为本己的，才获得时间性的有限性规定，但这又并非生物学的死亡与死去，反而更为靠近基督教良机的发生。而这个等待与倾听，只有通过决心，才可能保持敞开，只有在决断中形成边缘域，这就形成了“此在”的意义，即时间性。 1.23.海德格尔的哲学由此确立哲学话语的生成模式，从《存在与时间》开始，海德格尔区分开“此在”（Dasein）与“常人”，常人是注定沉沦的，只有“此在”才会去追问存在的意义而出离自身，摆脱“人性”，成为生存者，在倾听良知召唤中，向死而在，而获得“本真”（Authentic）5或本己的自身性，即获得时间性，建构起自身世界的视域。不断进入“被抛”的状态，再通过某个主体生存出离的决断，向着存在去理解与“筹划”，这构成海德格尔最为基本的哲学动作，并且打开“之间”的地带。由此形成了海德格尔最为基本的思考框架：一方面，“此在”必须不断深入被抛处境（Geworfenheit），越是深入被抛的处境，进入更深的深渊，越是抵达世界的深处，越是经验到实际性的处境；另一方面，也就越是需要去筹划或开抛（Entwurf），向着更高的高处筹划，不断筹划，更为敞开。这个被抛与敞开的张力，不断打开“之间”的场域，就是“此在”生存的新世界。存在论差异之为差异：就在于不断打开这个间域，而非陷入静止停顿之中。 本真（Authentic） @link: 05a.此在的本真-海德格的存在主义 https://www.sohu.com/a/200698036_227314 @tag: #存在主义 #海德格 1.烦： 在《存在与时间》里，人的行为举止分成三个方面：和形形色色的事物打交道，和他人打交道，和自己打交道。这三个方面，分别用Besorgen，Fuersorge，Sorge来标识。Sorge一词具有忧虑担心和操持置办两重主要的含义。Besorgen也有忧虑担心和操持置办两重主要的含义，只不过Sorge更突出忧虑而Besorgen更突出置办，因为后者主要具动词性而且有个及物的词头be。Fuersorge既然以Sorge为词根，难免有Sorge的意味，不过通用的含义主要是照顾、帮助、救济。这三个词，熊伟先生分别译作烦、烦心、麻烦。我分别译作烦、烦忙、烦神。 by 陈嘉映 ↩2.筹划： 海德格尔在《哲学论稿》中使用了以werfen为词根的一组词语，主要包括entwerfen，loswerfen，Entwurf，Entwerfer，Entworfenes，Werfer，Wurf，Gegenwurf，Loswurf，Geworfenheit等。这些词语按说都有“抛”(werfen)这个词根，但英译者却作了一个区分： Entwurf 翻译作 projecting-open（筹划性开启） ，entwerfen 翻译作 to project-open（筹划） ；除这两者之外，上述其他带有werfen的词语则统统以英文throw和throwing译之，也即以“抛”译之。我原先比较赞同英译者的这种做法，稍作修正，把动词entwerfen和名词Entwurf译为“筹划”(或“筹划性开启”)，因为正如英译者指出的，这两者指的是一种为存有所居有的开启和揭示行为；其他诸词则以“抛”为字根译之。 by 孙周兴 ↩3.沉沦（verfallen）： “沉沦”一词听起来带有否定的意义，但在海德格尔自己看来，以“常人”标识日常存在的此在，并且以“沉沦”标识日常此在的基本存在方式，并没有直接的伦理学意义。所谓“沉沦”并不带有任何消极的评价，而是意味着：此在首先且通常总是寓于它所烦忙的世界，多半消失在常人的公众意见中。“此在首先总是已经从它自身脱落、即从本真的能自己存在脱落而沉沦于‘世界’。共处是靠闲谈、好奇和两可来引导的，而沉沦于‘世界’就意指消散在这种共处中”。（海德格尔，1999年，第204页） by 孙周兴 ↩4.“向死而在”或“向死而生”： 德文Das Sein zum Tode，英文Being towards death ↩5.本真： 本真（Authenticity），或译真诚性。真诚性（authenticity）连通著个人的未来和过去，使自我具有连续性。它还要求在这种关系上接受自己的死亡。 ↩","categories":[{"name":"61.Philosophy","slug":"61-Philosophy","permalink":"https://beefyheisenberg.github.io/categories/61-Philosophy/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://beefyheisenberg.github.io/tags/哲学/"},{"name":"存在主义","slug":"存在主义","permalink":"https://beefyheisenberg.github.io/tags/存在主义/"},{"name":"海德格","slug":"海德格","permalink":"https://beefyheisenberg.github.io/tags/海德格/"}]},{"title":"05a.此在的本真-海德格的存在主义","slug":"61.Philosophy/05a.此在的本真-海德格的存在主义","date":"2024-01-24T01:27:53.729Z","updated":"2024-01-24T01:27:53.729Z","comments":true,"path":"61.Philosophy/05a.此在的本真-海德格的存在主义/","link":"","permalink":"https://beefyheisenberg.github.io/61.Philosophy/05a.此在的本真-海德格的存在主义/","excerpt":"此在的本真-海德格的存在主义 海德格尔的『此在』在德语里翻译成“Dasein”，在黑格尔体系里，“Dasein”意指“定在”或“有限存在”，物质世界或具体历史的有限性对应真理总体的无限性。“Da”表示“在此之中”，“此”表示“这里”。 海德格把『此在』关切自身的存在 称为牵挂（care），牵挂也是『此在』与世界的基本关联，也是『此在』在“这个世界”获得意义的基础。 牵挂由：生存（唯物的“存在”），实际性(存在于在……之中)，沉沦(存在于……状态里)，以及言谈组成。 沉沦（非指消极状态，也非道德上的堕落）的日常体现：闲谈，好奇，两可。","text":"此在的本真-海德格的存在主义 海德格尔的『此在』在德语里翻译成“Dasein”，在黑格尔体系里，“Dasein”意指“定在”或“有限存在”，物质世界或具体历史的有限性对应真理总体的无限性。“Da”表示“在此之中”，“此”表示“这里”。 海德格把『此在』关切自身的存在 称为牵挂（care），牵挂也是『此在』与世界的基本关联，也是『此在』在“这个世界”获得意义的基础。 牵挂由：生存（唯物的“存在”），实际性(存在于在……之中)，沉沦(存在于……状态里)，以及言谈组成。 沉沦（非指消极状态，也非道德上的堕落）的日常体现：闲谈，好奇，两可。 闲谈：本质是诉说的快感，不为真实性和合理性负责，不必经过自我验证好奇：这里不是指求知欲，而是放纵自己于世界，寻求不安和激动。不操持于所及的世界，而是涣散在新的可能性中两可：在“共在”的状况下，处在一种随从、不做决断的状态 这三种日常方式被称为“此在的沉沦”，但它们不是消极的，而是『此在』从“本真”状态脱离，而消失于常人的公共意见中（常人：自身之外的大众） 那么此在的“本真”又是一种什么状态呢？本真(Authentic)是此在的一种生活状态：『此在』在面对一个孤独的局面时采取决断的态度，并且敢于承担自己的唯一性和个体性，那么可以说，此在进取了本真(Authentic)的状态。并且此在意识到这个状态的存在。 海德格尔指出，「常人」表明为公众意见的“平均状态”。作为常人被从他的本真的可能性的筹划中拉离出来，陷入到 非本真存在的无根基状态之中。决心面对死亡之畏把此在从消散于世界的沉沦中唤回到他的最本真的能在。常人和本真性是海德格尔的两个核心概念， 海德格尔认为，当人与自己的死亡遭遇时，真实的属己的自我才会显露出来。死亡是对现实世界的否定，当人面对死亡时，才会停止对外界的忧虑和担心，从牵挂中脱离开来，从外界中孤立出自己，成为“真正的存在”。 [[../62.Psychology/《存在主义心理治疗》读书笔记]] /第三部《孤独》： 海德格用“不自在”来指代人失去了在世界中的熟悉感的状态，当人完全专注于表象世界，对自己的存在处境失去接触时，海德格称这个人处于“日常”或者“陷入”的模式里。 海德格的“畏”在存在主义哲学中，”畏”有特殊的概念性意义。最初使用这个词的是丹麦哲学家索伦·克尔凯郭尔。在作品《焦虑的概念》中，克尔凯郭尔使用”畏”来指代一种深层的情绪。他认为，除了人类以外的动物，它们的行为只被本能所引导，只有人类得以享受基于自由的选择，但也因此而感到恐惧。当考虑到前方未知的可能性，以及因选择而将要背负的无形义务，人们就会感到焦虑。 后世哲学家，例如弗里德里希·尼采、让-保罗·萨特、马丁·海德格尔等人继承了克尔凯郭尔的”畏”的概念。他们对这个概念进行了自主的延伸。克尔凯郭尔对于”畏”的理解更多是出于一种关于宗教的个人情感，而其他哲学家则寻求在个人原则、文化传统以及存在的绝望等方面进行自己的探索。 海德格尔的存在主义哲学认为，”此在的生存论意义就是畏”，”此在就是畏”，”此在的存在结构就是畏” 。畏的是”存在自身”，畏的是随时都可能来临，而又无法回避的”死”，”为死而存在就是畏” 。他认为存在是死亡的开始，而死亡是存在的终结，当人真正认清了此在的这个实质时，他就不会终日惶惶于死亡，就能视死如归，从畏转向大无畏。 =&gt; 05.存在主义","categories":[{"name":"61.Philosophy","slug":"61-Philosophy","permalink":"https://beefyheisenberg.github.io/categories/61-Philosophy/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://beefyheisenberg.github.io/tags/哲学/"},{"name":"存在主义","slug":"存在主义","permalink":"https://beefyheisenberg.github.io/tags/存在主义/"},{"name":"海德格","slug":"海德格","permalink":"https://beefyheisenberg.github.io/tags/海德格/"}]},{"title":"05.存在主义Index","slug":"61.Philosophy/05.存在主义","date":"2024-01-24T01:27:53.724Z","updated":"2024-01-24T01:27:53.725Z","comments":true,"path":"61.Philosophy/05.存在主义/","link":"","permalink":"https://beefyheisenberg.github.io/61.Philosophy/05.存在主义/","excerpt":"存在主义 存在主义的产生，有着强烈的时代背景。当时，两次世界大战使人的生存受到威胁，使人的尊严在战争中被践踏，而战后的经济萧条和各种社会问题又加深了人们心理上的阴影，形成了普遍的生存危机感。战后科技对社会生活的渗透，又使人们受到机械的控制和管理，人被平均化、整体化，个人的独立性和自主创造性被泯灭，“被异化了”成为人们的共同感觉。所有这一切，都已经不能用传统社会进步和人生观来说明和解释了。失去了生存的精神支柱而感到空虚和惶惑不安的人们，需要重新思考生存的目的和意义。为此，存在主义产生并发展起来。 存在主义（英语：existentialism），是一个哲学的非理性主义思潮，它认为人存在的意义是无法经由理性思考而得到答案的，以强调个人、独立自主和主观经验。尼采和克尔凯郭尔可被看作其先驱。在20世纪中它流传非常广泛，其哲学思想还延续到了60年代兴起的人本主义。雅斯贝尔斯和海德格尔、保罗·萨特和加缪是其代表人物。 其最突出的命题是：世界没有终极的目标；人们发现自己处于一个隐隐约约而有敌意的世界中；世界让人痛苦；人们选择而且无法避免选择他们的品格、目标和观点；不选择就是一种选择，即是选择了“不选择”；世界和我们的处境的真相最清楚地反映在茫然的心理不安或恐惧的瞬间。 参考: 存在主义 - 维基百科，自由的百科全书","text":"存在主义 存在主义的产生，有着强烈的时代背景。当时，两次世界大战使人的生存受到威胁，使人的尊严在战争中被践踏，而战后的经济萧条和各种社会问题又加深了人们心理上的阴影，形成了普遍的生存危机感。战后科技对社会生活的渗透，又使人们受到机械的控制和管理，人被平均化、整体化，个人的独立性和自主创造性被泯灭，“被异化了”成为人们的共同感觉。所有这一切，都已经不能用传统社会进步和人生观来说明和解释了。失去了生存的精神支柱而感到空虚和惶惑不安的人们，需要重新思考生存的目的和意义。为此，存在主义产生并发展起来。 存在主义（英语：existentialism），是一个哲学的非理性主义思潮，它认为人存在的意义是无法经由理性思考而得到答案的，以强调个人、独立自主和主观经验。尼采和克尔凯郭尔可被看作其先驱。在20世纪中它流传非常广泛，其哲学思想还延续到了60年代兴起的人本主义。雅斯贝尔斯和海德格尔、保罗·萨特和加缪是其代表人物。 其最突出的命题是：世界没有终极的目标；人们发现自己处于一个隐隐约约而有敌意的世界中；世界让人痛苦；人们选择而且无法避免选择他们的品格、目标和观点；不选择就是一种选择，即是选择了“不选择”；世界和我们的处境的真相最清楚地反映在茫然的心理不安或恐惧的瞬间。 参考: 存在主义 - 维基百科，自由的百科全书 用牛津的存在主义指南的归纳，存在主义有以下五种主题： 存在先于本质：你是你的选择的结果。// 把存在（你遇到的事情，你对事情的观点，你做的决定）视为比本质（客观存在的事实或者物质）更重要的存在 时间就是生命本质 （time is of the essence）：时间并不能被测量，个体不同的体验，时间并不相同。 人本主义：以人为本，寻找生活的意义，反抗非人性的异化。 自由/与责任：你的个体选择，不能被任何道德标准所框住，你的选择创造了你。但你对你的自由负有责任。 伦理思考是终极命题（ethical considerations are paramount）：每个大家都有自己的理论，但是总体理论是探寻我们个体与社会的伦理真谛。 参考自：什么是存在主义？存在主义的起源及社会背景是什么样的？ - 知乎 概念存在先于本质其最著名和最明确的倡议是让-保罗·萨特的格言：存在先于本质（法语：l’existence précède l’essence）： 人的存在则表现为种种可能性，经领会、筹划、选择获得本身的规定性，所以他是存在先于本质。萨特在《存在主义是一种人道主义》等著作中对此作了详尽阐述，断言不存在设定人性范本的上帝，也不存在古典哲学倡导的普遍人性人的生存状态展现出来的是，首先有人，人遭逢自己，在世界中涌现出来，然后才给自己下定义。开始人一无所有，只在后来他才成为某种东西。他不仅是自己设想的人，而且是他志愿成为的人。人们无法以固定的现成的人性说明人的行动，人获得本质的过程不外是自我设计、自我造就的过程，人就是他一系列行动的总和，他实现自己有多少，他就有多少存在。该原则意味着主观性和自由是研究人的存在的出发点，强调个人在世界上的独特地位及自决能力。 荒谬荒谬这个概念是指世界本身没有意义，只有我们赋予它的意义。这无意义性还涵盖着世界的是非不分与不公平。这与“坏事不会发生在好人身上”的概念相左；对世界而言，打个比方说，没有所谓的好人或坏人；发生的事就这样发生了，它可能降临在任何“好”人或“坏”人身上。 因为世界是荒谬的，任何时候任何事可能发生在任何人身上，而一件坏事就能迫使人直接面对荒谬。荒谬这概念一直以来都在文学上相当突出。克尔凯郭尔、贝克特、卡夫卡、陀思妥耶夫斯基、尤内斯库、乌纳穆诺、皮蓝德罗、萨特、海勒和加缪的许多文学作品都在描述人遭遇到世界的荒谬。 在痛苦地察觉到此无意义后，加缪在《薛西弗斯的神话》中称“真正严肃的哲学问题只有一个，就是自杀。”虽然针对这类可能极度有害遭遇的“药方”各自不同，不论是克尔凯郭尔的宗教“阶段”或加缪的坚持不懈，大多数存在主义哲学家的焦点都在帮助人们避开不好的生活方式，以免置于丧失一切意义的长期险境之中。这种意义崩解的可能性会对自身平静构成重要威胁，而这也就违背存在主义的哲学。[12]据信因自杀是可能的而使得所有人都是存在主义者。 海格德尔简介海德格尔指出西方哲学自从柏拉图便误解存在的意思，去研究个别存在的问题而不去研究存在本身的问题。换句话说，海德格尔不相信所有对存在的探讨焦点放在个别存在物／实体及其性质。对于海德格尔来说，一个对存在更可信的分析是查探已经了解的存在物的基础或者促成存在物如实体展现的背后基础。[1] 但是自从哲学家都忽略了这个更基本理论前期的存在，并且以此推导其他理论，错把那些理论在各处应用，终于混淆我们对存在及人类存在的理解。为免这些深层误解，海德格尔相信哲学的探求应该新方式来进行，重踏哲学历史足迹，一步一步出发。 二十世纪三十年代中期起，海德格尔 开始了对西方哲学史的系统性的阐释。他从现象学的、解释学的、存在论的角度研究了一些重要哲学家的著作，并且试图将这些著作未被思考过的前提和偏见展示出来。根据海德格尔的说法, 所有至今的哲学蓝图，都是对世界的 单向度的理解，这种单向度，他认为是所有形而上学的标志。 按照海德格尔的观点，这种形而上学的 对世界的理解, 在现代“技术”中达到了顶峰。“技术”这个概念，他不仅理解成一种中性的用来达到目的的手段，而且他试图去展示：通过技术，我们对世界的理解也发生了变化。 根据他的观点，由于技术，我们从实用的角度，去看待地球。由于技术的全球性传播，和毫无节制的对自然资源的利用，海德格尔在技术中看到了一种不可抗拒的危险。 他把艺术看成是技术的对立面，并且从三十年代末开始，他根据荷尔德林的诗，领会到了对于单纯的技术性的世界关联方式的替代方式。 海德格尔曾尝试引领哲学家脱离形而上学及知识论的问题而朝向本体论的问题。这就是存在的意义。 马丁·海德格尔 - 维基百科，自由的百科全书 哲学此在海德格尔的“此在”在德语里翻译成“Dasein”，在黑格尔体系里，“Dasein”意指“定在”或“有限存在”，物质世界或具体历史的有限性对应真理总体的无限性。“Da”表示“在此之中”，“此”表示“这里” 此在的牵挂牵挂（Care）是一种状态，是“此在”（Dasein）关切它本身的存在。因为“此在（Dasein）”的本性 在于它的生存（existence），也就是实现它的可能性。对任何从当前现实，朝向未来状况的变动，都必会产生这样的问题——“ 我将做什么？”这就是牵挂（Care）。牵挂（Care）植根于“此在”选择（Choice）它的存在的能力之中。牵挂（Care）被视为“此在”（Dasein）与世界之间的基本关联，并且是“此在”这个世界中获得意义的基础。它是“此在”所有经验的基本状态。由于所有的选择（Choice）都在世界中作出，牵挂就成为“在此世界中存在”的“此在”之存在的特性。牵挂由生存（先于自身存在）、实际性（已经存在于……之中）、沉沦（存在于……状态里）和言谈组成，并且将“此在”（Dasein）显示于其整体之中。 生存（先于自身存在） 实际性（已经存在于……之中） 沉沦（存在于……状态里） 言谈 它与时间性，即人类生活的时间结构息息相通。《存在与时间》中的“此在与时间性”部分就试图将时间性（Temporality）揭示为牵挂的所有要素的根基。 此在的本真和沉沦【此在】有两种生存状态，本真的和非本真的。 本真，“真诚的”（authentic）生存状态，如果此在（它、他或她）在面对这么一个孤独局面时采取决断的态度，并且敢于承担自己的唯一性和个体性，那么此在可说是进入了“真诚的”（authentic）生存状态，并意识到这个状态的含义。真诚性（authenticity）连通著个人的未来和过去，使自我具有连续性。它还要求在这种关系上接受自己的死亡。海德格尔认为，当人与自己的死亡遭遇时，真实的属己的自我才会显露出来。在真正属已状态中，“我”总是居先的，尽管这个“我”并不等同于一个传统哲学意义上的主体。 非本真，“不真诚的”（inauthenticity）状态，如果一个人被畏惧压倒，通过没入于众人或匿名的“人们”[They，das Man]来保护自己，正如人们通常所做的那様，这就是此在的非本真状态。在“不真诚的”（inauthenticity）状态中，“人们”（They）居先，人失去了自己的存有意义。这种态度或姿态就是 海德格尔所说的此有的“沉沦”[fallingness，Verfallen]，即此有避开自身，让自身沉沦于日常的一般性事务中，与俗世共浮沉。// 沉沦状态指的是一个人失去自我独立思考能力，把自我本身归入到群体中，用群体思维来思考问题的状态。 海德格尔所说的人人/人们/庸众（they），是指此有（Dasein）在日常生活中的存在方式，它的特征是：在意差距，屈从别人（subservient），要求平均（averageness）和压平自己（levelling down oneself）。 在这种存在方式下，此有无须承担自己的存有，因而让它无法得到本真的存在（being authentic），真正切已状态；也无法了解自己的存有。 沉沦的体现【沉沦】的体现有：闲谈、好奇、两可（海德格的“沉沦”并不是一种消极的评价，也不是指此在道德上的堕落） 1闲谈：闲谈的本质是相互言说的快感,不为真实性合理性 负责。不经过自我考证。2好奇：这里不是指为了有所知,而是为了放纵自己于世界,寻求不安和激动.不逗留于操心所及的周围世界,涣散在新的可能性中。// 八卦，新闻，看热闹3两可：指在共在状况下,此在处于一种不知不觉的虚伪，随从，无决断的状态。“这种两可总是把它所寻求的东西传递给好奇，并给闲言披上一种假象，仿佛在闲言中万事俱已决断好了。” 这三种日常方式被称为”沉沦”,但它们不是消极的.这是此在从本真脱落而消失于常人的公共意见中,与杂然共在.即非本真的状态.这种状态是有诱惑力和安定作用的,可以减少独自探索的痛苦和承担责任。在这种沉沦状态中，常人失去了能够为自己行为负责的个体性，成为异己力量的附庸。 为何沉沦在海德格尔看来，畏和“怕”不同。因为怕有确定的对象。或者怕某物，或者怕某人，总之是担心某一对象会给自己造成某种伤害。“怕”所表现的只是此在特定情况下的“当下状态”，而不是此在的“在本身”。畏与怕不同的是，不知道畏什么，“畏之所畏说明的是：进行威胁者什么也不是……但‘什么也不是’并不意味着无”。 而沉沦给了解脱畏的一种方式,当此在处于共在的状况下,闲谈,好奇,两可都能摆脱畏. 此在的死亡海德格尔指出，死亡是对现实世界生活的否定。当人面对死亡时，才会停止对世界的忧虑和担心，从陷落中孤立出自己，成为真正的存在。死亡是属于个人的事，他人无法替代，衹能靠你自己体验死亡。死亡是任何时候都可能发生的，人在什么时候死亡，都是合理的，没有规定你该活多久。人应随时准备死亡。因此, 海德格尔指出，人必须正视死亡，从恐惧中明白自己活着的重要性。为自己计划未来时，必须包括死亡。人不该衹接受生命，而拒绝接受死亡。 向死而生向死而生 (Being-towards-death)，意思是当人意识到自己终将一死时，就会深刻反思自己生命的意义。海德格称每个此在皆有死亡的可能性，生命的经验将在那一刻完全终结。当人意识到那一刻终将来临，就会反思自己整个人生规划。 著作《存在与时间》1927 存在与时间 - 维基百科，自由的百科全书 加缪 简介阿尔贝·加缪（Albert Camus，1913年11月7日—1960年1月4日），法国作家、哲学家，存在主义文学、“荒诞哲学”的代表人物。主要作品有《局外人》、《鼠疫》等。 加缪于1957年获得诺贝尔文学奖，他在20世纪50年代以前，一直被看作是存在主义者，尽管他自己多次否认。 1943年4月，加缪结识了萨特（让-保罗·萨特）和波伏娃，在哲学和戏剧等方面的共同爱好使他们成了非常亲密的朋友。然而萨特倾向于共产党和马克思主义，而加缪则对苏联社会有着比较清醒的认识。 1951年加缪发表了哲学论文《反抗者》之后，遭到了左派知识分子阵营的攻击，并引起一场与萨特等人长达一年之久的论战，最后与萨特决裂。这时人们才发现，加缪是荒诞哲学及其文学的代表人物。 加缪在他的小说、戏剧、随笔和论著中，深刻地揭示出人在异己的世界中的孤独、个人与自身的日益异化，以及罪恶和死亡的不可避免。但他在揭示出世界的荒诞的同时却并不绝望和颓丧，他主张要在荒诞中奋起反抗，在绝望中坚持真理和正义，他为世人指出了一条基督教和马克思主义以外的自由人道主义道路。他直面惨淡人生的勇气，他“知其不可而为之”的大无畏精神，使他在第二次世界大战之后不仅在法国，而且在欧洲并最终在全世界，成为他那一代人的代言人和下一代人的精神导师。 “荒诞” 是他强调的最重要的一个概念。“荒诞”这个概念也是20世纪文学和哲学中非常重要的关键词之一。但是，对“荒诞”的解释则大为不同，各人有各人的表述。加缪是这么说的：这个世界是不合理的，这是人们可以明确说出的表述。但是，荒诞是这一不合理性与人的心灵深处所呼唤的对理性的强烈要求的对立。听上去，他的这句解释特别的拗口和费解，其实，他理解的人生荒诞感，是人对世界的主观感受。加缪认为，人在面对艰难而机械的现实生存的时候，每天都要按照一个节奏和生活模式来生存，必然要产生出我为什么要这么生活，我为什么不能以其它方式生活的荒诞感，可是，偏偏人就不能以其它方式生活，人还必须要以人现在的方式生活。” 于是，这就产生了荒诞感。 主要思想人道主义加缪思想的核心是人道主义，人的尊严问题，一直缠绕着他的创作、生活和政治斗争的根本问题。《薛西弗斯神话》和《局外人》构成了加缪文学创作的母题，包含着加缪未来作品的核心问题。书中，薛西弗斯（又译：西叙福斯、西西弗斯）的幸福假设的提出，其本质动机，不在荒诞，因为荒诞不能告诉我们何谓幸福及不幸；之所以加缪假设薛西弗斯是幸福的，是因为他认为只有幸福的生活才符合人的尊严。 反抗才能体现尊严。薛西弗斯被责为永罚，却幸福，这绝对是一种反抗，也是在这种条件下唯一可能的反抗形式。加缪在假设薛西弗斯幸福的时候，充分运用了想象和独断，其潜台词，却是人类尊严的需要。 二元对立加缪的创作存在大量的二元对立的主题，其中有一些直接作为书名如反与正，流放和王国等，荒诞和理性，生与死，堕落和拯救，阳光和阴影，有罪和无辜。这些二元对立的主题经常成对出现，而且互不取消，甚至有相反相成的意思，这是他的一大特点和魅力之所在。加缪在他的随笔中数次使用这样的修辞方式：用一片黑暗来形容明亮的阳光。随笔中也许不过是一种修辞，但这种修辞代表的思维方式却贯穿了加缪几乎全部的创作，成为他的重要特色。正是在这样对矛盾的正视当中反映了人类思维的局限及其与世界的断裂。二元对立的两极互相为对方的存在而存在，形成强大的张力，悖论和歧义性、多义性在此从生，这也成为加缪难以被定义的地方，其间人道主义一以贯之，然而人道主义本来就是意义含混的词。 存在主义在第二次世界大战以后，人们更感到前途渺茫，苦闷彷徨，人的生存面临严重威胁，人失去了安全感，人被绝望、孤独和无家可归的情绪所笼罩，这时理性主义、科学主义和乐观主义逐步被荒诞哲学所取代。人们普遍感受到这个世界的荒诞性，人存在的荒诞性，于是荒诞哲学应运而生。存在主义哲学对于“荒诞”的解释是：由于人和世界的分离，世界对于人来说是荒诞的、毫无意义的，而人对荒诞的世界无能为力，因此不抱任何希望，对一切事物都无动于衷。 阿尔贝·加缪是存在主义哲学家中对荒诞论述得最为全面、最深刻，并使之具有新意的人之一，这也是他的哲学的最大特色，因而被人们称之为“荒诞哲学” 。荒诞哲学是资产阶级文明遭到严重冲击的哲学表现。随着西方资本主义社会在其发展过程中不断暴露出它的痼疾，和由此带来的灾难性、毁坏性后果，诸如剧烈的阶级斗争和社会震荡，周期性的经济危机，两次世界大战，法西斯主义的崛起和它对人的灭绝人性的迫害，“使得人们在资本主义发展初期所滋长蔓延起来的对理性和科学的颂扬，对社会进步的乐观幻想，迅速被一种所谓‘存在的不可理解’，‘人的存在的走投无路的悲剧性’的感觉所取代”。 存在主义包容了各种各样思想的一种思潮，在各种公认的存在主义思想之间也存在着尖锐的矛盾。简单而言，存在主义的重大主题为个人对于存在的恐惧，荒诞的感受；它反映人在面对世界时所感到的一种情绪：孤立无援、个人承担但无意义的世界荒谬而没有尽头、个人处于一种“被抛弃”的境地。 参考自 阿尔贝·加缪（法国作家、哲学家）_百度百科 著作《局外人》1942《局外人》形象地体现了存在主义哲学关于“荒谬”的观念；由于人和世界的分离，世界对于人来说是荒诞的、毫无意义的，而人对荒诞的世界无能为力，因此不抱任何希望，对一切事物都无动于衷。 局外人（阿尔贝·加缪著中篇小说）_百度百科 《反抗者》1951 为了将《西西弗神话》中所蕴含的主题更加深入地进行形而上的追索和沉入到历史经验的脉络中，1951 年，加缪完成了酝酿十年之久的哲学随笔《反抗者》。在这部著作中，加缪提出了如下命题：“我反抗，故我在”。“我们每天遭受的苦难中，反抗所起的作用犹如‘我思’在思想范畴所起的作用一样。 它是第一个明显的事实，然而这个事实使人摆脱了孤独状态。它使所有的人都接受了第一种价值。我反抗，故我们存在。”也只有反抗，人类才能最终超越荒诞的境地。 那么，何谓反抗者？加缪开宗明义地说：“一个说‘不’的人。然而，它虽然拒绝，却并不放弃：他也是从一开始行动就说‘是’的人。”“不”与“是”，岂不是相互矛盾？这正是加缪的深刻性和复杂性所在。 他举例说，当一个奴隶向主人说“不”时，他是一个反抗者。但同时，他又是一个说“是”的人，因为当他反抗时，他事实上肯定了主人与奴隶界限的存在。肯定与否定的共存，构建出反抗的价值，也就是人存在的价值。也就是说，反抗表面上看起来是否定之物，“其实它表现了人身上始终应该捍卫的东西，因而十足地成为肯定之物”。无论如何，反抗都应该成为一种绝对命令，因为反抗代表了人的不肯屈服的那一部分，是“人的最独特的东西”，也是人之为人、人的尊严感的体现。 在《反抗者》中，加缪将反抗分为两种：“形而上的反抗”和“历史上的反抗”。“形而上的反抗是人挺身而起反对其生存状态与全部创造。它之所以是形而上的，是因为它否认人与创造的目的。”从萨德的颂扬个人情欲与恶的“绝对否定”的反抗，到伊万·卡拉马佐夫的“拒绝得救”——除非拯救所有的人，否则无一人得救——式的反抗，再到尼采的对抗虚无主义1的“绝对肯定”的反抗，加缪构建了一个“反抗的形而上学”：我反抗，故我存在。反抗既是一种生命的尊严，也是一种生命的创造。“之所以存在反抗，是因为谎言、 非正义与暴力部分地构成了反抗者的生存状况。他若要坚持反抗，则要下决心完全不杀人与说谎，永远不同意一切杀人与暴力的行动。他也不能让自己杀人与说谎。”也就是说，反抗不是为了我们自己的存在而去杀人，相反，是为了“创造我们现在的存在而活着，并让他人活着”。反抗何时会走向它的反面？加缪认为，反抗堕落的形式之一就是革命。 在“历史上的反抗”一节中，加缪以“革命”为关键词，考察了自1793 年以来的历次革命运动，他得出的结论是：反抗一旦从纯心灵领域进入到历史领域的实际行动，就会变成改变社会秩序和结构的暴力行为。一旦反抗者变成革命者，形而上的谋杀就会带来普遍杀人的时代。反抗者的“不”与“是”的辩证平衡一旦被破坏，反抗就会演变为暴力与杀人的循环游戏。“大部分革命的形式与特点就在于杀人。所有的或几乎所有的革命都曾经是杀人的。”真正激怒萨特的，正是加缪对历史主义的清算，和对马克思主义的质疑。“马克思主义就其一个方面来说，是认为人是有罪的而历史是无罪的学说。” 人们一旦以历史之名，将杀戮制度化与合法化，反抗的历史将演变为一部血腥的历史。例如，苏联社会主义所依傍的斯大林化的马克思主义，不但将杀人合法化，而且变成了一种政府行为和国家恐怖主义，于是，便为人类反抗史带来了一份沉重的历史清单：流放、审判、集中营、劳改营、秘密处决、铁幕、 冷战……他甚至将苏联制度与法西斯制度做了一个意味深长的对比：“把法西斯主义的目标与俄国共产主义的目标混为一谈是不正确的。前者由刽子手自己颂扬刽子手，而后者更富有悲剧性，竟由受害者来颂扬刽子手。前者从未想过要解放所有的人，而仅仅想解放某些人而征服其他人。后者就其最深刻的原则而言，旨在解放所有的人，但要暂时地奴役他们所有的人。” 革命走入歧途的原因，就在于它的不知节制。“节制并非反抗的反面。反抗正是节制，在捍卫着它，穿过历史及其混乱而重新创立节制。”加缪如此言说，无异于与法国政治左派公然决裂，向萨特公开叫板。正如阿隆森教授所言：“在《反抗者》临近尾声时，加缪显然想激萨特作出回应，但是，为什么他不愿意提到朋友的名字？加缪强烈反对萨特的立场，想要了解一种历史导向的哲学何以是道德的，他似乎不得不与萨特正面交锋，而同时他又极力避免这样做。 作者：OnePerson链接：https://www.zhihu.com/question/19558616/answer/234453332来源：知乎 《西西弗的神话》1942在加缪的笔下，西西弗是一位荒诞的英雄。西西弗拥有巨大的精神力量，他是一个注定要与失败的命运抗争的人，他没有怨恨，没有犹豫，不存任何希望，他明明知道劳而无功，却朝着不知道尽头的痛苦，脚步沉重而均匀地走去，他清楚地知道，无数次的胜利其实是无数次的失败，但它只是激起了轻蔑，“没有轻蔑克服不了的命运”，他知道自己是命运的主人，他永远前进，他的行动就是对荒谬的反抗，他朝着山顶所进行的斗争本身就足以充实一颗人心，完全没有必要消除荒谬，关键是要活着，是要带着这种破裂去生活。人有精神，但还有至关重要的身体，精神依靠身体去穷尽现在的一切 萨特 简介让-保罗·萨特（法语：Jean-Paul Sartre，1905年6月21日－1980年4月15日），著名法国哲学家、作家、剧作家、小说家、政治活动家，存在主义哲学大师及二战后存在主义思潮的领军人物，被誉为二十世纪最重要的哲学家之一。其代表作《存在与虚无》是存在主义的巅峰作品。他主张一切从人、人的意识出发，来研究人和这个世界，把人的主观意识的存在看成是一切存在的根本。 参考： 让-保罗·萨特 - 维基百科，自由的百科全书 哲学理论和重要概念萨特的哲学是一种激进的自由意志主义。这种理论和决定论相对，认为人类有绝对的自由。“上帝已死”，尼采名言可以看作萨特哲学的一个基本前提。结果是人变成被抛弃。因为在人的身内身外，都无法找到依托的东西。人没有存在的理由。而如果确实是存在先于本质，人就不能用一种天生的现有的人性来解释自己的行动；也就是说，没有决定论。人是自由的。人就是自由。另一方面，如果上帝不存在，人就没有价值（什么是价值）和戒律说明人的行为是正当的。没有价值领域。人孤寂独处，无可辩解。这就是萨特说“人是被判定为自由”时想要表达的意思。因为一个人并不是自愿存在于世的，然而一旦存在，他就是自由的；但同时他要对自己所做的一切负责。 参考自： 虚无（Nothingness）“虚无”（nothingness）是人的意识作为“对己存有”（For-Itself）之根本特质，人在朝向未来，投射出理想的自我之时，他便不再只是当下的自己，这时，他从理想的状态回头看自己，而否定眼前的自己。 否定自己，就是将眼前的自己虚无化。但是，人们藉以否定当下状态的理想既然尚未实现，所以也是一种虚无。如此一来，人生彻头彻尾都由虚无所贯穿。然而，虚无不表示否定生命的意义。 相反地，萨特认为，这样才能肯定人之为人的意义。因为，假若人只是固定不变的物体，则他将任人摆布，这难道不是对人最大的否定吗？或许我们用“缺乏”（lack）来解释“虚无”的涵义会更为恰当。当人心中有个理想，因而对照出现状的种种缺失时，他就是处于一种“缺乏”（lack）的状态。 13.虚无主义 自己创造自己@todo 对他存有（Being-for-others）@todo 存在者的五种处境@todo 著作《禁闭》 他人即地狱这出自萨特的剧本《禁闭》。剧本是非常典型的三一律，而场景是在地狱的一个房间中。剧中三个主角都是身前犯有罪行的人，加尔散是个胆小绝，无耻的逃兵，伊内斯是同性恋，并且拥有强大欲望支配别人的心理变态，而艾丝黛儿是个沉浸于男人怀中的色情狂，同时也是一个狠毒的溺婴犯。他们三个身前毫不相识的人，被狱卒陆续送到了这个密闭的房间。这个房间里没有镜子，这让三个角色都异常的抓狂。加尔散说“只要能照一下镜子，我什么都舍得拿出来。”艾丝黛儿说“当我不照镜子的时候，我摸自己也没用，我怀疑自己是否真的还存在。”没有镜子的密室，他们只能将互相当做镜子，从对方那里寻找到自己存在的证据。在这个没有酷刑的地狱，他们的折磨来自他们互相的关系。在这个没有黑夜的地狱，他们无时无刻不暴露在别人的目光中。为了得到解脱和自由，他们开始试图去证明自己，去寻找自己存在的意义。因此加尔散这个胆小鬼，要证明自己不是懦夫他开始试图说服充满强势力量的伊内斯，而伊内斯这个同性恋，她需要去支配别人，于是她将艾丝黛儿视为自己彰显支配力量的猎物。而艾丝黛儿她沉溺与男人的怀抱，她需要从加尔散这个密室中唯一的男人那里证明自己的魅力从而去满足她色情狂的心。他们三个人就像是旋转木马一样一直互相追逐，而在这样之中他人便自然的形成了地狱的酷刑。从而导致最后他们发出了”他人即地狱“的哀嚎。 这样看来虽然不难让人理解 ”他人即地狱” 的含义，但是却产生了许多误解。萨特曾说，许多人误解了他的意思，人们以为他所说的是人与人的关系已经坏透了，而且永远都是难以沟通的。但是他却不是这个意思。他想说的是人只有通过自我选择才能决定自我存在，只有通过自我选择才能获得自由。剧中的人物已经死了，他们不能再进行选择，而我们却可以。所以不管我们身处于何种地狱般的环境之中，我们都可以自由的去打碎它。所以，“他人即地狱”其实含有了多层含义。 1、若不能正确对待别人，那么他人便是地狱。2、要正确对待他人对自己的判断，否则他人依旧是地狱。3、如果不能正确的对待自己，你也可以变成自己的地狱。 1.13.虚无主义 ↩","categories":[{"name":"61.Philosophy","slug":"61-Philosophy","permalink":"https://beefyheisenberg.github.io/categories/61-Philosophy/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://beefyheisenberg.github.io/tags/哲学/"},{"name":"存在主义","slug":"存在主义","permalink":"https://beefyheisenberg.github.io/tags/存在主义/"},{"name":"海德格","slug":"海德格","permalink":"https://beefyheisenberg.github.io/tags/海德格/"},{"name":"加缪","slug":"加缪","permalink":"https://beefyheisenberg.github.io/tags/加缪/"},{"name":"萨特","slug":"萨特","permalink":"https://beefyheisenberg.github.io/tags/萨特/"}]},{"title":"04.分析哲学","slug":"61.Philosophy/04.分析哲学","date":"2024-01-24T01:27:53.719Z","updated":"2024-01-24T01:27:53.720Z","comments":true,"path":"61.Philosophy/04.分析哲学/","link":"","permalink":"https://beefyheisenberg.github.io/61.Philosophy/04.分析哲学/","excerpt":"分析哲学（analytic philosophy）是现代西方哲学流派。认为传统哲学关于形而上学的思辨是没有意义的，主张哲学的任务在于“清思”，用尽可能客观的方法对语言进行逻辑分析，并阐明它们的意义。有广义、狭义之别。广义的，凡主张哲学的唯一任务在于“分析”（不管是哪一种分析）的，都可称为分析哲学。如英国穆尔的“概念分析”，逻辑原子论的“逻辑分析”，逻辑实证主义的“句法的”和“语义的”分析，牛津学派的“通常语言”的分析等便是。狭义的，专指第二次世界大战前后开始流行于英国的语言“通常用法”的分析学派或“语言哲学”学派。 谈论世界和谈论”谈论”我们不能分析思想, 我们只能分析思想的表达, 即分析语言. 弗雷格弗雷格_百度百科 罗素","text":"分析哲学（analytic philosophy）是现代西方哲学流派。认为传统哲学关于形而上学的思辨是没有意义的，主张哲学的任务在于“清思”，用尽可能客观的方法对语言进行逻辑分析，并阐明它们的意义。有广义、狭义之别。广义的，凡主张哲学的唯一任务在于“分析”（不管是哪一种分析）的，都可称为分析哲学。如英国穆尔的“概念分析”，逻辑原子论的“逻辑分析”，逻辑实证主义的“句法的”和“语义的”分析，牛津学派的“通常语言”的分析等便是。狭义的，专指第二次世界大战前后开始流行于英国的语言“通常用法”的分析学派或“语言哲学”学派。 谈论世界和谈论”谈论”我们不能分析思想, 我们只能分析思想的表达, 即分析语言. 弗雷格弗雷格_百度百科 罗素伯特兰·罗素 - 维基百科，自由的百科全书 维特根斯坦 路德维希‧约瑟夫‧约翰‧维特根斯坦（德语：Ludwig Josef Johann Wittgenstein；1889年4月26日－1951年4月29日）是一名奥地利哲学家。他生于奥地利，后入英国籍。维特根斯坦是20世纪最有影响力的哲学家之一，其研究领域主要在语言哲学、心灵哲学和数学哲学等方面。 简介第一次世界大战开始后，本可免服兵役的维特根斯坦作为志愿兵积极入伍，在战场上完成了标志所谓哲学的语言学转向的 《逻辑哲学论》 的初稿。《逻辑哲学论》后他认为所谓的哲学问题已被解决，于是怀着贵族式的热忱前往奥地利南部山区，投入格律克尔倡导的奥地利学校改革运动，成为一名小学教师。有着理想主义追求的维特根斯坦在这里过着苦行僧般的生活，对学生也充满了热情，然而却被无法理解的家长们视为“疯狂的家伙”，他们拒绝了这个古怪家伙提出的收养其中一个或两个学生的要求。 1928年春在听了数学家布劳维尔在维也纳有关“数学、科学和语言”的一次讲演后，维特根斯坦重新萌发了强烈的哲学探索的兴趣。1929年，维特根斯坦重返剑桥，以《逻辑哲学论》作为论文，通过了由罗素和G.E.摩尔主持评审的博士答辩后，留在三一学院教授哲学，并于1939年接替摩尔成为哲学教授。1947年，坚信“哲学教授”是“一份荒唐的工作”的维特根斯坦从剑桥辞职，以专心思考、写作。 去世后由弟子安斯康姆和拉斯·里斯出版了被认为是引导了语言哲学新的走向的 《哲学研究》。维特根斯坦的一生极富传奇色彩，被罗素称为“天才人物的最完美范例”：富有激情、深刻、炽热并且有统治力。 参考: 路德维希·维特根斯坦 - 维基百科，自由的百科全书 思想维特根斯坦是 语言学派（大约相当于分析哲学）的主要代表人物。在西方哲学界，有人称他的哲学为上一世纪唯心主义哲学转变为本世纪分析哲学的“革命”；也有人称他是把现代哲学方法“推进到决定性转折的第一人”。 他的哲学主要研究的是语言。他想揭示当人们交流时，表达自己的时候到底发生了什么。他主张哲学的本质就是语言。语言是人类思想的表达，是整个文明的基础，哲学的本质只能在语言中寻找。他消解了传统形而上学的唯一本质，为哲学找到了新的发展方向。 著作《逻辑哲学论》让哲学成为语言学问题，哲学必须直面语言，“凡是能够说的事情，都能够说清楚，而凡是不能说的事情，就应该沉默”，哲学无非是把问题讲清楚 世界是一切发生的事情。 发生的事情，即事实，就是诸事态[2]的存在。 事实的逻辑图像是思想。 思想是有意义的命题。 命题是基本命题的真值函项。 《哲学研究》把哲学回归哲学，在解构之后是建构，创造一套严格的可以表述哲学的语言是不可能的，因为日常生活的语言是生生不息的，这是哲学的基础和源泉，所以哲学的本质应该在日常生活中解决，在“游戏”中理解游戏。","categories":[{"name":"61.Philosophy","slug":"61-Philosophy","permalink":"https://beefyheisenberg.github.io/categories/61-Philosophy/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://beefyheisenberg.github.io/tags/哲学/"},{"name":"分析哲学","slug":"分析哲学","permalink":"https://beefyheisenberg.github.io/tags/分析哲学/"},{"name":"维特根斯坦","slug":"维特根斯坦","permalink":"https://beefyheisenberg.github.io/tags/维特根斯坦/"},{"name":"罗素","slug":"罗素","permalink":"https://beefyheisenberg.github.io/tags/罗素/"}]},{"title":"03.德国古典哲学","slug":"61.Philosophy/03.德国古典哲学","date":"2024-01-24T01:27:53.714Z","updated":"2024-01-24T01:27:53.715Z","comments":true,"path":"61.Philosophy/03.德国古典哲学/","link":"","permalink":"https://beefyheisenberg.github.io/61.Philosophy/03.德国古典哲学/","excerpt":"德国古典哲学康德 简介伊曼努尔·康德（德文：Immanuel Kant，公元1724年4月22日—公元1804年2月12日），康德是启蒙运动时期最后一位主要哲学家，是德国思想界的代表人物。他调和了勒内·笛卡儿的理性主义与弗朗西斯·培根的经验主义，被认为是继苏格拉底、柏拉图和亚里士多德后，西方最具影响力的思想家之一。康德有其自成一派的思想系统，并且有为数不少的著作，其中核心的三大著作被合称为“三大批判”，即《纯粹理性批判》、《实践理性批判》和《判断力批判》，这三部作品有系统地分别阐述他的知识学、伦理学和美学思想。《纯粹理性批判》尤其得到学术界重视，标志着哲学研究的主要方向由本体论转向认识论，是西方哲学史上划时代的巨著，被视为近代哲学的开端。此外，康德在宗教哲学、法律哲学和历史哲学方面也有重要论著。康德哲学理论的一个基本出发点是，认为将经验转化为知识的理性（即“范畴”）是人与生俱来的，没有先天的范畴我们就无法理解世界。他的这个理论结合了英国经验主义与欧陆的理性主义，对德国唯心主义与浪漫主义影响深远。","text":"德国古典哲学康德 简介伊曼努尔·康德（德文：Immanuel Kant，公元1724年4月22日—公元1804年2月12日），康德是启蒙运动时期最后一位主要哲学家，是德国思想界的代表人物。他调和了勒内·笛卡儿的理性主义与弗朗西斯·培根的经验主义，被认为是继苏格拉底、柏拉图和亚里士多德后，西方最具影响力的思想家之一。康德有其自成一派的思想系统，并且有为数不少的著作，其中核心的三大著作被合称为“三大批判”，即《纯粹理性批判》、《实践理性批判》和《判断力批判》，这三部作品有系统地分别阐述他的知识学、伦理学和美学思想。《纯粹理性批判》尤其得到学术界重视，标志着哲学研究的主要方向由本体论转向认识论，是西方哲学史上划时代的巨著，被视为近代哲学的开端。此外，康德在宗教哲学、法律哲学和历史哲学方面也有重要论著。康德哲学理论的一个基本出发点是，认为将经验转化为知识的理性（即“范畴”）是人与生俱来的，没有先天的范畴我们就无法理解世界。他的这个理论结合了英国经验主义与欧陆的理性主义，对德国唯心主义与浪漫主义影响深远。 参考：伊曼努尔·康德 - 维基百科，自由的百科全书 康德凭借着他的三部“批判性”的著作，为先验方法作出相应的结构： 分析论，分析理性的有效机能； 辨证论，展示理性的可能失误； 方法论，列举实用的各种规则。 哲学思想《纯粹理性批判》 《纯粹理性批判》要回答的问题是：我们能知道什么？康德的回答是：我们只能知道自然科学让我们认识到的东西，哲学除了能帮助我们澄清使知识成为可能的必要条件，就没有什么更多的用处了。自从柏拉图以来的哲学家把这个问题彻底给颠倒了。在此之前，人们让认识向外部事物看齐，而康德说，如果我们颠倒一下，让事物向我们的认识看齐，该会如何？于是康德认为客体必须按照主体的认识形式来形成知识。康德把这一思维方法与哥白尼的“日心说”相比较：哥白尼以前，人们认为一切星球围着我们地球转，哥白尼却说，我们地球是在围着其它星球转。 以下参考： 纯粹理性批判 康德在第二版序言，首先做出了一个假设：“不是知识符合对象，而是对象符合知识的先天认识形式”，这一新思路，就好像哥白尼从地心说转变成了日心说，康德称之为哲学界的“哥白尼式革命”。 康德提出了“先天综合判断”，“先天综合判断”这个概念来自于休谟综合命题与分析命题的区分。休谟认为分析命题是谓词包含在主词之中，比如“人都是会死的“，”死“包含在”人“这个概念之中，所以一切分析命题都是必然命题；综合命题的主词与谓词没有先天的逻辑关系，比如”人坐在椅子上“，休谟称之为偶然命题。康德为了寻求既是先天必然的，又对经验世界起作用的知识，增加了“先天综合判断”。康德不认为所有综合命题都是后天的，而一些先天的综合命题就是“先天综合判断”。 在导言中，康德提出了全书的总纲：纯粹理性的总任务是要解决“先天的综合判断”如何可能的问题；并按这总问题细分了以下的三个问题：1.纯粹数学如何可能？2.纯粹自然科学如何可能？3.形而上学作为科学如何可能？ 康德把全书大致的分为了五部分：“1.先验感性论，2.先验逻辑论，3.先验分析论，4.先验辩证论，5.先验方法论” 先验感性论：“先验感性论”主要是阐明，只有通过人的感性知识(接受能力)所先天具有的直观形式即“空间”和“时间”两大要素去整理自在之物（的表象即现象界）刺激感官的感觉材料，才能获得确定的感性知识，同时，空间和时间也是数学知识的先天直观形式。 先验逻辑论：“先验逻辑论”的阐明“感性必须与知性结合，直观必须与思维结合，才能产生自然科学的知识”，因而必须有一门不同于形式逻辑的先验逻辑来探讨知性的结构及其运用于经验对象时的各种原理。先验逻辑立足于知识与对象的关系，即知识的内容，而不是单纯的思维形式，这标著辩证逻辑在近代的萌芽。 先验分析论：“先验分析论”（真理的逻辑）阐明了知性的先天概念和先天原理是自然科学之所以可能的根据和条件。在概念分析论中，通过对知性判断中的逻辑机能的分析。而先验分析论当中的原理分析论主要阐明了知性指导判断力把范畴运用于现象的法规。 先验辩证论：“先验辩证论”（幻相的逻辑）主要阐明了理性不可避免地要超越现象去认识的本体，由此产生的作为自然倾向的形而上学只不过是一些先验的幻相，而不可能是真正的科学。康德在先验辩证论的导言之中指出，理性这种推广能力由于要从有条件者出发通过推论去认识无条件者。 先验方法论：先验方法论首先阐明，纯粹理性的经验使用虽然有正确的使用法规（知性的先更原理），但其理论的（思辨的、先验的）奥用却没有法规可言，因而必须对其先验使用方法(从定义出发的独断论、从正反两方争辩并互相证伪怀疑论方法、还有假设和证明的的方法等四个方面)加以训练，确立一些“消极的”规则，以限制纯粹理性的扩充到可能经验之外的倾向，从而为建立一种有关经验的形而上学准备了方法论的原则。 知识论要义与其他：虽然康德使用的是批判哲学，他本人却建立起一套完整的哲学理论。他本人自称发动了一场哲学领域内的哥白尼革命。在康德所处的时代，欧洲哲学思想主要有两种重要理论：由约翰·洛克、大卫·休谟等人发展出来的经验主义，以及笛卡儿等人的理性主义。经验主义者认为人类对世界的认识与知识来源于人的经验，而理性主义者则认为人类的知识来自于人自身的理性。而康德则在一定程度上接合了两者的观点。康德认为知识是人类同时透过感官与理性得到的。经验对知识的产生是必要的，但不是唯一的要素。把经验转换为知识，就需要理性（康德与亚里士多德一样，将这种理性称为“范畴”），而理性则是天赋的。人类通过范畴的框架来获得外界的经验，没有范畴就无法感知世界。因此范畴与经验一样，是获得知识的必要条件。但人类的范畴中也有一些可以改变人类对世界的观念的因素，他意识到，事物本身与人所看到的事物是不同的，人永远无法确知事物的真正面貌。 《实践理性批判》 《实践理性批判》是康德的前一部著作《纯粹理性批判》的归宿和目的。所谓“实践理性”，是指实践主体的意志，对于实践理性的“批判”，就是要考察那规定道德行为的“意志”的本质以及它们遵循的原则。全书包括“纯粹实践理性的原理论”和“纯粹实践理性的方法论”两大部分。该书的重要理论意义在于，它把人的主体性问题突出出来，强调了人格的尊严与崇高，表现了强烈的人本主义精神。 伦理学方面，康德否定意志受外因支配的说法，而是认为意志为自己立法，人类辨别是非的能力是与生俱来的，而不是从后天获得。这套自然法则是无上命令，适用于所有情况，是普遍性的道德准则。康德认为真正的道德行为是纯粹基于义务而做的行为，而为实现某一个个人功利目的而做事情就不能被认为是道德的行为。因此康德认为，一个行为是否符合道德规范并不取决于行为的后果，而是采取该行为的动机。 康德还认为，只有当我们遵守道德法则时，我们才是自由的，因为我们遵守的是我们自己制定的道德准则，而如果只是因为自己想做而做，则没有自由可言，因为你就成为各种事物的奴隶。 《判断力批判》 《判断力批判》要回答的问题是：我们可以抱有什么希望？康德给出的答案是：如果要真正能做到有道德，我就必须假设有上帝的存在，假设生命结束后并不是一切都结束了。“判断力批判”中，康德关心的问题还有人类精神活动的目的、意义和作用方式，包括人的 美学鉴赏能力 和 幻想能力 。 黑格尔 简介格奥尔格·威廉·弗里德里希·黑格尔（德语：Georg Wilhelm Friedrich Hegel，常缩写为G. W. F. Hegel；公元1770年8月27日—公元1831年11月14日），德国哲学家。 许多人认为，黑格尔的思想，标志着19世纪德国唯心主义哲学运动的顶峰，对后世哲学流派，如存在主义和马克思的历史唯物主义都产生了深远的影响。更有甚者，由于黑格尔的政治思想兼具自由主义与保守主义两者之要义，因此，对于那些因看到自由主义在承认个人需求、体现人的基本价值（什么是价值）方面的无能为力，而觉得自由主义正面临挑战的人来说，他的哲学无疑是为自由主义提供了一条新的出路。 主要思想国家观他的国家概念指的不是现存的国家制度，而是精神的国家理念。现实的国家只是国家理念的表现。国家的本质在于它是伦理理念的现实，是绝对自在自为的理性的东西。黑格尔对国家与社会进行了区分，市民社会是外在的国家，是主观意志、个人利益的结合形式。国家以它至高无上的意志、伦理精神把整个民族凝聚为一个有机的统一体。国家先于并高于家庭、市民社会，是它们存在的前提，是决定的力量，是人类生活的最高形式。它是自我与他人、个人与社会、特殊利益与普遍利益的统一。个人只是国家的一些环节，生活在国家中，才能获得个人的人格、自由和价值。黑格尔对德国古典哲学中整体国家观的倾向给予充分发挥，表明了他对古希腊以伦理和整体为特征的城邦国家观的崇尚。 辩证法黑格尔在18世纪末至19世纪初的哲学中提出了辩证发展的理论。他的发展和变化的学说对于辩证法的形成起了很大的作用。黑格尔的辩证法认为整个历史和精神的世界是一个过程，就是说，是在不断的地运动着，变化着，发展着和改造着的。同时过程内部的矛盾是事物自身运动和发展的源泉。黑格尔把辩证法应用到关于概念，判断的学说上，应用到认识的逻辑上。 黑格尔历来同其他曾抱有稍类似的形而上学观点的人有两点区别。一点是强调逻辑：实在的本性从它必须不自相矛盾这个唯一的考虑就能推演出来。另一个（与第一点密切相关的）区别特征是称作辩证法的三元运动。他的最重要的著作是两部《逻辑学》（Logic），要想正确理解他对其它问题的见解的依据，这两部书不可不懂。逻辑照黑格尔的理解，他明确地说和形而上学是一回事；那是一种跟普通所说的逻辑完全不同的东西。 他的看法是：任何平常的谓语，如果把它认作是限定“实在”全体的，结果它就是自相矛盾的。我们不妨举巴门尼德的学说：唯一实在的“太一”是球状的，作为一个粗浅的实例。任何东西如果没有边界便不会是球状的，而除非它外部有什么（至少有虚空间），它才可能有边界。因此，假定整个宇宙是球状的，便自相矛盾。（如果把非欧几里得几何抬出来，对这个议论未尝不可以有异议，但是这议论作为一个说明例子，也算可用。） 以上黑格尔观点类似于康德的二律背反。用以说明实在事物的内在矛盾性。并且这种矛盾性永恒存在，而结实这种存在的矛盾只能运用形而上学，即解释为绝对的“精神”，亦或是康德所说的“物自体” 认识论认识作为整体看，具有三元运动。认识始于感官知觉，感官知觉中只有对客体的意识。然后，通过对感觉的怀疑批判，认识成为纯主体的。最后，它达到自认识阶段，在此阶段主体和客体不再有区别。所以自意识是认识的最高形态。当然，在黑格尔的体系中必得如此，因为最高一种的认识一定要是“绝对”所具有的认识，既然“绝对”是 “全体”，所以在它自身之外再没有任何东西要它认识了。依黑格尔的意见，在最好的思维中，思想变得通畅无阻，水乳交融。真和假并不像普通所想的那样，是判然分明的对立物；没有任何事物是完全假的，而我们能够认识的任何事物也不是完全真的。“我们能够多少有些错误地去认识”；我们将绝对真理归于某一件孤离知识时便发生这种情况。像“凯撒是哪里出生的？”这种问题，有一个直截了当的答案，这答案从某个意义上说是真的，但是在哲学的意义上不真。按哲学讲， “真理就是全体”，任何部分事物都不十分真。黑格尔说：“理性即对全部实在这种有意识的确信。”这并不是说分立的人是全部实在；就他的分立性来说，他不是十分实在的，但是他的实在处在于他参与整体的“实在”。随着我们变得日益理性，这种参与也相应地增大。《逻辑学》末尾讲的“绝对理念”，是一种像亚里士多德的“神”似的东西。绝对理念是思维着自身的思想。很明显，“绝对”除思维自身而外什么也不能思维，因为除对我们理解“实在”的偏狭错误的方式而言外，不再有任何旁的东西。据他说，“精神”是唯一的实在，它的思想借自意识向自身中映现。定义“绝对理念”的实际原话非常晦涩。瓦勒斯译之如下：绝对的理念的统一，就是理念的概念，这概念以理念的本身作为对象，而且从这一概念看来，客观世界即是一理念——在这客观世界里一切规定均统一起来了（德文原文更难懂）。","categories":[{"name":"61.Philosophy","slug":"61-Philosophy","permalink":"https://beefyheisenberg.github.io/categories/61-Philosophy/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://beefyheisenberg.github.io/tags/哲学/"},{"name":"哲学史","slug":"哲学史","permalink":"https://beefyheisenberg.github.io/tags/哲学史/"},{"name":"叔本华","slug":"叔本华","permalink":"https://beefyheisenberg.github.io/tags/叔本华/"},{"name":"康德","slug":"康德","permalink":"https://beefyheisenberg.github.io/tags/康德/"},{"name":"黑格尔","slug":"黑格尔","permalink":"https://beefyheisenberg.github.io/tags/黑格尔/"}]},{"title":"02.西方哲学史","slug":"61.Philosophy/02.西方哲学史","date":"2024-01-24T01:27:53.710Z","updated":"2024-01-24T01:27:53.710Z","comments":true,"path":"61.Philosophy/02.西方哲学史/","link":"","permalink":"https://beefyheisenberg.github.io/61.Philosophy/02.西方哲学史/","excerpt":"西方哲学史西方哲学不同时代主要关注对象： 古代哲学: 本体论（Ontology）是探究世界的本原或基质的哲学理论，“存在”，物质的存在与精神存在之间的区别 近代哲学: 认识论（epistemology）, 康德: 对理性认识能力的考察。认识论即个体的知识观，也即个体对知识和知识获得所持有的信念，主要包括有关知识结构和知识本质的信念和有关知识来源和知识判断的信念，以及这些信念在个体知识建构和知识获得过程的调节和影响作用，长久以来一直是哲学研究的核心问题。 现代哲学: 语言哲学(弗雷格Frege~维特根斯坦) 附-极简欧洲史：","text":"西方哲学史西方哲学不同时代主要关注对象： 古代哲学: 本体论（Ontology）是探究世界的本原或基质的哲学理论，“存在”，物质的存在与精神存在之间的区别 近代哲学: 认识论（epistemology）, 康德: 对理性认识能力的考察。认识论即个体的知识观，也即个体对知识和知识获得所持有的信念，主要包括有关知识结构和知识本质的信念和有关知识来源和知识判断的信念，以及这些信念在个体知识建构和知识获得过程的调节和影响作用，长久以来一直是哲学研究的核心问题。 现代哲学: 语言哲学(弗雷格Frege~维特根斯坦) 附-极简欧洲史： 古典时代： 古希腊、古罗马 中世纪： 5世纪西罗马帝国灭亡~1453年东罗马帝国灭亡（君士坦丁堡陷落） 近代 文艺复兴： 13xx~16xx（14~17世纪） 宗教改革： 启蒙运动：16xx~17xx（17-18世纪） 现代 工业革命：1765~1844（18世纪60年代~19世纪） 政治革命：1848~ 一战/二战：1914~1945 西方哲学系谱图（整理）①古希腊罗马哲学（BC6 世纪 ~ AD4 世纪）古希腊罗马哲学包括自然哲学、形而上学和伦理哲学三个阶段，为西方哲学的理性思辨和形而上学打下了传统根基。它提出了逻辑、存在、实体等成为西方哲学的经典命题，而柏拉图和亚里士多德关于共相性质的争论开启了中世纪基督教哲学关于唯名论和实在论的争论。 苏格拉底代表论著：《克堤拉斯篇》《泰阿泰德篇》《智士篇》《政治家篇》 柏拉图代表论著：《对话录》《理想国》《柏拉图对话集》 亚里士多德代表论著：《工具论》《物理学》《形而上学》《伦理学》《政治学》 欧几里得：《几何原本》 恩培多克勒：《论自然》《论净化》 ②中世纪基督教哲学（4 世纪 ~ 14 世纪）中世纪哲学指的是西欧和中东在中世纪的哲学体系，其时间范围没有定论，大致上是从基督化的罗马帝国时期至文艺复兴时期。西罗马帝国崩溃后，基督教成为西欧不可侵犯的绝对意识形态，哲学成为“神学的婢女”，被基督教信仰的浓重阴影所笼罩。从教父哲学（柏拉图-奥古斯丁体系）到经院哲学（亚里士多德-阿奎那体系）的过渡反应了希腊罗马理性精神的复苏，而唯名论和实在论的对立为近代理性主义和经验论的兴起开辟了道路。 时间推进到中世纪，随着天主教的教会力量进入统治阶级，其神职人员开始将古希腊的哲学思想与宗教相结合，产生了经院哲学。经院哲学将萌芽期的自然科学和天主教的神学通过古希腊哲学的思想融合在一起。上帝成了至高无上的存在，这个世界都是上帝的造物，太阳是为了给大地带来光明，大地是为了生长草木，植物是为了饲养动物，而作为天主照自己肖像造的人，则是为了能认识及爱慕自己的造物主，在天主恩宠中过世的人则可以升入永恒的天堂。 奥古斯丁代表论著：《忏悔录》《论三位一体》《上帝之城》《论自由意志》《论美与适合》 阿奎纳代表论著：《神学大全》《论君主政治》《反异教大全》《亚里士多德（政治学）诠释》 威廉·奥卡姆代表论著：《逻辑大全》《辩论集7篇》 ③近代早期西欧哲学（14 世纪 ~ 18 世纪）西方哲学史上的近代早期一般指17世纪和18世纪，其中18世纪常被称为启蒙时代。现代哲学不同于其前身，它和传统权威例如教会、学院、亚里士多德的关系更加独立，出现了对知识基础和形而上学体系建设的新兴趣；和摆脱了自然哲学的近代物理学的出现。从17世纪开始，近代哲学就以认识论为研究重点。由于经验论（经验主义）与唯理论（理性主义）的争论，使物质与精神的关系作为认识论的首要问题突显出来。近代早期西欧哲学从文艺复兴和宗教改革运动开始，演化出欧陆唯理论同不列颠经验论的对立，其核心是理性反思和对经验（外在或内在）的重视。唯理论演变成莱布尼茨-沃尔夫体系中的独断论，而经验论则在休谟那里成为彻底的怀疑主义，这为法兰西启蒙思想和德意志古典哲学的出现埋下了伏笔。 进入16世纪，随着宗教改革文艺复兴启蒙运动，人文主义开始颠覆天主教会的统治。经验主义和理性主义从实证和思考两个方向对经院哲学发起挑战。经验主义方向上，从伽利略到牛顿等人逐渐建设起自然哲学并与狭义的哲学开始分离，成为日后的自然科学。理性主义则随着笛卡尔的“我故我在”开始重新推演上帝的存在与否。近代哲学中经验主义主张知识只能通过人的感官经验来获得，而理性主义主张知识独立于感官经验之外由人的理性通过推理获得。经验主义和理性主义的发展让认识论成为近代哲学的主题。随着康德在《纯粹理性批判》中将经验主义和理性主义进行融合和批判，近代哲学开始收束，并归结于黑格尔。 莱布尼茨代表论著：《神义论》《单子论》《论中国人的自然神学》 沃尔夫代表论著：《关于人类理智能力的理性思想》《关于上帝、世界及人的灵魂的理性思想》（讲演“中国的实践哲学”，1721） 休谟代表论著：《人性论》《道德原则研究》《人类理解研究》《宗教的自然史》 ④法兰西启蒙思想和唯物主义（18 世纪）18世纪法国哲学包括法国自然神论和唯物主义两块，探讨的核心问题是人与自然的关系，理论上则表现为思维和存在的关系。法国自然神论奠定了西方政治学的基础，而激进的卢梭则引导了后世批判哲学（马克思和尼采）的出现。法国唯物主义者否定自由意志，但推崇人的理性，使理性主义成为法国哲学鲜明的特点。 伏尔泰代表论著：《哲学通信》《形而上学论》 孟德斯鸠代表论著：《论法的精神》 卢梭代表论著：《论人类不平等的起源和基础》《社会契约论》《爱弥儿》《忏悔录》 ⑤德意志古典哲学（1770 ~ 1844）从18世纪中后期开始，直到19世纪初，哲学便进入了近代哲学的总结时期，这就是德国古典哲学时期。有两条线索标志着转折的到来：一、思维与存在的关系更加明确；二、产生了系统辩证法。其代表人物有I.康德、J.G.费希特、F.W.谢林、G.W.F.黑格尔等。德意志古典哲学体系的出现标志着传统西方哲学的最高成就。它将考察重点转向主体与客体的关系，实现了西方哲学继亚里士多德形而上学体系之后的第二次飞跃。康德通过对自在之物和现象的严格区分，发展出认识论的先验（先验与后验）自我意识统摄机能和道德实践领域的纯粹理性，以及沟通两者的判断力批判。黑格尔通过辩证法三段论将整个世界容纳在绝对精神从自在状态过渡到自为状态，最终达成绝对理性自我意识的宏大历史过程。因此，黑格尔成为最后一个形而上学大体系，并引发费尔巴哈和马克思对其的反思。 康德代表论著：《纯粹理性批判》《实践理性批判》《判断力批判》 黑格尔代表论著：《精神现象学》《逻辑学》《哲学科学全书纲要》《法哲学原理》 ⑥过渡时期-19世纪（1844 ~ 1900）从19世纪中叶开始，西方哲学就进入现代哲学阶段。因为在19世纪中期，欧洲的工业革命几近完成。 现代哲学，特别是19世纪中后期的哲学流派，有叔本华的意志主义，新康德主义，新黑格尔主义，马克思主义。然而此时的哲学与后来的存在主义、现象学等在当代一般归为“欧陆哲学”，与二十世纪以后着重严谨逻辑与语词分析所发展出的“分析哲学”（04.分析哲学）成为风格迥异的两大西方哲学典范。 唯意志主义：该潮流在费希特和谢林的学说下，又经过康德以及黑格尔的影响，终于由叔本华所注意到其中尚未被探索的领域——人类生命和一切生命基本特性的东西，即是“意志”。而尼采也有所谓的“权力意志”这种学说，一种关于生命与世界的与叔本华类似的诠释。但，尼采对其进行彻底的改革，有“对所有价值（什么是价值）重新作出评价”的论述。将其大胆的心理概括传统从宗教、艺术到道德、社会，再到科学和认识本身。 黑格尔主义：从G.W.F.黑格尔思想体系发展出来的庞大哲学运动。K.马克思的著作本身不能说成是一种哲学，更不是一种哲学体系，但他的全部论述是对哲学，特别是对黑格尔体系中的唯心主义进行的激进批判。他认为哲学必须变成现实，人就不能在只是解释世界，必须即改造世界本身，有改造人对世界的认识。但是尽管马克思本人批判黑格尔的观念论，但其思想却深受黑格尔的特别是辨证论的影响。并将其基本本质作了自然主义的改造。这之后，从19世纪末期到20世纪初期，马克思的哲学思想才在恩格斯、普列汉诺夫和列宁等人的阐释和补充下，为辩证唯物论和历史唯物论，并形成新的世界观。 过渡时期代表人物及论著： 叔本华：《作为意志和表象的世界》 尼采：《权力意志》《悲剧的诞生》《查拉图斯特拉如是说》《希腊悲剧时代的哲学》《论道德的谱系》 马克思：《资本论》《共产党宣言》《关于费尔巴哈的提纲》《1844年经济学哲学手稿》 ⑦现代哲学-20世纪进入20世纪，西方哲学上主流有两条： 一、由弗雷格、罗素创立的，并以维特根斯坦为主的分析哲学（04.分析哲学）。它把哲学问题变成语言分析问题，由此产生了逻辑经验主义或逻辑实证主义以及其他语言分析相关的哲学派系。 二、由胡塞尔创立的现象学发展起来，以海德格尔为主的存在主义。它把哲学问题变成对个人生存状态的反思，由此产生了解释学。 附表-德意志古典哲学~过渡时期~现代哲学代表人物： 时代 理论 人物 流派 工业革命 唯心主义 康德（1724~1804） 德意志古典哲学 客观唯心主义 黑格尔（1770~1831） 德意志古典哲学 唯意志主义 叔本华（1788~1860） 欧陆哲学 政治革命 唯意志主义 尼采（1844~1900） 欧陆哲学 唯物主义 费尔巴哈（1804~1872） 唯物主义 马克思（1818~1883） 一战二战 逻辑实证主义 弗雷格（1848~1925） 分析哲学 逻辑实证主义 罗素（1872~1970） 分析哲学 逻辑实证主义 维特根斯坦（1889~1951） 分析哲学 存在主义 海德格尔（1889~1976） 存在主义 萨特（1905~1980） 存在主义 加缪（1913~1960）","categories":[{"name":"61.Philosophy","slug":"61-Philosophy","permalink":"https://beefyheisenberg.github.io/categories/61-Philosophy/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://beefyheisenberg.github.io/tags/哲学/"},{"name":"哲学史","slug":"哲学史","permalink":"https://beefyheisenberg.github.io/tags/哲学史/"}]},{"title":"01.哲学简介","slug":"61.Philosophy/01.哲学简介","date":"2024-01-24T01:27:53.704Z","updated":"2024-01-24T01:27:53.705Z","comments":true,"path":"61.Philosophy/01.哲学简介/","link":"","permalink":"https://beefyheisenberg.github.io/61.Philosophy/01.哲学简介/","excerpt":"哲学简介 大部分哲学研究的基本内容可以归纳为本体论认识论和方法论。本体论探寻的是这个世界最根本的东西是什么，WHAT；认识论探究的是人的意识如何理解这个世界，WHY；方法论探讨的是人的意识如何作用于世界，HOW。作用于个人的话，那就是门卫三问，你是谁，从哪里来，到哪里去。 以下参考自: 哲学 - 维基百科，自由的百科全书 词源英语词语Philosophy（拉丁语：philosophia）源于古希腊语中的φιλοσοφία，意思为“爱智慧”，有时也译为“智慧的朋友”，该词由φίλος（philos，爱）的派生词φιλεῖν（Philein，去爱）和σοφία（Sophia，智慧）组合而成。一般认为，古希腊思想家毕达哥拉斯最先在著作中引入“哲学家”和“哲学”这两个术语。","text":"哲学简介 大部分哲学研究的基本内容可以归纳为本体论认识论和方法论。本体论探寻的是这个世界最根本的东西是什么，WHAT；认识论探究的是人的意识如何理解这个世界，WHY；方法论探讨的是人的意识如何作用于世界，HOW。作用于个人的话，那就是门卫三问，你是谁，从哪里来，到哪里去。 以下参考自: 哲学 - 维基百科，自由的百科全书 词源英语词语Philosophy（拉丁语：philosophia）源于古希腊语中的φιλοσοφία，意思为“爱智慧”，有时也译为“智慧的朋友”，该词由φίλος（philos，爱）的派生词φιλεῖν（Philein，去爱）和σοφία（Sophia，智慧）组合而成。一般认为，古希腊思想家毕达哥拉斯最先在著作中引入“哲学家”和“哲学”这两个术语。 “哲”一词在中国起源很早，如“孔门十哲”，“古圣先哲”等词，“哲”或“哲人”，专指那些善于思辨，学问精深者，即西方近世“哲学家”，“思想家”之谓。在《易经》当中已经开始讨论哲学问题，形而上学的中文名称取自《易经·系辞上传》“形而上者谓之道，形而下者谓之器”一语。1874年，日本启蒙家西周，在《百一新论》中首先用汉文“哲学”来翻译philosophy一词 哲学是什么对哲学的主题亦存在许多看法。一些人认为哲学是对问题本身过程的审查；另外一些人则认为实质上存在着哲学必须去回答的哲学命题。 哲学所涉及的研究范畴是其它学科的总和，它给出对世界本质的解释，在很大程度上影响着接受者的世界观。 哲学是研究范畴及其相互关系的一门学问。范畴涉及到一门学科的最基本研究对象、概念和内容，哲学具有一般方法论的功能。 哲学和其他承述问题方法的差异是有批判性的、有条理的方法以及以理性为基础的辩论。 后现代主义把哲学定义为创造概念的学术。 研究基础古希腊哲学家透过问问题来进行哲学实践，他们所提的问题大概可以归类为三类，这三类问题分别形成了哲学的基础学科——分别是 形而上学、伦理学、认识论（或知识论） 哲学基本问题所谓 哲学基本问题 是一个马克思主义哲学中的术语，又称哲学根本问题或哲学最高问题。恩格斯于1886年在《费尔巴哈与德国古典哲学的终结》中，第一次明确提出全部哲学的基本问题 “全部哲学,特别是近代哲学的重大的基本问题，是思维和存在的关系问题。”。他认为哲学的基本问题有两个方面： 思维和存在的第一性问题，即何者为本原的问题； 思维和存在的同一性问题，即思维能否正确认识存在的问题。 换言之，就是意识和物质之间的关系问题，根据对这个问题的不同回答而形成唯心主义哲学和唯物主义哲学两大对立派别。 哲学分支哲学家对哲学的不同理解，遂形成了很多不同的 主要分支： 形而上学：（英语：Metaphysics）是指研究存在和事物本质的学问。形而上学是哲学研究中的一个范畴，被视为“第一哲学”和“哲学的基本问题”。它指通过理性的推理和逻辑去研究不能直接透过感知所得到答案的问题，它是人类理性对于事物最普遍的面相和终极的原因的探索的一门学科。 形而上学的主要问题包括：根本上有什么存在？（What is ultimately there?）它是什么样的？（What is it like?） 逻辑学：怎样产生正确的思想？我什么时候能够确定的说一个东西没有意义？ 怎样批判的思考复杂的争论？ 知识论：知识论是探讨知识的本质、起源和范围的一个哲学分支。 世界可以被认知么？我们怎么确定我们知道？我们怎知道别的思维存在？ 伦理学/价值论： （英语：Ethics 或 Moral Philosophy）也称为道德哲学或道德学，是对人类道德生活进行系统性思考和研究的学科；在此，“道德”被定义为一群人或一种文化所认可的所有行为准则。伦理学试图从理论层面建构一种指导行为的法则体系，并且对其进行严格的评判。 美学： （英语：aesthetics），是以对美的本质及其意义的研究为主题的学科。 什么是艺术？什么是美？任何事情都是美的么？品位有没有标准？艺术是有含义的么？如果是，它有什么含义。什么是好的艺术？艺术有目的么，还是“为了艺术而 艺术”？我们和艺术有什么联系？艺术怎样影响我们？有些艺术是否不道德？艺术有极限么？艺术会腐蚀社会么？会改良社会么？艺术家真的知道他们作品的内容 么？比如说，一个演员演美国总统，他会知道做总统相关的所有的事情么？艺术都是模仿么？在模仿过程中会有什么损失或获得么？所有的东西都是原创的么？ 主题:哲学/分支 - 维基百科，自由的百科全书 哲学历史=&gt; 02.西方哲学史","categories":[{"name":"61.Philosophy","slug":"61-Philosophy","permalink":"https://beefyheisenberg.github.io/categories/61-Philosophy/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"https://beefyheisenberg.github.io/tags/哲学/"},{"name":"哲学史","slug":"哲学史","permalink":"https://beefyheisenberg.github.io/tags/哲学史/"}]},{"title":"户外露营装备","slug":"54.Trips-and-Exploration/户外露营装备","date":"2024-01-24T01:27:53.700Z","updated":"2024-01-24T01:27:53.700Z","comments":true,"path":"54.Trips-and-Exploration/户外露营装备/","link":"","permalink":"https://beefyheisenberg.github.io/54.Trips-and-Exploration/户外露营装备/","excerpt":"户外野营的神级装备有哪些？ - 知乎 户外不完全吃饱指南 - 少数派 雪拉杯我们常说的雪拉杯或者塞拉杯，全称是 Sierra cup，是美国十分著名的户外环境组织雪拉俱乐部(Sierra Club)的周边产品，其使用最早可以追述到1905年 1、起源","text":"户外野营的神级装备有哪些？ - 知乎 户外不完全吃饱指南 - 少数派 雪拉杯我们常说的雪拉杯或者塞拉杯，全称是 Sierra cup，是美国十分著名的户外环境组织雪拉俱乐部(Sierra Club)的周边产品，其使用最早可以追述到1905年 1、起源 它的起源与加利福尼亚的锡耶拉有关，最早可以追溯到20世纪初，是美国最大、历史最久、最有影响力的草根环境保护组织“塞拉俱乐部”的周边产品。在物资匮乏的年代，“塞拉杯”凭借其低廉的价格、实用性&amp;便携性，在户外界迅速火了起来。如果你是历史迷，那么同样会喜欢这款杯子！ 2、荒野的象征 在鼓励人们去户外的时代，塞拉杯被认为是背包客&amp;攀岩爱好者的“理想之杯”，也得到了普及。随着时代的进步，越来越多的人越来越多的人意识到“保护荒野”的重要性以及其内在价值。 推荐品牌：Cook’n’Escape 克米特椅Kermit Chair “克米特”这个名称最早是由美国户外家具品牌 Kermit Chair 设计的, 最初因为机车爱好者克米特想要设计出可以放在摩托车上, 并可以在篝火旁度过漫长夜晚的椅子 选购 @ref: 克米特椅的众多仿制品牌里，如何选择一张靠谱的? - 知乎","categories":[{"name":"54.Trips-and-Exploration","slug":"54-Trips-and-Exploration","permalink":"https://beefyheisenberg.github.io/categories/54-Trips-and-Exploration/"}],"tags":[]},{"title":"LAME | 阿根廷 / 玩什么","slug":"54.Trips-and-Exploration/LAME.阿根廷","date":"2024-01-24T01:27:53.695Z","updated":"2024-01-24T01:27:53.696Z","comments":true,"path":"54.Trips-and-Exploration/LAME.阿根廷/","link":"","permalink":"https://beefyheisenberg.github.io/54.Trips-and-Exploration/LAME.阿根廷/","excerpt":"","text":"阿根廷的国茶——马黛茶 博尔赫斯： “天堂应该是图书馆的模样”，圣菲大道上的雅典人书店位于大道1860号，由原先的光明剧院改造而成，店内设有博尔赫斯专区，他的处女诗集《布宜诺斯艾利斯的激情》被置放在一个显眼的位置上，仿若诗人独自站立在舞台中央。@ref: 卢桢：在布宜诺斯艾利斯的城市深处，寻找博尔赫斯 博尔赫斯纪念馆：布宜诺斯艾利斯-Adrogue镇 //关于博尔赫斯， @link: [[../64.Novel-and-Poesy/S01.博尔赫斯]]","categories":[{"name":"54.Trips-and-Exploration","slug":"54-Trips-and-Exploration","permalink":"https://beefyheisenberg.github.io/categories/54-Trips-and-Exploration/"}],"tags":[{"name":"城市探索","slug":"城市探索","permalink":"https://beefyheisenberg.github.io/tags/城市探索/"},{"name":"旅行","slug":"旅行","permalink":"https://beefyheisenberg.github.io/tags/旅行/"},{"name":"拉美","slug":"拉美","permalink":"https://beefyheisenberg.github.io/tags/拉美/"}]},{"title":"EURO | 意大利 / 玩什么","slug":"54.Trips-and-Exploration/EURO.意大利","date":"2024-01-24T01:27:53.691Z","updated":"2024-01-24T01:27:53.691Z","comments":true,"path":"54.Trips-and-Exploration/EURO.意大利/","link":"","permalink":"https://beefyheisenberg.github.io/54.Trips-and-Exploration/EURO.意大利/","excerpt":"","text":"意大利的旅游地图-意大利旅游地图(南部欧洲-欧洲)：","categories":[{"name":"54.Trips-and-Exploration","slug":"54-Trips-and-Exploration","permalink":"https://beefyheisenberg.github.io/categories/54-Trips-and-Exploration/"}],"tags":[{"name":"城市探索","slug":"城市探索","permalink":"https://beefyheisenberg.github.io/tags/城市探索/"},{"name":"旅行","slug":"旅行","permalink":"https://beefyheisenberg.github.io/tags/旅行/"},{"name":"欧洲","slug":"欧洲","permalink":"https://beefyheisenberg.github.io/tags/欧洲/"},{"name":"意大利","slug":"意大利","permalink":"https://beefyheisenberg.github.io/tags/意大利/"}]},{"title":"EURO | 俄罗斯 / 玩什么","slug":"54.Trips-and-Exploration/EURO.俄罗斯","date":"2024-01-24T01:27:53.686Z","updated":"2024-01-24T01:27:53.687Z","comments":true,"path":"54.Trips-and-Exploration/EURO.俄罗斯/","link":"","permalink":"https://beefyheisenberg.github.io/54.Trips-and-Exploration/EURO.俄罗斯/","excerpt":"@toc 加里宁格勒（柯尼斯堡大教堂） 莫斯科 彼得堡（冬宫广场、马琳剧院、涅瓦大街、滴血救世主教堂、普希金公寓） 贝加尔湖贝加尔湖位于俄罗斯西伯利亚的南部伊尔库茨克州及布里亚特共和国境内，距蒙古国边界111公里，是全世界最深、蓄水量最大的淡水湖","text":"@toc 加里宁格勒（柯尼斯堡大教堂） 莫斯科 彼得堡（冬宫广场、马琳剧院、涅瓦大街、滴血救世主教堂、普希金公寓） 贝加尔湖贝加尔湖位于俄罗斯西伯利亚的南部伊尔库茨克州及布里亚特共和国境内，距蒙古国边界111公里，是全世界最深、蓄水量最大的淡水湖 最佳旅行时间：11 月至 4 月，可以看蓝冰 @ref: 此生必去 贝加尔湖超强图文攻略_手机新浪网 @link: [[../66.History-and-Politics/通古斯大爆炸]] 柯尼斯堡即如今俄罗斯加里宁格勒州首府加里宁格勒，位于桑比亚半岛南部，由条顿骑士团北方十字军于1255年建立，先后被条顿骑士团国、普鲁士公国和东普鲁士定为首都或首府。柯尼斯堡曾是德国東部的文化中心之一。 1945年柯尼斯堡戰役后，苏联红军占领城市。战后，根据《波茨坦协定》，柯尼斯堡成为苏联领土。1946年，为纪念刚逝世的苏联共产党和苏维埃国家领导人米哈伊尔·加里宁，柯尼斯堡更名为加里宁格勒。 康德是柯尼斯堡最值得骄傲的儿子。然而1724年4月22日清晨5点当他在普列戈利亚河上的克奈普霍夫（德语：Kneiphof）岛（Kneiphof）降生之时，这座城市还尚未设立。直至6月13日，岛上市镇才正式与河北岸的柯尼斯堡老城（德语：Altstadt (Königsberg)）和勒伯尼希特（德语：Löbenicht）并为一处。新城的规模和人口超过了首都柏林，是普鲁士王国最大的城市。康德在这里出生，在这里受教育，学成之后，又在柯尼斯堡大学任教，一直到他1804年去世，他一生都未远离他的故乡，去世之后，他被埋葬在柯尼斯堡的大教堂。这座拥有四百多年历史的大教堂是当地罕见的未遭受战火摧毁的古建筑。 2018年11月27日在俄罗斯加里宁格勒，康德波罗的海联邦大学内的一尊康德（Immanuel Kant）雕像遭人泼上油漆。摄：Vitaly Nevar / TASS via Getty Images@ref: 康德应该算德国人还是俄国人？ - 知乎 俄羅斯加里寧格勒為機場命名辦網上投票，加里寧格勒民間及網絡也掀起「反康德熱潮」: https://theinitium.com/article/20181205-evening-brief/ House of Soviet（也在柯尼斯堡）： 1970开建，一直未完工，这个栋烂尾楼是苏联的粗野主义（Brutalist style）的一个典范，因为外形奇特，像个机器人脑袋，当地人都叫它“被土埋的机器人” @link: [[../63.Culture-and-Arts/Arch.建筑（苏联）]] 圣彼得堡“彼得堡”相同的中文翻译有几座城市： 彼德堡（英语：Peterborough）或译“彼得伯勒”，位于英国英格兰东区域剑桥郡 彼得堡 (北达科他州)（Petersburg），美国北达科他州纳尔逊县的一个市镇 彼得堡縣（Peterborough County），加拿大安大略省的一個地方行政區 圣彼得堡市（俄语：Са́нкт-Петербу́рг，罗马化：Sankt-Peterburg，旧名列宁格勒，是俄罗斯的联邦直辖市，也是西北部联邦管区和列宁格勒州的首府，曾为俄罗斯首都。位于俄罗斯西北部，濒临芬兰湾，涅瓦河流经过市区，为俄罗斯在波罗的海一带的重要港口和军事基地。 圣彼得堡由彼得大帝于1703年5月27日建立，在1712年至1918年期间为俄罗斯帝国的首都，并为帝国三次大革命——第一次俄国革命、俄国二月革命、十月革命的中心。圣彼得堡多次因时空背景而易名：第一次世界大战于1914年爆发后，圣彼得堡为因应当时“去日耳曼化”的风潮而改名为“彼得格勒”（Петрогра́д）；在列宁逝世后又改名为“列宁格勒”（Ленингра́д）。第二次世界大战苏德战争期间，列宁格勒被德军围城封锁长达872天，导致多达150万人死于饥饿，战后该城被授予“英雄城市”称号，并有三个下辖城市被授予“军事荣誉城市”称号——罗蒙诺索夫、克隆斯塔和科尔皮诺。1991年苏联解体后，列宁格勒经过公投决议后，恢复使用圣彼得堡的原名。 ➤ 圣彼得堡市（1）： 阿赫玛托娃文学纪念博物馆（Anna Akhmatova Literary and Memorial Museum）：它成立于1989年，在阿赫马托娃诞辰一百周年之际。博物馆位于喷泉之家（Fountain House）的南楼（丰坦卡河河岸34号）。喷泉之家建于18世纪，是舍列梅捷夫家族的贵族宫殿, 而花园中的南楼建于1845年，由Ieronim Corsini设计。 安娜·阿赫玛托娃，白银时代（Анна Ахматова. Серебряный Век）：是俄罗斯圣彼得堡的一个博物馆，位于该市西南部的阿夫托沃（Avtovo），靠近同名的地铁站阿夫托沃站，专注于安娜·安德烈耶芙娜·阿赫玛托娃，以及其他在俄国文学的白银时代开始写作的20世纪上半叶俄国其他诗人和文学人物的生平与著作。博物馆位于一座普通公寓楼的底层。 @link: [[../64.Novel-and-Poesy/R02.阿赫玛托娃]] ➤ 圣彼得堡市（2）： 《 不存在的白夜 》中提到的冬宫广场、马琳剧院、涅瓦大街、滴血救世主教堂、普希金公寓 许多年后， 面对汹涌的云层 ， 我会想起那天早晨看见涅瓦河冰封的时刻 。那是抵达俄罗斯的次日 ， 我们赶去圣彼得堡国立大学历史系开会 ， 需要从涅瓦大街靠近海军部的住处穿过冬宫广场和瓦西里岛 ， 去到河对岸的门捷列夫街 。 前一天晚上已经在马琳剧院见到一条小运河冻成不自然的粉绿色——其实只是尚未完全冰冻的水面映出剧院外墙的色彩 ， 像个宏伟而住满肺科病人的翡翠宫 。 剧院内部则是一座金黄的琥珀殿 ， 一个四处渗动着半透明蜂蜜的巨大蜂房 。我们在那里看了现代芭蕾 Camera Obscura ， 据说是根据纳博科夫 《 黑暗中的笑声 》 改编 。 彼得堡的芭蕾果然是这世上的珍宝 ， 只感到舞者的肌肉纷纷羽化成诗 ， 看不见的水禽向人类学习着飞翔 ， 而紫裙舞姬的足尖每次点地都犹如踩在我心上 ， 牵起生理性的疼痛 。…而这些都不重要 ， 那令人心悸的实际上是人类肢体与音乐语言之间某种近乎梵我合一的内在一体性 ， 这种一体性写在我们的基因里 ， 却在日常的疲惫 、 散乱 、 松懈中被我们损毁 。 芭蕾舞者正是以一种惊人的反刍能力让我们看到我们曾所应是 ， 那个人人都行走于大地如同阿佛洛狄特初次升起于群贝与泡沫的黄金时代 。 人类曾同时是鹰 ， 是鹤 ， 是孔雀 、 海豚和豹子 ， 现在却只是人 ， 在最好的情况下 。 即使羽片般的轻盈脱胎自厚重的血痂 ， 马琳的芭蕾舞台是映照我们的失落的一面圆镜 。但现在是融雪日的清晨 ， 人间的悲剧与喜剧齐齐退场 ， 寂静的时刻即将到来 ， 巨大的浮冰彼此撞击着 ， 缝隙间露出墨色河水 ， 昭告一种简洁而叵测的命运 。 一排鸭子如雕像般蹲伏在冰面上 ， 似在哀悼着水中生活的终结 。 黑与白 ， 除此之外就是不远处冬宫影影绰绰的淡绿色 ， 到了第二天 ， 连这淡绿也在忽然笼罩全城的浓雾中消隐 ， 水天相接于一片凛然的白 。 站在桥畔眺望涅瓦河 ， 我想象在这些几何形状的碎冰上跳房子 ， 或是谨慎地一步一步走入看起来并不遥远的太虚幻境 。 消失的诱惑如此真实 ， 人若低头 ， 就不肯呼救 。… 再没有什么比救世主滴血大教堂内部更是这种密集美学的完整化身 。 仿佛在某个神秘的时刻 ， 星空下所有的天使齐齐鼓动羽翼 ， 发出幽邃的叹息 ， 深蓝的穹窿和墙壁无一处不被这种叹息凝固而成的镶嵌画填满 。 东正教圣像传统与俄罗斯现代装饰美学糅合的结果是这座教堂生理性的美会令一些人心生厌恶 （ 就如他们厌恶新艺术运动以及穆哈的画）：就一座宗教建筑而言它太过耽美了 。 而我在其中独自逡巡了将近两个时辰 ， 无法比里尔克说得更好——美不过是我们恰好能承受的恐怖的开端1 。…但我毕竟找到了普希金的公寓 ， 并在玻璃柜里看到了娜塔莉亚的缎子舞鞋 ， 浅金色的 ， 放在一块酒红天鹅绒上 。 在那所公寓博物馆里我还看见了其他东西：那个法国纨绔发来的挑衅书 ， 那场决斗中普希金所使用的枪支 ， 他最后一次离开寓所时穿过的木门 ， 那天摊开在会客室书桌上的诗稿 ， 决斗负伤后他被抬回家中所躺卧的沙发 ， 墙上的煤油灯……整栋公寓里我最爱他的书房 。 被三面墙的桃花心木书架环绕却还不至于密恐 ， 书架塞得满满且顶天立地却还不至使人压抑得无法动笔 ， 座钟 、 手杖 、 墙上的剑 ， 书桌上友人赠送的小黑人墨水瓶 。 书桌是真正可以写作的书桌 ， 足够大并且杂乱无章 ， 是我能感觉舒服的工作环境 ， 而我自己的书房多少也有点奔这个方向而去 。 我知道书桌边的普希金雌雄同体 ， 无需枪支就能决绝有力 ， 无需死亡与悲剧就已获得绝对的寂静 。 莫斯科 国立亚历山大·普希金博物馆，俄罗斯莫斯科 – HiSoUR 文化 艺术 历史 人文 国家普希金博物馆（俄语：Всероссийский музей А. С. Пушкина，罗马化：Vsyerossiiskii muzei A. S. Pushkina - 英语：All-Russian Museum of A. S. Pushkin；法语：Musée national Pouchkine）是俄罗斯圣彼得堡的一个博物馆建筑群，献给亚历山大·谢尔盖耶维奇·普希金和其他俄罗斯诗人加甫里尔·杰尔查文以及尼古拉·阿列克谢耶维奇·涅克拉索夫，五个分馆分别位于圣彼得堡市内和附近的普希金镇。不要将其与位于莫斯科的普希金造型艺术博物馆相混淆。 俄式洗浴（Banya） Wiki：https://en.wikipedia.org/wiki/Banya_(sauna) 像一个真正的战斗民族一样洗个战斗澡 - 天才张 1.出自里尔克：《杜伊诺哀歌》：哀歌之一 ↩","categories":[{"name":"54.Trips-and-Exploration","slug":"54-Trips-and-Exploration","permalink":"https://beefyheisenberg.github.io/categories/54-Trips-and-Exploration/"}],"tags":[{"name":"城市探索","slug":"城市探索","permalink":"https://beefyheisenberg.github.io/tags/城市探索/"},{"name":"旅行","slug":"旅行","permalink":"https://beefyheisenberg.github.io/tags/旅行/"},{"name":"俄罗斯","slug":"俄罗斯","permalink":"https://beefyheisenberg.github.io/tags/俄罗斯/"}]},{"title":"EURO | 荷兰 / 玩什么","slug":"54.Trips-and-Exploration/EURO.荷兰","date":"2024-01-24T01:27:53.682Z","updated":"2024-01-24T01:27:53.682Z","comments":true,"path":"54.Trips-and-Exploration/EURO.荷兰/","link":"","permalink":"https://beefyheisenberg.github.io/54.Trips-and-Exploration/EURO.荷兰/","excerpt":"@inbox: 在荷兰生活是种什么样的体验？ - 知乎 荷兰是个怎样的国家？ - 知乎 定居荷兰是一种什么样的体验？ - 知乎 阿姆斯特丹 Van Gogh Museum：梵高美术馆有4层，主要展出的是梵高一生中各个时期的主要作品，作品的数量占到梵高所有作品总量的1/4，《向日葵》、《吃土豆的人》，《盛开的杏树》和多幅梵高自画像都在这里，此外还收藏梵高的素描，以及其与弟弟提奥来往的书信，是世界上最大的一座梵高博物馆 从中央火车站乘2/5路有轨电车，在Van Baerlestraat站 Rembrandt House：伦勃朗故居博物馆 - 每日环球展览 - iMuseum 犹太区： 犹太历史博物馆（JoodsHistorisch Museum）：其中有一个部分是斯宾诺莎（Baruch Spinoza） 滑铁卢广场（Waterlooplein）的跳蚤市场","text":"@inbox: 在荷兰生活是种什么样的体验？ - 知乎 荷兰是个怎样的国家？ - 知乎 定居荷兰是一种什么样的体验？ - 知乎 阿姆斯特丹 Van Gogh Museum：梵高美术馆有4层，主要展出的是梵高一生中各个时期的主要作品，作品的数量占到梵高所有作品总量的1/4，《向日葵》、《吃土豆的人》，《盛开的杏树》和多幅梵高自画像都在这里，此外还收藏梵高的素描，以及其与弟弟提奥来往的书信，是世界上最大的一座梵高博物馆 从中央火车站乘2/5路有轨电车，在Van Baerlestraat站 Rembrandt House：伦勃朗故居博物馆 - 每日环球展览 - iMuseum 犹太区： 犹太历史博物馆（JoodsHistorisch Museum）：其中有一个部分是斯宾诺莎（Baruch Spinoza） 滑铁卢广场（Waterlooplein）的跳蚤市场 还有蘑菇 在梵高博物馆门口吃迷幻松露 - 知乎 梵高、蘑菇与Ferdy，在荷兰的一些感悟 Nature解答关于梵高的百年生物学谜题 - 生物通 超ㄎㄧㄤ体验：去荷兰一定要吃的「 迷幻松露」！ - Klook 客路部落格 「 迷幻松露」通常被大家称为「蘑菇」，但它其实不是真正意义上的mushroom。但它和蘑菇事实上没有本质区别，两者关系简单可以用几点概括： 松露是由霉菌形成的菌核，而在这些结成块状的菌核上，可以生长出蘑菇。所以可以说蘑菇是松露的果实。 迷幻松露含有的致幻成分和蘑菇本质上是一样的，只是蘑菇的致幻成分浓度更高，效果也更强。 在荷兰，其交易是违法的，却可以合法经营。不过鉴于松露就是蘑菇出土前的菌核，也就是说松露养一养就可以长出蘑菇，所以Smartshops（出售各类合法迷幻物品的商店）也出售所谓的Growbox。通过Growbox可以自己培养出迷幻蘑菇。但是培养出蘑菇后，就不能再进行交易。 荷兰，吃迷幻蘑菇上飞机","categories":[{"name":"54.Trips-and-Exploration","slug":"54-Trips-and-Exploration","permalink":"https://beefyheisenberg.github.io/categories/54-Trips-and-Exploration/"}],"tags":[{"name":"城市探索","slug":"城市探索","permalink":"https://beefyheisenberg.github.io/tags/城市探索/"},{"name":"旅行","slug":"旅行","permalink":"https://beefyheisenberg.github.io/tags/旅行/"},{"name":"欧洲","slug":"欧洲","permalink":"https://beefyheisenberg.github.io/tags/欧洲/"}]},{"title":"EURO | 希腊 / 玩什么","slug":"54.Trips-and-Exploration/EURO.希腊","date":"2024-01-24T01:27:53.677Z","updated":"2024-01-24T01:27:53.678Z","comments":true,"path":"54.Trips-and-Exploration/EURO.希腊/","link":"","permalink":"https://beefyheisenberg.github.io/54.Trips-and-Exploration/EURO.希腊/","excerpt":"雅典雅典卫城（Ακρόπολη）是希腊最杰出的古建筑群，为宗教政治的中心地。现存的主要建筑有山门、帕特农神庙、伊瑞克提翁神庙等。这些古建筑都是人类遗产和建筑精品，在建筑学史上具有重要地位 从雅典各个方向都可以看到耸立于雅典卫城山上顶端的帕特农神庙，据说远古这里曾供奉著高达10m的雅典娜神像，是举世闻名的古代七大奇观之一。帕特农神庙建于公元前447年，是著名建筑师和雕刻家菲迪亚斯的杰作 奥林匹亚宙斯神庙位于雅典卫城东南方500米，始建于公元前515年，但直到公元2世纪哈德良皇帝统治时期才兴建完成，是当时希腊规模最大的神庙。据说原有104根壮观的列柱，目前仅存15根。","text":"雅典雅典卫城（Ακρόπολη）是希腊最杰出的古建筑群，为宗教政治的中心地。现存的主要建筑有山门、帕特农神庙、伊瑞克提翁神庙等。这些古建筑都是人类遗产和建筑精品，在建筑学史上具有重要地位 从雅典各个方向都可以看到耸立于雅典卫城山上顶端的帕特农神庙，据说远古这里曾供奉著高达10m的雅典娜神像，是举世闻名的古代七大奇观之一。帕特农神庙建于公元前447年，是著名建筑师和雕刻家菲迪亚斯的杰作 奥林匹亚宙斯神庙位于雅典卫城东南方500米，始建于公元前515年，但直到公元2世纪哈德良皇帝统治时期才兴建完成，是当时希腊规模最大的神庙。据说原有104根壮观的列柱，目前仅存15根。 奥林匹亚奥林匹亚（希腊语：Ολυμπία）是希腊南部平原的一个城市，位于伯罗奔尼撒的西北。它是古代厄利斯用以祭拜宙斯的宗教中心，又是古代奥林匹克运动会的遗址。其中由菲迪亚斯所作的奥林匹亚宙斯神像是世界七大奇迹之一。（@link [[../66.History-and-Politics/伯罗奔尼撒战争|伯罗奔尼撒战争]]） 赫拉神庙位于阿尔提斯的北区，它是圣地内最老的围柱式神庙和希腊最早的多立克式神庙之一。 宙斯神庙，其风格是科林斯式神庙。 奥林匹亚圣域格局图： 克里特据荷马史诗所记说，“在深红葡萄酒色的海中，是一片美丽，富庶的土地，四面环水，岛上的人多得数不清，城市有九十个”。岛屿地处埃及、希腊、意大利及腓尼基之间，自古为战略要冲和贸易重镇，岛上有米诺斯王宫等遗迹。","categories":[{"name":"54.Trips-and-Exploration","slug":"54-Trips-and-Exploration","permalink":"https://beefyheisenberg.github.io/categories/54-Trips-and-Exploration/"}],"tags":[{"name":"城市探索","slug":"城市探索","permalink":"https://beefyheisenberg.github.io/tags/城市探索/"},{"name":"旅行","slug":"旅行","permalink":"https://beefyheisenberg.github.io/tags/旅行/"},{"name":"欧洲","slug":"欧洲","permalink":"https://beefyheisenberg.github.io/tags/欧洲/"}]},{"title":"CN | 国内自驾路线","slug":"54.Trips-and-Exploration/CN.国内自驾路线","date":"2024-01-24T01:27:53.673Z","updated":"2024-01-24T01:27:53.673Z","comments":true,"path":"54.Trips-and-Exploration/CN.国内自驾路线/","link":"","permalink":"https://beefyheisenberg.github.io/54.Trips-and-Exploration/CN.国内自驾路线/","excerpt":"","text":"塞罕坝林区当年名噪一时的三北防护林工程，现在怎么样了？ - 小朋友的回答 - 知乎https://www.zhihu.com/question/37505597/answer/2690164364","categories":[{"name":"Drafts","slug":"Drafts","permalink":"https://beefyheisenberg.github.io/categories/Drafts/"}],"tags":[]},{"title":"CN | 香港 / 玩什么","slug":"54.Trips-and-Exploration/CN.香港","date":"2024-01-24T01:27:53.669Z","updated":"2024-01-24T01:27:53.669Z","comments":true,"path":"54.Trips-and-Exploration/CN.香港/","link":"","permalink":"https://beefyheisenberg.github.io/54.Trips-and-Exploration/CN.香港/","excerpt":"","text":"香港有哪些经典的城市赏景地？ - 知乎 Instagram网红才不会告诉你的香港十大建筑拍摄地 - 知乎 祖尧村, 荔景 坪石邨，九龙 西环邨，坚尼地城 彩虹邨，九龙 爱民邨，九龙 励德邨，铜锣湾 华富邨，薄扶林 百福花园，北角 坚尼地城","categories":[{"name":"54.Trips-and-Exploration","slug":"54-Trips-and-Exploration","permalink":"https://beefyheisenberg.github.io/categories/54-Trips-and-Exploration/"}],"tags":[{"name":"城市探索","slug":"城市探索","permalink":"https://beefyheisenberg.github.io/tags/城市探索/"},{"name":"旅行","slug":"旅行","permalink":"https://beefyheisenberg.github.io/tags/旅行/"},{"name":"HongKong","slug":"HongKong","permalink":"https://beefyheisenberg.github.io/tags/HongKong/"}]},{"title":"CN | 天津 / 玩什么","slug":"54.Trips-and-Exploration/CN.天津","date":"2024-01-24T01:27:53.664Z","updated":"2024-01-24T01:27:53.665Z","comments":true,"path":"54.Trips-and-Exploration/CN.天津/","link":"","permalink":"https://beefyheisenberg.github.io/54.Trips-and-Exploration/CN.天津/","excerpt":"@link: [[../63.Culture-and-Arts/City Walk|City Walk]] 天津｜从北到南走进一本城市编年史 - 知乎 天津有什么好玩的地方? - 知乎 在天津一个人一天去哪玩比较好？ - 知乎 天津市历代地名牌考（上） - 知乎 天津有哪些深藏不露的餐馆？ - 知乎 地道的天津菜馆有哪些推荐？ - 知乎 玉泉饭庄的白崩鱼丁、白汁鱼肚、软溜鱼扇、扒牛肉条。 卫鼎轩和天泰轩的罾蹦鲤鱼（全国获奖的津菜）。 燕春楼的芫爆散丹、红烧牛尾、煎烹大虾。 来顺成的羊尾。 河北区 📍王串场","text":"@link: [[../63.Culture-and-Arts/City Walk|City Walk]] 天津｜从北到南走进一本城市编年史 - 知乎 天津有什么好玩的地方? - 知乎 在天津一个人一天去哪玩比较好？ - 知乎 天津市历代地名牌考（上） - 知乎 天津有哪些深藏不露的餐馆？ - 知乎 地道的天津菜馆有哪些推荐？ - 知乎 玉泉饭庄的白崩鱼丁、白汁鱼肚、软溜鱼扇、扒牛肉条。 卫鼎轩和天泰轩的罾蹦鲤鱼（全国获奖的津菜）。 燕春楼的芫爆散丹、红烧牛尾、煎烹大虾。 来顺成的羊尾。 河北区 📍王串场@ref: 有一种回忆，叫王串场 - 知乎 王串场，大致是由真理道、金钟河大街、红星路和新阔路这四条道围成的区域。 “开”意指“开洼地带”，天津“四开”分别指： “南开”，就是过去老城厢西门以南的开洼地，差不多是今天南马路和南门外大街相交的西南方向区域，“西广开”则是南开再往西的开拓地。 “北开”，就是红桥区河北大街、原北营门东马路交汇的开阔地，今河海花园、瞰海一带； “西开”，就是今天西开教堂以西一带的开阔地。 有人认为老城以东就是海河，往东走就掉河里头了，所以天津没有“东开”。但实际上天津不但有东开，而且它今天的知名度不比前三个地方小，这个东开，就是河北区王串场。 在今王串场区域东北角有一片楼叫“开城里”，对过儿就是七十八中。因为前文提到，王串场的最初的人口聚集地就在东北部，所以我一开始认为，这个“开城”是以前延续下来的地名，因为“开城”从字面意思看，可以理解为东开地区形成人口聚落的开始。后来才知道满不是这么回事，原来现在的王串场一带的20多个居民区的名字，字头字尾连起来是首诗： 津开城垣焕玉容，彩环盛宇萃华屏；花芳景秀茵春艳，泉清水明溪波莹。 分别是开城里、城垣里、焕玉里、容彩里、彩环里… 其实天津以诗为名的地方不少，比如福桥里、贵桥里的“桥”系列连起来就是“福贵乐康宁观览”；华苑各小区名字连起来就是“安居莹碧绮，天地日长久”等等。 @ref: 谭汝为-《天津地名考》 系列地名就是指相关联的配套成龙的地名。例如河北区天纬路、地纬路、宇纬路、宙纬路、日纬路、月纬路、辰纬路、宿纬路……等，排序出于《千字文》：“天地玄皇，宇宙洪荒。日月盈昃，辰宿列张……” 再如1945～1949年，河北区以建国道、民主道、进步道、光复道、自由道、博爱道、民生路、民权路、民族路等，以“福寿庆永平”———福安街、寿安街、庆安街、永安街、平安街等系列街名取代原租界旧名。 近年来，随着城市建设事业的迅猛发展，新建的居民小区层出不穷，如何为这些星罗棋布的居民区和鳞次栉比的广厦楼群命名，已成为天津市地名委员会和专家们殚精竭虑统筹构思的一项系统工程。新建居住区系列命名，大体有三种方法： (一)以某个有代表性的单音节词为基础，形成系列，例如： 小海地居住区以“山”命名———微山里、骊山里、华山里、泰山里、天山里、庐山里等；（小海地在河西区东南部，传古为小片退海之地，故名） 鞍山西道居住区以“湖”命名———凤湖里、景湖里、光湖里、府湖里、美湖里、学湖里等； 民权门居住区以“江”命名———靖江里、义江里、开江里、满江里等； 天拖南、王顶堤居住区以“金”命名———金环里、金宇里、金云里、金堤里、金冠里、金厦里等； 铁东路街以“贤”字命名———圣贤里、贵贤里、爱贤里、颂贤里、慕贤里、师贤里、任贤里、招贤里、智贤公寓； 宁园街以“园”字命名———舒园里、润园里、竞园里、赛园里、滨园里、皓园里、珍园里、汇园里、芬园里、芳园里、花园里、柳园里等。 河西区的陵水道、延水道、双水道、三水道、泗水道、浯水道、渌水道、淇水道分别对应着0、1、2、3、4、5、6、7 (二)以一句诗或一首诗组成系列地名，例如： 分别用“福贵乐康宁观览”诗句的字为首字，第二个字固定为“桥”字组成———福桥里、贵桥里、乐桥里、康桥里、宁桥里、观桥里、览桥里。 王串场街以“津开城垣焕玉容，彩环盛宇萃华屏；花芳景秀茵春艳，泉清水明溪波莹”这首诗为基础，连绵相衔组成20多个新地名———津开里、开城里、城垣里、垣焕里、焕玉公寓、玉容花园、容彩里、彩环里、环盛里、盛宇里、宇萃里、萃华里、华屏里、屏花里、花芳里、芳景里、景秀里、茵春里、春艳里、艳泉里、清水园、水明里、明溪里、溪波里、波莹公寓、莹津里。 (三)利用老地名首字的谐音换字命名，例如： 河北区新开河街原白庙村1982年地名普查因重名，把“白”谐音为“百”，废弃旧名更为———百盛里、百朋里、百兴里、百乐里、百庆里、百寿里、百康里、百荣里、百贤里、百祥里等； 原席厂村，把“席”谐音为“喜”，废弃旧名更为———喜同里、喜康里、喜丰里、喜盈里、喜爱里、喜跃里、喜庆里等，又连缀为“同康丰盈爱跃庆”的诗句。 这些命名蕴意典雅，读音顺畅，易读易记，且充盈着文心雅趣，令人神往。 觉悟社天津觉悟社纪念馆位于天津市河北区宙纬路三马路三戒里，系依托觉悟社旧址而建，旧址是由7间青砖木结构平房组成的小宅院，1984年9月16日对外开放，1986年邓颖超专程来馆视察并题写匾额，为天津市文物保护单位和爱国主义教育基地。 觉悟社是五四运动时期天津的青年学生团体，1919年9月16日成立，领导人物有周恩来等，其核心人员为天津学生联合会和天津女界爱国同志会的20名男女青年，成员对外废除姓名，用拈阄的方式确定代号和化名。觉悟社团结进步青年开展反封建、反帝国主义活动、改造社会挽救祖国的斗争活动，积极学习和传播马克思主义，成为中国共产党成立前的重要革命组织之一。1920年底，觉悟社集体活动结束，组织不复存在 扶轮中学民国七年（1918 年）二月，京奉、津浦、京汉、京绥四路员工联合组建的“铁路同人教育会”在北京成立。交通部次长（时任交通总长曹汝霖）叶恭绰⑴为会长、交通部路政司司长 关庚麟⑵为副会长，徐世章⑶（时任交通部次长）、詹天佑⑷（时任总工程师）、施肇曾⑸（时任交通银行董事长）、周自齐⑹（前交通总长）、徐廷爵⑺、王景春 ⑻、任凤苞⑼、丁士源⑽、陈梦雄、孙鸿哲(1932年任唐山工程学院院长，西南交通大学)、方仁元、龙学竞⑾为董事。随即以“扶轮公学”为统一校名 在“四路” ⑿沿线筹建员工子弟学校。 是年夏，铁路同人教育会借用位于吕纬路与五马路交口处属于津浦铁路局的一块地基用于创建子弟中学，即天津扶轮公学第一中学。这是 我国铁路创办最早的一所员工子弟中学。聘请毕业于北京高等师范学堂的顾宝埏（赞延）先生任校长兼算术教员，主持建校工作；同年10月，学校面向“四路”员 工子弟招生，首届招收新生2个班共80人（男生），聘请职员兼教员11人，11月4日开学，实行“壬子癸丑学制”（旧四年制中学），前两年为普通科，后两 年分为文、理、商等科。经投标，由天津振元木器场承建的两座校舍楼分别于民国八年（1919年）和十年（1921年）建成投入使用，南楼为教学楼，北楼为 办公兼宿舍楼，两楼均用青石条砌成，仍为该校标志性建筑。两楼于1993年被天津市河北区认定为文物保护单位。 大悲禅院@ref： 天津地名故事丨大悲禅院 - 知乎 大悲禅院坐落河北区天纬路，是天津现存规模最大、历史最为悠久的佛门寺院。 大悲院始建于清代顺治末年（一说建于明代），因寺内供奉一尊高达3.6米的“大慈大悲救苦救难的观世音菩萨”而得“大悲”之名。 随着时代的变迁，大悲院几度沉浮。光绪二十六年（1900年），八国联军攻占天津，寺院被洗劫；民国时期又长期被法院、消防队、警察所占用。以至于到了解放前，只剩下了现在的西院。 1942年，大悲院扩建，在原有寺院的东侧陆续修建天王殿、大雄宝殿、大悲殿、东西配殿等建筑，连同园林景观等配套设施总计8000余平方米。 1945年，大悲院由南京请来了唐代高僧玄奘法师顶骨舍利，专设纪念堂作为镇寺之宝供奉。但在1956年，为了促进中印两国人民的友好交往，在印度政府的请求下，玄奘法师顶骨舍利重新回到了印度那烂陀寺遗址。 解放以后，大悲院曾在政府的协助下又进行过一次修缮，之后由天津的甲骨文专家王襄先生，书写了篆文的“古剎大悲禅院”，镌刻在寺院山门之上。 上世纪6、70年代，由于中国正经历特殊时期，大悲禅院也未能幸免，遭到了前所未有的破坏，寺庙内的文物被洗劫一空，损失惨重，之后76年的唐山大地震，寺院建筑又倒塌了一部分。所以直到1980年，大悲院才开始进行修复工作，并重塑所有佛像。 大悲院看似是一座寺庙，但实际上其不亚于一座小型博物馆，比如在大雄宝殿中供奉的佛祖金身像为明代所铸造，通高五米，重达六吨，是国家二级文物。 除此之外值得一提的是1956年在寺内设立的弘一大师（李叔同）纪念堂。李叔同生于天津，通古博今，专攻音乐和绘画，创办了中国第一个话剧社“春柳社”，主演了《茶花女》等名剧。后来他在杭州虎跑寺剃度为僧，并南下福建泉州，穷其一生潜心钻研佛经戒律，成为了一代宗师。如果您没听说过他，那您肯定听过一首歌叫《送别》。“长亭外，古道边，芳草碧连天。晚风拂柳笛声残，夕阳山外山。”这首传唱度十分高的歌曲，就是弘一法师所作 小关大街@ref: 天津河北区“小关大街”：消失的700年老街 - 知乎 金钢桥金钢桥是中国天津市连接红桥区与河北区的一座桥梁建筑。始建于1996年，长600米，宽15米，为双层拱桥。前身为始建于1903年的开启式铁桥。目前，金钢桥坐落在中山路南端、横跨海河之上的金钢桥是天津市内重要的交通桥梁之一。 金钢桥的前身为“窑洼木浮桥”，1901年，袁世凯任直隶总督兼北洋通商大臣之后，于1902年将原驻保定的直隶总督衙门搬移至天津并兴建河北新区。1903年，为了加强河北新区与海河对岸天津老城的沟通和联系，原木浮桥被改建为双叶承梁式钢架桥，并称其为“金钢桥”，桥长76.20米，宽为6.45米，中跨长为11.60米，桥身下部分为三孔。桥台用条石砌筑，桥面铺设有木板，可开启。后来，该桥因不能负重并于1922年在桥下游18米处建另建成一座大型钢梁双叶立转开启式新桥，1924年，新金刚桥竣工。 新金刚桥的设计和材料供应都为美国施特劳开启桥公司承包，天津大昌实业公司主持安装。桥长85.80米，宽为17米，两旁设有宽2米的人行道。新金刚桥的桥墩距桥面24.4米，为钢筋混凝土结构，桥的上部结构为上承式钢桁架，桥基部分设有气压况箱，桥墩和桥台部分为钢筋混凝土结构。桥的两边跨和中跨分别为固定桥孔和双叶立抟开启孔。此外，作为开启桥，新金刚桥可以从中间用电力操纵吊起开成八字形。建新金钢桥之后，旧金钢桥成便桥并于1927年因待修停用。日占天津时期的1942年，日军将金刚桥的桥梁拆除，仅剩下原有的四座桥墩。 中华人民共和国成立后，1981年，天津市人民政府利用原有桥墩建成钢架便桥。1996年5月1日，天津市人民政府因金刚桥成为危桥的缘由决定对其进行改建。同年11月20日，新双层拱桥建成并沿用其名 这张老明信片反映的是20年代第二代金钢桥建成不久的情景： 万国桥（解放桥） 望海楼教堂 意大利风情街上世纪二十年代的意式风情街: 和平区 📍小白楼@ref: 天津的昔日小白楼 小白楼（天津市标志性地标之一）_百度百科 地标建筑“小白楼”究竟在哪里其说不一，“小白楼地区”之范围又如何界定呢？曾有王文瑞、周恩玉著《话说小白楼》（天津文史资料选辑第59辑）文中记载：当初“其四至是东西以海河与墙子河（今南京路）为界，南至现在的徐州道，北迄现在的曲阜道。就是这块总面积约131亩的弹丸之地，形成今天人们所熟悉的‘小白楼’地区” 天津音乐厅天津音乐厅原名平安电影院或小白楼音乐厅，坐落在天津市和平区小白楼地区南京路、浙江路、开封道和建设路四路交口处，为浙江路32号。其前身为始建于1922年的平安电影院。此后，原建筑于2005年拆除重建。2009年，新天津音乐厅落成，目前，天津音乐厅已成为天津的国际专业音乐厅。 @ref: https://zh.m.wikipedia.org/zh-hans/天津音乐厅 起士林餐厅起士林（德语：Kiessling），是中国天津市的一家著名西餐厅，1901年由德国人阿尔伯特·起士林开办，地址曾先后位于天津法租界大法国路（今和平区解放北路）和天津德租界、天津美租界交界的威廉街（今河西区解放南路）。后与当时位于天津英租界马场道（Race Course Road）与达文波道（Davenport Road）交汇处（今和平区浙江路和建设路交汇处的浙江路33号）的维克多力餐厅合并。该建筑虽然和原貌有较大变化，但仍是重点保护等级历史风貌建筑和天津市文物保护单位。 1954年，起士林餐饮部分与当时的维克多力餐厅合并。维克多力餐厅原名“义顺合”，20世纪20年代初开业，至20世纪40年代扩大经营并改名维克多力。以经营俄式西餐大菜为主，同时兼做英、法、德、意式名菜和西点。起士林与维克多力合并后，定名为起士林餐厅。而两店的面包。西点制作部分，单独设立了起士林食品厂，专门从事西点、糖果、巧克力等生产。文化大革命期间，起士林餐厅先后更名为天津餐厅、工农兵餐厅等。1970年，起士林餐厅职工联合给时任中华人民共和国总理周恩来写信请求恢复起士林餐厅老字号，七天后得到国务院批准。之后，起士林在大理道和南市食品街开办了两家分店，在河北省秦皇岛市北戴河也恢复了分店。1990年7月5日，起士林餐厅正式更名为“起士林大饭店”，不但设有西餐厅、客房，而且有舞厅和卡拉OK等附属设施。1998年12月18日，起士林餐厅北京分店开业，位于东城区南河沿大街华龙街2楼。 起士林餐厅现主营德式西餐，兼做俄、英、法、意五国西式大菜，其代表菜有“奶油烤杂拌”、“罐焖牛肉”、“奶汁烤鱼”等。 @ref: https://zh.m.wikipedia.org/zh-hans/起士林餐厅 先农大院先农大院始建于1925年，坐落于当时的天津英租界的威灵顿道（Wellington Road）与达克拉道（Douglas Road）交口（今和平区河北路与洛阳道交口），占地面积为8100平方米，总建筑面积为8400平方米，由建筑围合形成建筑组团，该建筑群目前为一般保护等级历史风貌建筑。 先农大院建于1925年，由成立于1901年的先农地产工程股份有限公司的英籍工程师雷德设计，在当时该大院多为先农地产公司的高级职员居住，所以取名为先农大院。 大院由英式联排住宅、英式独立的住宅等六幢建筑组成，功能布局合理，居住舒适，是典型的中产阶级住宅。 @ref: 先农大院 - 维基百科，自由的百科全书 先农公司大楼先农公司大楼（英语：Tientsin Land Investment CO.,LTD. Building）又称天津先农公司大楼，始建于1923年至1924年，由英商先农工程股份有限公司英籍建筑师奈尔（D.LYLE）设计，坐落于当时天津英租界的海大道（英语：Taku Road，今和平区大沽北路111号），原建筑已于2006年拆除。 “2005年大沽北路拓宽改造工程中原计划保留，但时隔一年之后，该建筑被拆除。” 河东区 📍大直沽@ref：大直沽——天津城市原生点 - 知乎 大直沽影院原址是比利时工部局翻译靳云波的私人戏楼。 新中国建立初期，政府为了解决大直沽、大王庄一带的工人不能看电影的问题，1956年区政府将坐落在大直沽九号路的“新民戏院”改建为“大直沽影戏院”，总共有690个席位。1964年为了更好的观影效果，大直沽影戏院进行原址重建，拆除了观众厅的10棵柱子，座席也增加到802个 ，安装了国产放映设备 ，定名“大直沽影剧院”。但在1979年正月初一的时候因火灾被烧毁，1986年重建后更名为“大直沽影院”。 爬楼机位 📸↓拍摄于2017-4-2 周日 19:00，FUJIFILM X-T1，15 秒，50 mm，ISO200，天津环球金融中心①、金融街中心②、以及中心公园 ↓拍摄于2017-10-1 周日 18:15，SONY ILCE-7M2，ƒ/8，10 秒，16 mm，ISO100，解放南路（横）、新围堤道（中环线，竖） ↓拍摄于2017-10-2 周日 18:07，SONY ILCE-7M2，ƒ/10，4 秒，16 mm，ISO100，天津之眼","categories":[{"name":"54.Trips-and-Exploration","slug":"54-Trips-and-Exploration","permalink":"https://beefyheisenberg.github.io/categories/54-Trips-and-Exploration/"}],"tags":[{"name":"城市探索","slug":"城市探索","permalink":"https://beefyheisenberg.github.io/tags/城市探索/"},{"name":"旅行","slug":"旅行","permalink":"https://beefyheisenberg.github.io/tags/旅行/"},{"name":"天津","slug":"天津","permalink":"https://beefyheisenberg.github.io/tags/天津/"}]},{"title":"CN | 北京 / 玩什么","slug":"54.Trips-and-Exploration/CN.北京","date":"2024-01-24T01:27:53.659Z","updated":"2024-01-24T01:27:53.660Z","comments":true,"path":"54.Trips-and-Exploration/CN.北京/","link":"","permalink":"https://beefyheisenberg.github.io/54.Trips-and-Exploration/CN.北京/","excerpt":"@toc: 博物馆、旧货市场、话剧、青旅、建筑、城中村 @inbox 北京有什么鲜为人知的、很好玩的地方？ - 知乎 在北京生活有什么鲜为人知的技巧？ - 知乎：小西天电影资料馆、三联、国博、凡士林润肤露/ 滤水壶… 北京海淀区有哪些被埋没的好地方？ - 知乎 这5家我经常去的旧货市场，都在北京6环内 - 知乎： 孙河市场/大柳树/天宝/新七彩 北京哪里商场好逛? - 知乎 在北京看话剧，有哪些剧场值得推荐？ - 知乎 北京有哪些青年旅舍值得推荐？ - 知乎 北京41家博物馆亲身体验攻略手册 - 知乎 北京市 10 大建筑物 - Tripadvisor 北京值得观赏的现代的建筑有哪些？ - 知乎 红砖美术馆、树美术馆、鸿坤美术馆、中央美术学院美术馆、今日美术馆、宋庄美术馆 篱苑书屋 北京西站，扩展阅读： [[../63.Culture-and-Arts/Arch.北京建筑上的大屋顶]] 侨福芳草地 考古系列","text":"@toc: 博物馆、旧货市场、话剧、青旅、建筑、城中村 @inbox 北京有什么鲜为人知的、很好玩的地方？ - 知乎 在北京生活有什么鲜为人知的技巧？ - 知乎：小西天电影资料馆、三联、国博、凡士林润肤露/ 滤水壶… 北京海淀区有哪些被埋没的好地方？ - 知乎 这5家我经常去的旧货市场，都在北京6环内 - 知乎： 孙河市场/大柳树/天宝/新七彩 北京哪里商场好逛? - 知乎 在北京看话剧，有哪些剧场值得推荐？ - 知乎 北京有哪些青年旅舍值得推荐？ - 知乎 北京41家博物馆亲身体验攻略手册 - 知乎 北京市 10 大建筑物 - Tripadvisor 北京值得观赏的现代的建筑有哪些？ - 知乎 红砖美术馆、树美术馆、鸿坤美术馆、中央美术学院美术馆、今日美术馆、宋庄美术馆 篱苑书屋 北京西站，扩展阅读： [[../63.Culture-and-Arts/Arch.北京建筑上的大屋顶]] 侨福芳草地 考古系列 万寿寺 @link: [[../64.Novel-and-Poesy/C02.青铜时代]] 《阳光灿烂的日子》拍摄地：2013《游·阳光灿烂的日子》拍摄地~：段祺瑞执政府旧址、恭王府、辅仁大学、利马窦墓、东四六条、莫斯科餐厅、北展剧场 // @link：[[../64.Novel-and-Poesy/C14.动物凶猛]] 从胡同北平到大院北京 六郎庄死了，我很怀念它网易人间网易新闻 地图单向街买到的《书虫漫游北京指南》：书店、博物馆、文化地标、咖啡厅 《北京市城区街道图-1982版》： 废墟探险关于北京废墟探险，我能告诉你们的 - 知乎：帖子中所讲到的大部分地标性废墟，现在都已经消失了——小汤山医院、沃德兰乐园、玉泉路主题公园……早都拆了；朝内81号商业化了，有专人值守；首钢、首钢二通厂等地也都陆续在改造，如今也大都不是图片当中的样子。 北京有哪些被废弃的地方值得一看？推荐理由是什么？ - 知乎：首钢、玉泉路乐园（绝版）、沃德兰乐园（绝版）、广渠门烂尾楼（绝版）","categories":[{"name":"54.Trips-and-Exploration","slug":"54-Trips-and-Exploration","permalink":"https://beefyheisenberg.github.io/categories/54-Trips-and-Exploration/"}],"tags":[{"name":"城市探索","slug":"城市探索","permalink":"https://beefyheisenberg.github.io/tags/城市探索/"},{"name":"旅行","slug":"旅行","permalink":"https://beefyheisenberg.github.io/tags/旅行/"},{"name":"北京","slug":"北京","permalink":"https://beefyheisenberg.github.io/tags/北京/"}]},{"title":"CN | 上海 / 玩什么","slug":"54.Trips-and-Exploration/CN.上海","date":"2024-01-24T01:27:53.655Z","updated":"2024-01-24T01:27:53.656Z","comments":true,"path":"54.Trips-and-Exploration/CN.上海/","link":"","permalink":"https://beefyheisenberg.github.io/54.Trips-and-Exploration/CN.上海/","excerpt":"@inbox: 上海有哪些适合一个人吃饭的餐厅？ - 知乎 上海有哪些深藏不露的餐馆？ - 知乎 在上海和喜欢的姑娘在一起有哪些好玩的地方？ - 知乎 徒步路线上海的十条漫步线路","text":"@inbox: 上海有哪些适合一个人吃饭的餐厅？ - 知乎 上海有哪些深藏不露的餐馆？ - 知乎 在上海和喜欢的姑娘在一起有哪些好玩的地方？ - 知乎 徒步路线上海的十条漫步线路 漫步线路1 中山公园——愚园路——江苏路——华山路——徐家汇 漫步线路2 徐家汇——衡山路——淮海路 漫步线路3 延安西路——新华路——淮海路——华山路——徐家汇 漫步线路4 漕宝路地铁站——漕宝路——桂林路——田林路——宜山路 漫步线路5 徐家汇——建国西路——建国中路——建国东路——西藏南路 漫步线路6 外滩——南京东路——南京西路——静安寺 漫步线路7 南京西路——陕西南路——长乐路——镇宁路 漫步线路8 淮海中路——汾阳路——东平路——乌鲁木齐路 … …","categories":[{"name":"54.Trips-and-Exploration","slug":"54-Trips-and-Exploration","permalink":"https://beefyheisenberg.github.io/categories/54-Trips-and-Exploration/"}],"tags":[{"name":"城市探索","slug":"城市探索","permalink":"https://beefyheisenberg.github.io/tags/城市探索/"},{"name":"旅行","slug":"旅行","permalink":"https://beefyheisenberg.github.io/tags/旅行/"},{"name":"上海","slug":"上海","permalink":"https://beefyheisenberg.github.io/tags/上海/"}]},{"title":"使用谷歌街景进行街拍","slug":"53.Photograph/使用谷歌街景进行街拍","date":"2024-01-24T01:27:53.646Z","updated":"2024-01-24T01:27:53.646Z","comments":true,"path":"53.Photograph/使用谷歌街景进行街拍/","link":"","permalink":"https://beefyheisenberg.github.io/53.Photograph/使用谷歌街景进行街拍/","excerpt":"Jacqui Kenny “我不是摄影师，是谷歌街景截图艺术家”_网易订阅 Google地图街景创作！ 英国艺术家Jacqui Kenny截下独特迷人美景 Ins： https://www.instagram.com/streetview.portraits/ 居住在伦敦，患有广场恐惧症的艺术家 Jacqui Kenny，选择让它成为自己环游世界的交通工具，和照相机。 “广场恐惧和焦虑限制了我旅行的能力，于是我找到了另一种看世界的方式。” 在名为「streetview.portraits」的 Instagram 账号下，Jacqui Kenny 写下这段自我介绍。账号的第一张照片发布于 2016 年，是谷歌街景视角下的蒙古达尔汗城一角。","text":"Jacqui Kenny “我不是摄影师，是谷歌街景截图艺术家”_网易订阅 Google地图街景创作！ 英国艺术家Jacqui Kenny截下独特迷人美景 Ins： https://www.instagram.com/streetview.portraits/ 居住在伦敦，患有广场恐惧症的艺术家 Jacqui Kenny，选择让它成为自己环游世界的交通工具，和照相机。 “广场恐惧和焦虑限制了我旅行的能力，于是我找到了另一种看世界的方式。” 在名为「streetview.portraits」的 Instagram 账号下，Jacqui Kenny 写下这段自我介绍。账号的第一张照片发布于 2016 年，是谷歌街景视角下的蒙古达尔汗城一角。 5 年来，Kenny 给自己的标签从来没变过：Agoraphobic Traveller，广场恐惧症旅行者。两个看上去完全相互排斥的词汇，被谷歌街景地图，以及她本人的好奇心和创作欲连在一起。 「广场恐惧症」（Agoraphobia），大多的说法是一种人们认为环境不安全，并且不容易逃离而产生的焦虑症状。所谓的「不安全」环境，可能存在于任何空旷、开放的空间 — — 仅仅是自家门外，也有能让患者恐慌发作。 Agoraphobia involves fearing and avoiding places or situations that might cause panic and feelings of being trapped, helpless or embarrassed. You may fear an actual or upcoming situation. For example, you may fear using public transportation, being in open or enclosed spaces, standing in line, or being in a crowd. Kenny 40 多年的人生中，几乎一半的时间都在被这种常人难以理解的病症困扰。“说那是一种对空间的恐惧，好像不太确切，更多的是害怕自己在其中失去控制” 没有想象中前卫且极具未来感的创作动机，这位艺术家选择谷歌街景地图的根源，首先是为了实现自己无法在现实中完成的「旅行」概念。 2016 年，和朋友一起创业十年的公司最终走向失败，让 Kenny 极为受挫。为了消解那些负面的情绪，迫使自己随时保持专注，一次偶然的机会，她打开了谷歌地图，开始点击那些自己可能从没听说过的地名。从另一个角度看，这更像是一个无法出行的人，在低谷时找到的专属散心方式。 “我可以降落在世界上任何一个角落，不用坐飞机，不用担心恐慌发作。在那个世界，我能感受到更多的掌控力。” 如果有人也想像她一样，开始自己的谷歌街景数字之旅，Kenny 会建议他们从蒙古或吉尔吉斯斯坦出发 — — 特别是蒙古，算是 Kenny 的珍贵私藏。 “当我第一次发现它的美时，那种感觉是压倒性的。”身处伦敦的公寓，Kenny 的生活和那个亚洲的神秘国家没有任何相似之处，完全是平行空间中离她最远的世界。 几乎所有 Kenny 的照片，都共享着相似的干净天空，像是在同一个地方拍摄的。而这只是她对自己的截图时的视觉执念：要有完美的光线和足够吸引人的色彩搭配。 事实上，它们可能来自于秘鲁的利马，阿联酋的沙迦，或是美国亚利桑那州某个民居的前院。选定场景，截图，加上非常风格化的个人滤镜，让 Kenny 的作品即使放在真实的人文风景照片中，都能一眼被认出。 Michael Wolf谷歌街景对街头摄影造成了哪些影响？ - 知乎 Michael Wolf本身是以他的大尺寸建筑摄影出名，主要拍的是香港和芝加哥，比如 “architecture of density” and “the transparent city” 系列。但他前几年开始对公共环境的监控摄像头感兴趣，接着又关心到个人隐私和公共摄像头的关系，于是从摄影师的角度出发，他在问自己，作为现代科技武装下的街头摄影师，我们需要和被拍摄的对象保持多远的距离？ 这个问题并不新，许多摄影师和概念艺术家都研究过，例如我最爱的法国女艺术家Sophia Calle就做过一系列类似问题的探索，她雇佣了一个私家侦探，跟拍了自己的一天。 Michael Wolf后来做的一个摄影项目很出名，大家肯定都记得，是“Tokyo compression”，就是蹲在日本地铁里拍那些被压在车厢里的日本人的脸。有一种在公共空间窥探个人隐私、私人痛苦的感觉。link：MICHAEL WOLF PHOTOGRAPHY","categories":[{"name":"53.Photograph","slug":"53-Photograph","permalink":"https://beefyheisenberg.github.io/categories/53-Photograph/"}],"tags":[{"name":"摄影","slug":"摄影","permalink":"https://beefyheisenberg.github.io/tags/摄影/"},{"name":"街拍","slug":"街拍","permalink":"https://beefyheisenberg.github.io/tags/街拍/"}]},{"title":"如何评价富士的classic chrome胶片模拟？","slug":"53.Photograph/如何评价富士的Classic-Chrome胶片模拟","date":"2024-01-24T01:27:53.642Z","updated":"2024-01-24T01:27:53.642Z","comments":true,"path":"53.Photograph/如何评价富士的Classic-Chrome胶片模拟/","link":"","permalink":"https://beefyheisenberg.github.io/53.Photograph/如何评价富士的Classic-Chrome胶片模拟/","excerpt":"https://www.zhihu.com/question/58228287/answer/188459425 Classic chrome 的饱和度非常低，比Provia/Neg这些都要低，同时也抑制了高光部分的亮度，但是阴影更暗，色彩上蓝色偏青，黄和绿偏橙。 上面的色调和饱和度坐标图可以看到，Classic chrome的饱和度是最低的， 同时色调稍稍强烈一些。 富士并没有给早期的机型（X100，x100s等）更新这个胶片模拟，但是可以通过Provia来模拟classic chrome ：","text":"https://www.zhihu.com/question/58228287/answer/188459425 Classic chrome 的饱和度非常低，比Provia/Neg这些都要低，同时也抑制了高光部分的亮度，但是阴影更暗，色彩上蓝色偏青，黄和绿偏橙。 上面的色调和饱和度坐标图可以看到，Classic chrome的饱和度是最低的， 同时色调稍稍强烈一些。 富士并没有给早期的机型（X100，x100s等）更新这个胶片模拟，但是可以通过Provia来模拟classic chrome ： 高光色调-1，降低高光，保留更多高光细节 阴影色调+1，使阴影部分更暗 色彩-2，把饱和度降到最低 这样调整出来的Provia预设更像classic chrome，下面是样片：","categories":[{"name":"53.Photograph","slug":"53-Photograph","permalink":"https://beefyheisenberg.github.io/categories/53-Photograph/"}],"tags":[{"name":"摄影","slug":"摄影","permalink":"https://beefyheisenberg.github.io/tags/摄影/"},{"name":"相机","slug":"相机","permalink":"https://beefyheisenberg.github.io/tags/相机/"},{"name":"Fujifilm","slug":"Fujifilm","permalink":"https://beefyheisenberg.github.io/tags/Fujifilm/"}]},{"title":"索尼α系列-PP设置","slug":"53.Photograph/索尼α系列PP设置","date":"2024-01-24T01:27:53.636Z","updated":"2024-01-24T01:27:53.636Z","comments":true,"path":"53.Photograph/索尼α系列PP设置/","link":"","permalink":"https://beefyheisenberg.github.io/53.Photograph/索尼α系列PP设置/","excerpt":"PP的配置项说明@ref 帮助指南 | 图片配置文件 黑色等级 设定黑色等级。（-15至+15） 伽玛: 选择伽玛曲线。","text":"PP的配置项说明@ref 帮助指南 | 图片配置文件 黑色等级 设定黑色等级。（-15至+15） 伽玛: 选择伽玛曲线。 Movie：动态影像用的标准伽玛曲线 Still：静止影像用的标准伽玛曲线 Cine1：柔化暗部的对比度，强调亮部的层次以再现轻松彩色的动态影像。（相当于HG4609G33） Cine2：类似于[Cine1]，但实施了优化以适于编辑最高100%的视频信号。（相当于HG4600G30） … 黑伽玛: 校正低亮度区域的伽玛。 范围：选择校正范围。（宽 / 中 / 窄） 等级：设定校正等级。（-7（最大黑色压缩）至+7（最大黑色伸展）） 膝点: 设定视频信号压缩用的膝点和斜率，通过将被摄体高亮度区域的信号限制在相机的动态范围内来防止曝光过度。 模式: 选择自动/手动设置。 自动：自动设定膝点和斜率。 手动：手动设定膝点和斜率。 色彩模式: 设定色彩的类型和级别。 Movie：当［伽玛］设定为［Movie］时的适合色彩。 Still：当［伽玛］设定为［Still］时的适合色彩。 Cinema：当［伽玛］设定为［Cine1］时的适合色彩。 Pro：类似Sony专业相机标准画质的色调（与ITU-709伽玛组合时） ITU709矩阵：与ITU-709标准相应的色彩（与ITU-709伽玛组合时） 黑白：将饱和度设为0以进行黑白拍摄。 S-Gamut：以拍摄后图像将被处理为前提的设置。当［伽玛］设定为［S-Log2］时使用。 饱和度: 设定色彩饱和度。（-32至+32） 色彩相位: 设定色彩相位。（-7至+7） 色彩浓度: 设定各色相的色彩深度。颜色越深该功能的效果越明显，对于没有颜色的被摄体效果不明显。向正方向增加设定值时颜色会显得更深，向负方向减少设定值时颜色会显得更浅。将［色彩模式］设为［黑白］（黑和白）时该功能也有效。 ［R］-7 （淡红）至 +7 （深红） ［G］-7 （淡绿）至 +7 （深绿） ［B］-7 （淡蓝）至 +7 （深蓝） ［C］-7 （淡青）至 +7 （深青） ［M］-7 （淡品红）至 +7 （深品红） ［Y］-7 （淡黄）至 +7 （深黄） PP设定示例@ref 巧用sony a7m3的PP设置，直出日式小清新照片 黑色等级：+15。让阴影亮起来，降低对比度。 伽马：Cine4。没理由，挨个试了之后发现这个我最喜欢。 黑伽马：范围：窄。等级：+7。让黑色部分亮起来，继续降低对比度。 膝点：手动。点：97.5%，斜率：+2。让高光降一点，还是降低对比度。 色彩模式：ITU709矩阵。也没理由，挨个试了之后选的。 饱和度：+5。 色彩相位：-2。偏黄偏绿。 色彩浓度：R：+3，G：-2，B：-2，C：0，M：0，Y：-4。挨个试了之后的选择。 细节——等级+7。调整：模式：手动。V/H平衡：0。B/W平衡：类型1。限制：7。Crispning：0。高亮细节：0。 @ref 【摄影教程】这样简单设置索尼pp值，拍出来就是电影感 黑色等级：+3 伽马：Cine4 黑伽马：范围：宽，等级：+4 漆点：手动（最大点80%，斜率-5） 色彩模式：Pro 饱和度：0 色彩浓度：R=+2 / G=+1 / B=-1 / C=-4 / M=-3 / Y=+2 细节：-6","categories":[{"name":"53.Photograph","slug":"53-Photograph","permalink":"https://beefyheisenberg.github.io/categories/53-Photograph/"}],"tags":[{"name":"摄影","slug":"摄影","permalink":"https://beefyheisenberg.github.io/tags/摄影/"},{"name":"摄影器材","slug":"摄影器材","permalink":"https://beefyheisenberg.github.io/tags/摄影器材/"},{"name":"索尼","slug":"索尼","permalink":"https://beefyheisenberg.github.io/tags/索尼/"},{"name":"索尼A7","slug":"索尼A7","permalink":"https://beefyheisenberg.github.io/tags/索尼A7/"}]},{"title":"扫街指南","slug":"53.Photograph/扫街指南","date":"2024-01-24T01:27:53.627Z","updated":"2024-01-24T01:27:53.627Z","comments":true,"path":"53.Photograph/扫街指南/","link":"","permalink":"https://beefyheisenberg.github.io/53.Photograph/扫街指南/","excerpt":"按下快门之前的 4 Steps：构图-对焦-水平仪-Timing 在杂乱中寻找结构/在日常中寻找美感 脚步慢下来，这样可以避免错过的瞬间 帽子和口罩 气温不宜高于25摄氏度 or 低于0度，不适宜的天气会扫兴 决定性的瞬间 | 布列松作品精选 “我不是摄影师，是谷歌街景截图艺术家” 使用谷歌街景进行街拍","text":"按下快门之前的 4 Steps：构图-对焦-水平仪-Timing 在杂乱中寻找结构/在日常中寻找美感 脚步慢下来，这样可以避免错过的瞬间 帽子和口罩 气温不宜高于25摄氏度 or 低于0度，不适宜的天气会扫兴 决定性的瞬间 | 布列松作品精选 “我不是摄影师，是谷歌街景截图艺术家” 使用谷歌街景进行街拍 设备说明书： 相机manual.富士X100F：对焦辅助灯off / ISO范围 相机manual.索尼α7m3：","categories":[{"name":"53.Photograph","slug":"53-Photograph","permalink":"https://beefyheisenberg.github.io/categories/53-Photograph/"}],"tags":[{"name":"摄影","slug":"摄影","permalink":"https://beefyheisenberg.github.io/tags/摄影/"},{"name":"街拍","slug":"街拍","permalink":"https://beefyheisenberg.github.io/tags/街拍/"}]},{"title":"怎么拍-风光摄影指南","slug":"53.Photograph/怎么拍-风光摄影指南","date":"2024-01-24T01:27:53.623Z","updated":"2024-01-24T01:27:53.623Z","comments":true,"path":"53.Photograph/怎么拍-风光摄影指南/","link":"","permalink":"https://beefyheisenberg.github.io/53.Photograph/怎么拍-风光摄影指南/","excerpt":"城市： 城市风光摄影爬楼完全攻略（1） - 知乎 [[../54.Trips-and-Exploration/CN.天津|CN.天津]] / 爬楼机位 极光： 冰岛极光摄影|设备推荐、设置参数、常见问题 | Guide to Iceland 极光的拍摄对于相机和镜头以及参数设置有哪些要求？ - 知乎 星空：","text":"城市： 城市风光摄影爬楼完全攻略（1） - 知乎 [[../54.Trips-and-Exploration/CN.天津|CN.天津]] / 爬楼机位 极光： 冰岛极光摄影|设备推荐、设置参数、常见问题 | Guide to Iceland 极光的拍摄对于相机和镜头以及参数设置有哪些要求？ - 知乎 星空： 如何拍摄夜晚的星空，需要做哪些准备工作？ - 知乎","categories":[{"name":"53.Photograph","slug":"53-Photograph","permalink":"https://beefyheisenberg.github.io/categories/53-Photograph/"}],"tags":[{"name":"摄影","slug":"摄影","permalink":"https://beefyheisenberg.github.io/tags/摄影/"}]},{"title":"怎么拍-拍妹指南","slug":"53.Photograph/怎么拍-拍妹指南","date":"2024-01-24T01:27:53.619Z","updated":"2024-01-24T01:27:53.619Z","comments":true,"path":"53.Photograph/怎么拍-拍妹指南/","link":"","permalink":"https://beefyheisenberg.github.io/53.Photograph/怎么拍-拍妹指南/","excerpt":"","text":"拍妹只服 午饭饭： 「糖水日记」99 小唯的魔都阳光半日扫街 腾龙28-75F2.8/70-180F2.8 怎么拍妹子显瘦？ - 知乎 旅行拍照穿的超好看（上镜）的衣服有哪些？ - 知乎 拍照时怎样摆姿势好看？ - 知乎 什么样的灯光和角度下人比较好看？ - 知乎 其他 男性拍照时有哪些不错的姿势可以选择？ - 知乎 如何用手机拍出一张特别好看的自拍？ - 知乎","categories":[{"name":"53.Photograph","slug":"53-Photograph","permalink":"https://beefyheisenberg.github.io/categories/53-Photograph/"}],"tags":[{"name":"摄影","slug":"摄影","permalink":"https://beefyheisenberg.github.io/tags/摄影/"}]},{"title":"相机manual.索尼α7m3","slug":"53.Photograph/相机manual.索尼α7m3","date":"2024-01-24T01:27:53.615Z","updated":"2024-01-24T01:27:53.615Z","comments":true,"path":"53.Photograph/相机manual.索尼α7m3/","link":"","permalink":"https://beefyheisenberg.github.io/53.Photograph/相机manual.索尼α7m3/","excerpt":"@tag: #摄影 #相机 #说明书 快速使用 &amp; 自定义按键 C1：对焦区域（中间/区域/广域） C2：对焦模式（单次/连续/手动） C3：测光方式（多重/中心/点测） 方向键↓：屏幕亮度 删除键：屏幕触摸On/Off 菜单-收藏：静音拍摄/AF辅助照明/长曝降噪/防抖 一般拍摄option [ ] 关闭WiFi 和NFC 延长续航 [ ] 白平衡：偏冷 B1M1 / 偏暖 A2M2 [ ] 创意风格：清淡（对比+1、饱和-1）or Portrait [ ] 曝光：+1/3~2/3","text":"@tag: #摄影 #相机 #说明书 快速使用 &amp; 自定义按键 C1：对焦区域（中间/区域/广域） C2：对焦模式（单次/连续/手动） C3：测光方式（多重/中心/点测） 方向键↓：屏幕亮度 删除键：屏幕触摸On/Off 菜单-收藏：静音拍摄/AF辅助照明/长曝降噪/防抖 一般拍摄option [ ] 关闭WiFi 和NFC 延长续航 [ ] 白平衡：偏冷 B1M1 / 偏暖 A2M2 [ ] 创意风格：清淡（对比+1、饱和-1）or Portrait [ ] 曝光：+1/3~2/3 风光&amp;长曝拍摄option [ ] 拍摄1：影像质量（RAW+J ） [ ] 拍摄4：ISO 100 , 关闭多帧降噪（拍摄多张合成） [ ] 拍摄6：打开长时间曝光降噪（时间+一倍） [ ] 拍摄6：关闭高ISO降噪（对RAW无效） [ ] 拍摄7：关闭SteadyShot（如果上三脚架） [ ] 齿轮6：镜头校正-失真补偿（如果用16-35需要开启此选项）如果用手动Helios44需打开阴影补偿（改善暗角） 创意风格Sony 相机的色彩一般有3个参数决定，首先是白平衡，然后就是创意风格和图片配置文件（Picture Profile，后面简称 PP）其中，创意风格和 PP 是互斥的，只能任选一个，不能同时起作用，使用 PP 就得关闭创意风格。 创意风格中预设了几个常用的色彩模式，包括 Std.（标准）、Vivid（生动）、Ntrl（中性）、Clear（清澈）、Deep（深色）、Light（轻淡）、Port.（肖像）、Land（风景），说明书上是这样写的： 等效参数表： 自带创意风格分析（偏人像拍摄，主要测试不同风格对肤色的表现）： Standard(标准): 中规中矩，肤色表现一般 Neutral(中性): 比 Std 更柔和, 相比 Std，清晰度更低, 饱和度更低, 肤色比 Std 更好(少了黄绿色), 适合后期加工； Light(清淡): 并不清淡, 肤色表现一般； Portrait(人像): 优化了肤色, 完全可用，如果不想后期，是 Sony 系列拍人像最选择； Clear(清澈): 未测试 @ref: 卷毛- Eng Sub最简单改善“索尼黄”的方法：机内创意风格和色彩模式全对比「Isaac WEAPON」 - YouTube PP（图片配置文件）@link: 索尼α系列PP设置 待测试选项 [ ] （测试）更小的光圈和更长曝光时间 [ ] （测试）全景模式接片 [ ] （测试）后期堆栈叠加 应用程序 [ ] 延时拍摄App [ ] 多重曝光App [ ] 平滑反射App","categories":[{"name":"53.Photograph","slug":"53-Photograph","permalink":"https://beefyheisenberg.github.io/categories/53-Photograph/"}],"tags":[{"name":"摄影","slug":"摄影","permalink":"https://beefyheisenberg.github.io/tags/摄影/"},{"name":"摄影器材","slug":"摄影器材","permalink":"https://beefyheisenberg.github.io/tags/摄影器材/"},{"name":"索尼","slug":"索尼","permalink":"https://beefyheisenberg.github.io/tags/索尼/"},{"name":"索尼A7","slug":"索尼A7","permalink":"https://beefyheisenberg.github.io/tags/索尼A7/"}]},{"title":"相机manual.富士X100F","slug":"53.Photograph/相机manual.富士X100F","date":"2024-01-24T01:27:53.611Z","updated":"2024-01-24T01:27:53.611Z","comments":true,"path":"53.Photograph/相机manual.富士X100F/","link":"","permalink":"https://beefyheisenberg.github.io/53.Photograph/相机manual.富士X100F/","excerpt":"快速使用 Q键：检查图片尺寸/白平衡/ND/对焦模式… ISO默认使用AUTO3方案(最高3200, 快门1/60) Fn：是否开启「脸部/眼睛识别」 长按对焦杆, 锁定 //设置为“OFF”以防止误碰导致AF点移动 长按MENU键, 锁定 ND滤镜: 在日光下使用慢快门和大光圈, 可在Q中开启 自定义按键 对焦辅助灯：MENU → AF/MF → AF辅助灯 WiFi传输：MENU → 拍摄选项（第3个）→ 无线通信 数码变焦(50mm/70mm)：MENU → 拍摄选项（第3个）→ 数码远射增距镜 按键设定： MENU键：长按锁定/解除锁定 // 仅对MENU键有效 对焦杆：长按可进行设置 // 仅对对焦杆有效 Fn键：是否开启面部/眼睛识别 ▲键：DRIVE（单张/连拍/包围/视频）可开启胶片包围 ▼键：胶片模拟 ◀ 键：白平衡 ▶ 键：ISO 取景器拨杆按钮(Fn2按钮): 长按: 设定 短按: 进入设置功能，当前设置为【控制环设定】 按住+转动对焦环: 依据设置功能切换","text":"快速使用 Q键：检查图片尺寸/白平衡/ND/对焦模式… ISO默认使用AUTO3方案(最高3200, 快门1/60) Fn：是否开启「脸部/眼睛识别」 长按对焦杆, 锁定 //设置为“OFF”以防止误碰导致AF点移动 长按MENU键, 锁定 ND滤镜: 在日光下使用慢快门和大光圈, 可在Q中开启 自定义按键 对焦辅助灯：MENU → AF/MF → AF辅助灯 WiFi传输：MENU → 拍摄选项（第3个）→ 无线通信 数码变焦(50mm/70mm)：MENU → 拍摄选项（第3个）→ 数码远射增距镜 按键设定： MENU键：长按锁定/解除锁定 // 仅对MENU键有效 对焦杆：长按可进行设置 // 仅对对焦杆有效 Fn键：是否开启面部/眼睛识别 ▲键：DRIVE（单张/连拍/包围/视频）可开启胶片包围 ▼键：胶片模拟 ◀ 键：白平衡 ▶ 键：ISO 取景器拨杆按钮(Fn2按钮): 长按: 设定 短按: 进入设置功能，当前设置为【控制环设定】 按住+转动对焦环: 依据设置功能切换 图像质量 IQ 图像尺寸: 默认值L (3:2) 图像质量: 默认值FINE 动态范围: 默认值100%，影响高光细节, 动态范围200%在ISO 400+时可以使用, 动态范围400%在ISO 800+时可以使用, 对RAW文件有效 高光色调: 值越大, 高光部分越亮, 值越小, 能保留更多高光细节, 只影响JPG 阴影色调: 值越大, 阴影部分越暗, 值越小, 能保留更多暗部细节, 只影响JPG 降噪功能: 减少高ISO的噪点, 默认值0 长时间曝光降噪: 减少场曝光的斑点, 默认值开 对焦 AF/MF 释放/对焦优先: 快门按钮释放时, 没有清晰对焦也会拍摄, 默认值释放 胶片模拟X轴: 低饱和 高饱和Y轴: 色调柔和 色调强烈 按键 闪光灯选项","categories":[{"name":"53.Photograph","slug":"53-Photograph","permalink":"https://beefyheisenberg.github.io/categories/53-Photograph/"}],"tags":[{"name":"摄影","slug":"摄影","permalink":"https://beefyheisenberg.github.io/tags/摄影/"},{"name":"Fujifilm","slug":"Fujifilm","permalink":"https://beefyheisenberg.github.io/tags/Fujifilm/"},{"name":"摄影器材","slug":"摄影器材","permalink":"https://beefyheisenberg.github.io/tags/摄影器材/"},{"name":"X100","slug":"X100","permalink":"https://beefyheisenberg.github.io/tags/X100/"}]},{"title":"相机manual.TT350s闪光灯","slug":"53.Photograph/相机manual.TT350s闪光灯","date":"2024-01-24T01:27:53.607Z","updated":"2024-01-24T01:27:53.607Z","comments":true,"path":"53.Photograph/相机manual.TT350s闪光灯/","link":"","permalink":"https://beefyheisenberg.github.io/53.Photograph/相机manual.TT350s闪光灯/","excerpt":"📸 TT350s闪光灯使用说明@tag: #摄影 #闪光灯 #说明书 闪光灯按键：Mode键： 短按 在Multi(频闪), TTL, M之间切换 长按 进入频闪, set设定 3 - 2Hz, 一共闪3次频率2Hz","text":"📸 TT350s闪光灯使用说明@tag: #摄影 #闪光灯 #说明书 闪光灯按键：Mode键： 短按 在Multi(频闪), TTL, M之间切换 长按 进入频闪, set设定 3 - 2Hz, 一共闪3次频率2Hz Sync键： 短按 进入高速模式, 闪光指数下降 长按 切换无线模式的: 无线主 / 无线从 / 机顶灯 Slave键： 短按 设置无线的分组: A / B / C 长按 设置无线频道 Zoom键 短按 调节焦距（扩散板打开的情况下固定14mm） 长按 AF ON（AF辅助闪光） ST ON（自动休眠秒数） BL ON（背光秒数） X1s 引闪器按键：CH/OK： 短按 设置频道号0~32 长按 进入Fn设置, Fn00~Fn07, 按GR可以设置： Fn01 设置延迟 Fn04 频闪模式","categories":[{"name":"53.Photograph","slug":"53-Photograph","permalink":"https://beefyheisenberg.github.io/categories/53-Photograph/"}],"tags":[{"name":"摄影","slug":"摄影","permalink":"https://beefyheisenberg.github.io/tags/摄影/"},{"name":"摄影器材","slug":"摄影器材","permalink":"https://beefyheisenberg.github.io/tags/摄影器材/"},{"name":"闪光灯","slug":"闪光灯","permalink":"https://beefyheisenberg.github.io/tags/闪光灯/"}]},{"title":"胶片测光经验表","slug":"53.Photograph/film.胶片测光经验表","date":"2024-01-24T01:27:53.602Z","updated":"2024-01-24T01:27:53.602Z","comments":true,"path":"53.Photograph/film.胶片测光经验表/","link":"","permalink":"https://beefyheisenberg.github.io/53.Photograph/film.胶片测光经验表/","excerpt":"@tag: #摄影 #胶片 以下如果没有特殊说明, 默认是ISO200的胶卷, 快门速度250 室外： 白天/晴朗: f16 白天/多云: f11 白天/阴影: f5.6, 接近日落,光线变弱的时候f4 白天/阴天: f4 室内：","text":"@tag: #摄影 #胶片 以下如果没有特殊说明, 默认是ISO200的胶卷, 快门速度250 室外： 白天/晴朗: f16 白天/多云: f11 白天/阴影: f5.6, 接近日落,光线变弱的时候f4 白天/阴天: f4 室内： 白天明亮的室内: 参考室外阴天 灯光较暗(参考卧室): f1.8 快门30, 或者f1.8 快门15 灯光较亮(参考公司): f1.8 快门30或60(未测) 夜间： 夜间明亮的街道(南锣夜市): f1.8 快门30(未测) 夜间暗的街道(四环路灯): f1.8 快门15 阳光16法 艳阳16 阴天8多云11 日暮4阴云压顶5.6雨天落雪同日暮 解释:快门固定在胶片ISO的倒数，比如晴天日光下，光圈f16 + ISO200胶片 + 1/250快门（阳光16法只适用于春秋两季，如果夏季需要减少一档曝光，冬季提一档曝光）","categories":[{"name":"53.Photograph","slug":"53-Photograph","permalink":"https://beefyheisenberg.github.io/categories/53-Photograph/"}],"tags":[{"name":"摄影","slug":"摄影","permalink":"https://beefyheisenberg.github.io/tags/摄影/"},{"name":"胶片","slug":"胶片","permalink":"https://beefyheisenberg.github.io/tags/胶片/"}]},{"title":"宾得SPII使用说明","slug":"53.Photograph/film.宾得SPII使用手册","date":"2024-01-24T01:27:53.598Z","updated":"2024-01-24T01:27:53.598Z","comments":true,"path":"53.Photograph/film.宾得SPII使用手册/","link":"","permalink":"https://beefyheisenberg.github.io/53.Photograph/film.宾得SPII使用手册/","excerpt":"SPOTMATIC历史 在线说明书 M42镜头的光圈顶针 美能达X-700说明 卷片杆（P）下面的拨盘（O）没有实际作用，只是一个标记，方便记住当前用的什么胶卷（黑白/日光/灯光），还有一个窗能显示20/36的字样，大概是记录胶卷的张数吧，后面的EX. 是exposures的缩写。向上提起卷片杆（P），胶卷舱门会打开。 如何取出胶卷： 相机底有一个按钮，要按下去才能倒片。按下去的时候不会听到声音，只是按下去后它不会自己弹起来。 然后拉出相机机顶左侧卷片杆（P），顺时针方向旋转。手感上会有明显的阻碍感，那是倒片把手带动胶卷暗盒内的片轴拉动整卷胶片回绕。 最后，当回绕的手感明显变得更顺滑时，胶片已经被回绕进胶卷暗盒。提起倒片把手弹开后背，取出胶卷。","text":"SPOTMATIC历史 在线说明书 M42镜头的光圈顶针 美能达X-700说明 卷片杆（P）下面的拨盘（O）没有实际作用，只是一个标记，方便记住当前用的什么胶卷（黑白/日光/灯光），还有一个窗能显示20/36的字样，大概是记录胶卷的张数吧，后面的EX. 是exposures的缩写。向上提起卷片杆（P），胶卷舱门会打开。 如何取出胶卷： 相机底有一个按钮，要按下去才能倒片。按下去的时候不会听到声音，只是按下去后它不会自己弹起来。 然后拉出相机机顶左侧卷片杆（P），顺时针方向旋转。手感上会有明显的阻碍感，那是倒片把手带动胶卷暗盒内的片轴拉动整卷胶片回绕。 最后，当回绕的手感明显变得更顺滑时，胶片已经被回绕进胶卷暗盒。提起倒片把手弹开后背，取出胶卷。 与宾得Spotmatic SP相机配套的镜头名称是Auto Takumar1：1.8/55 Ashahi Opt Co.或AutoTakumar 1：1.4/55 Ashahi OptCo.。该镜头最近调焦距离从0.45米至无限远，调焦手感较平滑。镜头后部螺纹接口外缘有一选择拨动钮，将钮拨至露出“A”时，为自动式光圈，此时后部顶针发生作用。选择到使用的光圈时，光圈仍全开；压下顶针，光圈收缩；将钮反方向拨动露出“M”时，为手动光圈，此时顶针脱离控制结构，光圈随设定收缩。","categories":[{"name":"53.Photograph","slug":"53-Photograph","permalink":"https://beefyheisenberg.github.io/categories/53-Photograph/"}],"tags":[{"name":"摄影","slug":"摄影","permalink":"https://beefyheisenberg.github.io/tags/摄影/"},{"name":"胶片","slug":"胶片","permalink":"https://beefyheisenberg.github.io/tags/胶片/"},{"name":"相机","slug":"相机","permalink":"https://beefyheisenberg.github.io/tags/相机/"},{"name":"宾得","slug":"宾得","permalink":"https://beefyheisenberg.github.io/tags/宾得/"},{"name":"说明书","slug":"说明书","permalink":"https://beefyheisenberg.github.io/tags/说明书/"}]},{"title":"VSCO滤镜使用指南","slug":"53.Photograph/VSCO滤镜使用指南","date":"2024-01-24T01:27:53.592Z","updated":"2024-01-24T01:27:53.593Z","comments":true,"path":"53.Photograph/VSCO滤镜使用指南/","link":"","permalink":"https://beefyheisenberg.github.io/53.Photograph/VSCO滤镜使用指南/","excerpt":"TLDR： A1： 胶片复古，绿色 A6：“非常适合人像，一定要试一试” B2： 黑白，经典 B5~B6：黑白，情绪 C1： 海水、天空，粉色 E1~E2： 表现红色、蓝色 H1~H3： 多彩夏日 N1： 明亮的黄色，香蕉 S1~S3： Clean A1-A3A1 - A3 主打模拟胶片风格，提高了中间色调的同时有轻微过度曝光，色调比较柔和。官方使用了 Analog（模拟）、Archetype（典范）这两个词来命名，恰当概述了这三款滤镜，可以说是是拍摄肖像、室内和食物的完美选择。下面是这三款预设滤镜的参考作品：","text":"TLDR： A1： 胶片复古，绿色 A6：“非常适合人像，一定要试一试” B2： 黑白，经典 B5~B6：黑白，情绪 C1： 海水、天空，粉色 E1~E2： 表现红色、蓝色 H1~H3： 多彩夏日 N1： 明亮的黄色，香蕉 S1~S3： Clean A1-A3A1 - A3 主打模拟胶片风格，提高了中间色调的同时有轻微过度曝光，色调比较柔和。官方使用了 Analog（模拟）、Archetype（典范）这两个词来命名，恰当概述了这三款滤镜，可以说是是拍摄肖像、室内和食物的完美选择。下面是这三款预设滤镜的参考作品： A4-A6VSCO 这样形容 A4-A6 号滤镜： 它尽可能保留了自然色调，同时带有轻微的色彩转换和褪色效果。 A4 号滤镜对照片进行了一些褪色处理，并且增强了棕色的饱和度，给人一种略带温暖的感觉。A5 的褪色效果会更加强烈一些，红色通道被压低，整体给人一种酷酷的感觉。A6 貌似平淡无奇，但却赋予了照片清新简约的风格，漂亮的棕色的已经对肤色的友好，是我非常喜欢的一枚滤镜。 这三款滤镜的表现非常符合官方对它的设定。请尽量避免将其运用到色彩鲜艳的场景中，对于室内静物，食物以及一些北欧简约低调的场景都非常适合。另外，A6 款真的非常适合人像，一定要试一试。 B 经典黑白B 系列是黑白经典滤镜包，让照片在彩色和黑白之间起了微妙变化，其中 B1、B2 和 B3 官方使用了「Black &amp; White Classic（经典黑白）」命名，3 款滤镜对暗部细节表现十分优秀，适用于各种场景。下面是 B1、B2 和 B3 的参考样片： B 系列中的另外三款黑白滤镜 B4、B5 和 B6 官方则使用了「Black &amp; White Moody」命名，即略显情绪化，从色彩上反映出些许忧郁。相比之下，这三款滤镜更适合于肖像，高对比度使细节充满了更多戏剧性的色彩。而当其用于景物时，也可以表现出更多的纹理。 C1-C3 Vibrant ClassicC1 会让画面的整体色调带上一层粉红色，白色区域会非常明显。同时使得蓝色偏青，这一点在拍摄晴朗天空等场景时会特别突出。由于对比度提升幅度大，C1 也容易造成阴影部分的细节损失。 C2 虽然也提升了画面的对比度，但同时也提升了画面的亮度。与此同时，C2 对画面的原有色调保留比较好，所以 C2 和 C1 的区别非常大。在光线不太好的地方，选择 C2 要比 C1 的效果好很多。但是，当光线本身较为充足时，C2 又容易导致亮部过曝。 C3 是这三枚滤镜中我最喜欢的，它对画面的对比度和亮度的影响介于 C1 和 C2 之间，相对比较普适。 C4-C9 Chromatic该系列主打中世纪模拟胶片色彩，柔和而又稳重的中性色调让人感觉很「静」，肖像或静物类照片使用这套滤镜，会有非常棒的效果。 根据我使用一周的情况看来，这个系列在日常的适用情形比较少，效果感觉可以通过选择其他更常用的滤镜，配合参数微调达到近似效果，考虑到价格原因，我给出 三星（3/5）的评分，各位可参照示例图并对照平日自己的拍照风格来选用。 E 万用之选官方使用 Essence（本质）和 Archetype（原型）两个词来描述它。该系列色彩明亮而通透、丰富却不显艳丽的特点，适用场景广泛，可谓万用之选，相信你也会喜欢上这种色彩。下面带来 E 系列的参考作品： F Mellow官方使用 Desaturated（欠饱和的）和 Understated（轻描淡写）来形容 F 系列的三款滤镜。F1-F3：Mellow/Fade（柔和/淡色）。标签：低饱和度，肖像。低饱和度且颜色轻淡，F系列预设包用于展现出一种简洁。作为一个能保证表现出胶片品质的万能包，漂亮的肤色和宁静的日常生活是它的长项。F2会使图片偏蓝。 适合原本就很蓝色的照片。 比如海水。 G PortraitsG 系列是一款人物肖像滤镜包，提供了出色的肤色处理效果。这三款滤镜适用于较为清新风格的人物照片，能使肌肤获得较为均匀而又明亮的着色效果。G1、G2 和 G3 可以说是每个摄影爱好者必备的滤镜。 G系列的滤镜能让图片变红。 特别是需要正红的颜色。 G1/G2和G3 : 肖像，拥有明亮的肤色，G1，G2和G3为所有肖像提供一个讨人喜欢的预设集合。 H1-H3 多彩夏日H1 - H3 以 Polychrome Summer（多彩夏日）命名，微妙的粉色、黄色、紫色丰富表现出夏日时光的美好回忆。该系列擅长时尚潮流风格、生活或静物类的照片，是一个完美的通用滤镜包。 H4-H6 多彩冬日H4 - H6 由 Polychrome Winter（多彩冬日）命名，采用更多的冷色调来营造出冬季的梦幻色彩。该系列对拍摄时尚、生活和静物类的照片表现优异，同样也是一个完美的通用滤镜包。 K 深红K 系列基于经典的柯达彩色胶卷，色彩明亮而深红。K 系列虽然仅 K1、K2、K3 三款滤镜，但都非常经典，适合各种场景。我猜测 VSCO 之后会继续扩充 K 系列。下面是这三个滤镜的参考作品： M 情绪M 即取自于英语单词 Mood（情绪）的首字母，稍微褪色和曝光不足表现于 M1、M2、M3 之中。夸张的棕色和绿色使这个滤镜包搭配自然景观最好，适用于静物及较为广阔的环境照片。 M4、M5、M6 表现出来的微妙褪色感来源于 70 年代的复古色调，这三款滤镜是用于城市环境和肖像照片的理想之选。下面是参考作品： N 现代N1 - N3 主打时尚的艺术气息，色彩明亮同时又富有冲击力。当你拍摄这种风格的照片时，能得到非常棒的效果。官方使用了 New Modern（现代），Lights（光亮）这两个词来命名这三款滤镜。下面是参考作品： P 胶片电影P 系列是有三部分组成，包含 P1- P9，共 9 个滤镜，主打胶片电影效果。其中 P1、P2、P3 是暖色调，模拟了温暖、奶油似的色彩和流行的胶片电影效果。适用于食物、时尚和日常生活拍摄的照片。下面 6 幅作品作为这三个滤镜的参考： 同系列下的冷色包由 P4、P5、P6 组成，充满着冷色调以及稍许褪色效果的三个滤镜，模拟出了非常棒的胶片电影效果，偏蓝的冷色调能广泛适用于各种景物照片。 S CleanS 系列（S1 - S6）应该是大部分人使用频率最高的系列之一了，其中，S1、S2、S3 提供了明亮而干净的滤镜效果，这三款滤镜因具有较高的亮度，可以将人物肤色表现得非常完美，在搭配肖像照片或背景色较淡的场景照片时，可以达到最优效果。下面是这三款滤镜的参考作品： 另三款 S4、S5、S6 明亮且色彩更加温暖，充满了夏天的氛围。温暖的橙色和黄色色调非常适合于画面表现活跃的肖像画，有一种沐浴在阳光下的感觉。 T 忧郁-暗调T 系列强烈的褪色效果带有轻微的情绪化，以较高的灰度、丰富的戏剧性般的色调作为补充。T1、T2 和 T3 滤镜将这种气氛带入到一些包含自然环境和光线较暗的照片之中，灰蒙蒙的感觉增添了照片些许神秘感，适合一些纯自然环境的照片和整体不是特别明亮的照片。 X 黑白褪色X 系列也同属于黑白滤镜，作为 B 系列的补充。其中， X1、X2 和 X3 官方使用了「Black &amp; White Heavy Fade」命名，表现出强烈的黑白色调，并稍带褪色感。使用这三款滤镜之后，画面会略显粗糙感，其灰色色调也充满了强烈的戏剧色彩。这几款滤镜质量高，广泛适用。 X4、X5 和 X6 官方则使用了「Black &amp; White Light Tone」命名，即表现黑白色调的同时，质感较轻。柔和而略显活跃的色调，使这三款滤镜更接近于自然。同时大胆的提供了浓淡双色版本， 适用于各种场景，不要错过如此经典的滤镜包。 参考 VSCO Cam 滤镜包详解及购买指南（一） - 少数派 VSCO Cam 滤镜包详解及购买指南（二） - 少数派 VSCO Cam 滤镜包详解及购买指南（三） - 少数派","categories":[{"name":"53.Photograph","slug":"53-Photograph","permalink":"https://beefyheisenberg.github.io/categories/53-Photograph/"}],"tags":[{"name":"摄影","slug":"摄影","permalink":"https://beefyheisenberg.github.io/tags/摄影/"},{"name":"VSCO","slug":"VSCO","permalink":"https://beefyheisenberg.github.io/tags/VSCO/"}]},{"title":"F71.202211-债券大跌的归因","slug":"52.Financing/F71.202211-债券大跌的归因","date":"2024-01-24T01:27:53.588Z","updated":"2024-01-24T01:27:53.588Z","comments":true,"path":"52.Financing/F71.202211-债券大跌的归因/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F71.202211-债券大跌的归因/","excerpt":"@link: F21d.货币-信用周期 @trdr: 这次债券大跌，今天（11月15日）有上万亿的MLF资金到期了要回笼，因为市场担心央妈是不是要开始收紧钱根，债券基金们开始跑路、抛售债券和同业存单等固收类产品，债券跌了连累到相关的理财产品，投资者看理财跌了掀起赎回潮，又循环反馈给债市，加重卖出压力 债券市场收益率快速上行与“非理性抛售”大概率来源于银行理财赎回所造成的恶性循环，并不是因为经济回暖导致的流动性紧缺，没有看到经济数据的明显回升、没有看到明显的通胀压力（CPI同比降了，PPI同比已经转负），没有看到金融数据的企稳（存量社融同比增速继续下行到了10%）， 利率和债市走势相反：宽货币+紧信用时往往利率下行，债券处于牛市；紧货币+宽信用则债券处于熊市。一句话总结：宽货币时债券表现都不差，宽信用时债券表现都不好。但是此次周期并不明显，第一弱复苏，实体经济看不到实质上的复苏，更像是衰退-复苏的来回摇摆，但是CPI时不时的上涨给央行的政策带来了影响，归根结底还是海外加息周期的外部变量+内部疫情内部变量的不确定性 如何观察货币政策的松紧？如何观察信用的松紧？ =&gt; F21d.货币-信用周期,F27a.同业拆借利率（Shibor） 对于某个债基产品： 1机构持有比例不能太高；2如果是低风险的短债，持仓里是否有久期的错配；3杠杆率（=基金总资产/基金净资产）","text":"@link: F21d.货币-信用周期 @trdr: 这次债券大跌，今天（11月15日）有上万亿的MLF资金到期了要回笼，因为市场担心央妈是不是要开始收紧钱根，债券基金们开始跑路、抛售债券和同业存单等固收类产品，债券跌了连累到相关的理财产品，投资者看理财跌了掀起赎回潮，又循环反馈给债市，加重卖出压力 债券市场收益率快速上行与“非理性抛售”大概率来源于银行理财赎回所造成的恶性循环，并不是因为经济回暖导致的流动性紧缺，没有看到经济数据的明显回升、没有看到明显的通胀压力（CPI同比降了，PPI同比已经转负），没有看到金融数据的企稳（存量社融同比增速继续下行到了10%）， 利率和债市走势相反：宽货币+紧信用时往往利率下行，债券处于牛市；紧货币+宽信用则债券处于熊市。一句话总结：宽货币时债券表现都不差，宽信用时债券表现都不好。但是此次周期并不明显，第一弱复苏，实体经济看不到实质上的复苏，更像是衰退-复苏的来回摇摆，但是CPI时不时的上涨给央行的政策带来了影响，归根结底还是海外加息周期的外部变量+内部疫情内部变量的不确定性 如何观察货币政策的松紧？如何观察信用的松紧？ =&gt; F21d.货币-信用周期,F27a.同业拆借利率（Shibor） 对于某个债基产品： 1机构持有比例不能太高；2如果是低风险的短债，持仓里是否有久期的错配；3杠杆率（=基金总资产/基金净资产） 银行缺钱，关债券啥事？ 债券为什么跌？ 因为银行缺钱了，银行是买债的主力（同业存单也是），所以卖掉一部分债券，导致债券价格下跌。银行是否缺钱可以从 DR007、SHIBOR3M 是否走高看出来。 为什么银行会缺钱？而银行之所以最近开始缺钱了，主要有两个原因—— 一个是地产融资改善，交易商协会提到，会「继续推进并扩大民营企业债券融资支持工具，支持包括房地产企业在内的民营企业发债融资」，另一方面则是上周五的防疫政策调整 ，居民和企业贷款多（具体看下月社融） 二是央行公开市场操作总量有所下降，银行担心央行是否收紧钱根，所以选择出售债券 2018-2022 SHIBOR3m数据，可以看到 2020.2月、2022.4月 两个阶段SHIBOR3m大幅下降，这是央行释放了大量的流动性所致，而2022.11月SHIBOR3m的突然提升，也是因为央行回收流动性所致 聊一聊我们平时可能不太重视的债券基金 - 雪球 （1）、债券价格与利率水平呈反向波动，利率处于下行趋势，则债券价格会上涨；利率处于上行趋势，则债券价格会下跌。 （2）、债券基金久期越长的对利率变动越敏感，波动幅度越大。其他条件不变的前提下，利率变动一个百分点（100个基点），久期一年的债券基金单位净值变动幅度大体为1个百分点，三年的变动幅度大体为3个百分点，十年久期的变动幅度大体为10个百分点。 （3）利率处于下行趋势，则债券处于牛市（利率下行见底，债券牛市到头）。短期来看，利率受供需因素影响，宽货币紧信用时往往利率下行，债券处于牛市；紧货币宽信用则债券处于熊市。一句话总结：宽货币时债券表现都不差，宽信用时债券表现都不好。 （4）如果债券已经处于牛市之中，纯债基金可以一把买入。如果处于熊市或震荡市，则需要分批买入，我自己习惯分3-6个月买入。 （5）拉长时间周期到5年以上，利率是经济体的内生变量，而我国和世界主要经济体的GDP增速是趋于下降的，因而总体利率水平长期趋势也是趋于下降的。从这个角度看，债券长期是慢牛走势，长期持有债基是没有问题的 崩了，踩踏式清仓 - 雪球举个例子，假设我们买了一张面值100元，持续时间为一年，利率为2%的债券，我们持有到期后便能拿到102元的利息和本金。假设债券发行的时候，银行存款的利率也是2%，那么买债券和去银行存款的最终收益是一致的。然而，银行存款的利率会有波动，如果银行存款利率从2%提升到3%，那么把钱放到银行显然比买债券的收益大，人们就更倾向卖掉国债了去换存款了。所以当银行存款利率上升，国债就会被抛售，国债价格就会下跌。 但是下跌也会有一个底，跌多少合适呢？维持下面这个公式两边相等就可以了：国债本金+利息=银行存款本金+利息 刚才最开始，国债利率是2%，存款利率也是2%，同样买入100元，两边相等。但后来存款利率升到3%，左边是102元，右边是103元，那就不对等了。要对等的话，国债本金就需要跌1元。跌完之后，其他人在市场买入国债，就不是以100元价格买入了，而是99元买入，但是国债面值还是100元的，到期仍然能够获取100元本金和2元利息，所以实际是赚3元，最终收益跟银行存款是一样的，那么债券就止跌 债券为何接连重挫，怎么看？本轮国内市场债券牛市开始于2021年的2月底3月初，刚好是国内经济最旺盛的时候，而今年国内债券之所以走得这么好，有以下几个原因：第一，地产下行周期居民端购房需求短期低迷，影响居民的信贷需求；第二，疫情的反复，影响企业以以及居民的消费欲望；第三，国内通胀不及预期，货币投放量比较大；第四，今年股票大熊市，赶上地产的下行周期，导致居民更多的资金配置在债券端，压制收益率上行。这跟海外债券市场普遍下跌，收益率快速走高，呈现明显的背离。 但是我们看到以上几点因素近期都出现了明显的变化，首先是地产支持政策进一步加强，这引发市场对于房地产企稳复苏的预期。其次，国内的防疫政策有所调整，明显更加有利于提振经济。最后，美联储大幅度加息后逐渐转鸽派预期，以及10月份通胀数据大幅度的下滑，导致全球资产纷纷出现快速反弹。而前期始终维持在高位的债券资产，包括部分银行理财产品以及债券类基金，由于交易异常拥挤，近期都出现了明显的回撤，甚至不少抹去了近半年来的涨幅，这也表明部分债券类资金开始逐步抄底股市。 债市波动对股市有何影响?_手机新浪网 复盘历史经验，国海证券认为，债市的快速调整核心原因主要分为两类：一是经济周期驱动，二是由流动性收缩主导。若在经济周期驱动的情形下，债市目前的转变对股票市场的影响总体偏积极，股票市场有望进入一轮反弹行情。其中，以消费、周期为代表的顺周期板块往往占优；若是由流动性收缩主导的债市回调，短期内股票市场或受冲击，但局部结构性行情或被强化，“股债跷跷板效应”将驱动增量资金向景气板块的聚集。 债市的裸泳者？深入分析昔日网红富荣中短债的资产配置及风险暴露 - 雪球 1、杠杆率=基金总资产/基金净资产2、利率债比例=国债占净值比例+央行票据占净值比例+地方政府债占净值比例+政策性金融债占净值比例3、信用债比例=非政策性金融债占净值比例+企业债占净值比例+中期票据占净值比例+企业短期融资券占净值比例+同业存单占净值比例 富荣中短债为了提高收益，在三季度增加了杠杆风险和信用风险的暴露。从十年期国债利率的长周期上来看，三季度的国债利率也处于历史底部区域。十年期国债利率在2022年8月中旬触及2.58%的底部水平后开始拐头向上，对应的就是债市的顶部，富荣中短债在这个位置加杠杆，增加信用风险暴露是存在很大风险的 三季度富荣中短债的债券持仓以中期票据为主，占比达到了72.78%，其次是非政策性金融债，占比18.33%。高配的品种都是流动性差的券种，而对流动性较好，信用风险较低的品种国债、政策性金融债、短融、企债都是减持。持仓前5的债券中有2只永续债和3只中期票据，长债仓位占了75.6%，穿透到底仓，这已经不是短债基金了，而是个长债基金，承担了和这个产品类别不相对应的风险； 从前5重仓债券的久期来看，基本在2年左右。前5重仓债券的久期平均值为2.02年，对于中短债基品种来说，这个久期太高了，明显的久期错配，风险错配。而且我们看前面富荣中短债A、C类份额的规模，C类份额显著高于A类，从持有人角度来看都是打算短期持有的，基金经理对此完全的无视了 所以，富荣中短债的高收益源自于他的在杠杆、信用、流动性和久期上面的高风险暴露，可以说没有任何的风险控制措施，一旦潮水褪去，裸泳者暴露无疑。从网红到地狱仅用了2个星期的时间 债券是低流动性且有波动的，持有人是高流动性且无法忍受亏损的，要做好准备就应该大幅缩短久期减少中票永续债大比例配置国债政金债同业存单，把收益和风险往货基上面去靠，或者像部分银行理财一样设置严格的赎回上限，从根源上阻止可能的流动性危机。","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[]},{"title":"F71.202204-离岸人民币对美元升破6.6","slug":"52.Financing/F71.202204-离岸人民币对美元升破6.6","date":"2024-01-24T01:27:53.583Z","updated":"2024-01-24T01:27:53.584Z","comments":true,"path":"52.Financing/F71.202204-离岸人民币对美元升破6.6/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F71.202204-离岸人民币对美元升破6.6/","excerpt":"汇率的三元悖论：@link: F28.蒙代尔不可能三角 人民币对美元汇率逼近 6.2 元时代，这意味着什么？ - 知乎3月3日，中国人民银行授权中国外汇交易中心公布，2022年3月3日银行间外汇市场人民币汇率中间价为：1美元对人民币6.3016元，较上一交易日提升335个基点。此外，在岸人民币、离岸人民币对美元汇率处于6.32关口。 离岸人民币对美元升破 6.32 关口，创 2018 年 5 月来新高，说明什么？ - 知乎 中国外汇 | 李晓：后布雷顿森林体系的国际货币格局|美元新浪财经新浪网 1971年8月15日美国关闭黄金兑换窗口、布雷顿森林体系（美元与黄金挂钩）走向崩溃 布体系瓦解后，美元体系接管：由美元发挥关键货币功能，即美元在国际贸易、投资计价结算中居主导地位，在全球官方储备和金融资产中居领先地位，在全球信用周转体系中居核心地位的国际货币体系。现阶段的美元体系主要依靠三个机制来运行。 第一，石油交易的美元计价机制 第二，商品美元还流机制。 第三，美国对外债务的本币计价机制。美元体系给世界带来的风险与成本： 美元体系日愈具有自利性，其给世界带来的风险与成本日益增加，美元汇率的周期性波动甚至成为触发许多国家和地区货币金融危机的重要因素。 面临着日益上升的通货膨胀压力，美联储正在酝酿退出宽松政策。虽然其具体操作节点与进程尚未明确，但注定将给世界，尤其是新兴经济体的货币与金融稳定带来新一波巨大冲击。","text":"汇率的三元悖论：@link: F28.蒙代尔不可能三角 人民币对美元汇率逼近 6.2 元时代，这意味着什么？ - 知乎3月3日，中国人民银行授权中国外汇交易中心公布，2022年3月3日银行间外汇市场人民币汇率中间价为：1美元对人民币6.3016元，较上一交易日提升335个基点。此外，在岸人民币、离岸人民币对美元汇率处于6.32关口。 离岸人民币对美元升破 6.32 关口，创 2018 年 5 月来新高，说明什么？ - 知乎 中国外汇 | 李晓：后布雷顿森林体系的国际货币格局|美元新浪财经新浪网 1971年8月15日美国关闭黄金兑换窗口、布雷顿森林体系（美元与黄金挂钩）走向崩溃 布体系瓦解后，美元体系接管：由美元发挥关键货币功能，即美元在国际贸易、投资计价结算中居主导地位，在全球官方储备和金融资产中居领先地位，在全球信用周转体系中居核心地位的国际货币体系。现阶段的美元体系主要依靠三个机制来运行。 第一，石油交易的美元计价机制 第二，商品美元还流机制。 第三，美国对外债务的本币计价机制。美元体系给世界带来的风险与成本： 美元体系日愈具有自利性，其给世界带来的风险与成本日益增加，美元汇率的周期性波动甚至成为触发许多国家和地区货币金融危机的重要因素。 面临着日益上升的通货膨胀压力，美联储正在酝酿退出宽松政策。虽然其具体操作节点与进程尚未明确，但注定将给世界，尤其是新兴经济体的货币与金融稳定带来新一波巨大冲击。 人民币汇率破6.3人民币贬值，跟美元 &amp; 疫情有关系？ 导致RMB贬值的原因： 美联储加息，流通的美元减少，导致升值 国内因为疫情出口下降，间接导致RMB贬值 央行应对措施： 降低“外汇准备金”：可以提供借贷的外汇（$美元）增加，流通的美元增加… 人民币贬值真的会促进中国经济增长吗？ - 知乎 如果汇率下跌利好经济，央行为何还要下调外汇存款准备金率？：央行决定从5月15日起，下调外汇存款准备金率1个百分点，由现行的9%下调至8%。截至3月末，我国外币存款余额1.05万亿美元。将外汇存款准备金率下调1%，意味着外汇市场可以增加105亿美元的供给能力。央行这次“下调”，是在离岸人民币对美元汇率短短五个交易日贬值超过3%的形势下紧急释放的外汇政策。政策的即时后果反映了政策的意图。消息落地后，离岸人民币拉升超过200个基点，升破6.58关口；4月25日一度跌破6.57关口的人民币对美元即期汇率，接连收复6.57、6.56关口，升至6.55。 RMB贬值带来的影响： 对出口无利好，比如从出口来讲，东南亚走出疫情，制造业迅速恢复产能，以更低的价格截留我们的出口订单。美元和大多数发达国家，开始转向货币紧缩周期，抑制消费，减少了对中国商品的总需求。这两个因素实际上将抵消一部分甚至大部分人民币汇率下降所带来的出口价格下降的竞争优势。 放大输入性通胀：特别是在目前因为俄乌战争，能源和大宗商品价格持续高位的形势下，再叠加人民币汇率贬值的影响，输入性通胀的影响将变得更为可怕。 加重我们的外债负担：汇率下跌，一方面会增加我们的外债本金，同时还推高外债利率。 加剧资本外流：在美联储不断释放加息预期，但我们开始转向实施适当宽松的货币政策之后，海外投资者再次选择转向西方市场，对我们的债券、证券需求开始下降，对我们的投资冲动开始消退。 刺破资产泡沫。汇率贬值会导致资产缩水，这是基本常识。人民币贬值在重估GDP的同时，还会导致价格高估、泡沫较大的资产价格破裂，这对于房地产业是一个极其不利的消息。因为人民币大幅贬值，国内外游资将抛售人民币资产，转换为美元资产，中小城市的房价会率先下跌，随后也会轮动到大城市的房价下跌。 当初人民币的汇率破7大家都十分关注，现在人民币汇率到达了6.3，会有什么影响吗？ - 知乎从经济学常识来讲，汇率的形成，影响的主要因素涉及到 货币发行量、外债规模、外汇储备规模，进出口规模，外资对我国的直接投资和人民币对外直接投资。一直以来，我们的汇率实际上并非按这些因素所导致的对人民币和外汇的需求变化通过供求市场来形成，主要还是央行控制下的汇率。不过最近这些年，央行通过汇率改革，从直接控制进化为间接控制，即改为通过控制换汇交易来影响汇率的形成。 改革开放阶段：我们开始用货币灌水的手段发展经济。刚开始的时候，我们增发人民币，M2还是挂钩我们的外汇储备规模的。毕竟只要有汇率这东西存在，你本币的M2如不和外汇储备挂钩，一旦有人做空本币，那就非常危险了 2005-2014：受制于房地产成为了支柱产业和经济发展核心推动力的政策，人民币发行脱离了外储的制约，成为房地产规模急剧扩张的推手。2005-2014这十年，M2与外汇储备保持着4:1左右比较稳固的联系，2015年开始，M2与外储的关系开始失去控制，但和商品房销售额建立了稳定的关联，M2与商品房销售额保持着12.5:1的稳定联系。在M2为了适应房地产扩张的需要而同步扩张的时候，我们的外汇储备并未同步跟上扩张的步伐。 一边为了应对房地产的迅速扩张，货币供应量不得不大幅度增加。外债的增长、M2的增速、GDP的增速，都基本上以接近外汇储备2倍速增长，这意味着什么？为什么经济高速增长，外汇储备却相形见绌？因为中国外汇净收入(出口-进口+海外投资盈利+外来投资-外来投资盈利+入境外国游客-本国出境游+国民接收海外汇入-国民境内汇出)的增幅，完全跟不上外债和M2扩张的步伐。前年、去年，我们开始提住房不炒的时候，央行肯定就意识到，一旦房价走低，房地产规模缩小，房地产会严重影响经济走疲，反过来刺激经济，又必须增发 m2。但现在m2不仅已经失去了房地产的联系，又失去了外储的依靠，同时低规模的外储也无法做M2的依靠，因为外储的增速肯定无法追赶M2的脚步，毕竟M2与外储的比例，已经从2010年的25:1，如脱缰的野马，迅速扩大73:1了 M1-M2同比增长率的差值是股市资金供应的一个指标之一 若M1-M2的差值不断变大，说明存款活期化，企业和居民交易活跃，经济景气度上升。若M1-M2的差值不断变小，则表明企业和居民选择将资金以定期的形式存在银行，未来可选择的投资机会有限，多余的资金开始从实体经济中沉淀下来，经济运行回落。 货币供应与股市之间的实证关系表明，M1-M2差值与上证指数呈现较为明显的正向关系。M1-M2差值的拐点对股指有指示作用。","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"宏观经济","slug":"宏观经济","permalink":"https://beefyheisenberg.github.io/tags/宏观经济/"},{"name":"股市","slug":"股市","permalink":"https://beefyheisenberg.github.io/tags/股市/"},{"name":"财经历史数据","slug":"财经历史数据","permalink":"https://beefyheisenberg.github.io/tags/财经历史数据/"}]},{"title":"F71.202204-中美国债利差倒挂","slug":"52.Financing/F71.202204-中美国债利差倒挂","date":"2024-01-24T01:27:53.578Z","updated":"2024-01-24T01:27:53.579Z","comments":true,"path":"52.Financing/F71.202204-中美国债利差倒挂/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F71.202204-中美国债利差倒挂/","excerpt":"最近中/美财经新闻出现最频繁的词是：“倒挂（Inversion）” 3月：关于美国国债收益率曲线倒挂现象及下一步走势研究 4月：中国财政 | 中美利差倒挂的原因、后果、展望与应对 有关债券的收益率，简单来说是当债券买少卖多，债券价格下跌，但是债券收益率上涨。有关债券的票面利率参考F33.债券 中债券的票面利率和到期收益率的部分。 我们提起（国债）收益率倒挂，有两种情况： 第一种倒挂，久期长的国债收益率 &lt; 久期短的国债 第二种倒挂，中美国债收益率倒挂（自2010年起，10年中债收益率都高于10年美债，2022年以来，美债收益率持续上升，中美10年国债利差收窄，在4月份美债收益率超过中债）","text":"最近中/美财经新闻出现最频繁的词是：“倒挂（Inversion）” 3月：关于美国国债收益率曲线倒挂现象及下一步走势研究 4月：中国财政 | 中美利差倒挂的原因、后果、展望与应对 有关债券的收益率，简单来说是当债券买少卖多，债券价格下跌，但是债券收益率上涨。有关债券的票面利率参考F33.债券 中债券的票面利率和到期收益率的部分。 我们提起（国债）收益率倒挂，有两种情况： 第一种倒挂，久期长的国债收益率 &lt; 久期短的国债 第二种倒挂，中美国债收益率倒挂（自2010年起，10年中债收益率都高于10年美债，2022年以来，美债收益率持续上升，中美10年国债利差收窄，在4月份美债收益率超过中债） @link: F33b.美联储加息如何影响国债收益率 情况1：长/短美债利率倒挂2022年3月，美联储宣布加息后，5年10年美国国债收益率出现近15年来首次倒挂，2年10年利差亦大幅收窄并发生短暂倒挂。进入7月，对潜在经济衰退的担忧加剧，长端美债收益率大跌，2年10年美债收益率再度倒挂。 从收益率曲线变化的驱动因素来分析，造成美国国债收益率曲线倒挂的原因可以分为两类。 一是短端利率主导，当即期经济数据显示高通胀或经济过热时，受美联储启动加息（或市场普遍预期美联储将加息）抬升基准利率的影响，短端收益率上涨的幅度高于长端； 二是长端利率主导，加息中后期，市场转而评估紧缩货币政策对未来通胀及经济发展前景的负面影响，长期名义利率计入的长期通胀预期下行，带动长期名义利率下行。总的来说，收益率曲线出现倒挂是美联储货币政策、市场预期以及交易行为等多重因素相互影响后出现的结果。 // 关于加息对短端利率的影响，以及短端利率对长端利率的影响，参考 =&gt; F33b.美联储加息如何影响国债收益率、F33a.长端利率vs短端利率 借短贷长是金融机构普遍的经营模式，即通过发行短期债务来募集资金，投资长期资产。给定一个坡度向上的收益率曲线，这么做当然是有利可图的，因为长期利率高于短期利率；即使短期利率处在上升通道，只要长期收益率在建仓时可以高于未来持仓期间的平均短期利率，投资者仍然可以获利。银行、债券基金都靠这个盈利。 短端利率可以理解为金融机构的资金成本，长端利率为金融机构资产端的收益（也是市场主体的借贷成本）。 但是当短期利率开始上行，借短买长的投资者便面临两大风险。一是其持有的长期资产大概率会因为折现率升高而贬值；而与此同时，对于每季度甚至每个月就要重新去市场里用短期利率借钱的投资者来说，他们的借贷成本会不断上涨。除非投资者可以一直持仓不承担资产的重估值损失，那么大概率机构会面临亏损或被迫清仓。这两种风险在金融术语里统称利率风险。 当短期利率继续上行，收益率曲线出现倒挂时，意味着金融机构的资金成本将高于借贷收益，从而抑制金融机构的借贷意愿，导致经济动能逐步放缓，经济增长走弱。由此，美国（长短期）国债收益率倒挂常被视为美国经济衰退重要风向标。 从历史上每次利率倒挂情况的来看，当市场预期未来经济出现衰退时，长短端利率都会出现一定程度的下行。其中长端利率会因为长期经济增长预期的下降而出现下行，短期利率因为对美联储货币政应对衰退进行宽松的预期，也会下行。但整体上，长端较短端下行幅度更大，因此，会表现出期限利差“压缩”甚至“倒挂”的现象。 2000年7月，美国出现国债收益率倒挂，2001年美国出现经济衰退。 2006年8月，美国出现国债收益率倒挂，2008年全球经济危机来临。 2019年8月，美国出现国债收益率倒挂，2020年美国和全球经济出现严重衰退，当然这次的直接原因是新冠疫情 @ref: https://sc.macromicro.me/spotlights/152/key-charts-global-recession-from-u-s-treasury-yield-inversion ▷ 为什么长短天期国债倒挂比例可以用来观察经济衰退？ 短天期国债收益率则反映利率决策预期，收益率走扬时代表市场预期美联储将升息紧缩；长天期美国国债收益率除反映政策利率，更额外反应景气通胀状况，收益率走扬时代表市场看好未来景气与通胀； 而美债收益率曲线的关係，即是取决于长短天期美债收益率上扬的速率差异。一般情况下，长天期国债承担风险较高，因此应该有相较短天期国债更高的收益率以贴补风险，因此正常情况下，收益率曲线多为正斜率，然而当短天期国债收益率上升的速度对比长天期更快时，就可能产生短天期国债收益率高于长天期的「倒挂」现象。 当倒挂现象发生时，短天期美债收益率反映美联储升息立场而快速上升；长天期收益率则因为经济前景在高物价压力笼罩下不确定性增加，上升速度较慢（甚至出现下降）。在同时面临高物价与紧缩调控、景气疑虑变多时，意味着经济进入衰退的可能性较高，因此，长短天期国债倒挂比例 可用以观察经济衰退机率，当长短天期国债出现倒挂的比例增加时，代表收益率曲线转向负斜率的情况越严峻，景气也面临较高的衰退机率。 情况2：中美10y国债利率倒挂2022年4月，美国十年期国债收益率超过中国十年期国债收益率，这是自2010年下半年以来中美十年期国债收益率首次倒挂。在中美两国经济周期与货币政策双背离的背景下，这种倒挂现象可能会持续较长时间且倒挂幅度较大。 2010年之前，因为中美经济周期不同步、中国金融市场开放程度低，在资本管制下中美利率缺乏联动，中美利差波动较大，出现三次明显的利差倒挂，即2002年1月至2004年6月，2005年1月至2007年10月，2008年9月至2010年6月。 2010年6月之后，随着人民币汇改重启，我国金融市场开放程度大幅提高，中美利率的联动性明显增强，中美国债长期维持正利差，十年期国债利差平均为1.28% 为什么中国国债收益率&gt;美债才是“正常情况”？ 一般情况下十年国债收益率和GDP增长率有较大正相关关系，过去十年大多数时间中国经济增长率更高，说明国内（非国债）投资的收益高，国债要给出更高的利率才能卖出去。 ➤ 倒挂产生的原因 本次中美利差倒挂的直接原因是美联储加息引发美债收益率上涨，深层次原因是中美两国所处的经济周期和货币政策“双背离”。新冠疫情暴发以来，美联储采取量化宽松政策应对疫情冲击。随着美国宏观经济逐步复苏，美国扩张性货币政策的弊端逐步显现。2021年3月至2022年3月末，美国CPI从2%蹿升至8.6%，为过去40年以来的最高值。为抑制高通胀带来的影响，美联储开始进入加息通道，美国国债收益率随之开始快速上升。美国10年期国债收益率由2021年底的1.52%上升至2022年6月14日3.49%的高点。 美联储的加息更多是影响短端利率，长端利率（10Y国债收益率）更多是市场，但是十年期国债收益率上涨的原因是？ 加息意味着可能步入衰退，投资者对美国长期经济不看好，抛售长期国债，导致国债价格↓，收益率↑（可能） 美联储加息需要配合抛售短期高利率的国债，资本大量出售长期国债而流入短期国债，导致长期国债价格↓，收益率↑（可能） @link: F22.宏观调控手段（美联储） ➤ 中美利差倒挂对我国市场三大影响： （一）跨境资本流动。随着中美利差的收窄倒挂，2022年以来我国资本流动方向逆转，资本流出压力加大，多项高频指标均显示出资本外流的明显迹象。境外投资者减持人民币金融资产。 在债券方面，自2021年初中美利差收窄以来，境外投资者持有人民币债券的增速明显放缓，并从2022年2月开始出现罕见减持 在股票方面，2022年第一季度境外投资者持有的沪深股票资产减少7560亿元人民币 （二）加剧人民币汇率贬值。今年3月以来，人民币急剧贬值，人民币汇率从2022年3月1日最高的6.3014急贬至5月13日的6.7898，短短43天贬值7.75%。究其原因，从外部因素来看，俄乌冲突发生后，全球避险情绪加剧，资金回流美国，美元指数从2022年2月18日低点96急升至5月12日的105，这也导致人民币被动积蓄贬值压力。从内部因素来看，本轮疫情对我国的基本面产生显著扰动，国内供应链受阻，出口下滑明显。而中美利差倒挂又与内外部因素相互叠加，造成人民币汇率市场的明显波动。 （三）对我国的货币政策形成一定的掣肘。一方面，“蒙代尔不可能三角”理论认为，一国货币政策的独立性、汇率的稳定以及跨境资本的自由流动这三个目标通常不可能同时达成。从目前情况来看，中美利差收窄倒挂，人民币资产吸引力下降，资本外流，人民币贬值压力加剧。在此背景下，央行若采取宽松的货币政策推动国内利率下行，则会加剧中美利差倒挂，从而增强人民币贬值的预期。但是，国内目前稳增长的压力较大，保持宽松的货币政策环境又是必然选项。这就需要央行在内外部平衡之间做出一定的取舍，导致我国货币政策的实施难度加大。另一方面，中美利差倒挂导致资本外流，外汇占款减少，这会引发国内流动性被动收缩，从而影响我国宽松货币政策的实施效果。 ➤ 中美国债利差和人民币汇率的相关性： 来源：https://sc.macromicro.me/charts/18341/cn-10-year-yield-spread-between-cn-and-us--vs-cnh ➤ 中美国债利差和A股的相关性: 自2010年开始中美利差一直都为正的（中国债收益&gt;美国债收益），当利差收紧时（下跌趋势），A股走势大概率也是下跌趋势，当利差开始走阔（触底反弹），A股很大概率也触底反弹： 来源：https://www.touzid.com/compare/index.html#/edit-3213","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"宏观经济","slug":"宏观经济","permalink":"https://beefyheisenberg.github.io/tags/宏观经济/"},{"name":"股市","slug":"股市","permalink":"https://beefyheisenberg.github.io/tags/股市/"},{"name":"财经历史数据","slug":"财经历史数据","permalink":"https://beefyheisenberg.github.io/tags/财经历史数据/"}]},{"title":"F71.202204-A股见底了吗","slug":"52.Financing/F71.202204-A股见底了吗","date":"2024-01-24T01:27:53.574Z","updated":"2024-01-24T01:27:53.575Z","comments":true,"path":"52.Financing/F71.202204-A股见底了吗/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F71.202204-A股见底了吗/","excerpt":"如何判断A股估值是否到底了？@tldr：一些可能有用的指标 参考 中金|先发制人：A股左侧择时指标探讨提到的几种左侧择时指标：估值百分位、股权风险溢价（股债收益差）、期权认沽认购比、融资融券增长比、中国波指（50ETF恐慌指数, VIX）、北向资金、前后成交额差异… 大盘指数的三个量：PE百分位%、股价、交易量 - by【4.25重挫8%，见证历史 - 芝Sir】见下文↓ 股债收益差： 宽基指数E/P - 国债收益率（看收益差的百分位，越高意味着越被低估），另参考 F33.债券 中关于“国债收益率在资产配置中的使用” 格雷厄姆指数：宽基指数E/P ÷ 国债收益率 （大于2意味着股市非常低估）// @link: F30d.股市择时指标 融资融券余额：这里应该比较增速差，反映市场的多空情绪 // @ref: 融资融券 以及通过宏观经济的一些指标，经济状况同股市有一定相关性： 我们在哪一个经济周期里？复苏/扩张/通胀/衰退… 铜油比、金铜比、金铜比…宏观经济研究员们创造的一个又一个指标 F34a.期货 中美利差收窄甚至倒挂、长短久期债券利差倒挂，这些指标更多的是反应宏观经济的预期，对股市有间接影响 美元指数：美刀作为避险资产，一般来说指数走强很大概率意味着全球经济“可能衰退”，或者有局部战争 资金流动性：M1-M2增速剪刀差、新增社融增量（可能更多的和经济情况相关，但经济预期差，股市也不会好）F23a.M2和社融 政策底、情绪底、市场底、盈利底政策底、情绪底、市场底 你都搞清楚了吗？_天天基金网","text":"如何判断A股估值是否到底了？@tldr：一些可能有用的指标 参考 中金|先发制人：A股左侧择时指标探讨提到的几种左侧择时指标：估值百分位、股权风险溢价（股债收益差）、期权认沽认购比、融资融券增长比、中国波指（50ETF恐慌指数, VIX）、北向资金、前后成交额差异… 大盘指数的三个量：PE百分位%、股价、交易量 - by【4.25重挫8%，见证历史 - 芝Sir】见下文↓ 股债收益差： 宽基指数E/P - 国债收益率（看收益差的百分位，越高意味着越被低估），另参考 F33.债券 中关于“国债收益率在资产配置中的使用” 格雷厄姆指数：宽基指数E/P ÷ 国债收益率 （大于2意味着股市非常低估）// @link: F30d.股市择时指标 融资融券余额：这里应该比较增速差，反映市场的多空情绪 // @ref: 融资融券 以及通过宏观经济的一些指标，经济状况同股市有一定相关性： 我们在哪一个经济周期里？复苏/扩张/通胀/衰退… 铜油比、金铜比、金铜比…宏观经济研究员们创造的一个又一个指标 F34a.期货 中美利差收窄甚至倒挂、长短久期债券利差倒挂，这些指标更多的是反应宏观经济的预期，对股市有间接影响 美元指数：美刀作为避险资产，一般来说指数走强很大概率意味着全球经济“可能衰退”，或者有局部战争 资金流动性：M1-M2增速剪刀差、新增社融增量（可能更多的和经济情况相关，但经济预期差，股市也不会好）F23a.M2和社融 政策底、情绪底、市场底、盈利底政策底、情绪底、市场底 你都搞清楚了吗？_天天基金网 政策底、情绪底、市场底什么是： 政策底主要是指在市场持续下跌时，政府出台一系列组合拳“救市”。一般来说，“政策底”的确认通常伴随着政策组合拳的持续出台，包括货币政策、财政政策和资本市场相关政策。政策落地，往往货币宽松先行，而财政政策和资本市场政策的持续发力是构筑“政策底”的重点。 情绪底”，就是指市场主要投资者对于市场后续走势已经极度悲观，说简单点就是大家对后市不看好，已经不想再“买买买”了。情绪底虽然比较难量化，但我们也可以根据一些数据来跟踪。比如证券市场新增开户人数和公募基金新发认购情况。 市场底，是指市场在一段时间内下跌趋势走完后，形成的一个低点指数，它是过去一段时期内真正的最低指数。 盈利底，伴随着经济下行，不同行业的龙头企业在该季度的盈利都不甚理想，当季度财报（不佳）陆续公布时，还会有一次下跌。 从A股历次筑底行情统计来看，市场一般呈现“政策底—市场底—盈利底”的时间规律：回看市场发现，“政策底”通常领先于“市场底”1.5-3个月：2008-2009年“政策底—市场底—盈利底”分别出现在2008年9月、10月和2009年3月；2015-2016年“政策底—市场底—盈利底”分别出现在2015年7月、8月和2016年6月；“市场底”不一定领先于“盈利底”：2012年盈利底早于市场底3个月；2018年盈利底与市场底同步。(资料来源：《华西证券李立峰：A股历次筑底有何特征？》) 熊市三阶段： 熊市第一阶段：少数投资者对经济和企业盈利的前景能否维持产生怀疑。过高的估值或信贷的收紧驱动产业资本的减持。边际减仓驱动的下跌。 熊市第二阶段：经济和流动性的趋势性恶化，伴随一些长期的制度性的担心，使得投资人系统性普遍性的主动避险减仓。 熊市第三阶段：带止损线的资金，带杠杆的资金，资产管理的资金，因为止损、爆仓、赎回，被迫抛售。// “杠杆底”：熊市第四阶段：大部分投资人信心依然脆弱，盈利依然下行。但市场不再趋势下跌，转为震荡企稳。 但从中长期来看，有两个数据是判断大a股基本面的较好的参考指标。一个是PMI，一个是A股累计归母净利润增速。@ref: 半夏投资李蓓： https://mp.weixin.qq.com/s/CartYlNnGXXziwzni3rYbg 4.25重挫8%，见证历史 - 芝Sir见底的三个特征： 价格跌幅大 估值新低： 成交量低：成交额缩小到近一年的50%-60%左右 or 成交额回到上一轮牛市刚启动的水平 近5日的日均成交额是8213亿元，近一年的日均成交额是10655亿元，而2019年2月上旬牛市刚启动的成交额约4000-5000亿元， 那具备两个特征，少了一个会怎么样呢？有两种可能性： 第一种短期内开启一波反弹行情，但不是大行情，类似2015年9月或者2016年2月的状态。 第二种接着缩量，直到缩量特征满足，之后直接开启下一轮大行情。","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"宏观经济","slug":"宏观经济","permalink":"https://beefyheisenberg.github.io/tags/宏观经济/"},{"name":"股市","slug":"股市","permalink":"https://beefyheisenberg.github.io/tags/股市/"},{"name":"财经历史数据","slug":"财经历史数据","permalink":"https://beefyheisenberg.github.io/tags/财经历史数据/"}]},{"title":"F71.2022-行情备忘录","slug":"52.Financing/F71.2022-股市行情备忘录","date":"2024-01-24T01:27:53.568Z","updated":"2024-01-24T01:27:53.568Z","comments":true,"path":"52.Financing/F71.2022-股市行情备忘录/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F71.2022-股市行情备忘录/","excerpt":"2022 2.18美团闪崩：2月18日港股尾盘时候，FGW等14部门为了疫情后服务业恢复情况，决定倡导外卖等互联网平台降低商户服务费 2.21 传游戏公司2022年不新发版号，港股游戏概念股集体重挫：哔哩哔哩跌超9%，快手跌7%，腾讯跌超5% 2.24 阿里巴巴第三季度净利润同比下降 75%； 2.24 俄罗斯入侵乌克兰 2.28 美国冻结俄罗斯央行海外资产 3.2 G7和欧盟将俄罗斯七家银行踢出SWIFT国际结算系统 Apple停止在俄所有产品销售，暂停部分银行使用apple pay（fb禁止俄媒体投放广告，谷歌宣布 Google Pay 在俄罗斯无限期暂停使用；英特尔、戴尔、AMD 宣布向俄罗斯断供芯片、Oracle 表示已经暂停了在俄罗斯的所有业务 ）infq 3.16 美联储开始加息，25bp 3.12 电子烟的口味方面禁止除烟草口味外的其他口味，雾化添加剂由122项减少至101项。然后美股雾芯科技开盘跌了40% 3.14 网曝阿里、腾讯裁员，PCG/CSIG裁员比例最高 3月14日，港股持续下挫。恒生指数盘中重挫逾1000点，跌超5%；恒生科技指数加速下跌，跌幅超11%，创下该指数最大单日跌幅纪录。其中港股互联网板块跌幅居前。北向资金一共流出 363亿 // 2月中旬以来，港股和中概ADR市场的大幅波动主要是投资者负面情绪的集中发酵所导致。美国SEC首次将五家中概企业列入“预摘牌清单”，这加剧了俄乌冲突、海外货币政策收紧等背景下的恐慌情绪。而3月16日我国金稳会上政策的积极指引又显著提振了投资者风险偏好。 3月16日，在国务院金融委专题会议召开后，证监会党委迅速召开扩大会议传达学习会议精神。证监会继续加强与美方监管机构的沟通，争取尽快就中美审计监管合作达成协议。抓紧推动企业境外上市监管新规落地，支持各类符合条件的企业到境外上市，保持境外上市渠道畅通。贝壳涨近60%，知乎、滴滴涨超40%，拼多多、爱奇艺涨超38%，阿里巴巴、京东、网易、百度均涨超20%。 //在美联储公布加息25个基点后，美股涨幅一度回落，随后大幅飙涨，上演深V反转，纳指涨势最猛，单日暴涨3.77%。美股纳指涨幅一度扩大至3%，标普500指数涨1.91%，道指涨1.06%。 3月PMI：中国3月官方制造业PMI降至49.5，重陷萎缩 3月社融：3月社融超预期，实体融资呈上升趋势 4.25: 上证指数跌破3000，综合原因：上海+北京疫情反复、俄乌冲突、美国通胀美联储5月加息未定、中美国债利差倒挂、中概ADR预摘牌名单 4月PMI：财新4月中国服务业PMI降至36.2，连续第二个月创历史次低 4月社融：信贷、社融双双回落，M2增速超预期……4月金融数据传递哪些信息？ 5.4：美联储加息50bp, 单次最大幅度，6月开始缩表, 本轮累计加息75bp 5.16：首套房贷降20BP 5月PMI：5月财新中国制造业PMI回升至48.1 就业、预期继续走弱 5月社融：2022年5月金融数据点评：社融总量强结构弱 未来或仍反复- 6.16：美联储加息75个bp，至1.50%-1.75%区间，这是美联储自1994年以来最大的一次加息幅度 6月PMI：2022年6月PMI数据点评：6月经济景气度回升明显 两项PMI指数如期转入扩张区间 6月进出口：以美元计，中国6月出口同比增17.9%，高于预期11.9%；进口同比1%，低于预期3% 赵伟：出口强劲，能否持续？（国金宏观） 6月社融：6月金融数据来了！新增信贷、社融超预期回升，还有哪些亮点？ 7.21：欧洲央行（ECB）加息50bp 7.27：美联储加息75个bp，上 调联邦基金利率区间至2.25%-2.50%，为历史上首次连续2个月各加息75BP，回到2018 年12 月时利率水平。 7月PMI：2022年7月PMI数据点评：PMI因何降至线下？ 7月进出口：以美元计，中国7月出口同比增长18%，高于预期16.2%；进口同比增长2.3%，低于预期4.5% 赵伟：出口韧性，或仍将延续（国金宏观） 7月社融：社融天量回落背后是资金空转 - 雪球 8月LPR：下调！1年期LPR降至3.65% 8月PMI：8月财新中国制造业PMI降至49.5 重回收缩区间 8月进出口：以美元计，中国8月出口同比增长7.1%，低于预期13.5%；进口同比0.3%，低于预期1.6% 赵伟：出口“假摔”，还是拐点已现？（国金宏观） 8月社融：8月社融——总量比结构更重要 - 雪球 8月美国CPI：超预期通胀！美劳工部公布8月CPI数据，政府乐观判断被打脸 - 中国日报网 9.8：欧洲央行（ECB）加息75bp // 今年以来，在能源和食品价格高涨的推动下，欧元区的通胀率在9月份上升到了历史最高水平。与去年同月相比，消费价格上涨了9.9%，这是自1999年欧元作为存款货币推出以来的最高值。 9.21：美联储第三次加息75bp, 2022至今累计加息300bp，当前3%-3.25% 9月PMI：中国9月财新服务业PMI为49.3，不及54的预期；9月财新综合PMI为48.5，低于临界值， 9月进出口：以美元计，中国9月出口同比增长5.7%，低于预期5.8%；进口同比0.3%，低于预期1.3% 出口加速回落（国金宏观·赵伟团队） 9月社融：2022年9月金融数据点评：社融超预期 基建持续发力 9月美国CPI：美国9月CPI环比涨幅超预期-新华网 10.8：经文化和旅游部数据中心测算，2022年国庆节假期7天，中国国内旅游出游4.22亿人次，同比减少18.2%，按可比口径恢复至2019年同期的60.7%。实现国内旅游收入2872.1亿元，同比减少26.2%，恢复至2019年同期的44.2%。全国铁路、公路、水路、民航预计发送旅客总量25554.11万人次，日均发送3650.6万人次，比2021年同期日均下降36.4%，比2020年同期日均下降41.4%，比2019年同期日均下降58.1%。（央视）2020年十一全国铁路发送旅客1.2亿；2021年十一全国铁路发送旅客1.1亿；2022年十一全国铁路发送旅客0.68亿；2020年十一票房40亿；2021年十一票房44亿；2022年十一票房14亿； 10.23：20da公布名单 10.24：中概股公司遭遇集体暴跌。纳斯达克中国金龙指数跌幅一度超过20%，拼多多跌超33%，京东跌幅也超过20%，阿里巴巴跌幅接近20%；新东方、哔哩哔哩跌幅也都超过20%；腾讯音乐、爱奇艺跌幅也都超过10%。当天MSCI中国ETF也重挫10%，创下有史以来最大单日跌幅 10.27：欧洲央行（ECB）再次加息75bp，从欧洲央行贷款的基准利率达到2.0% 10月PMI：制造业PMI指数录得49.2%、较上月回落0.9个百分点。 10月CPI：通胀数据显示需求疲软 10月进出口：以美元计，中国10月出口同比降0.3%，低于预期3.4%；进口同比降0.7%，低于预期0.3%，出口加速下滑至负增，生产性产品、多数消费品等出口均明显走弱 出口加速回落进行时（国金宏观·赵伟团队） 10月社融： 社融大幅度低于预期，亟待新的内需政策 10月美国CPI：低于预期！美国10月CPI同比7.7% 较前值8.2%大幅回落 - 华尔街见闻 11-09：中国银行间市场交易商协会继续推进并扩大民营企业债券融资支持工具（“第二支箭”），支持包括房地产企业在内的民营企业发债融资 11.25：全面降准！5000亿元资金来了 11.30：国家统计局：11月制造业PMI为48.0% 比上月下降1.2个百分点 美国11月非农就业人数又大超预期，美联储还会放缓加息吗？ 11月社融： 11月金融、社融数据，货币宽松，社融萎缩 - 雪球 11月PMI： 11月财新中国服务业PMI降至46.7 就业指数创新低_ 12月：中央经济工作会议 12月重大会议前瞻：中央政治局会议与中央经济工作会议宏观研究新浪财经_新浪网 2023全力拼经济——四季度政治局会议传递重大信号 中信建投：中央政治局会议解读 12月FED： 12月15日周四凌晨3点，美联储公布最新的12月利率决议，美联储如期加息50基点，至4.25-4.50%。 经济预期中，美联储上调通胀预期和利率中值预期。 同时美联储仍然继续强调通胀风险。 12月PMI：中国12月官方制造业PMI为47，非制造业PMI为41.6 12月社融：中国12月新增社融1.31万亿元 同比减少1.05万亿 - 雪球 2021 2021.4.10 阿里巴巴因滥用市场支配地位行为，被处182.28亿元巨额罚款 2021.7.24 双减政策落地，教培机构陷入倒闭潮 2021.8.4 段永平抄底腾讯 2021.10 美团因“二选一”，涉嫌垄断行为被罚34.42亿元 2021.10 近日，查理·芒格旗下公司Daily Journal Corporation公布的第三季度13-F文件显示，该公司又购买了136740股阿里巴巴股票，使其股票总数达到302060股。https://finance.sina.com.cn/stock/hkstock/ggscyd/2021-10-07/doc-iktzqtyu0072135.shtml 10月7日，阿里巴巴率领一众互联网概念股大反弹。截至发稿，港股阿里巴巴大涨5.9%，报145.4港元。 2021.11 正式施行的《个人信息保护法》，该法律明确要求互联网平台不得有过度收集个人信息、大数据杀熟等行为。 2021.12.3 恒大债务危机：恒大集团在香港联交所发布无法履行2.6亿美元担保责任的公告，鉴于目前的流动性情况 2021.12.14 国家市场监管总局对腾讯、阿里、百度依法作出处罚","text":"2022 2.18美团闪崩：2月18日港股尾盘时候，FGW等14部门为了疫情后服务业恢复情况，决定倡导外卖等互联网平台降低商户服务费 2.21 传游戏公司2022年不新发版号，港股游戏概念股集体重挫：哔哩哔哩跌超9%，快手跌7%，腾讯跌超5% 2.24 阿里巴巴第三季度净利润同比下降 75%； 2.24 俄罗斯入侵乌克兰 2.28 美国冻结俄罗斯央行海外资产 3.2 G7和欧盟将俄罗斯七家银行踢出SWIFT国际结算系统 Apple停止在俄所有产品销售，暂停部分银行使用apple pay（fb禁止俄媒体投放广告，谷歌宣布 Google Pay 在俄罗斯无限期暂停使用；英特尔、戴尔、AMD 宣布向俄罗斯断供芯片、Oracle 表示已经暂停了在俄罗斯的所有业务 ）infq 3.16 美联储开始加息，25bp 3.12 电子烟的口味方面禁止除烟草口味外的其他口味，雾化添加剂由122项减少至101项。然后美股雾芯科技开盘跌了40% 3.14 网曝阿里、腾讯裁员，PCG/CSIG裁员比例最高 3月14日，港股持续下挫。恒生指数盘中重挫逾1000点，跌超5%；恒生科技指数加速下跌，跌幅超11%，创下该指数最大单日跌幅纪录。其中港股互联网板块跌幅居前。北向资金一共流出 363亿 // 2月中旬以来，港股和中概ADR市场的大幅波动主要是投资者负面情绪的集中发酵所导致。美国SEC首次将五家中概企业列入“预摘牌清单”，这加剧了俄乌冲突、海外货币政策收紧等背景下的恐慌情绪。而3月16日我国金稳会上政策的积极指引又显著提振了投资者风险偏好。 3月16日，在国务院金融委专题会议召开后，证监会党委迅速召开扩大会议传达学习会议精神。证监会继续加强与美方监管机构的沟通，争取尽快就中美审计监管合作达成协议。抓紧推动企业境外上市监管新规落地，支持各类符合条件的企业到境外上市，保持境外上市渠道畅通。贝壳涨近60%，知乎、滴滴涨超40%，拼多多、爱奇艺涨超38%，阿里巴巴、京东、网易、百度均涨超20%。 //在美联储公布加息25个基点后，美股涨幅一度回落，随后大幅飙涨，上演深V反转，纳指涨势最猛，单日暴涨3.77%。美股纳指涨幅一度扩大至3%，标普500指数涨1.91%，道指涨1.06%。 3月PMI：中国3月官方制造业PMI降至49.5，重陷萎缩 3月社融：3月社融超预期，实体融资呈上升趋势 4.25: 上证指数跌破3000，综合原因：上海+北京疫情反复、俄乌冲突、美国通胀美联储5月加息未定、中美国债利差倒挂、中概ADR预摘牌名单 4月PMI：财新4月中国服务业PMI降至36.2，连续第二个月创历史次低 4月社融：信贷、社融双双回落，M2增速超预期……4月金融数据传递哪些信息？ 5.4：美联储加息50bp, 单次最大幅度，6月开始缩表, 本轮累计加息75bp 5.16：首套房贷降20BP 5月PMI：5月财新中国制造业PMI回升至48.1 就业、预期继续走弱 5月社融：2022年5月金融数据点评：社融总量强结构弱 未来或仍反复- 6.16：美联储加息75个bp，至1.50%-1.75%区间，这是美联储自1994年以来最大的一次加息幅度 6月PMI：2022年6月PMI数据点评：6月经济景气度回升明显 两项PMI指数如期转入扩张区间 6月进出口：以美元计，中国6月出口同比增17.9%，高于预期11.9%；进口同比1%，低于预期3% 赵伟：出口强劲，能否持续？（国金宏观） 6月社融：6月金融数据来了！新增信贷、社融超预期回升，还有哪些亮点？ 7.21：欧洲央行（ECB）加息50bp 7.27：美联储加息75个bp，上 调联邦基金利率区间至2.25%-2.50%，为历史上首次连续2个月各加息75BP，回到2018 年12 月时利率水平。 7月PMI：2022年7月PMI数据点评：PMI因何降至线下？ 7月进出口：以美元计，中国7月出口同比增长18%，高于预期16.2%；进口同比增长2.3%，低于预期4.5% 赵伟：出口韧性，或仍将延续（国金宏观） 7月社融：社融天量回落背后是资金空转 - 雪球 8月LPR：下调！1年期LPR降至3.65% 8月PMI：8月财新中国制造业PMI降至49.5 重回收缩区间 8月进出口：以美元计，中国8月出口同比增长7.1%，低于预期13.5%；进口同比0.3%，低于预期1.6% 赵伟：出口“假摔”，还是拐点已现？（国金宏观） 8月社融：8月社融——总量比结构更重要 - 雪球 8月美国CPI：超预期通胀！美劳工部公布8月CPI数据，政府乐观判断被打脸 - 中国日报网 9.8：欧洲央行（ECB）加息75bp // 今年以来，在能源和食品价格高涨的推动下，欧元区的通胀率在9月份上升到了历史最高水平。与去年同月相比，消费价格上涨了9.9%，这是自1999年欧元作为存款货币推出以来的最高值。 9.21：美联储第三次加息75bp, 2022至今累计加息300bp，当前3%-3.25% 9月PMI：中国9月财新服务业PMI为49.3，不及54的预期；9月财新综合PMI为48.5，低于临界值， 9月进出口：以美元计，中国9月出口同比增长5.7%，低于预期5.8%；进口同比0.3%，低于预期1.3% 出口加速回落（国金宏观·赵伟团队） 9月社融：2022年9月金融数据点评：社融超预期 基建持续发力 9月美国CPI：美国9月CPI环比涨幅超预期-新华网 10.8：经文化和旅游部数据中心测算，2022年国庆节假期7天，中国国内旅游出游4.22亿人次，同比减少18.2%，按可比口径恢复至2019年同期的60.7%。实现国内旅游收入2872.1亿元，同比减少26.2%，恢复至2019年同期的44.2%。全国铁路、公路、水路、民航预计发送旅客总量25554.11万人次，日均发送3650.6万人次，比2021年同期日均下降36.4%，比2020年同期日均下降41.4%，比2019年同期日均下降58.1%。（央视）2020年十一全国铁路发送旅客1.2亿；2021年十一全国铁路发送旅客1.1亿；2022年十一全国铁路发送旅客0.68亿；2020年十一票房40亿；2021年十一票房44亿；2022年十一票房14亿； 10.23：20da公布名单 10.24：中概股公司遭遇集体暴跌。纳斯达克中国金龙指数跌幅一度超过20%，拼多多跌超33%，京东跌幅也超过20%，阿里巴巴跌幅接近20%；新东方、哔哩哔哩跌幅也都超过20%；腾讯音乐、爱奇艺跌幅也都超过10%。当天MSCI中国ETF也重挫10%，创下有史以来最大单日跌幅 10.27：欧洲央行（ECB）再次加息75bp，从欧洲央行贷款的基准利率达到2.0% 10月PMI：制造业PMI指数录得49.2%、较上月回落0.9个百分点。 10月CPI：通胀数据显示需求疲软 10月进出口：以美元计，中国10月出口同比降0.3%，低于预期3.4%；进口同比降0.7%，低于预期0.3%，出口加速下滑至负增，生产性产品、多数消费品等出口均明显走弱 出口加速回落进行时（国金宏观·赵伟团队） 10月社融： 社融大幅度低于预期，亟待新的内需政策 10月美国CPI：低于预期！美国10月CPI同比7.7% 较前值8.2%大幅回落 - 华尔街见闻 11-09：中国银行间市场交易商协会继续推进并扩大民营企业债券融资支持工具（“第二支箭”），支持包括房地产企业在内的民营企业发债融资 11.25：全面降准！5000亿元资金来了 11.30：国家统计局：11月制造业PMI为48.0% 比上月下降1.2个百分点 美国11月非农就业人数又大超预期，美联储还会放缓加息吗？ 11月社融： 11月金融、社融数据，货币宽松，社融萎缩 - 雪球 11月PMI： 11月财新中国服务业PMI降至46.7 就业指数创新低_ 12月：中央经济工作会议 12月重大会议前瞻：中央政治局会议与中央经济工作会议宏观研究新浪财经_新浪网 2023全力拼经济——四季度政治局会议传递重大信号 中信建投：中央政治局会议解读 12月FED： 12月15日周四凌晨3点，美联储公布最新的12月利率决议，美联储如期加息50基点，至4.25-4.50%。 经济预期中，美联储上调通胀预期和利率中值预期。 同时美联储仍然继续强调通胀风险。 12月PMI：中国12月官方制造业PMI为47，非制造业PMI为41.6 12月社融：中国12月新增社融1.31万亿元 同比减少1.05万亿 - 雪球 2021 2021.4.10 阿里巴巴因滥用市场支配地位行为，被处182.28亿元巨额罚款 2021.7.24 双减政策落地，教培机构陷入倒闭潮 2021.8.4 段永平抄底腾讯 2021.10 美团因“二选一”，涉嫌垄断行为被罚34.42亿元 2021.10 近日，查理·芒格旗下公司Daily Journal Corporation公布的第三季度13-F文件显示，该公司又购买了136740股阿里巴巴股票，使其股票总数达到302060股。https://finance.sina.com.cn/stock/hkstock/ggscyd/2021-10-07/doc-iktzqtyu0072135.shtml 10月7日，阿里巴巴率领一众互联网概念股大反弹。截至发稿，港股阿里巴巴大涨5.9%，报145.4港元。 2021.11 正式施行的《个人信息保护法》，该法律明确要求互联网平台不得有过度收集个人信息、大数据杀熟等行为。 2021.12.3 恒大债务危机：恒大集团在香港联交所发布无法履行2.6亿美元担保责任的公告，鉴于目前的流动性情况 2021.12.14 国家市场监管总局对腾讯、阿里、百度依法作出处罚","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"财经历史数据","slug":"财经历史数据","permalink":"https://beefyheisenberg.github.io/tags/财经历史数据/"}]},{"title":"F59.凯利公式","slug":"52.Financing/F59.凯利公式","date":"2024-01-24T01:27:53.564Z","updated":"2024-01-24T01:27:53.564Z","comments":true,"path":"52.Financing/F59.凯利公式/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F59.凯利公式/","excerpt":"约翰·拉里·凯利出生于1923年12月26日，二战期间凯利到了法定服役年龄，在海军航空部队当了4年飞行员，曾是二战期间的王牌飞行员。1953年他获得了物理学博士学位，博士论文题目为“不同材料的二阶弹性研究”，这项研究非常重要，使得凯利收到了贝尔实验室的工作邀请。这样30岁的凯利来到了贝尔实验室工作 该公式最早于1956年由物理学家约翰·L·凯利在《贝尔系统技术期刊》中发表，可以用来计算一个在期望净收益为正的独立重复赌局中，使本金长期增长率最大化的投注资金比例。 凯利公式和仓位管理玩一个设定对你有利的游戏","text":"约翰·拉里·凯利出生于1923年12月26日，二战期间凯利到了法定服役年龄，在海军航空部队当了4年飞行员，曾是二战期间的王牌飞行员。1953年他获得了物理学博士学位，博士论文题目为“不同材料的二阶弹性研究”，这项研究非常重要，使得凯利收到了贝尔实验室的工作邀请。这样30岁的凯利来到了贝尔实验室工作 该公式最早于1956年由物理学家约翰·L·凯利在《贝尔系统技术期刊》中发表，可以用来计算一个在期望净收益为正的独立重复赌局中，使本金长期增长率最大化的投注资金比例。 凯利公式和仓位管理玩一个设定对你有利的游戏 假设现在有一个公平的投资游戏，获胜和失败的概率都是50%。如果获胜，玩家的收益率是40%；如果失败，玩家会亏损30%。对于一个理性人来说，他一定会选择参加这个游戏，并且把这个游戏重复下去。为什么呢？因为单次游戏的期望收益是正数，也就是说，游戏的设计对他是有利的。举个例子，玩家投入1元钱，那么获胜可以取得1*(1+40%)=1.4元，而失败可以拿回1*(1-30%)=0.7元，这两种情况出现的概率都是50%，所以进行一次游戏后，玩家资产的期望是1.4*50%+0.7*50%=1.05元。玩家净赚0.05元，收益率5%。 在这样的情况下，如果初始资金是1元，游戏将重复100次，我们应该如何分配每次投资的仓位呢？肯定会有朋友认为，既然单次游戏的结果这么有利，那岂不是投得越多，赚得越多？我每把都全仓梭哈不就好了吗？——全仓梭哈会怎么样呢？由于胜率是50%，出手100次，那么获胜的期望次数是50次，失败的次数也是50次，按此假定（当然实际情况可能会有差异）。则玩家最终的资产是： 说到这里，也许有的朋友还是不能理解，这看似优势满满的设定，是如何在全仓梭哈的过程中蚕食掉我们的资产的呢？因为全仓梭哈的玩家，将自己过多的暴露在了“极端风险”当中，“十赌九输”也并不是一句玩笑话。 如果用凯利公式，可以计算出玩这个游戏单次投资的最佳仓位： 最佳的仓位设置是40%，使得资产直接增长1.8倍，而仓位高于或低于40%，起到的都是“副作用”； 每次只投资10%的仓位，最终也可实现55%的收益率； 全仓梭哈是最差的选择； @ref: 与友漫谈——什么是凯利公式 - 雪球 还不重视仓位管理？看似小事，却可以决定你的投资收益率- 雪球","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"量化交易","slug":"量化交易","permalink":"https://beefyheisenberg.github.io/tags/量化交易/"},{"name":"交易策略","slug":"交易策略","permalink":"https://beefyheisenberg.github.io/tags/交易策略/"}]},{"title":"F52z.Quant-量化交易经典策略","slug":"52.Financing/F52z.Quant-量化交易经典策略zz","date":"2024-01-24T01:27:53.559Z","updated":"2024-01-24T01:27:53.560Z","comments":true,"path":"52.Financing/F52z.Quant-量化交易经典策略zz/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F52z.Quant-量化交易经典策略zz/","excerpt":"量化交易主要有哪些经典的策略？量化交易主要有哪些经典的策略？ - flyerye的回答 - 知乎这是一个对于刚入门的投资者的好问题。讲之前，先推荐一本好书《Efficiently Inefficient》（作者：Lasse Heje Pedersen）。它对于想了解对冲基金的朋友，是一本很好的启蒙书籍。不说废话，讲正题。从对冲基金的角度，交易策略可以有以下分类（来自《Efficiently Inefficient》）： 我们可以先把交易策略大体分成三类：1）股票策略 2）宏观策略 3）套利策略。其中，股票策略和宏观策略的收益主要来自投资目标的实际价值（absolute value）的变化，而套利策略的收益来自一对或一组投资目标的相对价值（relative value）的变化。这三者不是完全的独立，比如套利策略也有应用于股票市场，宏观资产配置也会借鉴股票策略中基本面分析方法。之所以这么分是因为三者有各自显著的特点。下面我们来逐一介绍：","text":"量化交易主要有哪些经典的策略？量化交易主要有哪些经典的策略？ - flyerye的回答 - 知乎这是一个对于刚入门的投资者的好问题。讲之前，先推荐一本好书《Efficiently Inefficient》（作者：Lasse Heje Pedersen）。它对于想了解对冲基金的朋友，是一本很好的启蒙书籍。不说废话，讲正题。从对冲基金的角度，交易策略可以有以下分类（来自《Efficiently Inefficient》）： 我们可以先把交易策略大体分成三类：1）股票策略 2）宏观策略 3）套利策略。其中，股票策略和宏观策略的收益主要来自投资目标的实际价值（absolute value）的变化，而套利策略的收益来自一对或一组投资目标的相对价值（relative value）的变化。这三者不是完全的独立，比如套利策略也有应用于股票市场，宏观资产配置也会借鉴股票策略中基本面分析方法。之所以这么分是因为三者有各自显著的特点。下面我们来逐一介绍： 1）股票策略：股票策略主要指的是单一的应用于股票市场的交易策略。按照人的主观和计算机在策略的参与程度，我们把股票策略分成主动权益投资和主动量化投资。这里的主动投资更准确的翻译是决定型交易，之所以称为主动权益投资，是因为这是业界一般的称呼。主动权益投资主要是靠投资者的主观判断，他们通过对行业和企业的深入调查，形成自己的投资逻辑，然后进行筛选股票。这里又根据交易的限制分为多空策略，做多策略和做空策略。这里提一下做空策略（见于国外），只做空的投资者往往会把目标锁定在，那些对外披露的报告和实际表现不符的公司，然后去调查该公司的财务状况是否作假。该策略类型的代表就是浑水公司（Muddy Waters Research）。 相较于主动权益投资，主动量化投资 是把自己的逻辑输入计算机，通过计算机的快速运算，来构建自己的投资组合。它和主动权益投资的区别体现在研究的深度和广度上。量化投资依赖于数据。换句话说，对于那些不是以数据形式存在的信息（比如与他人的谈话），计算机是没法获得的，也无法转化成交易信号。从这个角度来看，量化投资对单一股票的研究深度不如主动权益投资。但是，借助于计算机的快速处理能力，量化投资所构建的自动化模型，能在短时间内消化各种类型的数据信息，并且把它转换成有价值的交易信号。从这个角度来看，量化投资在研究的广度上比主动权益投资更具有优势。在中国的股票市场，目前主要存在的量化交易策略是多因子选股模型（具体不在这里做介绍）和一些基于流动性的高频交易策略。前者更适用于资金规模大的公募基金，后者则适用于追求短期高回报的私募基金。 2）宏观策略：宏观策略的投资范围不局限于单一类型的市场，而是进行全类型市场的投资。这一类型的策略又可以分成以期货为投资工具的CTA策略，和宏观资产配置策略。 CTA策略全称是Commodity Trading Advisor Strategy，即“商品交易顾问策略”，也被称作管理期货策略。是由专业的管理人以追求绝对收益为目标，运用客户委托的资金投资于期货市场、期权市场，并收取相应投资顾问费用的一种基金形式。从具体策略来看，CTA可以划分为趋势、反转和套利策略。趋势策略是指跟踪大宗商品不同周期的趋势，进行做多或做空操作；反转策略是指利用期货价格的反转性波动进行反向交易；套利策略包括跨期套利和跨品种套利，是指利用相关品种不同期限的价格走势关系进行交易。 CTA策略是动量策略的代表作。动量策略又称作趋势型策略。它研究的是价格的变化趋势，基于行为金融学，找到价格变化背后的规律（动量和反转），通过趋势变化的规律赚取收益。CTA通过期货标的物，可以把自己的投资范围扩大到各个类型的资产，这样的目的是为了分散动量策略本身的高风险。 宏观资产配置策略多被一些全球资产管理公司以及投行（如德意志银行）采用。策略主要研究的是宏观经济的变化，然后做多或做空某一区域的所有类型的市场。比如如果某资产管理公司相信中国经济会持续高速增长，它就会做多中国的股指，做多中国的国债，做多与中国贸易有关联的大宗商品等等。 3）套利策略：套利在这里是一种方式，因此它理论上可用于不同类型的市场。对于固收类产品，因为未来的现金流动比较固定，所以其价格与到期时间，利率，通胀，信用利差之间的关系更为确定。借助这个特点，投资者能更容易找到固收类产品之间的关系，也产生出更为多样的套利策略。另外，在海外市场，固收类产品有着更丰富的结构特性和相应的衍生品（如CDS）作为辅助，所以相应的策略比国内市场更为多样。事件驱动类的套利一般用在兼并收购这类事件，通过预测事件是否成功，从而做多或做空与参与者相关的股票，债券等产品。 当然，策略的分类方式不是固定的。本篇只是借助《Efficiently Inefficient》的对冲基金策略的分类方式对几个常见的交易策略进行了介绍。细化到量化交易的策略，可以包括股票市场的多因子选股模型，高频交易，CTA，宏观资产配置，固定收益套利等。像高频交易，固定收益套利这类的策略，底下还有很多细分的量化交易策略。具体的，可以看看专门这方面的书籍。 量化交易主要有哪些经典的策略？ - BigQuant的回答 - 知乎量化交易起源于国外，在国外已经至少有长达几十年的发展历程，因此我们先看一下国外比较经典有效的一些策略。 中长线的交易策略： Aberration trading system Aberration 交易系统由Keith Fitschen 于1986 年发明，1993 年KeithFitschen 将该系统商业化发布，自发布之日起，该系统业绩一直名列前茅，在1997 年、2001 年、2005 年已发布交易系统的业绩排名中该系统均排名前十。该交易系统的特点是同时交易在8 种不同的品种上，包括谷物、肉类、金属、能源、外汇、金融以及股指期货等。Aberration 交易系统的交易频率常常是每年交易某一品种3-4 次，60%的时间都持有仓位，平均每笔交易持仓60 天。它通过长线交易捕捉趋势来获取巨额利润。那它如何来弥补亏损呢？因为它同时交易在多个不相关的市场，当某一品种损失时，另一品种可能获利。在一年的时间里，总是有某一种或者多种品种能获得巨额利润。这些大的利润弥补了那些没趋势市场的小额亏损。Aberration 交易系统对资金进行组合管理，因此可以接受比较大的资金量。 Andromeda Andromeda 交易系统于2001 年由Petros Development Corp 开发，是一个长线趋势交易系统，依赖简单的数学公式完全客观地进行交易，不带主观成分，并可以使用在多个市场。该系统于2002 年4 月发布，其核心优势是在公开发布之后也依然能保持稳定业绩。Andromeda 交易系统针对不同的市场都是用采同一套规则和参数，并没有进行最优化处理，属于非曲线匹配系统，样本外测试和样本内测试的结果一致，并且在发布后将近十年的时间里得到了验证。不同大小的资金账户皆可使用，由于是日线模型，因此不需要天天盯市，所有的进场出场指令均在下一日的开盘执行，有时候也可能很多天没有交易。 Andromeda 平均每笔交易的持仓时间为60-65 天，该系统的一大特色是，交易终止点不是根据价格，而是根据持仓时间而定。 Checkmate trading system Checkmate 交易系统是一个独特的交易系统，该系统最大的特点是，它的目标不是最大化利润，而是保证收益率的一致性和最大回撤最小化。该系统在全部的品种上使用相同的交易法则和参数，因此避免了过度优化和曲线匹配的问题。Checkmate 在进场点选择上把关严格，可能在跟踪时同时监控多个品种，但交易很少，这使Checkmate 使用的保证金平均来看会比其他系统要少。因此这个系统可以让较小的账户里来交易大额的组合。Checkmate 是中线交易系统，目的是捕捉中线趋势，它采用改进趋势过滤，这种方法可以使Checkmate 经常能在获利最大的最近高点或低点离场，这点和那些有大回撤的趋势系统有所不同，它能迅速止盈离场，因此Checkmate 让交易者的心理相对舒适。 Golden SX trading system Golden SX 系统发布于1995 年，到目前16 年的时间里，仅2005 年一年不盈利。它可以同时交易在13 个不同的品种上，并且采用相同的交易法则。Golden SX 采用一个十分有效的指标GSX Indicator，在开始交易前会先等市场有小幅回调再介入，以此来改进交易的成功率。系统有两种止损方法，一个是资金保护止损点，另一个是持有头寸后基于盈利的止损，这样可以保护资金的同时保证盈利。 新的改进版本Golden SX Electronic 于2009 年发布。可以对其中2 个参数做一定优化，也可以不优化。1983 年-2010 年的测试显示，该系统有60%的时间持有头寸，多个市场的平均胜率在56%左右。 Ready-Set-Go trading system Ready-Set-Go 交易系统是一个长线交易系统，可以使用在多个市场，自2000 年公布以来都是使用相同的法则和参数，参数值可以根据市场趋势强弱自动调整。该系统可以使用在多个市场，自1970 以来至2011 年中，系统交易于8 个市场，在扣除每笔交易100 美元费用后平均收益率43%，平均每年每个市场交易3-4 笔。 Ready-Set-Go 的进场点和离场点均会随趋势强度的变化而变化，持仓时间从一两周至半年不等，极少数情况会持仓1 年。该系统只有50-60%的时间是持有头寸的。它的止损方式是基于波动率过滤的移动止损，可以为百分比止损，或是资金止损。 STC S&amp;P Daytrade trading system 该系统每月平均交易10 笔左右，每天交易不超过2 笔。市场总是有起有伏，该系统首先采用”Price Trend Indicator”价格趋势指数来判断市场是超买还是超卖，超买的市场应该卖出头寸，超卖的市场应该买入头寸。第一笔交易进场方法是根据开盘价设一个区间，高于开盘价某些点位即买入，低于开盘价某些点位即卖出。日趋势通常会在3-4 天后改变方向，或是遇到跳空开盘，这些日子被称为”key reversal days”关键转折日。这种日子在目前的市场正在不断增多，因此有一套”Superior Clear-OutReversal Enhancement”系统来帮助找出反转信号并开始新方向的交易。最后，该系统每天都有不同的风险暴露，因此需要设臵止损，系统采用”Dynamic Risk Exposure Stops”方法止损。 日内交易策略日内的经典策略有： RANGE BREAK 波动区间突破交易，根据昨天波动幅度的一定百分比，来触发当日的趋势交易，如果昨天的波动幅度是异常的，应当对该波动幅度进行必要的调整，以保持合理性。 菲阿里四价 昨天高点，昨天低点，昨天收盘，今天开盘，可并称为菲阿里四价，它是由日本期货冠军菲阿里实盘采用的主要突破交易的参照系，此外，因菲阿里主观心智交易的模式，决定了其在实际交易中，还大量结合应用了“阻溢线”的概念，即我们通常所说的压力、支撑线。 空中花园 开盘突破，是最快的一种入场方式，当然出错的概率也最高，开盘第一根K线是收阳，还是收阴，是判断日内趋势可能运动方向的标准，我们发现这种入场在当天开盘 高开或低开时更为有效。在《期市截拳道》中，我把这种交易策略称为“空中花园”，有幸的是，听说西蒙斯在早期也曾经应用过类似的交易策略。 横盘突破 较易于实现量化的形态突破，有分型，窄幅横盘突破，各种K线组合、双顶、双底、缠论三买三卖等，较难于实现量化的形态突破，有趋势线、圆孤顶底、旗型、菱 形、三角形等各种经典技术分析形态，趋势之后是盘整，盘整之后是趋势，横盘突破的交易策略，充分体现了波动性循环的价格波动规律，我们需要做的事情就是合 理量化盘整的定义：周期跨度、波动幅度。 基于固定百分比幅度的转向交易 该系统曾在某交易系统策略大赛中荣获第二名的殊荣，也是笔者最为衷情的日内突破交易策略。相对而言，基于固定点位的突破，可能会受制于品种价格区域的变化而变迁，基于固定百分比幅度的突破，则较少受到类似的困扰，除非该品种的波动性水平发生巨变。 HANS123 作为外汇市场上广为流传的一种突破交易策略，HANS123以其简捷的开盘后N根K线（分钟）的高低点突破，作为交易信号触发的评判标准。这也是一种入场较早的交易模式，配套价格包括带、时间确认、波动幅度要求等项过滤技术、或可提高其胜算。 日均ATR波动性突破 我们有理由相信，当一定幅度的ATR波动性幅度已经发生，我们将更愿意去赌日内波动的方向朝着这个已经完成一定幅度ATR的方向继续发展，比较的基准，可以是开盘价，也可以是日内创下的新高、新低记录位置。 ORB失败突破 ORB交易最早于1988年由美国基金经理托比提出，它通过衡量开盘价与最高价、最低价距离的取小者，为失败突破幅度，后市一旦超出这个幅度，就认为真正的突破。在实际应用过程中，早评的突破、窄幅波动日后的突破，可以作为有效的过滤条件。 分时均价黄线 在此我无意讨论其它均线系统的日内表现，分时均价黄线，因其广泛出现于各类交易软件的内置分时走势图中，因而，就交易策略的自我实现预言而论，它的地位格外突出，醒目。 日内ATR波动性突破 与E7不同，E10更侧重于短期市场波动率的变化评估，波动性突破，在一定程度上具备适应市场的功能，在实际应用于适应不同市场环境的能力更强。 量化的字面含义其实表明是对收益和风险进行数量化建模管理。通常是结合“对冲”俩字一起使用。量化对冲策略即同时利用量化手段和对冲技巧的投资策略。经典的量化对冲策略有市场中性策略、事件驱动套利策略三种。 具体可见下图所示： 市场中性策略： 市场中性策略通过构造股票多空组合减少对某些风险的暴露;最典型的对冲策略是Alpha策略，通过构建相对价值策略来超越指数，通过指数期货或期权等风险管理工具消除投资组合的大部分或全部系统风险，获得额外收益。由于买入和卖出金额接近，中和了市场总体风险，管理业绩与市场牛熊无关，这就是“股票市场中性策略”的由来。国内对冲策略产品大多采用买入现货、卖出期货的对冲策略，期货价格和现货价格之间的差异会影响策略表现。 套利策略： 统计套利：统计套利通过对相关证券进行对冲来获得与市场相独立的稳定性收益。在价格出现背离走势的时候买进表现相对差的，卖出表现相对好的，就可以期待在未来当这种背离趋势得到纠正时获得相对稳定的收益。它的风险在于如果市场并未按照预想出现价格回归，而是进一步扩大价差，可能会产生风险。 期现套利：期现套利是指某种期货合约，当期货市场与现货市场在价格上出现差距，低买高卖而获利。当现货指数被低估，某个交割月份的期货合约被高估时，投资者可以卖出该期货合约，同时根据指数权重买进成份股。当现货指数被高估，某个交割月份的期货合约被低估时，如果允许融券，投资者可以买入该期货合约，同时按照指数权重融券卖空成份股。和统计套利类似，它的风险在于期货和现货的价差并未收敛而是进一步扩大。 ETF套利：ETF(Exchange Traded Fund)交易型开放式指数基金，通常又被称为交易所交易基金。由于其有两个价格，即基金净值和交易所交易价格，所以一旦两个价格相差过多时，就可以高卖低买套利。风险在于交易价格随时波动，较难捕捉，也可能会有流动性困难。 分级基金套利：一般分级基金有5个价格，母基金净值，A类份额净值、A类份额交易价格、B类份额净值、B类份额交易价格，正常情况下，A的净值+B的净值=2*母基金净值，当(A的交易价格+B的交易价格)大于或小于两倍母基金净值时，也可以通过高卖低买获利。但实际情况中，由于申购到拆分到卖出并非T+0，而交易价格又是瞬息万变的，可能会套利失败。 事件驱动套利策略：利用特殊事件造成的对资产价格的错误定价，买入股价受事件正面影响的公司，卖出股价受事件负面影响的公司，从错误定价中谋利。 CTA期货策略：CTA即commdity trading advisor,直译为商品交易顾问。其中期货套利策略即从不同期货市场或是同一市场内不同期货合约间的价差中寻求利润，风险和之前介绍的套利风险类似，即出现差价放大的情况。而趋势交易策略目前CTA运用最广泛的，通过运用大量不同的指标去除市场噪音并寻找当前的市场趋势，然后建立头寸，他们从市场趋势的持续发展中渔利。这个策略在市场出现震荡，没有表现出很强的趋势时失效。 BigQuant - 人工智能量化投资平台 一些经典的策略举例： 《【重磅】AI Alphas(A股版)》 《AI超越传统量化选股，通过AI自动获得收益提升》 《如何选出符合一定条件的股票》 《快速理解AI量化策略》 《基于LSTM的股票价格预测模型》 《LSTM Networks应用于股票市场之Sequential Model》 《借助talib使用技术分析指标来炒股》 《大师系列之价值投资选股策略》 《价值选股策略——基于机器学习算法》 《选股+择时策略组合》","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"量化交易","slug":"量化交易","permalink":"https://beefyheisenberg.github.io/tags/量化交易/"},{"name":"交易策略","slug":"交易策略","permalink":"https://beefyheisenberg.github.io/tags/交易策略/"}]},{"title":"F52f.量化策略-RSRS择时","slug":"52.Financing/F52f.量化策略-RSRS择时","date":"2024-01-24T01:27:53.555Z","updated":"2024-01-24T01:27:53.555Z","comments":true,"path":"52.Financing/F52f.量化策略-RSRS择时/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F52f.量化策略-RSRS择时/","excerpt":"阻力支撑相关概念常见的确定阻力支撑位的方法有，布林带上下轨突破策略（突破上轨建仓买入，突破下轨卖出平仓）和均线策略（如超过20日均线建仓买入，低于20日均线卖出平仓）。然而，布林带突破策略在震荡期间出现了持续亏损，均线策略交易交易成本巨大，且在震荡期间的回撤很大。 阻力位 &amp; 支撑位概念参考 F41a.K线和技术分析 RSRS（阻力支撑相对强度）择时RSRS概念来自光大证券研报《基于阻力支撑相对强度(RSRS)的市场择时》，","text":"阻力支撑相关概念常见的确定阻力支撑位的方法有，布林带上下轨突破策略（突破上轨建仓买入，突破下轨卖出平仓）和均线策略（如超过20日均线建仓买入，低于20日均线卖出平仓）。然而，布林带突破策略在震荡期间出现了持续亏损，均线策略交易交易成本巨大，且在震荡期间的回撤很大。 阻力位 &amp; 支撑位概念参考 F41a.K线和技术分析 RSRS（阻力支撑相对强度）择时RSRS概念来自光大证券研报《基于阻力支撑相对强度(RSRS)的市场择时》， RSRS即“阻力支撑相对强度”(Resistance Support Relative Strength,)是另一种阻力位与支撑位的运用方式，它不再把阻力位与支撑位当做一个定值，而是看做一个变量。 从最高价与最低价的形成机制出发，每日的最高价与最低价就是一种阻力位与支撑位，它是当日全体市场参与者的交易行为所认可的阻力与支撑。一个很自然的想法是建立最高价和最低价的线性回归，并计算出斜率。即： $$ High = β*Low + α $$ 其中，β即斜率，近似等于一段时间内的最高价/最低价： 当斜率β值很大时，支撑强度大于阻力强度。在牛市中阻力渐小，上方上涨空间大；在熊市中支撑渐强，下跌势头欲止。 当斜率β值很小时，阻力强度大于支撑强度。在牛市中阻力渐强，上涨势头渐止；在熊市中支撑渐送，下方下跌空间渐大。 我们按照不同市场状态分类来说明支撑阻力相对强度的应用逻辑： 市场在上涨牛市中： a.如果支撑明显强于阻力，牛市持续，价格加速上涨； b.如果阻力明显强于支撑，牛市可能即将结束，价格见顶； 市场在震荡中： c.如果支撑明显强于阻力，牛市可能即将启动； d.如果阻力明显强于支撑，熊市可能即将启动； 市场在下跌熊市中： e.如果阻力明显强于支撑，熊市持续，价格加速下跌； f.如果支撑明显强于阻力，熊市可能即将结束，价格见底； 如下4张图，对应上面的 a、b、e、f 四种情况： 情形a，牛市，High和Low的拟合曲线的斜率都是正值，High/Low（斜率）逐步增大，后续上涨空间大： 情形b，High/Low（斜率）逐步减小，上涨即将见顶： 情形e，High和Low的拟合曲线的斜率都是负值，High/Low（斜率）逐步减小，后续加速下跌：情形f，High/Low（斜率）逐步增加，下跌即将结束： RSRS的概念 &amp; 技术分析的比较从上面4种情形，最高价&amp;最低价的示意图，我们发现了一些端倪，RSRS和老派的画线技术分析中提到的一些“收敛/发散形态，上升楔形/下跌楔形”有相似之处： RSRS描述 对应技术分析中的形态 牛市中，斜率增加，加速上涨（情况a） 上涨过程中的发散形态 牛市中，斜率减少，上涨见顶（情况b） 上涨过程中，走出的向上的楔形 熊市中，斜率减少，加速下跌（情况e） 下跌过程中的发散形态 熊市中，斜率增加，下跌见底（情况f） 下跌过程中，走出的向下的楔形 一个是严谨的量化计算，一个是传统的画线分析，虽然二者在理念上有区别（量化交易更注重“机器量化”，传统的技术分析更注重基于经验的画线），但在某些方面是相通的。 表格右侧出现的技术形态，参考 F41a.K线和技术分析 RSRS相对强度的量化计算最简单的想法就是用最近N个交易日的最高价/最低价数据，求得今天的斜率值，然后与阈值比较，大于m某个阈值则开仓买入，小于某个阈值则卖出。但是实际上斜率β波动较大，效果不佳，所以尝试对斜率进行标准化，用标准分替代原始的β值，计算方式如下： （一）取前N日（N=18）的最高价序列与最低价数据，按公式的模型进行OLS（即普通最小二乘法，ordinary least squares）线性回归，拟合后的求得斜率β（也即当日的RSRS）； （二）取前M日（M=600）的最高价序列与最低价数据，计算当日RSRS的标准分：$$ RSRS_std = (RSRS-μ_M)/σ_M $$其中 $μ_M$ 为前M日的斜率均值，$σ_M$ 为前M日的标准差。 （三）若 $RSRS_std$ 大于买入阈值 $S_buy$，则全仓买入；若 $RSRS_std$ 小于卖出阈值$S_sell$，则卖出平仓。（$S_buy = 0.7$，$S_sell = -0.7$） RSRS的参数调优从策略净值来看，5分钟线&gt;30分钟线&gt;小时线&gt;日线，但5分钟与30分钟差异较小 • 按行情特征选择合适的择时频率：趋势行情下30分钟线择时效果最佳，震荡行情则日线择时效果最佳 • 各频率下参数N（前N个交易日的数据OLS拟合求斜率）的选择更重要，频率提高后对参数的敏感性上升： 5分钟、30分钟频率上，不同N对应的策略净值差异较大； 参数M的敏感性相对较低； • S存在最优区间，频率越高，策略净值对参数S越敏感： 无论在哪个频率下，S都有很明显的下凹抛物线形状； 日频策略在S属于0.6至0.7处较好； 其它频率的RSRS策略在S等于0.8，0.9附近较佳； 基于RSRS的几种策略（一）大小盘ETF轮动 参考：RSRS模型深入研究3-二八轮动策略及其探究分析 - Marshal - JoinQuant （二）行业ETF轮动： 参考光大原文“基于RSRS指标的行业轮动模型”：http://pg.jrj.com.cn/acc/Res/CN_RES/INVEST/2017/6/15/6baea273-4229-4ee5-88d0-1c940ccb190d.pdf （三）RSRS作为个股择时信号： 参考：价值选股与RSRS择时 - K线放荡不羁 - JoinQuant 参考 光大证券：RSRS指标择时及行业轮动——技术择时系列研究之二 【量化课堂】RSRS(阻力支撑相对强度)择时策略（上） - JoinQuant量化课堂 - JoinQuant 【量化课堂】RSRS(阻力支撑相对强度)择时策略（下） - JoinQuant量化课堂 - JoinQuant 基于阻力支撑相对强度（RSRS）的市场择时 - 知乎 8年10倍，回撤小，有滑点！ETF动量简单轮动策略！ - 萌新王富贵 - JoinQuant","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"量化交易","slug":"量化交易","permalink":"https://beefyheisenberg.github.io/tags/量化交易/"},{"name":"交易策略","slug":"交易策略","permalink":"https://beefyheisenberg.github.io/tags/交易策略/"},{"name":"阻力位","slug":"阻力位","permalink":"https://beefyheisenberg.github.io/tags/阻力位/"},{"name":"支撑位","slug":"支撑位","permalink":"https://beefyheisenberg.github.io/tags/支撑位/"}]},{"title":"F52e.配对交易(Pair Trading)","slug":"52.Financing/F52e.配对交易(Pair Trading)","date":"2024-01-24T01:27:53.551Z","updated":"2024-01-24T01:27:53.551Z","comments":true,"path":"52.Financing/F52e.配对交易(Pair Trading)/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F52e.配对交易(Pair Trading)/","excerpt":"配对交易是一种基于数学分析交易策略，其盈利模式是通过两只股票的差价（spread）来获取，因此与很多策略不同，它是一种中性策略，理论上可以做到和大盘走势完全无关，即策略的beta值可以很低。 配对交易的基本原理是，两个相似公司的股票，其股价走势虽然在中途会有所偏离，但是最终都会趋于一致。 具有这种关系的两个股票，在数学上称作协整性（cointegration），即它们之间的差价会围绕某一个均值来回摆动，这是配对交易策略可以盈利的基础。通俗点来讲，如果两个股票或者变量之间具有强协整性，那么不论它们中途怎么走的，它们的目的地总是一样的。 协整性与相关性 cointegration vs correlation：需要特别注意的是协整性和相关性虽然比较像，但实际是不同的两个东西。两个变量之间可以相关性强，协整性却很弱，比如说两条直线，y＝x和y＝2x，它们之间的相关性是1，但是协整性却比较差，其pvalue等于0.87811389067154477（两个变量之间的pvalue值越小表示协整性越好）。也有弱相关性+强协整性的例子，比如方波信号和白噪声信号，它们之间相关性很弱，但是却有强协整性。 我们以中国石油和中国石化为例，抛开个别的特殊问题，大致可以认为这两者的经营模式、市场规模、未来前景都极度相似。在大部分时间内，两者的涨跌幅都十分相似。从数据上来看，两者收益的相关性高达0.95，可以套用配对交易模型。","text":"配对交易是一种基于数学分析交易策略，其盈利模式是通过两只股票的差价（spread）来获取，因此与很多策略不同，它是一种中性策略，理论上可以做到和大盘走势完全无关，即策略的beta值可以很低。 配对交易的基本原理是，两个相似公司的股票，其股价走势虽然在中途会有所偏离，但是最终都会趋于一致。 具有这种关系的两个股票，在数学上称作协整性（cointegration），即它们之间的差价会围绕某一个均值来回摆动，这是配对交易策略可以盈利的基础。通俗点来讲，如果两个股票或者变量之间具有强协整性，那么不论它们中途怎么走的，它们的目的地总是一样的。 协整性与相关性 cointegration vs correlation：需要特别注意的是协整性和相关性虽然比较像，但实际是不同的两个东西。两个变量之间可以相关性强，协整性却很弱，比如说两条直线，y＝x和y＝2x，它们之间的相关性是1，但是协整性却比较差，其pvalue等于0.87811389067154477（两个变量之间的pvalue值越小表示协整性越好）。也有弱相关性+强协整性的例子，比如方波信号和白噪声信号，它们之间相关性很弱，但是却有强协整性。 我们以中国石油和中国石化为例，抛开个别的特殊问题，大致可以认为这两者的经营模式、市场规模、未来前景都极度相似。在大部分时间内，两者的涨跌幅都十分相似。从数据上来看，两者收益的相关性高达0.95，可以套用配对交易模型。 具体来说，若此时：中国石油的股价 - 中国石化的股价，严重高于长期均衡线，我们认为未来两者股价将逐渐靠近。所以，此时买入中国石化，卖出中国石油；反过来，若此时：中国石油的股价 - 中国石化的股价，严重低于长期均衡线，我们认为未来两者股价将逐渐远离。所以，此时买入中国石油，卖出中国石化。 以ETF为例，H股中的恒生医疗和恒生互联也可以做配对交易。 @ref: https://xueqiu.com/2401362725/59137819","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"交易策略","slug":"交易策略","permalink":"https://beefyheisenberg.github.io/tags/交易策略/"}]},{"title":"F52d.网格交易策略","slug":"52.Financing/F52d.网格交易策略","date":"2024-01-24T01:27:53.547Z","updated":"2024-01-24T01:27:53.547Z","comments":true,"path":"52.Financing/F52d.网格交易策略/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F52d.网格交易策略/","excerpt":"ETF网格总结 网格的买入方式决定了只适合手里有一定存量资金的, 网格交易是价格碰到格子就触发交易, 如果短期变化很大(多次触格)会有多次资金投入, 定投只是每月发工资了就投; 网格的局限性: 只适合有幅度的震荡行情: 如果是长期熊市, 会很快用完资金, 并被套住; 如果是长期牛市, 网格又不能非常好的提高收益(单边上涨时, 每上升一格就卖出一部分, 相比按照PE分批止盈的方式盈利更差) 如果长期横盘(震荡幅度不大, 很少触到网格), 资金利用率会很低 如果股价上or下穿破网格, 需要重新调整网格和数值 ETF网格构建工具 =&gt; ETF网格计算器 网格交易法（双向）➤ 不知道哪位交易员可以解释下网格交易法？ - 秦KK的回答 - 知乎","text":"ETF网格总结 网格的买入方式决定了只适合手里有一定存量资金的, 网格交易是价格碰到格子就触发交易, 如果短期变化很大(多次触格)会有多次资金投入, 定投只是每月发工资了就投; 网格的局限性: 只适合有幅度的震荡行情: 如果是长期熊市, 会很快用完资金, 并被套住; 如果是长期牛市, 网格又不能非常好的提高收益(单边上涨时, 每上升一格就卖出一部分, 相比按照PE分批止盈的方式盈利更差) 如果长期横盘(震荡幅度不大, 很少触到网格), 资金利用率会很低 如果股价上or下穿破网格, 需要重新调整网格和数值 ETF网格构建工具 =&gt; ETF网格计算器 网格交易法（双向）➤ 不知道哪位交易员可以解释下网格交易法？ - 秦KK的回答 - 知乎 先看上涨情形: 每次到达一个新格, 就开一个多单(绿)+一个空单(红) 上涨到达B的格子时, 首先平掉A的盈利, 然后在B处开一个多单+一个空单 上涨到达B的格子时, 首先平掉B的盈利, 然后在C处开一个多单+一个空单 当股价达到定点C的时候, 如下图: 当股价下跌时: 当从C跌回B, 把刚刚平掉的多单补回来, 同时卖掉C点的空单(红) … ➤ 不知道哪位交易员可以解释下网格交易法？ - 知乎信息论之父申农在黑板上给大家演示：任何一个价位买进资金的50%，也就是说资金数量：股票市值=50%：50%。股票价格上涨一定幅度就卖出一部分股票，保持剩余的资金数量：剩余股票市值=50%：50%；反之股票价格下跌一定幅度，就用剩余资金买进一部分股票，始终保持剩余资金数量：剩余股票市值=50%：50%。用这个办法来对付股票价格的随机走势，长期交易是盈利的。他在十多年的交易生涯中，资金获得了29%的年复利增长。50岁后因为得了老年痴呆症，交易战绩没能延续。我在这里暂且称上面使用的交易数学模型为“等比例仓位模型”—-事实上，50%完全可以是其他的百分比数值。 ➤ 指数基金买卖网格交易 具体如何操作？ 天天基金 哪些指数更适合网格交易？ 近2年来，年化波动率超过25%的行业指数和宽基指数，它们的年化波动率和收益率相对更优，对比观察发现，休闲服务、有色金属、电气设备、创业板指等主流行业表现突出，投资者可尝试进行网格交易。 ➤ 关于网格交易（forcode原创） 起始买入价，一般在公司陷入暂时危机、股价处在最近几年最低位、PE/PB极低的时候开始关注。 起始买入量，我一般定在可投资总资产的1%以内，一般最低不少于1万元，这样手续费比较合算点；而每个交易间隔的递增交易量，尽量控制在总仓位的0.2% 交易间隔，我现在倾向于股价波动4~8%触发一次交易，尽量取整数间隔，方便记忆。比如20元以内的标的，每下跌1元触发一次交易。 起始卖出价，我现在一般定在反弹超过4个交易间隔（大约20%）开始分批卖出、下跌超过4个交易间隔开始分批买入。 以及：网格交易闲置资金的问题？网格交易投资标的的选择？ ➤ ETF 网格交易策略（全） - 尼基的梦 - 知乎 用上证指数作为表格标的… 3680 ~ 2440 如何估算网格上限, 用了GNP(证券化率)","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"交易策略","slug":"交易策略","permalink":"https://beefyheisenberg.github.io/tags/交易策略/"}]},{"title":"F52c.轮动策略","slug":"52.Financing/F52c.轮动策略","date":"2024-01-24T01:27:53.540Z","updated":"2024-01-24T01:27:53.540Z","comments":true,"path":"52.Financing/F52c.轮动策略/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F52c.轮动策略/","excerpt":"如果说宏观大类资产配置是宏观视角下选优质资产，那么行业轮动就是权益市场视角下选热门行业。 宏观: 大类资产配置(β) 中观: 行业轮动(smart β) 微观: 个股(α) 轮动策略：行业轮动、风格轮动、大小盘轮动等。行业轮动其实本身也是风格切换的一种表现，只是它的这种切换的属性在一个行业上，而不是单纯的大盘或者说市场的风格上 @ref: 行业轮动策略及代表基金经理分享 - 雪球 量化轮动：因子的选择","text":"如果说宏观大类资产配置是宏观视角下选优质资产，那么行业轮动就是权益市场视角下选热门行业。 宏观: 大类资产配置(β) 中观: 行业轮动(smart β) 微观: 个股(α) 轮动策略：行业轮动、风格轮动、大小盘轮动等。行业轮动其实本身也是风格切换的一种表现，只是它的这种切换的属性在一个行业上，而不是单纯的大盘或者说市场的风格上 @ref: 行业轮动策略及代表基金经理分享 - 雪球 量化轮动：因子的选择光大证券-行业轮动系列研究：三位一体，自适应行业轮动(ADC)模型-200615.pdf - H3_AP202006171385474036_1.pdf 标的选择： 覆盖产业上/中/下游，不同的美林时钟周期偏向不同的标的 这个轮动的模型（相比纯动量模型）更复杂，构建SAMI指标：量价+财务+分析师预期 做轮动策略，最简单的因子即是动量因子，总结几种动量因子计算： 20日涨幅 10日涨幅xa + 20日涨幅xb 当前20日涨幅 &gt; 3日前20日涨幅 当前20日均线 &gt; 3日前20日均线 RSRS: N日的最高价/最低价，各自拟合出一条直线，两条直线的斜率之比，作为动量 BBI 动量 - BBIC：计算公式： BBI(3, 6, 12, 24) / 收盘价 （BBI 为常用技术指标类因子“多空均线”） 6日变动速率（Price Rate of Change）- ROC6：计算公式：① AX=今天的收盘价—6天前的收盘价；② BX=6天前的收盘价；③ ROC=AX/BX*100 10日乖离率 - BIAS10：计算公式： （收盘价-收盘价的N日简单平均）/ 收盘价的N日简单平均*100，在此n取10 @ref: 因子看板 - JoinQuant @ref: 一些常用的动量因子，简单而不简约 大小盘轮动@ref: 手把手教你构建轮动策略 动量效应是由 Jegadeesh 和 Titman 提出的，是指股票的收益率有延续原来的运动方向的趋势，即过去上涨的资产未来还会上涨，过去下跌的资产未来还会下跌。 交易策略：每天收盘后将沪深300ETF（510300）和创业板（159915）按照最近20个交易日的涨幅排序，排名第一并且20日涨幅大于2%则次日以开盘价买入；如果排名不是第一或者20日涨幅小于-2%则次日开盘价卖出；如果以上两个条件都不满足则买入银华日利（511880） 在趋势明显的的市场，轮动策略的效果更好，优势明显。比如牛市中市场趋势性上涨，容易获得超额收益；熊市中择时机制能够及时预警，赎回权益资产买人货基，从而躲避下跌降低熊市风险。在趋势不明显的震荡市场中，轮动策略的劣势也暴露无遗，反复“打脸”在所难免。 宽基ETF轮动三标的ETF轮动策略代码分享 - 雪球 【标的】创业板、沪深300、中证500、红利ETF、深红利、上证180和上证50【买入条件】（两个条件全部满足才买入）1、近13个交易日涨幅排名前三（设置涨幅阈值为0.1%），选择最强势的基金；2、当前价大于13日均线，主要用于过滤假突破信号。【卖出条件】（三个条件满足一个就卖出）1、近13个交易日涨幅排名未入前三（先剔除不符合买入条件的基金再排序）；2、近13个交易日涨幅不足0.1%；3、当前价小于近13个交易日均线 三标的ETF轮动策略搭配大盘止损的效果 - 雪球改进：以30日成交量均线作为参考（以上证指数为标的） 买进时：连续3日不过30日量线不进行买入操作。 卖出时：连续3日不过30日量线，无条件卖出，提前出场等待 我们可以看到收益发生了大幅的下降，检查日志之后发现，整个回测周期中有554个交易日是因为大盘成交量持续低于30日均线，保持空仓状态。这对于总计1388个交易日来说，止损信号的发出太过频繁。再考虑到三个标的轮动，已经在一定程度上分散了风险。所以，我们可以认为选择30日成交量均线显得过于保守。 关于大盘量线过滤的思考: 首先，基于动量的轮动是一种偏进攻型的策略，不追求高胜率，核心逻辑在于“多赚少亏”，整体盈利。连续3日不过量线不进行买入操作虽然可以过滤一些假信号，但是损失的收益可能会更多，这和“多赚”的逻辑有一定抵触。 其次，轮动策略的“少亏”是通过轮动换仓实现的，但是我们发现基础策略的回撤幅度仍然是非常大的（超过35%），通过同时持有多个标的分散风险，我们把回撤控制在了25%以内，但是目前为止我们还未采用任何硬止损手段，这方面应该还有文章可做 行业轮动@ref: 行业轮动(股票) - 经典策略 - 掘金量化 本策略每隔1个月定时触发计算：SHSE.000910.SHSE.000909.SHSE.000911.SHSE.000912.SHSE.000913.SHSE.000914(300工业.300材料.300可选.300消费.300医药.300金融)这几个行业指数过去20个交易日的收益率并选取了收益率最高的指数的成份股获取并获取了他们的市值数据随后把仓位调整至市值最大的5只股票上 标的：行业ETF @link F32b.行业ETF","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"交易策略","slug":"交易策略","permalink":"https://beefyheisenberg.github.io/tags/交易策略/"}]},{"title":"F52b.布林线策略","slug":"52.Financing/F52b.布林线策略","date":"2024-01-24T01:27:53.534Z","updated":"2024-01-24T01:27:53.534Z","comments":true,"path":"52.Financing/F52b.布林线策略/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F52b.布林线策略/","excerpt":"有关布林线定义 =&gt; F41.K线 布林线均值回归策略（1）布林线均值回归策略： 标的价格在上轨线和下轨线围成的范围内浮动，即使短期内突破上下轨，但长期内仍然会回归到布林带之中 当股价向上突破上界时，为卖出信号，当股价向下突破下界时，为买入信号。 （2）布林线突破策略：","text":"有关布林线定义 =&gt; F41.K线 布林线均值回归策略（1）布林线均值回归策略： 标的价格在上轨线和下轨线围成的范围内浮动，即使短期内突破上下轨，但长期内仍然会回归到布林带之中 当股价向上突破上界时，为卖出信号，当股价向下突破下界时，为买入信号。 （2）布林线突破策略： 创业板50ETF，收盘价超过上轨, 次日买入并持有；收盘价低于上下轨, 次日清仓, 同时买入货币基金 更适合波动性大的成长性指数ETF","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"交易策略","slug":"交易策略","permalink":"https://beefyheisenberg.github.io/tags/交易策略/"}]},{"title":"F52a.双均线策略","slug":"52.Financing/F52a.双均线策略","date":"2024-01-24T01:27:53.529Z","updated":"2024-01-24T01:27:53.529Z","comments":true,"path":"52.Financing/F52a.双均线策略/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F52a.双均线策略/","excerpt":"移动平均线（MA）定义 =&gt; F41.K线 双均线策略@ref ETF之家：双均线策略是经典的趋势择时策略,具体策略为: 当50ETF的20日均线高于120日均线时, 次日买入 当20日均线低于120日均线时, 次日卖出, 同时换成货币基金","text":"移动平均线（MA）定义 =&gt; F41.K线 双均线策略@ref ETF之家：双均线策略是经典的趋势择时策略,具体策略为: 当50ETF的20日均线高于120日均线时, 次日买入 当20日均线低于120日均线时, 次日卖出, 同时换成货币基金 @ref: 双均线策略(期货) - 经典策略 - 掘金量化本策略以SHFE.rb2101为交易标的，根据其一分钟(即60s频度）bar数据建立双均线模型，短周期为20，长周期为60，当短期均线由上向下穿越长期均线时做空，当短期均线由下向上穿越长期均线时做多,每次开仓前先平掉所持仓位，再开仓。注：为了适用于仿真和实盘，在策略中增加了一个“先判断是否平仓成功再开仓”的判断逻辑，以避免出现未平仓成功，可用资金不足的情况。 哪种均线组合才是最优的？回测了几种均线组合的收益率，最高的是.. MA3+MA21 ?","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"交易策略","slug":"交易策略","permalink":"https://beefyheisenberg.github.io/tags/交易策略/"}]},{"title":"F51.Quant-量化交易101","slug":"52.Financing/F51.Quant.量化交易101","date":"2024-01-24T01:27:53.525Z","updated":"2024-01-24T01:27:53.525Z","comments":true,"path":"52.Financing/F51.Quant.量化交易101/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F51.Quant.量化交易101/","excerpt":"@tag: #入门101 #量化交易 @todo: 量化交易入门指南 - 力扣（LeetCode） 待整理: F52z.Quant-量化交易经典策略zz 简单策略","text":"@tag: #入门101 #量化交易 @todo: 量化交易入门指南 - 力扣（LeetCode） 待整理: F52z.Quant-量化交易经典策略zz 简单策略@ref: “掘金量化”: 行业量化轮动 &amp; 大小盘轮动: F52c.轮动策略 布林线策略: F52b.布林线策略 均线策略: F52a.双均线策略 网格交易：[[F52n.网格交易策略]] 待整理：F52z.Quant-量化交易经典策略zz 几种量化策略比较：轮动 vs 双均线 vs 布林带 vs 网格 轮动（动量）： 效果取决于市场主线是否清晰（资金一致看好产生的抱团），各个标的轮动效应明显 熊市反弹的特点是资金的分歧导致的轮动过快，这种情况下用动量可能会被左右打脸 双均线（20MA + 120MA）： 无论均线还是动量，都是基于“过去的价格”的趋势策略，对于没有明显趋势 &amp; 震荡行情，也会被反复打脸 可以在组合策略里作为右侧买入信号，也可以构建独立的双均线策略 顾比均线 顾比均线和双MA策略并无本质不同，顾比均线策略的买入信号要求短期组全部线上穿长期组，错误的买入信号更少，相对更稳妥，更加右侧 除了关注长/短周期组的金叉和死叉，还可以通过组线之间的开口发散和收敛作为信号 布林带： 适用性：3000以下出现布林带突破下轨是不错的抄底信号（偏左侧） 网格： 适合横盘震荡期，但是底部的震荡期用网格会过早抛掉便宜的筹码，而市场顶部用网格风险系数增加 理想的标的: 有波动性 + 在一定的箱体内波动 如果要吃掉一切波动的利润, 要选择更多&amp;覆盖更全的标的, 维护这么多的条件单也成了一种负担 网格是种保守不聪明的办法 国内量化平台试用&amp;比较（1）聚宽： https://www.joinquant.com/ 无需本地环境，相当于一个 FaaS服务 （2）掘金/东方财富量化终端： 东财的量化终端实际是用的掘金量化客户端，Windows Only，依赖本地Python环境，如果之前没搞过Py，搭环境很痛苦…3.8~4各种版本，各种依赖包… 安装位置： 如果单独安装掘金客户端：C:\\Users\\steff\\.goldminer3\\projects\\567a7e0e-5d8f-11ed-b923-84a93e8fc41b策略的Py代码：C:\\Users\\steff\\.goldminer3\\projects\\567a7e0e-5d8f-11ed-b923-84a93e8fc41b东财的掘金客户端： D:\\eastmoney\\swc8\\EastMoneyGoldminer\\goldminer3策略的Py代码：C:\\Users\\steff\\.emgm3\\projects\\281227ed-5cfe-11ed-97ae-84a93e8fc41b 安装步骤： pip install grpcio --force-reinstallpip install scipy --force-reinstallpython -m pip uninstall scipypython -m pip install scipy 相关库使用工具——BaostockBaostock是一个免费、开源的证券数据平台，我们可以用它来遍历沪深市选股，监测股票行情，进行量化分析和定投回测。Baostock的安装方法和其他Python包一样，pip install baostock就行。类似的包还有Dtshare、Tushare，这两个都是免费的Python金融数据接口库，可以自行选择，不过Tushare现在取数需要注册和积分，稍有点麻烦。 Baostock官方说明文档：baostock.com Tushare官方说明文档：tushare.pro/document/1 Dtshare官方说明文档：http://dt-share.com QUANTAXIS，程序员们还有其他轮子可供选择 quantopian，优矿，JoinQuant，vnpy，Abu量化等等。QUANTAXIS是个只能本地部署的基于python的量化开源系统。有基于Docker部署和基于pip部署和基于Git部署三种方法","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"量化交易","slug":"量化交易","permalink":"https://beefyheisenberg.github.io/tags/量化交易/"},{"name":"交易策略","slug":"交易策略","permalink":"https://beefyheisenberg.github.io/tags/交易策略/"}]},{"title":"F49.戴维斯双杀","slug":"52.Financing/F49.戴维斯双杀","date":"2024-01-24T01:27:53.521Z","updated":"2024-01-24T01:27:53.521Z","comments":true,"path":"52.Financing/F49.戴维斯双杀/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F49.戴维斯双杀/","excerpt":"戴维斯双杀P = PE*EPS, 即$$ 股价 = 市盈率 * 每股净利润 $$ 股价受到企业盈利和企业估值产生的乘数效应的影响，在成长股成长的过程中PE和EPS都会增长，而最终股价增长的幅度是两者增长倍数的乘积。 如果EPS（每股净利润）下降，可能带来PE（估值，也即投资者的“期望值”）同时下降，估值和每股净利润的乘数下滑导致股价暴跌。该模型向上叫做“戴维斯双击”，向下叫做“戴维斯双杀”。 什么是杀业绩、杀估值","text":"戴维斯双杀P = PE*EPS, 即$$ 股价 = 市盈率 * 每股净利润 $$ 股价受到企业盈利和企业估值产生的乘数效应的影响，在成长股成长的过程中PE和EPS都会增长，而最终股价增长的幅度是两者增长倍数的乘积。 如果EPS（每股净利润）下降，可能带来PE（估值，也即投资者的“期望值”）同时下降，估值和每股净利润的乘数下滑导致股价暴跌。该模型向上叫做“戴维斯双击”，向下叫做“戴维斯双杀”。 什么是杀业绩、杀估值$$ Price = EPSPE = 利润市盈率 $$ 其中利润是“业绩”，市盈率即“估值”，企业经营＝不断的把估值（投资者的期望值）转化为“预期中的业绩”，但是高业绩增长又进一步提高估值，在这种逻辑中，一旦业绩变差，上面的转化就无法持续，变为戴维斯双杀。 其中，估值分为几部分： 情绪： 理解为股东情绪？ 业绩预期：是对未来的预测。始终围绕的着业绩的增长，高价值（投入资本回报）和风险 增长：经常性的超预期可以获得市场的经常性溢价。比如连续几年稳定增长，这部分也会拉高估值，变为增长预期。 高价值：高价值企业，会获得经常性溢价。比如roe比较高，容易形成复利，RNG三要素明显，经营态势良好。 风险：比如高负债，周期性。 ①是否为估值杀：在业绩和企业经营态势没有发生变化的情况下，可以简单的归结为估值杀，比如在熊市底部的杀跌阶段，白马股也无法逃过估值的下降，这种股价下跌的原因，在熊市初期可以认为是资金风险偏好承受力的下降（对企业给出的估值自然降低），在熊市底部还可能因为对股市的悲观情绪进一步杀估值。 ②是否为业绩杀：企业的动态经营信息会告诉我们，如果业绩不及市场预期，在悲观的情况下，会迎来短期业绩杀，这也是市场定价周期与企业经营周期之间的时差导致的。市场定价是每天都在进行的，而企业经营周期是一个缓慢的过程，基本面的改变需要时间。当市场对企业产生了积极的情绪，而短期业绩又不能符合预期的话，市场先生大概率会以下跌作为响应。 ③双杀：代表企业的经营基本面和态势都发生了变化。比如某企业连续几年增长，而在遇到市场天花板之后增速放缓，作为成长股就要遭遇双杀。在估值杀、业绩杀、双杀之间存在时滞效应。由于企业的经营数据只按照季度对外公布，在股价下跌开始，看起来像是估值杀，因为短期业绩或业绩增速并未发生大变化。 随后公布的财报如果不及预期，可能出现业绩杀。","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"股市","slug":"股市","permalink":"https://beefyheisenberg.github.io/tags/股市/"}]},{"title":"F44.周期股","slug":"52.Financing/F44.周期股","date":"2024-01-24T01:27:53.516Z","updated":"2024-01-24T01:27:53.516Z","comments":true,"path":"52.Financing/F44.周期股/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F44.周期股/","excerpt":"库存周期基钦周期就是我们常说的库存周期，也叫短波理论，时间跨度在3-4年左右，在市场投资判断方面更具有实操意义。 简单来说，库存周期就是企业的库存变化情况，企业如果预期未来需求将增加，就会主动投资扩产，带动库存增加，如果预期未来需求减弱，则会降低产能，从而减少库存。不过，在实际业务中，由于工业企业是根据商品价格走势与盈利预期来调整产成品存货的，因此库存变动一般会滞后于价格与盈利预期的变化。 ➤ 如何确定现在在哪个库存周期？@ref: https://finance.sina.cn/zl/2022-10-26/zl-imqqsmrp3791137.d.html 观察单个指标似乎难以确认中国经济所处的周期性位置。因此笔者尝试从制造业的库存周期来进行分析。具体地，可以使用制造业PMI的产成品库存、原材料库存两个指标来进行观察。分析结果显示：当前中国经济正处于被动补库存阶段，即产成品面临积压上升，同时原材料库存呈现下降。按照库存周期的短期视角来看，中国经济未来可能面临进入主动去库存的压力，即在原材料库存维持下降的同时，积压的产成品库存也可能通过延缓生产、消化库存方式呈现下降。","text":"库存周期基钦周期就是我们常说的库存周期，也叫短波理论，时间跨度在3-4年左右，在市场投资判断方面更具有实操意义。 简单来说，库存周期就是企业的库存变化情况，企业如果预期未来需求将增加，就会主动投资扩产，带动库存增加，如果预期未来需求减弱，则会降低产能，从而减少库存。不过，在实际业务中，由于工业企业是根据商品价格走势与盈利预期来调整产成品存货的，因此库存变动一般会滞后于价格与盈利预期的变化。 ➤ 如何确定现在在哪个库存周期？@ref: https://finance.sina.cn/zl/2022-10-26/zl-imqqsmrp3791137.d.html 观察单个指标似乎难以确认中国经济所处的周期性位置。因此笔者尝试从制造业的库存周期来进行分析。具体地，可以使用制造业PMI的产成品库存、原材料库存两个指标来进行观察。分析结果显示：当前中国经济正处于被动补库存阶段，即产成品面临积压上升，同时原材料库存呈现下降。按照库存周期的短期视角来看，中国经济未来可能面临进入主动去库存的压力，即在原材料库存维持下降的同时，积压的产成品库存也可能通过延缓生产、消化库存方式呈现下降。 @ref: https://xueqiu.com/1878306520/90259668 帖子比较久远（2017），下面描述的库存周期落后经济周期1/2个周期（供需完全错位，经济上行期库存仍在减少）这种模型只可能出现在完全自由化的市场，一般来说，库存会因供需关系，落后经济1/4个周期，参考“蛛网模型”（Cobweb model) https://www.zhihu.com/question/20693750/answer/372500961。但在已经“供给侧改革”的国内，上游资源同宏观经济更具同步性，所以当前属于哪个“库存周期”，应该通过最新的数据来观测，而不是套用理论化的模型。 主动型库存增加阶段：这是产能不断扩大并超过短期的均衡需求，并且企业会寻找和创造新的需求，这一时期宏观经济向好，企业也预期未来经济形势向好，于是会主动增加库存，使得产能持续扩大。这一阶段的库存量也呈下降趋势，虽然生产量在增加，但库存增加的速度小于外在需求增加的速度。但库存增加的速度超过需求增加的速度时，库存量开始上升的时候，就进入了被动库存增加时期 被动型库存增加阶段：当库存增加到一定的程度，就会出现产能扩张超过需求的增长，但是企业意识到需求减少到实施减少产量决策之间有一个时滞过程，但产出的惯性使得产能扩张维持一段时间，因此会出现被动型库存增加过程。这一时期库存量呈增加趋势，并且增长的速度很快 主动型库存减少阶段：当宏观经济形势真正向坏时，就会主动减少库存，降低产能利用率。这一阶段宏观经济向坏，企业面也向坏，市场的短期供给能力超过了短期需求。这一阶段企业开始减少生产，但需求减少的速度大于库存增加的速度，库存总量还在上升 被动型库存减少阶段：这是一个供不应求的阶段，价格在回升，产品的销售量在增加，企业的盈利能力在回升。因此，企业有强烈的扩张产能的冲动，但是这时的宏观经济情况尚未改观，可能存在通胀压力也可能存在产能利用率下降等，总之，这一阶段的特征是：企业面向好，宏观面向坏的趋势未变。库存量呈下降趋势 2022.10:重回“主动去库存” - 雪球 分析库存周期，要区分上/中/下行业，不同的行业可能在不同的周期中： 上游（采矿业，仅占全部库存2%） 中游（中上游制造，占全部库存54%） 下游（下游制造、水电气，占全部库存43%） 周期股相关什么是「周期股」，它是如何形成的，有哪些特点？ - 知乎 什么是周期股：指支付股息非常高（股价相对不会太高），并随着经济周期的盛衰而涨落的股票。该类股票诸如煤炭（传统能源）、钢铁、有色、化工、航运等行业的股票，当整体经济上升时，这些股票的价格也迅速上升；当整体经济走下坡路时，这些股票的价格也下跌。与之对应的是非周期股，生产必需品的公司，不论经济走势如何，人们对这些产品的需求都不会有太大变动，例如食品饮料和医药生物行业。 上述这些周期性行业企业构成股票市场的主体，其业绩和股价因经济周期的变化而起落，因此就不难理解经济周期成为主导牛市和熊市的根本原因的道理了。鉴此，投资周期性行业股票的关键就是对于时机的准确把握，如果你能在周期触底反转前介入，就会获得最为丰厚的投资回报，但如果在错误的时点和位置，如周期到达顶端时再买入，则会遭遇严重的损失，可能需要忍受5年，甚至10年的漫长等待，才能迎来下一轮周期的复苏和高涨。虽然预测经济周期什么时候达到顶峰和谷底，如同预测博彩的输赢一样困难，但在投资实践中还是可以总结出一些行之有效的方法和思路，让投资者有所借鉴。其中利率是把握周期股入市时机最核心的因素。当利率水平低位运行或持续下降时，周期性的股票会表现得越来越好，因为低利率和低资金成本可以刺激经济的增长，鼓励各行各业扩大生产和需求。 周期股市盈率低就一定可以买吗？以钢铁股为例，在景气低迷阶段，其市盈率只能保持在个位数上，最低可以达到 5倍以下，如果投资者将其与市场平均市盈率水平对比，认为“便宜”后买入，则可能要面对的是漫长的等待，会错过其他投资机会甚至还将遭遇进一步亏损。而在景气高涨期，如2004年上半年，钢铁股市盈率可以达到20倍以上，那个时候如果看到市盈率不断走高而不敢买入钢铁股就会错过一轮上升行情。相对于市盈率，市净率由于对利润波动不敏感，倒可以更好地反映业绩波动明显的周期股的投资价值，尤其对于那些资本密集型的重工行业更是如此。当股价低于净资产，即市净率低于1时，通常可以放心买入，不论是行业还是股价都有随时复苏的极大可能。 投资周期性行业重点关注的10个要点|周期股|景气度_网易订阅 对周期性行业企业的估值难度大，应结合行业景气指标判断。主要从行业多年平均收益、企业上轮周期主要财务数据、与历史高低股价、与历史高低市净率等进行比较。更重要的是行业景气的底部、顶部的正确判断几乎是不可能的。因此，只能根据历史数据比较，大致得出一个景气底、景气顶相对的股价区间，分批投入或卖出。 是关于估值指标：与正常的股票分析相反，周期性行业企业市盈率越低实际估值反而越高。市盈率高倍数时周期性行业企业反而估值一般处于低位，这时市净率会更低，行业景气底部周期性行业企业的市净率一般会明显降低。特别是强周期行业企业一般会远远降至一倍以下，极端时也有降至三四成的情况。无论从安全空间方面，还是从清算保本方面考虑，此时都是大量买入投资的良机。同理，行业繁荣时期，价值回归，市净率会上升到一倍以上，长至两三倍以上，市盈率也会降至个位数，这个时期便是投资周期行业企业获利了结之时。从这个方面来看，投资周期性行业企业参考市净率可能更为靠谱。 参考行业景气度判研投资周期性行业企业的进出时机可能会加大优势。行业景气度处于峰值期是风险最大的时期，股价巨大的涨幅一眼都看得出，峰值期过后便是衰退萧条，这是一条漫漫“熊”途，峰值之后一两年或更长的时间内仍是买入周期性行业企业股票的极度谨慎期。 切记不要以股票价格跌幅较深为由进行买进操作。强周期性行业企业的股价跌幅远远会超乎人们意料之外，处于强周期衰退阶段企业的股价，会不断地被拦腰斩断。 牢记“阶段性持有”五个字。它不像成长类好公司，长期持有或许10年能增长10倍，至更多。但周期性行业企业的股价会随着收益的好坏做高低起伏波浪式轮回运动，如果不在盈利高峰期卖出，股票价格一般会跌到前期萧条的低点，以至于吞没在复苏繁荣阶段辛苦持有产生的盈利。因此说，周期性行业企业的股票不能超出复苏繁荣期长期持有，复苏繁荣阶段性持有才是投资周期性行业企业的最优策略。 投资周期性行业企业一定、必须选择行业龙头企业。因为只有行业的龙头企业才有在衰退萧条期生存下来的高确定性，并能坚持到行业复苏繁荣。而非龙头企业很可能会在黎明前的黑暗中倒下，再也看不到第二天的太阳。 小心周期行业的伪周期：如产业国际大转移或被淘汰的行业。中国近30年来的发展得益于赶上了发达国家劳动密集型产业大转移的好时光。如钢铁、纺织、化工等行业。如果在美国20世纪七八十年代经济衰退期间投资钢铁、纺织等劳动密集型周期性产业，其投资业绩将是大失所望的，至是一场血本无归的败局。股神巴菲特在他认为以非常大的便宜收购了伯克希尔·哈撒韦纺织企业后，为经营管理、市场营销等受尽煎熬，在产业国际大转移的潮流面前，他败下阵来，贴钱卖掉厂房设备，将纺织企业转型成为投资控股公司。 周期行业的魔力和宿命 - 21财经 当这类行业从周期底部逐渐复苏时，因为基数极低，所以其业绩往往爆发性增长，带来的是股价的脉冲性上涨；当行业从周期顶部回落时，过高的基数又会导致业绩出现大幅下滑，股价随之急速下跌。周期股的突出特点，就是行情如疾风劲雨一般，非常简单粗暴，涨得快跌得也快，主升浪和主跌浪经常在很短的时间内走完。 当然，房地产在本轮经济周期和牛市行情中表现极差，这跟当下的经济政策关系很大；上游资源品价格暴涨，其实也并不是需求增加所致，而是碳中和背景下限产带来的影响。这些现象都是当下经济中非常复杂的一面，对判断宏观经济周期和走势增加了难度。 信达证券-策略周观点：周期股的卖点在什么时候？2020年中-2021年2月是这一次周期股的第一波行情，2021年3-6月由于经济下行担心开始出现，周期股产生了很大的分歧，随着产业逻辑（产能和碳中和）和成长性逻辑的继续发展，7月以来，周期股正式进入第二波行情。我们预计第二波周期股行情持续的时间在2个季度左右。 （1）从博弈角度来看：兑现很充分了。如果不考虑任何成长性，也不考虑碳中和或商品超级周期的可能性，周期股的行情已经达到尾声了。从估值层面来看，化工和有色估值（PB）水平已经超过2016-2017年的水平，采掘和钢铁估值低于2017年的水平，考虑到当下A股整体PB和2017年高点比较接近，单从均值回归的角度，当下周期股的估值是合理的。 （2）但如果考虑到成长性因素（新能源需求+碳中和政策），还没兑现充分。由于这一轮周期本身启动的时候，并没有产能过剩，所以虽然没有经历过较为剧烈的供给侧改革，但是这一次商品涨价的幅度远比2016-2017年更大。并且这一次不管是全球经济疫情后需求恢复的弹性，还是新能源和碳中和对周期股需求和供给的双重利好，都比2016-2017年更有想象空间，我们认为，周期股在交易层面和估值层面只回到2016-2017年的水平可能是不够的。 （3）从历史上周期股波动规律来看：2022年上半年是周期股见顶的区域。按照我们的经验判断，大宗商品的涨价，一般分三个阶段。第一个阶段是需求刚出现拐点。商品价格开始快速上涨，摆脱亏损区域。此时投资者的主流认识是需求只是超跌反弹，恢复空间不大，对商品价格顶部的预期只是恢复到成本附近。此时货币宽松，股市上涨，商品上涨，经济总需求触底回升。第二阶段是随着价格的上涨，企业利润回升，开始有足够的现金流，闲置产能和建设中的产能快速投产。此时周期股大震荡，商品小震荡，总需求稳定。第三阶段是由于商品价格的连续上涨，通胀压力增大，经济总需求开始小幅回落。供需缺口依然存在，而且已经没有可以快速恢复的产能了，未来新的产能短期内看不到，所以商品价格可能会继续上涨。 风险因素：房地产市场超预期下行，美股剧烈波动。","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"股市","slug":"股市","permalink":"https://beefyheisenberg.github.io/tags/股市/"},{"name":"经济周期","slug":"经济周期","permalink":"https://beefyheisenberg.github.io/tags/经济周期/"}]},{"title":"F42.公司和行业的基本面指标","slug":"52.Financing/F42.公司和行业的基本面指标","date":"2024-01-24T01:27:53.511Z","updated":"2024-01-24T01:27:53.512Z","comments":true,"path":"52.Financing/F42.公司和行业的基本面指标/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F42.公司和行业的基本面指标/","excerpt":"基本财务指标➤ 利润： 毛利润：是一个在商业根深蒂固，约定成俗的概念，它一般是指：毛利润=营业收入-营业成本 = 营业收入-材料成本-人工成本，计算毛利润的意义在于，如果不做该（笔）业务，一些资源就会被浪费或仍然会消耗，利润就会变成负值；如果做该业务，就可能赢利或减少亏损。对于效益相当好，资源利用率高的企业，完全可以忽视毛利润这个概念。 净利润 =营业收入-营业成本-三费-税金，三费包括营业费用（包装运输费/广告费…）、管理费用（公司工会经费/劳动保险/职工教育…）、财务费用（利息支出/汇兑损失） ➤ 资产： 固定资产= 指固定资产原价 - 历年已提折旧额后的净额 流动资产：指可以在一年或者超过一年的一个营业周期内变现或者耗用的资产，包括现金及各种存款、短期投资、应收及预付货款、存货等。 净资产总额：企业的资产总额减去负债总额以后的净额，包括流动资产、长期投资、固定资产、无形及递延资产、其他长期资产等 净资本：是衡量证券公司资本充足和资产流动性状况的一个综合性监管指标，通过对证券公司净资本情况的监控，监管部门可以准确及时地掌握证券公司的偿付能力，防范流动性风险。证券公司的净资本计算公式为：净资本=净资产－证券类资产的风险调整－应收项目的风险调整－其他流动资产的风险调整－长期资产的风险调整－或有负债×扣减比例+/－其他","text":"基本财务指标➤ 利润： 毛利润：是一个在商业根深蒂固，约定成俗的概念，它一般是指：毛利润=营业收入-营业成本 = 营业收入-材料成本-人工成本，计算毛利润的意义在于，如果不做该（笔）业务，一些资源就会被浪费或仍然会消耗，利润就会变成负值；如果做该业务，就可能赢利或减少亏损。对于效益相当好，资源利用率高的企业，完全可以忽视毛利润这个概念。 净利润 =营业收入-营业成本-三费-税金，三费包括营业费用（包装运输费/广告费…）、管理费用（公司工会经费/劳动保险/职工教育…）、财务费用（利息支出/汇兑损失） ➤ 资产： 固定资产= 指固定资产原价 - 历年已提折旧额后的净额 流动资产：指可以在一年或者超过一年的一个营业周期内变现或者耗用的资产，包括现金及各种存款、短期投资、应收及预付货款、存货等。 净资产总额：企业的资产总额减去负债总额以后的净额，包括流动资产、长期投资、固定资产、无形及递延资产、其他长期资产等 净资本：是衡量证券公司资本充足和资产流动性状况的一个综合性监管指标，通过对证券公司净资本情况的监控，监管部门可以准确及时地掌握证券公司的偿付能力，防范流动性风险。证券公司的净资本计算公式为：净资本=净资产－证券类资产的风险调整－应收项目的风险调整－其他流动资产的风险调整－长期资产的风险调整－或有负债×扣减比例+/－其他 ➤ 比率指标： 净利润率（Net Profit Margin） = 净利润÷营业收入×100%，在净利润率内又有许多类别，比如有资产净利润率、销售净利润率等。A股和美股的一般性公司利润率 5~10%，但金融、科技、医药等类型公司的利润率 10~20% 净利润增长率=（本年净利润-上年净利润）÷上年净利润×100%=（本年净利润÷上年净利润－1）×100% 毛利率（Gross Profit Margin）= 毛利润÷营业收入×100% 资产流动比率 = 流动资产/流动负债，Current Ratio = Current Assets/Current Liablilities，资产流动比率&lt;1意味着一年之内要资不抵债, 财务还算健康的公司至少应 资产流动比率&gt;1.5 非量化指标“护城河”：商业模式可复制性、核心竞争力、比较优势、品牌效应，互联网行业的“网络效应”，用户数量比例更重要，例如IM/内容平台，赢者全拿 PE(市盈率) &amp; PB(市净率) PB(市净率) = Price/Book Value = 股价/每股净资产，或者用总市值/净资产计算，PB越高，表示股票被高估 PE(市盈率) = Price/EPS = 股价/每股净利润，或者用总市值/净利润计算，PE越高，表示盈利能力越低 一家企业每年净利润都是100万元，你愿意以多少的价格收购？1000万元，则PE= 1000/100 = 10，也就是用10年的利润收购，10年后收回成本，当然这里并没考虑增长。实际上在一级市场，6-8倍PE是常见的合理区间，一些特殊行业的PE范围需特殊对待，见下：[[#行业PE、PB和百分位]]。 同理，一家企业净资产是1000万元，你愿意以多少的价格收购？还是1000万元？那PB= 1000/1000 = 1，也就是用企业净资产值收购，当然这里并没考虑资产结构和债务质量 净资产简单的理解是总资产减去总负债得出净资产。若是要再严格要求，则可以考虑总资产减去总负债的基础上再减去无形资产。因为无形资产这东西估值多少，很多时候全凭企业说了算,市净率更适合用于重资产而言。那么重资产行业有哪些？核心包括资金型的行业，比如，银行，券商，房地产等。 市盈率根据采样周期的不同, 还分为: 静态PE: 当前总市值/过去一年盈利 动态PE: 当前总市值/上季度盈利*4 = 当前总市值/上半年盈利*2 PE-TTM(滚动PE)，代表滚动市盈率的意思，它会运用最新的(一般来说，最近四个季度的窗口期)净利润指标，使得市盈率的值更有时效性。 TTM（Trailing Twelve Months）字面意思是滚动12个月，即为截至最近的连续12个月。通常，TTM用于财务报表分析，以最近的12个月（或者最近4个季度）作为一个周期，进行分析、比较。TTM常用于和上一个12个月周期进行对比，从而得出一种趋势 PEGG即Growth, 预估公司未来3~5年的利润增长率 $$ PEG = PE/G $$ PEG&gt; 1 表示企业被高估 PEG&lt; 1 表示企业被低估 美国投资大师彼得·林奇的努力下发扬光大，他曾指出，最理想的投资对象PEG应该小于0.5 PEG估值的适用对象是成长性公司或指数，这类公司的特点是利润增速很快，市盈率通常也高 ROE(资产净收益率) 如果非要我用一个指标进行选股，我会选择ROE（净资产收益率），那些ROE能常年持续稳定在20%以上的公司都是好公司，投资者应当考虑买入。——沃伦•巴菲特 净资产收益率 (Return on equity): $$ ROE = 每股净利润 / 每股净资产 = E / B $$ PE、PB两个指标都事关“股价”，而E、B则为股价的支撑。如果企业的利润增高，则市盈率降低；如果企业的净资产增加，则市净率降低，而ROE指标剥离了股价，其的核心底层在于“资本使用效率”，即：给予企业更多的资金之后，企业能否获得长足且稳健的扩展。但是，行业存在天花板，资金效率边际递减，受限于“市场规模、技术创新、管理幅度、产业竞争”等因素影响，资金有其巨大的作用，但也有明显的“临界值”。 ➤ ROE的范围： 一般的企业：10%-15%，ROE为10%是选择投资标的的一个最低标准 不错的企业：15%-20% 优秀的企业：20%-30% ➤ 使用ROE需要注意的几个问题： 企业上一年的净利润，会归集到下一年的净资产中，这部分新增资产是否能保持去年一样的ROE增长会是一个很大的考验。大部分情况下随着时间推移，企业的ROE会降速至市场平均水平，即基本通胀率+优秀企业超社会平均生产效率的部分，因此又有一句话：优秀的股权投资是抵抗通胀的超级法宝。但是企业也可以通过对利润的分红，人为稳定ROE，把“无法有效帮助企业增长”的那部分资金分红掉，然后继续以与去年同样的净资产，在特定领域内保持净利润率，从而能稳定较高的ROE。 企业通过高负债率提升ROE，当企业资产负债率越高时，通过杠杆的作用，放大净资产收益率（衡量这种杠杆用“权益乘数”）。然而，资产负债率越大，公司的经营风险就越大，所以靠提高资产负债率提高ROE要适可而止，一般资产负债率建议可控范围在&lt;50%左右（茅台资产负债率在22%左右、海康在40%左右、腾讯控股在50%左右） 总结： ROE需要考虑增长率的边际效应，随着时间推移，大部分企业ROE会降至平均水平； 透过分红、负债等数据看ROE，漂亮的ROE数据，有可能是高分红（甚至100%利润分红）、或者高负债杠杆实现的； @ref: 估值的标尺：浅析ROE指标的优与劣 - 雪球 PE &amp; PBPB/PE百分位: 比当前值低的时间的百分比, 如果当前百分位很高, 意思是现在的PE/PB在历史上很高, 投资价值低 一般情况下，当PE,PB百分位均低于30%时，就开始具备投资价值，当PE,PB百分位均高于80%时，考虑卖出。 Ref: 指数基金PE,PB百分位详解 - 知乎 Ref: 投资指数基金不得不知的估值百分位 如果不是计算一个公司的PE, 而是某个行业指数（或者综合指数）的PE, 还有两种情况: 市值加权计算法: 按照市值排序，高市值公司有更大权重，这是默认规则，大部分中证指数如果没明确写“等权”都是这种方法； 等权计算法: 无论市值大小相同权重, 避免PE收到大市值股票影响不能很好的反应市场整体的估值水平 详细指数编制规则 @ref: 关于发布中证煤炭等权指数和中证白酒指数的公告 天天、蛋卷、支付宝的数据都是PE-TTM，但为什么和中证指数公司的不一样？ // 中证的去掉了亏损 @ref: 哪里的PE估值比较准？ - 知乎 ➤ 另外，不同风格的宽基指数，其PE范围也不同： 宽基价值指数（大盘、红利）的PE估值范围： 低估🟩：0~9 适中🟨：10~16 高估🟥：16+ 创业板的PE估值范围： 低估🟩：0~50 适中🟨：50~64 高估🟥：64+ ➤ 不同行业的PE范围也有较大差别：一般来说，宽基指数、周期性不强的（消费、医药）才适合用PE进行估值，钢铁、有色、银行证券、保险不适合使用PE作为估值标准。 以下行业不适用PE估值方法： 强周期行业，如传统能源、有色、钢铁、原材料等行业，在景气周期顶点PE很低，却往往是可能需要卖出的时候；而景气低点盈利很少或者亏损，PE很高，最悲观的时候反而是逐步买入的时机。所以强周期行业股票或指数基金主要靠判别周期进行投资，而不能用PE进行估值。@link: F44.周期股 银行业，带有明显周期属性，不适用PE估值，常用PB（市净率）进行估值，一般在五大行PB达到0.7以下达到低估。 证券行业，股市交易活跃，业绩越好，PE甚至PB可能越低；股市越差，业绩越差，PE甚至PB越高。不适用PE或PB估值，只能靠判断股市周期进行投资或进行右侧趋势投资。 保险业，不适用PE估值，常用PEV（内含价值）估值，一个专属保险企业的估值方法。PEV=股价/EV，EV一般会在保险企业年报里公布。 房地产行业具有明显的周期特征，不适用PE估值。 成长期的企业，如互联网企业（净利润可能为负），一般用PS（市销率）估值。 高科技企业在走向成功途中“每天都面临着破产”，也不适用PE估值 更多有关PE参考=&gt; [[../_attachments/你以为你真的搞懂了市盈率？.pdf]] PE BandX轴是时间，Y周左边是市盈率（PE）,右边是股价， 上轨是将该股在一段时期所有最高的市盈率乘以每一个时点的每股收益计算对应的股价连接而成，下轨则是将该股在一段时期所有最低的市盈率乘以每一个时点的每股收益计算对应的股价连接而成， 中间几条轨线，是最高和最低PE二者求差值，再4等分，这样一共5条轨线 假设A公司历史最高PE = 40倍（黄色），最低13倍（粉色），得到5个PE：40x、33x 、27x..把历史的EPS分别乘以上面5个PE，连起来形成5条线。最上面一条虚拟股价线表示，“假如A公司一直都能保持40倍的估值，股价是多少”， 真实股价（红色）会触到最高的那条轨线，也即是那个时间产生了最高的PE，那个时候市场对A公司的预期达到最高 上图中的例子，应要注意估值中枢一直抬高，所以判断是否真正“足够便宜”， 可以查询到 PE Band的软件：Choice、芝士财富、万得 数据：中证指数PE、PB、ROE2022.11：","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"基本面","slug":"基本面","permalink":"https://beefyheisenberg.github.io/tags/基本面/"},{"name":"PE","slug":"PE","permalink":"https://beefyheisenberg.github.io/tags/PE/"},{"name":"市盈率","slug":"市盈率","permalink":"https://beefyheisenberg.github.io/tags/市盈率/"},{"name":"PEG","slug":"PEG","permalink":"https://beefyheisenberg.github.io/tags/PEG/"},{"name":"PB","slug":"PB","permalink":"https://beefyheisenberg.github.io/tags/PB/"},{"name":"市净率","slug":"市净率","permalink":"https://beefyheisenberg.github.io/tags/市净率/"},{"name":"ROE","slug":"ROE","permalink":"https://beefyheisenberg.github.io/tags/ROE/"},{"name":"净利率","slug":"净利率","permalink":"https://beefyheisenberg.github.io/tags/净利率/"},{"name":"毛利率","slug":"毛利率","permalink":"https://beefyheisenberg.github.io/tags/毛利率/"}]},{"title":"F41b.技术分析指标-量化回测","slug":"52.Financing/F41b.技术分析指标-量化回测","date":"2024-01-24T01:27:53.507Z","updated":"2024-01-24T01:27:53.508Z","comments":true,"path":"52.Financing/F41b.技术分析指标-量化回测/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F41b.技术分析指标-量化回测/","excerpt":"@ref: 量化择时之技术分析指标择时初探 技术分析进行择时回测： 趋势型: MA, MACD 超买超卖型: KDJ(随机指标), BIAS(乖离率), RSI(强弱指标)、BOLL MACD： 实证做法：当日收盘后，MACD指标为正，即DIF上穿DEA时，以当日收盘价买入并持有。反之卖出空仓。 实证结果：从总体上看，MACD指标对于各指数收益率的优化是有效的，但回撤偏大。可优化的空间很大。","text":"@ref: 量化择时之技术分析指标择时初探 技术分析进行择时回测： 趋势型: MA, MACD 超买超卖型: KDJ(随机指标), BIAS(乖离率), RSI(强弱指标)、BOLL MACD： 实证做法：当日收盘后，MACD指标为正，即DIF上穿DEA时，以当日收盘价买入并持有。反之卖出空仓。 实证结果：从总体上看，MACD指标对于各指数收益率的优化是有效的，但回撤偏大。可优化的空间很大。 KDJ： 实证做法：以当日收盘价计算，K上穿D即KD指标呈现多头排列时，以当日收盘价买入并持有。反之卖出空仓。 实证结果：从各指数收益率看，KDJ指标的这种KD指标多头的用法是无效的。回撤过大，造成总体收益不理想。验证了KDJ指标应与其它指标结合使用的说法。 RSI： 实证做法：以当日收盘价计算，短、中、长三个周期的RSI指标线呈现多头排列，买入持有；反之卖出空仓。 实证结果：从各指数收益率看，RSI指标的这种用法有一定的有效性，也可以称为弱有效，只有中证500的总收益率超越了指数。回撤较MACD和KDJ幅度小，但回撤的持续周期仍然偏长。造成总体收益不理想。 BIAS: 实证做法：以当日收盘价计算，短、中周期的BIAS指标线呈现多头排列，以当日收盘价买入并持有；反之卖出空仓。 实证结果：从各指数收益率看，BIAS指标的这种用法完全无效，累积收益亏损严重。回撤巨大，净值到统计周期末仍未创出新高。验证了BIAS指标应与其它指标，如移动平均线一并使用的说法。 BOLL： 实证做法：以当日收盘价计算，布林线中轨值大于上个交易日，布林线上轨的值大于上个交易日，以当日收盘价买入并持有。反之卖出空仓。 实证结果：从各指数收益率看，BOLL指标的这种择时方法是明显有效的，收益率好于上述单指标择时收益率。回撤在30%左右，仍然不十分理想，有进一步优化的空间。","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"股市","slug":"股市","permalink":"https://beefyheisenberg.github.io/tags/股市/"},{"name":"量化回测","slug":"量化回测","permalink":"https://beefyheisenberg.github.io/tags/量化回测/"},{"name":"K线","slug":"K线","permalink":"https://beefyheisenberg.github.io/tags/K线/"},{"name":"技术分析","slug":"技术分析","permalink":"https://beefyheisenberg.github.io/tags/技术分析/"},{"name":"量化交易","slug":"量化交易","permalink":"https://beefyheisenberg.github.io/tags/量化交易/"}]},{"title":"F41a.K线和技术分析","slug":"52.Financing/F41a.K线和技术分析","date":"2024-01-24T01:27:53.500Z","updated":"2024-01-24T01:27:53.501Z","comments":true,"path":"52.Financing/F41a.K线和技术分析/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F41a.K线和技术分析/","excerpt":"所谓「技术分析」 技术分析包含的内容： 技术分析理论的主要的代表有道氏理论、波浪理论、江恩法则等； 主要分析方法有K线理论、切线理论（趋势线、轨道线、黄金分割线、角度线）、形态理论（背离、发散、M头、W底、头肩顶、头肩底、圆弧底）、量价关系理论； 主要的分析指标包括：趋势型指标、超买超卖型指标、人气型指标、大势型指标等内容； 技术分析的特性: 技术分析区别于其他分析方法的关键在于，它更像一门艺术。 其一、在它的各种理论体系中，从定义到规则，都带有明显的经验总结色彩，不具备严格的数学推理过程； // 哈哈哈 其二、它包含的理论很多，每位技术分析家都有不同的见地 // 像不像星座？ ➤ 技术分析效果如何？ 专业量化交易从业人士如何看待传统的技术分析？ - 知乎 ：这里的传统技术分析包括像均线、布林带，或者MACD等技术指标，他们在量化从业人士的工具箱中处于什么地位？ MACD指标在量化策略实战中如何应用？ - 知乎 =&gt; F51.Quant.量化交易101 ➤ 技术分析的三大假设：","text":"所谓「技术分析」 技术分析包含的内容： 技术分析理论的主要的代表有道氏理论、波浪理论、江恩法则等； 主要分析方法有K线理论、切线理论（趋势线、轨道线、黄金分割线、角度线）、形态理论（背离、发散、M头、W底、头肩顶、头肩底、圆弧底）、量价关系理论； 主要的分析指标包括：趋势型指标、超买超卖型指标、人气型指标、大势型指标等内容； 技术分析的特性: 技术分析区别于其他分析方法的关键在于，它更像一门艺术。 其一、在它的各种理论体系中，从定义到规则，都带有明显的经验总结色彩，不具备严格的数学推理过程； // 哈哈哈 其二、它包含的理论很多，每位技术分析家都有不同的见地 // 像不像星座？ ➤ 技术分析效果如何？ 专业量化交易从业人士如何看待传统的技术分析？ - 知乎 ：这里的传统技术分析包括像均线、布林带，或者MACD等技术指标，他们在量化从业人士的工具箱中处于什么地位？ MACD指标在量化策略实战中如何应用？ - 知乎 =&gt; F51.Quant.量化交易101 ➤ 技术分析的三大假设： 天风证券 - 技术分析的三大假设 技术分析的理论技术是基于三项市场假设：一、市场行为包含一切；二、价格以趋势方式演变；三、历史会重演。 技术分析三大假设的漏洞是什么？ - 知乎 技术分析常用指标@ref: https://www.futunn.com/learn/detail-introduction-of-k-line-1172-1901400024 MACD、KDJ、RSI、BIAS在量化中的实际效果：F41b.技术分析指标-量化回测 ▷ 成交量 放量（成交量增加）所表明的是买卖双方对目前的价格分歧特别大。 缩量（成交量减少）所表明的是买卖双方对市场非常的一致，无论是一致的看涨也好还是看跌也罢，核心点就是一致。 缩量上涨：有些股票进入拉升状态后呈现缩量上涨的格局,很多投资者并不认可这种走势,认 为是上升乏力的表现,因为缺乏持续资金进场.事实上这种看法比较片面,缩量上 涨虽然表明增量进场比较少,但也反过来说明卖盘不多.成交量缩小还能保持上升 态势,说明主力不用多少资金就能拉升股价,实质就是浮筹比较少,即该股已经高 度控盘,后市很可能有超强的表现 缩量下跌：如果在很低的价格位置，有可能形成底部；如果在价格高位出现，突然放量下跌后，继续缩量下跌，这样的股票比较危险，因为很有可能主力已经出货完毕，缩量下跌只是散户的行为 ▷ 换手率$$ 换手率 = 单位时间成交量/总股数 $$ 按时间参数的不同，在使用上又划分为日换手率、周换手率 除新股外，大多数股票日换手在1%-25% 70%的股票日换手率低于3%（分界线），过高的换手率也意味着风险（买卖方分歧大） A股散户多，所以A股平均换手率稳居世界前列，为券商贡献巨量手续费 ▷ 量比 &amp; 委比 量比：1分钟成交量/过去5日分钟平均交易量，大于1表示交易活跃 委比：委托买入量/委托卖出量，委比反应的是买:卖的意愿，但是委托是可以撤单的，所以可能不那么准确 ▷ 总结：均线系统常见的均线系统（MACD/MA/EMA/KDJ/DKX等..）的使用方法： 均线排列：多头/空头排列、收敛/发散趋势 均线交叉：金叉、死叉 不同均线系统的背离情况 基于价格的均线系统（MACD/MA/EMA/KDJ/DKX等..）都有滞后性的问题，如果增加短期的权重可以使其变灵敏，但灵敏度的上限=K线的变化，过于频繁发出信号，比较几种均线系统： MACD(12, 26)：约等于“K线上站5MA” DK点：D点 ≈ “K线上站5MA”，K点 ≈ “K线跌破5MA” DKX： 约等于双均线 MA（5，20），但加上了成交量 EMA(5, 20)：MA的平滑版本 20MA+60MA（ETF之家提供的双均线策略）：明显滞后，能躲过一部分大跌，但由于滞后性也没机会吃到涨幅 KDJ： MACD的神经质版本，频繁的买入信号，对于中长期没法用 复盘上个牛熊周期（2019-2022），均线系统是否有效：- DK线（5MA+20MA）：在牛市启动期，可以保证上车，但在牛市顶部阶段随时可能崩盘时，会发出错误的买入信号（参考2022.03），所以DK点（包括短均线）在不同时期的信号需区别对待，在估值过高的阶段应该选择空仓 or 极小仓位- 观察（MACD/MA/EMA/DK线等..）周线背离情况，2021.4之后的周MACD/DKX/DDX出现了背离，意味着随时可能变盘：牛市跌破120MA，等于结束了，均线再次发出买入信号可以不理会 ▷ MA（移动均线）移动平均线－MA (Moving Average): 当日MA = 过去N天的收盘价求算数平均, 类似一个N天的滑动窗口 ➤ 均线的用法： 股价上站/回踩均线：例如“K线上站5日均线”作为短期趋势 均线排列： 多头排列：短期均线依次在长期均线之上，例如从上向下依次为 5—10—20—40—120 空头排列：相反 均线交叉： 金叉：短期均线上穿长期均线 死叉：短期均线下穿长期均线 均线收敛/发散： 均线间的距离呈收敛 + 向上突破：当多条均线出现收敛（均线值接近）迹象时，表明市场成本趋于一致，此时是买入信号 =&gt; [[#顾比均线]] ➤ 均线的周期： 均线 又称 功能 5日均线 周线 20日均线 月线 短期趋势 60日均线 季线 中期趋势 120日均线 半年线 中长趋势 250日均线 年线 长期趋势 120月均线 十年线 大经济周期中的超长趋势 一般以日线 MA5 + MA10解析短期走势，以 MA30 + MA60解析中期走势，以 MA120 + MA250解析中长期走势 年线、5年线（月K，MA60）和10年线（月K，MA120）的支撑性逐步增强 ➤ 不同周期 K 线的双均线设置： 月 K： MA(4, 8)，对应半年、年； MA(60, 120)，对应五年、十年； 周K：MA(17, 35)，对应 半年、年； 日K：MA(20, 60, 120)，对应 月、季、半年； 15分钟K线 / 30分钟K线，这个级别的K线在东财上可以看到资金的（大户/小户）分时博弈： 15分钟K线均线参数：MA(80, 320)，对应5日、20日； 30分钟K线均线参数：MA(40, 160)，对应5日、20日； 简单量化交易之均线策略：F52a.双均线策略 MA策略量化实测：F41b.技术分析指标-量化回测 ▷ MACD（平滑移动均线）指数平滑移动平均线（Moving Average Convergence / Divergence，缩写：MACD，港澳台称为指数平滑异同移动平均线）。是利用快速移动平均线和慢速移动平均线，在一段上涨或下跌行情中两线之间的差距拉大，而在涨势或跌势趋缓时两线又相互接近或交叉的特征，通过双重平滑运算后研判买卖时机的方法。运用两条移动平均线相互背离，相互应证的交易法则：当MACD从负数转向正数，是买的信号。当MACD从正数转向负数，是卖的信号。当MACD以大角度变化，表示快的移动平均线和慢的移动平均线的差距非常迅速的拉开，代表了一个市场大趋势的转变。 白色线(DIF): DIF = EMA(close, 12) - EMA(close, 26)，EMA(close, n)表示过去n日收盘价的指数移动平均 EMA12: 最近12日移动平均值= 前一日EMA12 × 11/13 + 今日收盘价×2/13 EMA26: 最近26日移动平均值= 前一日EMA26 × 25/27 + 今日收盘价×2/27 黄色线(DEA): 即再计算上面 DIF的 9日EMA = 前一日DEA × 8/10 + 今日DIF × 2/10 红蓝色柱: 即为MACD柱状图 = (DIF-DEA)×2，正数为红，负数为绿 零轴：在零轴以上，意味着每天的DIF大于零（每天的12EMA一直大于26EMA） MACD使用的 EMA（指数移动平均值） 的计算方法，和另一种均线指标 EXPMA（指数平均线） 还是有区别的，前者“前一日”权重更大，后者“今日”权重更大； 相比较移动均线（MA）和 MACD，二者都属于“针对过去股价”计算的均线，所有均线都有同样的问题——滞后性，但MACD为了弥补这一点，使用了DIF差值，DIF可以认为是长/短周期均值的差，反应变化程度，（对于平滑的曲线，计算变化程度用切线角度，但是K线不是“平滑”曲线，故这里也就不用切线斜率，而是用差值，来反应变化的程度）。 所以MACD指标的核心就是快慢线的变化趋势，也即DIF 相较 DIF的均值（DEA）的变化趋势，如果仅靠观察两条线的敞口大小（收敛趋势 or 发散趋势）不是很直观，为了方便观察快慢线差值变化，MACD还引入了红绿柱，用红蓝柱体能更明显反应两条线之间的差值。 ➤ MACD基本用法: DIF 向上穿过 DEA 时，被称为“金叉”，这是一个买入信号 DIF 向下穿过 DEA 时，被称为“死叉”，这是一个卖出信号 处于高位且 快慢线和K线的趋势出现背离… 卖出 参考： MACD指标的内在逻辑是什么？ - 知乎 MACD择时效果量化实测： MACD指标在量化策略实战中如何应用？- 知乎 // 结论很有意思 F41b.技术分析指标-量化回测 为什么MACD的默认参数是12、26、9（DIFF参数设置是12日和26日收盘价的EMA，DEA是9日DIFF的EMA）？ ○ 为什么是12、26？ 坊间对“12”和“26”的来历说法都较为一致。相传在 Gerald 发明 MACD 的上世纪70年代，漂亮国交易市场仍在“996”，一周有6个交易日，于是“12”对应的是两周。每个月有4周，一周休息一天，那么30-4=26，“26”对应的是一个月。但是查了道琼斯工业指数和麦当劳的历史日K图，发现一周并没有6根Bar，说明至少在漂亮国股票交易市场并没有“996”，觉得更可能是Gerald关注的交易品种一周是交易6天，类似于期货从周一上午交易到周六凌晨。 ○ 为什么是9？ “9”是每周交易日数目乘以概率密度系数后的结果，其中1/sqrt(2π)是标准正态分布的概率密度函数的系数： $$ (1+ 1/sqrt(2π)) * 6 ≈ 9$$ @ref: MACD参数设置的逻辑是什么 ？ - 知乎 ▷ KDJ（随机指标）KDJ指标的中文名称又叫随机指标，最早起源于期货市场，由乔治·莱恩（George Lane）首创。随机指标KDJ最早是以KD指标的形式出现，而KD指标是在威廉指标的基础上发展起来的。不过KD指标只判断股票的超买超卖的现象，在KDJ指标中则融合了移动平均线速度上的观念，形成比较准确的买卖信号依据。在实践中，K线与D线配合J线组成KDJ指标来使用。KDJ指标在设计过程中主要是研究最高价、最低价和收盘价之间的关系，同时也融合了动量观念、强弱指标和移动平均线的一些优点。因此，能够比较迅速、快捷、直观地研判行情，被广泛用于股市的中短期趋势分析，是期货和股票市场上最常用的技术分析工具。 RSV（未成熟随机值）的计算较复杂，忽略 K值 = 2/3 × 前一日K值 + 1/3 × 当日RSV，变化率介于D、J之间 D值 = 2/3 × 前一日D值 + 1/3 × 当日K值，D值可以看作是比K更“平均化”的RSV，变化率最低 J值 = 3 × 当日K值 - 2 × 当日D值，反应了K和D之间的差值，变化率最高 KDJ主要是利用价格波动的真实波幅来反映价格走势的强弱和超买超卖现象，在价格尚未上升或下降之前发出买卖信号的一种技术工具。它在设计过程中主要是研究最高价、最低价和收盘价之间的关系，同时也融合了动量观念、强弱指标和移动平均线的一些优点，因此，能够比较迅速、快捷、直观地研判行情。由于KDJ线本质上是一个随机波动的观念，故其对于掌握中短期行情走势比较准确。 ➤ KDJ基本用法： K/D指标的交叉类似快慢MA，K线向上突破D线时金叉，K线从上方下穿D线时死叉； K/D/J三个值都大于80，进入超买（大部分人只愿意买，股价被推高）区域，后续下跌的可能性变大； K/D/J三个值都小于20，进入超卖（大部分人只愿意卖，股价被拉低）区域，后续反弹的可能性变大； KDJ在进入超买/超卖区域后，容易出现钝化（3条线变得纠缠）； KDJ适用于短期买卖点，一般和长期MACD配合使用； ▷ RSI（强弱指标）相对强弱指标（Relative Strength Index），RSI强弱指标是根据一定时期内上涨和下跌幅度之和的比率制作出的一种技术曲线。能够反映出市场在一定时期内的景气程度。是由威尔斯.威尔德（Welles Wilder)最早应用于期货买卖，后来人们发现在众多的图表技术分析中，强弱指标的理论和实践极其适合于股票市场的短线投资，于是被用于股票升跌的测量和分析中。 技术方法： N日RSI = A /（A+B）× 100，其中：A：N日内收盘涨幅之和B：N日内收盘跌幅之和（取正值）N常用的周期有：6日 / 12日 / 24日 由上面算式可知RSI指标的技术含义，即以向上的力量与向下的力量进行比较，若向上的力量较大，则计算出来的指标上升；若向下的力量较大，则指标下降，由此测算出市场走势的强弱。 ➤ RSI基本用法：RSI值范围在0-100，”强”和”弱”以50作为分界线： RSI&gt;50，表明市场进入强市，可以考虑买入; RSI&gt;80，表明买入力量极强，进入超买区，后市回调的机会增加； RSI&lt;50，表明市场进入弱市，可以考虑卖出; RSI&lt;20，表明卖出力量极强，进入超卖区，后市反弹的机会增加。 具体使用时，三条不同周期的RSI类似多周期均线，“金叉”/“死叉”，多头排列/空头排列，敞口收敛/发散…也适用于多周期RSI； ▷ BIAS（乖离率指标）BIAS乖离率指标是测量股价偏离均线大小程度的指标。当股价偏离市场平均成本太大时，都有一个回归的过程，即所谓的“物极必反”。乖离率是指股价与平均移动线之间的偏离程度，通过百分比的形式来表示股价与平均移动线之间的差距。如果股价在均线之上，则为正值；如果股价在均线之下，则为负值。乖离率最早来源于葛兰维的平均线定律，它的理论基础主要从投资者心理角度来分析，当股价偏离市场平均成本太大时，都有一个回归的过程，即所谓的“物极必反”，因为均线可以代表平均持仓成本，利好利空的刺激，造成股价出现暴涨暴跌。 $$ BIAS=(收盘价-收盘价的N日简单平均)/收盘价的N日简单平均*100 $$ BIAS指标有三条指标线，N的参数一般设置为6日、12日、24日， 从BIAS的计算过程可以看出，其值 = 最近一天价格，相较过去N日均价的波动程度，由于只是简单的算术平均，没有归一化，导致绝对值上下限波动大，且回复性并不怎么好； 因为BIAS三条线也属于快慢线，所以均线的用法（多空排列、上穿下穿）也适用于BIAS，绝对值越大=波动越大； ➤ 实际对BIAS的应用，是均值回归。大盘指数的均值回复性比个股更好；如果是振荡期，BIAS三条线纠缠，绝对值也不大（=波动不大）；但如果出现过大的波动（上涨/下跌），则反向做，即出现正值的大波动开始做空，出现负值的大波动开始做多； ▷ EMA（指数平均数）EXPMA指标简称EMA，中文名字指数平均数指标，一种趋向类指标，从统计学的观点来看，只有把移动平均线（MA)绘制在价格时间跨度的中点，才能够正确地反映价格的运动趋势，但这会使信号在时间上滞后，而EXPMA指标是对移动平均线的弥补，EXPMA指标由于其计算公式中着重考虑了价格当天（当期）行情的权重。EXPMA=（当日收盘价－上一日EXPMA）/N + 上一日EXPMA ▷ GMMA（顾比均线）顾比均线： GMMA（Guppy Multiple Moving Average）——顾比复合移动平均线，简称顾比均线 顾比均线由两组均线构成，分别是长期组（黄线部分）和短期组（蓝线部分）。 短期组6根均线，分别是3、5、8、10、12和15日（周、月）平均线； 长期组也是6根均线，分别是30、35、40、45、50和60日（周、月）平均线。 ➤ 顾比均线使用：短期均线组和长期均线组，分别反映了短线交易者和中长期投资者的行为，当这两组指标相互靠近的时候，说明投资者和投机者对于证券的价值有了共识，而当两组相互远离的时候，就说明对价值产生了分歧 从偏股混合基金指数2005年以来的月线图来看， 在顾比均线短期组完全上穿长期组时买入，是偏右侧的买入时机； 在K线下穿长期和短期均线时，是偏左侧的买入时机 @ref: 一个简单易行的基金买入策略 - 雪球 顾比均线在基金投资中的运用 - 雪球 ▷ 布林(BOLL)线在所有的指标计算中，BOLL指标的计算方法是最复杂的之一，其中引进了统计学中的标准差概念，涉及到中轨线（MB）、上轨线（UP）和下轨线（DN）的计算。另外，和其他指标的计算一样，由于选用的计算周期的不同，BOLL指标也包括日BOLL指标、周BOLL指标、月BOLL指标年BOLL指标以及分钟BOLL指标等各种类型。经常被用于股市研判的是日BOLL指标和周BOLL指标。虽然它们的计算时的取值有所不同，但基本的计算方法一样。 以日BOLL指标计算为例，其计算方法如下： 中轨线=N日的移动平均线 // 一般用20日MA 上轨线=中轨线＋两倍的标准差 下轨线=中轨线－两倍的标准差 布林线的理论使用原则：1是均值回复，主要是K线穿过上/下轨时，可能出现反向走势；2是排列，3线敞口收敛/发散、3线方向； ➤ BOLL指标使用规则： （1）买卖信号： 当股价K线带量向上突破布林线的上轨，并且TRIX指标也已经发出底位“金叉”时，说明股价即将进入一个中长期上升通道之中，这是BOLL指标发出的买入信号。 当布林线轨道很长一段时间的底位窄幅水平运动后，一旦股价K线带量向上突破布林线的上轨，同时原本狭窄的布林线通道突然开口向上时，说明股价即将脱离原来的水平运行通道、进入新的上升通道之中，这也是BOLL指标发出的买入信号。 当股价K线向下突破布林线的中轨，并且TRIX指标也在已经发出高位“死叉”时，说明股价即将进入一个中长期下降通道之中，这是BOLL指标发出的卖出信号。 当布林线轨道很长一段时间的高位窄幅水平运动后，一旦股价K线向下突破布林线的下轨，同时原本狭窄的布林线通道突然开口向下时，说明股价即将脱离原来的水平运行通道、进入新的下降通道之中，这也是BOLL指标发出的卖出信号。 （2）持股持币信号： 当布林线开口向上后，只要股价K线始终运行在布林线的中轨上方的时候，说明股价一直处在一个中长期上升轨道之中，这是BOLL指标发出的持股待涨信号，如果TRIX指标也是发出持股信号时，这种信号更加准确。 当布林线开口向下后，只要股价K线始终运行在布林线的中轨下方的时候，说明股价一直处在一个中长期下降轨道之中，这是BOLL指标发出的持币观望信号，如果TRIX指标也是发出持币信号时，这种信号更加准确。 其他： 简单量化交易之布林带策略：F52b.布林线策略 F41b.技术分析指标-量化回测 软件特色指标（DKX、DDX）@link: [[F41a1.东方财富PC版功能说明]] DKX（DK线/多空线）根据收盘价和成交量计算出是 D点（多） or K点（空），算法未知 DDX（主力强度，分时DDX=大单净买入量/流通盘），由快/中/慢三条DDX均线： DDX也是快/中/慢 3条线，用法同均线的快慢线 DDX的红/绿柱：红-大单流入较多，绿-大单流出较多 DDX走强（持续红柱 &amp; 金叉），表示主力持续进入，但有大单持续流入不代表股价一定上涨 DDX可以在大盘/个股/板块的日K下显示，但是ETF和行业指数无（在DDE显示的ETF的DDX似乎有问题，值&gt;1） DDX与大盘股价的背离（20个交易日为窗口观察趋势），是一个逃顶信号 同花顺也有类似功能：BBD指标_百度百科 DDY (散户动向）衡量当日成交中散户参与度大小的指标 正值越大，表示当日散户离场现象明显； 负值越小，表示当日散户进场意愿强烈； DDZ (主力博弈）衡量买卖双方大单力度的指标，对于成交量大或者多空分歧较大的股票比较有效。 红色彩带表示大资金买入强度，色带越宽、越高表示买入强度越大。 当彩带突然升高放宽时往往预示短线将快速上涨。 如果要计算某天的大单净量 占交易量的比例 = 今天累计DDX/日换手率 资金博弈：每日买入单按金额分为超大/大户/中户/小户，累积计算买入量 只需关注4条线的分歧（距离走阔 or 收窄） 大盘的资金博弈，在日级别K线走阔/收窄的趋势并不明显，15分钟/30分钟下看短期的资金分歧 和DDX一样，有大单持续流入不代表股价一定上涨 资金趋势：柱状线代表每日资金流向占比情况，红色柱状线表示主力资金流入，绿色柱状线表示主力资金流出 K 线形态阳线形态 ① 全秃阳线：也称光头光脚阳线，该线是一条既无上影线，也无下影线的图线。因开盘价是最低价，收盘价是最高价，故当天一直处于上升走势，表示上升走势强劲，后市可持续看好。 ② 开盘秃阳线：也称光脚阳线，即只有上影线而无下影线的阳线。因收盘价并不是最高价，而开盘价是最低价，当天依然处于上升行情，但上挡压力开始显现。 ③ 收盘秃阳线：也称光头阳线，即只有下影线而无上影线的阳线。因收盘价是最高价，当天虽有下跌，但开盘价依然较低，表示上升力度较大，行情持续看好。 ④ 大阳线：实体较长，又带有上下影线，因实体较长，当天涨幅较大，显示较强上升走势，行情持续看好。 ⑤ 小阳线：也称小棋子，实体较小，带有不太长的上下影线，涨跌走势不明朗，行情难料。 ⑥ 星形阳线：也称极阳线，实体很小，上下影线更短，相对上方小阳线，走势更加不确定，涨跌难判断。 ⑦ 长下影阳线：实体较小，下影线较长，无上影线，或只有很短的上影线。若处在高价位（上吊线），是行情见顶的信号，应卖出股票；若处在低价位（锤子线），则是行情见底的信号，可考虑买入股票。 ⑧ 长上影阳线（倒锤头线）：也叫流星线，实体较短，上影线较长，无下影线或只有很短的下影线。若处在高价位，是行情见顶的信号，应卖出股票；若处在低价位，则是行情见底的信号，可考虑买入股票。 阴线形态 ① 全秃阴线：也称光头光脚阴线，该线是一条既无上影线，也无下影线的图线。开盘价是最低价，收盘价是最高价，上升走势很弱，行情看淡。 ② 收盘秃阴线：也称光脚阴线，即只有上影线而无下影线的阴线。遇到上涨阻力较大，行情看淡。 ③ 开盘秃阴线：也称光头阴线，即只有下影线而无上影线的阴线。虽然下挡出现了一定程度的支撑，但行情一时可能还难以变好。 ④ 大阴线：即实体大，而又带有上下影线的图线，当天下跌幅度较大，显示弱势走势，后市看淡。 ⑤ 小阴线：趋势看法同上⑤ ⑥ 星形阴线：趋势看法同上⑥ ⑦ 长下影阴线：趋势看法同上⑦ ⑧ 长上影阴线：趋势看法同上⑧ 组合形态K 线技术分析不是国内老法师特产，其实都是进口来的概念，比如上面的： 上吊线 = Hanging Man； 锤子线 = Bullish Hammer； 英为上还有根据K线形态看涨跌的专区：https://cn.investing.com/technical/candlestick-patterns … •Doji Star Bearish（十字星看跌）： •Bullish doji Star（十字星看涨）： •Falling Three Methods（中文翻译成什么？）： 趋势形态本章内容参考自：速学21个技术分析利器_富途 ▶ 阻力位 &amp; 支撑位 判断是否是“有效的支撑位”：还要看交易量，有大量交易/换手的区域，才能算为有效支撑 支撑位的形成：下跌过程中，如果在某个位置（在众多散户心理上是一个低价）出现大量的买盘，那么价格在此处不再下跌，但是当支撑位跌破后，后续可能会有较大幅度的下跌； 同时支撑位和阻力位是可以相互转化的：当股价跌破支撑位后触底，再次反弹到上次的支撑位，这个位置可能变成阻力位，因为股价运行到这里后有太多“保本出”的卖盘（这种压力位往往出现在股价底部反弹的过程中）； 压力位另一种解释（这种往往是高价位出现的阻力）：当股价足够高，因为很多人已经获利，形成众多散户的“止盈心理价位”，卖出盘会变多，此时这个位置便成为阻力位。 @ref: 【陈珺盈】：支撑位和阻力位背后的秘密 - 经管之家(原人大经济论坛) 支撑位与阻力位 因为有很多看技术指标的交易者，所以某些技术指标也可以成为阻力位 &amp; 支撑位： 均线阻力(压力)位：主要指5、10、20、30、60、120、250日等均线对股价的压力 高点(波峰)压力位：前期两个以上高点(波峰)的连线构成高点阻力位。股价突破此连线也需成交量放大配合。 低点(波谷)压力位;股价跌破前期两个以上低点(波谷)连线后，如果反弹，这条连线对股价将产生压力，这条连线就叫低点压力位。 颈线压力位：双底(W底)、头肩底、N形底、双顶(M顶)、头肩顶等形态的颈线对股价上涨或反弹都有压力。 轨道压力位：上升或下跌轨道的中轨、上轨；BOLL线的中轨、上轨对股价也有压力。这里主要讲一下BOLL中轨，上轨对股价的压力，因为在轨道中常用的就是BOLL轨道 ▶ 筹码理论什么是筹码分布？确切地说是“流通股票持仓成本分布”，展示的是不同价位上投资者的持股数量。 所有的“技术形态”都是对筹码分布的动态修改，交易量越大的点位，对筹码分布的修改力度越大。 上面提到了“有效的” 阻力位 &amp; 支撑位，应该是“成交密集区”，无论是周K线或日K线，如果在某价位区内停留一段时间（n个交易日）。这个K线集中且成交量较大的价位区称之为“成交密集区”。通常多头与空头实力变化决定成交密集区面积的大小。 但是“成交密集区”并不是静态的，因为市场过高的换手率无时无刻不在化解“成交密集区”。例如许多资金套牢之后并非死守，有些会选择卖出止损，“阻力位”也会动态下移。而且距离上个“成交密集区”的时间越长，期间换手率越高，上个“成交密集区”的效力越小。 无论是大盘还是个股，都是这样，尤其是个股，有些股票换手率极高，成交密集区作用十分微小。也就不可能形成什么压力。 K线的走出来的形态，可以认为是对筹码分布的不断修改，而筹码分布决定了阻力和支撑在哪里，阻力和支撑又在引导K线走势。 当然技术分析派称，还有所谓的“势能”… 这同样可以用筹码理论去解释：筹码分布决定了阻力的位置，股价更倾向于往阻力最小的方向移动，例如上下都有筹码集中，但上方的筹码分布更密集，这时候下行的概率更大；再例如筹码稀薄区，只需很少的成交量就可以穿过，无论向上还是向下，这种区域也是K线容易出现缺口的地方。 @ref: 同花顺等股票软件中筹码分布图有多大可信度，数据来源是什么？ - 知乎 技术分析，有用撒？——筹码分布笔记（1） - 雪球 ▷ 趋势线 上升趋势线：连接K线低点，当跌破上升趋势线时意味着可能反转下跌 下降趋势线：连接K线高点，当突破下跌趋势线意味着可能反转反弹 注意： 收盘价K线上穿or下跌趋势线波动超过3%时才视为有效； 趋势线穿过的点越多，它所反映的趋势走向越准确； ▷ 轨道线在趋势线的基础上，添加上升轨道线(上升过程中连接高点) 和 下降轨道线（下降过程中连接低点），当股价突破上升轨道线 &amp; 跌破下降轨道线后，行情可能有大的变动。 ▷ 楔形形态如果轨道线的上下轨道相交，则被称为楔形 例①-上涨趋势中，出现的向下运行楔形，其调整的是相对应的此前一轮上涨，最后还将向上突破顺应原有趋势来发展： 例②-下跌趋势中，出现的向上运行楔形，这则是对原有下跌趋势进行的一轮修正，此后的运行方向也延续向下： 例③-两个典型的反转楔形： 楔形形态，可以认为是对上一段走势（筹码分布）的整理： @ref: https://xueqiu.com/8773730078/237417419 好多老法师喜欢画线，画线中的玄学之一就是下跌过程中的上楔形走势，所有技术分析的预测都能用筹码理论解释，因为所有技术形态都是对筹码的整理。如何用筹码理论解释“下跌过程中的上楔形走势”呢，先简化一下模型，假如每天成交量都完全相等的情况，那么楔形走势，可以认为对筹码的整理如下： 筹码中枢一定是上移的 K线的震荡逐步减弱，k线下方的筹码分布变得更集中综上，这种楔形走势，实际增加了获利盘的风险，更有可能出货。但是，每天的成交量是不同的，那筹码未必走出上面的期望分布，楔形也就失效了，所以任何画线技术分析都是概率的 ▷ 头肩形态 构成：头肩顶图形以左肩、头部、右肩，以及颈线构成 成交量：左肩的到右肩，成交量呈递减现象 在头肩形态中，颈线成为支撑位，当颈线被击破时，是一个沽出信号 注意事项： 如果成交量在跌破颈线时明显增加，表示抛售力量庞大，加速下跌。 跌破颈线后偶尔会出现暂时性的回调，但大概率不会超越颈线位（颈线变为回调的压力位），这情形通常会在低成交量的跌破时出现。 若跌破颈线后，回调时超越颈线位置，头肩顶形态很大可能会失败，不适合追空/卖出。 ▷ 圆顶 &amp; 圆底圆顶的理论：股价运行到在圆顶左边时，切线斜率较大（也意味着买盘强），接近圆顶的顶部附近，斜率为0，意味着买盘力量减弱，无法再支撑股价向上运行 ▷ 背离形态背离形态往往意味着后续趋势可能发生变化。由于日线存在着较多的骗线，一些技术指标会反复发出背离信号，使得其实用性不强，建议重点关注周线上的技术指标背离现象。 （1）K线与交易量背离（量价背离）： 底背离：出现于价格的阶段性底部区域，K线价格持续阶段下跌，成交量出现上扬趋势，有可能筑底 &amp;向上反转；从筹码理论解释，放量意味着这个区域迅速集中起来一堆筹码，放量的价位也就变成了“阻力位”，至于反弹能走多远，要看上面套牢筹码的抛压，如果抛压过重，下面获利筹码也会撤离… 顶背离：出现于价格的阶段性顶部区域，K线价格持续阶段上涨。成交量出现下降趋势，有可能价格见顶 &amp;下跌。从筹码理论解释，出现顶背离的时候，因为上涨的时候缩量，所以出现了“价涨，但筹码中枢没跟着涨”的现象，也就是说，让下方大量的获利筹码（绿色最长的线）有了结账退出的动力： 在App的设置中，K线和成交量都设置同样周期的移动平均线，更容易观察到背离。 （2）K线与 MACD 背离： 顶背离: K线上涨, 但是MACD（DIF和DEA）趋势向下，“一般是股价在高位即将反转转势的信号，表明股价短期内即将下跌”。这种背离也不神秘，只要K线趋势的斜率变小，就一定有“MACD背离形态”，至于上升中趋势线斜率变小意味着什么不言而喻，但最终还是看筹码分布和趋势 底背离: K线下跌, 但是MACD（DIF和DEA）向上，“预示着下跌行情将结束”。底部MACD背离的形成同上 ▷缺口K线补缺口理论： A、向上的缺口。由于缺口下端以上全部是获利盘，所以赚到钱的人就有了结的动力，这股力会一直持续到价格接近缺口下端为止。从“筹码分布”的理论解释.. B、向下的缺口。由于缺口下端以下部分全都是套牢盘，卖出的人就会减少，直到价格接近缺口上端时实现平衡 交易理论江恩理论、道氏理论、波浪理论、箱体理论 @ref: https://www.futunn.com/learn/detail-ganns-theory-1172-1902400011 ▷ 波浪理论五浪理论_百度百科 推动浪： 第一浪：建仓浪 第二浪：洗盘浪 第三浪：主升浪 第四浪：调整，通常在低一级的对上一个第四浪之范围内完结，浪底不会低于第一浪的顶。 第五浪：股市中第五浪升幅，一般较第三浪为小。 调整浪 A浪：调整浪的第一波 B浪：升势较为情绪化，出现传统图表的牛势陷阱 C浪：调整浪的终点，破坏力较强，C浪应该可以再划分为低一级的五个波浪 … ▷ 箱体理论 K线在箱体内波动，是调整阶段； 在箱体内运行是调整阶段，一旦K线突破压力位，会进入下一个箱体周期，此时是较好的买入时期； ▷ 江恩理论参考：江恩理论 - 快懂百科 ▷ 道氏理论参考：道氏理论 - 快懂百科","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"股市","slug":"股市","permalink":"https://beefyheisenberg.github.io/tags/股市/"},{"name":"K线","slug":"K线","permalink":"https://beefyheisenberg.github.io/tags/K线/"},{"name":"技术分析","slug":"技术分析","permalink":"https://beefyheisenberg.github.io/tags/技术分析/"}]},{"title":"F41.K线","slug":"52.Financing/F41.K线","date":"2024-01-24T01:27:53.496Z","updated":"2024-01-24T01:27:53.496Z","comments":true,"path":"52.Financing/F41.K线/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F41.K线/","excerpt":"K线▷ K线图, 英文名：K Chart, Candlestick Chart 中文中的「K 线图」一词与英文字母 K 没关系，也是从日语误译而来：「K 线」音译自日文汉字「罫線」（kei-sen），因为日语「罫線表」一词指行情图表，并不专指 K 线图，这个张冠李戴的翻译，最终因简单好记不胫而走，成了一个让世界人民莫名其妙的中文词。 最上方的一条细线称为上影线，中间的一条粗线为实体，下面的一条细线为下影线。 当收盘价高于开盘价，也就是股价走势呈上升趋势时，我们称这种情况下的 K 线为阳线，中部的实体以空白或红色表示。反之称为阴线用黑色实体或绿色表示。 上影线的长度表示最高价和收盘价之间的价差，实体的长短代表收盘价与开盘价之间的价差，下影线的长度则代表开盘价和最低价之间的差距。","text":"K线▷ K线图, 英文名：K Chart, Candlestick Chart 中文中的「K 线图」一词与英文字母 K 没关系，也是从日语误译而来：「K 线」音译自日文汉字「罫線」（kei-sen），因为日语「罫線表」一词指行情图表，并不专指 K 线图，这个张冠李戴的翻译，最终因简单好记不胫而走，成了一个让世界人民莫名其妙的中文词。 最上方的一条细线称为上影线，中间的一条粗线为实体，下面的一条细线为下影线。 当收盘价高于开盘价，也就是股价走势呈上升趋势时，我们称这种情况下的 K 线为阳线，中部的实体以空白或红色表示。反之称为阴线用黑色实体或绿色表示。 上影线的长度表示最高价和收盘价之间的价差，实体的长短代表收盘价与开盘价之间的价差，下影线的长度则代表开盘价和最低价之间的差距。 常用K线周期5分钟、15分钟、60分钟、日K、周K（7个交易日）、月K（30个交易日） 分时图中的两条线➤ 大盘（上证指数、深成指数）分时图 白线：也即“上证指数”，在上海证券交易所全部上市企业股票（包括A股和B股）经过加权计算得出的； 黄线：“上证领先指标”，不加权计算出的指数，更多反应了小盘的走势 ➤ 股票分时图 白线：实时成交价格； 黄线：当日平均成本线，是根据每笔成交量按照移动加权计算的价格的反映，表示该种股票即时成交的平均价格(当日的平均成本)，即当天成交总金额除以成交总股数 ➤ ETF、LOF基金分时图 白线和黄线同上 紫线：IOPV(Indicative Optimized Portfolio Value)，是ETF和LOF的参考性基金单位净值 IOPV(Indicative Optimized Portfolio Value) 是由交易所计算的ETF实时单位净值的近似值,以便于投资者估计ETF交易价格是否偏离了内在价值。每15秒计算并公告，计算方法是由证券交易所根据基金管理人提供的计算方法及每日提供的申购、赎回清单，按照清单内组合证券的最新成交价格计算 以ETF为例，当现价小于IOPV价格时，称为折价；当现价大于IOPV价格时，称为溢价，需要注意的是，溢价的大部分都是QDII的基金，折价的大部分都是封闭基金， QDII基金容易产生溢价的原因可能为：QDII基金买的是海外的股票，基金有一定的外汇额度，一旦用完就无法购买海外的股票。但如果有大量的看多资金，场外因没有外汇额度无法申购，就只有在场内买入，造成溢价。 =&gt; 扩展阅读：如何通过基金的IOPV进行套利 复权让 K 线图更真实说复权，首先要明白什么是 送转和除权: 送转就是上市公司给股东送股或者转增股票，比如10送10、10送15。转股和送股的区别主要是前者是用的资本公积金，后者用的是未分配利润。上市公司在送股后，股票的数量变多，但是公司价值不变，所以要把分配的部分从当前股价上扣除，导致股价变低，在K线图上出现一个缺口，这个缺口就是除权形成的。 复权是什么意思？ 复权就是对股价和成交量进行权息修复，按照股票的实际涨跌绘制股价走势图，并把成交量调整为相同的股本口径，然后用相同成本进行比较。复权可以消除由于除权除息造成的价格走势畸变，保持股价走势的连续性。复权后方便判断当前股价在较长的一段时间内是处于相对历史高位还是低位。 不复权就是除权后不填补股价走势图上的巨大空隙，任由断层存在。 前复权是以目前股价为基准复权 后复权是保持上市第一天的价格不变，根据分红配股数据处理之后的价格，这会导致最后一天的价格显示出来不是当前实际成交价，但可以看出股票真实价值的增加及持股者的真实收益率，查询也比较直观。但是，由于后复权的K线价格和当前的成交价相差较大，容易对用户造成一定困扰。 技术分析=&gt; F41a.K线和技术分析","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"股市","slug":"股市","permalink":"https://beefyheisenberg.github.io/tags/股市/"},{"name":"K线","slug":"K线","permalink":"https://beefyheisenberg.github.io/tags/K线/"}]},{"title":"F38.桥水全天候策略","slug":"52.Financing/F38.桥水全天候策略","date":"2024-01-24T01:27:53.491Z","updated":"2024-01-24T01:27:53.491Z","comments":true,"path":"52.Financing/F38.桥水全天候策略/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F38.桥水全天候策略/","excerpt":"@tag: #资产配置 风险平价(Risk Parity)理论，风险平价的意思是通过配置不同类型的资产（如股票、债券、商品、黄金等），目的是创造一个更好的分散组合，这个分散组合将有更好的收益风险比率，天候策略能适应各种经济环境，在风险最小的情况下获取市场平均回报。 在漫长的投研积累过程中，Ray Dalio 最终把经济环境拆分成了四类，并描绘出了全天候策略： 这个四宫格和平时看到的不太一样，并不是把2个要素当做2个轴组成四宫格，黄色上下表示通胀高低，红色上下表示经济增长高低","text":"@tag: #资产配置 风险平价(Risk Parity)理论，风险平价的意思是通过配置不同类型的资产（如股票、债券、商品、黄金等），目的是创造一个更好的分散组合，这个分散组合将有更好的收益风险比率，天候策略能适应各种经济环境，在风险最小的情况下获取市场平均回报。 在漫长的投研积累过程中，Ray Dalio 最终把经济环境拆分成了四类，并描绘出了全天候策略： 这个四宫格和平时看到的不太一样，并不是把2个要素当做2个轴组成四宫格，黄色上下表示通胀高低，红色上下表示经济增长高低 1、经济上升期：股票、商品、公司信用债、新兴市场债券将有较好表现；// 增长2、经济下降期：普通债券、通胀联系债券表现较好； // 衰退3、通胀上升期：通胀联系债券、商品、新兴市场债券表现较好； // 通胀4、通胀下降期：股票、国债、公司债表现较好。 // 通缩 比较F21a.美林时钟，1对应复苏期，2=衰退期，3=通胀期，4没有对应（美林时钟把滞胀期考虑进去了，但没有考虑通缩，桥水全天候有通缩期） 达里奥认为四宫格涵盖了可能出现的经济情形，而且这四种情形会等概率的情况出现，所以只需要在每种可能出现的场景中配置相同风险的资产，即可确保无论在哪种经济条件下都能很好控制风险敞口。 而桥水基金公司的全天候策略基金做的工作是，假定不知道图中四个象限内未来哪种资产表现较好，试图买入各种类别的资产相同权重（25%）来分散风险，也即是说“四宫格”期望通过将风险等量分布于四种经济环境来达到组合的分散和平衡。 @ref: 基于桥水的中国版全天候策略–ETF之家 详细说风险平价(Risk Parity)理论： 全天候（AW）的理念： 承认风险（波动无可避免），但AW组合要求在不同周期内风险要等分（波动率都25%） 每种资产给整个投资组合带来的波动率相同。简单的说，如果股票的波动率是国债的10倍，那么国债的持仓就应该是股票的10倍，这样股票和国债对投资组合的影响才能相同。并不是“当前时期的x资产收益最高，就在这个周期就优先多配x资产”。 如上，全天候策略的特点是低波动低风险（Sharpe Ratio是0.73），收益率并不太高 为了实现Risk Parity，通常需要借助杠杆（主要是债券，因为波动率低，想让它和其他东西波动一样需要持有相当于资金量数倍的国债，这会就需要用到保证金交易了）。在几十年前，甚至现在，在资产组合里用上杠杆都会被视为是一种高风险的举动，虽然这样做可以实际上降低风险。为了应对类似08这样的股市回调，Ray Dalio给AW加上了Depression gauge（萧条度量），似乎是在萧条时将股票转成T-Bills，具体细节不知。 一直有人质疑AW或RiskParity类基金赚钱只是因为放大了债券上的收益，赶上了债券几十大年牛市。Bob Prince认为，加息发生在经济过热（至少是向好）或者通胀的时候，那时AW可以通过股票和商品获利。比如1972~81也是加息周期，但伴随着大通胀，所以AW表现也不错。 @ref: Ray Dalio 的「全天候交易策略」是什么？如何理解？ - 知乎 如何执行风险平价(Risk Parity)策略？比如上面提到了通过xx资产的波动率决定它在组合中的比例，是如何观测xx资产的波动率呢？ 1，风险的度量。经典的有方差，VaR，ES等等，每家公司具体的选择不同，结果会很不同。2，数据的质量。这里的数据不是指价格的原始数据，而是作为模型输入的参数。举个例子，如果风险测度选择传统的方差，那就免不了涉及到协方差矩阵。原始数据直接估计出的协方差矩阵很noisy，最简单的方法是用高斯先验shrinkage一下 @ref: 就算 Raymond Dalio 的「全天候交易策略」被公布出来，让其保持领先优势的核心在哪里？他人模仿的难点在哪？ - 知乎","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"资产配置","slug":"资产配置","permalink":"https://beefyheisenberg.github.io/tags/资产配置/"}]},{"title":"F35.REITs","slug":"52.Financing/F35.REITs","date":"2024-01-24T01:27:53.487Z","updated":"2024-01-24T01:27:53.487Z","comments":true,"path":"52.Financing/F35.REITs/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F35.REITs/","excerpt":"","text":"@tag: #REITs 在我的投资组合里，必须要持有什么样的REITs基金？ - 雪球 中国REITs-IPO市场溢折价与投资价值分析- 雪球","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"投资","slug":"投资","permalink":"https://beefyheisenberg.github.io/tags/投资/"}]},{"title":"F34b.期指和期权","slug":"52.Financing/F34b.期指和期权","date":"2024-01-24T01:27:53.483Z","updated":"2024-01-24T01:27:53.483Z","comments":true,"path":"52.Financing/F34b.期指和期权/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F34b.期指和期权/","excerpt":"期货股指期货（期指）顾名思义，股指期货就是股票指数的期货，因此通常也被专业人士称为期指。它是在中国金融期货交易所上市的标准化期货合约。属于期货产品中的一种，但有别于在商品交易所交易上市的商品期货，股指期货是以现金方式进行交割，因此它属于金融期货的一种。 当前上市的股指期货品种有: IH合约对应的标的物是上证50指数（代码：000016）， IF合约对应的标的物是沪深300指数（000300）， IC合约对应的标的物是中证500指数（000905）。 IM：中证1000 TS：2年期国债期货 TF：5年期国债期货 T：10年期国债期货","text":"期货股指期货（期指）顾名思义，股指期货就是股票指数的期货，因此通常也被专业人士称为期指。它是在中国金融期货交易所上市的标准化期货合约。属于期货产品中的一种，但有别于在商品交易所交易上市的商品期货，股指期货是以现金方式进行交割，因此它属于金融期货的一种。 当前上市的股指期货品种有: IH合约对应的标的物是上证50指数（代码：000016）， IF合约对应的标的物是沪深300指数（000300）， IC合约对应的标的物是中证500指数（000905）。 IM：中证1000 TS：2年期国债期货 TF：5年期国债期货 T：10年期国债期货 每个股指期货品种又分别对应四个月份的合约，当月、下月、季月、隔季月，比如，当前IH对应的四个月份合约分别是6月（合约代码：IH2006）、7月（IH2007）、9月（IH2009）和12月（IH2012）。 期权 期权类型：买入股票的选择权称为认购期权，call option;卖出股票的选择权称为认沽期权，put option; 买入Call（Long Call）:买入看涨期权；买入Call使投资者以固定费用获得到期前用预定价格购买标的资产的权利。 买入Put（Long Put）：买入看跌期权，即买入卖权；买入Put使投资者支付固定的权利金以获得在到期之前按照预定价格卖出标的资产的权利。 到期日：合约的最后执行期限。美式期权可以在到期日前的任何时候行权。在美股中，股票期权合约的期限有1个月、3个月、6个月和9个月，到期日为对应月的第三个星期五。 行权价（strike price）: 约定的对应股票的交易价格。如果期权持有人马上行权而有利可图时，称为价内期权；例如，行权价低于当前股价的认购期权和行权价高于当前股价的认沽期权都是价内期权。 股票期权的买卖单位是以一个合约为单位的（contract）。一个合约代表了100股股票的权利。 @ref: https://zhuanlan.zhihu.com/p/21360748 ETF期权股票ETF期权虽然跟股指期货一样属于衍生品，但它作为期权工具，与期货又有很大的不同。所谓期权是指未来的一种权利。是赋予其购买方在规定期限按买卖双方约定的价格购买或者出售一定数量某种标的资产的权利。期权买方为了获得这个权利所支付的费用叫做权利金，也就是期权的价格。而期权的卖方为了确保买方行权时能过履行相关义务而向交易所质押的费用则叫做保证金。 股票ETF期权的标的物是ETF指数基金， 比如，当前在上交所上市的300ETF期权，它对应的标的物指数就是300ETF（代码：510300）； 在深交所上市的300ETF期权，它对应的标的物指数也是300ETF，但代码是（159919）。这说明跟踪同一指数沪深300（000300）的股票ETF可以有两个或者多个，比如此例中上交所和深交所分别有一个。它们分别有自己的股票ETF期权。 股票ETF期权品种也会对应多个不同到期月份的合约，如下图所示，对于300ETF股票期权，当前就有6月、7月、9月和12月到期的合约。 指数期权股票指数期权跟股票ETF期权一样同属于期权，但它们却因标的物的不同而有所不同。 股票ETF期权的标的物是ETF指数基金，而股票指数期权的标的物是股票指数。比如，IO合约就是以沪深300指数为标的物的股票指数期权。 标的物：沪深300指数（000300）对应期权：IO合约 标的物：沪深300ETF（510300）对应期权：上交所300ETF期权合约 标的物：沪深300ETF（159919）对应期权：深交所300ETF期权合约 通过以上对比会发现，沪深300指数有自己的期权。而跟踪复制沪深300指数的ETF指数基金们也有它们的期权。 当前IO期权有6个不同到期月份的合约，分别是6月（IO2006）、7月（IO2007）、8月（IO2008）、9月（IO2009）、12月（IO2012）和明年3月到期的（IO2103）。 比较股指期权 vs ETF期权 上市交易所不同，股指期权上市交易所是中国金融期货交易所，而ETF期权是上海证券交易所和深圳证券交易所； 标的指数不同，股指期权的标的物指数是沪深300指数，代码为000300；而ETF期权的标的物是ETF指数基金； 交割方式不同，股指期权是现金交割，而ETF期权是实物交割； 到期日不同，股指期权是合约到期月份的第三个星期五（与股指期货到期日相同），而ETF期权是到期月份的第四个星期三； 合约月份不同，股指期权有6个，分别是当月、下2个月及随后3个季月，而ETF期权有4个，分别是当月、下月及随后两个季月。 @ref: https://zhuanlan.zhihu.com/p/148297444 期货、期权的交易比较➤ 【股指期货】的交易特点： 股指期货作为期货品种的一员，具备双向交易两个维度，即，做多与做空。常见的交易指令包括：买入开仓、卖出平仓、卖出开仓、买入平仓。所谓开仓包含两层意思，一、看涨指数的时候，逢低买进股指期货合约，也叫买入开仓指令；二、看跌指数的时候，逢高卖出股指期货，又叫卖出开仓指令。 所谓平仓是指对上述已经开仓的股指期货合约进行了结，也包含两层意思。一、对买入开仓合约的平仓，相当于卖出股票；二、对卖出开仓合约的平仓，相当于融资融券时，买券还券。最终的结果是空仓，不持有任何合约。 小结，看涨大盘，可以通过做多股指期货获利；看跌大盘，可以通过做空股指期货获利。它有两个交易维度，可以类比成几何中的二维平面 。 ➤ 【期权】的交易特点： 期权作为金融衍生品皇冠上的明珠，其交易维度更加丰富。除了期货的做多/做空，还可以交易波动率（例如50ETF波指）。","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"期权","slug":"期权","permalink":"https://beefyheisenberg.github.io/tags/期权/"},{"name":"期货","slug":"期货","permalink":"https://beefyheisenberg.github.io/tags/期货/"},{"name":"期指","slug":"期指","permalink":"https://beefyheisenberg.github.io/tags/期指/"}]},{"title":"F34a.期货","slug":"52.Financing/F34a.期货","date":"2024-01-24T01:27:53.479Z","updated":"2024-01-24T01:27:53.479Z","comments":true,"path":"52.Financing/F34a.期货/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F34a.期货/","excerpt":"期货基本概念开仓也叫建仓，是指投资者新买入或新卖出一定数量的股指期货合约。如果投资者将这份股指期货合约保留到最后交易日，他就必须通过现金交割来了结这笔期货交易。 卖出合约一方，叫空方，货品（标的）跌价获利 买入合约一方，叫多方，货品涨价获利 持仓：股指期货投资者在开仓之后尚没有平仓的合约，叫做未平仓合约，也叫持仓。开仓之后股指期货投资者有两种方式了结股指期货合约：或者择机平仓，或者持有至最后交易日并进行现金交割。 期货逐日盯市制度：每天都会结算一次保证金、合约的盈亏（如果合约涨价，空方需要把合约上涨的价格给多方账户，从空方保证金扣除，如果空方保证金不足，需要再补保证金 货品单价有可能跌成负的（a买入期货合约，但是又卖不出去无法平仓…","text":"期货基本概念开仓也叫建仓，是指投资者新买入或新卖出一定数量的股指期货合约。如果投资者将这份股指期货合约保留到最后交易日，他就必须通过现金交割来了结这笔期货交易。 卖出合约一方，叫空方，货品（标的）跌价获利 买入合约一方，叫多方，货品涨价获利 持仓：股指期货投资者在开仓之后尚没有平仓的合约，叫做未平仓合约，也叫持仓。开仓之后股指期货投资者有两种方式了结股指期货合约：或者择机平仓，或者持有至最后交易日并进行现金交割。 期货逐日盯市制度：每天都会结算一次保证金、合约的盈亏（如果合约涨价，空方需要把合约上涨的价格给多方账户，从空方保证金扣除，如果空方保证金不足，需要再补保证金 货品单价有可能跌成负的（a买入期货合约，但是又卖不出去无法平仓… 平仓，是指期货投资者买入或者卖出与其所持股指期货合约的品种、数量及交割月份相同但交易方向相反的股指期货合约，了结股指期货交易的行 为。 一般期货都不会交割，而在交割前平仓 平仓分为对冲平仓和强行平仓 对冲平仓：对于多方，是卖出合约 强行平仓：如果未及时增加保证金，会被强行平仓 @ref: 词条页面_百科_东方财富网 期货交割是指期货合约到期时，交易双方通过该期货合约所载商品所有权的转移，了结到期未平仓合约的过程。交割方式有现金交割、实物交割两类：现金交割是指合约到期日，核算交易双方买卖价格与到期日结算价格相比的差价盈亏，把盈亏部分分别结算到相应交易方，期间不涉及标的实物交割；实物交割是指合约到期日，卖方将相应货物按质按量交入交易所指定交割仓库，买方向交易所交付相应货款，履行期货合约。一般金融证券类期货合约以现金交易为主，商品期货合约以实物交割方式为主。 国内主要期货市场&amp;品种国内期货行情_新浪期货 郑州商品交易所: 大连商品交易所: 上海期货交易所:","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"投资","slug":"投资","permalink":"https://beefyheisenberg.github.io/tags/投资/"},{"name":"金融衍生品","slug":"金融衍生品","permalink":"https://beefyheisenberg.github.io/tags/金融衍生品/"},{"name":"期货","slug":"期货","permalink":"https://beefyheisenberg.github.io/tags/期货/"}]},{"title":"F34.金融衍生品","slug":"52.Financing/F34.金融衍生品","date":"2024-01-24T01:27:53.475Z","updated":"2024-01-24T01:27:53.475Z","comments":true,"path":"52.Financing/F34.金融衍生品/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F34.金融衍生品/","excerpt":"金融衍生品（derivatives)，是指一种基于基础金融工具的金融合约，其价值取决于一种或多种基础资产或指数，合约的基本种类包括远期合约、期货、掉期（互换）和期权。 金融衍生品还包括具有远期、期货、掉期（互换）和期权中一种或多种特征的混合金融工具。 这种合约可以是标准化的，也可以是非标准化的 衍生品主要四大类：期权、期货、远期、互换 南十里 - 雪球：想要真正了解衍生品世界，比如期权和期货市场，有时需要用不同方式去思考，而且这些方式通常都会让我们脱离自己的思维舒适地带。爱因斯坦曾说过：“任何一个聪明的傻瓜都可以把问题搞得更大、更复杂、更激烈。而朝相反方向前进，则需要一点点天分以及很大的勇气。” 期货=&gt; F34a.期货","text":"金融衍生品（derivatives)，是指一种基于基础金融工具的金融合约，其价值取决于一种或多种基础资产或指数，合约的基本种类包括远期合约、期货、掉期（互换）和期权。 金融衍生品还包括具有远期、期货、掉期（互换）和期权中一种或多种特征的混合金融工具。 这种合约可以是标准化的，也可以是非标准化的 衍生品主要四大类：期权、期货、远期、互换 南十里 - 雪球：想要真正了解衍生品世界，比如期权和期货市场，有时需要用不同方式去思考，而且这些方式通常都会让我们脱离自己的思维舒适地带。爱因斯坦曾说过：“任何一个聪明的傻瓜都可以把问题搞得更大、更复杂、更激烈。而朝相反方向前进，则需要一点点天分以及很大的勇气。” 期货=&gt; F34a.期货 期货 vs 期权： 期货是指买卖双方约定在未来某一特定时间按照约定的价格在交易所进行交收标的物的合约。 期权是一种可交易的合约，它给予合约的买方在双方约定期限以约定价格购买或者出售约定数量合约指定资产的权利。简单而言，它是一种“未来”可以选择执行与否的“权利”。 1、买卖双方的权利和义务不同。期权是单向合约，买卖双方的权利与义务不对等。买方有以合约规定的价格买入或卖出标的资产的权利，而卖方则被动履行义务。期货合约是双向的，双方都要承担期货合约到期交割的义务。 2、履约保证不同。在期权交易中，买方最大的亏损为已经支付的权利金，所以不需要支付履约保证金。而卖方面临较大风险，可能亏损无限，因而必须缴纳保证金作为担保履行义务。而在期货交易中，期货合约的买卖双方都要交纳一定比例的保证金。 3、保证金的计算方式不同。由于期权是非线性产品，因而保证金非比例调整。对于期货合约，由于是线性的，保证金按比例收取。 4、清算交割方式不同。当期权合约被持有至行权日，期权买方可以选择行权或者放弃权利，期权的卖方则只能被行权。而在期货合约的到期日，标的物自动交割。 5、合约价值不同。期权合约本身有价值，即权利金。而期货合约本身无价值，只是跟踪标的价格。 6、盈亏特点不同。期权合约的买方收益随市场价格的变化而波动，但其最大亏损只为购买期权的权利金。卖方的收益只是出售期权的权利金，亏损则是不固定的。在期货交易中，买卖双方都面临着无限的盈利与亏损。以上为期货与期权的区别报道。 @ref: 与友漫谈——期权保证金“十一问” - 雪球 期权➤ 期权分类： 从期权买方的权利内容来看，期权可以分为认购期权（call options）和认沽期权（put options）。 认购期权是指期权的买方向期权的卖方支付一定数额的权利金后，将有权在期权合约规定的时间内，按事先约定的价格向期权卖方买入一定数量的期权合约规定的标的资产，但不负有必须买进的义务。而期权卖方有义务在期权合约规定的时间内，应期权买方的要求，以期权合约事先规定的价格卖出期权合约规定的标的资产。 认沽期权是指期权的买方向期权的卖方支付一定数额的权利金后，即有权在期权合约规定的时间内，按事先约定的价格向期权卖方卖出一定数量的期权合约规定的标的资产，但不负有必须卖出的义务。而期权卖方有义务在期权合约规定的时间内，应期权买方的要求，以期权合约事先规定的价格买入期权合约规定的标的资产。 按行权时间来看，可以分成欧式期权和美式期权。 欧式期权只允许期权买方在到期日当天行使购买（如果是认购期权）或出售（如果是认沽期权）标的资产。 美式期权允许期权买方在到期日或到期日前任一交易日行使购买（如果是认购期权）或出售（如果是认沽期权）标的资产的权利。 按标的资产不同来看，期权可以分为个股期权、股指期权、利率期权、外汇期权和商品期权等。 个股期权的标的资产是单只股票，期权买方在交付了权利金后取得在期权合约规定的行权日按照行权价买入或卖出一定数量的某一只股票的权利。 按照行权价与标的资产价格的相关关系，期权可以分为实值期权、虚值期权和平值期权。 实值期权，也叫价内期权，是指行权价与标的资产的当前市场价格相比较为有利（即如果立即行权可以获得相应收益）的期权。如果是认购期权，那么行权价小于标的资产价格的期权为实值期权；如果是认沽期权，那么行权价大于标的资产价格的期权为实值期权。 虚值期权，也叫价外期权，是指行权价与标的资产的当前市场价格相比较为不利（即如果立即行权将会导致亏损）的期权。如果是认购期权，那么行权价大于现行标的资产价格的期权为虚值期权；如果是认沽期权，那么行权价小于现行标的资产价格的期权为虚值期权。 平值期权，也叫价平期权，是指行权价与标的资产的当前市场价格一致的期权。 ➤ 奇异期权： 奇异期权也可以称为“新型期权”（exotic options），奇异期权花样繁多，他们通常都是在传统期权的基础上加以改头换面，或通过各种组合而形成。 奇异期权比常规期权(标准的欧式或美式期权)更复杂的衍生证券，这些产品通常是场外交易或嵌入结构债券。比如执行价格不是一个确定的数，而是一段时间内的平均资产价格的期权，或是在期权有效期内如果资产价格超过一定界限，期权就作废。一般来说，奇异期权包括障碍期权、亚式期权、打包期权、回溯期权和复合期权等。 奇异期权-雪球与友漫谈——障碍期权之雪球结构 - 雪球 障碍期权可分为敲出期权（knock-out）和敲入期权（knock-in）两类。当标的资产价格达到一定水平时，敲出期权不再存在；当标的价格达到一定水平时，敲入期权才开始存在。我们常常听到的雪球结构期权就是障碍期权，设计中即包括敲入事件，也包括敲出事件，这样一来，最后的收益就取决于挂钩标的走势和敲入、敲出事件发生的时间 比如有这样一款产品： 收益计算规则： 发生敲出事件，产品提前结束，具体收益需要用年化票息率计算，比如第1个月就敲出，实际持有1个月，18%/12=1.5%，收益=本金*1.5%。 发生敲入事件，未发生敲出事件。如果到期日股价&gt;期初价格，投资者收益为0；如果到期日股价&lt;期初价格，需承担标的下跌损失。 如果敲入和敲出都没有发生，产品12个月到期，按约定票息率18%结算。由于最后的收益取决于挂钩标的走势和敲入、敲出事件发生的时间，那么会出现几种情形呢？ 在12个月期限内，共有5种可能性，逐一分析：","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"投资","slug":"投资","permalink":"https://beefyheisenberg.github.io/tags/投资/"},{"name":"金融衍生品","slug":"金融衍生品","permalink":"https://beefyheisenberg.github.io/tags/金融衍生品/"},{"name":"期权","slug":"期权","permalink":"https://beefyheisenberg.github.io/tags/期权/"},{"name":"期货","slug":"期货","permalink":"https://beefyheisenberg.github.io/tags/期货/"}]},{"title":"F33c.可转债","slug":"52.Financing/F33c.可转债","date":"2024-01-24T01:27:53.470Z","updated":"2024-01-24T01:27:53.471Z","comments":true,"path":"52.Financing/F33c.可转债/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F33c.可转债/","excerpt":"一文读懂可转债整理自： https://xueqiu.com/9842090891/111996583 1、什么是可转债可转债顾名思义可转换为股票的债券，首先它是债券，但是它可以在给定的条件内转换成股票。所以可转债由两种特性，一个是债券特性，一个是期权特性。也就是加上期权的债券，对于债券来说，这要公司不违约，债券都是保本的，但是由于附件了股票期权，所以可以把它看成可以保本的股票，当然这只是一个戏称。 基本上能发行可转债的公司，至少在发行年份以及之前都表现不差。我们看看《可转债公司债券管理暂时办法》对发行可转债上市公司的一些要求：","text":"一文读懂可转债整理自： https://xueqiu.com/9842090891/111996583 1、什么是可转债可转债顾名思义可转换为股票的债券，首先它是债券，但是它可以在给定的条件内转换成股票。所以可转债由两种特性，一个是债券特性，一个是期权特性。也就是加上期权的债券，对于债券来说，这要公司不违约，债券都是保本的，但是由于附件了股票期权，所以可以把它看成可以保本的股票，当然这只是一个戏称。 基本上能发行可转债的公司，至少在发行年份以及之前都表现不差。我们看看《可转债公司债券管理暂时办法》对发行可转债上市公司的一些要求： （1）最近连续三年盈利，且最近2年的净资产收益率平均在10%以上，部分行业可以略低。 （2）可转债发行后，公司资产负债率不高于70%； （3）累计债券余额不超过公司净资产的40%； （4）其他符合公开发行股票的条件等 从净资产收益率以及资产负债率基本上看，能够发行可转债的公司一般都不会太差，所以能够大概率（当然也存在可能发行期内公司经营出现严重问题，债券无法兑付）确保债券的兑付。 2、可转债的基础条款 几个重要的概念： （1）转股价：可转换债券为每股股票所支付的价格，转股的股价，相当于以多少价格买股票。 （2）转股价值：（面值/转股价）*现在股票的价格。我们这里看看100面值的蓝色光标的转股价值 ： （100/9.79）*5.50 = 56.18 （2018-08-10日收盘价是5.5）。什么意思呢，就是你将现在手上的债券转换成股票并卖出，那么现在的每100面值的债券，换成股票就只能卖到56.18 （3）转股溢价率：转股溢价率用来衡量债券现价和转股价之间的差距。其公式如下：转股溢价率= 可转债现价/转股价值-1。这里的蓝色光标的转股溢价率 ：88.596/56.18 – 1 = 57.7%。转股溢价率说明，以当前的价格买转债并转股卖出的亏损程度，如果你现在买入蓝标转债并转股卖出，那么现在肯定是亏损的，亏损比例为1-56.18/88.596。所以转股溢价率越高，说明其不适合现在转股，债券的债的价值更加明显。当溢价率接近0的时候说明此时的股性更加明显 （4）纯债价值：因为可转债是债上面附加了个期权，假设我们把这个期权给剔除掉。那么他这个债券值多少钱呢。众所周知计算一个债券的价值，需要考虑债券的现金流，以及利率（价格）。按照可转债合约上的情况，他的现金流已经确定了。但是他们的贴现利率我们并不知道，常规来说一般使用国债收益率来进行贴现。这里我们使用蓝色光标最近发的同等类型的债券的利率来进行贴现，16蓝标债5年期利率3.99%；18蓝色光标超短融利率8%。从两只债债券的收益率来看，目前资金的价格较为贵，所以这里我们按照18年对于蓝色光标的资金价格进行纯债价值的计算（从逻辑上说，长期借款的价格应该高于短融，所以这里按照8%的价格进行估计，纯债价值估计略高），其现金流的纯债价值为87.273。 （5）纯债溢价率：纯债溢价率= （可转换债市价-纯债价格）/纯债价格，这里蓝色光标的纯债溢价率为：（88.596-87.273）/87.273 = 1.52%。纯债溢价率表示什么意思呢？这个意思就是说明，此时的外挂在债权上的转股期权价值很小，或者说基本上大家都不会转股。 （6）回售触发价：在进行可转债设立时，为了保证投资者的利益，大部分的可转债都设有回售触发价。按照合约条款按照从2019年12月18日起，如果股票在任意连续30个交易日内的收盘价格低于当期转股价的70%，可转债持有人有权按照面值加上当期应计利息回售给发行人。此时的回售触发价为6.85.也就是说，如果2019年12月18日，股价连续30个交易没有到6.85,距离现在股价为25%的上升空间。结合纯债溢价率以及回售触发价，我们得到以9.79元来进行转股的期权价+ 若股价在2019年12月18日没有达到6.85的回售权= 88.596-87.273 = 1.3元 3、影响可转债的几个因素可转债作为一种外带期权的债券，其价值当然受到影响债券的因素以及影响股票的因素的影响。具体来说，影响债券收益率的包含，市场利率，期限、公司质地等；影响期权价格的为期限、行权价（转股价）、股价、股价波动率。 （1）影响债券价格的部分 期限：以来来说时间越长的债券，我们要的收益率越高，对应面值的债券的价格就越低； 市场利率：相应的现在整个市场的资金价格（利率）越高，对应面值的债券的价格就越低 公司质地：同样公司质地越不好我们借钱给他所需要的收益就越高，风险和收益成正比，对应的面值的债券的价格就越低 （2）影响期权价格的部分 期限：对于可转债这样一种美式期权，其行权时间越长，所对应的价格就越高 行权价：正股价- 行权价 约大，行权获取的收益就越高，所以期权价格就越高 股价波动率：波动率决定了能够达到行权价的概率，波动率越大期权价格越高。 4、可转债投资策略（1）债券投资：当纯债溢价率极低的时候，买入可转债就类似于买入收益相对于现在市场收益率相对客观的债券。另外加上一个很便宜的期权。所谓保本，还加上为了可能增加收益的权利。 （2）触发回售：当股价长期低迷的时候，触发的回售条款，这时我们获得了提前获取收益的机会。但是在一般情况下，公司为了避免支付一大笔钱，很可能会拉升股价，以不触发回售。 （3）套利：套利很容易理解，就是当转股溢价率产生明显偏差的时候，通过转股或者买债券进行套利 （4）对冲套：国外主流的采用Delta 对冲进行套利获取超额收益，由于计算Delta 计算比价复杂，这里就不介绍了 强赎、回售和下修","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"债券","slug":"债券","permalink":"https://beefyheisenberg.github.io/tags/债券/"},{"name":"可转债","slug":"可转债","permalink":"https://beefyheisenberg.github.io/tags/可转债/"}]},{"title":"F33b.美联储加息如何影响国债收益率","slug":"52.Financing/F33b.美联储加息如何影响国债收益率","date":"2024-01-24T01:27:53.466Z","updated":"2024-01-24T01:27:53.466Z","comments":true,"path":"52.Financing/F33b.美联储加息如何影响国债收益率/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F33b.美联储加息如何影响国债收益率/","excerpt":"@ref: 美联储加息如何影响美国利率（国债）期货市场？ - 雪球 根据债券的偿还期限不同，美国国债大致可分为短期国库券（T-Bills）、中期国库票据（T-Notes）和长期国库债券（T-Bonds）3类。尽管利率期货的种类很多，但是它们也有共同之处：一是利率期货会受美联储利率政策的影响，二是利率期货会受国债交易者本身影响。 短期国债的利率（收益率）是偏低的，而长期国债的利率（收益率）是偏高的。短期利率是由美联储控制的，而长期利率则是有长期国债的交易者决定的。正常情况下，无论是30天的短期利率还是30年的长期利率都是一条抛物线式的平滑曲线。 短期利率 是由美联储控制的，其典型代表是30天期的联邦基金利率（Fed Funds Rate，FFR），也被称为有效联邦基金利率（Effective Fed Funds Rate，EFFR）。联邦基金利率 是美国银行间同业拆借利率。美联储通过控制联邦基金利率来实现对经济的调控。联邦基金利率也被视为是基础利率，并且该利率是可被控制的最低利率。 长期利率 是由长期国债交易者决定的。长期利率的典型代表是30年期国债收益率（ the yield on the 30-year T-bonds）。一般而言，持有长期国债的投资者都希望获得更高的收益率。国债是可以流通的，可以被交易，交易者一般不会一直持有长期国债直到它到期，因而为了获取更高的收益率会在债券市场上买卖，市场买卖的力量会影响到国债的价格，从而影响到国债的收益率（国债的价格和其收益率成反比，国债价格越高，其收益率越低）。因而，那些30年期长期国债的持有者会通过买卖行为影响到长期利率。","text":"@ref: 美联储加息如何影响美国利率（国债）期货市场？ - 雪球 根据债券的偿还期限不同，美国国债大致可分为短期国库券（T-Bills）、中期国库票据（T-Notes）和长期国库债券（T-Bonds）3类。尽管利率期货的种类很多，但是它们也有共同之处：一是利率期货会受美联储利率政策的影响，二是利率期货会受国债交易者本身影响。 短期国债的利率（收益率）是偏低的，而长期国债的利率（收益率）是偏高的。短期利率是由美联储控制的，而长期利率则是有长期国债的交易者决定的。正常情况下，无论是30天的短期利率还是30年的长期利率都是一条抛物线式的平滑曲线。 短期利率 是由美联储控制的，其典型代表是30天期的联邦基金利率（Fed Funds Rate，FFR），也被称为有效联邦基金利率（Effective Fed Funds Rate，EFFR）。联邦基金利率 是美国银行间同业拆借利率。美联储通过控制联邦基金利率来实现对经济的调控。联邦基金利率也被视为是基础利率，并且该利率是可被控制的最低利率。 长期利率 是由长期国债交易者决定的。长期利率的典型代表是30年期国债收益率（ the yield on the 30-year T-bonds）。一般而言，持有长期国债的投资者都希望获得更高的收益率。国债是可以流通的，可以被交易，交易者一般不会一直持有长期国债直到它到期，因而为了获取更高的收益率会在债券市场上买卖，市场买卖的力量会影响到国债的价格，从而影响到国债的收益率（国债的价格和其收益率成反比，国债价格越高，其收益率越低）。因而，那些30年期长期国债的持有者会通过买卖行为影响到长期利率。 一些人认为，只要美联储加息，所有期限的收益率（利率）曲线都会上升，这种说法是错的。加息只会影响到短期利率 // 关于美联储如何通过 FFR影响短期利率，参考： F22.宏观调控手段（美联储） 长期国债收益率的决定因素是国债交易者对经济的看法，而并不是中央银行的货币政策。，当一国的经济政治状况良好时，长期利率的很稳定，但是当 一国经济糟糕或者政治不稳定时，投资者就会卖出长期国债，从而推高国债收益率，反过来就会增加该国的借贷成本 举例：在美国总统大选竞选阶段时，特朗普承诺会实施一万亿美元的财政刺激计划，这意味着，若特朗普胜选，特朗普政府为了支付庞大的财政支出必须得背上更多的债务。由于美国政府的债务已经临近历史高位，投资者开始抛售长期国债，从而推升了国债收益率。特朗普胜选后，美国30年期国债收益急速走升，自2.6%快速涨至3.15% 美联储加息时，一些重要的利率期货合约如何反应： 30天联邦基金利率期货对美联储加息政策反应最为强烈 … 你可以根据30天期联邦基金利率期货来预测美联储何时加息。纽约联储主席杜德利之前谈到过：“如果你正在观察联邦基金利率的期货市场，那么你看到的就是我们想达到的目标…” 10年期国债期货很有意思，因为它处于利率区间的中部，如果你真的想了解利率的走势，那么选择10年期国债期货应该是最合适的，因为10年期的国债在短期收益率和长期收益率之间达到了一个平衡状态。当美联储加息时，10年期国债期货的反应并不会像30天期联邦基金利率期货一样那么明显，当然，当美联储加息时，10年期国债期货价格就是下跌，因为10年期国债利率上升，反之亦然。另一个需考虑的因素是，10年期国债也是一种避险资产，当政治经济不确定性因素存在时，避险资金就会涌入购买国债，10年期国债期货价格就是上升，尤其是外部风险产生时。 30年期长期国债期货：长期国债期货的表现和中期国债期货很相似，但同时，美联储加息对长期国债期货的影响力更加小。30年期国债市场是对交易者开放的，因而，交易者对美国政府偿债能力的看法就成为了影响其价格的重要因素。 @link F33a.长端利率vs短端利率","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"美联储","slug":"美联储","permalink":"https://beefyheisenberg.github.io/tags/美联储/"},{"name":"国债","slug":"国债","permalink":"https://beefyheisenberg.github.io/tags/国债/"},{"name":"收益率","slug":"收益率","permalink":"https://beefyheisenberg.github.io/tags/收益率/"}]},{"title":"F33a.长端利率vs短端利率","slug":"52.Financing/F33a.长端利率vs短端利率","date":"2024-01-24T01:27:53.460Z","updated":"2024-01-24T01:27:53.461Z","comments":true,"path":"52.Financing/F33a.长端利率vs短端利率/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F33a.长端利率vs短端利率/","excerpt":"一、利率的三大决定因素：供给端、政策端与需求端 （一）期限利差与信用利差是宏观研究中最为关注的两类分析视角，前者可被视为短期限资产与长期限资产之间的市场定价差异（时间维度），后者则可被视为无风险资产与风险资产之间的市场定价差异（资产维度）。 （二）长端利率主要由诸多短端利率的滚动加权平均水平决定。特别是当将每一段期限划分的足够短时，长端利率便可被视为短端利率的时点极限，从这个角度来说，能够影响短端利率水平的因素也必然会影响到长端。 （三）事实上对期限结构的研究有一些理论可供借鉴，如传统的市场预期理论（如流动性偏好、市场分割理论、优先偏好理论等）以及现代的不确定性理论（需要借助于静态或动态模型）等。不过除供给端与政策端外，长端利率的走势还取决于市场对未来经济基本面的预期、风险偏好变化的预期以及流动性情况的改变等各种因素。 （四）整体来看，利率的影响因素可以分为需求端、政策端和供给端三个部分，其中供给端以及政策端主要有通过影响短端利率水平来间接影响长端利率水平，而需求端则是长端利率水平的最重要决定因素。 （五）供给端的冲击具有短期化、稳定性与可预测性差以及突发性高等特征，其对市场的冲击往往呈现“来无影、去无踪”的典型特征，主要包括疫情、大宗商品价格震荡、地缘政治、中美贸易摩擦、股债跷跷板以及债券供给等。 （六）政策端的冲击则具有短周期性、反复性与复杂性等特征，主要包括监管政策、政府行为以及宏观经济政策等。 1、通常情况下当内外形势压力趋于加大时，意味着宏观经济政策将更加有攻击性和针对性，也即货币政策趋松、财政政策趋向积极，前者易导致利率下行、后者则容易导致利率上行。而在宏观经济政策的助力下，供给层面可能率先出现企稳回暖的假象（持续性尚存在不确定性），从而对债市造成冲击。 2、监管政策的影响同样不可忽略，这在中国的债市分析框架中尤其需要给予关注。一般情况下监管政策通常会呈现强制性、针对性和倾斜性两个特征，并造成债市出现流动性分层和信用分层两个层面的问题，从而对债市形成冲击，2013年的钱荒与2017年的严监管便是一个很好的例证。 （七）需求端冲击主要体现在经济基本面，既包括人口、劳动生产率、技术等韧性与趋势特征较为明显的长期因素，也包括社融与高频指标等先验特征较为明显的短期因素。某种程度上说，经济基本面对长端利率水平的决定力量更大，且无论政策层面与供给层面如何变化，需求端的趋势性一旦形成，将很难被改变，当然这种趋势性也会因为政策层面与供给层面的冲击而有所起伏。 二、经济基本面如何决定长端利率？ （一）逻辑基础：利率可以被理解为资本的边际产出 1、利率、汇率、通胀水平、工资等常用经济金融术语的本质均是一种价格，如工资是劳动的价格、通胀是生活资料和生产资料的价格、汇率是人民币资产的价格，而利率则可视为是资本的价格。 2、从这个角度来看，我们可以将利率视为资本的边际产出，也即当利率较高时，意味着资本的边际产出通常较高，此时资本往往处于稀缺状态，反则反之。 （二）现实印证：经济发展水平越高的经济体，资本越过剩、利率往往越低 （三）人口增长率、技术进步率、储蓄转化率等因素决定长端利率走向 （四）主要结论：人口增长率、技术进步率与长端利率水平正相关","text":"一、利率的三大决定因素：供给端、政策端与需求端 （一）期限利差与信用利差是宏观研究中最为关注的两类分析视角，前者可被视为短期限资产与长期限资产之间的市场定价差异（时间维度），后者则可被视为无风险资产与风险资产之间的市场定价差异（资产维度）。 （二）长端利率主要由诸多短端利率的滚动加权平均水平决定。特别是当将每一段期限划分的足够短时，长端利率便可被视为短端利率的时点极限，从这个角度来说，能够影响短端利率水平的因素也必然会影响到长端。 （三）事实上对期限结构的研究有一些理论可供借鉴，如传统的市场预期理论（如流动性偏好、市场分割理论、优先偏好理论等）以及现代的不确定性理论（需要借助于静态或动态模型）等。不过除供给端与政策端外，长端利率的走势还取决于市场对未来经济基本面的预期、风险偏好变化的预期以及流动性情况的改变等各种因素。 （四）整体来看，利率的影响因素可以分为需求端、政策端和供给端三个部分，其中供给端以及政策端主要有通过影响短端利率水平来间接影响长端利率水平，而需求端则是长端利率水平的最重要决定因素。 （五）供给端的冲击具有短期化、稳定性与可预测性差以及突发性高等特征，其对市场的冲击往往呈现“来无影、去无踪”的典型特征，主要包括疫情、大宗商品价格震荡、地缘政治、中美贸易摩擦、股债跷跷板以及债券供给等。 （六）政策端的冲击则具有短周期性、反复性与复杂性等特征，主要包括监管政策、政府行为以及宏观经济政策等。 1、通常情况下当内外形势压力趋于加大时，意味着宏观经济政策将更加有攻击性和针对性，也即货币政策趋松、财政政策趋向积极，前者易导致利率下行、后者则容易导致利率上行。而在宏观经济政策的助力下，供给层面可能率先出现企稳回暖的假象（持续性尚存在不确定性），从而对债市造成冲击。 2、监管政策的影响同样不可忽略，这在中国的债市分析框架中尤其需要给予关注。一般情况下监管政策通常会呈现强制性、针对性和倾斜性两个特征，并造成债市出现流动性分层和信用分层两个层面的问题，从而对债市形成冲击，2013年的钱荒与2017年的严监管便是一个很好的例证。 （七）需求端冲击主要体现在经济基本面，既包括人口、劳动生产率、技术等韧性与趋势特征较为明显的长期因素，也包括社融与高频指标等先验特征较为明显的短期因素。某种程度上说，经济基本面对长端利率水平的决定力量更大，且无论政策层面与供给层面如何变化，需求端的趋势性一旦形成，将很难被改变，当然这种趋势性也会因为政策层面与供给层面的冲击而有所起伏。 二、经济基本面如何决定长端利率？ （一）逻辑基础：利率可以被理解为资本的边际产出 1、利率、汇率、通胀水平、工资等常用经济金融术语的本质均是一种价格，如工资是劳动的价格、通胀是生活资料和生产资料的价格、汇率是人民币资产的价格，而利率则可视为是资本的价格。 2、从这个角度来看，我们可以将利率视为资本的边际产出，也即当利率较高时，意味着资本的边际产出通常较高，此时资本往往处于稀缺状态，反则反之。 （二）现实印证：经济发展水平越高的经济体，资本越过剩、利率往往越低 （三）人口增长率、技术进步率、储蓄转化率等因素决定长端利率走向 （四）主要结论：人口增长率、技术进步率与长端利率水平正相关 三、中国的自然利率当然处于什么水平？自然利率，亦称中性利率，一直是美联储货币政策的隐含参考指标，即联邦基金利率的潜在目标。所谓中性利率，是经济既不过热、亦不过冷下的利率水平，即刚刚好的利率水平，某种程度上可以将其理解为经济在稳态增长率下的通胀水平。目前来看美联储将其设定在2%左右的水平。 按照前面所讨论的，自然利率也可以被理解为经济稳态增长下资本的边际产出，从这个角度看，$$自然利率=（人口增长率+技术进步率+折旧率）/储蓄转化率 $$ 目前中国的名义自然利率在4-5%左右 2021年6月，国际清算银行公布的工作论文“中国的自然利率”（央行货币政策司司长孙国锋联合撰写）指出“中国的自然实际利率在1995-2010年期间平均为3-5%，随后逐步降至2019年底的2%以上……如果假设通胀率为2-3%，则意味着目前对应的自然名义利率应在4-5%之间”。 4-5%的名义自然利率毕竟是现状，自然利率在未来如何演变还需要通过更有效观察人口、技术进步、金融等其它因素的变化来推断，但是从目前大部分经济体的实践来看，自然利率趋势性下降是全球普遍现象，这可能是因为全球经济增长中枢水平在不断下移（如美国10年期国债收益率的中枢水平这三十年来呈现出趋势下移的特征），中国也不会例外（虽然目前并不明显）。如果技术进步和人口增长没有出现明显变化，那么自然利率水平的下降趋势仍将持续。","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"债券","slug":"债券","permalink":"https://beefyheisenberg.github.io/tags/债券/"},{"name":"利率","slug":"利率","permalink":"https://beefyheisenberg.github.io/tags/利率/"}]},{"title":"F33.特别国债回顾","slug":"52.Financing/F33.特别国债回顾","date":"2024-01-24T01:27:53.456Z","updated":"2024-01-24T01:27:53.456Z","comments":true,"path":"52.Financing/F33.特别国债回顾/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F33.特别国债回顾/","excerpt":"特别国债有何特别之处？从资金用途看，特别国债通常是为服务特定政策、支持特定项目、解决特殊问题而发行。从发行流程看，特别国债发行流程与普通国债相比更加简单灵活，从人大常委会审议到财政部发行一般需经历1-6个月。从预算管理看，特别国债纳入债务余额管理，但不列入预算赤字。此前共有3次特别国债发行（不含续发），分别在1998年、2007年和2020年。 ① 1998.8：发行特别国债补充国有银行资本金。8月财政部面向工商银行、农业银行等四大行定向发行2700 亿元特别国债。这次特别国债全为定向发行，从人大常委会通过议案到财政部发行特别国债期间历时6个月，所筹资金全部用于补充四大行资本金。 ② 2007.8：发行特别国债用于加强外汇储备管理，同时缓解流动性过剩和通胀压力。这次特别国债发行历时2个月，主要为定向发行（1.35万亿元），用于购买外汇建立中投公司从事外汇资金投资管理业务，其余公开发行的2000亿元实现间接回收市场流动性。 ③ 2020.3：发行抗Yi特别国债，以应对YQ对宏观经济的冲击。20年6-7月财政部发行4期抗疫特别国债、共计1万亿元，主要用于保就业、保基本民生、保市场主体，包括支持减税降费、减租降息、扩大消费和投资等。 其中第②次发行的1.35万亿元，分两部分到期：","text":"特别国债有何特别之处？从资金用途看，特别国债通常是为服务特定政策、支持特定项目、解决特殊问题而发行。从发行流程看，特别国债发行流程与普通国债相比更加简单灵活，从人大常委会审议到财政部发行一般需经历1-6个月。从预算管理看，特别国债纳入债务余额管理，但不列入预算赤字。此前共有3次特别国债发行（不含续发），分别在1998年、2007年和2020年。 ① 1998.8：发行特别国债补充国有银行资本金。8月财政部面向工商银行、农业银行等四大行定向发行2700 亿元特别国债。这次特别国债全为定向发行，从人大常委会通过议案到财政部发行特别国债期间历时6个月，所筹资金全部用于补充四大行资本金。 ② 2007.8：发行特别国债用于加强外汇储备管理，同时缓解流动性过剩和通胀压力。这次特别国债发行历时2个月，主要为定向发行（1.35万亿元），用于购买外汇建立中投公司从事外汇资金投资管理业务，其余公开发行的2000亿元实现间接回收市场流动性。 ③ 2020.3：发行抗Yi特别国债，以应对YQ对宏观经济的冲击。20年6-7月财政部发行4期抗疫特别国债、共计1万亿元，主要用于保就业、保基本民生、保市场主体，包括支持减税降费、减租降息、扩大消费和投资等。 其中第②次发行的1.35万亿元，分两部分到期： 2017年8月 到期并接续6000亿，发行结果为7年期4000亿、10年期规模为2000亿。 2022年12月 到期并接续7500亿，此次续发期限为3年，期限明显缩短。 对债市影响：首发有冲击，续发影响小 2022续发7500亿国债用途猜想： 1）用途或以抗疫、基建为主，消费补贴也有可能。今年与2020年较为相似，特殊目的或仍在于抗疫和对冲疫情对经济的影响，故参考2020年，抗疫和基建是特别国债的主要用途。此外，今年4月失业率已处于6.1%的历史第二个高的水平且消费需求弱，特别国债或部分用于相关补贴性支出等 2）宣布发行特别国债时或对债市产生一定影响，发行时对债市的影响或可控，中期来看，特别国债的发行有利于经济修复加快，或将利空债市。 海通：特别国债增发的历史回顾与展望.pdf","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[]},{"title":"F33.债券","slug":"52.Financing/F33.债券","date":"2024-01-24T01:27:53.451Z","updated":"2024-01-24T01:27:53.452Z","comments":true,"path":"52.Financing/F33.债券/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F33.债券/","excerpt":"信用债 vs 利率债 利率债：财政部发行的国债；地方政府委托财政部发行的地方政府债（当然现在14年开始地方政府自发自还试点了）；三家政策性银行（国开、农行、进出口）发行的政策性金融债；铁道债（政府支持机构债）；央行票据等。 信用债：企业债和公司债；普通金融债（包括商业银行和非银金融机构发行的债券）；次级债和混合资本债（一般为商业银行为满足巴塞尔协议要求发行的）；交易商协会主导的一些企业债务融资工具，包括 短融、超短融、中票等（CP SCP MTN），城投债也属于信用债。 政金债就是政策性金融机构发行的债券，在中国，政策性金融机构只有3家：国家开发银行、中国农业发展银行、中国进出口银行。它们执行国家政策，信用比普通商业银行高得多，所以它们发行的债券也被称为“准国债”。 由分类可以看出两者的区别：","text":"信用债 vs 利率债 利率债：财政部发行的国债；地方政府委托财政部发行的地方政府债（当然现在14年开始地方政府自发自还试点了）；三家政策性银行（国开、农行、进出口）发行的政策性金融债；铁道债（政府支持机构债）；央行票据等。 信用债：企业债和公司债；普通金融债（包括商业银行和非银金融机构发行的债券）；次级债和混合资本债（一般为商业银行为满足巴塞尔协议要求发行的）；交易商协会主导的一些企业债务融资工具，包括 短融、超短融、中票等（CP SCP MTN），城投债也属于信用债。 政金债就是政策性金融机构发行的债券，在中国，政策性金融机构只有3家：国家开发银行、中国农业发展银行、中国进出口银行。它们执行国家政策，信用比普通商业银行高得多，所以它们发行的债券也被称为“准国债”。 由分类可以看出两者的区别： 利率债的兑付有国家或政府信用背书，一般认为没有违约风险，极特殊情况可能会有技术性违约。利率债主要受利率变动影响，包括长短期利率，宏观经济运行情况，通胀率，流通中的货币量等。 信用债的兑付依赖企业经营情况，如果企业经营不善，将面临本金不能按时足额兑付的风险。由于信用风险的存在，因此信用债必须有信用风险补偿。信用风险补偿的幅度跟发行人所处行业，股权情况，经营情况等密切相关，总的来说，经营情况好的企业容易以低利率发行债券，经营情况差的企业只能接受更高的融资成本。 目前，国内信用风险没有有效的定价，城投强于国企强于民企外企，产能过剩弱于其他债券，投资者只是在这种大框架下面凭借刚兑信仰投资信用债，踩到雷就是运气不好，没有几个人真正去关注发行人实际运营情况，真正选择优质信用去投资。 信用债比利率债在二级市场上面临更大的流动性风险。首先表现在回购再融资上，质押利率债可以轻松地在市场上进行回购融资，而信用债难度要大不少，如果是资质较差的信用债则非常难。其次，在市场持续下跌过程中，利率债如果要止损可以轻松找到对手盘，而信用债则非常难止损，市场流动性风险更大，真要止损也要承受比利率债大的多的亏损幅度。 在二级市场上利率债和信用债区别也非常明显，关键期限新发利率债的流动性非常好，参与交易的机构多，全天持续有买卖盘，买卖价差很小，价格透明，一般全天成交多笔。信用债一般都是一两家卖盘先报价，有感兴趣的买盘再报买价，一张债券的交易参与机构一般不多于四家，买卖价差较大，全天成交少有时买卖盘会僵持一整天，有成交时一般一家卖盘出完货该券就不再有报价和交易了。利率债和信用债的市场走势是高度相关的，一般来说，信用债走势会滞后于利率债，但是波动幅度会大于利率债。在熊市转牛市时，利率债收益率先开始下行，趋势即将形成时，信用债跟随开始下行，但幅度来说信用债要大得多，牛市转熊市也类似。 @ref: https://www.zhihu.com/question/38236720/answer/98192585 国内债券市场关注几个指标：债券市场余额、存量、新发、成交额 https://baijiahao.baidu.com/s?id=1705988824243204991利率债和信用债构成了目前120.8万亿的债券市场，其中利率债大约有80.14万亿，主要由国债、地方债、央票、同业存单和政策性金融债构成；信用债大约有40.66万亿，主要由发改委、证监会、协会，以及人行和银保监主管的金融债相关产品构成。 ➤ 信用债构成: 1、金融债： 广义的金融债可以理解为金融机构发行的债券，其中具备代表性的有银行、证券和保险等，此类债券主要由一般金融债券和补充资本为主的次级债券构成。目前信用类金融债存量规模大约有9.46万亿，占整个信用债的比重为23.27%。 证券公司短期融资券发行规模相对较少，之前申报流程相对复杂，目前虽然有一定优化，但是基于目前已经可以发行短期公司债，替代性很强，这个品种的地位预计会越来越较低。 其他金融机构主要是指满足金融债要求的其他发行主体，如：租赁、财务公司、消费金融公司等。 2、企业债： 企业债作为发改委主管的债券品种，以强悍的兑付能力享誉市场。在经历2016的巅峰之后，近年来，企业债存量规模持续下行，从2016年末的3.27万亿，下降到目前的2.23万亿，下降幅度比较明显。 3、公司债： 自2015年初，公司债改制以来，公司债呈现持续、快速上升的态势，虽然去年末至今，公司债政策出现收紧的趋势，但是其存量规模依然处于较高的位置。截止2021年6月30日，公司债存量规模达到9.40万亿，与金融债体量相当，其中公募公司债和私募公司债基本各占半壁江山。 4、中票、短融和PPN： 作为协会主要的信用债品种，基本可以和公司债的相关品种一一匹配，其中中票和短融可以对应公募公司债，而PPN则和私募公司债相对应。一直以来，协会产品在信用债市场占据中流砥柱的作用，笔者以为这主要和我国金融体系以银行为中心有关。截止2021年6月30日，上述三个品种累计存量达到12.20万亿，占整个信用债存量的30%。 华泰期货：中国债券市场结构介绍.pdf截至2019年12月29日，中国债券市场余额达到96.96万目前利率总存量为53.51万亿元，较年初增加6.16万亿，利率债市场仍然是目前国内最大的债券市场；信用债存量为32.83万亿元，较年初增加4.3万亿；同业存单数量为10.62万亿元，较年初增加0.74万亿元。 2020年金融市场运行情况 .pdf：2020年，国债发行7万亿元，地方政府债券发行6.4万亿元，金融债券发行9.3万亿元，政府支持机构债券发行3580亿元，资产支持证券发行2.3万亿元，同业存单发行19万亿元，公司信用类债券发行12.2万亿元 2020年，债券市场现券交易量253万亿元，同比增长16.5%。其中，银行间债券市场现券交易量232.8万亿元，日均成交9350.4亿元，同比增长12%。交易所债券市场现券成交20.2万亿元，日均成交830.4亿元，同比增长142.6% 股票市场：两市全年成交额206.83万亿元，同比增长62.3%， 债券收益率 vs 票面利率债券收益率和债券价格是负相关的： 比如，一个十年期国债产品，票面价格是100元，发行时确定的票面利率是3.5%，每半年兑付一次利息。如果在国债交易市场上该产品的交易价格是90元，则买到该国债产品的持有人每年获得的收益就不是3.5%，而是3.5÷90×100%=3.89%。当然我们在英为财情等平台看到的实时国债收益率，它的计算方法（贴现率）比这个复杂，我们只需要了解这个道理就行了。 票面利率（Coupon rate）： 票面利率是指发行债券时规定应付的并直接印刷在债券票面上的利率，表示每年应付的利息额与债券面额之比。票面利率的高低直接影响着证券发行人的筹资成本和投资者的投资收益，一般是证券发行人根据债券本身的情况和对市场条件分析决定的。债券的付息方式是指发行人在债券的有效期间内，向债券持有者分批支付利息的方式，债券的付息方式也影响投资者的收益。 票面利率固定的债券通常每年或每半年付息一次。Coupon亦指息票，即附于债券上，供持有人支取利息的凭证。 企业债券必须载明债券的票面利率。票面利率的高低在某种程度上不仅表明了企业债券发行人的经济实力和潜力，也是能否对购买的公众形成足够的吸引力的因素之一。 债券的票面利率越低，债券价格的易变性也就越大。在市场利率提高的时候，票面利率较低的债券的价格下降较快。但是，当市场利率下降时，它们增值的潜力较大。如果一种附息债券的市场价格等于其面值，则到期收益率等于其票面利率；如果债券的市场价格低于其面值（当债券贴水出售时），则债券的到期收益率高于票面利率。反之，如果债券的市场价格高于其面值（债券以升水出售时），则债券的到期收益率低于票面利率。总之，债券价格、到期收益率与票面利率之间的关系可作如下概括： 票面利率＜到期收益率－债券价格＜票面价值 票面利率=到期收益率－债券价格=票面价值 票面利率＞到期收益率－债券价格＞票面价值 国债➤ 十年期国债收益率是各类资产估值的锚: 资产从大类来讲有房产、股票（权益）、债券、商品、黄金、现金，等等。逐利是资本的本性，另一方面资本随时在寻找价值（估值）洼地。所以我们创造了一个又一个的估值指标：房地产的投资价值用“租售比”衡量；股票有大家熟知的市盈率、市净率、市销率、巴菲特指标；商品、黄金有“金油比”、“金银比”等等。但所有这些估值都绕不开一个指标：十年期国债收益率。它代表着市场无风险收益率，是各种资产估值的“锚”。 ➤ GDP增速 和 国债收益率：如果我国GDP增速维持在6-6.5%的水平，十年期国债收益率就会围绕3.25%左右中值上下波动 国债收益率在资产配置中的使用➤ 如果投资债券基金, 如何根据十年国债收益率调整 短/中/长期债券的配比? 投资债券基金只在两种极端情况下有比较高的确定性：十年期国债收益率向上偏离接近4%，和向下偏离接近2.5%。 向上接近4%时，逐步调升债券基金的久期，增加长久期的债券基金比例； 向下接近2.5%时，做反向操作，调降债券基金久期。 为什么这样做呢？ 久期越长的债券基金，在利率（收益率）下降过程中涨幅越大，同样，在利率（收益率）上升过程中跌幅也越大，理论上在利率开始震荡见底时，债券价格（为什么是久期长的债券涨幅更大？） ➤ 如果投资股票, 如何根据十年国债收益率调整仓位? 针对股市估值，最著名的估值模型就是 股权风险溢价 ERP（Equity Risk Premium）了。根据这个模型，有两个公式（PE为全部A股市盈率，r为十年期国债收益率）： （1）股权风险溢价（股债收益差）越低，性价比越低, 考虑卖出股票（这往往出现在股市高点）$$ 股权风险溢价 = 盈利收益率 - 市场无风险收益率 = 1/PE - r $$ （2）股债收益比：$$ 股债比 = 盈利收益率 ÷ 市场无风险收益率 = 1/PE ÷ r $$ 地方债「地方债」是怎么运转的？ - 知乎 地方债的产生：因为分税制改革后地方政府事权财权不匹配产生了资金缺口，而修订前的预算法又不允许地方政府借债，使得地方政府不得不通过其他方式变相举债。而债务的主要用途其实就是用于建设政府所承担的公共服务资金支出。比如城市供水、供电、垃圾处理还包括一些项目建设，比如机场、路桥、甚至包括公园等等公共服务的建设资金。 目前地方债的情况：目前地方债全部是省级地方政府通过债券市场发行的，而且自主承担偿还责任，这就是所谓的自发自还。这些地方债包括两个用途，一是置换，二是新增。所谓置换，就是借新还旧。地方政府在2013-14年集中统计上报了一次政府债务的存量数据，这些债务随着时间的推移会逐渐到期，需要还本付息，然而地方政府财力有限，无法完成，那怎么办呢？置换，通过发行新的地方债来还老的地方债，债务问题就可以得到暂时的解决。 短融短期融资券(Commercial Paper, CP)，是指具有法人资格的非金融企业在银行间债券市场发行的，约定在1年内还本付息的债务融资债券，是一种流动性较高、风险较低的债券，所以从风险收益特征上看，这只基金有点像短债产品，风险收益介于货币基金与普通债券型基金之间。","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"债券","slug":"债券","permalink":"https://beefyheisenberg.github.io/tags/债券/"},{"name":"国债","slug":"国债","permalink":"https://beefyheisenberg.github.io/tags/国债/"},{"name":"信用债","slug":"信用债","permalink":"https://beefyheisenberg.github.io/tags/信用债/"},{"name":"利率债","slug":"利率债","permalink":"https://beefyheisenberg.github.io/tags/利率债/"}]},{"title":"F32h1.SmartBeta-神奇公式","slug":"52.Financing/F32h1.SmartBeta-神奇公式","date":"2024-01-24T01:27:53.447Z","updated":"2024-01-24T01:27:53.448Z","comments":true,"path":"52.Financing/F32h1.SmartBeta-神奇公式/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F32h1.SmartBeta-神奇公式/","excerpt":"神奇公式来源于美国天才投资大师乔尔·格林布拉特所著的《股市稳赚》，从1988年到2004年的17年间，平均年化收益为22.9%，同期的标普500年平均回报率为12.4%；另一种收益较高的回测，平均年化收益高达30.8%，令人印象深刻 神奇公式深受追捧的深层原因，在于它在全球股票市场中的普遍适用性，以及具备适合计算机进行基于基本面数据的量化投资的特点。概括起来有三点：长期有效、普遍适用、适合量化。神奇公式的基本原则就是挑选又好又便宜的公司，低价买入好企业。 神奇公式的表述形式是： $$资本收益率 = 息税前利润 /（净营运资本 + 固定资产）$$ $$股票收益率 = 息税前利润 / 企业价值 ( 企业价值=市值+净有息债务 )$$","text":"神奇公式来源于美国天才投资大师乔尔·格林布拉特所著的《股市稳赚》，从1988年到2004年的17年间，平均年化收益为22.9%，同期的标普500年平均回报率为12.4%；另一种收益较高的回测，平均年化收益高达30.8%，令人印象深刻 神奇公式深受追捧的深层原因，在于它在全球股票市场中的普遍适用性，以及具备适合计算机进行基于基本面数据的量化投资的特点。概括起来有三点：长期有效、普遍适用、适合量化。神奇公式的基本原则就是挑选又好又便宜的公司，低价买入好企业。 神奇公式的表述形式是： $$资本收益率 = 息税前利润 /（净营运资本 + 固定资产）$$ $$股票收益率 = 息税前利润 / 企业价值 ( 企业价值=市值+净有息债务 )$$ 资本收益率体现了公司对于资产的运用和经营能力，资本收益率好的企业一般处于行业的领先地位或是增长性行业中，因此采用资本收益率可以衡量公司的经营和盈利能力。 股票收益率体现了公司的估值情况，高的股票收益率意味着较高的升值潜力。股票价值被低估时，股票收益率就会上升，此时的潜在升值机会就会变大 中国版神奇公式：中证价值回报量化策略指数（930949） 中证价值回报量化策略指数由中邮创业基金管理股份有限公司定制开发，基于价值投资理念，选取投资回报率高且估值相对较低的上市公司股票作为样本股 样本空间：中证价值回报量化策略指数的样本空间由满足以下条件的沪深A股构成 （1）非ST、*ST股票，非暂停上市股票； （2）非金融类股票。 选样方法： （1）根据上市公司最新财务报告的合并报表数据，对样本空间提取或计算如下财务数据：应收票据及应收账款、其他应收款（合计）、预付账款、存货、无息流动负债、固定资产（合计）、其他权益工具、带息债务、少数股东权益、总市值，并对数据缺失的股票进行处理； （2）根据上述财务数据计算资本收益率（ROC）和股票收益率（EY）： ROC = EBIT /（净营运资本 + 固定资产（合计）），其中，EBIT 为息税前利润，采用过去半年滚动形式计算；净营运资本=应收票据及应收账款+其他应收款（合计）+预付账款+存货-无息流动负债 EY = EBIT /（总市值 + 带息负债 + 其他权益工具 + 少数股东权益） （3）对上述两个指标按如下规则进行排序： 先对 ROC 的倒数进行升序排列，再对其中为负的部分进行降序排列，得到每只股票的 ROC 排名； 对 EY 进行降序排列，得到每只股票的 EY 排名； 对 ROC 排名和 EY 排名之和进行升序排列，得到最后的综合排名；选取综合排名前 80 的股票构成中证价值回报量化策略指数样本股。 指数计算采用等权重方式 跟踪930949指数的基金有一只：中邮中证价值回报量化策略A（006255），但2021年清盘了 -。- 没跑赢沪深300","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"SmartBeta","slug":"SmartBeta","permalink":"https://beefyheisenberg.github.io/tags/SmartBeta/"},{"name":"神奇公式","slug":"神奇公式","permalink":"https://beefyheisenberg.github.io/tags/神奇公式/"}]},{"title":"F32h.指数基金SmartBeta策略","slug":"52.Financing/F32h.指数基金SmartBeta策略","date":"2024-01-24T01:27:53.444Z","updated":"2024-01-24T01:27:53.444Z","comments":true,"path":"52.Financing/F32h.指数基金SmartBeta策略/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F32h.指数基金SmartBeta策略/","excerpt":"@tag: #基金 #ETF Smart Beta 策略常见因子： 质量因子：通过企业基本面筛选优质的成份股，倾向于选择具有稳定收入和盈利能力的公司，常见的质量因子包括净资产收益率、总资产收益率等。 成长因子：侧重公司未来的盈利，选择中长期业绩增长较快的公司进行投资，可以使用营业收入增长率、净利润增长率等指标。成长因子是进攻之王，在流动性宽松、估值扩张这样的环境下往往表现优异。 价值因子：以一系列指标衡量公司股价是否相对其价值低估，常见的价值因子相关指标包括市净率、市现率、市销率等。 红利因子：主要以股息率为选股标准，目的在于选取分红较高的股票。红利因子可以获得超额收益的逻辑在于，分红的基础是盈利，而高分红的基础是高的累计盈余，这些体现的是一个企业良好的经营状况。 低波动因子：通过降低波动率，倾向于选择成熟的公司，这类公司往往表现出更好的风险调整收益。 值得注意的是，红利因子的使用最为久远。长年稳定分红的公司，盈利能力和财务状况都比较好，是成熟的机构投资者最喜欢的标的。当市场处于熊市时，分红率高的公司一般被视为防御属性标的，相对表现会更为稳健；当市场处于牛市时，随着股价的上涨，股票的股息率就会减少，股息率低的股票会自动剔除出组合，因此，在市场上涨的过程中，红利因子往往也表现不错。 因子策略既可单独使用，即单因子策略，也可组合使用，形成多因子策略。随着市场的发展和研究的深入，因子策略仍在不断完善。近年来，越来越多的Smart Beta指数是以复合因子来实现，比如质量因子和价值因子混搭的复合策略，比如红利因子与低波动因子混搭的复合策略，中证东方红红利低波动指数(简称：东证红利低波，代码931446)就是具有复合策略的Smart Beta指数，值得关注。","text":"@tag: #基金 #ETF Smart Beta 策略常见因子： 质量因子：通过企业基本面筛选优质的成份股，倾向于选择具有稳定收入和盈利能力的公司，常见的质量因子包括净资产收益率、总资产收益率等。 成长因子：侧重公司未来的盈利，选择中长期业绩增长较快的公司进行投资，可以使用营业收入增长率、净利润增长率等指标。成长因子是进攻之王，在流动性宽松、估值扩张这样的环境下往往表现优异。 价值因子：以一系列指标衡量公司股价是否相对其价值低估，常见的价值因子相关指标包括市净率、市现率、市销率等。 红利因子：主要以股息率为选股标准，目的在于选取分红较高的股票。红利因子可以获得超额收益的逻辑在于，分红的基础是盈利，而高分红的基础是高的累计盈余，这些体现的是一个企业良好的经营状况。 低波动因子：通过降低波动率，倾向于选择成熟的公司，这类公司往往表现出更好的风险调整收益。 值得注意的是，红利因子的使用最为久远。长年稳定分红的公司，盈利能力和财务状况都比较好，是成熟的机构投资者最喜欢的标的。当市场处于熊市时，分红率高的公司一般被视为防御属性标的，相对表现会更为稳健；当市场处于牛市时，随着股价的上涨，股票的股息率就会减少，股息率低的股票会自动剔除出组合，因此，在市场上涨的过程中，红利因子往往也表现不错。 因子策略既可单独使用，即单因子策略，也可组合使用，形成多因子策略。随着市场的发展和研究的深入，因子策略仍在不断完善。近年来，越来越多的Smart Beta指数是以复合因子来实现，比如质量因子和价值因子混搭的复合策略，比如红利因子与低波动因子混搭的复合策略，中证东方红红利低波动指数(简称：东证红利低波，代码931446)就是具有复合策略的Smart Beta指数，值得关注。 Smart Beta指数基金让投资者了解可能提供超额回报的源头，并且让投资者能够以比较方便的途径去进行投资，获得这些因子回报。 系列： Smart beta策略研究和指数基金分析 Smart beta策略研究和指数基金分析①——价值(低估值) Smart beta策略研究和指数基金分析②——质量(高ROE) Smart beta策略研究和指数基金分析③——红利 Smart beta策略研究和指数基金分析④——低波动 Smart beta策略研究和指数基金分析⑤——成长 Smart beta策略研究和指数基金分析⑥——动量 Smart beta策略研究和指数基金分析⑦——市值（规模&amp;大小盘） Smart beta策略研究和指数基金分析⑧——基本面 Smart beta策略研究和指数基金分析⑨——等权重 Smart beta策略研究和指数基金分析⑩——多因子 作者：零城逆影链接：https://xueqiu.com/9290769077/122476700?page=3来源：雪球著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。风险提示：本文所提到的观点仅代表个人的意见，所涉及标的不作推荐，据此买卖，风险自负。","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"基金","slug":"基金","permalink":"https://beefyheisenberg.github.io/tags/基金/"},{"name":"ETF","slug":"ETF","permalink":"https://beefyheisenberg.github.io/tags/ETF/"},{"name":"SmartBeta","slug":"SmartBeta","permalink":"https://beefyheisenberg.github.io/tags/SmartBeta/"}]},{"title":"F32g.商品ETF","slug":"52.Financing/F32g.商品ETF","date":"2024-01-24T01:27:53.438Z","updated":"2024-01-24T01:27:53.439Z","comments":true,"path":"52.Financing/F32g.商品ETF/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F32g.商品ETF/","excerpt":"跟踪大宗商品相关指数的ETF@ref: 中国目前有商品指数基金吗？如果有，都有哪些？风险是什么？ - 知乎 与商品指数相关的基金有这么几大类： 跟踪国际大宗商品（包含贵金属）指数，目前全部都是FOF基金，且因为投资标的是境外的金融资产，所以目前是以QDII形式 跟踪境内或境外的大宗商品生产商的股票指数。注意大宗商品生产商的股票价格与大宗商品本身（现货或期货）相关但不同，包括这么几只——华安标普全球石油指数(QDII)、华宝兴业标普石油天然气上游股票指数(QDII)、国联安上证大宗商品ETF、招商中证大宗商品股票等基金","text":"跟踪大宗商品相关指数的ETF@ref: 中国目前有商品指数基金吗？如果有，都有哪些？风险是什么？ - 知乎 与商品指数相关的基金有这么几大类： 跟踪国际大宗商品（包含贵金属）指数，目前全部都是FOF基金，且因为投资标的是境外的金融资产，所以目前是以QDII形式 跟踪境内或境外的大宗商品生产商的股票指数。注意大宗商品生产商的股票价格与大宗商品本身（现货或期货）相关但不同，包括这么几只——华安标普全球石油指数(QDII)、华宝兴业标普石油天然气上游股票指数(QDII)、国联安上证大宗商品ETF、招商中证大宗商品股票等基金 黄金ETF（159934）：上海黄金交易所现货实盘合约收盘价 黄金ETF（518880）：国内黄金现货价格收益率 有色ETF（159980）：上海期货交易所有色金属期货价格指数收益率 能源化工ETF（159981）：跟踪易盛郑商所能源化工指数A：编制方法考虑商品期货成交及现货消费情况、市场流动性等因素（主要商品包括PTA、甲醇、玻璃） 南方原油（501018）：60%WTI原油价格收益率+40%BRENT原油价格收益率（DQII） 嘉实原油LOF（160723）：100%WTI原油价格收益率 华宝油气（162411）：标普石油天然气上游股票指数（SPSIOP），选择在美国主要交易所（纽约证券交易所、美国证券交易所、纳斯达克等）上市的石油天然气勘探、采掘和生产等上游行业的公司为标的。成份股数量一般在60～80范围。 有色金属（512400）：跟踪中证申万有色金属指数：从沪深市场申万有色金属及非金属材料行业中选取50只上市公司证券作为指数样本，以反映沪深市场有色金属行业上市公司证券的整体表现。 银华抗通胀主题(QDII-FOF-LOF)，业绩比较基准-标普高盛商品总指数收益率 （S&amp;P GSCI Commodity Total Return Index） 在全球范围内精选跟踪单个或大类商品价格的ETF，业绩比较基准90%以上是商品指数的共同基金，以及主要投资于通货膨胀挂钩债券的ETF或债券型基金的主题投资基金； 本基金的投资组合比例为：投资于基金的资产合计不低于本基金基金资产的60%，其中不低于80%投资于抗通胀主题的基金，现金或者一年以内的政府债券投合计不低于基金资产净值的5%； 本基金所投资的商品类基金以跟踪商品指数或商品价格为投资目标，通常情况下不采用卖空策略，也不使用资金杠杆； 一季度发布的持仓前三： • 15% Powershares DB Commodity INDEX（景顺DB商品ETF） • 15% iShares GSCI Commodity（标普高盛商品指数ETF ） • 15% United States Brent Oil Fund（布伦特原油基金） 商品ETF和周期股从事大宗商品的企业一般属于周期股，与经济周期高度相关 @link: F44.周期股 商品ETF也有风险@ref: 交割制度与中行“原油宝”穿仓 固体大宗交割还要注意“单位运费”的影响，黄金白银“单位运费”成本极低，可以忽略不计，交割更加方便，但是原油储存和交割的成本非常高。所以石油期货价格有可能出现“负价格”。 正常的期货交易中，最后几个交易日都是“现货商”在参与，投机性空头和多头都会提前换仓（也可以叫“移仓”）。“换仓”之后，原来的主力合约流动性变差，极容易发生踩踏， 交割方式而言，布伦特原油可以现金交割，上海原油期货是仓库交割，而WTI原油期货是管道交割。 @link: F34a.期货","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"基金","slug":"基金","permalink":"https://beefyheisenberg.github.io/tags/基金/"},{"name":"ETF","slug":"ETF","permalink":"https://beefyheisenberg.github.io/tags/ETF/"}]},{"title":"F32d.货币ETF","slug":"52.Financing/F32d.货币ETF","date":"2024-01-24T01:27:53.432Z","updated":"2024-01-24T01:27:53.432Z","comments":true,"path":"52.Financing/F32d.货币ETF/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F32d.货币ETF/","excerpt":"为什么债券类基金跌的时候货币类基金涨？ 如果不考虑流动性，货币类基金和一年定期存款哪个收益较高？ - 知乎 货币基金的收益率主要反映短期的银根松紧 - 根据Shibor（上海银行间拆解利率2周至一个月的利率水平）就可以知道当前的水平。银根紧，则货币市场基金收益高；反之，则收益低。原因在于货币市场基金作为市场的流动性供应方，银根紧则流动性需求高。一月份由于春节效应，通常是一年中银根比较紧的时候 - 因素在于很多合同要在这时候结账，工资，年终奖金，税都要付钱等等…，因此此时货币基金收益高。债券基金的收益率则跟即期的银根松紧呈现较强的负相关 - 一方面市场整体利率的上升（尽管长期利率可能没有多少变动），会使得债券的价格下跌，另外其它的债券持有方（银行，保险，社保）由于应对银根紧的因素要变现，卖出债券，使得价格下降。 第二个问题：货币基金主要投资于银行协议存款。从存期上来讲，一般达不到一年，但是由于协议存款是公对公大额存款，利率不是按照个人存款利率给的，通常比个人存款利率高出不少。这两个因素一起考虑的话，这一部分协议存款利率收益不低于一年期个人存款利率，至少目前如此。此外，货币基金还持有部分债券（国债，金融债等）这些的利率要高于一年定存。最后，货币基金还参与逆回购交易，在市场流动性缺乏时候通过逆回购融出资金，这时候的收益率也高于一年定存收益。因此，总的来说，货币基金收益高于一年定存利率是比较靠谱的。 @link: F27a.同业拆借利率（Shibor） 投资货币基金需要学习什么知识？货币基金的增值和贬值跟什么有关？ - 知乎影响货币基金的主要因素：具体持有的一揽子债券的票面利息有关、短期市场利率、货币基金组合的杠杆倍数、平均持有久期（简单理解就是这一揽子债券的平均到期期限）、市场资金面宽松程度、货币基金的规模、货币基金的持有者构成等因素。","text":"为什么债券类基金跌的时候货币类基金涨？ 如果不考虑流动性，货币类基金和一年定期存款哪个收益较高？ - 知乎 货币基金的收益率主要反映短期的银根松紧 - 根据Shibor（上海银行间拆解利率2周至一个月的利率水平）就可以知道当前的水平。银根紧，则货币市场基金收益高；反之，则收益低。原因在于货币市场基金作为市场的流动性供应方，银根紧则流动性需求高。一月份由于春节效应，通常是一年中银根比较紧的时候 - 因素在于很多合同要在这时候结账，工资，年终奖金，税都要付钱等等…，因此此时货币基金收益高。债券基金的收益率则跟即期的银根松紧呈现较强的负相关 - 一方面市场整体利率的上升（尽管长期利率可能没有多少变动），会使得债券的价格下跌，另外其它的债券持有方（银行，保险，社保）由于应对银根紧的因素要变现，卖出债券，使得价格下降。 第二个问题：货币基金主要投资于银行协议存款。从存期上来讲，一般达不到一年，但是由于协议存款是公对公大额存款，利率不是按照个人存款利率给的，通常比个人存款利率高出不少。这两个因素一起考虑的话，这一部分协议存款利率收益不低于一年期个人存款利率，至少目前如此。此外，货币基金还持有部分债券（国债，金融债等）这些的利率要高于一年定存。最后，货币基金还参与逆回购交易，在市场流动性缺乏时候通过逆回购融出资金，这时候的收益率也高于一年定存收益。因此，总的来说，货币基金收益高于一年定存利率是比较靠谱的。 @link: F27a.同业拆借利率（Shibor） 投资货币基金需要学习什么知识？货币基金的增值和贬值跟什么有关？ - 知乎影响货币基金的主要因素：具体持有的一揽子债券的票面利息有关、短期市场利率、货币基金组合的杠杆倍数、平均持有久期（简单理解就是这一揽子债券的平均到期期限）、市场资金面宽松程度、货币基金的规模、货币基金的持有者构成等因素。 一文搞懂场内货币基金 - 雪球 申赎型场内货币基金：基金编码“519”开头，申赎型场内货币基金只能在场内进行申赎而无法进行交易： 计息规则，“算头不算尾”，T日申购，当日享受收益；T日赎回，不享受当日收益。 交易规则：T日申购的份额，T+1日可赎回。T日赎回后T日资金可用，T+1日可取 交易型场内货币基金：基金编码以“511”开头，场内交易型货币基金除了可以在场内申购赎回以外，还可以像股票一样在场内交易，并且可以T+0交易： 计息规则：买卖“算头不算尾”，T日买入，当天享受收益，T日卖出，当天不享受收益；申赎“算尾不算头”，T日申购，T+1日享受收益，T日赎回，T日享受收益，T+1日不享受收益。 交易规则：（场内交易T+0，申购赎回T+2）T日买入，T日可赎可卖，T日卖出，资金T日可用，T+1日可取；T日申购，T+2日可卖可赎，T日赎回，资金T+2日可用可取 交易兼申赎型场内货币基金：基金编码以“159”开头，既可以在市场上T+0交易，又可以T+0申赎，是目前市场上交易效率最高的场内货币基金。 计息规则：“算尾不算头”，T日申购或买入，T+1日享受收益；T日赎回或卖出，T日享受收益，T+1日不享受收益。 交易规则：（场内交易T+0，申购赎回T+0）T日买入，T日可赎可卖，T日卖出，资金T日可用，T+1日可取；T日申购，T日可卖可赎，T日赎回，资金T日可用，T+1日可取 获利手段： 基金收益：场内货币基金归根结底是一个货币基金，买入或申购后可以享受货币基金的收益，最近一般年化3+%。大部分场内货币基金的净值采用固定净值，一份100元，每日收益单独结算，类似于传统基金。少数场内货币基金（比如银华日利）采用累积净值，收益在每年年底结算。 交易价差：对于场内交易型货币基金，可以类似股票一样进行交易，由于基金申赎在额度和时间方面存在的局限性，在市场资金面变化的情况下，交易价格会产生折溢价。因为折溢价的存在，就可以获得价差收益，折价买入，溢价卖出。 市场套利：利用二级市场交易的折溢价，同一级市场申赎平价之间的差异进行套利，具体可以分为两类 市场折价交易的时候，买入，然后赎回。对于交易型场内货币基金（基金编码以“511”开头），T日买入，T日可以赎回，T日享受收益，T+1日不享受收益，资金T+2日可用可取，因此，折价收益必须要超过基金的一日收益，才值得套利。对于交易兼申赎型场内货币基金（基金编码以“159”开头），T日买入，T日可赎回，资金T日可用，只要有折价就可以套利。如果没有赎回额度的限制，理论上来说交易兼申赎型场内货币基金是不应该出现折价的。 市场溢价交易的时候，申购，然后到市场卖出。对于交易型场内货币基金（基金编码以“511”开头），T日申购，T+1日享受收益，T+2日可卖，因此，价差要超过一日基收益，并且，在T+2日价差仍然还要存在，才能成功套利，条件比较苛刻。对于交易兼申赎型场内货币基金（基金编码以“159”开头），T日申购，T日可卖可赎，只要有折价就可以套利。如果没有申购额度的限制，理论上来说交易兼申赎型场内货币基金不应该出现溢价。 同业存单是指由银行业存款类金融机构法人在全国银行间市场上发行的记账式定期存款凭证，整体流动性较好，是比较好的流动性管理工具和货币市场投资工具。自2013年12月首期同业存单发行至今，同业存单市场发展迅猛，已成长为债券市场的重要组成部分。从债市总体来看，截至2021年11月30日，同业存单存量13.81万亿，是继地方政府债、国债、政策银行债之后，排名第四的债券品种。 对应指数：中证同业存单AAA指数样本券由在银行间市场上市的主体评级为AAA、发行期限1年及以下、上市时间7天及以上的同业存单组成，具有流动性较优的特性，通过市值加权，反映了信用评级为AAA的同业存单的整体表现。 @ref: https://m.lu.com/h5-content/article/show?id=57759","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"基金","slug":"基金","permalink":"https://beefyheisenberg.github.io/tags/基金/"},{"name":"ETF","slug":"ETF","permalink":"https://beefyheisenberg.github.io/tags/ETF/"},{"name":"债券","slug":"债券","permalink":"https://beefyheisenberg.github.io/tags/债券/"},{"name":"同业存单","slug":"同业存单","permalink":"https://beefyheisenberg.github.io/tags/同业存单/"}]},{"title":"F32c.债券ETF","slug":"52.Financing/F32c.债券ETF","date":"2024-01-24T01:27:53.427Z","updated":"2024-01-24T01:27:53.428Z","comments":true,"path":"52.Financing/F32c.债券ETF/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F32c.债券ETF/","excerpt":"@ref: 债券基金如何选（附TOP基金） - 知乎 当前市场上的债券ETF按债券资产细分可分为三类，分别是：利率债、信用债、可转债 // @link: F33.债券 利率债 利率债：利率债分为国债和地方政府债，利率债的价格主要受利率变动影响 国泰上证 5 年期国债 ETF（511010）：跟踪指数000140（上证5年期国债指数） 富国中债 7-10 年政策性金融债ETF（511260） 博时中债 0-3 年国开行 ETF（159650） 华安中债 1-5 年国开行债券ETF（159649） 政金债基金：政金债就是政策性金融机构发行的债券，在中国，政策性金融机构只有3家：国家开发银行、中国农业发展银行、中国进出口银行。它们执行国家政策，信用比普通商业银行高得多，所以它们发行的债券也被称为“准国债”。和国债ETF相比，政金债ETF的收益也会更高一些 2020年因为国债利率大幅上涨，从2.5%涨到了3.4%，政金债指数和十年期国债指数一个跌了3.85%，一个跌了4.36% 大部分都是场外，“中债1-5年政金债”","text":"@ref: 债券基金如何选（附TOP基金） - 知乎 当前市场上的债券ETF按债券资产细分可分为三类，分别是：利率债、信用债、可转债 // @link: F33.债券 利率债 利率债：利率债分为国债和地方政府债，利率债的价格主要受利率变动影响 国泰上证 5 年期国债 ETF（511010）：跟踪指数000140（上证5年期国债指数） 富国中债 7-10 年政策性金融债ETF（511260） 博时中债 0-3 年国开行 ETF（159650） 华安中债 1-5 年国开行债券ETF（159649） 政金债基金：政金债就是政策性金融机构发行的债券，在中国，政策性金融机构只有3家：国家开发银行、中国农业发展银行、中国进出口银行。它们执行国家政策，信用比普通商业银行高得多，所以它们发行的债券也被称为“准国债”。和国债ETF相比，政金债ETF的收益也会更高一些 2020年因为国债利率大幅上涨，从2.5%涨到了3.4%，政金债指数和十年期国债指数一个跌了3.85%，一个跌了4.36% 大部分都是场外，“中债1-5年政金债” 信用债 信用债：主体为企业债和公司债，公司债ETF主要发行方为上市公司，相对数量较多，企业债主要由长周期央企项目建设和城投债组成。 城投债ETF（511220）：海富通上证城投债ETF，跟踪上证城投债指数，包括中票、公司债、企业债 公司债ETF（511030）：平安中高等级公司债利差因子ETF：跟踪「中债-中高等级公司债利差因子」指数，其风险收益特征与标的指数所表征的债券市场组合的风险收益特征相似。 海富通中证短融ETF（511360）：跟踪中证短融指数 (H11014)，短期融资券(Commercial Paper)，是指具有法人资格的非金融企业在银行间债券市场发行的，约定在1年内还本付息的债务融资债券，是一种流动性较高、风险较低的债券，所以从风险收益特征上看，这只基金有点像短债产品，风险收益介于货币基金与普通债券型基金之间。 央企债基金：央企债基金主要投向央企发行的债券。和国债、政金债相比，央企的信用低一些， 少量几只场外： “中债1-3年久期央企xx” 地方债 / 城投债基金：虽然它们的信用等级更低一些，近年来也偶有违约事件发生，但可以通过摊大饼的方式规避，比如上证10年地债指数中就有1644只债券，单只债券违约对整个组合影响有限 可转债 可转债：中证转债及可交换债指数（931078.CSI），指数样本券由沪深交易所上市的可转换公司债券和可交换公司债券组成 上证可转债（511180）： 可转债ETF（511380）：中证可转债及可交换债券指数（931078）样本券由沪深交易所上市的可转换公司债券和可交换公司债券组成。指数采用市值加权计算，以反映沪深交易所可转换公司债券和可交换公司债券的整体表现。 更多参考：F33c.可转债","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"基金","slug":"基金","permalink":"https://beefyheisenberg.github.io/tags/基金/"},{"name":"ETF","slug":"ETF","permalink":"https://beefyheisenberg.github.io/tags/ETF/"},{"name":"债券","slug":"债券","permalink":"https://beefyheisenberg.github.io/tags/债券/"}]},{"title":"F32b.行业ETF","slug":"52.Financing/F32b.行业ETF","date":"2024-01-24T01:27:53.423Z","updated":"2024-01-24T01:27:53.423Z","comments":true,"path":"52.Financing/F32b.行业ETF/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F32b.行业ETF/","excerpt":"消费ETF必须消费行业，指数基金如何选 - 知乎 ▷ 必须消费类指数： 上证消费（000036）选择上海证券市场主要消费行业股票组成，以反映该行业公司股票的整体表现。该指数成分股为30只，前十大权重占比71.63%，其中贵州茅台、伊利股份、海天味业三只个股的权重占比超过43%，典型的食品饮料蓝筹属性。该指数权重集中，龙头汇集，缺点是没有涵盖深市龙头。 中证消费（000932）中证主要消费指数由中证800指数样本股中的主要消费行业股票组成，成分股为41只，代表A股市场中大市值消费类股票指数，白酒板块个股占比较高，龙头股集中。业绩上不分伯仲，建议投资者选择汇添富中证主要消费ETF(159928)，嘉实中证主要消费ETF（512600）这只产品的规模只有600万，存在清盘风险。 全指消费(000990) 全指消费指数从中证全指样本股主要消费行业内选择流动性和市场代表性较好的股票构成指数样本股，由134只个股组成，主要权重集中食品饮料行业。广发基金管理的中证全指共有3只基金产品（001458、002976、159946），由于产品规模持续下滑，已经停止申购，被清盘的概率很大，非常可惜。 ▷ 可选消费指数：","text":"消费ETF必须消费行业，指数基金如何选 - 知乎 ▷ 必须消费类指数： 上证消费（000036）选择上海证券市场主要消费行业股票组成，以反映该行业公司股票的整体表现。该指数成分股为30只，前十大权重占比71.63%，其中贵州茅台、伊利股份、海天味业三只个股的权重占比超过43%，典型的食品饮料蓝筹属性。该指数权重集中，龙头汇集，缺点是没有涵盖深市龙头。 中证消费（000932）中证主要消费指数由中证800指数样本股中的主要消费行业股票组成，成分股为41只，代表A股市场中大市值消费类股票指数，白酒板块个股占比较高，龙头股集中。业绩上不分伯仲，建议投资者选择汇添富中证主要消费ETF(159928)，嘉实中证主要消费ETF（512600）这只产品的规模只有600万，存在清盘风险。 全指消费(000990) 全指消费指数从中证全指样本股主要消费行业内选择流动性和市场代表性较好的股票构成指数样本股，由134只个股组成，主要权重集中食品饮料行业。广发基金管理的中证全指共有3只基金产品（001458、002976、159946），由于产品规模持续下滑，已经停止申购，被清盘的概率很大，非常可惜。 ▷ 可选消费指数： 中证可选消费指数 (000989) 目前全市场可选消费指数只有中证可选消费指数一只 ，包含432只成份股，前十大权重中家电、汽车占比较高，其中美的和格力占比超过20%。 ▷ 消费主题（消费主题指数编制规则没有主要消费和可选消费之分，只要符合条件即可选入）： 上证消费80成份股由沪市规模靠前的80只主要消费+可选消费+医药卫生组成，主要消费占比39.5%，可选消费占比27.1%，医药占比33.3%，相当于是沪市消费+医药大蓝筹集合。 中证消费龙头和中证消费50两者的编制思路较为接近，都是选消费龙头。他俩的主要区别在于消费50剔除了汽车和传媒两大可选消费，因此同样是选龙头，消费龙头在可选消费/主要消费方面没有偏向，而消费50偏向主要消费。 ▷ 消费细分： CS食品饮料：中证主要消费指数，它和CS食品饮料指数接近，食品占比较高，两者的主要区别在于中证主要消费生猪养殖企业占比更高。 细分食品：细分食品和国证食品中酒占比较高，比分别是64%、63%，食品占比大约是35% 国证食品： 中证白酒： 医疗/医药ETF@ref: 生物医药行业，ETF如何选 - 知乎 ▷ 下面这幅图是对行业的划分，并标记整个产业链相关龙头企业，建议保存好： 药械可以理解为产业上游企业，主要是研发、生产环节，包含：中药、化学药、生物药、器械； 服务分为两方面，一方面是医疗服务机构，比如民营医院、体检机构；另一方面是医药研发相关的服务机构（外包服务），比如CRO、CMO、CSO等等(CXO是CRO、CMO、CDMO的统称)。 CRO企业（合同定制研发机构）是指通过合同形式为制药企业和研发机构在药物研发过程中提供专业化服务的机构。CRO企业服务于药物研发的整个阶段，负责药物开发过程所涉及的全部或部分活动，其基本目的在于协助制药企业进行科学或医学研究，主要提供的服务包括新药发现、安全性评价研究服务、药代动力学、药理毒理学等临床前研究及临床数据管理、新药注册申请等。 CMO/CDMO 企业主要侧重于药物的生产服务。其中，CMO（合同定制生产机构）是指以合同定制形式为制药企业提供中间体、原料药、制剂的生产以及包装等服务的企业。传统的CMO企业仅提供以委托企业提供的技术路线为基础的代工生产服务。随着制药公司对成本控制和效率提升的要求不断提高，制药企业希望CMO 企业能够承担更多工艺研发、改进的创新性服务职能，CDMO企业应运而生。 ▷ 相关指数： 300医药卫生（000913）： 沪深300医药卫生指数（000913），以沪深300指数样本股，从事医药卫生行业的公司股票作为指数样本股（11个一级行业之一） https://www.csindex.com.cn/#/indices/family/detail?indexCode=000913 中证医药（000933）：以中证800指数样本股中的医药卫生行业公司组成（中证800=300+500） CS创新药（931152）：以中证全指指数为样本，主营创新药研发的公司 CS生药（930726）： 以中证全指指数为样本，主营基因、疫苗、血液制品等的公司 中证医疗（399989）：沪深A股中涉及医疗器械、医疗服务的公司股票作为指数样本股 比较近7年收益：CS创新药 &gt; 300医药卫生 &gt; CS生药 &gt; 中证医疗 &gt; 中证医药 未列出的指数： 医药50（931140）：中证医药50指数从沪深市场的医药卫生行业中选取规模大、经营质量好的50只龙头上市公司证券作为指数样本，以反映沪深市场医药行业内龙头上市公司证券的整体表现。https://www.csindex.com.cn/#/indices/family/detail?indexCode=931140 CS医药创新（931484）：中证医药及医疗器械创新指数，从沪深市场按规模、盈利能力、成长性、研发创新能力，选取得分最高的30只股票 https://www.csindex.com.cn/#/indices/family/detail?indexCode=931484 恒生医疗保健（HSHCI）：任何按恒生行业分类系统归类为医疗保健业(28)的恒生综合指数成份股将被纳入恒生医疗保健指数。采用流通市值加权法计算，而每只成份股的比重上限设定为10%。恒生医疗里biotech公司较多，Biotech生物科技(Biotechnology，简称Biotech)，是以基因工程为核心，包括细胞工程、酶工程、发酵工程和蛋白质工程在内的互相联系、互相渗透的高技术。https://www.hsi.com.hk/static/uploads/contents/zh_cn/dl_centre/brochure/hshcic.pdf 制造业ETF@ref: 一文看懂新能源出题ETF - 知乎 中证高装（930599）：高端装备制造指数，通信设备、电气、重型电气、新能源设备、铁路设备、航天、国防… 装备产业（H11054）：中证800指数样本股中的装备产业股票 智能制造（930850）： 新能源主题一键打包: 中证新能源（399808） 南方中证新能源ETF（516160） 新能源（000941） 新能源车指数: 智能电车（H11052） 新能源车（930997） 平安中证新能源汽车产业ETF（515700） CS新能车（399976） 华夏中证新能源汽车ETF（515030 国证新能源车（399417） 电池指数: 新能源电池（980032） 广发国证新能源车电池ETF（159755） CS电池（931719） 光伏指数: 光伏产业（931151）指数 华泰柏瑞的中证光伏产业ETF（515790） 环保+碳中和指数: 中证内地低碳经济主题指数（000977） 易方达碳中和50ETF（516070） 中证环保产业50指数（930614） 半导体ETF投半导体ETF前，还是仔细看看半导体指数有什么差 - 知乎 半导体芯片基金哪家强！ - 雪球总结一下三个指数： ①把三个指数的全部成分股列出来，其实成分股高度的相似，特别是中证全指半导体，几乎所有的成分股在中华半导体以及国证芯片里都能找到 指数编制的行业选择上，中华半导体以及国证芯片都是选择了芯片产业链上的材料、设备、设计、制造、封装和测试等 中证半导体则是细分产品以及设备，稍微跟上面的不一样，我理解是这个指数认为半导体产业里面，更重要的是产品以及设备？ ②指数编制上，三者都是在日均成交金额以及市值的基础上进行挑选。中华半导体跟国证芯片很相似，但国证芯片的条件要更加苛刻 ③三个指数估值，国证芯片综合来看，各项数据都是最优 ④我们经常说，目前是少数个股的结构性牛市，成分股指数更少的基金往往表现的更好。而成分股更少，侧面说明指数编制的时候要更加严格，更加精选。 介绍一个热门的指数：国证芯片指数投资价值分析|产业链新浪财经新浪网 ➤ 国证芯片指数:为反映A股市场芯片产业相关上市公司的市场表现，丰富指数化投资工具，深证信息公司于2015年编制并发布了国证半导体芯片指数(8502.587, 116.75, 1.39%)。该指数从芯片产业中材料、设备、设计、制造、封装和测试等A股上市公司中选取样本股，并以2002年12月31日为基日，1000点为基点。截至2019年12月31日，国证芯片指数成份股个数为25只，总市值8289亿元，个股平均市值332亿元。 从指数成份股来看，国证芯片指数囊括了A股芯片产业链上的龙头企业。从产业链细分环节来看，国证芯片指数成份股在芯片设计、芯片制造领域的累计权重最高，分别为39.74%、28.61%，在芯片封测、芯片材料、芯片设备领域的权重分别为13.10%、10.14%、8.41% 前十大成份股合计占比71.89%，其中5家属于芯片设计公司，合计权重34.53%： 第一大成份股三安光电(20.820, -0.62, -2.89%)占比为10.63%，是LED芯片龙头企业，具有强大的技术壁垒，在专利、客户和产品方面远远领先于其他国内厂商，本轮LED芯片行业洗牌后，龙头集中度有望持续提升；同时公司的砷化镓射频产品已与100多家客户有业务接触，氮化镓射频已实现客户送样，电力电子产品已进入量产阶段，化合物半导体业务成长可期。 第二大成份股兆易创新(127.090, 3.51, 2.84%)占比9.82%，是中国存储芯片设计领先公司，存储业务包括NOR Flash、NAND Flash和DRAM，是内资唯一一个存储全产业布局的企业，并迅速在多个领域做大做强，成为中国存储行业的领先企业。同时公司业务不断向MCU、传感器等领域渗透，在物联网领域的布局已经形成闭环，未来众多业务将共同拉动公司业绩增长。根据网易援引自CINNO RESEARCH的数据，19Q2 NOR FLASH市场，公司市场份额为13.9%，超越Micron，位居全球第四。 ▷ 中华半导体指数追踪中国A股市场半导体行业上市公司的股价表现，相关公司经营范围涵盖半导体材料、设备、设计、制造、封装和测试，成份股个数为50只； ▷ 中证全指半导体指数选取中证全指样本股中的半导体产品与设备行业股票组成，成份股个数为32 互联网ETF 易方达中概互联ETF(513050)：追踪中证海外互联网50指数，单样本权重不超过30%； 广发中概互联ETF(159605)：追踪中证海外互联网30指数，单样本权重不超过15%，前五大样本权重合计不超过60%","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"基金","slug":"基金","permalink":"https://beefyheisenberg.github.io/tags/基金/"},{"name":"ETF","slug":"ETF","permalink":"https://beefyheisenberg.github.io/tags/ETF/"}]},{"title":"F32a1.宽基指数的估值偏移","slug":"52.Financing/F32a1.宽基指数的估值偏移","date":"2024-01-24T01:27:53.417Z","updated":"2024-01-24T01:27:53.418Z","comments":true,"path":"52.Financing/F32a1.宽基指数的估值偏移/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F32a1.宽基指数的估值偏移/","excerpt":"宽基指数PE/PB/ROE的中枢变化我们最常用的估值指标是市盈率PE、市净率PB，通常会取过去一段历史区间，拿当前的PE、PB和历史值去比，看当前指标在历史上所处的百分位。如果当前指标比历史大部分时候都低，就认为当前估值比较低；反之，则认为当前估值偏高。这套估值方法隐含了一个假设：PE和PB都会均值回归，即长期看它们会围绕一个较稳定的中枢波动。只有这个假设成立，拿当前指标和历史比才有意义。 在很多股票上，我们都可以观察到估值中枢的长期单向变化，比如一些银行股，观察近十几年的PB估值，我们会发现整体是不断下移的，并没有出现均值回归。 ➤ 估值（PE）中枢的偏移： 市场整体层面，股票市场的供求关系变化会影响估值。在A股早期，股票数量很少，大家抢着买，就容易享受较高的估值，后来股票不断IPO、增发，供应越来越多，估值的中枢就会下降。A股近20年来上市公司的数量快速增加，总市值不断提高，估值中枢就会下降，除非市场新引入了大量资金重新改变供求关系，否则这种下降就不太可能回归。 宽基指数层面，成分股的更替会影响估值。 比如中证500，它的成分股是排在沪深300之后，自由流通市值次大的那500只股票，大致可以理解为自由流通市值排在301-800的股票。早年A股上市公司数量少，一共只有1000多只，排在301-800，就属于靠后的小盘股。但现在A股就快有5000家上市公司了，排在301-800，就已经变成了靠前的中盘股。小盘股的估值水平，普遍会比大盘股高一些，中证500在成分股市值变大的过程中，估值就会出现向下的偏移，这种偏移也不会回归； 但沪深300相反，10年前沪深300的权重股以金融为主，而金融股的PE一直比较低。而如今沪深300的前十大权重中，金融股占比下降，消费、制造业等占比增加，导致沪深300的估值中枢变高； 行业和个股层面，ROE长期变化会影响估值。比如银行自十几年前股改上市以来，ROE呈下降趋势，估值指标特别是PB，就会向下偏移。反之，如果一个行业迎来了大发展，ROE长期变高了，那估值指标也就会向上偏移。","text":"宽基指数PE/PB/ROE的中枢变化我们最常用的估值指标是市盈率PE、市净率PB，通常会取过去一段历史区间，拿当前的PE、PB和历史值去比，看当前指标在历史上所处的百分位。如果当前指标比历史大部分时候都低，就认为当前估值比较低；反之，则认为当前估值偏高。这套估值方法隐含了一个假设：PE和PB都会均值回归，即长期看它们会围绕一个较稳定的中枢波动。只有这个假设成立，拿当前指标和历史比才有意义。 在很多股票上，我们都可以观察到估值中枢的长期单向变化，比如一些银行股，观察近十几年的PB估值，我们会发现整体是不断下移的，并没有出现均值回归。 ➤ 估值（PE）中枢的偏移： 市场整体层面，股票市场的供求关系变化会影响估值。在A股早期，股票数量很少，大家抢着买，就容易享受较高的估值，后来股票不断IPO、增发，供应越来越多，估值的中枢就会下降。A股近20年来上市公司的数量快速增加，总市值不断提高，估值中枢就会下降，除非市场新引入了大量资金重新改变供求关系，否则这种下降就不太可能回归。 宽基指数层面，成分股的更替会影响估值。 比如中证500，它的成分股是排在沪深300之后，自由流通市值次大的那500只股票，大致可以理解为自由流通市值排在301-800的股票。早年A股上市公司数量少，一共只有1000多只，排在301-800，就属于靠后的小盘股。但现在A股就快有5000家上市公司了，排在301-800，就已经变成了靠前的中盘股。小盘股的估值水平，普遍会比大盘股高一些，中证500在成分股市值变大的过程中，估值就会出现向下的偏移，这种偏移也不会回归； 但沪深300相反，10年前沪深300的权重股以金融为主，而金融股的PE一直比较低。而如今沪深300的前十大权重中，金融股占比下降，消费、制造业等占比增加，导致沪深300的估值中枢变高； 行业和个股层面，ROE长期变化会影响估值。比如银行自十几年前股改上市以来，ROE呈下降趋势，估值指标特别是PB，就会向下偏移。反之，如果一个行业迎来了大发展，ROE长期变高了，那估值指标也就会向上偏移。 ➤ 区分中枢偏移的“可逆”和“不可逆”： 上面提到的中证500和沪深300的行业成分变化，估值中枢的趋势不太可能发生“逆转”。但是“资金偏好”是可逆的，2015年之前，小市值一直是A股中非常有效的因子，甚至可以说是超额收益最好的因子之一。但在2016年熔断之后，这一因子几乎彻底失效，市场开始青睐大市值的蓝筹股，原因之一是2016年末深股通开放，外资借北向通道开始加速流入A股。互联互通机制的股票池更偏向大盘股。接下来随着持有大盘股的公募基金规模出现快速扩张，在之后2016-2017年走出了上证50领衔的大盘股行情。而“资金偏好”是可逆的，过去几年市场热捧大盘风格，导致资金拥挤在其中，让大盘指数估值过高；最近2022行情中，大盘风格下跌，成长/小盘风格受到资金青睐，所以这段时期大盘指数的估值中枢是下降的。 ➤ 使用PB需要注意的问题： PE直接和净利润挂钩更直观，但容易受周期波动影响。一家周期性强的公司，比如周期股，ROE是随着商品价格而波动的。在商品价格高的时候，ROE特别好，盈利也多，PE反而会显得很低，但这时候未必意味着股价低估。未来商品价格还会随着周期回落，那时候ROE、盈利都会降低，PE就会被动升高。因此对ROE呈周期性波动的公司，不适合直接去看PE的百分位，更多的可以参考PB。 PB不容易受周期波动影响，但无法反映一个行业ROE的长期单向变化。一个处于上升行业或衰落行业的公司，其ROE可能在十几年的时间里，都持续增加或减少，这意味着单位资本取得的回报改变了，那PB的中枢就应该跟着改变，无法期待它均值回归。这时候就不适合使用PB估值，而更多的可以参考PE。 @ref: 买大盘还是买小盘？ - 雪球","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[]},{"title":"F32a.宽基ETF","slug":"52.Financing/F32a.宽基ETF","date":"2024-01-24T01:27:53.413Z","updated":"2024-01-24T01:27:53.413Z","comments":true,"path":"52.Financing/F32a.宽基ETF/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F32a.宽基ETF/","excerpt":"@tag: #基金 #ETF 选择宽基指数A股主要宽基指数和各自特点： F30a.A股101 选择宽基指数，需要注意指数构成是否有过大的调整。比如今年5月，中证100这个很重要的宽基指数，就发生了一次指数编制机制的修改。加大了对ESG因子的参考权重，从权重指数变成了ESG指数。","text":"@tag: #基金 #ETF 选择宽基指数A股主要宽基指数和各自特点： F30a.A股101 选择宽基指数，需要注意指数构成是否有过大的调整。比如今年5月，中证100这个很重要的宽基指数，就发生了一次指数编制机制的修改。加大了对ESG因子的参考权重，从权重指数变成了ESG指数。 以及指数的估值中枢近几年是否有较大的变化： 例如中证500，如果看的是十年PE百分位，会把2015年也包括进去。2015年的中证500还是小盘成长指数，指数估值在2015的爆炒中泡沫很大，中证500的估值中枢从2017年以来就一直处于一个下行的阶段。会使现在的估值百分位看起来“很低”但实际上并不低。 @ref: 定投宽基指数，除了估值的历史分位数，还应该注意什么？ 富时A50富时中国A50指数(XIN9)是由全球四大指数公司之一的富时罗素指数公司为满足中国国内投资者及合格境外机构投资者(QFII)而推出的产品。富时中国A50指数包含了中国A股市场市值最大的50家公司，其各项指标，包括业绩表现、流动性、波动性、行业分布和市场代表性均处于市场领先水平。其总市值占A股总市值的33%，是最能代表中国A股市场的指数，许多国际投资者把这一指数看作是衡量中国市场的精确指标 富时中国A50同时兼顾了沪深两市，更能代表A股市场，这一点上证50是无法取代的，其总市值占A股总市值的34%，是国际投资者衡量A股市场的重要指标之一。另外，它也是受无数小伙伴关注的富时A50期货的跟踪标的，由于该期货品种在新加坡期货交易所上市，交易时间上的优势也让它成为A股市场的风向标，同时也是海外投资者的有效对冲工具。 MSCI A50 大摩 vs 小摩： • 摩根士丹利（大摩），MSCI 是其旗下的指数编制公司 • JP摩根=摩根大通=小摩，在中国是上投摩根 MSCI中国A50互联互通指数于 2021年8月20日推出。该指数采用创新的方法，从满足互联互通条件的最大市值股票中选取50支，确保分散化的板块配置，均衡代表广泛的中国A股市场。该指数旨在使国际和国内投资者能够追踪中国行业领头羊，包括关键行业板块的领先股票，并且作为指数挂钩的ETF和ETN以及其它金融产品的基础。 MSCI中国A50互联互通指数采用行业中性的方法，旨在代表50只大盘中国A股的表现。该指数基于我们的旗舰MSCI中国A股指数（母指数），满足我们所有的可投资性要求（请参阅MSCI全球可投资市场指数方法论），并且符合互联互通要求，代表包括中国的新经济的整体市场机会。该指数在每个行业至少纳入两只股票，使配置分散遍及整个中国经济领域。该指数以实现优于简单50强方法的行业均衡敞口为目标，避免对金融或日常消费品行业的超配。 富时A50 vs MSCI A50相比市场上已有的上证50指数和富时A50指数，MSCI中国A50互联互通指数有什么不同？业内人士表示，主要体现在三方面，其中选样空间、行业分布是最核心的差异。 一是覆盖范围不同。MSCI中国A50互联互通指数、富时A50指数均在沪深两市选股，上证50仅覆盖沪市。 二是选股指标不同。MSCI仅以自由流通市值选股(A股)，上证50以总市值(A股)、成交金额综合选股，富时仅以总市值(全球)选股。 三是行业分布不同。MSCI中国A50互联互通在选股和行业分配权重上均有使行业更加均衡的设计，上证50的母指数上证180按行业配比选股，但对上证50的行业均衡基本没有影响，富时A50无行业调整 ➤ 数据来自 http://fund.eastmoney.com/a/202110182144535177.html : 前十大重仓： 行业分布： MSCI A50 vs 沪深300两者都是大盘股的代表指数，A50的“大盘”属性更集中，单个股所占的比例也更高： ![[../_images/2022/IMG20221125-3.png]] 历史数据：300 vs 500 vs 创业板@Onenote 《宽基指数基金》 创业板、科创、双创2020~今，创业板50 &gt; 创业板 &gt; 科创50 ≈ 科创创业(双创) 近3年: 跟踪创业板 ：一图看懂创业板指数家族财富号东方财富网 创业板指（399006）由创业板中市值大、流动性好的100只股票组成，反映创业板市场的运行情况； 创业板综（399102）选取在深圳证券交易所创业板上市的全部股票，反映创业板市场的总体趋势； 创业板50（399673）由创业板市场中日均成交额较大的50只股票组成，反映了创业板市场内知名度高、市值规模大、流量性好的企业整体表现。 创业蓝筹（399295）即创业板低波蓝筹指数，从盈利、会计稳健、投资稳健、违约风险和低波动五个维度综合选取50只创业板股票，反映创业板中具备良好盈利能力、具有稳健财务质量、且波动率较低的上市公司整体运行情况。 创成长（399296）即创业板动量成长指数，由创业板市场中具有良好成长能力和动量效应的50只股票组成，反映创业板中成长能力好、动量效应显著的上市公司整体运行情况； 创业成长（000958）即中证创业成长指数，由具备创业和高成长特征的100只股票组成，旨在刻画沪深两市创业和成长特征较为显著的中小型上市股票群体的整体表现； 创业价值（000838）即中证创业价值指数，由在创业板、中小板以及主板市场上市的具备创业和价值特征的100只股票组成，旨在刻画沪深证券市场内创业和价值较为显著的中小型上市股票群体整体表现。 科创50和创业板50哪个性价比高？ - 知乎 创业板指数ETF机会 - 知乎 2020年创业板指涨幅约为64.96%，上证综指、深证成指涨幅分别约为13.87%和38.73% 易方达创业ETF(159915）：创业板指数（在剔除创业板上市所有股票最近半年日均成交总额后10%后，选取日均总市值前100名的股票构成样本股）【126亿，0.50%，0.10%】 天弘创业板ETF（159977）：创业板指数【36亿，0.50%，0.10%】 南方创业板ETF（159948）：创业板指数【23亿，0.15%，0.05%】 华安创业50ETF(159949）：创业板50指数（在创业板指的100只股票中，选取最近半年日均成交额排名靠前的50只股票作为创业板50的样本股）【104亿，0.15%，0.05%】 四家科创板50ETF哪家强？ - 知乎 华夏科创50ETF（588000）：上证科创板50指数收益率【200亿，0.50%，0.10%】 易方达科创板50ETF（588080）：上证科创板50指数收益率【110亿，0.50%，0.10%】 工银瑞信科创ETF（588050）：上证科创板50指数收益率【48亿，0.50%，0.10%】 华泰科创板ETF（588090）：上证科创板50指数收益率【29亿，0.50%，0.10%】 科创50和创业板50哪个性价比高？ - 知乎 科创50：半导体、信息科技 创业板50：医疗、新能源、电子 基日至今，科创50指数年化波动率为41.60%，创50指数年化波动率为31.44%。综合来看，年初至今，创50指数在收益风险比上表现更佳，夏普比率接近科创50指数的两倍。 从ROE角度看，去年年报科创50较优，今年三季报创50更优。 科创50指数与创50指数的自由流通市值分布差异较大。科创50指数目前大多数成分股的自由流通市值都较小，42只成分股自由流通市值在100亿元以下，占指数权重的84%，这里面也有解禁的问题。创50指数汇集了创业板的头部公司，大多都是成熟期的新兴科技企业，成分股自由流通市值在100亿元以上的企业居多，其中48%的权重在100至300亿元之间，18%的权重在500亿元以上。","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"基金","slug":"基金","permalink":"https://beefyheisenberg.github.io/tags/基金/"},{"name":"ETF","slug":"ETF","permalink":"https://beefyheisenberg.github.io/tags/ETF/"}]},{"title":"F32.ETF产品索引zz","slug":"52.Financing/F32.ETF产品索引zz","date":"2024-01-24T01:27:53.408Z","updated":"2024-01-24T01:27:53.408Z","comments":true,"path":"52.Financing/F32.ETF产品索引zz/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F32.ETF产品索引zz/","excerpt":"INDEX* 宽基ETF：&#123;% post_link 52.Financing/F32a.宽基ETF &apos;F32a.宽基ETF&apos; %&#125;* 行业ETF：&#123;% post_link 52.Financing/F32b.行业ETF &apos;F32b.行业ETF&apos; %&#125;* 债券ETF: &#123;% post_link 52.Financing/F32c.债券ETF &apos;F32c.债券ETF&apos; %&#125;* 商品ETF：&#123;% post_link 52.Financing/F32g.商品ETF &apos;F32g.商品ETF&apos; %&#125; ETF交易指南（2023最新版）@ref: https://mp.weixin.qq.com/s/TtI526clUFe1_4w1FgkYoA","text":"INDEX* 宽基ETF：&#123;% post_link 52.Financing/F32a.宽基ETF &apos;F32a.宽基ETF&apos; %&#125;* 行业ETF：&#123;% post_link 52.Financing/F32b.行业ETF &apos;F32b.行业ETF&apos; %&#125;* 债券ETF: &#123;% post_link 52.Financing/F32c.债券ETF &apos;F32c.债券ETF&apos; %&#125;* 商品ETF：&#123;% post_link 52.Financing/F32g.商品ETF &apos;F32g.商品ETF&apos; %&#125; ETF交易指南（2023最新版）@ref: https://mp.weixin.qq.com/s/TtI526clUFe1_4w1FgkYoA 相比2021年，ETF基金总规模增长约2000亿元。其中，规模增长的主要来源是股票类ETF，抛开下跌因素，全年总规模增长仍旧达到了1894.02亿元，各类ETF的具体规模如下所示： ETF交易指南（2021最新版） @ref: https://zhuanlan.zhihu.com/p/340812618 1975年，先锋基金（Vanguard）发行全球第一只指数投资信托 ，跟踪标普500指数，起初被动投资策略并不被市场所接受，指数投资发展非常缓慢。 1993年，美国证券交易所推出了全球第一只跟踪S&amp;P500指数的ETF——标准普尔存托凭证SPDR。自此，以ETF为代表的指数基金在美国蓬勃发展。 2004年，国内第一只ETF基金——华夏上证50ETF（510050）诞生。它的到来不仅仅是填补了市场的空白，并以低费率、高效率的优势在指数基中占主要市场份额，此后ETF产品在国内盛行。 截至2020年12月30日，已上市ETF多达341只，总规模8193.72亿元（统计数据剔除货币ETF，产品数量27只，基金规模2650.85亿元）。 相比2019年，ETF基金规模大增2493亿，产品新增数量115只，ETF基金成为全市场发展最快的指数产品。当下，ETF基金产品已形成全方位的投资阵型：类固收性质的货币ETF、债券ETF，为投资者提供便捷的场内现金理财需求。 ETF产品线架构图 权益类ETF权益类ETF也可以称为股票ETF，在ETF家族中占比最大，所跟踪指数也最为丰富。 由于产品多达286只容易混淆，因此ETF之家将权益类ETF又划分为四类，分别是宽基、行业、主题、策略（Smart Beta）。 跨境ETF跨境ETF是指全部或者部分资产投资于中国内地以外的证券指数所对应组合证券的开放式基金。简单而言，跨境ETF就是“跟踪境外指数，在境内上市交易”的ETF产品。 债券ETF当前市场上的债券ETF按债券资产细分可分为三类，分别是：利率债、信用债、可转债。 利率债分为国债和地方政府债，利率债的价格主要受利率变动影响。利率债ETF产品：5年地方债ETF（511060）、国债ETF（511020）。 信用债ETF则包含公司债和企业债两类，公司债ETF主要发行方为上市公司，相对数量较多，企业债主要由长周期央企项目建设和城投债组成。举例信用债ETF：公司债ETF（511030）。 可转债指数：中证转债及可交换债指数（931078.CSI），指数样本券由沪深交易所上市的可转换公司债券和可交换公司债券组成。 债券ETF产品市场成交量较小，购买此类产品的投资者切记选择流动性好的产品入手。 商品ETF商品ETF由10只黄金ETF、3只商品期货ETF组成。 货币ETF截至当前，市场上共有27只货币ETF，其中华宝添益（511990）和银华日利（511880）资金规模有优势、流动性好","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"基金","slug":"基金","permalink":"https://beefyheisenberg.github.io/tags/基金/"},{"name":"ETF","slug":"ETF","permalink":"https://beefyheisenberg.github.io/tags/ETF/"}]},{"title":"F31.可投资的金融产品Index","slug":"52.Financing/F31.可投资的金融产品Index","date":"2024-01-24T01:27:53.403Z","updated":"2024-01-24T01:27:53.403Z","comments":true,"path":"52.Financing/F31.可投资的金融产品Index/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F31.可投资的金融产品Index/","excerpt":"","text":"@tag: _Index * 多头基金：[[F31.基金101]]* 债券大类：&#123;% post_link 52.Financing/F33.债券 &apos;F33.债券&apos; %&#125;* 固收+：@Onenote* 期货：[[F34.期货]]* REITs：&#123;% post_link 52.Financing/F35.REITs &apos;F35.REITs&apos; %&#125;* 衍生品：[[F35.金融衍生品]]","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"基金","slug":"基金","permalink":"https://beefyheisenberg.github.io/tags/基金/"},{"name":"_Index","slug":"Index","permalink":"https://beefyheisenberg.github.io/tags/Index/"},{"name":"投资","slug":"投资","permalink":"https://beefyheisenberg.github.io/tags/投资/"}]},{"title":"F31.投资的α和β收益","slug":"52.Financing/F31.投资的α和β收益","date":"2024-01-24T01:27:53.398Z","updated":"2024-01-24T01:27:53.398Z","comments":true,"path":"52.Financing/F31.投资的α和β收益/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F31.投资的α和β收益/","excerpt":"什么是α / β收益 在投资领域中，收益分为阿尔法(α)收益和贝塔(β)收益，其中，α指主动投资收益，来源于选股和择时，超越市场收益；β指被动投资收益，来源于组合和市场相关的收益，跟随市场收益。 衡量一个基金（or 投资品）的表现： $$ Y = α + βX + u $$ Y： 股票或基金的表现 α： 阿尔法，基金收益减去基准的波动率，获得的超额收益 β：贝塔，是相对于“基准”的波动率，可能带来收益也可能带来亏损 X： 基准，例如可以使用沪深300指数 u：残差，这是一年中无法解释的随机表现部分","text":"什么是α / β收益 在投资领域中，收益分为阿尔法(α)收益和贝塔(β)收益，其中，α指主动投资收益，来源于选股和择时，超越市场收益；β指被动投资收益，来源于组合和市场相关的收益，跟随市场收益。 衡量一个基金（or 投资品）的表现： $$ Y = α + βX + u $$ Y： 股票或基金的表现 α： 阿尔法，基金收益减去基准的波动率，获得的超额收益 β：贝塔，是相对于“基准”的波动率，可能带来收益也可能带来亏损 X： 基准，例如可以使用沪深300指数 u：残差，这是一年中无法解释的随机表现部分 ➤ 关于α这些股票型基金如果取得超越沪深300指数的收益率，那么多出来的部分就叫超额收益“α”。举个例子，假设沪深300指数过去一年的时间盈利为10%，B基金在同样的时间里盈利为15%，市场的无风险利率为零，那么B基金取得的超额收益α值就是5%。 对冲基金的策略就是「去掉β，保留α」 ➤ 关于β贝塔策略是指被动跟踪指数的策略。从长期来讲，贝塔策略是可能盈利的，但由于股票市场波动比较大，在某段特定时间内往往会出现亏损或被套住的状况。该策略在上涨趋势和下跌趋势中都好于对冲策略。比如上涨趋势中，要么只做多股票，要么只做多期指；在下跌趋势中，要么只做空期指，要么只融券卖出。当然，这要求对于行情中长期的趋势要有个准备的判断。 举例：假设沪深300指数在过去一年的时间里下跌了20%，A基金在相同的时间里下跌了18%，那么A基金的β系数就是0.9 （大部分成长型企业的β系数是大于1的） Smart Beta strategy（聪明贝塔策略）：以“Smart Beta”为策略的基金本质上追求的不再是对指数的紧密跟踪，而是希望通过在指数编制过程中对选股和权重安排的优化，获得跑赢传统市值加权指数的超额收益。 Smart Beta指数相当于把优秀的主动管理人的管理理念和管理方法提炼出来，形成指数标准化的投资框架，用指数方法表达出来。Smart Beta指数通过将股票的回报分解到因子层面，揭示出股票获得超额收益的源头。经过国外长期的理论与实践发现，价值、质量、成长、红利、低波动等因子是最有长期获取超额收益能力的因子。 详细参考： F32h.指数基金SmartBeta策略 @ref: 初学者的Alpha和Beta 聊聊对冲策略（一）：α（alpha）和β（beta） - 知乎 smart beta 是什么？为什么最近如此受追捧？ - 伍治坚的回答 - 知乎","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"基金","slug":"基金","permalink":"https://beefyheisenberg.github.io/tags/基金/"},{"name":"投资","slug":"投资","permalink":"https://beefyheisenberg.github.io/tags/投资/"}]},{"title":"F30e1.关于剩余流动性","slug":"52.Financing/F30e1.关于剩余流动性","date":"2024-01-24T01:27:53.393Z","updated":"2024-01-24T01:27:53.394Z","comments":true,"path":"52.Financing/F30e1.关于剩余流动性/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F30e1.关于剩余流动性/","excerpt":"剩余流动性流动性可以说是金融市场含义最丰富的概念之一了，但并无统一的定义，这里的“宏观流动性”指宏观层面的（货币投放、居民-企业-金融部门之间）的流动性，也即货币-信用周期中衡量是否是“宽货币”的重要指标，同时也包括海外流动性；“微观流动性”特指股票/债券交易市场的流动性，与股市短期运行情况更具相关性； ▷ 宏观流动性： 海外流动性观测指标：美元指数、离岸人民币、美国长短债利差、中美十年国债利差，主要影响国内的 H股 和 A50定价； 国内中短期流动性同步观测指标：SHIBOR3m、十年国债收益率、以及AAA同业存单收益率，与流动性负相关，与（债券和存单的）价格净值负相关； 国内中长期流动性同步和滞后指标： M2同比-社融同比：反应的是货币供应量和实体经济融资的差速值。如果指数上行，意味着货币宽松，但是企业融资需求弱，表现是银行同业投资活跃，但是非标偏弱。同业投资主要投资固定收益类，非标是真实运用至实体经济的融资。所以，对股票而言这个剪刀差的直接影响是偏弱的，但对于债券利率表现是有效的指引。 商业银行总资产/央行总资产：反映的是银行和央行的资产增速差，指数上行说明商业银行较央行资产扩张更快，是为宽信用，反之 则为紧信用。 M1同比-PPI同比：M1 变化很多时期都是由地产销售驱动的，地产销售作为大额消费，居民往往需要贷款，然后会创造出相应的货币，转移为企业存款。所以当货币供给M1 改善时，往往背后伴随着地产销售改善。经济在地产周期的带动下可能走出衰退走向复苏，投资者基于这一点，会提前入场做复苏交易，从而推升股票价格。 M1-M2同比增速：M1的构成是企业活期存款和流通中的现金，由于可以随时支取，M2是广义货币供应量。指数上行：经济预期变好，企业和居民的活期存款增加，可能是宽货币转向宽信用的转变。考虑到M1和房地产销售的关系… 指数负向扩大可能代表资金在金融体系内部空转，后续可能转向宽货币","text":"剩余流动性流动性可以说是金融市场含义最丰富的概念之一了，但并无统一的定义，这里的“宏观流动性”指宏观层面的（货币投放、居民-企业-金融部门之间）的流动性，也即货币-信用周期中衡量是否是“宽货币”的重要指标，同时也包括海外流动性；“微观流动性”特指股票/债券交易市场的流动性，与股市短期运行情况更具相关性； ▷ 宏观流动性： 海外流动性观测指标：美元指数、离岸人民币、美国长短债利差、中美十年国债利差，主要影响国内的 H股 和 A50定价； 国内中短期流动性同步观测指标：SHIBOR3m、十年国债收益率、以及AAA同业存单收益率，与流动性负相关，与（债券和存单的）价格净值负相关； 国内中长期流动性同步和滞后指标： M2同比-社融同比：反应的是货币供应量和实体经济融资的差速值。如果指数上行，意味着货币宽松，但是企业融资需求弱，表现是银行同业投资活跃，但是非标偏弱。同业投资主要投资固定收益类，非标是真实运用至实体经济的融资。所以，对股票而言这个剪刀差的直接影响是偏弱的，但对于债券利率表现是有效的指引。 商业银行总资产/央行总资产：反映的是银行和央行的资产增速差，指数上行说明商业银行较央行资产扩张更快，是为宽信用，反之 则为紧信用。 M1同比-PPI同比：M1 变化很多时期都是由地产销售驱动的，地产销售作为大额消费，居民往往需要贷款，然后会创造出相应的货币，转移为企业存款。所以当货币供给M1 改善时，往往背后伴随着地产销售改善。经济在地产周期的带动下可能走出衰退走向复苏，投资者基于这一点，会提前入场做复苏交易，从而推升股票价格。 M1-M2同比增速：M1的构成是企业活期存款和流通中的现金，由于可以随时支取，M2是广义货币供应量。指数上行：经济预期变好，企业和居民的活期存款增加，可能是宽货币转向宽信用的转变。考虑到M1和房地产销售的关系… 指数负向扩大可能代表资金在金融体系内部空转，后续可能转向宽货币 【图1】中短期流动性指标（10Y国债收益率/AAA同业存单一年收益率/MLF一年利率）：其中同业存单的收益率和SHIBOR3m基本一致，前二者（国债和同业存单收益率）放在一起作为观测指标，当两条线走势同时下行/上行时，对应流动性的宽松/收紧，两个指标的走势确定性更强 【图2】隔夜SHIBOR &amp; 3个月SHIBOR： ▷ 微观流动性 = 新发偏股型基金规模 + 北上资金净流入 + 融资余额 - 重要股东减持 - IPO募集 @ref: 2022 年 A 股“钱”从何处来？ - 华尔街见闻 （一）展望2023年，伴随美联储激进加息减缓，国内宏观经济与盈利回温带动市场摆脱资金困境，A股有望迎来近8000亿元的增量资金，其中：资金供给来源主要来自偏股公募基金净增量（约8000亿）、私募基金净增量（约5600亿）、保险资金股票配置（约4900亿增量资金），个人养老金产品（约105亿增量资金），杠杆资金（融资）净流入（约2500亿），外资（北向）净流入（约2700亿），散户资金净买（约3100亿）； （二）展望2023年资金需求： 股权融资需求将回升至1.77万亿元，其中IPO约6400亿，再融资约1.13万亿； 产业资本净减持规模可能会达到3700亿以上； 资金需求来源主要来自IPO（约6400亿）、再融资（约1.13万亿）与交易费用（约4100亿）。 《剩余流动性与资产表现》@tldr：探讨了几种“剩余流动性”指标的异同：M1-PPI同比增速差、M2同比-名义GDP同比、M2同比-社融余额同比等… 以及2022年，这几种流动性指标都较好，但今年资产（股债资产+房产）的走势却出现了背离的原因： 对于M1-PPI同比增速，以前之所以有效，是因为M1增速和房地产销售绑定较多，过去几轮经济周期M1增长都伴随着房地产销售的增长，新一轮地产周期启动，经济在地产周期的带动下可能走出衰退走向复苏，基于这种预期，股市情况可能有较好的表现；但今年M1增长并不是居民部门购房与消费驱动，主要贡献是金融部门、海外部门与政府部门。 对于M2同比-社融余额同比，其中同业投资和非标（同业拆借存单和非标准化债权），分别是两者最核心的两项，两者的剪刀差与M2同比-社融余额同比趋势基本一致。货币政策宽松、融资需求偏弱时，同业投资较为活跃，非标偏弱，此时剪刀差会趋于走阔，在这种环境下利率会趋于下行，剪刀差对债券利率表现有指引价值。但对股票而言，这个剪刀差的直接影响是偏弱的。 “剩余流动性”是金融市场研究中较为盛行的概念，它通常被认为是实体未吸收的、进入金融市场的货币规模。在实际应用中，M1 同比-PPI 同比、M2 同比-名义GDP 同比、M2同比-社融余额同比等指标均可用于度量。 “剩余流动性”越充裕，资产价格表现会越好；但今年明显不同，偏宽的货币与财政政策之下，M1 与M2 均有不同程度的改善，同时实体经济偏弱，M1 同比-PPI 同比、M2 同比-名义GDP 同比与M2 同比-社融余额同比等指标均明显走阔。我们该如何理解这一背离，“剩余流动性”扩张带来资产价格上涨这一逻辑是否成立？本文将对此做些探讨。 目前市场度量“剩余流动性”通常有三种方法。 一是用货币市场利率度量（十国债收益率 &amp; SHIBOR），认为货币市场利率处于较低水平，意味着流动性淤积在银行体系，流动性过剩； 二是用M1 同比-PPI 同比或M2 同比-名义GDP 同比度量，其中M1 同比与M2 同比表示货币供给，PPI 同比与名义GDP 同比代表实体经济消耗/需求的流动性，总供给扣减调实体经济消耗流动性即为可投资金融资产的剩余流动性； 三是用M2 同比-社融余额同比度量，认为社融表示实体经济的货币需求，货币总供给扣减实体经济的货币需求即为金融市场的剩余流动性。 我们重点关注后两种方法。第一种方法按照我们的流动性分析框架，代表的是银行体系流动性，是基础货币供需作用的结果，与后两种所指代的“存款货币”即广义流动性的剩余有本质区别，这一点我们在《宏观金融如何从入门到熟悉》一文有过详细介绍。 今年用后两种方法度量的“剩余流动性”都出现了明显改善。但是金融资产的表现却很差——万得全A 在今年前七个月下跌了12% … 在经济衰退时期，微观主体对货币的偏好会明显提升(倾向于保留现金)，货币会更多发挥价值贮藏职能，而不是在实体与金融市场上用于交易。因此，即便货币供给在逆周期调节政策作用下趋于扩张，实体经济仍偏弱，被创造出来的货币也不一定会进入金融市场，推升金融资产价格，而更有可能被微观主体持有 或沉淀在银行体系中。 既然“剩余流动性”对资产价格有指引作用这一逻辑存在缺陷，那么为什么经验数据显示M1 同比-PPI 同比、M2 同比-名义GDP 等剩余流动性指标与万得全A 确实存在相关性呢？我们理解，这背后主要原因在于这些“剩余流动性”指标主要是由货币供给M1 与M2 驱动，而货币供给M1 之所以会对资产价格有一定的指引价值，主要逻辑在于：M1 变化很多时期都是由地产销售驱动的，地产销售一则会带来居民存款向企业存款的转移，二则作为大额消费，居民往往需要贷款，这会创造出相应的货币，变成企业存款；地产销售在很多时期又是经济表现的“晴雨表”，是国内增长的重要驱动力。所以当货币供给M1 改善时，往往背后伴随着地产销售改善，新一轮地产周期启动，经济在地产周期的带动下可能走出衰退走向复苏，投资者基于这一点，会提前入场做复苏交易，从而推升股票价格。 今年正好是这一情景。稳增长政策虽然带来了基建投资的修复，但由于地产下行惯性与疫情影响，基本面偏弱的预期并没有发生明显变化。因此，即便稳增长政策带来了货币供给的扩张，投资者也不会因此入场做复苏交易，资产价格自然也就很难出现趋势性的上涨 今年上半年，M1 同比增速为5.8%，较2021 年末提升了2.3 个点。M1 主要由流通中现金M0 和企业活期存款组合，其中企业活期存款占比在80%以上，是M1 波动的主要来源。企业活期存款主要由五个来源，一是金融部门的融资；二是海外部门跨境收付；三是政府部门财政支出；四是企业部门内部定期转活期；五是居民部门购房与消费。 今年上半年M1 的升幅，显然不是居民部门购房与消费所致，其主要贡献是金融部门、海外部门与政府部门。 … 另一个用于度量“剩余流动性”的指标M2 同比-社融余额同比，其内涵和上述提及的M1 同比-PPI 同比以及M2同比-名义GDP 同比有显著不同。 从宏观视角粗略来看，M2 代表的金融机构负债端，社融代表的是金融机构资产端，两者的剪刀差代表的是金融机构资产负债的相对变化，如果M2同比-社融余额同比的剪刀差走阔，也就意味着金融机构负债端较为充裕，但资产端较为缺乏，金融机构出现了结构性资产荒，此时利率往往趋于下行。 M2主要是由存款组成，影响其变化的主要是四个因素：跨境收付（外汇占款）、银行信贷与投资信用债、银行投资政府债券、同业投资。这四个因素当中，跨境收付（外汇占款）与同业投资由于不是金融机构对实体的支持，因此不计入社融，只会单方面影响M2，会造成M2 与社融增速的差异。 社融主要由信贷、非标、企业债券融资、股票融资、政府债等项目组成。在这些项目当中，非标、非银投资的企业债券以及股票融资只会带来存款的转移，并不会创造出新存款，因此只会影响社融本身，并不会对M2 造成影响，也会导致M2 与社融增速不同。 总结而言，造成M2与社融增速差异的主要是前者的跨境收入（外汇占款）、同业投资、以及后者的非标和直接融资项。在这四个项目中，同业投资和非标是最核心的两项，两者的剪刀差与M2同比-社融余额同比趋势基本一致。 同业投资和非标（同业拆借存单和非标准化债权）主要受货币政策、金融政策和融资需求等因素影响，货币政策宽松、金融政策稳定与融资需求偏弱时，同业投资较为活跃，非标偏弱，此时M2 同比-社融余额同比剪刀差会趋于走阔，在这种环境下利率会趋于下行。所以，无论是从宏观视角粗略来看，还是从统计视角细致来看，最终我们都会发现M2 同比-社融余额同比主要是对债券利率表现有指引价值。对股票而言，这个剪刀差的直接影响是偏弱的。非标是真实运用至实体经济的融资，同业投资是银行表内的投资，主要投资固定资产收益类资产，直接投资到股票市场。 就2022这一年而言，制约资产价格中期趋势的核心变量之一是地产。如果在流动性领域要关注除“剩余流动性”和货币供给之外的相关变量，最核心的应是居民中长期贷款。宏观环境超预期；流动性环境超预期；但地产信用风险与疫情变化超预期导致货币供给周期重新回归被地产周期驱动的传统框架； @ref: 广发宏观：剩余流动性与资产表现__新浪财经 《关于股市剩余流动性的研究》@tldr：剩余流动性充裕，利好十年国债和小市值股票这两类资产，但信用风险降低（一般来说，经济复苏，信贷增加）正好相反 剩余流动性越多，无风险资产价格越高。以债券市场为例，十年国债为无风险资产，在无风险资产供给增速给定的情况下（ps：把无风险资产的供给列为次要因素），价格变化主要反馈了剩余流动性的变化。也就是说，十年国债的价格是一个十分好的剩余流动性的观测指标。 地产信用风险贡献了很大比例的信用风险，当我们提到信用风险的时候往往指的是地产信用风险。 真正像十年国债的品种并不是成长股，而是小市值板块。很多小市值股票的特征在于：既不能证实，也无法证伪。通俗的来讲，就是做个题材，炒个概念，业绩要N年后才能验证。这跟十年国债十分像，十年国债的特质在于：分子是固定的；对称的，小市值股票的特质在于：景气度无法质疑。因此，股市剩余流动性真正有效的标度是小市值指数，4.27股市见底以来，小市值指数持续上涨，累计上涨了33%+。这反馈了股市剩余流动性泛滥的局面。 1、小市值指数测度股市剩余流动性； 2、价值板块走势测度信用风险在股市的影响； 3、债市和股市是同构的，同时反馈系统的信用风险分布； 尽管并不是所有投资者都同意这个结论——地产政策对小市值板块是利空，但是，市场总体是按照这个逻辑运行的。 @ref: 关于股市剩余流动性的研究|流动性_新浪财经","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"股市","slug":"股市","permalink":"https://beefyheisenberg.github.io/tags/股市/"},{"name":"社融","slug":"社融","permalink":"https://beefyheisenberg.github.io/tags/社融/"},{"name":"M2","slug":"M2","permalink":"https://beefyheisenberg.github.io/tags/M2/"},{"name":"A股","slug":"A股","permalink":"https://beefyheisenberg.github.io/tags/A股/"},{"name":"债市","slug":"债市","permalink":"https://beefyheisenberg.github.io/tags/债市/"},{"name":"剩余流动性","slug":"剩余流动性","permalink":"https://beefyheisenberg.github.io/tags/剩余流动性/"}]},{"title":"F30e.股市与宏观经济的关系","slug":"52.Financing/F30e.股市与宏观经济的关系","date":"2024-01-24T01:27:53.389Z","updated":"2024-01-24T01:27:53.390Z","comments":true,"path":"52.Financing/F30e.股市与宏观经济的关系/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F30e.股市与宏观经济的关系/","excerpt":"经济基本面和大盘的相关性背离的原因一国的经济增长和股市回报没有必然的关系，有时候甚至有负相关关系。国家经济增速越快，股市回报未必更好。在发达国家中，两者之间甚至有微弱的负向关系：也就是说国家经济增速越快，股市回报反而越差。可能有以下几个原因： 有不少国家的经济开放程度很高，其股市回报来自于一些规模很大的跨国企业。这些跨国企业的收入并不仅仅局限于他们总部所在的母国。 美国的经济增速，当然会影响到标准普尔500指数的表现。但是该股票指数的回报，不仅受到美国经济的影响，还受到世界其他国家和地区的经济表现的影响。 再以代表韩国股市的韩国综合股价指数KOSPI 200为例来分析一下这个问题。在KOSPI 200指数中，占比最大的公司为韩国三星（Samsung），其市值大约占到KOSPI 200指数的30%左右，然而我们如果仔细分析三星公司的销售收入，就会发现这是一家高度全球化的公司。如上图所示，三星公司从韩国国内得到的销售收入，仅占全集团年销售收入的10%。因此，韩国股市（KOSPI）的表现，和韩国本国经济的盛衰关系不大，就不那么难以理解了 其次股市具有前瞻性，炒的都是预期 —— “Buy the rumor, sell the fact”，预期主要反映在股票的估值上。当一国经济处于高速增长期的时候，资产升值和信贷的扩张，导致大众情绪无比高涨和乐观，对风险溢价的承受也增长 —— 更多的钱进入股票市场，因此整个股市的估值也会偏高。这个时候的股票市场，已经把未来的高速发展预期消化进了价格。因此在这个时候如果购进股票，只要未来的经济发展比预期来的低，投资回报就会受到影响。 经济增长的动力和股市回报的来源不同。对于经济的增长，根据美国经济学家克鲁格曼（Krugman, 1994）的研究，他将过去50年东亚国家的经济增长归因于：比较高的个人储蓄率，劳动力参与率的增加，以及教育和医疗的进步。这些改善都极大的提高了国民的生活水平，但它们却未必有利于资本所有者（股东）。主要原因在于很多新兴的科技变革都来自于新兴企业，对原有的行业造成了冲击，而未必会增加那些“老公司”的价值。还有一种情况，是带来变革的新公司不在本国内上市。以中国为例，为中国社会带来变革的最多的几家科技企业，比如阿里巴巴，百度，腾讯，京东等，他们全都在海外上市。因此虽然这些公司为中国的经济增长做出了不少贡献，但作为国内A股的股东却无法享受到这些成长的红利。 另外，一国家股市的行业偏重也会影响经济对股市市值的影响，举例来说，德国股票指数DAX中，化工类股票（巴斯夫BASF和拜尔BAYER）占的权重特别大，因此德国股市和化工行业的景气程度息息相关。瑞士股市指数中的医疗类股票（诺华制药Novartis和罗氏制药Roche）权重很高，因此瑞士股市的表现受医药行业影响最大。西班牙股指中的银行股（桑坦德Santander和毕尔巴鄂比斯开银行BBVA）特别重，因此其股价表现和金融行业的表现紧密相关。对比A股，流动市值最大的板块：消费、医药、金融、电子、制造，但高成长性的科技类（CXO多在港股、互联网多在港股和美股）不在沪深上市。 @ref: 股市和经济是怎样一种关系？ - 知乎","text":"经济基本面和大盘的相关性背离的原因一国的经济增长和股市回报没有必然的关系，有时候甚至有负相关关系。国家经济增速越快，股市回报未必更好。在发达国家中，两者之间甚至有微弱的负向关系：也就是说国家经济增速越快，股市回报反而越差。可能有以下几个原因： 有不少国家的经济开放程度很高，其股市回报来自于一些规模很大的跨国企业。这些跨国企业的收入并不仅仅局限于他们总部所在的母国。 美国的经济增速，当然会影响到标准普尔500指数的表现。但是该股票指数的回报，不仅受到美国经济的影响，还受到世界其他国家和地区的经济表现的影响。 再以代表韩国股市的韩国综合股价指数KOSPI 200为例来分析一下这个问题。在KOSPI 200指数中，占比最大的公司为韩国三星（Samsung），其市值大约占到KOSPI 200指数的30%左右，然而我们如果仔细分析三星公司的销售收入，就会发现这是一家高度全球化的公司。如上图所示，三星公司从韩国国内得到的销售收入，仅占全集团年销售收入的10%。因此，韩国股市（KOSPI）的表现，和韩国本国经济的盛衰关系不大，就不那么难以理解了 其次股市具有前瞻性，炒的都是预期 —— “Buy the rumor, sell the fact”，预期主要反映在股票的估值上。当一国经济处于高速增长期的时候，资产升值和信贷的扩张，导致大众情绪无比高涨和乐观，对风险溢价的承受也增长 —— 更多的钱进入股票市场，因此整个股市的估值也会偏高。这个时候的股票市场，已经把未来的高速发展预期消化进了价格。因此在这个时候如果购进股票，只要未来的经济发展比预期来的低，投资回报就会受到影响。 经济增长的动力和股市回报的来源不同。对于经济的增长，根据美国经济学家克鲁格曼（Krugman, 1994）的研究，他将过去50年东亚国家的经济增长归因于：比较高的个人储蓄率，劳动力参与率的增加，以及教育和医疗的进步。这些改善都极大的提高了国民的生活水平，但它们却未必有利于资本所有者（股东）。主要原因在于很多新兴的科技变革都来自于新兴企业，对原有的行业造成了冲击，而未必会增加那些“老公司”的价值。还有一种情况，是带来变革的新公司不在本国内上市。以中国为例，为中国社会带来变革的最多的几家科技企业，比如阿里巴巴，百度，腾讯，京东等，他们全都在海外上市。因此虽然这些公司为中国的经济增长做出了不少贡献，但作为国内A股的股东却无法享受到这些成长的红利。 另外，一国家股市的行业偏重也会影响经济对股市市值的影响，举例来说，德国股票指数DAX中，化工类股票（巴斯夫BASF和拜尔BAYER）占的权重特别大，因此德国股市和化工行业的景气程度息息相关。瑞士股市指数中的医疗类股票（诺华制药Novartis和罗氏制药Roche）权重很高，因此瑞士股市的表现受医药行业影响最大。西班牙股指中的银行股（桑坦德Santander和毕尔巴鄂比斯开银行BBVA）特别重，因此其股价表现和金融行业的表现紧密相关。对比A股，流动市值最大的板块：消费、医药、金融、电子、制造，但高成长性的科技类（CXO多在港股、互联网多在港股和美股）不在沪深上市。 @ref: 股市和经济是怎样一种关系？ - 知乎 1）长期看，A股反映了宏观经济持续高增长的态势，一定程度上起到了晴雨表的作用。从1991年（基期为1990年12月29日）创立时100点左右的水平到2021年12月31日的3639.78点，历经31年上涨了35倍，年化增长率为12.3%，同期名义GDP年化增长率为13.6%，整体上契合宏观总量数据的情况。其他主要指数也表现出相似的规律，例如2005-2021年，沪深300、中证500分别上涨4.0倍和6.5倍，年化增速为10.0%和12.5%，同期名义GDP年化增速为11.2%。从相关系数来看，股指与实体经济发展的相关性较强，1992至2021年上证指数和GDP定基指数的相关系数约0.7。 2）2010年后股指走势与经济基本面出现较大背离，上证指数表现尤其突出，投资者因此形成“A股十年不涨”的观感。2010年以来，我国经济增速稳中有进，领先其他主要经济体，但上证综指的变化幅度却不大，2015年“快牛”行情后持续波动，与我国经济状况不相匹配。2010-2021年上证指数仅上涨12.2%，年化增长率1.0%，同期名义GDP年化增速约8%。沪深300、中证500等其他宽基指数表现相对较好，但整体涨幅仍偏低，大约在3%-5%之间。从相关系数看，2010至2021年间上证指数与名义GDP定基指数的相关系数仅为0.4。 发达资本市场中股指与实体经济的关联性普遍更强。美国道琼斯工业指数、标普500指数从1947年至2021年分别上涨了204倍和313倍，年化增长率分别为7.4%和8.0%，同期名义GDP增速为6.2%，两者间的相关系数高达0.9。 尤其是在代表性历史阶段，这种同涨同跌的关系表现得格外突出。例如大萧条时期（1929-1933年），GDP大幅下挫，同比增速深度负值，道琼斯指数从381点的高位跌至仅40点水平。 又如，1993-2001年，美国经历了高速增长的黄金时期，高基数下GDP仍保持年均4%的增速，道琼斯指数也经历了长达8年的上涨。 股指长期不涨的现象并非A股独有。例如，1966-1982年美国道琼斯工业指数基本徘徊在1000点左右；又如韩国KOSPI200指数于2011-2017年间基本在250点上下震荡。当然我们也必须认识到，海外成熟市场股指长期不涨的背后往往经济基本面也出现了问题，如美国1970-1982年基本处于滞胀阶段，而我国上证指数等近十年不涨则发生在经济总体强势的背景下，因此背后的原因仍需进一步深究。 @ref: 粤开证券-【粤开宏观】A股走势与宏观经济：一致与背离的原因 一致的原因正经历的2021年~2022年的牛转熊，和经济基本面见顶有着密切的关系： 因为长期来说，大盘的收益是来源于A股上市公司的利润创造和增长： 而上市公司们的业绩会受到宏观经济大环境的影响： @ref: 啥时候会有新一轮牛市？ 经济 &amp; 股市指标的相关性基础分析框架 剩余流动性-盈利框架 // 见下 “货币-信用”分析框架 // 见下 盈利指标：PMI &amp; 工业企业利润PMI 和 工业企业利润代表企业盈利，是“剩余流动性-盈利框架”中表示盈利性的指标。 观察近20年股市和PMI的关系，得出以下结论： PMI触底（同时期也在经济衰退）股市大概率也触底； PMI反应了一种对经济的预期，当PMI还处于荣枯线以下但有触底向上的趋势时（或者遇上宽货币），股市也会因为“炒预期”而上涨，但如果PMI复苏不符合预期，炒预期的势头则无法持续下去，股市一般会转头下跌； 所以A股和实体经济的关系可以概括为：经济好 or 经济预期变好，股市才有上涨的可能性。后者预期可能包括：PMI势头良好（始终处于50%荣枯线以上）或者 PMI处于衰退期间但货币宽松。 流动性指标：SHIBOR &amp; 国债收益率参考 F30e1.关于剩余流动性中的“国内中短期流动性”部分 货币指标：M1 &amp; M2M1-M2剪刀差，即M1同比增速-M2同比增速，M1的构成是企业活期存款和流通中的现金，由于可以随时支取，M2是广义货币供应量。 M1-M2 &amp; 经济的相关性 如果企业对未来增长前景乐观，准备补库存或者扩大资本开支的话，企业会选择将存款活期化，以随时应对补库存和扩大资本开支所需要的现金，这个时候企业账户上活期存款的部分占比会相对较高，M1-M2（同比增速）剪刀差就会扩大（↑） 相反，如果企业对未来预期谨慎，对增长前景悲观，企业会更倾向于低风险的金融投资，将存款定期化，或者买货基、保本银行理财、大额存单等，这个时候M1会向M2转化，M1-M2（同比增速）剪刀差就会收窄（↓） M1-M2同比增速剪刀差负向扩大（M2的增速大于M1增速）还可能代表资金在金融体系内部空转 除此之外，房地产销售转好也会导致M1-M2同比差值扩大：在一手房认购时，居民部门购买开发商新盘，实际等同于居民部门的储蓄存款（M2）转向了企业部门的存款。 在运用这一指标的时候，有一点需要注意，那就是在春节期间，由于工资奖金支付的需要，企业的活期存款会大幅转向居民储蓄存款。如果春节时间错位，则会对M1同比读数产生较大的扰动。为了消除这种干扰，我们一般会对每年1月和2月的M1余额数据做平均处理。 我们以工业增加值与PPI之和来近似拟合名义经济增长水平，会发现M1-M2（同比增速）差值确实对增长具有一定领先性，且拟合度较高： @ref: 什么才是读懂社融、M2的正确姿势？请收好这份金融数据分析手册 - 华尔街见闻 M1-M2 &amp; 股市的相关性M1-M2增速剪刀差 vs 上证指数：数据来源：https://legulegu.com/stockdata/broadmoney 观察近20年上证指数和M1-M2剪刀差的关系，得出以下结论： M1-M2剪刀差的底部，与沪市的底部是几乎同步的：剪刀差由负转正的过程中，股市也有较好表现； M1-M2剪刀差的顶部，往往先于股市的顶部出现； 当实体经济在正常状态时（M1-M2剪刀差处于-5%~5%之间），观察到M1-M2剪刀差大幅下滑，则有股市顶部的指导意义。 当实体经济在被动持币的状态里挣扎时（M1-M2剪刀差小于-5%），观察到中长期贷款余额（贷款余额指：至某一节点日期为止，借款人尚未归还放款人的贷款总额。）持续回升（经验是至少4个月连续上涨，也即同比持续为正）具有股市底部的指导意义。@ref: https://mp.weixin.qq.com/s/d6F-S3_qJ65FcX6z2CjOYA @ref: 卢平：M1-M2增速差修复，股市表现皆上涨 M1与M2只是货币供应量的不同维度，大概率应为同向，但是由于经济演化过程中的变数，M1的波动率更大，M2作为央行货币政策中介目标，其变化相对于M1更加稳定，从而导致M1和M2的增速不一致。 一、经济出现危机时，较高的M2增速用于恢复经济： 我国央行货币政策的中介目标是盯住M2，平时媒体和研究报告讨论M2增速比较多，一般M2增速与GDP增速挂钩，常见的说法是，货币政策要保持M2增速与GDP增速基本匹配。即：M2增速=GDP增速+CPI+其他溢价因素。 每次经济出现危机后，政府一般通过宽松的货币政策和财政政策支持实体经济的恢复。在货币政策方面通过降准降息来达到货币量的扩张和货币价格的降低，即通过“双降”政策来达到货币“量增价跌”。货币宽松，央行大量释放流动性，过量供给货币，M2增速较高，远远超过匹配的经济增速。 二、对经济未来预期不同导致M0、M1和M2货币增速不一致： M1的增速主要由单位活期存款增速决定：M1中，M0占M1的比例大约13.5%，单位活期存款占M1的比例接近86.5%，而且M0的增速相对稳定，因此M1的增速主要由单位活期存款的增速决定，从图上看二者的增速基本一致。因此M1增速一般可以看做资金活性指标，也代表了企业进行投资购买的准备金，因此该项指标与经济走势息息相关。 M2的增速由个人存款和单位定存增速决定：对M2增速影响最大的是个人存款（42%）和单位定期存款（19%）（两者占比大约60%）。这就是前面说的投资因素，个人存款一般通过银行贷款给企业，满足企业的投资需求，单位定存大致对应企业的投资需求。 单位活期存款增速波动剧烈，使得货币供给的三个指标中 M0和M2相对稳定，M1剧烈波动。 三、货币政策宽松后M1-M2增速的变化： 每次经济出现危机后，央行通过降息降准等宽松的货币政策，为社会注入大量的流动性，一般会把提高M2的增速作为中介目标。为了更好的理解信贷资金的流转过程，我们把流转分为两步：第一步：信贷资金最初的流向为个人，企业，政府。流向个人的资金形成M2，流向企业的资金，如果是活期则为M1，如果是定期，则为M2，流向政府的资金成为M2。第二步：资金在个人，企业和政府之间流转，可以通过M1和M2的增速变化来进行描述。 第一阶段：M1的增速远低于M2的增速，M1-M2为负且负值最大。M2过高，而M1过低，表明投资过热，需求不旺，存在资产泡沫风险，这就是股票市场中估值提升阶段行情。 第二阶段：M1的增速逐渐追上M2的增速，M1-M2负值逐渐收窄至零。随着央行和商业银行大量释放流动性后，经济的逐步好转。企业的活期存款增加，定期存款减少，个人的存款也由于消费增加趋向于减少，所以看到的货币结构就是M1（企业活期存款增加）增速大幅度提升，逐渐追上M2的增速。 第三阶段：M1的增速超过M2的增速，M1-M2为正且逐步抬升。反映的企业的活期存款大幅增加，背后的逻辑就是大量库存销售变成了现金，企业进入被动去库阶段，而企业也将资金大量活化用于采购原材料增加生产。实体经济开始变得过热了。 经济最重要的流转：就是M2向M1的转化，在这个过程中，我们能看到的就是： 物价：M1-M2增速上升，PPI价格上涨，企业盈利好转， 产量：GDP和工业增加值等的增速不断提升。 库存：M1-M2增速上升，企业库存被动去库，到主动补库，到被动去库。 股市：M1-M2增速上升，股市由货币超发的估值驱动，经过观望盘整后，逐步过渡到业绩驱动。 M1-PPI &amp; 经济的相关性M1-PPI的解析详见：F30e1.关于剩余流动性 信用指标：社融社融的定义，以及社融同M2的历史数据 =&gt;详见 F23a.M2和社融 新增社融 &amp; 股票资产的相关性新增社融增速（以六个月移动平均为计算标准）有40个月左右的周期运行规律。每隔40个月左右新增社融增速会转正并加速上行进入到上行周期，随着新增社融增速转正并进入上行周期，A股也将开启两年半的上行周期。当然到新增社融增速转负之后，A股表现将会更加平淡，甚至不排除有出现回撤的可能，如此一来A股存在三年半左右的周期运行规律。 A股历史上5个重要的低点2005年9月、2008年12月、2012年年底、2016年1月份、2019年1月份均是发生在新增社融增速转正之后，A股在一个季度之内见到大底。但是2005年9月，2008年12月，2019年1月都是新增社融增速转正当月同时A股出现大涨，而2012年9月 和2016年1月市场见底滞后于新增社融增速转正的时间一个季度，这个差异来自于何处呢？ 从历史上来看中美利差对于A股尤其是权重股（北向喜欢的蓝筹）有一定影响，沪深300指数的走势与中美利差有趋同之处，同时历史上比较大的调整多次出现在中美利差缩窄至120个bp以内 // HS300和中美利差走势的趋同，究其原因是，中美国债利差缩小意味着资本流出A股、流入美债/美元市场的风险增大，对A股造成冲击。 2012年9月上证50指数见底、2016年1月指数见底、2019年1月指数见底，都发生了相似的情况，美联储释放了鸽派信号，美债收益率加速下行，中美利差迅速扩大，而A股也就相应见底进入到上行周期。所以，新增社融增速转正作为国内因素指引A股见底，但是A股并不见得是在新增社融增速转正当月就一定见到底部，还不得不考虑外部环境。 @ref: 新增社融增速转正与A股转机 - 华尔街见闻 社融-M2 &amp; 债类资产的相关性“社融-M2”增速差反映了货币供需矛盾间的较量，是利率的先行指标，当增速差扩大，利率水平预计将随之抬升。 根据我们此前对于社融和M2的理解，二者增速差值走阔，表明实体经济的融资需求或资产扩张速度快于银行M2的派生扩张速度，信用主体对货币的需求更加旺盛，因此对应更高的资金价格（导致银行间拆借率上行，利率上行，宽货币→宽信用的转变），并最终反映到利率这个衡量指标。 若无基础货币的超预期紧缩或扩张，理论上社融-M2同比增速差应当与10年期国债收益率呈现出正相关关系。历史数据同样支持“社融-M2”背后的信用-货币观点，且我们发现“社融-M2”的拐点相对靠前，对于债市走势有较好的风向标意义。 社融-M2剪刀差开始上行后，利率也会随之上行，是“宽信用-紧信用”转换的前置信号： @ref： 解读社融-M2剪刀差背后的债市密码 M2-社融 &amp; 股/债的相关性-剩余流动性框架入门 关于剩余流动性的更多内容 =&gt; F30e1.关于剩余流动性 流动性可以说是金融市场含义最丰富的概念之一了。它大致可以分成四大层级（并无包含与被包含的关系）—— 那怎么才能了解市场流动性的情况呢？ 一方面我们可以看换手率（交易量÷总市值），这个可以反映市场活不活跃，换手率高则生龙活虎，换手率低则死气沉沉。 另一方面我们可以计算净流入资金，拿新发基金规模、北上资金净流入、融资规模等流入的资金量，减去重要股东减持、交易费用、IPO募集规模等流出的资金量。 这样做的好处是非常直观、容易理解。而且虽然看着指标有点多、算起来也麻烦，但其实我们可以直接用券商策略分析师算好的数据。只是要注意得用同一家券商的，这样才能做不同时间段的比较。因为不同券商口径存在细微差别，算出来的数字也是不一样的。 其实，我们还可以推算出，投资者们短期内还有多少子弹可能会打向股市。想搞清楚投资者们手里还有没有子弹，我们得引入一个新概念——剩余流动性。剩余流动性就是从宏观流动性里头，剔除实体部门流动性需求后剩下的部分，也就是金融市场的流动性。至于如何衡量剩余流动性，我们给出的方案是用 M2同比增速-社融存量同比增速 来判断。 选股还是选债，这里可以引入我们的投资决策框架——剩余流动性-盈利框架，至于盈利方面，可以用 PMI和 工业企业利润两个高频指标结合来看。// 对比「货币-信用周期」 情况1：剩余流动性充裕+盈利情况很好，这种情况一般发生在经济的复苏期 情况2：剩余流动性充裕+盈利情况不行，这种情况一般出现在经济的下行期 情况3：剩余流动性不足+盈利情况很好，这种情况一般见于经济的过热期 情况4：剩余流动性不足+盈利情况不行，滞胀期，一般比较少见 @ref: 为啥央妈放水也救不了股市 中长期贷款余额@todo: 中长期贷款余额与存量社融的关系是？ 为什么关注中长期贷款增速？在“货币-信用”分析框架中，以社融为代表的信用增速是重要观测目标之一。而社融余额增速在衡量实体经济信用扩张意愿时可能存在一些需要关注的点，一方面，政府债发行与支出存在一定时滞，发行时计入社融并不意味着资金流入经济体系；另一方面，宽信用初期新增信贷中短期贷款和票据融资占比较高，因此，中长期贷款余额增速相对社融增速可能对货币政策解释效果更好。我们对比了2015 年以来中长期贷款余额增速和社融存量增速背离的三个时期（2016.5-2017.9，2018.12-2019.8，2021.9-2022.5）DR007 走势均与中长期贷款增速方向一致。在拐点方面，中长期贷款增速拐点整体领先于资金利率拐点。从2016Q4 和2020Q2 资金利率上行时的情况，我们大致可以得出这样一个规律：当中长贷增速接近或超过中长期趋势值时，资金价格抬升概率上升。@ref: https://stock.finance.sina.com.cn/stock/go.php/vReport_Show/kind/search/rptid/710928074495/index.phtml 中长期贷款余额数据每季度发布一次，通常滞后1个月内发布： 2022年一季度金融机构贷款投向统计报告部门政务中国政府网：工业中长期贷款余额14.39万亿元，同比增长20.7% 2022年二季度金融机构贷款投向统计报告数据快递中国政府网：工业中长期贷款余额15.25万亿元，同比增长21.2% 2022年三季度金融机构贷款投向统计报告部门政务中国政府网：工业中长期贷款余额16.08万亿元，同比增长23.3% 股市风格与宏观经济的关系股市的风格切换（大盘/小盘、价值/成长）与流动性、经济增长、资本风险偏好有如下关系： ▷ 宽货币（充裕的流动性）则会影响股市的大小盘风格： • 流动性好（SHIBOR下行区间），利好 小盘股；• 经济从衰退→ 复苏（PMI上行），流动性收紧，利好 大盘股 （2017年）；• 经济衰退+流动性也不好，股市跌，但大盘股更抗跌 ▷ M1-M2剪刀差在一定程度上同步反应了投资的风险偏好，二者呈正比关系： • M1-M2剪刀差为正值且走阔，表示投资风险偏好的上升，成长股 往往优于 价值股，同样剪刀差从过热区间回落到正常区间，风险偏好降低，市场转向为价值风格（例如2020~2021，剪刀差显著回升，叠加同期美联储的超级QE，创业板牛市）； ▷ 同样股债利差（股权风险溢价）and 成长指数PE百分位，也可以用来预测风险偏好： • 当指标偏离中位数过多时（意味着风险极高），成长股可能出现回调，同时市场向价值风格切换； @link: F30a1.A股方法论zz：风格轮动 F12.基金101：主动基金的风格","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"股市","slug":"股市","permalink":"https://beefyheisenberg.github.io/tags/股市/"},{"name":"社融","slug":"社融","permalink":"https://beefyheisenberg.github.io/tags/社融/"},{"name":"M2","slug":"M2","permalink":"https://beefyheisenberg.github.io/tags/M2/"},{"name":"A股","slug":"A股","permalink":"https://beefyheisenberg.github.io/tags/A股/"},{"name":"债市","slug":"债市","permalink":"https://beefyheisenberg.github.io/tags/债市/"},{"name":"剩余流动性","slug":"剩余流动性","permalink":"https://beefyheisenberg.github.io/tags/剩余流动性/"}]},{"title":"F30d1.股市择时指标-量化回测","slug":"52.Financing/F30d1.股市择时指标-量化回测","date":"2024-01-24T01:27:53.384Z","updated":"2024-01-24T01:27:53.384Z","comments":true,"path":"52.Financing/F30d1.股市择时指标-量化回测/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F30d1.股市择时指标-量化回测/","excerpt":"@ref: 中金|先发制人：A股左侧择时指标探讨|先发制人_新浪财经 几种左侧择时指标：估值百分位、股权风险溢价（股债收益差）、期权认沽认购比、融资融券增长比、中国波指（50ETF恐慌指数, VIX）、北向资金、前后成交额差异… 左侧指标的选取原则 1）能够从逻辑上反映股市短期价格对其内在价值的偏离。当指标处于极端状态时，可以一定程度反映股市短期价格相比于其内在价值的显著过高/过低状态，从而在未来会有价格走势反转的出现。 2）指标具有均值回复性。如果指标没有一个明确的中枢位置，则我们无法判断指标当前取值的过高/过低状态；如果指标没有在极值状态下向中枢收敛的特征，则我们无法根据当前的高低状态来预测未来股市的反转出现。 3）指标具有平稳性。平稳性保证了指标的方差不随时间推移而改变。如果指标的方差随时间而改变，如呈现逐渐增大的趋势，则过去指标取值的极端状态在当前可能只是个中间状态，从而使指标状态的可参考意义下降。 出于此考虑，我们在下文中，将从逻辑性、均值回复性和平稳性三个角度，来选择股市的左侧择时指标，并最终根据各指标的实际应用效果，挑选出10个实战效果较好的指标。这10个指标可以分为三个大类：估值水平、市场情绪和资金流向。","text":"@ref: 中金|先发制人：A股左侧择时指标探讨|先发制人_新浪财经 几种左侧择时指标：估值百分位、股权风险溢价（股债收益差）、期权认沽认购比、融资融券增长比、中国波指（50ETF恐慌指数, VIX）、北向资金、前后成交额差异… 左侧指标的选取原则 1）能够从逻辑上反映股市短期价格对其内在价值的偏离。当指标处于极端状态时，可以一定程度反映股市短期价格相比于其内在价值的显著过高/过低状态，从而在未来会有价格走势反转的出现。 2）指标具有均值回复性。如果指标没有一个明确的中枢位置，则我们无法判断指标当前取值的过高/过低状态；如果指标没有在极值状态下向中枢收敛的特征，则我们无法根据当前的高低状态来预测未来股市的反转出现。 3）指标具有平稳性。平稳性保证了指标的方差不随时间推移而改变。如果指标的方差随时间而改变，如呈现逐渐增大的趋势，则过去指标取值的极端状态在当前可能只是个中间状态，从而使指标状态的可参考意义下降。 出于此考虑，我们在下文中，将从逻辑性、均值回复性和平稳性三个角度，来选择股市的左侧择时指标，并最终根据各指标的实际应用效果，挑选出10个实战效果较好的指标。这10个指标可以分为三个大类：估值水平、市场情绪和资金流向。 图1：几种左侧指标的构建方法和逻辑 图2：预测收益的左侧指标，三个不同维度 图3：左侧指标效果（胜率、盈亏比） (1)估值分位：沪深300指数估值分位，计算方法为先求沪深300市盈率和市净率的滚动5年分位数，然后求两者的平均值。 从均值回复性来说，沪深300指数的市盈率和市净率并没有特别好的均值回复性。以市盈率为例，2005~2011年沪深300指数的平均市盈率为22.17x，2012年至今则为12.22x，取值中枢显著下降。因此，我们对沪深300指数的市盈率和市净率进行了滚动5年分位数处理，从而将其标准化为0~1之间的取值，此时2005~2011年沪深300指数市盈率平均分位数为0.51，2012年至今为0.48，均值回复性显著增强。从上文可以看到，估值分位指标在0.9以上时，未来沪深300指数有较为明显的下跌；当估值分位指标在0.1以下时，未来沪深300指数虽没有明显上涨，但整体也维持正收益。 当指标在0.9以上时，做空沪深300，直到指标恢复到0.75以下，恢复平仓。当指标在0.1以下时，做多沪深300，直到指标恢复到0.25以上，恢复平仓。 指标历史上共看空3次，胜率66.67%，但拥有较高的盈亏比；指标历史上共看多6次，胜率83.33%，不过盈亏比相对较低，这与2011/4/30~2013/2/2看多期间中的较高跌幅有关。 (2)股权风险溢价(股债利差): 计算方法为先求沪深300盈市率与10年期国债到期收益率之差，然后求其在自身过去5年分位数。 股权风险溢价指标在0.05以下时，未来沪深300指数有较为明显的下跌；当股权风险溢价指标在0.9以上时，未来沪深300指数虽没有明显上涨，但整体也维持正收益。 当指标在0.05以下时，做空沪深300，直到指标恢复到0.25以上，恢复平仓。当指标在0.9以上时，做多沪深300，直到指标恢复到0.75以下，恢复平仓。 指标历史上共看空3次，胜率66.67%，拥有较高的盈亏比；指标历史上共看多5次，胜率60%，同样盈亏比较高。与同属估值水平的第一个指标“估值分位”相比，股权风险溢价指标的看空情况基本类似，看多时胜率略有下降，但盈亏比有所上升。 (3)期权认沽认购比：第三个指标为市场情绪维度的期权认沽认购比，计算方法为50ETF所有看跌期权合约当日总成交量除以所有看涨期权合约当日总成交量。 从上文可以看到，当期权认沽认购比指标在0.5以下时，未来沪深300指数有较为明显的下跌；当期权认沽认购比指标在1.2以上时，未来中长期沪深300指数有较为明显的上涨。同时，从期权认沽认购比指标的历史走势可以看到，指标的均值回复性过强，从而使得指标易在短期内出现快速波动，不适合使用前文所讨论的两个指标所采用的“动态区间”择时方法。 当指标在0.5以下时，做空沪深300指数63个交易日，之后恢复平仓。如果期间再次触发看空信号，则重新看空63个交易日；如果期间触发看多信号，则转为看多。当指标在1.2以上时，做多沪深300指数63个交易日，之后恢复平仓。如果期间再次触发看多信号，则重新看多63个交易日；如果期间触发看空信号，则转为看空。 指标历史上共看空4次，胜率75%，盈亏比接近1；指标历史上共看多5次，胜率80%，盈亏比较高。整体来看，期权认沽认购比指标具有较好的多空择时效果 (4)融券余额增长率：计算方法为全市场融券余额近21日增长率减去全市场流通市值近21日增长率，然后将时间序列做5期移动平均，再求其在自身过去5年的分位数。 从逻辑性来说，当融券余额增长率较高时，意味着市场看跌情绪过强，未来可能会有反弹；当融券余额增长率较低时，意味着市场看跌情绪过弱，未来可能会有调整。 当指标在0.1以下时，做空沪深300指数21个交易日，之后恢复平仓。如果期间再次触发看空信号，则重新看空21个交易日；如果期间触发看多信号，则转为看多。当指标在0.95以上时，做多沪深300指数21个交易日，之后恢复平仓。如果期间再次触发看多信号，则重新看多21个交易日；如果期间触发看空信号，则转为看空。 指标历史上共看空21次，胜率61.90%，盈亏比为1.28；指标历史上共看多5次，胜率100%，具有较好的上涨预测效果。 (5)中国波指：第五个指标为市场情绪维度的中国波指，计算方法为基于50ETF期权所计算的VIX指数。 从逻辑性来说，与美国市场“慢涨急跌”不同，A股市场具有较为显著的“急涨慢跌”特征，因此中国波指往往在牛市中拉升，并在牛市末期达到极大值，而在熊市中降低，并在市场磨底期达到极小值。即当中国波指较高时，可能市场未来会有调整，而当中国波指较低时，可能市场未来会有反弹。 (6)创新高个股占比：计算方法为当日复权收盘价创历史新高的个股数量，占当日总上市股票数量的比例，计算时剔除上市5个交易日内的股票。 从逻辑性来说，当大量个股创新高时，意味着市场可能处于过热状态，未来有更大的概率出现调整；当几乎没有个股创新高时，意味着市场可能处于过冷状态，未来有更大的概率出现反弹。 当指标大于40%时，做空沪深300指数63个交易日，之后恢复平仓。如果期间再次触发看空信号，则重新看空63个交易日；如果期间触发看多信号，则转为看多。当指标为0时，做多沪深300指数63个交易日，之后恢复平仓。如果期间再次触发看多信号，则重新看多63个交易日；如果期间触发看空信号，则转为看空。 (7)重要股东减持： (8)北向资金净流入：第八个指标为资金流向维度的北向资金净流入，计算方法为北向资金近5个交易日净流入之和。 从逻辑性来说，北向资金大幅净流入时，意味着市场可能处于过度乐观状态，未来可能会出现调整。北向资金大幅净流出时，意味着市场可能处于过度悲观状态，未来可能会出现反弹。 当指标大于500亿元时，做空沪深300指数21个交易日之后恢复平仓。如果期间再次触发看空信号，则重新看空21个交易日；如果期间触发看多信号，则转为看多。 当指标小于-500亿元时，做多沪深300指数21个交易日，之后恢复平仓。如果期间再次触发看多信号，则重新看多21个交易日；如果期间触发看空信号，则转为看空。 指标历史上共看多1次，胜率100%；指标历史上共看空3次，胜率100%。从结果看，北向资金净流入指标整体具有较好的多空择时效果。 (9)资金流向维度的偏股基金募资额：计算方法为偏股型基金近7个日历日的发行份额。 从逻辑性来说，偏股型基金发行火热时，意味着大量资金涌入股市，市场处于过热状态，未来可能会出现调整。偏股型基金发行冷清时，意味着市场情绪处于过于悲观状态，未来可能会出现反弹。 当指标大于1000亿元时，做空沪深300指数21个交易日，之后恢复平仓。如果期间再次触发看空信号，则重新看空21个交易日。其余时间，维持平仓状态。 指标历史上共看空5次，胜率80%，盈亏比58.29。从结果看，偏股基金募资额指标整体具有较好的下跌判断效果。","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"A股","slug":"A股","permalink":"https://beefyheisenberg.github.io/tags/A股/"},{"name":"择时","slug":"择时","permalink":"https://beefyheisenberg.github.io/tags/择时/"},{"name":"股市估值","slug":"股市估值","permalink":"https://beefyheisenberg.github.io/tags/股市估值/"},{"name":"股债利差","slug":"股债利差","permalink":"https://beefyheisenberg.github.io/tags/股债利差/"},{"name":"风险溢价","slug":"风险溢价","permalink":"https://beefyheisenberg.github.io/tags/风险溢价/"},{"name":"左侧择时","slug":"左侧择时","permalink":"https://beefyheisenberg.github.io/tags/左侧择时/"},{"name":"量化回测","slug":"量化回测","permalink":"https://beefyheisenberg.github.io/tags/量化回测/"}]},{"title":"F30d.股市择时指标（估值、风险溢价...）","slug":"52.Financing/F30d.股市择时指标","date":"2024-01-24T01:27:53.379Z","updated":"2024-01-24T01:27:53.380Z","comments":true,"path":"52.Financing/F30d.股市择时指标/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F30d.股市择时指标/","excerpt":"=&gt; 量化回测结果： @link: F30d1.股市择时指标-量化回测 大盘指数PE百分位上证指数/中证全指/国证A指/万得全A等综合指数的PE百分位：30%以下为低估，70%以上为高估 但是需要注意估值中枢的改变，最近几年是不断抬升的，可以在万得App参考茅指数/宁组合的 PE Band 图 - 沪深300 PE Bands：","text":"=&gt; 量化回测结果： @link: F30d1.股市择时指标-量化回测 大盘指数PE百分位上证指数/中证全指/国证A指/万得全A等综合指数的PE百分位：30%以下为低估，70%以上为高估 但是需要注意估值中枢的改变，最近几年是不断抬升的，可以在万得App参考茅指数/宁组合的 PE Band 图 - 沪深300 PE Bands： @link: F42.公司和行业的基本面指标 股债利差@ref: 投资笔记：股债利差（股权风险溢价）失效了吗？ - 雪球 股债利差/股债收益差，或者叫“股权风险溢价”，等于 宽基指数E/P - 10y国债收益率，不考虑股票的低买高卖，只考虑股票的股息（这里用HS300指数的E/P，也即HS300的股息收益）和无风险利率的比较（十年国债收益率），股债利差越高意味着股市的性价比越高。 统计2016-2022.4，历次股市低点（也即股债利差达到最大值的位置）利差约为6.8%，但是2022.11股市暴跌后出现了7.7%（自2015年之后就没有再出现过如此高的溢价值）： 2016.2：6.5% 2019.1：6.8% 2020.3：6.8% 2022.4：6.4% 2022.11：7.7% 该指标的均值回归性不太好，自2016-2022年中枢值比较稳定，但2008-2014年中枢发生较大上移，此外指标的平稳性也不是特别好，从上面历次极端值（出现在股市底部）可以看出； 以往的“6.8%是股债利差的上限”，在2022大宏观年似乎偏离的有些大，原因无他，还是因为美联储大规模加息，美元资产的强势，对股债利差的稳定性造成扰动。从图中可以看到，2022年的股债利差中枢在上移，标准差通道的敞口也在走阔。上一次美联储大规模加息是在2006-2007年（利息最高5,25%并持续一年），虽然美联储2019也在加息，但加息高点只有2.4%持续时间也短，不能与2006-2007的加息强度相提并论。这个从美国10Y国债-2Y国债利差也可以看出来：2006-2007、2022年的大幅加息都造成了10Y国债-2Y国债利差的倒挂（尤其注意2022年的倒挂更严重），但2019的加息并未造成倒挂。 在哪儿看股债利差： 蛋卷：中证全指股债利差 乐咕：沪深300股债利差 指盈汇：沪深300股债利差 2022年的股债利差是否依然有效？ @ref: 股债性价比择时失效了吗？ - 雪球 文章中的股债利差使用沪深300的EP和美国10Y国债国债作比较，得出的结论恰好相反——现在是不是高性价比的买入时机，而是应该卖出。但美股和A股是两个完全不同也相对独立的市场，加上国内的外汇管制，导致这两种资产并不具备自由的转换关系，这样构建的性价比似乎不太有说服力，事实上两国确实处于相反的宏观周期（一个加息一个降息），作为全球资产定价的核心，美国10年期国债收益率的快速上升，确实干扰到了沪深300股债性价比的有效性 格雷厄姆指数 比较与股债利差的异同：都是股市整体股息收益和无风险利率的比较，前者用比值，后者用差值 市场红绿灯指数：格雷厄姆指数格雷厄姆指数定义：假设某只股票的盈利收益率是10%，此时十年期国债收益率为5%，那么这只股票的格雷厄姆指数为2（10%÷5%=2）；其中 盈利收益率=E/P，也就是市盈率的倒数。 20年的历史数据显示， - 当股市的盈利收益率是十年期国债收益率2倍时（格雷厄姆指数&gt;=2），是比较好的投资机会。 - 格雷厄姆指数 = 1.5，中位 - 格雷厄姆指数 &lt;=1，这时候股市EP是小于国债的，相对危险 格雷厄姆指数计算持仓： - graham &gt; 2.2，权益：固收=10：0 - graham = 2， 权益：固收=8:2 - graham = 1.8，权益：固收=5：5 - graham = 1， 权益：固收=0：10 在哪看格雷厄姆指数：市场-格雷厄姆指数-投资数据网 证券化率（GNP） &amp; 巴菲特指数用 GNP （证券化率） 估算买入时机： 巴菲特认为，在美国证券化率在70%-80%之间适合持有股票，在证券化率低于60%，可以大举买入股票，而当该指标大于100%时，市场就开始值得警惕，而当该指标超过120%，市场就进入了疯狂的状态。 标普500指数具有非常高的相关性。在90年代前，该指标从40%稳步提升至80%，之后该指标在80-150%的区间范围内大幅度震荡。在2000年左右美国的证券化率一度超过150%。随着当时一众互联网公司的市值泡沫破裂，该指标急剧下降，反弹后遇到08年金融危机，再度大幅下挫。 A股 从07年~今：分别是2007年7月（对应后期证券化率高点及时间：2007/12/27、146.60%）；2009年8月（2009/8/4、81.14%）；2015年4月（2015/6/12、113.26%）；2018年1月（2018/1/26、81.67%）；2021年末A股证券化率达到84.3%；但是我们也可以清晰地看到，在10年11月到14年3月期间，该指标没有任何作用。而指数也一路阴跌，期间产生了最大的回撤超过40%。 数据 @ref ：https://legulegu.com/stockdata/marketcap-gdp 中国波指iVIX波动率指数（Volatility Index，VIX），又称恐慌指数，鉴于其有效反映美股市场恐慌和避险情绪而成为出色的市场情绪跟踪指标和风险对冲工具。最早是由芝加哥期权交易所（CBOE）推出的，测度标普100指数平值期权所隐含的市场对未来30天波动的预期的指数。 例如，假设VIX指数为15，表示未来30天预期的年化波动率为15%，因此可以推断指数期权市场预期未来30天标准普尔500指数向上或向下波动15%/√12 = 4.33% 。即指数未来30天的波动率在正负4.33%以内的几率为68%。 VIX典型的指标值为30，当高于30，暗示市场内在的高波动性与恐惧程度。而当读数低于30，表明市场安心，或更确切地说市场不那么紧张。 68–95–99.7法则（68–95–99.7 rule）是在正态分布中，距平均值小于一个标准差、二个标准差、三个标准差以内的百分比，更精确的数字是68.27%、95.45%及99.73% 2015年2月19日，我国正式推出上证50ETF波动率指数（000188），又称中国波指（iVIX），该指数由中证指数有限公司维护。但生不逢时，该指数刚诞生不久就遭遇较大的股市动荡，作为恐慌指数表现“过于耀眼”，2018年2月22日起，中证指数有限公司暂停发布中国波指(iVIX) 。 iVIX是基于方差互换原理，根据上交所挂牌的50ETF期权合约编制而成，计算近月及次近月合约的加权波动率来复合出未来30天的波动率（预期） @ref: VIX指数 - 维基百科，自由的百科全书 VIX指数的来龙去脉和iVIX的计算方法 - 知乎 上证50 ETF波动率指数编制方案 波动率-换手率波动率-换手率模型：量化择时系列之三-“双趋择时模型” 将市场分为四种状态： 波动率上升、换手率上升：波动大+成交活跃，牛市特征； 波动率上升、换手率下降：波动大+缩量，未来走弱的可能性大； 波动率下降、换手率上升：波动小+成交活跃，稳步上升； 波动率下降、换手率下降：震荡，尤其是熊市磨底； 【图】黑色线是上证的收盘价、黄色线是换手率情况，蓝色线是波动率（这里的波动因子是什么？）的平方： 创新高、新低的股票数量上证指数 vs 60日新高股票数量： 120以下为绿色，熊市，交易冷清，2022.4月出现最低15； 200-600为黄色，上涨趋势中通常都是这个范围； 600以上为红色，后市变盘概率极大，2021.12月层出现过800的最高值（截止2022年，A股上市公司≈5000家） 指标可以当做反指，出现极低/极高数值后，股市会反向走。出现大于600时，后续下跌的概率非常高，但出现极低值还可能继续磨底一段时间； 数据来源：新高、新低数量统计_乐咕乐股网 破净股比例破净股是指个股的股价跌破每股净资产，在市场较为低迷的时候破净股往往大量出现，统计整个A股的破净股比例，市场底部区域，A股中破净股的比例大约在10% @ref: 354只股破净 银行板块破净率最高 个股的 破净率 就是股票价格跌破每股净资产后，每股净资产减去股票现价之后，同每股净资产的比率。如某只股票现价2.89元，每股净资产6.22元，则市净率46.45%，破净率则为53.55%。理论上的涨幅空间为3.33元 新增开户数新增股票账户（左） vs 上证指数（右） 来源：https://data.eastmoney.com/cjsj/yzgptjnew.html 两融余额（杠杆率）两融余额: 还有多少杠杆资金留在场内，杠杆的使用量是一个十分有效的情绪指标，融资存量大于融券存量一个数量级(千亿vs百亿)，一般情况下只看融资余额。 2019.1月、2020.7月 两次融资余额快速上涨，对应股市大涨，；2022.4月、2022.10月 两次大跌后融资余额快速下降（黄色柱状值是融资买入额，非净买入额）： 对融资融券（余额）的变动部分做柱状图统计，A股在2022.4、2022.10两次触底的原因一目了然，4月份的底是爆仓形成的“杠杆底”： 当两融余额出现连续较大幅度上涨（经验是连续3个月呈现上涨趋势，平均月涨幅接近或超过10%），具有底部的指导意义。当产业资本净增持出现连续的减持减少/增持（经验是连续6~8个月超过历史合理中位数），具有底部的指导意义 @ref: https://mp.weixin.qq.com/s/d6F-S3_qJ65FcX6z2CjOYA 每日融资买入额、两融余额等数据来源：http://data.10jqka.com.cn/market/rzrq/","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"A股","slug":"A股","permalink":"https://beefyheisenberg.github.io/tags/A股/"},{"name":"择时","slug":"择时","permalink":"https://beefyheisenberg.github.io/tags/择时/"},{"name":"股市估值","slug":"股市估值","permalink":"https://beefyheisenberg.github.io/tags/股市估值/"},{"name":"股债利差","slug":"股债利差","permalink":"https://beefyheisenberg.github.io/tags/股债利差/"},{"name":"巴菲特指数","slug":"巴菲特指数","permalink":"https://beefyheisenberg.github.io/tags/巴菲特指数/"}]},{"title":"F30c1.美股交易指南","slug":"52.Financing/F30c1.美股交易指南","date":"2024-01-24T01:27:53.375Z","updated":"2024-01-24T01:27:53.375Z","comments":true,"path":"52.Financing/F30c1.美股交易指南/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F30c1.美股交易指南/","excerpt":"美股抄底/逃顶技术手册@ref: 美股的启示：如何在慢牛中逃顶、抄底？ 1970年以来，美股历次调整期的盈利、估值与货币政策情况： 1）除1987年股灾之外，美股历次20%幅度以上的调整均伴随着上市公司盈利能力的走弱（或走弱的预期）。 2）历史上，同时存在盈利走弱、估值偏高、货币政策收紧三重利空的情况只有1973年，这段时期美股跌幅超过45%，创过去40年来的最大跌幅。 3）当美股盈利走弱，但估值处于低位，且货币政策偏宽松时，美股跌幅通常在20%以内。如1990年、2011年。 ➤ 盈利（ROE）：美股上市公司ROE的变化决定股市运行方向。ROE的下行确实会对美股行情构成负面影响，美股在ROE下行期更容易出现波动增加、回撤扩大的情况；另一方面也说明，在美国市场上用ROE来择时存在局限性，因为美股熊市的持续时长一般都短于ROE下行的时长，ROE小幅度的下行一般不会导致美股出现年度级别的熊市。","text":"美股抄底/逃顶技术手册@ref: 美股的启示：如何在慢牛中逃顶、抄底？ 1970年以来，美股历次调整期的盈利、估值与货币政策情况： 1）除1987年股灾之外，美股历次20%幅度以上的调整均伴随着上市公司盈利能力的走弱（或走弱的预期）。 2）历史上，同时存在盈利走弱、估值偏高、货币政策收紧三重利空的情况只有1973年，这段时期美股跌幅超过45%，创过去40年来的最大跌幅。 3）当美股盈利走弱，但估值处于低位，且货币政策偏宽松时，美股跌幅通常在20%以内。如1990年、2011年。 ➤ 盈利（ROE）：美股上市公司ROE的变化决定股市运行方向。ROE的下行确实会对美股行情构成负面影响，美股在ROE下行期更容易出现波动增加、回撤扩大的情况；另一方面也说明，在美国市场上用ROE来择时存在局限性，因为美股熊市的持续时长一般都短于ROE下行的时长，ROE小幅度的下行一般不会导致美股出现年度级别的熊市。 当美股上市公司盈利能力大幅恶化、ROE下行幅度超过5pct时，一方面，美股都会出现大级别调整（跌幅超过50%）。另一方面，美股熊市持续时长与盈利下行时长比较接近。这样的情况在1970年之后只发生过两次——2002年互联网泡沫时期与2008年金融危机时期。 而当美股上市公司ROE出现5pct以内幅度的调整时，一方面，标普500指数的调整幅度通常在20%到30%之间，美股的跌幅和ROE调整幅度的关系不是很显著。另一方面，美股熊市通常只会持续半年左右，并不会出现年度级别的熊市。 ➤ 估值（PE）：估值对美股调整和企稳时点的影响体现为以下两点： 1）当美股估值偏高时，美股倾向于在盈利下行之前调整（即还未出现盈利下降，市场先杀一波估值），而美股估值偏低时则倾向于在盈利下行之后调整。 2）当美股估值偏低时，美股在盈利企稳之前回升的概率较大。如1974年、1982年、2009年、2020年。反例是2002年，企业盈利在2002年上半年就已经企稳，但美股因为偏高的估值直到2002年9月才见底。 3）不符合这两点统计规律的特例是1990年和1998年，也就是20世纪90年代美股“非理性繁荣”的时期。这段时期美国宏观经济增速、上市公司ROE出现过两轮下降，但美股却走出了持续上涨的行情，时任的美联储主席格林斯潘在1996年底发表了以《非理性繁荣》为主题的演讲。事后来看，美股在这段时期存在诸多利好，如宏观层面上高增长、低通胀的美好环境，中观层面上美国信息技术产业的快速发展、美国企业在全球范围内竞争力的提升，资金层面上全球资金向美国市场的持续涌入。 ➤ 货币政策对美股调整和企稳时点的影响主要体现以下两方面： 1）加息一般不会成为美股进入技术性熊市的触发因素。比较常见的情况是，美联储加息是为了应对经济增长过热的风险。所以在货币政策刚刚开始收紧时，美股面临着盈利上行和流动性收紧这两股相反的力量，更偏向于震荡。直到投资者对盈利走弱的担忧增强时，美股才会出现调整。 美股企稳的时点通常都与货币政策宽松的时点接近。在1970年以来美股的11次下跌行情中，有8次美股的企稳时点都与货币政策宽松的时点接近。不符合这一规律的情况有3次，可以分为两类。 一类是2002年、2008年这样的危机式下跌行情。虽然美联储大幅度降息，但市场对盈利回升的信心不足，直到盈利真正企稳（2002年）或估值跌至历史底部（2008年）时美股才重回升势。 另一类是美联储在美股下跌期间没有释放宽松信号，发生在1978年。这段时期货币政策没有转松主要是因为美元危机再次爆发（1977年10月）、美元指数下跌、美国国际收支恶化等制约了美联储的降息行为。美股企稳回升的利好因素在于估值偏低，在下跌后期标普500指数的席勒市盈率已经接近1974年的前低水平。","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"股市","slug":"股市","permalink":"https://beefyheisenberg.github.io/tags/股市/"},{"name":"美股","slug":"美股","permalink":"https://beefyheisenberg.github.io/tags/美股/"}]},{"title":"F30c.美股101","slug":"52.Financing/F30c.美股101","date":"2024-01-24T01:27:53.370Z","updated":"2024-01-24T01:27:53.370Z","comments":true,"path":"52.Financing/F30c.美股101/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F30c.美股101/","excerpt":"@todo: 川财证券-多角度评估美股的估值 美股估值的三种常用方法，一看就懂 抄底美股的三种方法和思路 - 雪球 主要指数 纳斯达克指数-百度百科 平均指数, 基本指数为100. 纳斯达克的上市公司涵盖所有新技术行业, 包括软件和计算机、电信、生物技术、零售和批发贸易等. 纳斯达克”综合指数”(IXIC): 相比标准普尔500指数、道·琼斯工业指数（它仅包括30个著名大工商业公司, 20家运输业公司和15家公用事业大公司）更具有综合性. 纳斯达克综合指数包括5000多家公司, 超过其他任何单一证券市场. 因为它有如此广泛的基础, 已成为最有影响力的证券市场指数之一. 标普500指(S&amp;P 500 Index): 当中囊括了美国500 家主要公司，占美国股市约八成的可投资市值。标普500 代表了美国市场，占美国股市的80%-85%, 几乎所有标准普尔中的公司都是全美最高金额买卖的500只股票。这个股票指数由标准普尔公司创建并维护。 道琼斯工业平均指数(DJIA): 道琼斯工业平均指数不是加权算术平均值，并不代表其组成公司的市值，而是每个组成公司的一股股票价格总和后的平均值。是在美国证券交易所上市的 30 家著名公司的价格加权衡量股票市场指数。// 不少专业人士认为，与标准普尔 500 指数或罗素 3000 指数等等，更广泛的市场指数相比，道琼斯工业平均指数仅包括 30 家大公司，不足以代表整个美国股市。此外，道琼斯工业平均指数也不使用加权算术平均值。 表1：美国三大指数对比情况","text":"@todo: 川财证券-多角度评估美股的估值 美股估值的三种常用方法，一看就懂 抄底美股的三种方法和思路 - 雪球 主要指数 纳斯达克指数-百度百科 平均指数, 基本指数为100. 纳斯达克的上市公司涵盖所有新技术行业, 包括软件和计算机、电信、生物技术、零售和批发贸易等. 纳斯达克”综合指数”(IXIC): 相比标准普尔500指数、道·琼斯工业指数（它仅包括30个著名大工商业公司, 20家运输业公司和15家公用事业大公司）更具有综合性. 纳斯达克综合指数包括5000多家公司, 超过其他任何单一证券市场. 因为它有如此广泛的基础, 已成为最有影响力的证券市场指数之一. 标普500指(S&amp;P 500 Index): 当中囊括了美国500 家主要公司，占美国股市约八成的可投资市值。标普500 代表了美国市场，占美国股市的80%-85%, 几乎所有标准普尔中的公司都是全美最高金额买卖的500只股票。这个股票指数由标准普尔公司创建并维护。 道琼斯工业平均指数(DJIA): 道琼斯工业平均指数不是加权算术平均值，并不代表其组成公司的市值，而是每个组成公司的一股股票价格总和后的平均值。是在美国证券交易所上市的 30 家著名公司的价格加权衡量股票市场指数。// 不少专业人士认为，与标准普尔 500 指数或罗素 3000 指数等等，更广泛的市场指数相比，道琼斯工业平均指数仅包括 30 家大公司，不足以代表整个美国股市。此外，道琼斯工业平均指数也不使用加权算术平均值。 表1：美国三大指数对比情况 粉单（pink sheet）https://www.zhihu.com/question/22409430粉单市场的功能就是为那些选择不在美国证券交易所或NASDAQ挂牌上市、或者不满足挂牌上市条件的股票提供交易流通的报价服务。 今天的粉单交易市场，已纳入纳斯达克最底层的一级报价系统，是美国柜台交易(OTC)的初级报价形式。广义的美国OTC市场包括NASDAQ、OTCBB和粉单市场，按其上市报价要求高低依次为：NASDAQ→OTCBB→粉单。 粉单市场不是一个股票交易所，它不受证券监管当局的监管，只要每天交易结束时公布挂牌公司的报价即可。但是NASD监管当局(NASDR)和SEC会对粉红单市场和黄单市场上证券的所有做市商进行严格的监管。","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"股市","slug":"股市","permalink":"https://beefyheisenberg.github.io/tags/股市/"},{"name":"美股","slug":"美股","permalink":"https://beefyheisenberg.github.io/tags/美股/"}]},{"title":"F30b.港股101","slug":"52.Financing/F30b.港股101","date":"2024-01-24T01:27:53.365Z","updated":"2024-01-24T01:27:53.365Z","comments":true,"path":"52.Financing/F30b.港股101/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F30b.港股101/","excerpt":"港股对比A股➤ 港股流动性问题： 【策略】当谈及港股流动性时，我们在讨论什么？——策论海外系列报告之二（张宇生/巩健/刘芳）|港股新浪财经新浪网 港股和A股有几千万散户流动性充裕不一样，港股本土由于人口所限，能带来的资金量很小，内资（南向资金）由于港股通门槛较高导致数量也很有限，所以“港股估值更低”并不是投资的好理由，而是先天流动性不足导致的低估陷阱； 流动性对股价走势影响有多大，这个问题很难量化，流动性好的股票一般表现会比同行业流动性差的股票表现的更好。流动性好则交易活跃，那么卖价高也会有人愿意买。但流动性差，挂单没人接，只好降价卖，结果是股价一路向下，资本都是倾向于朝着阻力最小的方向推波助澜。经常会看到港股有一些股票直线暴跌50%以上，就是里边的资金想要跑路，但是又没有流动性，只能通过砸盘来解决，最后股价暴跌。 对于美元汇率的敏感度很高：港币和美元挂钩，是一个自由流动市场，例如2022年，美联储加息对港股资金外流有很大影响。 ➤ 港股的红利税问题：投资者通过港股账户投资H股有10％的红利税，通过港股通投资H股有20％红利税 @ref: 香港市场股票红利税释疑 主要指数","text":"港股对比A股➤ 港股流动性问题： 【策略】当谈及港股流动性时，我们在讨论什么？——策论海外系列报告之二（张宇生/巩健/刘芳）|港股新浪财经新浪网 港股和A股有几千万散户流动性充裕不一样，港股本土由于人口所限，能带来的资金量很小，内资（南向资金）由于港股通门槛较高导致数量也很有限，所以“港股估值更低”并不是投资的好理由，而是先天流动性不足导致的低估陷阱； 流动性对股价走势影响有多大，这个问题很难量化，流动性好的股票一般表现会比同行业流动性差的股票表现的更好。流动性好则交易活跃，那么卖价高也会有人愿意买。但流动性差，挂单没人接，只好降价卖，结果是股价一路向下，资本都是倾向于朝着阻力最小的方向推波助澜。经常会看到港股有一些股票直线暴跌50%以上，就是里边的资金想要跑路，但是又没有流动性，只能通过砸盘来解决，最后股价暴跌。 对于美元汇率的敏感度很高：港币和美元挂钩，是一个自由流动市场，例如2022年，美联储加息对港股资金外流有很大影响。 ➤ 港股的红利税问题：投资者通过港股账户投资H股有10％的红利税，通过港股通投资H股有20％红利税 @ref: 香港市场股票红利税释疑 主要指数 恒生指数(HSI): 指数由64只恒指成份股的市值计算出来的，代表了香港交易所所有上市公司的十二个月平均市值涵盖率的63%。恒生指数成份股，即是香港的蓝筹股。恒生指数由恒生指数有限公司负责计算及按季检讨，公布成份股调整。 恒生中国企业指数(HSCEI): 恒生科技指数(HSTECH): 恒生高股息率指数(HSHDYI): 窝轮、牛熊证牛熊证能追踪相关资产的表现，且有杠杆作用，投资者买入牛熊证犹如借钱买入相关股票，只需付出财务费用，便可达到杠杆投资的效用，不会如期指般需要按金，亦没有被追收Margin的风险。牛熊证亦附有强制性收回机制。相关资产价格触及牛熊证之收回价时，牛熊证便会被收回。 牛熊证有牛证和熊证之分，设有固定到期日，投资者因应看好或看淡相关资产而选择买入牛证（看好）或熊证（看淡）。 现时的牛熊证会使用新的中文简称格式，由八个字位组成，如「恒指瑞银年月熊Q」，名称上出现“牛”或“熊”的字样。 收回价：在牛熊证有效期内，如相关资产价格触及上市文件内指定的水平（称为「收回价」），发行商会实时收回有关牛熊证，提早进行结算，而且就算相关资产价格回升／回落，该牛熊证亦不会再恢复交易。指数牛熊证的价格变动受期指牵引，但决定收回与否仍取决于指数现货。在牛熊证相关资产的价格接近收回价时，牛熊证的价格波动可能会较大，甚至与相关资产价格的变动不成比例。 行使价：在其他条款相同下，如行使价距离现价愈远（愈价内），有关的牛熊证价格愈高，所产生的杠杆比率亦愈小。 窝轮：认股证是衍生工具的一种，由银行或金融机构发行的投资产品，一般香港投资者称认股证为窝轮 (Warrant)。现时香港上市认股证市场上全是欧式认股证。 欧式认股证只能在到期日时才能被行使。认股证的杠杆效应，投资者利用小金额便可以参与正股波动。 认股证可根据其行使权利分为两类—认购证及认沽证： 认购证 (Call Warrant)： 给予持有人一个权利 (但非责任) 在指定的到期日时，以特定的价格，买入特定数量相关资产。当到期时正股结算价处于行使价以上, 持有人有权以行使价行使该权利从而获利。 认沽证 (Put Warrant)： 给予持有人一个权利 (但非责任) 在指定的到期日时，以特定的价格，沽出特定数量相关资产。当到期时正股结算价是处于行使价以下, 持有人有权以行使价行使该权利从而获利。","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"股市","slug":"股市","permalink":"https://beefyheisenberg.github.io/tags/股市/"}]},{"title":"F30a1.富国基金：A股方法论（2022.10）","slug":"52.Financing/F30a1.A股方法论zz","date":"2024-01-24T01:27:53.360Z","updated":"2024-01-24T01:27:53.361Z","comments":true,"path":"52.Financing/F30a1.A股方法论zz/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F30a1.A股方法论zz/","excerpt":"盈利-估值分析框架 短期估值（PE）波动：股权风险溢价（股债收益差）、无风险利率、流动性 常用估值指标：PE市盈率、PB市净率、PEG、PS市销率…等指标，适合用于不同的行业 三碗面","text":"盈利-估值分析框架 短期估值（PE）波动：股权风险溢价（股债收益差）、无风险利率、流动性 常用估值指标：PE市盈率、PB市净率、PEG、PS市销率…等指标，适合用于不同的行业 三碗面A股分析的“三碗面”： 基本面（企业盈利）：P=EPS * PE // @link：F49.戴维斯双杀 资金面（无风险收益率）：由利率决定 情绪面（股权风险溢价）：由风险偏好决定 市场风格划分 &amp; 风格轮动如何划分成长/价值风格： 成长股：渗透率高、ROE增速高（大于15%）、PE估值高 价值股：渗透率70%+、ROE稳定5%-10%、高分红、PE估值低（10-20倍+） 价值和成长风格轮动因素， 此处参考 “剩余流动性-盈利框架”： 盈利周期：经济向上，成长占优；经济向下，价值占优；经济衡量指标：GDP同比、工业增加值、PMI、PPI 金融周期：货币宽松，成长占优；货币收紧，价值占优；货币衡量指标：货币流动性、国债利率 大小盘风格轮动因素： 经济上行+流动性宽松，利好小盘； 经济下行+流动性收紧，利好大盘； 解释：小盘和流动性关系更大，大盘在经济不好的时候抗跌，但是小票的特点是业绩难以证伪，容易在经济不好的时候炒概念 // @link：F30a.A股101/A股主要指数 根据 “市值” 和 “ROE增速” 四象限规则，划分大盘/小盘 × 成长/价值四类风格 成长/价值切换的时机： 流动性收紧（最重要因素） 经济开始下行，但流动性不宽松 股市风险偏好承受下降，一般是是盈利（or经济）下滑，股权风险溢价（利差）增加 成长股估值太高 市场行业划分 &amp; 行业轮动A股行业划分： 周期板块：能源、有色、钢铁、建材、化工、机械 大消费板块：必选、可选、医药 科技成长板块：电子、军工、TMT 大金融：银行、证券保险、地产 A股行业上下游关系： 金融+地产为驱动力，利好中游周期（机械、建材、化工）、上游周期（有色、煤炭..）， 同时地产景气也能传导下游消费（可选、必选） 不同经济周期（基于普林格六周期） 的 行业轮动： … 行业轮动因子：景气度（财务+预期）、盈利质量、估值回复、动量、资金（北向、两融） 基于行业分类及其特征的投资框架不同行业所处的（成长-成熟-衰退）周期 周期和大宗板块-投资逻辑周期板块投资逻辑：经济周期、供需关系 @link：F44.周期股 金融板块-投资逻辑 消费板块-投资逻辑 科技板块-投资逻辑 总结 &amp; 展望A股投资方法论总结： 趋势研判：经济状况、行业景气度、流动性 风格研判： 行业选择：","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"A股","slug":"A股","permalink":"https://beefyheisenberg.github.io/tags/A股/"}]},{"title":"F30a.A股101","slug":"52.Financing/F30a.A股101","date":"2024-01-24T01:27:53.356Z","updated":"2024-01-24T01:27:53.356Z","comments":true,"path":"52.Financing/F30a.A股101/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F30a.A股101/","excerpt":"A股 and B股 A股: 在我国境内由境内公司发行,由境内投资者购买的,在境内交易的人民币普通股票。 B股: 公司在境内发行和上市,以人民币表明面值,由外国人/境内外的中国公民,以外币认购 A股主要指数中证指数大全：https://www.csindex.com.cn/#/indices/family/list?index_series=2 中证全指（000985）：覆盖了A股上市公司的几乎全部自由流通市值 国证A指（399317）：不包括科创板 上证50（000001）：挑选上海证券市场规模大、流动性好的最具代表性的50只股票组成样本股。这个金融地产占比较多，金融服务行业占比50%+； 沪深300（000300）：这个是最能够代表A股表现的指数，并且一般软件都会跟沪深300比较业绩。沪深300指数以规模和流动性作为选样的两个根本标准，并赋予流动性更大的权重，算是国内股市规模最大的300只股票。金融服务行业占比30%+； 中证500（000905）：其样本空间内股票是由全部A股中剔除沪深300指数成份股及总市值排名前300名的股票后，总市值排名靠前的500只股票组成，综合反映中国A股市场中一批中小市值公司的股票价格表现。其实中证500只能算是中盘股。各行业占比均衡； 中证800（000906）：A股市值最大的800（中证800=沪深300+中证500）； 中证1000（000852）：A股市值第801-1800； 国证2000（399303）：A股市值第1001-3000；","text":"A股 and B股 A股: 在我国境内由境内公司发行,由境内投资者购买的,在境内交易的人民币普通股票。 B股: 公司在境内发行和上市,以人民币表明面值,由外国人/境内外的中国公民,以外币认购 A股主要指数中证指数大全：https://www.csindex.com.cn/#/indices/family/list?index_series=2 中证全指（000985）：覆盖了A股上市公司的几乎全部自由流通市值 国证A指（399317）：不包括科创板 上证50（000001）：挑选上海证券市场规模大、流动性好的最具代表性的50只股票组成样本股。这个金融地产占比较多，金融服务行业占比50%+； 沪深300（000300）：这个是最能够代表A股表现的指数，并且一般软件都会跟沪深300比较业绩。沪深300指数以规模和流动性作为选样的两个根本标准，并赋予流动性更大的权重，算是国内股市规模最大的300只股票。金融服务行业占比30%+； 中证500（000905）：其样本空间内股票是由全部A股中剔除沪深300指数成份股及总市值排名前300名的股票后，总市值排名靠前的500只股票组成，综合反映中国A股市场中一批中小市值公司的股票价格表现。其实中证500只能算是中盘股。各行业占比均衡； 中证800（000906）：A股市值最大的800（中证800=沪深300+中证500）； 中证1000（000852）：A股市值第801-1800； 国证2000（399303）：A股市值第1001-3000； 表1：中国主要指数对比情况 如果我们以宽基指数为视角，上证50代表了外资对中国核心资产估值扩张的殖民地指数，沪深300代表了机构跟随洋人加持核心资产的买办指数，中证500代表了产业资本绑定国内大宗商品和制造业的产业指数，中证1000代表了最草根阶层助推国内先进制造转型的草根指数。 大市值板块，股票数目少且业绩极其容易证伪，与经济景气度的预期相关性较强； 小市值板块，最大特点是股票数目众多，并存在很多业绩难以证伪的股票，可以在经济不景气的时候炒概念，所以在经济景气度很差的时候，小票指数往往好于大票指数； 主要宽基指数行业占比（数据来自wind，截止20220528） 指数编制：综指和成指综合指数，是指综合了市场全部 股票并按规则编制而成的指数，比如，上证指数、深证综指、创业板综指等就属于综合指数 。 成分指数，则是挑选了市场中部分股票 作为成分股并按规则编制而成的指数，比如：上证50指数、沪深300指数、中证500指数、深成指数、创业板指等。 创业板综合指数，代码为：399102，涵盖了创业板当前800多只股票； 创业板成分指数，也就是我们通常说的创业板指，代码为：399006，涵盖的成分股数量为100只 指数编制：全收益指数和净收益指数上面说的这些指数其实是指价格指数。事实上，为满足不同投资者的需要，指数编制公司还编制了收益指数，具体又划分为全收益指数和净收益指数。 全收益指数、净收益指数是价格指数的辅指数，与价格指数的区别在于全收益指数、净收益指数的计算中考虑了样本股税前、税后现金红利的再投资收益，以供投资者从不同角度考量指数。 ▷ 全收益指数计算方法： 其中，T 代表任意交易日，T-1 代表 T 日的上一交易日，调整市 值 = ∑(股价×调整股本数)，税前调整股息=∑(税前每股现金股息×调整 股本数)； ▷ 净收益指数计算方法： 其中，T 代表任意交易日，T-1 代表 T 日的上一交易日，调整市 值 = ∑(股价×调整股本数)，税后调整股息=∑(税后每股现金股息×调整 股本数)，适用税率为 10%。 全收益指数、净收益指数与价格指数的区别在于样本公司发生分红派息时全收益指数、净收益指数点位不会自然回落。 上证3000点10年前，2010年5月28日，上证指数收报2655点。10年后，2020年5月28日，上证指数收报2846点。 ➤ “上证指数十年不涨”可能的成因： 上证指数采用总市值加权计算，客观上提升了总股本大、但流通股本（市场上实际可买卖的部分）小的大市值上市公司权重。导致前十大成分股基本被传统行业的四大行和两桶油给占据，实际上四大行和两桶油的流通市值非常少，也基本涨不动，拖累了指数整体表现； 成分股未能充分反映新兴产业变化。早期上证指数以金融、交运、化工、地产等传统行业为主。而多数信息科技、医药、消费服务等新经济行业选择在深交所上市，互联网行业多数选择在美股（VIE 架构）、港股上市； 纳入新股的时间太快。2020年前，上证指数执行的是新股第11个交易日开始计入指数的规则。A股的特点之一是新发股的价格被严重炒作，这意味着新股被纳入的时候恰好处于高位，没有经历充分的市场定价博弈，随后相当一部分股票的股价持续回落，拖累指数表现。 很长时间上证指数包含了ST及*ST股，严重扭曲了资本市场“优胜劣汰”的信号，影响指数代表性和合理性。// 中证全指（000985）：剔除ST、*ST股票，以及上市时间不足3个月等股票构成样本股 2020年6月19日，上证指数迎来了创立近30年来的首次修订（7月22日生效）。修订内容包括剔除ST、*ST个股，将科创板CDR及股票纳入样本空间（但创业板没有被纳入，仍是深市），以及延长新股纳入期限三个方面。可以看到，导致股指与经济运行背离的很多技术面障碍已经打破，上证指数的市场代表性与稳定性正逐步提高。 为什么很多人还是习惯用上证指数？ 而不用更有代表性的中证全指/国证A指？ 除了“交流标准的统一”，各家App的特色特色指标（例如：DDX/分时博弈）在中证全指上是看不到的，可能是中证没开放这些数据；一些成分指数（上50/沪深300/中证500/中证1000）可以看到这些数据；除了上面提到的两个全A指数，东方财富全A/万得全A也可以参考，与上证指数根据股票的总市值确定权重不同，万得全A是根据股票的自由流通市值确定权重，更有效反映股市运行状况。 A股机制和特点&amp;成因A股机制： T+1机制交易：当日买，次日才可卖出 涨跌停机制：沪深交易所A股主板的涨跌幅限制为10%，创业板的涨跌幅限制比例为20%，科创板的涨跌幅限制为20%。此外：新股上市首日，不设涨跌幅限制、增发股票上市当天不设涨跌幅 A股特色： 牛短熊长：最大的两轮牛市，2006年、2007年有两年是牛市，接下来一直到2014年整整7年没有大牛市。2014年下半年到2015年上半年，接近一年时间的融资杠杆牛市，但就下来又陷入长时间熊市。 散户比例高、换手率高（2018年中报披露的数据显示，A股个人投资者持有的自由流通市值占比达到40.5%，美股、港股的个人投资者持有的市值占比分别仅为4.14%、6.82%），散户缺乏理性，羊群效应明显 大盘指数无法有效反应宏观经济的情况 // @link: F30e.股市与宏观经济的关系 个股股价与公司的基本面的关系相对较弱，受经济政策和市场情绪的影响很大 中国股市由于人民币不能自由兑换，总体上是个封闭的股市。与外国股市的联系与影响主要是心理上的和间接的，其影响有个时滞期，没有实质上的直接的敏感联系。// 汇率的稳定性 =&gt; F28.蒙代尔不可能三角 缺少真正意义的退市机制：一旦企业成功上市，即使后续业绩表现不佳也很难被退市— — 因为“壳”具有价值。围绕“壳”进行的大量诸如资产重组这样的交易使得市场估值极为混乱，容易形成炒作，也难以形成有效的退市机制去淘汰质量不好的上市公司。A股市场近30年来监管当局主动令其退市的公司不到70家，作为对比，美国仅在20世纪90年代至今就有超过7000家企业退市。 缺少真正意义的做空机制，双向交易机制理论上来讲能够使市场波动【相对】更加理性，因为股票有一个大体的估值【区间】作为锚，高了会有做空力量压制，低了也会有做多力量支撑。但以上有一个前提，那就是市场相对有效的情况下。具备完善做空机制的市场里，机构等专业交易者会更有优势，但对于散户… “对于越是业余的人而言，选择越多，只是让你错误的方式越多而已” A股是有做空机制的，但并不是普遍意义上的做空机制，而是部分做空：第一，可以通过股指期货做空（比如上证50、沪深300、中证500等指数）；第二，可以通过融券业务做空，但A股中并不是所有股票都能融资融券。 @ref: 海通证券：A股与美股的市场结构对比 - 2018 A股市场离成熟的资本市场有多远？ 庄家能把散户看透到什么地步？ - 知乎 熊锦秋：A股引入做空机制还有哪些障碍 _ 东方财富网 A股各类投资者持股市值占比 根据中金测算的2021年数据： “个人投资者”的比例为47%，机构投资者合计比例为53%。此处的个人投资者可简单理解为“散户”，但大股东、大户持有的（流通市值）股票数量也算在“个人投资者”中。 公募基金比例在2015-2019比例非常低，缘于那次股灾后的瓦解？ A股业绩披露时间表@ref: https://xueqiu.com/9752824777/122766349 业绩预告：主要是对公司当期净利润情况的预计，内容简略，出的最快最早。 业绩快报：内容更加详细，会披露主要的财务数据，比业绩预告要晚，比正式报告要早，且数据比较接近正式报告。 正式的季报、半年报和年报：内容最详实，要求最严格，披露时间最晚 A股交易规则 &amp; 费率 交易时间：周一到周五，上午 9：30 - 11：30，下午 1：00-3：00，周末以及法定节假日休市； 交易规则：实行’T＋1’交易制度，即当日买进的股票，必须要到下一个交易日才能卖出。国债ETF、货币ETF等等少数几种是T+0交易。 ▷ 股票交易中产生的主要费用： 印花税：收费主体为财税部门，卖出的时候向卖方收取，0.1% （注：ETF无印花税） 过户费：收费主体为中国结算，买卖双方收取，0.001% 券商佣金：收费主体为券商，买卖双方收取，比如0.0015（万1.5）, 不满1w按5块计 举个例子，假设一个人买入然后又卖出10万元的股票，他需要支付的税费是多少呢？ 买入时：佣金15 + 过户费1 卖出时：佣金15 + 过户费1 + 印花税100 @ref: 节后A股大利好消息来啦！速读！ A股行业指数开头编码 H开头的一般都是二级、三级行业指数，同时一级行业全指指数在000986-000995之间 上交所编的指数名称一般前两个字是上证，代码000开头 深交所编的指数名称一般前两个字是深证、国证，代码399开头 中证指数公司的指数名称一般前两个字是中证，代码同时有000和399开头，比如最著名的中证500指数，399905和000905两个代码都是该指数。 创业板、中小板、科创板、新三板场内市场，包括上海证券交易所和深圳证券交易所。主板(沪深主板, 也叫一板)、中小板、创业板都是场内交易所市场，对应的企业均为上市公司；场外市场（otc），包括新三板（全称叫全国中小企业股份转让系统）、区域性股权交易市场、券商otc市场，对应的企业均为非上市公司； 深交所： 中小板（代码为002打头的股票）：2004年创立，主要针对发展成熟，盈利稳定的中小企业。中小板跟沪深主板一样，同属一板市场(Main-Board Market)。 创业板（代码为300打头的股票）：2009年创立，创业板的上市标准比主板和中小板都要低一些，而且创业板企业的融资量的需求也没有中小板大，主要针对高科技高成长的中小企业。创业板是对主板市场的重要补充，属于二板市场(Second-board Market) 上交所： 科创板（代码为688打头的股票）：2019年创立，是上交所在主板外单独设立，主要针对符合国家战略、突破关键核心技术、市场认可度高的科技创新企业。 新三板：即全国中小微企业(不是上市公司)股份转让系统，主要针对创新型、创业型、成长型的中小微企业。是独立于沪深股市之外的证券交易场所。新三板内不是上市公司，但是可以在新三板买卖交易公司企业股份。 各个板板投资风险从高到低是：新三板 &gt; 科创板 &gt; 创业板 &gt; 中小板 &gt; 主板 @ref: 科创板基础知识_东方财富网 港股通、沪股通、深股通 沪股通：投资者委托香港券商，经由香港联合交易所，买卖规定范围内的上交所上市的股票； 深股通：投资者委托香港券商，经由香港联合交易所，买卖规定范围内的深交所上市的股票； 陆股通 = 沪股通 + 深股通 港股通: 投资者委托内地证券公司，经由上海证券交易所，向香港联合交易所进行申报(买卖盘传递)，买卖规定范围内的港股股票。 大小非解禁“非”=非流通股，当初股权分置改革时，限制了一些上市企业的部分股票上市流通的日期。也就是说，有许多企业的部分股票暂时是不能上市流通的。这就是非流通股（也叫限售股）。其中的小部分就叫“小非”，大部分叫“大非”。“小非”是指持股量在5%以下的非流通股东所持股份，这就是“小非”的由来。与“小非”相对应，“大非”则是指持股量5%以上非流通股东所持股份。解禁就是允许上市流通。“大小非”解禁也就意味着该公司的非流通股允许上市。大小非解禁减持将给市场带来急剧的扩容压力，使流通股股东的信心受挫，股价下跌。 大小非减持：非流通股可以流通后，会有股东抛售套现，就叫减持。因为大非一般都是企业的大股东，战略投入者，一般不会抛，小非则是许多年的不流通，一但流通，又有很大获利，很多都会套现。 @ref: 大小非解禁_东方财富网 日历效应 星期效应： A股最典型的星期效应，是“黑周四”。2000年到2016年期间，周四平均涨跌幅低于其他日，方正证券认为，“黑周四”的成因是T+1。A 股特殊的“T+1”交易制度，是造成“黑周四”的主要原因。如果投资者想要在周末（或下周初）拿到现金，就需要在周四卖出股票。?? 美国、香港等“T+0” 市场的星期效应，主要表现为“黑周一”，这和A股有很大不同。原因可能是“T+0”制度下，这些市场的投资者更倾向于周一卖出。 月份效应： A股2月效应：春季往往较好，上涨概率较高，我们都知道，这个现象叫“春季躁动”。2月涨幅的平均值、中位数显著高于其他月份，那看下来，一年中，首尾月份的收益相对较高、中间月度塌陷 A股10月效应：2009 年以来的日历效应表明，每年国庆节前2个交易日，到节后的12-13个交易日，上证综指上涨概率非常大。叠加5年一届的中央换届会议会期确定，市场“维稳预期”很浓。 中美均于每年1月发布年度GDP数据，于1、4、7和10月发布季度GDP数据。在这些时间段内，A股/美股/港股表现较佳 年底的中央经济工作会议也起到相同的作用，使得A股在11-12月期间走势向好； 机构投资者在季度末一般需要提交财务报告公布持仓情况，一般基金经理为了迎合投资者，会进行一系列调仓，引起市场波动，使得三地市场在3月、6月、9月、12月表现较为平淡； 美国华尔街有谚：“Sell in May and Go Away，Come Back after Labor Day”。有意思的解释，是美国投资者夏季休假造成交投清淡;另一个来自基本面的解释，是美国夏季气温较高造成企业投资开工下降。 央行工作会议：上半年1月，下半年8月 @ref: 光大证券-海外策略双周专题(2021年第4期)：国内与海外市场有哪些共同的“日历效应“？ A股市场日历效应的初步研究“只要在每个月的25日之后清仓，下个月1号再重新入场，收益可提高一倍” 以下两种策略的回测均显著跑赢基准： 策略1：只在每个月第1到5个交易日内持有指数，其他时间空仓 策略2：只在每个月25号之后空仓一直到月底，其他时间满仓 基于Python的A股春节效应研究除了2008年、2013年春节期间收益率表现较差外，其余年度春节期间基本都取得了正收益，说明A股市场存在着较为明显的“春节效应”。 A股大揭秘：星期几最赚钱？ - 21财经 近10年统计： 正收益：周2&gt;周5（周2最好） 平：周3 负收益：周1&gt;周4（周4最差） 最近十年周2最赚钱，而更长的历史数据显示是周3更赚钱。2016年以后，周2的赚钱效应明显。但是否意味着，我们接下来持续能在周2赚钱呢？不好说，因为我担心大家都知道这个赚钱秘籍后，在不久的将来，周2的赚钱效应会消失。尽管每周最赚钱的1天是不确定的，但是我们有幸的发现了最稳定亏钱的周4。 策略1：每周避开周4不投资，其余时间均持有股票。简单的说，就是每周3收盘卖出上证指数，周4收盘再买入指数，从而避开周4的当日涨跌。 策略2：每周仅在周2和周3持股，其余时间空仓。简单的说，就是每周1收盘买入上证指数，周3收盘卖出指数。 使用近十年的上证指数回测，得到结论： 策略1：每周4空仓的策略近十年的累计净值可以达到2，投资收益率达到100%。说明每周规避掉周4之后，投资收益居然得到大大改观，年化收益也达到了近8%，夏普比率0.415。 策略2：每周2周3持股的策略近十年的累计净值达到1.64，投资收益率为64%，波动也明显小很多。说明每周在周2和周3持股，可以获得较稳健的收益，夏普比率提高到0.462。 近十年A股总市值趋势A股总市值历史数据： @ref https://data.eastmoney.com/gzfx/scgk.html 成交量： 2020年牛市-日成交量峰值 1.6万亿 2015年牛市-日成交量峰值 2万亿 总市值： 目前A股总市值 80万亿 2021牛市-顶部 90万亿 2018熊市-底部 45万亿 2015牛市-顶部 70万亿 2014熊市-底部 20万亿 结论：2022上证指数的底部依然在3000点徘徊，但是整体市值相较2015年抬高了近一倍左右，如果2023要走出一波牛市，日成交额的峰值预测需要1.5~2万亿 根据巴菲特指数，A股牛市顶点的证券化率（=总市值/GDP）约为80% // @link F30d.股市择时指标","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"股市","slug":"股市","permalink":"https://beefyheisenberg.github.io/tags/股市/"}]},{"title":"F29.金融大事记","slug":"52.Financing/F29.金融大事记","date":"2024-01-24T01:27:53.351Z","updated":"2024-01-24T01:27:53.352Z","comments":true,"path":"52.Financing/F29.金融大事记/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F29.金融大事记/","excerpt":"1992-黑色星期三Black Wednesday:是指1992年9月16日英国保守党政府因无力维持英镑的汇率下限而被迫退出欧洲汇率体系（ERM）。著名投资经理人乔治·索罗斯通过大量做空英镑而获利超过10亿美元。据英国财政部于1997年的估计，英国为此付出了34亿美元的代价. 背景:英国最初于1990年加入欧洲汇率体系。根据规定，各成员国有责任使本国货币汇率的波动稳定在一定范围之内。两德统一之后，德国为缓解通货膨胀压力而提升利率，给包括英国在内的许多为刺激经济增长而实行低利率的国家造成了很大压力。英镑对马克间的汇率开始大跌，汇率逐渐逼近欧洲汇率体系规定的下限2.778。1992年9月16日上午，英国政府决定将利率由10%提升至15%，但无力缓解英镑下跌之势。当天晚上，英国最终决定退出欧洲汇率体系，并将利率下调至12%。次日，又降回原先的10%。 索罗斯和他的助手们卖空了大约70亿美元的英镑，买入了约60亿美元的德国马克，并买入了一定的法国法郎。作为平行交易，他们还在做空英镑的时候，就买入了价值高达5亿美元的英国股票，预期股市通常会在货币贬值后上涨。 索罗斯还做多了德国和法国债券，同时做空这些国家的股票。对于在法国和德国市场的操作，索罗斯的理由是：估值上升在股票是坏事，但在债券是好事，因为它会导致利率走低。 我们在来看看他当时的杠杆头寸是如何奏效的：英镑下跌10%，马克和法郎均上涨约7%，伦敦股市上涨7%，德国和法国债券各上涨3%左右，德国和法国股市短暂反弹，但基本持平。","text":"1992-黑色星期三Black Wednesday:是指1992年9月16日英国保守党政府因无力维持英镑的汇率下限而被迫退出欧洲汇率体系（ERM）。著名投资经理人乔治·索罗斯通过大量做空英镑而获利超过10亿美元。据英国财政部于1997年的估计，英国为此付出了34亿美元的代价. 背景:英国最初于1990年加入欧洲汇率体系。根据规定，各成员国有责任使本国货币汇率的波动稳定在一定范围之内。两德统一之后，德国为缓解通货膨胀压力而提升利率，给包括英国在内的许多为刺激经济增长而实行低利率的国家造成了很大压力。英镑对马克间的汇率开始大跌，汇率逐渐逼近欧洲汇率体系规定的下限2.778。1992年9月16日上午，英国政府决定将利率由10%提升至15%，但无力缓解英镑下跌之势。当天晚上，英国最终决定退出欧洲汇率体系，并将利率下调至12%。次日，又降回原先的10%。 索罗斯和他的助手们卖空了大约70亿美元的英镑，买入了约60亿美元的德国马克，并买入了一定的法国法郎。作为平行交易，他们还在做空英镑的时候，就买入了价值高达5亿美元的英国股票，预期股市通常会在货币贬值后上涨。 索罗斯还做多了德国和法国债券，同时做空这些国家的股票。对于在法国和德国市场的操作，索罗斯的理由是：估值上升在股票是坏事，但在债券是好事，因为它会导致利率走低。 我们在来看看他当时的杠杆头寸是如何奏效的：英镑下跌10%，马克和法郎均上涨约7%，伦敦股市上涨7%，德国和法国债券各上涨3%左右，德国和法国股市短暂反弹，但基本持平。 英镑贬值导致马克升值的逻辑是? 欧洲国家汇率联动（锚点为德国马克）// 为什么汇率联动？ 方便结算 所以各国要维持自己对马克的汇率稳定 德国通胀，需要加息，英国通缩，需要降息，但这样会引起市场上卖出英镑换马克，英镑贬值，如果英国无法维持英镑对马克汇率，会被迫退出.. 进一步打击经济 索罗斯已经开始大量抛售（前期借来的）英镑，进一步加剧英国国对于英镑贬值的内恐慌情绪 英格兰银行动用外汇储备接盘索罗斯抛售的英镑，同时宣布加息（加息可以在一定程度让英镑回流，但在通缩周期加息emmm） 最后的结果是 待整理: “索罗斯”如何狙击英镑？干倒英格兰银行？_腾讯新闻 索罗斯狙击英镑 1997-亚洲金融危机1997年亚洲金融危机_百度百科 1998-香港金融保卫战香港金融保卫战_百度百科 link: F30b.港股101 2000-互联网泡沫破裂@todo 2007-次贷危机@ref: 什么是“做空”？“做空”是如何赚钱的？ - 叶泊枫的回答 - 知乎 次贷危机: “次级贷款市场危机”，次级贷=信用资质不太好的贷款. MBS——房屋抵押贷款债券。房屋抵押贷款即房贷，债券就是借条。打包在一起，就是……一堆借条。所以这个 MBS，往简单了说，就是一堆房贷合同打包在一起的，可以交易的债券CDO可以看成各种债券反复打包的套娃产品。CDO 里可能有房贷，也可能有消费贷等其他各种贷，甚至 CDO 里还有 CDO。 理论上，MBS 模式可以形成一个无限的放贷循环：放贷 ➜ 打包 ➜ 售出 ➜ 再放贷 ➜ 再打包…… 如何做空MBS 和 CDO? (美国楼市存在大量泡沫), 当次级贷违约率上升， MBS 和 CDO 就会暴雷，MBS 和 CDO 将会跌得一文不值 第一种做空, (借钱)从券商那里大量买入CDO, 然后抛售, 等CDO暴跌, 再以便宜的价格买入等量的CDO还给, 但是看涨的投资人，通常会买下一整期的 CDO，且拒绝向外借出，不给你做空的机会 CDS出场: CDS 是一种保险，专门为债券资产提供保护。例如买了A公司债券, 又担心无法兑现, 就买对应的CDS, 当A公司爆雷, 保险公司就赔偿给你损失. 但实际上, 你无需购买债券, 也可以买对应的CDS, 华尔街的伟大发明! 2000~2022-A股大事记 2000.2: 美联储大幅加息 2000.4: 纳指跌超25% 2001.11: 911 2001: 纳指跌至巅峰时期的1/4不到 … 2007.10: 上证新高6100点 2007: 05~07年我国贸易顺差扩大, 人民币升值, 经济过热, 为抑制经济过热, 07年开始连续加息, 提高准备金率, 导致08年经济降温, 叠加泡沫严重, 大小非接近高峰 2008.5 中国出口同比增速见顶于28% 2008下半年: 美国次贷危机开始 2008.9: 雷曼兄弟破产, 美国次贷危机升级为全球危机 2008.10: 上证跌至1660点 2008.11: 上证指数跌幅73%, 沪深300指数跌至1600 2009.1: 中国出口同比增速下滑到-17%, 一季度GDP累积同比下滑到6% 2009.11: 4万亿计划出台 … 2014年后, 宽松经济政策, 连续降准降息 2015: 房地产调控加强, 投资股市进一步升温 2015: 沪深300涨至5300点, 历史新高 2015.6: 上证指数新高5100点 2015: 开始去杠杆 @ref 资本市场去杠杆系列（1）：投资端杠杆与2015年“股灾” 2015.6~ 2016.2 : “股灾”, 沪指跌至2700点, 创业板-70% … 2018.3: 贸易战开始 中概互联大跌48% 2019整年的走势参考: ![[../_images/川普推文-A股走势.png]] 2020: 创业板大涨65%, 牛冠全球 2021.7: 创业板指最高涨至3576点, 涨幅超200% // 宁德时代等 2021.11: 纳指新高16000点, 是2002.10的14倍 2021.2: 中概互联新高 2021.2~年底: 监管层密集的动作——从2021年1月对电子烟的限制，到3月以来对K12教育持续加码的监管政策，以及对阿里、腾讯和美团的反垄断处罚，和对滴滴、BOSS直聘、满帮的审查等等， 2022.3: 百济神州等5家在美上市的中国公司被列入美国证监会(SEC)的可能摘牌名单 2022.3.10: 美股收盘，热门中概股集体大跌，30多只股票跌幅超过10%，贝壳跌近24%、爱奇艺跌21%、拼多多跌17%、京东跌15%、哔哩哔哩跌14%，创下2008年10月以来最大跌幅 2022.4.25 F71.202204-A股见底了吗","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"财经历史数据","slug":"财经历史数据","permalink":"https://beefyheisenberg.github.io/tags/财经历史数据/"}]},{"title":"F28.蒙代尔不可能三角","slug":"52.Financing/F28.蒙代尔不可能三角","date":"2024-01-24T01:27:53.347Z","updated":"2024-01-24T01:27:53.347Z","comments":true,"path":"52.Financing/F28.蒙代尔不可能三角/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F28.蒙代尔不可能三角/","excerpt":"","text":"蒙代尔不可能三角：一个国家不可能同时实现 货币政策独立性、汇率稳定、资本自由流动 三大金融目标，只能同时选择其中的两个。 “蒙代尔不可能三角”还适用吗？ - 知乎","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"宏观经济","slug":"宏观经济","permalink":"https://beefyheisenberg.github.io/tags/宏观经济/"}]},{"title":"F28.费雪公式","slug":"52.Financing/F28.费雪公式","date":"2024-01-24T01:27:53.343Z","updated":"2024-01-24T01:27:53.343Z","comments":true,"path":"52.Financing/F28.费雪公式/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F28.费雪公式/","excerpt":"费雪方程式费雪方程式是表示国民收入水平与价格水平、货币供应量之间的数量关系的。利率有实际利率和名义利率之分。 名义利率，是指没有考虑通货膨胀因素，按照承诺的货币价值计算的利率。 实际利率，是对名义利率按货币购买力的变动修正后的利率。 由于借贷双方更关心货币的实际购买力而不是货币的名义额，因此实际利率能更准确地衡量借贷的成本和收益。名义利率的计价单位是货币，实际利率的计价单位则为标准化的一篮子商品和服务。若年名义利率为i，则现在投资1元，1年后将获得1+i 元，若当年通货膨胀率的预期值为π，按照现在的实际购买力计算，1年后的1+i 元只相当于现在的(1+i)／(1+π)。如果实际利率用R来表示，则应该具有下列关系： $$ 1+R＝(1+i)／(1+π) $$ 由上述公式可以推导出： $$ i = π + R + πR $$","text":"费雪方程式费雪方程式是表示国民收入水平与价格水平、货币供应量之间的数量关系的。利率有实际利率和名义利率之分。 名义利率，是指没有考虑通货膨胀因素，按照承诺的货币价值计算的利率。 实际利率，是对名义利率按货币购买力的变动修正后的利率。 由于借贷双方更关心货币的实际购买力而不是货币的名义额，因此实际利率能更准确地衡量借贷的成本和收益。名义利率的计价单位是货币，实际利率的计价单位则为标准化的一篮子商品和服务。若年名义利率为i，则现在投资1元，1年后将获得1+i 元，若当年通货膨胀率的预期值为π，按照现在的实际购买力计算，1年后的1+i 元只相当于现在的(1+i)／(1+π)。如果实际利率用R来表示，则应该具有下列关系： $$ 1+R＝(1+i)／(1+π) $$ 由上述公式可以推导出： $$ i = π + R + πR $$ 在通货膨胀不是很严重的情况下，如预期的通货膨胀率低于5％，最后一项πR的数值就非常小，可以忽略不计。因此上述关系式可以进一步简化为： $$ i = π + R $$ 即名义利率 = 通胀率 + 实际利率。费雪方程式表明，名义利率必须包含一个通货膨胀溢价，以弥补预期的通货膨胀给贷款人造成的实际购买力损失。当实际利率保持稳定时，名义利率就会随着预期通货膨胀率的提高而提高。 费雪交换方程式费雪交换方程式是传统货币数量论的方程式之一。20 世纪初, 美国经济学家欧文·费雪在《货币的购买力》一书中提出了交易方程式： $$ MV = PT $$ M - 货币的数量 ; V - 货币流通速度 ; P - 物价水平 ; T - 各类商品的交易总量。 根据这一方程式，P（物价水平）的值取决于 M、V、T 三个变量。在这3个经济变量中： M 是一个由模型之外的因素所决定的外生变量 ; V 是由制度因素决定的 , 而制度因素变化缓慢 , 因而可视为常数 ; T 与产出水平保持一定的比例 , 也是大体稳定的。 M 可以是流通货币总数（大概相当于M1），V 可以看作货币流动性（相当于居民消费和企业贷款等引起的货币流通），当经济不景气的时候，大众消费信心下降、企业减少贷款，导致V（流动性）不足。","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"宏观经济","slug":"宏观经济","permalink":"https://beefyheisenberg.github.io/tags/宏观经济/"}]},{"title":"F27c.贴现率","slug":"52.Financing/F27c.贴现率","date":"2024-01-24T01:27:53.339Z","updated":"2024-01-24T01:27:53.339Z","comments":true,"path":"52.Financing/F27c.贴现率/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F27c.贴现率/","excerpt":"什么是贴现: 贴现，也称为折现或票据贴现（英语：Discounting），是指将未来的货币转换成当前货币的实际价值，与累积恰好是相反的概念和过程。贴现也就是折合成现在的价值。 贴现率 r = 无风险利率 + 风险补偿 + 通货膨胀率 通过贴现率衡量股票/债券的价值: 例子1: 中国银行发行一个永久债券, 利率4.5%, 不复利, 每股100元 // 计算模型: 债券价值= 每年产生利率相加求和 (每年的利率都要贴现)， 这种方法叫 股利贴现 计算: 每年产生的分红(D = 4.5元), 贴现率(r = 3% + 1% + 4%), 最终计算价值 (P=56.25)","text":"什么是贴现: 贴现，也称为折现或票据贴现（英语：Discounting），是指将未来的货币转换成当前货币的实际价值，与累积恰好是相反的概念和过程。贴现也就是折合成现在的价值。 贴现率 r = 无风险利率 + 风险补偿 + 通货膨胀率 通过贴现率衡量股票/债券的价值: 例子1: 中国银行发行一个永久债券, 利率4.5%, 不复利, 每股100元 // 计算模型: 债券价值= 每年产生利率相加求和 (每年的利率都要贴现)， 这种方法叫 股利贴现 计算: 每年产生的分红(D = 4.5元), 贴现率(r = 3% + 1% + 4%), 最终计算价值 (P=56.25) 例子2: 计算股票价值, 设某公司股票, 每年都分红, D元/股, 贴现率设为r , 股票产生的价值分为… 如果只用股息产生的价值来计算股票现在的价值, 也即下面的”股利贴现模型” (不考虑股价上涨带来的收益, 只考虑股票分红) .以工商银行股票为例, 分红D = 0.25￥/股, r = 3%无风险 + 5%风险补偿 = 8% (此处没考虑通货膨胀) 模型1, 每股分红D是静态: D = 3.125￥ 模型2, 如果考虑到每股分红是动态的(D每年增加g), D = 6.25￥ 另外一种计算股票价值：自由现金流贴现 ， 这种模型，只需要把 $$P = D/(r-g)$$ 中的股息(D)换成自由现金流, 查到工商银行的自由现金流 = 1.6元/股, 设g = 4%, r=8% , 计算P=40￥ F27.LPR和利率","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[]},{"title":"F27b.等额本息 vs 等额本金","slug":"52.Financing/F27b.等额本息-vs-等额本金","date":"2024-01-24T01:27:53.335Z","updated":"2024-01-24T01:27:53.335Z","comments":true,"path":"52.Financing/F27b.等额本息-vs-等额本金/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F27b.等额本息-vs-等额本金/","excerpt":"贷款利息（等额本息 vs 等额本金） ➤ 等额本息:指在还款期内，每月偿还同等数额的贷款(包括本金和利息)。 如何计算月还款数:","text":"贷款利息（等额本息 vs 等额本金） ➤ 等额本息:指在还款期内，每月偿还同等数额的贷款(包括本金和利息)。 如何计算月还款数: P:贷款本金R:月利率N:还款期数附：月利率 = 年利率/12 假定借款人从银行获得一笔20万元的个人住房贷款，贷款期限20年，贷款年利率4.2%，每月还本付息。按照上述公式计算，每月应偿还本息和为1233.14元。上述结果只给出了每月应付的本息和，因此需要对这个本息和进行分解。仍以上例为基础，一个月为一期，第一期贷款余额20万元，应支付利息700元（200000×4.2%/12），支付本金533.14元，仍欠银行贷款199466.86元；第二期应支付利息（199466.86×4.2%/12)元。 ➤ 等额本金:是在还款期内把贷款数总额等分，每月偿还同等数额的本金和剩余贷款在该月所产生的利息，这样由于每月的还款本金额固定，而利息越来越少，借款人起初还款压力较大，但是随时间的推移每月还款数也越来越少。 每月还款金额= （贷款本金/还款月数）+（本金—已归还本金累计额）×每月利率 ➤ 等额本息 vs 等额本金 等额本息：一般的银行贷款均可使用等额本息。等额本息是指：把贷款时间内的所有本金以及对应产生的利息，均匀的分配在每一个月中。这种还款方式的特点是：每个月还款金额相同。但每个月还款额中，前面是还利息多，后期是还本金多。 等额本金：一般的银行贷款均可使用等额本金。等额本金是指：把贷款时间内的所有本金均匀分配在每个月中，同时每个月配上未还款及当月本金对应的利息。这种还款方式的特点：每个月还款的金额不同，第一个月最多，后续越来越少。 等额本息还款法特点： 月还款数不变；该方法每月的还款额固定，可以有计划地控制家庭收入的支出，也便于每个家庭根据自己的收入情况，确定还贷能力。 等额本金还款法特点：月还款数递减；由于每月的还款本金额固定，而利息越来越少，贷款人起初还款压力较大，但是随时间的推移每月还款数也越来越少。 二者相比，在贷款期限、金额和利率相同的情况下，在还款初期，等额本金还款方式每月归还的金额要大于等额本息，但在后期每月归还的金额要小于等额本息。即按照整个还款期计算，等额本金还款方式会节省贷款利息的支出。 总体来讲，等额本金还款方式适合有一定经济基础，能承担前期较大还款压力，且有提前还款计划的借款人。等额本息还款方式因每月归还相同的款项，方便安排收支，适合经济条件不允许前期还款投入过大，收入处于较稳定状态的借款人。","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[]},{"title":"F27a.同业拆借利率(Shibor)","slug":"52.Financing/F27a.同业拆借利率（Shibor）","date":"2024-01-24T01:27:53.329Z","updated":"2024-01-24T01:27:53.329Z","comments":true,"path":"52.Financing/F27a.同业拆借利率（Shibor）/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F27a.同业拆借利率（Shibor）/","excerpt":"Shibor（一）定义银行除上缴或留存一部分存款准备金外，部分银行账面上会留有超额准备金，同时一部分银行的账面上会出现准备金短缺的现象。此外，受到流动性以及头寸调剂等因素影响，此时就需要向其他银行借入资金。因此，Shibor便应运而生了。 Shibor 即Shanghai InterBank Offered Rate （上海同业拆借利率）的缩写，是我国仿照Libor(London Inter Bank Offered Rate,伦敦同业拆借利率)的模式，建立起银行间拆借市场后出现的。目前，对社会公布的Shibor品种包括隔夜、1周、2周、1个月、3个月、6个月、9个月、12个月利率等等形式，给银行间的拆借提供指导价格。 （二）定价模式Shibor报价银行现由18家商业银行组成。报价银行是公开市场一级交易商或外汇市场做市商，属于在中国货币市场上人民币交易相对活跃、信息披露比较充分的银行。每个交易日根据各报价行的报价，剔除最高、最低各4家报价，对其余报价进行算术平均计算后，得出每一期限品种的Shibor，并于11:00对外发布。 （三）意义Shibor是一个了解银行资金是否充足的晴雨表：每当央行上调存准率或者有上调预期时，Shibor会有一定幅度的上升。而一旦Shibor下行，意味着银行资金充足，市场偏宽松即有可能是央行进行公开市场操作的结果。这就为投资者在进行市场资金面分析时提供了一个重要的指标。譬如当Shibor持续上升时，说明银行间资金趋紧，市场资金面偏紧缩，这时持有现金的保值能力较强。当Shibor持续下降时，表明银行间资金偏宽松，说明此时市场资金较多，现金保值能力不强，此时可进行投资或消费。","text":"Shibor（一）定义银行除上缴或留存一部分存款准备金外，部分银行账面上会留有超额准备金，同时一部分银行的账面上会出现准备金短缺的现象。此外，受到流动性以及头寸调剂等因素影响，此时就需要向其他银行借入资金。因此，Shibor便应运而生了。 Shibor 即Shanghai InterBank Offered Rate （上海同业拆借利率）的缩写，是我国仿照Libor(London Inter Bank Offered Rate,伦敦同业拆借利率)的模式，建立起银行间拆借市场后出现的。目前，对社会公布的Shibor品种包括隔夜、1周、2周、1个月、3个月、6个月、9个月、12个月利率等等形式，给银行间的拆借提供指导价格。 （二）定价模式Shibor报价银行现由18家商业银行组成。报价银行是公开市场一级交易商或外汇市场做市商，属于在中国货币市场上人民币交易相对活跃、信息披露比较充分的银行。每个交易日根据各报价行的报价，剔除最高、最低各4家报价，对其余报价进行算术平均计算后，得出每一期限品种的Shibor，并于11:00对外发布。 （三）意义Shibor是一个了解银行资金是否充足的晴雨表：每当央行上调存准率或者有上调预期时，Shibor会有一定幅度的上升。而一旦Shibor下行，意味着银行资金充足，市场偏宽松即有可能是央行进行公开市场操作的结果。这就为投资者在进行市场资金面分析时提供了一个重要的指标。譬如当Shibor持续上升时，说明银行间资金趋紧，市场资金面偏紧缩，这时持有现金的保值能力较强。当Shibor持续下降时，表明银行间资金偏宽松，说明此时市场资金较多，现金保值能力不强，此时可进行投资或消费。 @ref: https://www.poly.com.cn/blcw/s/1429-4870-19844.html R007（一）定义R007即七天回购利率，是指全市场机构的加权平均回购利率，包括银行间市场所有的质押式回购交易，不限定交易机构和标底资产。做个通俗的比方，A作为一家机构，目前资金短缺需要融资，于是，A可以通过质押手中信用债或者利率债等债券的方式进行融资，并且规定好一定期限后，再进行回购，而在回购时A需要支付给借款机构一定的利息，所以，这就产生了回购利率。为何采用的是7而不是2、3、4等这些数字呢？R007实际覆盖了回购期限为2、3、4、5、6、7天的质押式回购交易。 （二）意义7天回购利率是当前最具有市场均衡意义的利率。由于其参与机构广，交易量大，不易被个别机构操纵；此外，七天回购率反应灵敏，连续性和弹性好，所以，它成为了货币市场的关键利率指标。 DR007（一）定义DR007，为银行间存款类机构以利率债为质押的7天期回购利率。1997 年，中国人民银行制定了《银行间债券回购业务暂行规定》。根据规定，质押式回购全市场的交易主体为“具有债券交易资格的商业银行及其授权分支机构、农村信用联 社、城市信用社等存款类金融机构，保险公司、证券公司、基金管理公司及其管理的基金、资产管理组合、保险产品、财务公司等非银行 金融机构，以及经营人民币业务的外资金融机构” （二）DR007和R007的区别DR007与R007的区别主要有两点：首先，DR007的参与者主要是银行，而R007的参与者除了银行之外，还包括非金融性机构等，它的参与者的范围更加广泛。换言之，R007所代表的是整个银行间的质押式回购加权平均利率，而 DR 007是代表存款类机构的质押式回购加权平均利率。（是不是反了？）其次，DR007的质押品是以利率债等作为标的，实际上降低了信用风险溢价，同时也由于参与者和质押品的范围较窄，所以大大降低了DR007的便利性。 （三）DR007和Shibor的区别DR007与Shibor的最大区别在于：是否为真实成交利率。DR007是中国外汇交易中心根据银行间质押式回购市场所有存款类机构之间开展的质押式回购交易形成的回购市场加权利率，是真实成交利率；而Shibor是基于报价行报价计算得到的利率，并非真实成交利率","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"宏观经济","slug":"宏观经济","permalink":"https://beefyheisenberg.github.io/tags/宏观经济/"},{"name":"宏观调控","slug":"宏观调控","permalink":"https://beefyheisenberg.github.io/tags/宏观调控/"}]},{"title":"F27.LPR和利率","slug":"52.Financing/F27.LPR和利率","date":"2024-01-24T01:27:53.323Z","updated":"2024-01-24T01:27:53.323Z","comments":true,"path":"52.Financing/F27.LPR和利率/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F27.LPR和利率/","excerpt":"在宏观经济学的有关模型中（比如IS-LM）不必区分存款利率和贷款利率，因为存贷款利率是同方向移动的，不影响对模型的理解。 利率的构成如果拆解一下利率的组成（广义上的利率，存款利率/信用卡利率/房贷利率），主要有三部分构成：利率 = 无风险利率 + 风险溢价率 + 银行收益 ，无风险利率≈国债的利率（对应本国货币的无风险利率），风险溢价率一般是放贷方根据对方偿还能力计算出来的（信誉越高，这部分就越低），以及银行收益（银行通过放贷赚取的差价） 基准利率和LPR 基准利率: 是人民银行公布的商业银行存款、贷款、贴现等业务的指导性利率, 各金融机构的存款利率目前可以在基准利率基础上下浮10%, 贷款利率可以在基准利率基础上下浮20%. 存款利率分为 活期, 定期 贷款利率, 一年, 一年至五年 2019前的贷款利率使用“基准利率”形式，新（2019后）的贷款都使用LPR计算方式 LPR也即“贷款市场报价”（Loan Prime Rate），由18家银行向同业拆借中心提交报价，去头去尾平均得到LPR，每月公布 LPR = avg（18家银行的“MLF利率+浮动点”） 浮动贷款实际放贷利率 = avg（MLF + 报价浮点） + 银行放贷加点 央行决定MLF 银行自己决定自己的报价浮点 银行自己决定实际放贷加点，但央行可以通过政策影响这部分加点 LPR分1年和5年LPR，对应不同期限的贷款使用 无论固定利率贷款还是浮动利率贷款，利率都是按照“ LPR+点数”计算出的，不同的是前者一旦签订利率不变，后者每年都根据LPR做调整，但点数不变（点数取决于不同银行，不同地区也不同） 住房贷款部分，新签订的住房贷款采用最近一次公布的5年LPR，再加点，点数取决于地区和银行。合同签订后，住房贷款每年调整一次（按照合同里的重定价周期），一般是1月1号。","text":"在宏观经济学的有关模型中（比如IS-LM）不必区分存款利率和贷款利率，因为存贷款利率是同方向移动的，不影响对模型的理解。 利率的构成如果拆解一下利率的组成（广义上的利率，存款利率/信用卡利率/房贷利率），主要有三部分构成：利率 = 无风险利率 + 风险溢价率 + 银行收益 ，无风险利率≈国债的利率（对应本国货币的无风险利率），风险溢价率一般是放贷方根据对方偿还能力计算出来的（信誉越高，这部分就越低），以及银行收益（银行通过放贷赚取的差价） 基准利率和LPR 基准利率: 是人民银行公布的商业银行存款、贷款、贴现等业务的指导性利率, 各金融机构的存款利率目前可以在基准利率基础上下浮10%, 贷款利率可以在基准利率基础上下浮20%. 存款利率分为 活期, 定期 贷款利率, 一年, 一年至五年 2019前的贷款利率使用“基准利率”形式，新（2019后）的贷款都使用LPR计算方式 LPR也即“贷款市场报价”（Loan Prime Rate），由18家银行向同业拆借中心提交报价，去头去尾平均得到LPR，每月公布 LPR = avg（18家银行的“MLF利率+浮动点”） 浮动贷款实际放贷利率 = avg（MLF + 报价浮点） + 银行放贷加点 央行决定MLF 银行自己决定自己的报价浮点 银行自己决定实际放贷加点，但央行可以通过政策影响这部分加点 LPR分1年和5年LPR，对应不同期限的贷款使用 无论固定利率贷款还是浮动利率贷款，利率都是按照“ LPR+点数”计算出的，不同的是前者一旦签订利率不变，后者每年都根据LPR做调整，但点数不变（点数取决于不同银行，不同地区也不同） 住房贷款部分，新签订的住房贷款采用最近一次公布的5年LPR，再加点，点数取决于地区和银行。合同签订后，住房贷款每年调整一次（按照合同里的重定价周期），一般是1月1号。 以上参考: &lt;https://av.sc.com/cn/content/docs/cn-question-and-answer-of-loan-market-quotation-rate.pdf &gt; ➤ 同业拆借利率： Ø F27a.同业拆借利率（Shibor）采用报价制度，以拆借利率为基础，即参与银行每天对各个期限的拆借品种进行报价，对报价进行加权平均处理后，公布各个期限的平均拆借利率即为SHIBOR利率。 Ø 若当前SHIBOR利率低，意味着银行不缺钱 Ø SHIBOR和MLF的关系？ 是否 SHIBOR＝MLF+点？ @todo 名义利率 &amp; 实际利率根据费雪效应：$$（1+名义利率）=（1+实际利率）*（1+通胀率）$$ 解释: 储蓄100元，储蓄时约定利率为10%。则一年后获得本金+利息总计110元。如果该年内通胀率为0，那么名义利率=实际利率=10% 同样的100元，储蓄时约定利率为10%。但该区域内通胀率为4%，即一年前某物品需要100元，则现在该产品需要104元才能购买。在这种情况下进行储蓄，一年后获得本金+利息=100+10=110元。 根据（1+名义利率）=（1+实际利率）*（1+通胀率）（名义利率=10%，通胀率=4%） 实际利率=（1+10%）/（1+4%）-1=5.76% 即：我们储蓄的利率随着通货膨胀（紧缩）而相应的减少（增加） @link: F28.费雪公式","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"宏观经济","slug":"宏观经济","permalink":"https://beefyheisenberg.github.io/tags/宏观经济/"},{"name":"宏观调控","slug":"宏观调控","permalink":"https://beefyheisenberg.github.io/tags/宏观调控/"}]},{"title":"F23b.汇率.md","slug":"52.Financing/F23b.汇率","date":"2024-01-24T01:27:53.316Z","updated":"2024-01-24T01:27:53.316Z","comments":true,"path":"52.Financing/F23b.汇率/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F23b.汇率/","excerpt":"人民币为什么不能自由兑换外币？为什么要进行外汇管制？ - 知乎 人民币自由兑换 - MBA智库百科 1、在岸人民币市场 在岸人民币用Chinese Yuan表示，简称CNY。在岸人民币市场我们简单理解为，在中国境内市场流通人民币的市场。比如，我们平时接触的个人银行业务等… 在岸人民币市场受到管制相对较多： 例如兑换美元，境内个人每年购汇上限是5万美元,向境外汇款上限是“每天5万美元” 这时候换汇的汇率，称为在岸人民币汇率，中国外汇交易中心于每个工作日上午会对外发布兑美元等货币的汇率中间价，中间价作为当日银行间即期外汇市场及银行柜台交易汇率的参考价，人民币兑美元汇率中间价的偏离度不能超过2%，人民币兑其他币种的中间价偏离度不超过3%。 2、离岸人民币市场","text":"人民币为什么不能自由兑换外币？为什么要进行外汇管制？ - 知乎 人民币自由兑换 - MBA智库百科 1、在岸人民币市场 在岸人民币用Chinese Yuan表示，简称CNY。在岸人民币市场我们简单理解为，在中国境内市场流通人民币的市场。比如，我们平时接触的个人银行业务等… 在岸人民币市场受到管制相对较多： 例如兑换美元，境内个人每年购汇上限是5万美元,向境外汇款上限是“每天5万美元” 这时候换汇的汇率，称为在岸人民币汇率，中国外汇交易中心于每个工作日上午会对外发布兑美元等货币的汇率中间价，中间价作为当日银行间即期外汇市场及银行柜台交易汇率的参考价，人民币兑美元汇率中间价的偏离度不能超过2%，人民币兑其他币种的中间价偏离度不超过3%。 2、离岸人民币市场 所谓离岸人民币市场，就是中国境外经营人民币存放款业务的市场。与在岸相比，离岸市场的发展时间较短，规模较小，主要向非居民提供服务，由于离岸人民币市场受管制较少，汇率受市场供需关系影响更大。 中国香港是重要的人民币离岸市场，在中国香港实施的离岸人民币交易被称为 CNH 我们对离岸人民币市场可以这样定义，主要由非居民参与，受国内金融法规管制较少，进行人民币与国际自由兑换货币交易的市场，资金出入相对自由。因为我国还不具备全面放开资本管制的条件，而发展离岸市场对于人民币国际地位的提升具有重要意义。通过设立离岸市场，有利于提高人民币在国际市场的认可度、接受度及使用频率。 由于上述原因，自然就也就有了两个市场、两种汇率。 汇率的不可能三角：F28.蒙代尔不可能三角","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"汇率","slug":"汇率","permalink":"https://beefyheisenberg.github.io/tags/汇率/"},{"name":"离岸人民币","slug":"离岸人民币","permalink":"https://beefyheisenberg.github.io/tags/离岸人民币/"},{"name":"在岸人民币","slug":"在岸人民币","permalink":"https://beefyheisenberg.github.io/tags/在岸人民币/"}]},{"title":"F23a.M2和社融","slug":"52.Financing/F23a.M2和社融","date":"2024-01-24T01:27:53.312Z","updated":"2024-01-24T01:27:53.312Z","comments":true,"path":"52.Financing/F23a.M2和社融/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F23a.M2和社融/","excerpt":"@moc: 什么是货币供应指标（M0、M1、M2） 什么是社融？社融看哪些指标？ M2和社融，与实体经济/股市/债市的关系：@link F30e.股市与宏观经济的关系 “社融-M2”增速差 &amp; 债市的关系 新增社融增速 &amp; 股市的关系 M1-M2同比增速差 &amp; 经济增长水平的关系 货币供应指标（M0、M1、M2） M0（货币）= 流通中的现金，即流通于银行体系之外的现金。 M1（狭义货币）= M0 + 活期存款； M2（广义货币）= M1 + 定期存款（准货币） 定期存款（准货币）包括：单位定期存款 + 居民定期存款 + 其他存款 + 证券公司客户保证金 + 住房公积金中心存款 + 非存款类金融机构在存款类金融机构的存款","text":"@moc: 什么是货币供应指标（M0、M1、M2） 什么是社融？社融看哪些指标？ M2和社融，与实体经济/股市/债市的关系：@link F30e.股市与宏观经济的关系 “社融-M2”增速差 &amp; 债市的关系 新增社融增速 &amp; 股市的关系 M1-M2同比增速差 &amp; 经济增长水平的关系 货币供应指标（M0、M1、M2） M0（货币）= 流通中的现金，即流通于银行体系之外的现金。 M1（狭义货币）= M0 + 活期存款； M2（广义货币）= M1 + 定期存款（准货币） 定期存款（准货币）包括：单位定期存款 + 居民定期存款 + 其他存款 + 证券公司客户保证金 + 住房公积金中心存款 + 非存款类金融机构在存款类金融机构的存款 M1主要是企业的营运资金。所以如果M1增速没有M2快，往往说明实体经济不愿意搞扩张，而是把钱给存起来。 @link: F30e.股市与宏观经济的关系/M1-M2剪刀差 货币供应的季节性M0、M1、M2季节性特点明显：和贷款一样，每个季末银行内部都会有存款规模考核，所以每个银行到了季末的时候，都会提高揽储的力度，增加表内的居民或企业存款，有些银行会将到期理财暂时转入表内做存款等。在具体分析某一个季末月的存款规模时，可以将该数值与季节性均值相比，从而看这种季节性冲量效应的强弱与贡献。（春节的时点也容易出现存款的异动。很多企业在春节前发年终奖，所以我们会看到在1月份或2月份，企业端的存款规模会大幅减少，而居民端的存款规模会有很明显的上涨） 既然货币供应量是由存款和流通中的现金（比例不足5%，基本忽略）构成，那么我们就从存款入手，分析各项存款规模变化的原因 还需要关注财政存款的变化引发的存款波动： 央行在披露货币供应量的同时，还会披露财政存款的规模，但财政存款不在M2的口径范围内。 一旦财政存款增加，就意味着企业把钱上缴给了国库，货币从企业或个人手中流向了政府部门，存留于实体经济的钱少了。相反，当财政存款下降，就意味着国库里的钱流向了实体经济，货币从政府部门到了企业部门，存留于实体经济的钱多了。 因此，财政存款增长会拖累M1和 M2；财政存款的下降会提升M1和M2。 财政存款有其自身的季节性变化。一般来讲，1、4、5、7、10月是财政存款上缴月，而3、6、9、12月（也就是每个季末）是财政资金投放的时点。 从M2看信用的派生$$ M2= 各项贷款 ＋ 一级市场信用债投资 + 非标 + 外汇占款 - 财政存款 $$ 1、贷款可以派生出存款，对M2是正贡献。 2、债券投资主要是银行自营持有的国债、地方政府债以及非金融企业发行的信用债，但要扣减掉其他诸如政策性银行债、存单及二级资本债等债券，因为这部分没有直接创造存款。债券投资扣减金融债券的部分才是能够反映创造存款的债券投资部分。 如果银行自营持有的是国债+地方政府债，那么相当于货币流向了政府部门，增加的是财政存款，所以我们在等式右边减掉了一个财政存款，将这部分债券投资规模去掉。 只有国债+地方债用于了财政支出，财政的钱转化为了企业的钱，才能算成是存款。 如果银行自营持有的非金融企业发行的信用债，那么这些资金会带来银行企业存款的增长，对M2同样是正贡献。 因此，债券投资能够增加M2的部分主要指的是一级市场上的信用债投资。 3、股权及其他投资项里，主要是银行自营持有的非标、券商资管计划、同业理财、公募基金等资管产品。 如果投资的是非标，那么资金直接流向了企业部门，增加的是企业存款；如果投资的是券商资管计划、公募基金等资管产品，那么资金流向了非银机构，短期增加的是非银存款，非银存款也计入M2，如果非银买了债，或者做了非标，还是会回到实体，同样对M2是正向贡献。 不过在股权及其他投资项里，要扣减其他项，这一项目前没有一个明确的答案，从我们了解得到的信息来看，这一项主要是用来平衡资金运用和资金来源的等式关系的，但它的波动似乎与金融同业活动头寸没有轧差干净有关，所以把它扣减在表内委托和非标投资里。 4、央行口径的外汇占款。这个代表的是外部力量带来的增长动力，当出口企业收到外汇时，它们找商业银行结汇，这个过程让企业得到了人民币（存在了银行体系），银行得到了外汇，企业存款得到了增加。 社融@tldr: 如何正确解读社融？ 一要排除社融增量的季节性，可以通过窗口周期的方式求的移动平均，或者与同样有周期性的M2等数据做剪刀差，具体参考 =&gt; F30e.股市与宏观经济的关系/社融 二是除了社融增量，还需注意社融结构的变化、以及中长期比重的变化，可以通过研报和分析师文章解读 ➤ 什么是社融：社会融资规模，一定时期实体经济从金融体系获得的资金总额。 ➤ 社融的构成：我们可以将社融分为四个大项，四个大项里有十二、三个小项： ➤ 几个主要部分的解释： 表内贷款（约60-70%）：金融机构发放这些贷款时，要记入资产负债表（监管会针对这些业务上缴存款准备金） • 人民币贷款是直接体现在银行资产负债表中且以人民币为计算单位的贷款，不包括非银贷款。谁会找银行借钱呢？一般就是居民、企业和非银同业了。所以，新增人民币信贷可以从流向分为企业部门、居民部门和非银部门三个类别。 • 外币贷款是金融机构以票据贴现、信贷、垫款等方式向非金融企业与居民发放的，以外币为计算单位的贷款。从使用用途上来讲，外币贷款主要用于进口商品付汇或资本账户下的对外投资。 表外融资（约10%+）：信托贷款、委托贷款、未贴现银行承兑汇票 • 信托贷款：投资者把钱投资到信托，信托会把一部分钱拿去放贷 • 委托贷款：A找B贷款，但B没有放贷资质，B需要委托银行作为中间人 • 未贴现银行承兑汇票： … 直接融资（很小）： • 企业债券融资：包括非金融企业发行的企业债、超短期融资券、短期融资券、中期票据… • 股票融资指非金融企业通过境内正规金融市场进行的股票融资，具体包括IPO、定向增发等方式，受监管政策和股票市场行情影响较大。当股票市场是牛市，IPO多的时候，这块新增量就会放大，不过股票融资毕竟在国内还不是主流，每个月高的时候也就新增1000亿出头，低的时候只有几百亿，分析社融的时候不需要太过关注。 如何解读社融数据？ 1）社融增量：因为社融增量波动很大，一般也不看环比和同比，更多情况下看社融增量的绝对值和预期值的差额 2）社融存量：看同比增速，与预期增速的差额（上面提到了和GDP增速有相关性）// 社融规模存量同比 3）社融结构： @todo 社融数据，央行会公布两种口径，一个是当月新增规模（增量），第二个是存量规模数据。 • 在数据分析过程当中，主要是看新增值，因为当月的新增社融能很快地揭示实体融资需求和金融扩表意愿，一般是拿这个月的新增值和上个月的环比、去年同期的数据去做分析。 • 而社融存量数据主要是看社融存量的同比数据。至于说见顶的标志，指的就是社融存量同比是不是见顶。比如2020年四季度，因为疫情对经济的冲击减弱，经济陆续回归正常，货币政策也在回归常态化，不可能保持和疫情期间一样的宽松货币政策，所以市场都在讨论社融是不是要见顶了。 图1：2020年10月的社融（存量）同比为13.7%见顶，随后就持续下行至2021年1月的13% （纵轴是社融余额同比，单位%）： 社融数据的季节性需要注意的是，新增社融非常容易受到季节性因素的影响，在做分析的时候，不仅要和上个月对比，最好也要和去年同期去对比，否则容易有误判。新增社融季节性冲量特征体现在1月、3月、6月、9月与11月会有明显扩张，而在4月、5月、7月、10月和12月会有明显的收缩。然后就是季末的时候会多放点，季末用力过猛后下个季度的初月就少放点。因为在每个季末，银行内部有业绩指标的考核压力，监管会来看银行支持了小微企业没有，支持了制造业企业没有，为满足考核要求，银行业务人员会在季末冲量，然后下个月项目就少了，所以社融新增就增不动了。因此，新增社融数据是有高波动性的。在分析一个高波动数据的时候，一定得先过滤掉季节性影响，绝不能把季节性的波动当成趋势。 社融和M2具有极其相似的季节性：1月、3月、6月、9月与11月会有明显扩张 @ref: 什么才是读懂社融、M2的正确姿势？请收好这份金融数据分析手册 - 华尔街见闻 M2和社融的产生、差异➤ 钱是怎么印的： 发行货币时，央行先向银行投放基础货币（比如一次放贷款行为，即再贷款），形成银行在央行账户里的“存款”（准备金）。基础货币还不是我们手上流通的货币。银行再把这些基础货币投放给居民（比如发放贷款），于是就在居民的账户里形成存款，这才是我们的货币（计入M2）。所以，这里有两个动作，先是央行向银行投放基础货币，然后是银行向居民投放M2。 银行完成了一笔贷款并形成相应的M2（比如100元）后，借款人把这钱存到另外一家银行B。银行B拿到100元存款，交了20%的存款准备金（相当于有20元按央行要求被冻结起来），然后把其余的80元继续放贷款去。第二个借款人拿到80元，又存到另一家银行……继续循环。 如此无穷尽，央行最初投放的一笔100元的基础货币，经过无数次投放贷款，最后在全社会形成500元的M2。所以货币乘数是5，也就是货币派生倍数（或者叫货币乘数，等于准备金率的倒数）。 所以，在二级银行制度（央行-商业银行-居民）下，央行只“印”了基础货币，而广义货币是银行通过信贷投放来派生的。央行又规定了存款准备金率，从而限定的银行派生M2的能力。 银行每一次放贷派生M2，就是一次融资行为，同时形成社融余额和M2余额，这两个指标处于银行资产负债表的两边。 社会融资为金融机构的“资产端”，可大体反映市场的融资需求和金融机构放贷意愿。 M2 为金融机构的“负债端”，主体为银行的存款，反映的是实体经济的流动性多寡 从这个意义上讲，如果贷款几乎是惟一的融资渠道，又几乎是惟一的M2派生渠道，那么信贷、M2和社融三者几乎是相近的，仿佛是会计科目的借贷两边，金额相等。 但是随着金融体系的多元化，三者出现偏离，主要有： 非信贷的M2派生渠道增多，比如银行通过购买企业债券、投放非标的方式给企业融资，形成M2。但此时，信贷、债券、非标都计入社融里，所以M2和社融依然相近，但信贷会低于M2和社融。 非派生而来的M2增多，比如外汇占款直接投放M2。此时，M2高出了信贷和社融。 直接融资增加，计入社融，但完全不影响信贷和M2，因为直接融资不会派生M2（是存量M2的转移）。此时，社融就高过了信贷和M2。 最后，形成了信贷&lt;M2，信贷&lt;社融 的局面。而M2与社融的大小比较，则取决外占和直接融资的比较。 …由此，就引出了一个融资结构问题。央行管控了全部的M2增量，并不因此就高枕无忧了。因为现在派生M2的方法很多，信贷、银行购债、银行放非标等均可。同样派生100块钱的M2，不同方法，对融资者有不同的影响。 因为，不同类型的主体，会适应不同的融资工具。比如，中小企业普遍使用贷款，而大中型企业倾向使用债券等。还有些不那么“合规”的融资主体，比如受限期间的房地产企业、地方政府融资平台，则使用非标等。这些工具都具有派M2功能，如果央行关注M2总量，任由银行自行选择派生渠道，则有可能出现结构失衡，某些渠道泛滥而某些渠道干涸，这意味着某些类型的主体撑死，另一些则渴死。比如，近期经济不行，银行给中小企业放款少，却拼命给政府平台放款。从银行自身而言，规避风险无可厚非，但中央支持实体经济的意图就落空了。 直接融资（股票、债券、信托等，但由银行自有资金购买的除外）和表外融资（银行承兑汇票）的特点，是不增加M2。我国M2/GDP比例已经很高，把很多人吓坏了。其实，从前文分析能看出来，这并不意味着我国一定是货币超发，而可能是意味着我国产业太传统，大多适合间接融资（信贷、非标等）。而新兴产业则多适合用直接融资，其中又以股权融资为主。 所以，随着我国新兴产业发展，直接融资比例会上升，M2/GDP也就会下降的。 @ref : 一文阐明货币政策、信贷、M2与社融|货币政策|社融|M2_新浪财经_新浪网 M2和社融历史数据 @OneNote： • 社融连续N个月维持较高增量，才视作有效的融资需求增加• 社融增量明显的几个年份：2009-2010、2013、2017、2020社融增量和PMI的关系：除了2013特殊（社融增量↑，但PMI表现平淡，熊市），此外几个年份股市都表现同社融较为同步；","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"宏观经济","slug":"宏观经济","permalink":"https://beefyheisenberg.github.io/tags/宏观经济/"},{"name":"社融","slug":"社融","permalink":"https://beefyheisenberg.github.io/tags/社融/"},{"name":"M2","slug":"M2","permalink":"https://beefyheisenberg.github.io/tags/M2/"}]},{"title":"F23.经济指标和历史数据","slug":"52.Financing/F23.经济指标和历史数据","date":"2024-01-24T01:27:53.307Z","updated":"2024-01-24T01:27:53.308Z","comments":true,"path":"52.Financing/F23.经济指标和历史数据/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F23.经济指标和历史数据/","excerpt":"常用宏观经济指标➤ 经济指标： GDP: 国内生产总值 PPI: 生产者价格指数 CPI: 消费者物价指数, 是反映一定时期内城乡居民所购买的生活消费品和服务项目价格变动趋势和程度的相对数，是对城市居民消费价格指数和农村居民消费价格指数进行综合汇总计算的结果。通过该指数可以观察和分析消费品的零售价格和服务项目价格变动对城乡居民实际生活费支出的影响程度。 CPI反映消费价格变化情况，是一个相对数。GDP反映国民经济生产总量，是一个绝对数。CPI的变动反映经济运行过程中物价变动情况，是观察通货膨胀程度的重要指标，GDP的变化则反映经济的增长情况。经济增长与通货膨胀的关系存在以下四种情形：高增长低通胀，高增长高通胀，低增长低通胀，低增长高通胀。 PMI: 采购经理人指数, PMI是衡量制造业的体检表，为领先指标中一项重要数据，可衡量制造业在生产、新订单、商品价格、存货、雇员、订单交货、新出口订单和进口等状况。PMI是以百分比来表示,常以50%作为经济强弱的分界点：当指数高于50%时，则被解释为经济扩张的讯号。当指数低于50%，尤其是非常接近40%时，则有经济萧条的忧虑。一般在40~~50之间时，说明制造业处于衰退，但整体经济还在扩张。 @ref: https://zh.m.wikipedia.org/zh-hans/%E9%87%87%E8%B4%AD%E7%BB%8F%E7%90%86%E6%8C%87%E6%95%B0 其中GDP/CPI是经济的滞后指标，PPI/PMI是超前指标，除此之外反应实体经济的观测指标如：M1-M2剪刀差、社融、中长期贷款余额… 参考=&gt;《实体经济观测指标》 除了经济指标，还有反应股市情况的指标：参考=&gt;《股市估值指标》，实体经济和股市的关系：参考=&gt; 《股市和宏观经济的关系》","text":"常用宏观经济指标➤ 经济指标： GDP: 国内生产总值 PPI: 生产者价格指数 CPI: 消费者物价指数, 是反映一定时期内城乡居民所购买的生活消费品和服务项目价格变动趋势和程度的相对数，是对城市居民消费价格指数和农村居民消费价格指数进行综合汇总计算的结果。通过该指数可以观察和分析消费品的零售价格和服务项目价格变动对城乡居民实际生活费支出的影响程度。 CPI反映消费价格变化情况，是一个相对数。GDP反映国民经济生产总量，是一个绝对数。CPI的变动反映经济运行过程中物价变动情况，是观察通货膨胀程度的重要指标，GDP的变化则反映经济的增长情况。经济增长与通货膨胀的关系存在以下四种情形：高增长低通胀，高增长高通胀，低增长低通胀，低增长高通胀。 PMI: 采购经理人指数, PMI是衡量制造业的体检表，为领先指标中一项重要数据，可衡量制造业在生产、新订单、商品价格、存货、雇员、订单交货、新出口订单和进口等状况。PMI是以百分比来表示,常以50%作为经济强弱的分界点：当指数高于50%时，则被解释为经济扩张的讯号。当指数低于50%，尤其是非常接近40%时，则有经济萧条的忧虑。一般在40~~50之间时，说明制造业处于衰退，但整体经济还在扩张。 @ref: https://zh.m.wikipedia.org/zh-hans/%E9%87%87%E8%B4%AD%E7%BB%8F%E7%90%86%E6%8C%87%E6%95%B0 其中GDP/CPI是经济的滞后指标，PPI/PMI是超前指标，除此之外反应实体经济的观测指标如：M1-M2剪刀差、社融、中长期贷款余额… 参考=&gt;《实体经济观测指标》 除了经济指标，还有反应股市情况的指标：参考=&gt;《股市估值指标》，实体经济和股市的关系：参考=&gt; 《股市和宏观经济的关系》 ➤ 货币/金融指标： M1-M2（增速的）剪刀差：《实体经济观测指标》 外汇储备/汇率：《蒙代尔不可能三角》 准备金率/利率：《LPR和利率》 国债收益率： 《中美国债利差倒挂》、《长端利率vs短端利率》 指标历史数据数据来源: 中国宏观成绩单 | MacroMicro 财经M平方 数据中心_东方财富 数据中心_同花顺财经 GDPGDP：纵轴是GDP同比增长率，单位是%来源：https://data.eastmoney.com/cjsj/gdp.html PMIPMI：可以看到20年2月 &amp; 22年4月都跌破了50荣枯线，PMI需要连续扩张（高于50%）才表示经济上行 还需要注意PMI的结构变化： PPI来源：https://data.eastmoney.com/cjsj/ppi.html CPI来源：https://data.eastmoney.com/cjsj/cpi.html CPI-PPI剪刀差数据来源：http://data.10jqka.com.cn/macro/cpippi/ 货币供应量（M1、M2）来源：https://data.eastmoney.com/cjsj/hbgyl.html M1-M2剪刀差 M1增速&lt;M2增速（即M1-M2为负剪刀差），表明市场对经济悲观，实体经济中的投资机会减少，存款定期化，经济活力较弱，更多的钱流入金融投资市场。M1-M2负剪刀差往往预示着市场投资过热、需求不旺，具有一定的经济下行风险。理论上来说，连续6个月M1-M2负剪刀差，便进入通货紧缩状态。 来源：https://sc.macromicro.me/charts/35879/zhong-guo-M1-M2-jian-dao-cha 逆回购操作 逆回購操作為中國人民銀行短期調節流動性的方法之一，是人行於市場內買入債券等有價證券，為市場注入資金和流動性，通常會使短期市場利率下滑，反之則為正回購操作。 @link: F22.宏观调控手段（中国央行） 来源：https://www.macromicro.me/collections/31/cn-finance-relative/53839/china-reverse-repurchase-agreement SHIBOR 中國上海隔拆利率 Shibor（人民幣）為銀行間同業拆借人民幣的利率，由信用等級較高的銀行組成報價團，是中國貨幣市場的基準利率，可依此了解中國金融市場的流動性。當 Shibor 利率上升，反映銀行間資金流動性趨緊。當 Shibor 利率下降，反映銀行間資金流動性寬鬆。 由于国债价格和利率负相关，所以SHIBOR见底也就是国债价格见顶的时候，至于SHIBOR的底部在哪里？ 可以参考 2020.5月 SHIBOR3m跌至1.4%（近十年最低），这是因为疫情初期为了提振经济，央行注入了大量流动性导致SHIBOR急剧下降，这也是特殊情况下的特殊货币政策，未来几年可能很少有如此大的货币刺激政策 来源：https://www.macromicro.me/collections/31/cn-finance-relative/935/cn-overnight-shibor 利率（LPR）15年之前叫基准利率，15年之后开始启用LPR利率 =&gt; F27.LPR和利率来源：https://data.eastmoney.com/cjsj/globalRateLPR.html 准备金率存款准备金率最大的意义在于作为货币乘数调节货币供应量，确定新增规模是调节信贷投放量，有不同的作用，一般银行在央行都有巨额的超额储备，但是存款流动性大，吸收有助于形成流动性沉淀。来源：https://data.eastmoney.com/cjsj/ckzbj.html 十年国债收益率来源：https://wallstreetcn.com/markets/codes/CN10YR.OTC 中美国债利差（10Y）来源：https://sc.macromicro.me/charts/18341/cn-10-year-yield-spread-between-cn-and-us--vs-cnh 美国10Y-2Y利差正常情况下，10Y（久期更长）国债收益率是大于2Y国债的，但如果市场对美联储加息的预期更猛烈（也意味着可能出现大的经济衰退），会让导致2Y国债收益率涨的更快，极端情况下造成10Y-2Y利差的倒挂。出现过倒挂的年份，都出现过大幅加息和严重的经济衰退，如2000年、2006年，虽然在2019年也有加息，但加息幅度不高（高点2.4%）且持续时间很短，所以2019并未造成倒挂。 美联储FED数据https://sc.macromicro.me/central_bank/us 外汇储备来源：https://data.eastmoney.com/cjsj/hjwh.html 社融左轴-蓝色（新增社融，单位亿RMB），最新2022.10新增社融仅9079 亿元，对比之前峰值（2022.01）61000亿元；右轴-红色（新增社融同比，单位%）； 社融与 M2 的差异： 社会为金融机构的“资产端”，可大体反映市场的融资需求和金融机构放贷意愿。 M2 为金融机构的“负债端”，主体为银行的存款，反映的是实体经济的流动性多寡 注意社融增量的季节性：社融在1/3/6//9/11月新增量有明显提升，分析时应排除这方面的影响，不能看环比，而是看增量的同比，或者使用同样具有季节性的M2增量去求剪刀差，或者用6个月为时间窗口做移动平均去观察增量 // @link F30e.股市与宏观经济的关系数据来源：https://sc.macromicro.me/charts/8685/cn-total-social-financing 居民活期存款 来源：https://www.macromicro.me/collections/31/cn-finance-relative/5038/china-demand-deposits 人民币存款余额 来源：http://data.10jqka.com.cn/macro/rmb/ 居民/企业杠杆率来源：https://www.macromicro.me/collections/31/cn-finance-relative/33510/cn-macro-leverage-ratio 新增信贷新增信贷有明显的月份效应，1、3、6、9月新增明显超过其他月份。来源：https://data.eastmoney.com/cjsj/xzxd.html 消费者信心指数来源：https://data.eastmoney.com/cjsj/xfzxx.html 企业景气及企业家信心指数来源：https://data.eastmoney.com/cjsj/qyjqzs.html 工业增加值 中国工业增加值即工业企业在生产活动最后的成果，是用来反映一定时期工业生产物量增减变动程度的指标，统计范围为年主营业务收入 2000 万元及以上的工业企业，工业增加值为中国 GDP 的重要组成( 约 占 30％)，是观察中国整体景气的重要经济指标。工业增加值的公式如下工业增加值 = 工业总产出-工业中间投入+应缴增值税来源：https://data.eastmoney.com/cjsj/gyzjz.html / https://sc.macromicro.me/collections/55/cn-shanghai-shengzhen-csi-300-index/229/cn-value-added-of-industry-pmi 海关进出口来源：https://data.eastmoney.com/cjsj/hgjck.html 左轴：百分比；蓝（进口总值同比）；红（出口总值同比）；右轴：贸易差额（亿美元）;来源：https://sc.macromicro.me/collections/27/cn-trade-finance-relative/276/cn-china-trade-balance 全国税收收入来源：https://data.eastmoney.com/cjsj/qgsssr.html 股市-融资融券来源：https://sc.macromicro.me/charts/2835/china-sse-and-margin-buy 来源：https://legulegu.com/stockdata/margin-trading 来源：https://data.eastmoney.com/rzrq/total.html 股市-行业估值来源：https://data.eastmoney.com/gzfx/ 股市-月交易额来源: https://data.eastmoney.com/cjsj/gpjytj.html 期货库存来源：https://data.eastmoney.com/ifdata/kcsj.html","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"宏观经济","slug":"宏观经济","permalink":"https://beefyheisenberg.github.io/tags/宏观经济/"},{"name":"财经历史数据","slug":"财经历史数据","permalink":"https://beefyheisenberg.github.io/tags/财经历史数据/"}]},{"title":"F22.宏观调控手段（中国央行）","slug":"52.Financing/F22.宏观调控手段（中国央行）","date":"2024-01-24T01:27:53.301Z","updated":"2024-01-24T01:27:53.302Z","comments":true,"path":"52.Financing/F22.宏观调控手段（中国央行）/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F22.宏观调控手段（中国央行）/","excerpt":"央行资产负债表右边红色=资产端，左边绿色=负债端： 资产端： （1）“国外资产”包括外汇、黄金和其他国外资产。其中外汇占比高达96.95%（截至2020年7月）。“国外资产”中的外汇项即俗称的央行口径外汇占款。由于人民币是非自由兑换货币，外资引入后需兑换成人民币才能进入流通使用，国家为了外资换汇要投入大量的资金，需要国家用本国货币购买外汇，因此增加了负债端的“储备货币”，从而形成了外汇占款。 （2）“对其他存款性公司债权”指央行通过公开市场操作、创新工具和其它工具（再贴现、再贷款）向其他存款性公司投放的基础货币。“对其他存款性公司债权”主要投放方式： • 公开市场操作（传统型）： ○ 逆回购 ○ 短期流动性调节工具（SLO) ○ 中央国库现金管理商业银行定期存款 • 创新工具： ○ 常备借贷便利（SLF) ○ 中期借贷便利(MLF) ○ …. • 其他工具： ○ 再贴现、再贷款","text":"央行资产负债表右边红色=资产端，左边绿色=负债端： 资产端： （1）“国外资产”包括外汇、黄金和其他国外资产。其中外汇占比高达96.95%（截至2020年7月）。“国外资产”中的外汇项即俗称的央行口径外汇占款。由于人民币是非自由兑换货币，外资引入后需兑换成人民币才能进入流通使用，国家为了外资换汇要投入大量的资金，需要国家用本国货币购买外汇，因此增加了负债端的“储备货币”，从而形成了外汇占款。 （2）“对其他存款性公司债权”指央行通过公开市场操作、创新工具和其它工具（再贴现、再贷款）向其他存款性公司投放的基础货币。“对其他存款性公司债权”主要投放方式： • 公开市场操作（传统型）： ○ 逆回购 ○ 短期流动性调节工具（SLO) ○ 中央国库现金管理商业银行定期存款 • 创新工具： ○ 常备借贷便利（SLF) ○ 中期借贷便利(MLF) ○ …. • 其他工具： ○ 再贴现、再贷款 负债端： 负债端中占比最大的项目是“储备货币”和“政府存款”。（1）从储备货币内部结构来看，其主要分为货币发行（占比28.66%）、其它存款性公司存款（占比65.98%）和非金融机构存款（占比5.37%）。（2）政府存款：季初上缴、季末投放，加剧了储备货币的波动（3）央行发行债券又称中央银行票据，这是外汇流入阶段为回收基础货币的产物。是中央银行为调节商业银行超额准备金而向商业银行发行的短期债务凭证，其实质是中央银行债券。央行票据与金融市场各发债主体发行的债券具有根本区别：各发债主体发行的债券是一种筹集资金的手段，其目的是为了增加可用资金；而央行发行的央行票据是央行调节基础货币的一项货币政策工具，目的是减少商业银行可贷资金量。 从国债的发行看资产负债表： 财政部于2007年8月-12月发行8期特别国债，共计1.55万亿元。其中1.35万亿是定向发行。具体而言，财政部向农行发行1.35亿元特别国债，筹集人民币资金后，向央行购买等值的外汇，同时人民银行利用卖汇获得的1.35万亿人民币向农行购买等值的特别国债。// 央行-减少外汇（资产端），增加国债（负债端） @ref: 财政部将定向发行7500亿特别国债： 系到期特别国债的续作，不会对市场流动性产生影响 央行调控手段@ref: 【经济指标解读专栏】货币政策框架分析1—货币政策工具体系 - 知乎 货币政策框架包括三个部分，即货币政策目标体系、货币政策工具体系、货币政策传导机制。这三部分的关系是，央行运用自己创建的各类货币政策工具，去实现自己事先规定好的操作目标，并借助现有的传导机制来实现最终目标的一个过程。具体可梳理为两个框架： 数量型框架： 再贷款、法定存款准备金率等 价格型框架：如MLF利率、OMO利率等为了实现上述的最终目标，央行创设了越来越多便利、精准的货币政策工具，包括逆回购、MLF、TMLF、SLF、PSL等等，其既有数量型工具，也有价格型工具，既有总量型工具，也有结构型工具。 法定存款准备金率（总量/结构、数量型） 逆回购（总量型、数量/价格型） 中期借贷便利（MLF）和定向中期借贷便利（TMLF）（总量/结构型、数量/价格型） 再贷款、再贴现（总量型+数量型） 常备借贷便利（SLF）（结构型+数量型） 超额存款准备金利率（总量型+价格型） 直达实体经济的货币政策工具（结构型+数量型） 上图参考自：如何建立自己的宏观经济分析框架？ - 知乎 何为放水央行放水是央行将流动资金投放到市场当中，为市场注入流动性。央行放水主要有两种方式，包括将央行储备投入市场流通，增发更多人民币现金。 央行放水的表现形式，包括但不限于如下几种：一是降低准备金存款率；二是增加贷款储备、贷款途径；三是促进银行存款；四是发放国债、地方债。 准备金准备金（reserve）: 是商业银行库存的现金按比例存放在中央银行的存款. 实行准备金的目的是为了确保商业银行在遇到突然大量提取银行存款时, 能有相当充足的清偿能力. for example： 假设商业银行吸收了100亿存款，但是为了应付平时的支付和防止挤兑风险，会被国家法定截流10％作为“存款准备金”，银行只允许释放最多90亿的贷款资金。 降准：央行通过降低准备金率，增加银行可放贷金额，从而增加市场上货币总量的一种手段。 降准有利于商业银行释放资金，调用更多的资金投向收益更高的地方，增加银行的利润。这时候投资者也可以瞄准机会投资于银行股，银行指数基金等。 MLFMLF是中期借贷便利（Medium-term Lending Facility）的英文缩写，也俗称“麻辣粉”，是中央银行提供中期基础货币的货币政策工具。其发放对象是符合监管要求的商业银行和政策性银行，发放方式为质押方式。 MLF操作过程为，人民银行通过招标方式，选择合适的商业银行，按中标利率给商业银行借钱，同时商业银行将优质的债券作为质押品的过程；说简单点，就是央行借钱给商业银行。 以引导（商业银行）向符合国家政策导向的实体经济部门提供低成本资金，促进降低社会融资成本 “X月X日，央行进行9500亿元历史最高MLF超额操作”。 解释：期限1年就是央行把钱借给参与MLF投标的银行1年，1年后相关银行要还钱。操作量9500亿元就是央行借给符合条件的银行9500亿。中标利率2.95%就是利息，即央行把钱借给相关银行的利息。 央行可以通过控制MLF的投放量和利率来影响市场的货币供应和市场利率，所以在一定程度上，MLF通过调节向金融机构中期融资的成本来对金融机构的资产负债表和市场预期产生影响，促进降低社会融资成本。 例如小微企业往往达不到银行的风控标准，银行不愿放贷，但是如果银行以国债、央行票据、政策性金融债、高等级信用债等优质债券 或 不低于AA级的小微、绿色和“三农”金融债券作为质押品，那么央行愿意以较低的利率借给银行一笔资金。 国债逆回购 “央行进行350亿7天期逆回购” 央行向银行购买350亿的有价证券（一般是国债），把之前卖给银行的国债再“买回来”，同时向银行释放资金（等于向市场释放资金），7天后央行收回资金+利息，同时把国债还给银行。 相比较 MLF 是中期放水，国债逆回购是短期放水。 加息&amp; 降息降息途径：央行控制MLF利率 =&gt; 影响 LPR =&gt; 影响银行的浮动利率（？不确定） // @link： F27.LPR和利率 央行亲自划重点：加息降息主要看DR007加权平均利率 - 21财经： 2月8日，央行发布《2020年第四季度货币政策执行报告》指出，判断短期利率走势首先要看政策利率是否发生变化，主要是央行公开市场7天期逆回购操作利率是否变化，而不应过度关注公开市场操作数量。公开市场操作数量会根据财政、现金等多种临时性因素以及市场需求情况灵活调整，其变化并不完全反映市场利率走势，也不代表央行政策利率变化。其次，在观察市场利率时重点看市场主要利率指标（DR007）的加权平均利率水平，以及 DR007 在一段时期的平均值，而不是个别机构的成交利率或受短期因素扰动的时点值。 @link: F27a.同业拆借利率（Shibor）","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"央行","slug":"央行","permalink":"https://beefyheisenberg.github.io/tags/央行/"},{"name":"宏观调控","slug":"宏观调控","permalink":"https://beefyheisenberg.github.io/tags/宏观调控/"},{"name":"MLF","slug":"MLF","permalink":"https://beefyheisenberg.github.io/tags/MLF/"}]},{"title":"F22.宏观调控手段（美联储）","slug":"52.Financing/F22.宏观调控手段（美联储）","date":"2024-01-24T01:27:53.297Z","updated":"2024-01-24T01:27:53.297Z","comments":true,"path":"52.Financing/F22.宏观调控手段（美联储）/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F22.宏观调控手段（美联储）/","excerpt":"名词： FED：美联储即美国联邦储备系统，是美国中央银行，英文全称为The Federal Reserve System，简称FED FOMC：FOMC是联邦公开市场委员会（Federal Open Market Committee） QT：量化紧缩，Quantitative Tightening； QE：量化宽松，Quantitative Easing； OMO： 公开市场操作（Open Market Operations），简称 OMO FFR： 联邦基金利率（Federal funds rate），简称 FFR，类似国内的隔夜拆借利率 EFFR：联邦基金有效利率，Effective Federal Fund Rate，简称EFFR。美联储的纽约分联储，会根据上一日联邦基金市场实际成交利率，统计出来并向社会公布的短期美联储体系内的加权利率 IORB Rate：准备金利率（Interest on Reserve Balances）。2006年，美国金融服务监管救济法案中，授权美联储对银行存款准备金付息，原定2011年10月1日生效。但是，次贷危机爆发后，提前至2008年10月1日生效。根据这一法案，美联储对法定准备金及超额准备金支付利息（原来像其他西方国家一样，不支付利息） 美联储常规的货币政策工具有三：存款准备金制度、再贴现政策和 公开市场业务。 这里提到的 公开市场业务（or称 “公开市场操作”，英文是Open Market Operations，简称OMO），即美联储在公开市场上买卖有价证券（一般是美国国债）的做法 // 参考 [[#加息]] &amp; [[#缩表]]，抛售债券 &amp;停止债券再投资 再贴现政策：中央银行对商业银行发放贷款（基础货币）的利率，即为再贴现率，美联储通过调整再贴现率，影响银行间的拆借率 @ref: 美联储联邦基金利率和再贴现率的关系是怎样的？ - 知乎 存款准备金制度： @ref 从“准备金短缺”到“准备金盈余” ——美联储货币政策操作框架转型及展望|货币政策新浪财经新浪网","text":"名词： FED：美联储即美国联邦储备系统，是美国中央银行，英文全称为The Federal Reserve System，简称FED FOMC：FOMC是联邦公开市场委员会（Federal Open Market Committee） QT：量化紧缩，Quantitative Tightening； QE：量化宽松，Quantitative Easing； OMO： 公开市场操作（Open Market Operations），简称 OMO FFR： 联邦基金利率（Federal funds rate），简称 FFR，类似国内的隔夜拆借利率 EFFR：联邦基金有效利率，Effective Federal Fund Rate，简称EFFR。美联储的纽约分联储，会根据上一日联邦基金市场实际成交利率，统计出来并向社会公布的短期美联储体系内的加权利率 IORB Rate：准备金利率（Interest on Reserve Balances）。2006年，美国金融服务监管救济法案中，授权美联储对银行存款准备金付息，原定2011年10月1日生效。但是，次贷危机爆发后，提前至2008年10月1日生效。根据这一法案，美联储对法定准备金及超额准备金支付利息（原来像其他西方国家一样，不支付利息） 美联储常规的货币政策工具有三：存款准备金制度、再贴现政策和 公开市场业务。 这里提到的 公开市场业务（or称 “公开市场操作”，英文是Open Market Operations，简称OMO），即美联储在公开市场上买卖有价证券（一般是美国国债）的做法 // 参考 [[#加息]] &amp; [[#缩表]]，抛售债券 &amp;停止债券再投资 再贴现政策：中央银行对商业银行发放贷款（基础货币）的利率，即为再贴现率，美联储通过调整再贴现率，影响银行间的拆借率 @ref: 美联储联邦基金利率和再贴现率的关系是怎样的？ - 知乎 存款准备金制度： @ref 从“准备金短缺”到“准备金盈余” ——美联储货币政策操作框架转型及展望|货币政策新浪财经新浪网 加息FOMC是联邦公开市场委员会（Federal Open Market Committee），由政府和美联储银行的12名委员组成，他们每6周在华盛顿开一次会（议息会议），做出关于利率的决策。=&gt; [[#看懂点阵图]] 例如22年11月的 FOMC 会议上：“本次是美联储连续第四次加息75个基点，从而将联邦基金利率推高至3.75%～4%之间”。 联邦基金利率（Federal funds rate， FFR）是最重要的短期利率，最主要的为隔夜拆借利率。这种利率的变动能够敏感地反映银行之间资金的余缺，美联储瞄准并调节同业拆借利率能直接影响商业银行的资金成本，并且将同业拆借市场的资金余缺传递给工商企业，进而影响消费、投资和国民经济。 加息xx点, 100个基点相当于1%，一个基点就是0.01%。所以说兑美元基点，美联储降息25基点意思就是把利率下调25个基点，那也就是说下调后，利率降低了0.25% 联邦基金利率如何影响到实际贷款利率？ 商业银行在日常经营过程中，不管是因为放贷或者大额支取，常会遇到暂时性的流动性短缺。流动资金不够了怎么办？找手头有富余资金的银行借钱，支付一定的利息就可以了。这个利率中国叫做银行间 同业拆借利率，同业拆借率最终可以影响到 实际利率。 但同业拆借率是银行和银行之间商量的事情，美联储是不能插手改变同业拆借率的。那么美联储如何通过 联邦基金利率 影响到银行间拆借率，进而影响到贷款利率呢？ 如果美联储想降息：美联储降低其贴现利率，因为银行向美联储拆借的成本低，商业银行之间的拆借就会转向商业银行与美联储之间，进而整个市场的拆借利率也将随之下降 // 再贴现政策 如果美联储想加息：当宣布“联邦基金利率目标区间”上调后，美联储此时会通过在公开市场上抛出高息国债（一般来说是短期国债）换取美元，大量资金回到央行，市场上的货币总量减少，通过吸纳金融市场过剩的超额货币，造成同业拆借市场的资金紧张，迫使银行间拆借利率与美联储的拆借利率同步上升。所以说美联储只需要控制抛售国债的力度，就可以将利率稳定在它制定的目标区间内 // 缩表 美联储加息后，债券发行利率上升，特别是短期国债利率。当然长期国债利率也会随之上升。由于美债在一级市场和二级市场交易都非常方便和频繁，因此债券价格会随着发行利率的变动密切变动。新发行债券的利率上升会带来老债券的抛售，抛售带来债券价格下降，而价格下降带来到期收益率的升高。同时新债利率上升会带来新债买的人多，从而价格上升，到期收益率下降。由于在市场上的交易，最终会导致新债老债同时期的到期收益率一致，就是我们看到的N年期国债收益率了。 美联储拥有如此干预市场利率的超能力，故一旦美联储宣布想提高联邦基金利率，整个市场就会跟风而动。so 美联储 往往也不需要真的在公开市场操作，商业银行就会跟着调整利率 @ref: https://mp.weixin.qq.com/s/wQuyRFQdetniokWzgNF6GQ 对比中国央行调整的是LPR，但也不是央行直接操控，而是18家银行向同业拆解中心的报价，参考 [[F27.LPR和利率.md]] 看懂点阵图1年中，美联储会分4次公布点阵图，分别是在3、6、9、12月，我们可以通过比较2次连续公布的点阵图，看看委员们对利率主张的趋势性变化，从而解读金融市场的变化。FOMC（FOMC全称是美国联邦公开市场委员会，主要负责公开市场操作）的成员一般有12人，包括美联储理事会的主席、副主席和理事、及n家联邦储备银行的行长，由他们预测未来的基准利率 每个代表的预测值，反映到点阵图就是一个点（点是匿名的）； 发布点阵图时，会公布利率中值(中位数)，代表美联储未来的前瞻利率。但是只是预测利率，可能与实际利率发生偏差； 除了预测当年末的利率，委员们还需要分别预测未来几年和长期的利率； 所以看到的点阵图长这样： @ref: 美联储加息啦！有何重大影响？ 缩表什么是美联储缩表？ - 知乎 “缩表”是指美联储缩减自身资产负债表规模。是中央银行减少资产负债表规模的行为。说白了就是卖出自己的资产，目前美国的资产主要是国债和MBS（一种证券），两者高峰时达到4.46万亿。缩表就是卖出国债和MBS，最后市场上的美元被美联储回收，达到收紧货币的目的，同时美联储的资产负债表也会减少。“缩表”从经济体中抽走货币，货币减少，相应货币价值增加。 美联储通过 直接抛售所持债券 或 停止到期债券再投资的方式（抛售债券使市场上债券增加，债券变得便宜，收益率提高）可实现对基础货币的直接回收，相当于变相提高利率，是更为严厉的紧缩政策。 除了抛售债券，缩表的手段还有“停止债券再投资”，债券再投资意味着，美联储持续购入更多债券，如果停止再投资，意味着不会再增持债券，也是缩表的手段之一。 综上，美联储调控手段（这里仅讨论紧缩政策）： 直接加息xx BP（FFR，短期利率）； 停止所持债券的再投资，手里的债券不再增持； 直接抛售债券（市场上债券变多，债券贬值，收益率↑），如上所说，是比加前两种息更严格的紧缩； 美联储宽松调控手段： 降息xx BP； 债券再投资（不断增持债券） 购入债券（市场上债券变少，债券升值，收益率↓）； 当然美联储的负债表构成没这么简单，缩表的手段也没那么简单，那么如何观测美联储缩表？ 见下 [[#跟踪联储缩表]] 硬核科普： 美联储缩表是怎么缩的？ - 华尔街见闻 // 更硬核的科普，没看懂 跟踪联储缩表问题2：为什么缩表重要？需要观察哪些项目？ 答：因为缩表会影响银行体系的准备金数量，或者直观地说，基础货币的数量会变少。如果美联储不再认购美债，那么市场上必然有其他人承接了这部分美债，具体的机制大家可以参阅解读美联储官方解读缩表这个视频。 简言之，有四个项目会影响准备金的数量： 一是现钞，现钞的需求会稳定增长，不断蚕食掉存量的准备金。 二是财政存款（TGA），财政部发行国债或者收税的行为会导致存款留入财政部账户，导致准备金数量下降。 三是隔夜逆回购工具，非银的隔夜逆回购工具会蚕食准备金，反之，资金从隔夜逆回购流出到存款/准备金则会增加流动性。 四是准备金本身的需求，比如银行放贷很勤快，那么就会面对越来越高的支付需求。 问题3：如何跟踪这三个项目？ 答：我认为要综合预测这四个项目很难。 现钞的需求比较稳定，可以设一个基准的增速去推。 财政存款很难预测，因为这取决于财政的资金需求，那么相应的就和整个财政的收支有关（赤字），财政的收支又涉及债务上限和两党的角力。这个部分的内容智堡其实一直在跟踪了，大家可以关注我们的财政部再融资系列，当时我们设立这个系列文章的主要目的就是为了跟踪财政会怎样改变流动性状况，TGA内的资金只是结果而已，可能反映税收的上缴和退税，也可能反映债券的发行与赎回。如果你跟着TGA的量做投资，那么很遗憾是滞后的。 隔夜逆回购工具的用量有很多影响因素，比如利率（相比于存款）的高低，工具的参数设定，短期国债的供给等等。 准备金需求同样复杂，涉及银行的监管指标、信贷、大小银行的准备金持有结构等等。 因此，你想通过单一指标就判断流动性是多了还是少了，或者想根据单一指标判断联储在流动性问题上的想法和政策，这属于痴人说梦。有些变化是结构性的有些则是周期性的，不存在长期有效的单一跟踪指标。 问题4：如何预判体系内的准备金可能稀缺？ 答：虽然我们预测综合的流动性状况演变情况很困难，但我们至少可以通过一些公开信息来了解金融机构参与者的流动性需求状况。 比如，对于银行体系的资金需求，大家可以参阅美联储的 Senior Financial Officer Survey以及 Senior Credit Officer Opinion Survey on Dealer Financing Terms，分别对应银行和交易商的融资和流动性状况。 美联储H.4.1，即资产负债表的周度报表中回购便利工具（SRF）以及贴现窗口工具（DW）的用量也是比较好的指标，一旦有用量，说明市场内有金融机构已经不得不向美联储寻求融资，流动性状况可能趋紧。 还有就是需要实时关注财政的动向和发展，比如今年以来美国的个人所得税大幅增加，为半个世纪之最，导致赤字下降，债券发行需求也会下降，但是资金还是通过税收到了财政口袋。当然，像近期的债务上限和中期选举问题都是值得关注的，因为这都和未来的债券发行有关。 @ref: 宏观研究日记（2022年12月5日）：跟踪联储缩表 美联储缩表，会导致市场缺钱么？美联储『资产』构成中：国债为5.77万亿美元，占比为64.5%；MBS（房地产抵押债券）为2.72万亿美元，占比为30.4%。两项合计高达8.48万亿美元，占了资产总规模的95%，美联储所谓的缩表，就是减少国债和MBS的持有量。 当前阶段美联储负债的主要类别是哪些呢？答案是： 商业银行准备金、财政部账户（TGA）现金、流通现金、逆回购账户资金。在以上四个大项负债中，对金融市场影响较大的，是 商业银行准备金规模 和 流通现金额度，而TGA和逆回购账户资金波动，基本不会影响市场上的资金状况。 这里说明一下，美联储逆回购账户与中国央行正好相反，中国央行的逆回购账户持有资产，属于资产端，规模越大，意味着为市场释放资金越多； 而美联储的逆回购账户，属于负债端，主要从市场上回笼资金，规模越大，意味着从市场上吸收的资金越多。 国内的逆回购参考 F22.宏观调控手段（中国央行） 当美联储逆回购账户资金屡创新高，这就意味着，市场上的资金极其充裕，只是因为美联储的加息，导致市场资金涌入逆回购账户，追求绝对安全的收益。明白了美联储资产端和负债端的主要构成之后，我们再来看美联储的缩表。 不管怎么缩表，理论上说，只要能做到不影响 负债端的准备金 和 流通现金的规模，就不怎么会影响金融市场，因为只有那两个账户的钱，特别是流通中的美元数量，才与市场上所谓的“缺钱”还是“不缺钱”，有密切关系。 美联储负债端拥有高达2.1万亿美元的逆回购资金，缩表根本不用抽走准备金。也就是说，如果缩表规模在2万亿美元以内，既不会影响市场流通资金的松紧，也根本涉及不到商业银行准备金的问题。 @update: 11月 流动性吃紧！美联储海外逆回购使用量3510亿美元创新高，单周涨幅历史最大 - 雪球最新数据显示，截至11月2日本周三，外国央行与国际货币当局存放在美联储相关隔夜逆回购便利工具中的美元金额，升至创纪录新高的3510亿美元。 在美联储海外逆回购机制（foreign reverse repo facility）下，外国央行和其他货币机构将现金存放在美联储，类似于现支现取的支票账户，并在交易平仓前从美联储获得美国国债作为抵押品。在美国的定义中，逆回购操作具有回笼流动性的功能。 @ref: 美联储缩表，会导致市场缺钱么？ 美联储资产负债表右边红色=资产端，左边绿色=负债端： 资产端（1）资产端变化的主要分项是美联储持有的国债和MBS。两者共经历了两次攀升，分别是2008年金融危机后与2020年新冠疫情爆发后。从2020年年初，国债规模为23289亿美元，8月26日规模达到43586亿美元，扩大近一倍；MBS则分别为14087亿美元、19492亿美元，增长近38.4%（2）资产端CPFF、CCF、MSF、MLF、TALF逐步铺开。截至8月26日，上述工具规模分别为85.88亿美元、446亿美元、383.71亿美元、165.41亿美元、107.71亿美元。 负债端（1）负债端变化的主要分项是财政存款、存款机构其他存款和联储票据、联储银行持有净额。两者同样经历了两次攀升，分别是2008年金融危机后与2020年新冠疫情爆发后。以财政存款为例，多轮次QE后，财政存款上涨幅度接近20倍；2020年疫情爆发后，财政存款增长幅度则接近4倍。（2）超额存款准备金则大幅下降。其中，金融危机后超额存款准备金率从1%降至0.25%；2020年年初疫情爆发后，从1.55%降至0.1%。","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"美联储","slug":"美联储","permalink":"https://beefyheisenberg.github.io/tags/美联储/"},{"name":"FED","slug":"FED","permalink":"https://beefyheisenberg.github.io/tags/FED/"},{"name":"量化宽松","slug":"量化宽松","permalink":"https://beefyheisenberg.github.io/tags/量化宽松/"},{"name":"量化紧缩","slug":"量化紧缩","permalink":"https://beefyheisenberg.github.io/tags/量化紧缩/"},{"name":"加息","slug":"加息","permalink":"https://beefyheisenberg.github.io/tags/加息/"},{"name":"缩表","slug":"缩表","permalink":"https://beefyheisenberg.github.io/tags/缩表/"}]},{"title":"F21d.货币-信用周期","slug":"52.Financing/F21d.货币-信用周期","date":"2024-01-24T01:27:53.292Z","updated":"2024-01-24T01:27:53.292Z","comments":true,"path":"52.Financing/F21d.货币-信用周期/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F21d.货币-信用周期/","excerpt":"货币-信用周期what’s 货币 &amp; 信用： 货币宽松：资金流入金融体系；信用宽松：资金流入实体经济，所谓“宽信用”指的是企业和个人的贷款意愿提升。二者发生的顺序是宽货币先行，再出现宽信用； 货币-信用周期： 分为四个阶段，周期的开始总是货币先行，宽货币在宽信用之前: 宽货币+紧信用：在经济下行时，央行会释放流动性，经济触底之前，企业和个人信心不足，贷款意愿不高，因此衰退阶段大体上是宽货币、紧信用特征。 宽货币+宽信用：经济触底成功增加了企业和个人的信心，贷款意愿增加，信贷上升；同时经济增长不够强劲，央行会继续净投放。因此经济复苏阶段大体上是宽货币、宽信用特征。 紧货币+宽信用：经济强劲增长，通胀苗头显现，央行开始收缩流动性，但企业和个人信心十足，贷款意愿依然高企。过热阶段大体对应着紧货币、宽信用周期。 紧货币+紧信用：经济增速见顶回落，物价依然高企，央行继续收缩流动性，同时企业和个人信心丧失，贷款意愿下降。因此滞胀阶段大体对应着紧货币、紧信用周期","text":"货币-信用周期what’s 货币 &amp; 信用： 货币宽松：资金流入金融体系；信用宽松：资金流入实体经济，所谓“宽信用”指的是企业和个人的贷款意愿提升。二者发生的顺序是宽货币先行，再出现宽信用； 货币-信用周期： 分为四个阶段，周期的开始总是货币先行，宽货币在宽信用之前: 宽货币+紧信用：在经济下行时，央行会释放流动性，经济触底之前，企业和个人信心不足，贷款意愿不高，因此衰退阶段大体上是宽货币、紧信用特征。 宽货币+宽信用：经济触底成功增加了企业和个人的信心，贷款意愿增加，信贷上升；同时经济增长不够强劲，央行会继续净投放。因此经济复苏阶段大体上是宽货币、宽信用特征。 紧货币+宽信用：经济强劲增长，通胀苗头显现，央行开始收缩流动性，但企业和个人信心十足，贷款意愿依然高企。过热阶段大体对应着紧货币、宽信用周期。 紧货币+紧信用：经济增速见顶回落，物价依然高企，央行继续收缩流动性，同时企业和个人信心丧失，贷款意愿下降。因此滞胀阶段大体对应着紧货币、紧信用周期 货币-信用周期与美林时钟（衰退、复苏、过热和滞胀）四周期有交叉和跨越，但也有大体上的对应关系。// @link F21a.美林时钟 货币-信用（信贷）周期中，每个周期最优资产： 1、宽货币+紧信用周期，股票震荡市，债券强牛市；// 衰退 2、宽货币+宽信用周期，股票强牛市，债券震荡市；// 复苏 3、紧货币+宽信用周期，股票弱牛市，债券熊市； // 过热 4、紧货币+紧信用周期，股票强熊市，债券震荡市 // 滞胀 利率同债市的关系： F71.202211-债券大跌的归因 也对比 Ray Dalio 提到的“债务周期” ，这里把影响周期的要素分为了二个（货币和信用），也加入了更适合中国国情的观测指标（见下） ➤ 如何判断货币的松紧？ （1）看央行怎么说：央行每个季度的《货币政策执行报告》会对下一阶段的货币政策作出展望：模糊的表达有宽松的货币政策，适度宽松的货币政策，稳健的货币政策，适度从紧的货币政策，从紧的货币政策 （2）看央行怎么做： 大的动作是调整 存款准备金比率（降准），往往几年一次，最近一次全面降准0.5个百分点直接释放1万亿流动性； 常规动作是： 公开市场操作、SLF、MLF、SLO等等。关注央行网站或财经频道，可以及时了解到最短一周内央行是净回笼还是净投放资金。如果是宽货币政策中连续出现较大幅度净回笼资金，就要观察货币政策会不会转向。 （3）反应货币松紧的一些指标： SHIBOR、十年国债收益率，SHIBOR3m利率是直观的反应“现在银行是否缺钱”的指标，当银行流动性紧张时，SHIBOR3m利率也会随之提升，但其原因可能是信用的扩张、或者是货币的收缩。 ➤ 如何判断信用的松紧？ （1）宏观定调：“去杠杆”就是信用收缩，2018年就是一个典型的紧信用周期；“加杠杆”就是信用扩张。 （2）观察信用利差，即“企业债利率”与“国债同期利率”的差值，信用利差收窄，表明处于宽信用周期；反之则处于紧信用周期 （3）反应信用松紧的一些指标： 社融-M2同比增速差、M1-PPI同比增速差 （4）每年12月举行的中央经济工作会议的部署来预测未来的财政政策定调，是扩张还是收缩：https://m.gelonghui.com/p/501738 @link: F30e.股市与宏观经济的关系、F30e1.关于剩余流动性 @ref: 雕虫小技之：看懂货币信用周期与股债基金配置逻辑 - 雪球 为啥央妈放水也救不了股市 信达证券《信用周期分析框架》 “信用”本质上是银行的资产。凡是涉及货币政策、金融市场的研究分析，我们总能读到“信用”一词。我国的金融体系中， 银行是信用创造的主体，最具有代表性的信用派生渠道便是贷款。从银行资产负债表的角度来看，信用反映在银行的资产端，属于银行的资产，比如居民、企业贷款，同业资金往来，发放给非银机构的贷款等等。 “货币”本质上是银行的负债(存款)。当银行发放贷款，本质上是银行和客户(居民、企业、其他金融机构)的信用交换，银行增加了贷款债权和存款债务，客户则获得了贷款债务和存款债权。在这一过程中居民、企业或非银存款增加，广义货币供应量(M2)增加。 现代银行信用货币制度下贷款先行，银行通过信用扩张创造货币。信用派生的渠道主要有三条，向实体部门发放贷款、同业信用派生以及购买政府债券。在央行货币政策(控制基础货币)、信用需求以及金融监管三大因素影响下，信用的扩张与收缩呈现周期变化，信贷与社融增速是衡量信用周期的常见指标。 基于“信用”的含义，最直接的观测指标就是各项贷款增速。随着实体部门融资渠道不断丰富，信用融资的范围也在拓宽，社融能够更加全面的反映金融机构对实体经济的信用支持。比如社融多纳入了表外融资三项、政府债券和企业债融资，这些都属于银行扩张信用、创造存款货币的渠道。 社融中还包含股票融资，该项属于股权融资而非信用范畴，不过占比较小，对社融指标的有效性影响不大。 观察两项指标的同比增速，可见信用总体呈现“扩张-收缩-平稳-扩张”的周期变化，如此循环往复。参考下图，2003 年以来我国大致经历了 5 轮信用扩张周期。 相比社融指标，商业银行资产增速 进一步涵盖了金融体系内部的信用派生。社融指标 衡量的是商业银行信用派生中流向实体的部分，并未考虑金融体系内部的信用派生，比如社融口径下信贷数据不包含非银贷款。商业银行资产增速 的涵盖面更广，对手方不止是实体部门，还包括同业部门(对其他存款性公司、其他金融机构债权)。 通过商业银行较央行资产的相对变化定义“宽/紧信用”。单看商业银行资产增速仍然是不够的，从银行信用扩张的路径可知，央行通过控制基础货币来约束银行信用派生上限，而增加基础货币只能来自央行资产端扩张。这意味着，在央行扩表周期内，商业银行资产需要扩张得更快，才能称为“宽信用”。反之，“紧信用”则表现为商业银行相对央行资产扩张得更慢。 将“商业银行总资产/央行总资产”求同比，构建得到信用周期指数。指数反映的是银行和央行的资产增速差，指数上行说明商业银行较央行资产扩张更快，是为宽信用，反之 则为紧信用。指数相比社融指标更具优势，一是涵盖面更广，考虑了同业信用派生;二是波动性更强、周期性更明显;三是具备领先性。与指数构建思路相仿的，还有社融-M2增速、货币乘数 等。 “商业银行总资产/央行总资产”实际上是资产端的货币乘数。货币乘数=M2/基础货币，其中 M2 对应商业银行负债端，基础货币对应央行的负债端。由于资产“咬合”负债，二者在走势上是十分趋近的，区别在于资产倍数用来衡量信用扩张，货币乘数用来衡量货币创造。 信用周期指数反映的是银行和央行的资产增速差。通过数学推导可以进一步得到: 信用周期指数=(商业银行总资产/央行总资产)求同比 ≈ 商业银行总资产增速-央行总资产增速 分别来看 M2 和社融的构成。 社融的分项构成很明确: 社融=表内信贷+表外融资+政府债券+企业债融资+股票融资 M2与各项存款的差别在于前者包含流动中现金(M0)，同时不包含财政性存款。利用金融机构信贷收支表资金来源方=资金运用方，移项后剔除占比较小的几项科目，可得 M2 的表达式:M2=各项存款-财政性存款+流通中货币(M0) =各项贷款+债券投资+股权及其他投资+外汇占款-财政存款-金融债券-其他 如果将社融与 M2 简单相减，可得: 社融-M2 = (表内信贷-各项贷款)+(政府债券+金融债券+企业债券-债券投资)+(表外融资+其他-股权及其他投 资)+股票融资+财政存款-外汇占款 其中，表内信贷和各项贷款基本相当，后者包含非银贷款而前者不包含; 信贷收支表中的“债券投资”项指的是 金融机构持有的政府债(地方政府债+国债)和非金融企业债;“股权及其他投资”主要包括银行持有的资管计划、 理财产品等，属于金融体系的非标投资，“其他”项可视作金融同业资金往来的轧差项。化简等式、剔除干扰项， 最终可得: 社融-M2=(金融债券+实体部门购买的企业债)+实体部门非标投资+股票融资+财政存款-外汇占款 ▷ 两种信用指数的比较： 社融-M2增速可反映实体融资需求强弱。通过社融和 M2 的口径差异可知，影响二者增速差的主要变量是实体部 门非标投资。财政存款是对财政收支的综合反应，体量不大，求同比后也会滤掉季节性波动。股票、债券融资对 社融同比的影响也相对较小。 商业银行总资产/央行总资产更具领先性。从两项指标的走势上看，信贷周期指数的领先性更强。除此之外，需要注意非标投/ 融资受金融监管的影响很大，在强监管的周期内，社融-M2 增速会有很大的下行压力，难以捕捉到实体融资需求 的正向变化。比如 2017 年金融体系内部开启去杠杆，直至 2020 年初，期间社融-M2增速差都在持续滑坡。而在 2019 年实际上迎来了一波信用扩张周期。 国海证券《五轮宽信用周期》 2008 年以来我国共经历五轮信用扩张周期，分别发生在 2008年10月至2009年11月、2012年5月至2013年4月、 2015年6月至 2016年3月、2018年12月至 2019年6月和 2020年3月-10月。每轮宽信用周期具备一定规律性，均经历从货币宽松先行到信用端政策持续发力、直至经济企稳或金融风险暴露后逐渐收紧的过程。 过去五轮宽信用周期主要依靠地产、非标和专项债驱动，地产、非标对信用扩张的支持力度较强，专项债的支持力度一般。其中房地产是我国宽信用的最主要抓手，过去四轮都主要 依靠地产驱动。2016年前基建投资更多依靠非标融资的方式，项目也多聚集在交通及水利建设等传统基建领域，2016年后更多依靠专项债，新能源电力建设、信息基础设施建设等新基建 领域迎来投资热潮。 宽信用期内 A 股易上难下，特别是信用扩张进入加速期对应着市场抬升斜率最大的阶段。2016年前宽信用的发力对市场的影响是脉冲式的，地产链条以及逆周期板块可阶段性跑赢大 盘，但行情持续性不佳，一般在1个月以内。2019年后新基建发力，对应到 A 股电力设备、公用事业、新能源汽车等行业超额收益显著。 本轮宽信用周期大概率会依靠专项债的放量，通过刺激基 建投资以实现对经济的托底，一季度是基建发力的重要观察窗口。绿色贷款受到政策支持的方向确定，但规模的相对有限将很难支撑起信用的全面扩张。地产融资的边际回暖将助力社融企稳回升，但幅度取决于政策的放松程度，预计本轮信用扩张将相对克制。 宽信用周期下，建议关注两条配置线索。一是适时把握新老基建的阶段性投资机会，包括建材、建筑装饰、工程机械 等，以及新基建的大数据、云计算、物联网等数字经济领域。 二是在成长风格负面因素阶段性缓释之后，坚持成长扩散的方向，沿着产业周期的演绎路径重点关注汽车智能化和元宇宙背景下的软件开发、IT 服务、光学图像等细分领域。","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"宏观经济","slug":"宏观经济","permalink":"https://beefyheisenberg.github.io/tags/宏观经济/"},{"name":"经济周期","slug":"经济周期","permalink":"https://beefyheisenberg.github.io/tags/经济周期/"},{"name":"社融","slug":"社融","permalink":"https://beefyheisenberg.github.io/tags/社融/"},{"name":"M2","slug":"M2","permalink":"https://beefyheisenberg.github.io/tags/M2/"}]},{"title":"F21c.经济机器是如何运行的（Ray Dalio）","slug":"52.Financing/F21c.经济机器是如何运行的","date":"2024-01-24T01:27:53.287Z","updated":"2024-01-24T01:27:53.288Z","comments":true,"path":"52.Financing/F21c.经济机器是如何运行的/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F21c.经济机器是如何运行的/","excerpt":"[!info]Ray Dalio在2008年美国金融危机之后，在Youtube上的分享的一个30分钟的视频，介绍生产效果、短期债务周期、长期债务周期的起源。这个视频对于没有任何经济学基础的人都是便于理解的。比尔盖茨对这个视频的推荐语是这样的：”This knowledge would help everyone as investors and citizens. Watching it for 30 minutes is a worthwhile investment.” 这些知识对每个人都有帮助，无论是投资者还是普通人；看三十分钟本身就是一个值得的投资。 01 经济运行的三股动力经济就像一部简单的机器那样运行，但很多人没有看到这一点。经济虽然看起来很复杂，但其实是以简单和机械的方式运行。经济有几个简单的零部件和无数次重复的简单交易组成。这些交易首先是由人的天性所驱动，因而形成三股主要的经济动力：1、生产率的提高；2、短期债务周期；3、长期债务周期。下面我们谈一下这三股动力，并介绍如何把它们组合在一起形成良好的模型，便于我们跟踪经济的走势，并理解当前正在发生的事情。 上面提到的三个周期，叠加起来如何影响经济","text":"[!info]Ray Dalio在2008年美国金融危机之后，在Youtube上的分享的一个30分钟的视频，介绍生产效果、短期债务周期、长期债务周期的起源。这个视频对于没有任何经济学基础的人都是便于理解的。比尔盖茨对这个视频的推荐语是这样的：”This knowledge would help everyone as investors and citizens. Watching it for 30 minutes is a worthwhile investment.” 这些知识对每个人都有帮助，无论是投资者还是普通人；看三十分钟本身就是一个值得的投资。 01 经济运行的三股动力经济就像一部简单的机器那样运行，但很多人没有看到这一点。经济虽然看起来很复杂，但其实是以简单和机械的方式运行。经济有几个简单的零部件和无数次重复的简单交易组成。这些交易首先是由人的天性所驱动，因而形成三股主要的经济动力：1、生产率的提高；2、短期债务周期；3、长期债务周期。下面我们谈一下这三股动力，并介绍如何把它们组合在一起形成良好的模型，便于我们跟踪经济的走势，并理解当前正在发生的事情。 上面提到的三个周期，叠加起来如何影响经济 02 经济中的交易我们先来看一下经济中最简单的部分——交易。经济不过是无数交易的总和，而交易是一件非常简单的事情。交易时刻都在发生，你每次买东西都是进行一笔交易。在每次交易中，买方使用货币或信用向卖方交换产品、服务或金融资产。信用在使用时和货币一样，因此把花费的货币和信用加在一起，就可以得出支出总额。支出总额，是经济的驱动力。如果用支出金额除以销量，就得出价格。就是这么简单，这就是交易。交易是经济的基本零件，所有的经济周期和动力，都是交易造成的。所以，理解了交易，就理解了整个经济。一个市场，由买卖同一种商品的所有买方和卖方组成，比如小麦市场、汽车市场、股票市场，和千百万种其他市场。经济就是由所有市场内的全部交易构成的。把全部市场的总支出和销量加在一起，就得到了了解经济运行所需要的全部信息。就这么简单。个人、企业、银行和政府，都在以上述方式从事交易，用货币和信用，交换产品、服务和金融资产。 政府是最大的买方和卖方。政府由两个部分组成，即收税和花钱的中央政府和中央银行。央行控制着经济中的货币和信贷数量，因此不同于其他买方和卖方。央行通过影响利率和发行更多货币，来实行这种控制。正因如此，央行在信贷流通过程当中发挥着重要作用。 03 信贷001请诸位注意信贷！信贷是经济中最重要的组成部分，但也许是人们最不了解的部分。它之所以最重要，是因为它是经济中最大且最为变幻莫测的部分。贷款人和借款人，与在市场中进行交易的买方和卖方没有两样。通常，贷款人希望自己的钱生出更多的钱，而借款人则想购买当前无法负担的东西，比如房子、汽车，或是进行投资开办企业。借贷可以同时满足贷款人和借款人的要求。借款人保证偿还借款（称为本金），并支付额外的款额（称为利息）。利率高时，借款就会减少，因为贷款变得昂贵；当利率低时，借贷就会变得增加，因为贷款变得便宜。如果借款人保证偿还债务，而且贷款人相信这一承诺，信贷就产生了。任何两个人都可以通过协定，凭空产生信贷。信贷看似简单，实则复杂。因为信贷还有其他的名称，信贷一旦产生，立即成为债务。债务是贷款人的资产，是借款人的负债。等到借款人今后偿还了贷款，并支付了利息，这些资产和负债将消失，交易得以完成。 002那么，为什么信贷如此重要？这是因为，借款人一旦获得信贷，就可以增加自己的支出。不要忘记，支出是经济的驱动力。 这是因为，一个人的支出，是另一个人的收入。想想看，你每花一块钱，另一个人就收入了一块钱，而你每挣一块钱，必定有别人花了一块钱。所以，你花的越多，别人挣的就越多。如果某人的收入增加，其信用度就会提高，贷款人就更愿意把钱借给他。信用良好的借款人具备两个条件：偿还能力和抵押物。收入/债务比率高，借款人就具备偿还能力，如果无法偿还，借款人还可以用有价值、可以出售的资产作为抵押物。这样，贷款人可以放心地把钱借给他们。所以收入增加使得借贷也增加，从而能够增加支出。由于一个人的支出是另一个人的收入，这将导致借贷进一步增加，并不断循环。这一自我驱动的模式导致经济增长，也正因为如此，才产生了经济周期。 003在一项交易中，你为了获得某样东西，必须付出另一样东西。长期来看，你得到多少取决于你生产多少。我们的知识随时间而增多，知识的积累会提高我们的生活水平，我们将此称为生产率的提高。一个善于创新和勤奋的人，将比那些自满和懒惰的人更快地提高生产率和生活水平。但在短期内，不一定能体现出来。生产率在长期内最关键，但信贷在短期内最重要。 这是因为，生产率的提高不会剧烈波动，因此不是经济起伏的重要动力。但债务是这种动力！因为我们能够通过借债，让消费超过产出，但是在还债时，不得不让消费低于产出。债务量的波动有两大周期，其中一个周期持续大约5-8年，另一个则持续75-100年。 大部分人虽然能够感受到波动，但由于距离波动太近，每天每周都身临其境，通常并不认为这是周期。我们将考察这三股动力，并观察它们如何相互作用，以及它们在日常经济中的表现。如上所述，经济的上下起伏，不是取决于人们多么善于创新或勤奋工作，而是主要看信贷的总量。 第三部分 @tldr: [!note]在这部分，达里奥阐述了经济的“长短周期”理论，“生产率在长期内最关键，但信贷在短期内最重要” 长周期即生产率周期，受社会生产率的提高，周期约75-100年，参考 F21.经济的周期性 短周期则是信贷周期，受信贷影响，周期约5-8年那么信贷如何影响经济活动？交易中的支出= 货币支出 + 信贷支出 前者在短时间内不会大幅变化（可以理解为受限于个人的生产率提高带来的收入提高，短期变化不大），而后者是个可变量，利率宽松的时候后者大幅提高。 而交易中的支出总量，是经济的主要驱动力 =&gt; 增加信贷=短期内经济增长的驱动力 04 信贷与经济周期001我们先想象一个没有信贷的经济运行：在这样的一个经济运行中，增加支出的唯一办法是增加收入，因此需要提高生产率和工作量。提高生产率是经济增长的唯一途径。由于我的支出是另一个人的收入，当我或者另一个人提高生产率的时候，经济就会增长。如果我们观察各种交易加以总结，就会发现一条类似生产率增长轨迹的渐近线。但是由于我们借债，于是产生了周期。原因并不是任何法规，而是人的天性和信贷的运作方式。借债不过是提前消费，为了购买现在买不起的东西，你的支出必定超过收入，因此，你需要借钱。实质上，是向未来的自己借钱。你给自己设定了一个未来的时间，到那个时候，你的支出必须少于收入，以便偿还债务，这样马上就形成了一个周期。通常，一旦你借钱，你就制造了一个周期。对于个人是这样，对于整个经济运行也是这样。这就是为什么必须理解信贷。因为信贷触发了一系列机械和可以预料的、将在未来发生的事件。这就是信贷不同于货币的地方。完成交易需要使用货币。当你在酒吧买一瓶啤酒，交易立即完成。但是如果你用信用来买一瓶啤酒，比如赊账，你相当于承诺今后为这瓶啤酒付钱。你和酒吧一起创造了一笔资产和一笔负债，你们凭空制造出了信贷。只有在你今后清偿了这笔赊账之后，上述资产和负债才会消失。债务才会还清，交易才会了结。 002现实生活中，大部分所谓的“钱”，实际上是信贷。美国国内的信贷总额大约为50万亿美元（当时），而货币总额只有大约3万亿美元。不要忘记，在没有信贷的经济运行中，增加支出的唯一办法是增加生产。但是在有信贷的经济运行中，还可以通过借债来增加支出。因此，有信贷的经济运行能增加支出，使得收入的增长速度在短期内超过生产率的增长。 但在长期内，并非如此。但是请不要误解我的意思，信贷不一定是坏事，只是会导致周期性变化。信贷如果造成超出偿还能力的过度消费，就是不良信贷；但是，信贷如果高效率地分配资源和产生收入，让你能偿还债务，就是良性的。例如，你如果借钱买一台大彩电，电视机不会带来任何收入让你偿还债务；但你如果借钱买一台拖拉机，用它来收获更多的庄稼，赚更多的钱，你就能够偿还债务，提高生活水平。在有信贷的经济运行中，我们可以跟踪各种交易，观察信贷如何带来经济增长。我举一个例子。假设你每年挣10万美元，没有任何债务，你有不错的信用，可以借1万美元（例如用信用卡借），因此你每年可以花11万美元（即使你的收入只有10万美元）。由于你的支出是别人的收入，另一个因此挣了11万美元。这个挣了11万美元的人如果没有任何债务，可以借1.1万美元，他可以消费12.1万美元（即使他的年收入只有11万美元）。由于他的支出是另一个人的收入，而我们通过跟踪交易可以看到这个过程不断自我强化。但不要忘记，借债形成周期。周期会上升，最终也会下降。 05 短期债务周期下面我们谈谈短期债务周期。 001随着经济活动的增加，出现了扩张，这是短期债务周期的第一阶段。支出继续增加，价格开始上涨。原因是，导致支出增加的是信贷，而信贷可以即刻凭空产生。如果支出和收入的增长速度超过出售的商品的生产速度，价格就会上涨。我们把价格的上涨称为通货膨胀。央行不希望通货膨胀过高，因为这会导致许多问题。央行在看到价格上涨时就会提高利率。随着利率的上升，有能力借钱的人会减少，同时，现有的债务成本也会上升，就等于你每个月的信用卡还款额会增加。由于人们减少借债，还款额度增长，剩下来用于支出的额度将减少，因此，支出速度放慢。而由于一个人的支出是另一个人的收入，环环相扣，人们的收入将下降。由于支出减少，价格将下跌，我们称之为通货紧缩。经济活动减少，经济便进入衰退。如果衰退过于严重，而且通货膨胀不再成为问题，央行将降低利率，使经济活动重新加速。随着利率降低，偿债成本下降，借债和支出增加，出现另一次经济扩张。可见，经济像一部机器一样运行。 002在短期债务周期中，限制支出的唯一因素，是贷款人和借款人的贷款和借款意愿。 如果信贷易于获得，经济就会扩张；如果信贷不易获得，经济就会衰退。请注意，这个周期主要由央行控制。短期债务周期通常持续5-8年，在几十年里不断重复。但是请注意，在每个周期的低谷和高峰后，经济增长和债务都超过前一个周期。 为什么会这样？是人促成的。人具有借更多钱和花更多钱的倾向，而不喜欢偿还债务，这是人的天性。因此在长期内，债务增加的速度超过收入，从而形成长期债务周期。 003尽管人们债务增加，但贷款人会提供更宽松的信贷条件。这是为什么？这是因为大家都以为形势一片大好，人们仅注意最近出现的情况。最近的情况是什么呢？——收入一直在增加，资产价值不断上涨，股票市场欣欣向荣，现在是繁荣时期。用借来的钱购买商品、服务和资产很划算。当人们过度借贷消费时，泡沫就产生了。因此，尽管债务一直增加，但收入也以相应的速度增加，从而抵消了债务。我们把债务与收入比率称为债务负担。只要收入继续上升，债务负担就可以承受。与此同时，资产价值迅速上升，人们大量借钱来购买资产。因为投资促使资产价格日益上升，人们感觉自己很富有。因此尽管积累了大量债务，收入和资产价值的上升帮助借债人在长期内保持良好的信用度。 //第五部分的 @tldr: [!note] 短期债务周期中经济阶段参考 F21a.美林时钟 ，这些阶段受政府和央行对信贷的调控、以及人们影响 每次短债务周期（信贷出现低谷和高峰）后，经济增长（近似等于GDP总量）和债务（信贷的债务）都超过前一个短周期，也就是说，经济总量越来越偏离“实际”，也就是生产率决定的那个经济总量 当经济总量高于均值太多，按均值回归理论，经济总量会回落，至于回落的原因，也就是下一部分要讲的，去杠杆化。去杠杆化的表现可能有：人们减少消费，同时也减少了贷款，信贷总量也会下降。 在去杠杆化的过程中，每次短债务周期，经济增长和债务都下降，最终低于经济总量的“均值” 06 去杠杆化但是这种情况显然无法永久持续下去，也确实没有持续下去。 001几十年来，债务负担缓慢增加，使偿债成本越来越高。到了一定程度，偿债成本超过了收入，迫使人们削减支出。由于一个人的支出是另一个人的收入，收入开始下降，人们的信用因此降低，致使借贷减少，偿债成本继续增加，使得支出进一步减少，周期开始逆转，这时到达长期债务的顶峰，债务负担变得过重。美国、欧洲和世界上很多其他地区在2008年即发生了这一情况，日本在1989年和美国在1929年因同样的原因也发生了这一情况。 002现在，经济进入去杠杆化时期。// 视频是Dialo在2008之后发布的在去杠杆化过程中，人们削减支出，收入下降，信贷消失，资产价格下跌，银行发生挤兑，股票市场暴跌，社会紧张加剧，整个过程开始下滑，并形成恶性循环。随着收入下降和偿债成本增加，借款人倍感拮据。随着信用消失，信贷枯竭，借款人再也无法借到足够的钱来偿还债务。借款人竭力填补这个窟窿，不得不出售资产，在支出下降的同时，出售热潮使市场充斥待售资产。这时股票市场暴跌，不动产市场一蹶不振，银行陷入困境。随着资产价格下跌，借款人能够提供的抵押物的价值下降，这进一步降低了借款人的信用。人们觉得自己很穷，信贷迅速消失。支出减少，收入减少，财富减少，信贷减少，借债等等随之减少，这是一个恶性循环。 003它看起来与衰退相似，但不同之处是它无法通过降低利率来挽回局面。在衰退中，银行可以通过降低利率来刺激借贷；但在去杠杆化过程中，由于利率已经很低，接近零，从而丧失刺激功能，因此降低利率不起作用。美国在1930年代的去杠杆化期间下降到零，2008年也是如此。衰退与去杠杆化之间的区别在于，在去杠杆化的过程中，借款人的债务变得过重，无法通过降低利率来减轻。贷款人意识到，债务过于庞大，根本无法足额偿还。借款人失去了偿债能力，其抵押物失去价值，他们觉得受到债务的极大伤害，不想再借入更多债务。贷款人停止放贷，借款人停止借贷，整个经济体与个人一样，都失去了信用度。 004那么应该怎样应对去杠杆化？问题在于债务负担过重，必须减轻。为此可以采用四种办法：1、个人、企业和政府削减支出；2、通过债务违约和重组来减少债务；3、财富再分配，将财富从富人转给穷人；4、央行发行更多货币。这四种办法被用于现代历史上的每一个去杠杆化过程。// 2015年我们是如何去杠杆化的？ 005通常第一个措施是削减支出。我们刚才看到，个人、企业和政府都勒紧裤腰带，削减支出，我们把这称为紧缩。当借款人不再借入新债务，并开始减少旧债务的时候，你会以为债务负担会减轻。但情况正好相反！支出减少了，而一个人的支出是另一个人的收入，这就导致收入下降。收入下降速度超过还债的速度，因此债务负担实际上更为沉重。我们已经看到，这种削减支出的做法引起通货紧缩，令人痛苦。企业不得不削减成本，这意味着工作机会减少，失业率上升，这导致下一个步骤，即必须减少债务。很多借款人无法偿还贷款，而借款人的债务是贷款人的资产，如果借款人不偿还银行贷款，人们会担心无法返还其存款，因此纷纷从银行取出存款，银行受到挤兑，而个人、企业和银行出现债务违约。这种严重的经济收缩就是萧条。萧条的一个重要特征，是人们发现原来以为属于自己的财富中，有很大一部分实际上并不存在。我们仍以酒吧为例：当你以赊账的方式购买一瓶啤酒时，是在承诺今后偿还酒吧的赊账。你的承诺成为酒吧的一项资产。但是若你不兑现承诺，实际上是债务违约，那么酒吧的这项资产实际上一钱不值，它实际上是消失了。 006很多贷款人不希望自己的资产消失，同意债务重组。债务重组，意味着贷款人得到的还款减少，或偿还期延长，或利率低于当初商定的水平，无论如何，合约被破坏，结果是债务减少。贷款人希望多少收回一些贷款，这强过血本无归。债务重组让债务消失，但由于它导致收入和资产价值以更快的速度消失，债务在日趋沉重。削减债务与减少支出一样，令人痛苦和导致通货紧缩。所有这些都对中央政府产生影响，因为收入降低和就业减少，意味着政府的税收减少。与此同时，由于失业率上升，中央政府需要增加支出；很多失业者储蓄不足，需要政府的财务资助；此外，政府制定刺激计划和增加支出，以弥补经济活动的减少。在去杠杆化过程中，政府的预算赤字飙升，原因是政府的支出超过税收。你在新闻中所听到的预算赤字，正是这种情况。政府必须加税或者举债，以填补赤字。 007但是在收入下降和很多人失业的时候，应该向谁融资呢？富人。由于政府需要更多的钱，而且大量财富集中在少数人的手中，政府自然而然的增加对富人的征税，以帮助经济中的财富再分配，把财富从富人那里转给穷人。正在困苦之中的穷人开始怨恨富人，承受经济疲弱、资产贬值和增税压力的富人也开始怨恨穷人。如果萧条继续下去，就会爆发社会动荡，不仅国家内部的紧张加剧，而且国家之间也会这样，债务国和债权国之间尤其如此。这种局势可以导致政治变革，有时甚至是极端的变革。1930年代，这种局势导致希特勒掌权，欧洲爆发战争和美国的大萧条。要求采取行动来结束萧条的压力越来越大。 008不要忘记，人们心目中的货币，实际上大部分是信贷，因此信贷一旦消失，人们的钱会不够花。人们迫切需要钱，而你一定记得，谁可以发行货币——中央银行可以。央行已经将利率降到接近零的水平，现在不得不发行更多货币。发行货币与减少支出、债务重组和财富再分配不同，会引起通货膨胀和刺激经济。中央银行不可避免地会凭空发行更多货币，并使用这些货币购买金融资产和政府债券。这种情况发生于1930年代美国大萧条期间，并于2008年再次爆发。当时美国的中央银行即美联储增加发行了2万多亿美元，世界其他各国能够这样做的央行也增发了很多货币。央行通过用这些货币购买金融资产，推升了资产价格，提高了人们的信用。但是，这仅仅有助于那些拥有金融资产的人。你看，央行能够发行货币，但是只能购买金融资产；但另一方面，中央政府可以购买商品和服务，可以向人民送钱，但是无法印钞票。因此，央行和政府必须合作。央行通过购买债券，其实是把钱借给政府，使其能够运行赤字预算，并通过刺激计划和失业救济金，来增加购买商品和服务的支出，这增加了人们的收入，也增加了政府的债务。但这个办法将降低经济中的总债务负担。 009这是一个风险很大的时刻。决策者需要平衡考虑降低债务负担的四种办法，必须平衡兼顾通货紧缩的办法和通货膨胀的办法，以便保持稳定。如果取成适当平衡，会带来和谐的去杠杆化。所以，去杠杆化可以是痛苦的，也可以是和谐的。怎样才能实现和谐的去杠杆化？尽管去杠杆化是艰难的，但以尽可能好的办法来处理艰难的局势却是一件好事。这比杠杆化时期大量举债产生过度失衡现象要好得多。在和谐的去杠杆化过程中，债务收入比率下降，经济实际上是正增长。同时，通货膨胀并不是一个问题。这是通过适当的平衡所取得的。为了取得适当的平衡，需要结合削减支出、减少债务、转移财富和发行货币的办法，以保持经济和社会稳定。有人问，发行货币是否会加剧通货膨胀。如果增发的货币抵销信贷的降幅，就不会引发通货膨胀。不要忘记，重要的是支出。每一块钱的支出（无论货币还是信用），对价格的影响都是一样的。央行可以增加货币发行量来弥补消失的信贷。 010央行为了扭转局面，不仅需要推动收入的增长，而且要让收入的增长率超过所积累债务的利率。这是什么意思？主要的意思是，收入一定要比债务增长得快。例如，我们有个国家正在经历去杠杆化，其债务收入比例是100%，这意味着债务量是整个国家一年的收入。假设这些债务的利率是2%，如果债务以2%利率的速度增加，而收入的增长率仅有大约1%，那么债务负担永远不会减轻，必须发行更多货币，使收入增长率超过利率。然而发行货币太容易了，而且又比其他办法受欢迎，因此这个办法很容易被滥用。关键是避免像1920年代去杠杆化的德国那样，发行过多的货币，从而导致恶性通货膨胀。如果决策层取得适当的平衡，去杠杆化过程就不会那样激烈，经济增长速度缓慢但债务负担会下降，这就是和谐的去杠杆化。当收入上升的时候，借款人的信用就会提高，借款人一旦显得更有信用，贷款人就会恢复贷款，债务负担终于开始下降，人们可以借到钱，就可以增加消费，经济终于开始恢复增长，长期债务周期从而进入通货再膨胀阶段。去杠杆化过程中如果处理不当，会非常可怕。但如果处理得当，最终将解决问题。为了使债务负担下降和经济恢复正常，大约需要7-10年或更长的时间，因此有“失去的十年”这种说法。 07 尾声综上所述，经济当然要比这种模式复杂一点，然而把短期债务周期、长期债务周期和生产率增长轨迹结合起来分析，我们会得到一个不错的模式，可以看清我们在过去和当前的处境，以及未来可能的发展方向。最后，我希望大家学到三条经验法则：第一，不要让债务的增长速度超过收入，因为债务负担最终将把你压垮；第二，不要让收入的增长速度超过生产率，因为这最终将使你失去竞争力；第三，尽一切努力提高生产率，因为生产率在长期内起着最关键的作用。","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"宏观经济","slug":"宏观经济","permalink":"https://beefyheisenberg.github.io/tags/宏观经济/"},{"name":"经济周期","slug":"经济周期","permalink":"https://beefyheisenberg.github.io/tags/经济周期/"}]},{"title":"F21b.普林格周期","slug":"52.Financing/F21b.普林格周期","date":"2024-01-24T01:27:53.282Z","updated":"2024-01-24T01:27:53.283Z","comments":true,"path":"52.Financing/F21b.普林格周期/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F21b.普林格周期/","excerpt":"@ref: 美林时钟vs普林格周期：德邦证券-策略专题：大类资产配置框架，基于普林格经济周期六段论-210608.pdf - H3_AP202106081496680732_1.pdf 传统美林时钟框架的不足 美林投资时钟忽视了央行们的逆周期调控，央行们试图通过政策调控来降低经济运行中过度的周期性波动：当经济持续上行时，央行收紧货币政策避免经济过热；在经济持续下行时，央行放宽货币政策阻止经济陷入萧条。央行逆周期调控会让经济周期出现逆时针转动或跨阶段现象。2019年年末，新冠疫情在全球爆发，美国同步指标和滞后指标共振下行，3月底美联储为了刺激经济开始了逆周期调节，包括开放式的资产购买计划及降息至0-0.25%。一系列极度宽松的货币政策有效地缓解了市场的恐慌情绪并增加了市场的流动性，从2020年6月开始美国同步指标和滞后指标共振上行，美国经济周期直接从衰退期进入了过热期。 美林时钟框架把CPI当作滞后指标并以此来观察美国的通胀变化，观察美国近6年来CPI同比的变化趋势可以发现美国通胀迟迟处于低位，通胀同比增速从2015年以来均未超过3%，甚至在2015年4月跌入负值区间。拉平的通胀周期导致市场无法释放相对比较明显的上行或下行信号，2015年1月至2021年2月CPI同比增速上下浮动的绝对平均值只有0.27%，CPI同比增速的历史平均百分位在此阶段为25%。宏观指标上下波动相对较小且增速普遍处于历史低位，使得投资者在近几年使用美林时钟框架时无法有效地对经济周期进行正确划分，也使得其解释力与预测力较弱。而且在中国应用时出现了2013-2015无法解释的偏差（需要用框架外的因素解释）；对于美国而言，美林时钟无法解释2009-2018年（甚至不排除2019-2020年）美国的长期复苏，低失业率、正向产出缺口叠加通胀迟迟处于低位的经济状况。 普林格经济周期六阶段对于美林时钟的改进： 普林格周期中加入了先行指标（信贷周期，见F21d.货币-信用周期），更好适应了货币主义时代。与美林投资时钟框架不同，普林格经济周期在已有的同步指标和滞后指标基础上，加入了先行指标（M1/M2）并以此来更好的适应货币主义时代。 周期阶段划分更为清晰：美林时钟下的周期划分基于库存周期及通胀，并列出每一阶段最好的大类资产，但其过于粗糙的周期划分使得周期阶段并不连续。相比之下，普林格经济周期六阶段在美林时钟的基础下考虑了政府对经济的干涉与调控，从而更准确地划分了经济周期阶段。","text":"@ref: 美林时钟vs普林格周期：德邦证券-策略专题：大类资产配置框架，基于普林格经济周期六段论-210608.pdf - H3_AP202106081496680732_1.pdf 传统美林时钟框架的不足 美林投资时钟忽视了央行们的逆周期调控，央行们试图通过政策调控来降低经济运行中过度的周期性波动：当经济持续上行时，央行收紧货币政策避免经济过热；在经济持续下行时，央行放宽货币政策阻止经济陷入萧条。央行逆周期调控会让经济周期出现逆时针转动或跨阶段现象。2019年年末，新冠疫情在全球爆发，美国同步指标和滞后指标共振下行，3月底美联储为了刺激经济开始了逆周期调节，包括开放式的资产购买计划及降息至0-0.25%。一系列极度宽松的货币政策有效地缓解了市场的恐慌情绪并增加了市场的流动性，从2020年6月开始美国同步指标和滞后指标共振上行，美国经济周期直接从衰退期进入了过热期。 美林时钟框架把CPI当作滞后指标并以此来观察美国的通胀变化，观察美国近6年来CPI同比的变化趋势可以发现美国通胀迟迟处于低位，通胀同比增速从2015年以来均未超过3%，甚至在2015年4月跌入负值区间。拉平的通胀周期导致市场无法释放相对比较明显的上行或下行信号，2015年1月至2021年2月CPI同比增速上下浮动的绝对平均值只有0.27%，CPI同比增速的历史平均百分位在此阶段为25%。宏观指标上下波动相对较小且增速普遍处于历史低位，使得投资者在近几年使用美林时钟框架时无法有效地对经济周期进行正确划分，也使得其解释力与预测力较弱。而且在中国应用时出现了2013-2015无法解释的偏差（需要用框架外的因素解释）；对于美国而言，美林时钟无法解释2009-2018年（甚至不排除2019-2020年）美国的长期复苏，低失业率、正向产出缺口叠加通胀迟迟处于低位的经济状况。 普林格经济周期六阶段对于美林时钟的改进： 普林格周期中加入了先行指标（信贷周期，见F21d.货币-信用周期），更好适应了货币主义时代。与美林投资时钟框架不同，普林格经济周期在已有的同步指标和滞后指标基础上，加入了先行指标（M1/M2）并以此来更好的适应货币主义时代。 周期阶段划分更为清晰：美林时钟下的周期划分基于库存周期及通胀，并列出每一阶段最好的大类资产，但其过于粗糙的周期划分使得周期阶段并不连续。相比之下，普林格经济周期六阶段在美林时钟的基础下考虑了政府对经济的干涉与调控，从而更准确地划分了经济周期阶段。 我们将可跟踪的经济指标分为： 先行指标（信贷周期，典型指标为利率、M1/M2，国内常用的是M1-M2同比，详见F21d.货币-信用周期） 同步指标（生产周期，典型的有GDP） 滞后指标（价格指标，制造国为PPI，消费国为CPI）// 不再使用美林时钟的GDP+CPI 于是经济周期出现六个阶段： 阶段1：经济失速下跌，政府开始逆周期调节。先行指标上行（央行放水，货币指标↑），同步指标及滞后指标下行（GDP 和 CPI下行↓） // 买入债券 阶段2：经济下行拐点出现，开始复苏，先行指标与同步指标上行（持续放水↑、GDP增长率↑），滞后指标仍然下行（CPI、PPI下行↓） // 买入股票 阶段3：先行、同步、滞后指标共振上行（复苏与过热的中间阶段） 阶段4：先行指标下行（经济过热，央行开始收紧货币↓），同步指标及滞后指标上行（GDP↑，CPI↑，经济仍增长，同时也通胀）// 买入抗通胀商品，卖出债券 阶段5：先行指标下行（央行持续收紧货币↓），同步指标下行（GDP不再增长，开始拐头向下↓），滞后指标上行（CPI、PPI上行↑，物价上涨）// 卖出股票，滞胀周期往往股债表现都不好 阶段6：先行、同步、滞后指标皆共振下行（衰退 or 萧条）// 卖出抗通胀商品，持有现金 以上所有的资产买入时机都对应其价格的底部，卖出的时机对应其价格顶部。 需要注意的是，在实践中，经济由于各种原因可能出现重启（例如疫情/战争等黑天鹅），投资者更需要重视的是数据的验证（判断当前处于哪个阶段）而非接下来将进入哪个阶段（政府和央行的逆周期调节）","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"宏观经济","slug":"宏观经济","permalink":"https://beefyheisenberg.github.io/tags/宏观经济/"},{"name":"经济周期","slug":"经济周期","permalink":"https://beefyheisenberg.github.io/tags/经济周期/"}]},{"title":"F21a2.美林时钟在国内的应用","slug":"52.Financing/F21a2.美林时钟在国内的应用","date":"2024-01-24T01:27:53.278Z","updated":"2024-01-24T01:27:53.278Z","comments":true,"path":"52.Financing/F21a2.美林时钟在国内的应用/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F21a2.美林时钟在国内的应用/","excerpt":"@ref: 泽平宏观：传统美林投资时钟在中国不灵？改良的中国投资时钟对大类资产配置的整体准确率达73% 理论回顾美林投资时钟本质上是一种基于需求侧变化的经济周期波动理论，背后的主要逻辑认为，基本面和货币政策相互作用形成短期经济周期，从而影响大类资产走势。投资者可以通过识别基本面和货币政策的重要拐点，在周期变换中把握趋势获利。 美林时钟在美国的回测","text":"@ref: 泽平宏观：传统美林投资时钟在中国不灵？改良的中国投资时钟对大类资产配置的整体准确率达73% 理论回顾美林投资时钟本质上是一种基于需求侧变化的经济周期波动理论，背后的主要逻辑认为，基本面和货币政策相互作用形成短期经济周期，从而影响大类资产走势。投资者可以通过识别基本面和货币政策的重要拐点，在周期变换中把握趋势获利。 美林时钟在美国的回测依照美林投资时钟，本文仍然通过产出缺口和通胀走势判定经济所处阶段，并对每阶段的四大类资产表现进行统计。 以产出缺口衡量经济增速，我们主要对6个月以上较长时段的趋势做上升或者下降的判断。 以同比CPI衡量的通胀数据，CPI是美联储和其它央行盯住的目标和划分通胀等级的依据，自2012年美联储明确2%的通胀目标以来，大多数时间未能实现该目标，因此2012年至今，除个别区间通胀明显上升至2%以外，CPI主要表现为下行趋势。 按照经济增长与通胀变化周期划分四个阶段，产出缺口与通胀同时下行为衰退，产出缺口上行通胀下行时为复苏，产出缺口与通胀同时上行时为过热，产出缺口下行通胀上行时为滞涨。 ▷ 「产出缺口」的定义： 产出缺口是衡量经济体实际产出与其潜在产出之间差距的经济指标。潜在产出是经济体在其效率达到最高时，即满负荷运转时，能够生产的商品和服务的最大值。正如GDP可能增长也可能下跌一样，产出缺口也有两个方向：正向和负向；但这两种方向均非理想状况。当实际产出超过满负荷生产时的产出时，产出缺口为正。在需求居高不下时会出现这种情况，为了满足需求，工厂和工人超负荷运转，远远超出其最高产能。而当经济体的实际产出低于其在满负荷生产时的产能时，产出缺口为负。产出缺口为负意味着由于需求疲弱而存在闲置产能。 我们将1970年1月至2020年9月共划分为34个经济周期，统计结果显示，与美林证券原文的检验结果相同，美国经济周期并未时刻呈现“衰退—复苏—过热—滞涨”依次循环轮转的现象，外部冲击、经济发展阶段变化或造成理论与现实偏差，20世纪80年代中期石油输出国协议瓦解，90年代中期的亚洲金融危机等，都对美国的经济和通胀产生影响，但21世纪前基本遵循明显美林时钟轮动规律。2008年金融危机后，全球持续低利率、超前宽松等导致复苏和衰退成为美国经济主旋律，轮动规律减弱。 美国的复苏期和过热期是持续时间最长的两个周期。从周期平均持续时间来看，复苏期平均达25个月，过热期平均为15.5个月，滞胀期平均为15.0个月，衰退期最短为12.8个月。 美林时钟定义的大类资产在美国1970-2020的表现：基本符合经典理论 Ⅰ衰退：债券是衰退阶段的最佳选择。债券的收益率达到6.30%，高于债券长期平均收益3.23%。处于投资时钟对立位置的大宗商品表现最差。 Ⅱ 复苏：股票是复苏阶段的最佳选择。股票收益率达到20.02%，高于股票长期平均收益9.25%，现金收益远低于股票，大宗商品表现糟糕。 Ⅲ 过热：大宗商品是过热阶段的最佳选择。大宗商品年收益率为26.74%，高于大宗商品长期平均收益7.57%。处于投资时钟对立位置的债券表现糟糕，年收益率只有2.87%。 Ⅳ 滞胀：现金是除大宗商品以外表现最好的。现金年均收益率为5.09%。处于投资时钟对立位置的股票表现最糟糕，年收益率为-8.05%。大宗商品的年均收益率高达22.56%，主要受20世纪70年代两次石油危机冲击的影响比较大，而同时期非石油类大宗商品价格主要呈下跌趋势。 美林时钟在中国的检验注意这里的观测数据（产出缺口和CPI）的处理：由于我国暂无官方统计的产出缺口指标，这里测算数据做了一下换算，产出缺口定义为=(实际GDP-趋势值)/实际GDP。在通胀方面，我们采用统计局公布的CPI当月同比值。 根据统计结果，我们将2002年12月至2020年9月共划分为33个经济周期，其中衰退期10个，复苏期6个，过热期8个，滞涨期9个。从特征来看： 过热期和衰退期是持续时间最长的两个周期。从周期平均持续时间来看，过热期平均达10.6个月，衰退期平均为6个月，滞涨期平均为5.2个月，复苏期最短为3.7个月。 仅少数周期遵循美林投资时钟的周期轮动规律，大部分周期呈现前后跳跃或逆时针转动现象。 检验传统美林投资时钟的大类资产收益率表现，结论： Ⅰ 衰退期中，美林时钟正确率仅为30%，10个小周期中仅有3个周期债券收益率表现最好，其他在衰退期表现较好的资产包括现金(3次)、股票(3次)、商品(1次)。 Ⅱ 复苏期中，美林时钟正确率为50%，6个小周期中有3个周期股票收益率表现最好，其他在复苏期表现较好的资产主要为现金(3次)，其他资产则均表现较差。 Ⅲ 过热期中，美林时钟正确率为50%，8个小周期中有4个周期商品收益率表现最好，其他在过热期表现较好的资产包括股票(3次)、现金(1次)。 Ⅳ 滞涨期中，美林时钟正确率仅为33%，9个小周期中仅有3个周期现金收益率表现最好，其他在滞涨期表现较好的资产包括股票(4次)、债券(1次)、商品(1次)。 为什么美林时钟在中国的效果欠佳整体来看，传统美林时钟在我国对于大类资产配置的指导正确率为40%，较美国数据明显偏低。为什么传统美林时钟在中国的效果偏差? ➤ 原因1：中美货币政策制定框架存在差异 传统美林时钟的基本假设和逻辑与美联储的货币政策框架相近，因而对大类资产配置的指导意义更强。 1993年7月起，美联储开始以新凯恩斯主义理论为核心思想，运用类似泰勒规则来设定联邦基金利率，通过公开市场操作引导货币市场利率围绕联邦基金利率波动，实现充分就业和稳定物价的政策目标。 根据泰勒规则，央行应该根据产出和通胀的情况实施货币政策，利率决定公式为：r=0.5*(π_t-2%)+0.5*y ̂+π_t+2%其中π_t 代表通胀，y ̂代表产出缺口，在美联储的目标利率决定框架中，实际通胀与目标通胀的差值(π_t-2%)占50%权重，产出缺口y ̂占50%权重，如果通胀高于目标，以及产出缺口提升，美联储应该加息，反之则应该降息。 当不存在通胀偏离以及产出缺口时，联邦基金利率应该等于名义利率，也即通胀加上长期实际利率(π_t+2%)。泰勒规则后，美联储利率政策规则经过一系列修订，先后有伯南克规则、埃文斯规则、耶伦规则等，三者均是在泰勒规则基础上进行部分权重调整，或增加就业指标。 而我国货币政策需兼顾多重目标，包括经济增长、充分就业、物价稳定、内外平衡、防范金融风险、维护金融稳定等。不同目标可能会对货币政策制定提出方向相反的要求，增加货币政策的决策难度。 图1 vs 图2：美联储和央行货币政策的决策因素对比 ➤ 原因2：大类资产表现除受货币政策影响外，还受金融监管、改革等政策影响 如2016年开启供给侧结构性改革造成的商品牛市。在“三去一降一补”的政策导向下，落后产能持续退出，供给收缩造成商品在2016年走出一波牛市。 2015年12月，中央经济工作会议上提出的供给侧结构性改革，“三去一降一补”即：去产能、去库存、去杠杆、降成本、补短板。 再比如2014-2015年股市行情，在经济周期整体处于“滞涨”及“衰退”期，由于政策驱动叠加监管宽松，大量资金加杠杆入市，我国股票市场走出一波大牛市。但是随着监管关注配资风险，严查杠杆入市，大量资金撤离，造成股市快速下挫。 同样，2016年债券市场走出一波行情，而主要驱动因素为宽松的金融监管环境下，理财-委外加杠杆等市场行为催生债券投资需求，与央行货币政策意图相左，因此债市走势和传统美林时钟背后逻辑出现明显偏差。 结论：国内的资产走势，体现出明显的政策市、资金市的特征 ➤ 原因3：通胀的概念、范畴和度量存在不足，造成实际经济周期的划分存在偏差 居住消费在通胀指标中占比过低。周小川：“对于住房，过去的概念是购房算作投资，价格变化不计入CPI;后来则租房可计入，但在篮子中的权重偏小;再后来，人们主张把自住房用类比租金来计量，但是住房权重仍相对比较小” 在当前的经济环境下，出现全面通胀的可能性较低，“结构性通胀”成为通胀的主要表现形式。因此，在CPI内部主要表现为食品、农产品以及资源性产品的价格上涨，其他产品价格则相对稳定。 改良的中国投资时钟 不再使用生产缺口+CPI同比作为周期的观测指标，而是以货币+信用作为周期观测指标 @link: F21d.货币-信用周期 实际上，产出缺口和通胀是货币政策的部分输入变量，而货币与信用是输出变量，且受金融监管等因素影响。如果说产出缺口和通胀是货币政策的其中一部分输入变量，“货币”和“信用派生”可以理解为货币政策的主要输出变量，其中“信用派生”也是实体经济运行的结果，与大类资产的之间的逻辑链条更为直接。 图3：化简为繁，不再观测产出缺口、通胀等等这些影响货币政策的指标，而是直接用央行现行的货币政策观测，预判大类资产的走势 我们在这里，把“货币”定义为货币政策的意图，即狭义流动性水平，央行通过货币政策工具操作，调控银行间市场流动性;把“信用”定义为通过货币政策操作形成的结果，即广义流动性水平，央行通过货币政策影响广义流动性，但狭义流动性是否能传导至广义流动性，还要看市场主体的加杠杆行为、金融监管等因素。 从逻辑上来说，货币和信用因素也可以与产出缺口和通胀构建的经济周期形成统一： 1)在衰退期：经济下行，产出缺口恶化、通胀下行。货币政策趋松，而实体经济融资需求较弱，广义流动性仍然较紧，对应“宽货币+紧信用”格局。 2)在复苏期：经济上行，产出缺口好转，通胀下行。随着经济转好，企业盈利改善，融资需求提升，广义流动性提升，对应“宽货币+宽信用”格局。 3)在过热期：经济上行，产出缺口继续向好，通胀上行。经济存在过热风险，央行收紧流动性，货币政策趋紧，但是此时实体经济融资需求依然旺盛，广义流动性短期难以回收，形成“紧货币+宽信用”格局。 4)在滞胀期：经济下行，产出缺口恶化，通胀上行。由于通胀压力较大，央行难以放松货币，叠加实体经济需求不振，狭义及广义流动性均较紧，形成“紧货币+紧信用”格局。 ➤ 货币与信用的指标选择及周期划分： 货币：判断狭义流动性的松紧，最简单的方式是观察银行间市场流动性。但是还有其他因素会影响银行间市场流动性，如实体经济融资需求较强时，银行间市场流动性同样趋紧，影响对于宽货币政策意图的判断。因此我们还是采用最基础的方法，即通过典型的货币政策转向操作，判断货币松紧意图的转变，作为定性判断。 信用：我国自从2002年开始公布社会融资总量数据，其涵盖了主要的信用派生渠道，可以作为衡量广义流动性松紧的主要指标。但是在2016年前，社融增速的公布频率较低，难以捕捉具体月份的社融增速走势，因此我们共同参考社融增速与M2增速，判断信用走势。 结果显示，从2002年12月至2020年9月，我国信用周期共17个，其中9个宽信用周期，8个紧信用周期；宽信用（复苏-过热）周期共计83个月，平均持续9.2个月；紧信用（滞胀-衰退）周期共计132个月，平均持续16.5个月； ➤ 基于货币-信用周期划分的大类资产收益测算： Ⅰ 宽货币+紧信用（衰退）周期中，大类资产配置于债券的正确率达83%。6个小周期中有5个周期债券表现明显优于其他资产，仅2014-2016年周期，股票收益率超过债券，但主要因素是2015年股市杠杆牛，对股票收益率造成扰动。 Ⅱ 宽货币+宽信用（复苏）周期中，大类资产配置于股票的正确率达100%，6个小周期中，股票收益率均明显优于其他资产。 Ⅲ 紧货币+宽信用（过热）周期中，大类资产配置于商品的正确率为57%，7个小周期中有4个周期商品表现明显优于其他资产，在紧货币+宽信用的周期组合下，股市也具有较好表现，在两个周期里收益超过商品。 Ⅳ 紧货币+紧信用（滞胀）周期中，大类资产配置于现金的正确率仅为43%，7个小周期中仅有3个周期现金表现明显优于其他资产，在紧货币+紧信用的周期组合下，大类资产表现缺乏明显特征，商品、债券、股票都曾出现较好表现。 结论：以货币及信用因素进行划分的周期，对大类资产配置的整体准确率达到73%，在宽货币紧信用时期（衰退）、宽货币宽信用时期（复苏）、以及紧货币宽信用时期（过热），均对大类资产配置有较好的指导意义。仅在紧货币紧信用周期（滞胀）缺乏明确的资产配置指向。 股票市场投资时钟我们将申万一级行业剔除国防军工和综合后分类成周期类、大金融类、消费类、成长类四大板块，其中周期进一步细分为上中下游。根据前文货币与信用周期的时间划分，按照市值加权平均数计算区间板块年化收益率，以探索板块间轮动规律。 Ⅰ 衰退：金融和消费板块在衰退阶段抗跌能力最强。衰退期时期宽货币，银根放松，利率敏感型的金融、消费类股票领跑。在6个衰退期中，3个阶段金融板块收益率最高，5个阶段消费板块收益率第2，二者均值分别为-8.9%、-3.9%（跌的少…）成长板块受2019年11月-2020年2月5G牌照发放、科创板推出等利好影响，均值超过金融和消费板块。 Ⅱ 复苏：周期和金融板块是复苏阶段的最佳选择。宽货币宽信用下，各大板块同时受益于盈利改善和估值上升，股市呈现普涨。因此，对景气度上行弹性最大的周期板块，对流动性宽松弹性最大的金融板块收益率最佳。在6个复苏期中，4个阶段金融板块收益率最高，5个阶段周期板块收益率第2，二者均值分别为64.9%、55.5%。 Ⅲ 过热：周期和消费板块是过热期表现最佳的。过热期对应紧货币宽信用，实体经济仍然景气，但是流动性转向，利率抬升导致金融资产估值下行，股市呈结构性行情。周期板块盈利仍处高位，消费板块现金流较为稳定，对流动性收紧相对不敏感，收益率较高。在7个过热期中，5个阶段消费板块收益率靠前，消费和周期板块收益率远高于其他两个板块，高达55.9%、44.5%。 Ⅳ 滞胀：消费和成长板块在滞胀阶段相对抗跌。紧货币紧信用阶段，实体景气下滑，企业盈利恶化，利率上升、估值收缩，股票市场整体表现糟糕。其中，伴随政策对通胀的控制，折现率有所下行，长久期的成长股价值提升明显，相对抗跌。而消费板块由于现金流较为稳定，表现相对抗跌。 债券市场投资时钟从理论上来说，债券市场在不同周期下，由于债券短端利率受货币政策影响较大，长端利率取决于基本面，利率走势及曲线形态存在明显特征。随着经济周期从衰退期依次轮动至复苏、过热、滞涨期，债券利率走势及曲线形态依次经历牛陡、熊陡、熊平、牛平。 Ⅰ 衰退（宽货币+紧信用）：债券收益率曲线呈现牛陡形态。衰退期经济触底，货币转为宽松，宽货币紧信用，短端利率快速下行，债券市场走牛，短端利率下行幅度显著高于长端利率，债券收益率曲线呈现牛陡形态。 Ⅱ 复苏（宽货币+宽信用）：债券收益率曲线呈现熊陡形态。经济逐步复苏，货币政策宽度幅度收敛，短端利率下行幅度收敛，同时市场预期经济基本面逐步恢复，长端利率上行，债券收益率曲线呈现熊陡形态。 Ⅲ 过热（紧货币+宽信用）：债券收益率曲线呈现熊平形态。随着经济增速持续加快，货币政策转向，紧货币宽信用，短端利率快速上行，而长端利率上行幅度收敛，导致收益率曲线呈现熊平形态。 Ⅳ 滞胀（紧货币+紧信用）：债券收益率曲线呈现牛平形态。在经济过热期结束前，市场预期经济将由盛转衰，长端利率开始下行，而此时货币政策相对稳定，收益率因此呈现牛平形态。 商品市场投资时钟商品一级分类指数包括南华工业品指数、南华农产品指数、南华金属指数和南华能化指数：其中，工业品指数由金属指数和能化指数品种构成。由于南华贵金属指数数列时间区间较短，我们采用上海黄金交易所AU9999的价格涨幅表示贵金属板块。 Ⅰ 衰退：贵金属在衰退阶段表现最佳。衰退阶段，以黄金为代表的贵金属，一方面可以避险，另一方面可作为组合资产改善风险收益特征。而传统商品资产受经济放缓影响，需求回落叠加产能过剩，工业品暴跌，但衣食等消费刚需支撑农产品板块相对较强。在6个衰退期中，3个阶段黄金收益率第一，黄金年平均收益率为4.3%，工业品、农产品年平均收益率分别为-23.0%、-14.0%。// 不过在2022年全球滞胀-衰退周期中，美元表现最好，并且对黄金和加密货币造成了挤兑 Ⅱ 复苏：工业品整体表现不错，金属板块是最佳选择。经济景气度复苏，地产、汽车和基建的拉动下，工业品需求旺盛，但产能不足，价格上涨。金属与地产等板块等相关性强，表现优于能化。而此阶段，居民收入增长有限，消费能力不足，农产品表现较差。 Ⅲ 过热：投资时钟配置商品阶段，金属板块表现最佳。经济景气度持续，通胀上行，工业品价格继续上涨。金属需求仍然强于能化，表现更好。在7个过热期中，4个阶段金属收益靠前、3个阶段能化收益靠前。各商品平均收益率均在10%以上，其中金属收益率为35.6%，表现相对最差的黄金收益率也高达15.6%。 Ⅳ 滞胀：贵金属在滞胀阶段最为抗跌。经济景气度下滑，工业需求放缓，产能由于过度乐观处于扩张，供大于求，工业品价格下跌。这一阶段，贵金属的避险属性凸显，抗跌能力强。在7个滞胀期中，6个阶段黄金收益表现靠前，年平均收益为5.8%，是五大板块唯一正值。","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"宏观经济","slug":"宏观经济","permalink":"https://beefyheisenberg.github.io/tags/宏观经济/"},{"name":"经济周期","slug":"经济周期","permalink":"https://beefyheisenberg.github.io/tags/经济周期/"},{"name":"美林时钟","slug":"美林时钟","permalink":"https://beefyheisenberg.github.io/tags/美林时钟/"},{"name":"社融","slug":"社融","permalink":"https://beefyheisenberg.github.io/tags/社融/"},{"name":"M2","slug":"M2","permalink":"https://beefyheisenberg.github.io/tags/M2/"}]},{"title":"F21a.美林时钟","slug":"52.Financing/F21a.美林时钟","date":"2024-01-24T01:27:53.273Z","updated":"2024-01-24T01:27:53.273Z","comments":true,"path":"52.Financing/F21a.美林时钟/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F21a.美林时钟/","excerpt":"美林时钟美林时钟是美国投行美林证券提出的一个The Investment Clock资产配置理论。美林时钟用经济增长率（GDP）和通货膨胀率（CPI）这两个宏观指标的高和低，将经济周期分成了四个阶段: 复苏期（高GDP+低CPI）； 过热期（高GDP+高CPI）； 滞胀期（低GDP+高CPI）； 衰退期（低GDP+低CPI）； GDP &amp; CPI =&gt; F23.经济指标和历史数据","text":"美林时钟美林时钟是美国投行美林证券提出的一个The Investment Clock资产配置理论。美林时钟用经济增长率（GDP）和通货膨胀率（CPI）这两个宏观指标的高和低，将经济周期分成了四个阶段: 复苏期（高GDP+低CPI）； 过热期（高GDP+高CPI）； 滞胀期（低GDP+高CPI）； 衰退期（低GDP+低CPI）； GDP &amp; CPI =&gt; F23.经济指标和历史数据 ➤ 美林时钟的资产配置方法： 在复苏中，经济增长开始加速。然而通货膨胀继续下降，因为多余的产能还没有完全被利用起来，周期性生产力的增长强劲，利润也开始边际修复。中央银行仍然保持政策松动，债券收益率曲线下降，处在较低位置（利率在极低位置，也意味着债券价格在高位）。此时股票表现最好。 在经济过热中，通货膨胀上升。中央银行加息使过热的经济回到可持续增长路径。GDP增长仍保持在较高水平。 央行试图通过加息抑制经济过热，导致债券收益率开始拐头上涨和平坦化（意味着债券价格见顶）。这一阶段债券表现较差，股票回报如何取决于利润增长导致估值上升和利率上升导致的估值下降两方面，大宗商品表现最好。 在滞胀中，GDP增长率低于潜在经济增长，但是通货膨胀率持续上升（通常部分来自于石油价格冲击等）。生产力下降，工资、价格螺旋式上升，公司提高价格以保护其利润边际。这个阶段因为通胀太高，央行也不愿意放松货币政策（高利率，故债券价格持续在低位）。只有急速上升的失业率可以打破这种恶性循环。这一阶段股债双杀，此时现金是最好的投资资产。 在衰退中，GDP增长缓慢。产能过剩和大宗商品价格下跌使得通胀率也较低。企业利润微弱，债券收益率曲线向下移动并陡峭（意味着债券价格上涨），因为央行会降低短期利率，试图使经济复苏。此时债券是最好的投资配置。 如果考虑到利率，名义利率和实际利率在整个周期中的介入如下： ➤ 当前处于哪个阶段? 通过哪些指标来判断?通过监控宏观经济指标来判断将要来临的经济周期，并确定相应的投资时钟时段。通常可以考虑的指标有 CPI 增速、PMI 指数、工业增加值等。 ➤ 美林时钟配置模式:一般的配置原则为超配处于投资时钟周期内的品种。初始阶段是均衡配置：债券、股票、商品、货币基金各 25% 为基准，处于投资时钟周期内的品种超配至 50%～70% ，其他三类各配置 10%～15%。比如衰退期，债券基金的配置比例为 70%，其他三类各 10%。具体配置比例以对宏观的判断可靠性为准，可靠性高一些则超配比例高一些。 美林时钟的实际应用实际上美林时钟并不好用，缺陷包括： 观测指标使用了GDP/CPI（数据滞后，GDP这种总量型数据过于宏观，可观测性差）； 没考虑现代经济体中的宏观调控（逆周期调节、去杠杆等），这些调控可能会直接影响周期（见下）； 以及现在的经济全球化后，单一经济体的周期性更容易受到外部经济环境的影响，比如2022现在的情况：经济开始衰退后，zf开始通过宏观调控放水，但是外部状况很差（国外都在加息，出口预期不会好），同时内部状况也不好（疫情带来的消费意愿下降，内需不足）.. 综上，现在的美林时钟不太会给个人的资产配置有直接指导性作用，更多的是帮助理解经济的周期性 中国经济的美林时钟周期@link: F21a2.美林时钟在国内的应用","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"宏观经济","slug":"宏观经济","permalink":"https://beefyheisenberg.github.io/tags/宏观经济/"},{"name":"经济周期","slug":"经济周期","permalink":"https://beefyheisenberg.github.io/tags/经济周期/"},{"name":"美林时钟","slug":"美林时钟","permalink":"https://beefyheisenberg.github.io/tags/美林时钟/"}]},{"title":"F21.经济的周期性","slug":"52.Financing/F21.经济的周期性","date":"2024-01-24T01:27:53.268Z","updated":"2024-01-24T01:27:53.269Z","comments":true,"path":"52.Financing/F21.经济的周期性/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F21.经济的周期性/","excerpt":"“万物皆周期” 经济周期相关文章索引： 美林时钟周期：F21a.美林时钟 普林格周期：F21b.普林格周期 Ray Dailo提出的长短期债务周期 F21c.经济机器是如何运行的 国内的货币-信用周期 F21d.货币-信用周期","text":"“万物皆周期” 经济周期相关文章索引： 美林时钟周期：F21a.美林时钟 普林格周期：F21b.普林格周期 Ray Dailo提出的长短期债务周期 F21c.经济机器是如何运行的 国内的货币-信用周期 F21d.货币-信用周期 宏观经济的周期理论： 按照传统经济学理论，理想状态下，一个国家的经济增长应该基于自身的技术、资本以及劳动力等要素情况，沿着潜在增长轨迹稳定增长。但由于外部冲击和非理性行为等等，实际的经济增长并不会沿着潜在经济增速稳定运行，而是围绕理论增速上下波动，类似股票内在价值线和实时价格线的关系，最终呈现出“复苏-繁荣-衰退-萧条-再复苏”这样的循环推进过程。如下图所示。 此外，根据不同投资的波动，还可划分出几大经济周期： 农产品周期（蛛网周期）：农产品价格对产能的迟滞作用，周期长度1~12M 库存周期（基钦周期）：增长与通胀周期，周期长度2~4Y 设备周期（朱格拉周期）：经济景气度、设备寿命，周期长度6~11Y 地产周期（库兹涅茨周期）：人口增长周期，周期长度24~40Y 康波周期（康德拉季耶夫周期）：科技创新周期，周期长度50~70Y，周天王“人生发财靠康波” 库存周期（基钦周期）@link: F44.周期股 设备周期（朱格拉周期）朱格拉周期又称为设备更新周期，时间跨度约10年，属于中等长度的经济周期。在经济生产中，机器设备因磨损、技术进步等因素影响，往往过几年就需要更新，这种设备更替带动资本开支（固定资产投资）呈现出周期性变化，进而导致经济呈现周期性波动：当企业大规模更新设备时，带动固定资产投资增加，从而拉动经济增长；随着设备更新的完成，企业投资开始下降，这又会导致经济增速放缓。 ➤ 影响朱格拉周期的因素： 供求关系的反应速度，在市场条件下，供需关系总是不同步 企业家心态：朱格拉周期体现的是企业家对产能的投资，在繁荣-萧条不同周期心态是不同的 ➤ 朱格拉周期的追踪指标： 由于朱格拉周期主要受设备更替和资本开支的驱动，因此，一般可通过固定资产投资中的企业设备投资增速、设备投资占GDP的比重、资本开支增加情况等指标来追踪。从某种程度上说，设备投资增速像是结果，也是最基本的识别变量，而在指导投资策略时，还需综合考虑价格变化、信贷、经济增速、投资增速等等因素，来判断所处的朱格拉周期阶段。简单来讲： （1）GDP增速与朱格拉周期相一致，即设备投资与经济增速挂钩。 （2）设备投资的需求离不开终端消费需求的回暖，投资增长的动力在于消费。 （3）经济全球化下，外需产业链是拉动经济回暖、设备投资的主要动力，加速设备更新迭代。 （4）固定资产投资的历史趋势和朱格拉周期保持一致，全球主要国家固定资产投资完成额增速周期性信号显著，中国的固定资产投资完成额增速则与全球朱格拉周期不一致，可能是房地产周期的不同步。 （5）全球朱格拉周期开启时，全球主要经济体的制造业固定资产投资同比迅速上升，制造业PMI也持续走高。 （6）与设备投资相关的工业锅炉、金属切削机床等的产量增速指标代表着微观上制造业资本支出意愿，这些指标的历史走势呈现出朱格拉周期特征。 （7）朱格拉周期中设备投资增速增加，拉动上游大宗商品需求上涨，因此价格变化也可以捕捉朱格拉周期形成，可选取CPI、PPI以及大宗商品期货价格指数来对朱格拉周期进行识别。 （8）信贷投放宽松程度是朱格拉周期的重要影响因素，货币供给量、金融机构贷款余额同比增速等指标可以作为判断朱格拉周期启动的先行信号。 ➤ 国内的朱格拉周期： 历史上我们观察到的朱格拉周期是6-11年，1987年前后中国一共经历了4个： 地产周期（库兹涅茨周期） 浅议房地产周期与人口周期 第三代“婴儿潮”的消退：40年未见之变局 库茨涅兹周期一般受房地产和建筑驱动，又称建筑周期和房地产周期，时间跨度约15-20年，属于中长期的经济周期。库茨涅兹周期是1930年美国经济学家库兹涅兹提出来的，不过即使是在美国，其实际地产周期长度也不稳定，因此一些西方学者对该周期提出质疑，认为人口因素才是更本质的影响地产周期的因素。 就我国而言，由于我国房地产市场起步较晚（1998年正式开启商品房市场），数据周期较短，中国房地产市场规模一直处于上升阶段，理论上还没有走完一个完整的库茨涅兹周期。不过，借鉴其他国家的历史经验，中国可能正处于第一个库茨涅兹周期的尾部。而我们日常所说的中国房地产周期，其实指房地产短周期（政策金融周期，3-5年），库茨涅兹周期则是指房地产长周期。 ➤ 库茨涅兹周期的追踪指标： 一般我们用住房新开工数量、房地产投资等相关指标来跟踪各国房地产的发展情况，但是人口因素是更领先的本质因素。 ➤ 库兹涅兹周期——以美国为例： 以数据较为完备的美国为例，从下图可以看出，美国的地产周期长度实际并不稳定。按照地产景气低点划分，最近的一轮美国地产周期是1990-2008年，持续时间18年左右；而再往前看，1974、1980均是-20%左右的低点，其间隔明显小于库兹涅茨周期定义的15-20年，地产周期的波动显然更为剧烈。人口因素可以更本质解释地产景气的长期变动： 1970-1985年：美国地产市场虽然因为石油危机、股灾等因素波动较大，但是整体景气度维持较高水平，主因当时战后婴儿潮进入成年，推升了购房需求。 1990年至今：随着人口增速下行，地产销售和投资增速峰值明显下降，高点在20%以下。这一轮房地产周期时间跨度较长，约20年，可能原因是2000年之后，美国通过降低住房抵押利率等方式刺激房地产市场，让政策为房地产续命，从而延迟了地产下行周期的到来，当然也直接导致了次贷危机。 康波周期（康德拉季耶夫周期） 周金涛的“2019大预言”，为何落空了？ 重温周期天王周金涛：对2025年之前的经济预测。周金涛-中信建投首席经济学家-2016年3月16日演讲 - 知乎 康德拉基耶夫长波周期简称为康波周期，是俄国著名的经济学家康德拉季耶夫提出。康波理论认为经济成长过程中呈现出上升与衰退交替出现的一种波动。这种波动存在着为期55年~60年左右的周期性特征。康波周期长达55年~60年，因此康波又称为长波或者长周期。 关于长波理论，康德拉季耶夫先后发表了《经济生活中的长波》(1925年)和《大经济周期》(1928年)等论著。在这些论著中，他分析了英、法、美、德以及世界经济的大量统计数据，发现发达商品经济中存在着为期54年的周期性波动。熊彼特等人后来继承和发展了长波理论。1939年经由熊彼特提议，世界经济学界都接受了用“康波周期”代表经济成长过程中长时段的波动。 康波周期有不同的划分方式，目前受到比较广泛认可的康波划分方法是荷兰经济学家雅各布·范杜因（Jacob J. Van Duijn）的划分。一个完整的康波周期分为：繁荣、衰退、萧条、回升四阶段；一般来说，第四阶段（回升）是下一次主线产业带动的，然后成为新一轮周期的繁荣阶段。 第一次长波周期发源于英国，从大约1782-1845（约63年），这个时期正好是第一次工业革命时期。这个时期，由于蒸汽机的发明和运用，工业制造取代手工制造，并且推广到所有的工业部门和工业国家 第二次长期周期是1845-1892（约47年）。这个时期早期工业化国家开始进入“钢铁时代”和“铁路化时代”，这个周期实际上世界工业的中心就已经从英国以及欧洲大陆转移到了美国，当时世界一半的铁路在美国 第三次长期周期是1892-1948（约56年），“电气、重化工业”，期间发生了一战和二战，石油作为当时的新兴能源变得越来越重要，Seven Sisters（七姐妹） 第四次，1948-1991（约43年），“石油、电子计算机”，期间冷战持续，也发生了数次基于石油能源争夺的中东战争；时代之子：通用汽车、IBM（大型机）；有意思的是这个时代的末期发生的几件事情：G5签署广场协议、日本经济泡沫从开始到破灭（期间日本电信公司NTT市值全球最高） 第五次，1991-？，“信息技术”，AT&amp;T、微软（PC OS）、Apple … ➤ 从另一个角度看康波周期 上世纪60年代至今，科技股相对于标准普尔500的估值曲线： 第一个峰值：20世纪60年代末的漂亮50“nifty fifty”时代，由IBM和少量其他技术相关问题领导。接下来的熊市非常严重，尤其是考虑到当时通胀压力带来的负面影响。// IBM、AT&amp;T、Apple、Intel 第二个峰值，2000年，世纪之交的互联网泡沫时代。像“nifty fifty”时代一样，互联网泡沫是由相对较小的一批公司推动的，这些公司因对互联网新技术的热情而获得了巨额估值。接下来的熊市又一次很严重，以科技股为主的纳斯达克市值损失了约80%。 第三个峰值，2021年的科技股估值峰值与其前身有些相似，由一小批股票(FAANGs、微软等)引领。 这种由技术驱动的市场峰值是市场的一个特征(它们最早出现在19世纪)。历史告诉我们，接下来的熊市往往会很严重。而且，下一轮牛市的领导者将与上次不同。迄今为止，2022开始的熊市相对温和，但还没有结束。在我们看来，持续加息、衰退加剧以及重大地缘政治风险表明，我们可以预计未来市场将出现更多波动。 @ref: https://xueqiu.com/1488541085/237672170 周期叠加，会发生什么？ @ref： 人生发财靠康波？周期论真的靠谱吗？","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"宏观经济","slug":"宏观经济","permalink":"https://beefyheisenberg.github.io/tags/宏观经济/"},{"name":"经济周期","slug":"经济周期","permalink":"https://beefyheisenberg.github.io/tags/经济周期/"},{"name":"_Index","slug":"Index","permalink":"https://beefyheisenberg.github.io/tags/Index/"}]},{"title":"F20.宏观经济框架","slug":"52.Financing/F20.宏观经济框架","date":"2024-01-24T01:27:53.264Z","updated":"2024-01-24T01:27:53.264Z","comments":true,"path":"52.Financing/F20.宏观经济框架/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F20.宏观经济框架/","excerpt":"@link: F10.经济学101 IS-LM模型 @todo: 如何建立自己的宏观经济分析框架？ - 张涔子沐的回答 - 知乎 https://www.zhihu.com/question/46135259/answer/2367963781","text":"@link: F10.经济学101 IS-LM模型 @todo: 如何建立自己的宏观经济分析框架？ - 张涔子沐的回答 - 知乎 https://www.zhihu.com/question/46135259/answer/2367963781 在此基础上，扩展如下:","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"宏观经济","slug":"宏观经济","permalink":"https://beefyheisenberg.github.io/tags/宏观经济/"}]},{"title":"F13.股市101","slug":"52.Financing/F13.股市101","date":"2024-01-24T01:27:53.260Z","updated":"2024-01-24T01:27:53.260Z","comments":true,"path":"52.Financing/F13.股市101/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F13.股市101/","excerpt":"@tag: #入门101 一级市场、二级市场 一级市场(发行市场): 公司上市需要证监会批准, 根据公司净值定发行价, 股民投资者可以从证券公司申购, 申购成功则以发行价买入 (券商=&gt;投资者) 二级市场(交易市场): 在上述过程之后，公司到二级市场(也即证券交易市场, 故二级市场是’场内’)上市流通, 股民之间的转手/交易 买方、卖方 买方（buyside）：买（股票）的一方，主要包括公募基金，私募基金，保险公司投资部等以资产管理模式为代表的公司； 卖方（sellside）：卖（股票）的一方，券商和一些独立研究机构，他们主要从事分析和研究股票的工作，并且对于公司的基本面给予建议。从历史上看，卖方这个行业真正出现比较强的定价权是发生在美国上世纪的70年代。当时《对冲基金风云录》作者，摩根斯坦利著名的策略分析师巴顿.比格斯第一次在公司内部组建了一只超级豪华的分析师阵容，在那个时代就给出了6位数美元的工资。之后就是进入80年代美国股市最长的一轮牛市。这一次牛市同时推动了卖方研究所和买方投资机构的市场地位","text":"@tag: #入门101 一级市场、二级市场 一级市场(发行市场): 公司上市需要证监会批准, 根据公司净值定发行价, 股民投资者可以从证券公司申购, 申购成功则以发行价买入 (券商=&gt;投资者) 二级市场(交易市场): 在上述过程之后，公司到二级市场(也即证券交易市场, 故二级市场是’场内’)上市流通, 股民之间的转手/交易 买方、卖方 买方（buyside）：买（股票）的一方，主要包括公募基金，私募基金，保险公司投资部等以资产管理模式为代表的公司； 卖方（sellside）：卖（股票）的一方，券商和一些独立研究机构，他们主要从事分析和研究股票的工作，并且对于公司的基本面给予建议。从历史上看，卖方这个行业真正出现比较强的定价权是发生在美国上世纪的70年代。当时《对冲基金风云录》作者，摩根斯坦利著名的策略分析师巴顿.比格斯第一次在公司内部组建了一只超级豪华的分析师阵容，在那个时代就给出了6位数美元的工资。之后就是进入80年代美国股市最长的一轮牛市。这一次牛市同时推动了卖方研究所和买方投资机构的市场地位 @ref: https://m.gelonghui.com/p/164848 公募/私募公募又称公开发行，是指发行人通过中介机构向不特定的社会公众广泛地发售证券，通过公开营销等方式向没有特定限制的对象募集资金的业务模式。为适应更广大投入者的需求，公募没有合同份数和起点金额的限制。因为涉及众多中小投入人的利益，监管当局对公募资金的使用方向、信息披露内容、危机防范要求都非常高。而私募是面向少量的、特定的投入者募集资金的方式。参加人一般应具备一定的经济实力、危机识别和危机承担能力。 融资/融券 融资融券账户与普通账户相比有哪些区别和限制？（除了融资融券的特性以外） - 双牛做的木子星 的回答 - 知乎 图文说明：融资（做多）与融券（做空）- 雪球 集合竞价开盘前，不需要按照时间优先和价格优先的原则交易，而是按最大成交量的原则来定出股票的开盘价， 使它同时能满足以下3个条件： 成交量最大。 高于基准价格的买入申报和低于基准价格的卖出申报全部满足（成交）。 与基准价格相同的买卖双方中有一方申报全部满足（成交）。 对冲 对冲: 一般对冲是同时进行两笔行情相关、方向相反、数量相当、盈亏相抵的交易 对冲基金 https://wiki.mbalib.com/wiki/%E5%AF%B9%E5%86%B2%E5%9F%BA%E9%87%91 做空可以做空的品种包括股票、股指期货、某国货币 股票市场是通过融资融券“做空”的，融券卖出，即借来股票现值卖掉，等待价格下跌，再以低价买回股票归还，实现差价收益。实际操作中，做空是先借入标的资产（有专门出借方如证券公司），然后卖出获得现金，这段时间内如果标的资产价格下跌，再以低价买入标的等量资产归还(证券公司), 获取差价利润为什么出借方愿意出借标的的资产呢？通常出借方出借资产的利率是远高于贷款利率的，而且会不断浮动（根据市场情绪及下跌的可能性浮动，下跌可能性大，利率高；下跌可能性小，利率低），因此如果资产价格没有下跌，出借方就可以获得远超市场利率的收益，这也是出借方愿意出借的原因。 什么是“做空”？“做空”是如何赚钱的？ - 飞翔的勇士的回答 - 知乎 详解港股做空机制之一：做空到底怎么玩? 索罗斯做空英镑：F29.金融大事记 索罗斯做空港元：F29.金融大事记 做空失败的案例: 游戏驿站GameStop是做什么的？机构为何做空它？为何遭到散户毒打？|游戏|gamestop 李永乐：游戏驿站GME股票为何暴涨？美国散户如何血洗华尔街？ - YouTube Gamestop 美国散户逼空机构的“华尔街暴徒”事件是怎么一回事儿？ - 知乎 爆仓、平仓 爆仓：期货市场 or 有融资情况下的股市，当市场行情发生较大变化时，如果投资者保证金账户中资金的绝大部分都被交易保证金占用，而且交易方向又与市场走势相反时，由于保证金交易的杠杆效应，就很容易出现爆仓。//@ref : 股市里的“爆仓”是什么意思？_股票 平仓: 可分为对冲平仓和强制平仓。 对冲平仓是期货投入企业在同一期货交易所内通过买入卖出相同交割月份的期货合约，用以了结先前卖出或买入的期货合约。 强制平仓是指仓位持有者以外的第三人(期货交易所或期货经纪企业)强行了结仓位持有者的仓位，又称被斩仓或被砍仓。 在期货交易中发生强行平仓的原因较多，譬如客户未及时追加交易保证金、违反交易头寸限制等违规行为、政策或交易规则临时发生变化等。而在规范的期货市场上，最为常见的当属因客户交易保证金不足而发生的强行平仓。具体而言，是指在客户持仓合约所需的交易保证金不足，而其又未能按照期货企业的通知及时追加相应保证金或者主动减仓，且市场行情仍朝持仓不利的方向进展时，期货企业为避免损失扩大而强行平掉客户部分或者全部仓位，将所得资金填补保证金缺口的行为。 PB、PE、ROE=&gt; F42.公司和行业的基本面指标","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"入门101","slug":"入门101","permalink":"https://beefyheisenberg.github.io/tags/入门101/"},{"name":"股市","slug":"股市","permalink":"https://beefyheisenberg.github.io/tags/股市/"}]},{"title":"F12.基金101","slug":"52.Financing/F12.基金101","date":"2024-01-24T01:27:53.255Z","updated":"2024-01-24T01:27:53.256Z","comments":true,"path":"52.Financing/F12.基金101/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F12.基金101/","excerpt":"@tag: #入门101 #基金 基金分类 @ref: 再论科学的基金分类 主动基金/被动基金","text":"@tag: #入门101 #基金 基金分类 @ref: 再论科学的基金分类 主动基金/被动基金 主动型基金: 基金经理通过自身分析（包括技术分析和基本面分析）来选股和择时以取得市场超额收益的一类基金 被动型基金（指数基金）: 被动的跟踪指数，复制指数的涨跌。 场内基金/场外基金 什么是 场内基金？场内就是股票市场，也就是通常说的二级市场，场内基金就是通过证券账号购买的二级市场基金，它没有申购赎回费，只有券商的佣金费，一般现在都在万1.5到万5之间。场内基金是在证券交易所内买卖的基金，所以需要有股票账户才能买卖； 什么是 场外基金？场外基金就是指在银行、基金公司或者天天基金网、蚂蚁财富等第三方平台上购买基金，有申购/赎回费。 场内/场外基金对比: 分红方式不同。场外基金分红有现金分红和红利再投资两种方式。场内基金的分红方式只有现金分红，不能红利再投资。 交易费用： 参考 =&gt; [[#购买基金的费用]] 现在的券商佣金公开就是万分之三（3‱）的佣金，很多已经低至万分之一（1‱），ETF一买一卖，也就是万分之二（2‱）的费用。 也就是说，你买进￥1W的ETF，再卖出，总的费用也就￥2 // 上面提到的万一佣金: @ref: 万一手续费的券商有哪些？看到有些大V在推万一的券商，到底可靠不？ - 知乎 而场外ETF联接基金定投申购费是1.2%，通常打一折，就是0.12%，也就是万分之十二（12‱）。 同样的￥1W买成ETF联接基金，光申购费就要￥12 场内ETF的买入卖出一共也就 2‱ 的费用，而场外的ETF联接基金单是买入就要 12‱，赎回还要等两年后才能免赎回费，期间赎回的份额，持有不足7天，赎回费要1.5%，￥1W就要￥150，7天以上一年以内的持有期，要0.5%的赎回费（￥50），一年以上两年以内要0.25%（￥25）。 便利程度： 场外ETF联接基金，由于定投起来操作傻瓜化，申购时间24小时无休，也比较受投资者的欢迎。 场内ETF对交易时间有要求，比如只能是在交易日的盘中进行交易，上午下午各两小时。其他时间都是休市，无法交易。 场内基金的投资特点是以份额定金额，而场外是以金额定份额。场内基金一般不提供定投。 ETF &amp; LOF关于ETF基金, ETF又称“交易型开放式指数证券投资基金”(Exchange Traded Fund的缩写)，简称“交易型开放式指数基金”，又称“交易所交易基金”。ETF的一个特点是’跟踪指数’, 可以是: 宽指 / 行业指数(消费,能源,医药,金融) / 主题指数(人工智能,5G,元宇宙) / 策略指数(成长型,价值型) @link F32.ETF产品索引zz LOF基金，英文全称是“Listed Open-Ended Fund”,汉语称为“上市型开放式基金”英语缩写为LOF。也就是上市型开放式基金发行结束后,投资者既可以在指定网点申购与赎回基金份额,也可以在交易所买卖该基金。 上市开放式基金本质上仍是开放式基金，基金份额总额不固定，基金份额可以在基金合同约定的时间和场所申购、赎回。 上市开放式基金获准在证交所上市交易后，投资者既可以选择在银行等代销机构按当日收市的基金份额净值申购、赎回基金份额，也可以选择在证交所各会员证券营业部按撮合成交价买卖基金份额。基金在银行等代销机构的申购、赎回操作程序与普通开放式基金相同。上市开放式基金在证交所的交易方式和程序则与封闭式基金基本一致。 ➤ ETF基金 vs LOF基金: ETF通常是被动指数基金，但也有主动ETF，比如木头姐的 ARK Innovation ETF（ARKK.US），LOF可能是被动指数基金，也可能是主动LOF； 都可以在场内/外购买: ETF可以在场内(股票市场)和场外(银行/券商/三方销售)购买，场内的叫ETF基金, 场外的叫ETF连接基金, 在场外购买连接基金类似从代购手里购买； LOF同上同时可以在场内/场外购买, 且在场外购买LOF不需要”代购”, 所以 LOF在购买场所上比ETF更方便 ‘ETF基金’ 和 ‘ETF连接基金’的比较: 场内交易的是’ETF基金’, 需要有’证券账户’才可以交易, 一般场内的没有定投功能 场外交易的是’ETF连接基金’, 需要在银行/券商/三方销售开’基金账户’购买, 一般提供定投功能 封闭基金 vs 开放基金 开放式基金 封闭式基金 封闭式基金(Closed-end Funds),是指基金发行总额和发行期在设立时已确定，在发行完毕后的规定期限内发行总额固定不变的证券投资基金。封闭式基金的典型特征之一就是有一定的封闭期限，在这个期限内，虽然不能申购赎回，但是由于封闭式基金可以像普通上市公司的股票一样在证券交易市场挂牌交易，你便可以通过二级市场买卖封闭式基金 在封闭期内，就可以避免散户投资者陷入追涨杀跌的困境，避免由于二级市场的波动，而影响散户投资者的投资信心和策略。 分级基金分级基金指事先约定基金份额的风险收益分配，将母基金份额分为预期风险收益不同的两类子份额，其中，分级基金基础份额也称为“母基金份额”，预期风险收益较低的子份额称为“A份额”或“稳健份额”，预期风险收益较高的子份额称为“B份额”或“进取份额”。 A份额获取约定的收益率，最常见的如：银行一年期定存收益率+ 3%； B份额具有杠杆属性，初始杠杆为2倍。当市场走强时，B份额投资者可以获取高于母基金指数的涨幅。B份额的净值杠杆等于分级基金总资产净值除以B份额资产净值； 分级基金中三类基金份额的净值关系如下：母基金净值= A份额参考净值× A份额所占比例+ B份额参考净值× B份额所占比例。 如何选基@ref: 三步选基：一种简单、方便、有效的基金选择方法 - 雪球 史上最便捷“4433”选基法了解一下？ - 知乎 如何选择一支好基金 05 | 掌握了这 9 个数学概念，选好基金不再难 - 少数派 ➤ 根据收益成绩选基金: 第一步：选择长期业绩优秀的基金 从十年业绩排行榜中找出所有十年年化回报超过20%的基金 从五年业绩排行榜中找出所有五年年化回报超过25%的基金 第二步：匹配长期业绩优秀的基金经理 从十年年化回报超过20%的基金中，筛选出现任基金经理任职天数超过6年的基金 从五年年化回报超过25%的基金中，筛选出现任基金经理任职天数超过3年的基金 第三步、建立备选优秀基金池 排行榜业绩期限和任职天数匹配度一致的基金 选择业绩期限内回报最好的（各）三只基金 选择现任基金经理任职回报最高的基金 选择行业基金 选择最大回撤小的基金 优中选优基金：本节前面5种选择方案中入选3次以上的基金 更简单的4333业绩选基方法：业绩在最近2、3、5年前1/4，最近1年前1/4，最近6个月前1/3，最近3个月前1/3的基金。问题：短期业绩高也会拉高长期业绩，所以还要结合基金经理管理时间。 ➤ 指数基金 &amp; 主动基金选择指标： 基金公司: 晨星5基金最多的公司 基金规模: 2亿以上的(一般建议规模在10~100亿), 绝对不要选择5000万以下或者超过100亿 晨星评级: 排除差的, 3星or以下不考虑 // 同类基金中前10%是五星，前10%~32.5%是四星 整个周期历史业绩, 贯穿牛市和熊市 持有人结构: 机构/内部/个人 基金经理本人也持有自己管理的基金，对于基金而言是绝对的加分项 管理人从业人员，指的是基金公司中的工作人员 机构投资者的占比也值得考察 基金购买费用: 管理/运作/托管费 基金指标: 大盘和行业ETF不用过多考虑夏普率、最大回撤等等，看PE、ROE即可 最大回撤率: 标准差: 用来衡量过去一段时间内基金的波动大小。数字越小，则基金的波动就越小，收益曲线就越平稳 夏普比率: 高于1,越高越好(2的很少) // 夏普比率 = (基金报酬率– 无风险利率)/标准差 R平方 阿尔法系数, 贝塔系数 https://sspai.com/post/66816 从十年赌约看指数基金 2007年12月的一天，一个叫Protege Partners的对冲基金给巴菲特打来电话，他们提出了一个有趣的想法：一个十年的赌约。巴菲特坚信战胜指数是一个几乎不可能的任务，而Protege partners认为专业的对冲基金能够战胜市场。于是他们在美国的Long Bet网站上定下来十年赌约，巴菲特选择标普500指数，Protege Parterns选择五家对冲基金的基金（FOF）。赌注100万美元。 市场有效假说理论认为，在法律健全、功能良好、透明度高、充分竞争的股票市场，一切有价值的信息已经及时、准确、充分地反映在股价走势里，其中包括企业当前和未来的价值，除非存在市场操纵，否则投资者不可能通过分析以往价格获得高于市场平均水平的超额收益。 结论：如果市场有效，倾向于选指数基金，获取市场平均收益（β收益）且费率低；如果市场无效，也可以选主动基金，因为它可以带来超额收益（α收益）。 买入策略（定投）1）慧定投: 支付宝等等app使用的智能定投模式，动态计算下次投多少金额 (1)均线模式, 参考500日内的均线计算出扣款率(60%~210%), 实际定投价格=基础定投金额x扣款率 ; 银河创新成长: 参考创业板指, 500日均线; 中欧医疗健康: 参考创业板指, 500日均线; 中证红利ETF: 参考中证500, 180日均线; 汇添富消费: 参考创业板指, 500日均线; (2)估值模式: PE百分位 华宝券商ETF: 按中证券商指数的PE百分位 易方达上证50增强: 指数不明, PE百分位 2）基于均线：当价格低于均线的时候多买一点，当价格高于均线的时候少买一点。 3）基于估值： PE的倒数 = E/P = 盈利收益率 每月定投金额 = $$ 首次低估时的定投金额 * (当月EP/首次定投时EP)^n $$ 其中 n是放大器， 可以取1、2 缺点： 比如说2008年金融危机时，美股标普500指数中很多公司的盈利大幅下滑。但是标500指数因为公司盈利下滑，导致市盈率反而被动提升到了八九十倍。这就是短期原因导致的市盈率失效 比较 ETF网格交易策略, 相同点是股价越高买的越少,这种方法的不便之处: 用PE计算系数是有些麻烦的(每月定投的时候算一次),上面还是每月固定时间的定投, ETF网格则不固定间隔, 一旦股价碰到网格即触发, 然后这两个方法的上下限选择不同: 网格是选一高一低两个价格作为标的, 这里的定投是以PE高低为标的 关于 盈利收益率：指数投资进阶利器——盈利收益率＆博格公式 止盈策略 估值止盈： 如果是一个指数基金，可以用PE百分位估值 或者通过股债收益差/格雷厄姆指数/证券化率..等等判断整个大盘的状态： F30d.股市择时指标 回撤止盈法：就是比如你现在收益率40%，但是不知道卖不卖。利用回撤止盈法，这时就可以随便躺着等回调。设置一个比如回调10%时候止盈。 外围情绪止盈法 技术指标止盈法：量价背离、MACD顶背离、MACD死叉、布林带触碰上轨压力位、长上影线、高位破位大阴线、向上跳空高开等等的适合中短线 F41a.K线和技术分析 @ref：如果做基金定投的话，什么时候应该卖出呢？ - TopView 的回答 - 知乎 主动基金的风格@ref: 晨星投资风格箱 晨星投资风格箱把影响基金业绩表现的两项因素单列出来：基金所投资股票的规模和风格。晨星以基金持有的股票市值为基础，把基金投资股票的规模风格定义为大盘、中盘和小盘；以基金持有的股票价值-成长特性为基础，把基金投资股票的价值-成长风格定义为价值型、平衡型和成长型。 @ref: 5种“基金风格”，哪个最适合A股？ - 雪球 先从股票的风格说起：从“成长-价值”、“小盘-大盘”两个维度衡量，构成一个四宫格，四种不同风格的个股 市场风格的形成：牛市时，资金对某个赛道看好而开始抱团，但熊市时往往容易分歧 基金的风格：根据重仓股的风格构成基金风格，晨星用的是九宫格“晨星风格箱” 价值风格：通常用企业未来现金流的折现值来估算。因此，能比较容易和比较准确估算出来内在价值的企业，通常商业模式都比较简单易懂，盈利比较稳定，赚多赚少都在可预计的范围内，几乎没有大爆发的可能。价值风格的基金持仓以低估值的股票为主，强调安全边际。持有的行业通常有2种（周期股: 化工、煤炭、钢铁）和（传统行业：银行、地产、基建、轻工业、纺织业）。价值风格基金经理，基本不做宏观经济和行情走势的判断，不在意行业景气度；更看重股价是否足够便宜，企业是否具有竞争力。更看重安全边际和确定性 成长风格：成长股一定是处于未成熟的阶段，行业有着巨大的成长空间。成长风格基金经理极度看重企业和行业“未来发展空间”和“业绩增速”，其次看企业在同业中的竞争力。他们对估值的容忍度较高，宁愿买贵，也不愿意错过成长爆发期；他们不太控制回撤和波动，更专注于挖掘导入期和成长期的行业和个股。 价值成长风格：“价值成长风格”的投资者更看重企业的基本面，致力于投资他们所认为的真正的好公司（有护城河、商业模式好、有现金流等等）。“价值成长风格”基金经理更加看重企业的“盈利能力”和“现金流”的持续性。重视ROE、自由现金流这2个财务指标，持仓以垄断性强、品牌力强的行业龙头为主。“价值成长风格”又叫做“GARP”，即：Growth at reasonable price，用合理的价格买入有成长性的好公司 （巴菲特） 均衡风格：均衡风格一般主要是指“行业的分散均衡”，而极致一点的均衡风格基金，还会做到风格（成长、价值），股票市值（大盘、小盘）的均衡。均衡风格基金经理，非常在意“风险控制”，因此，他们基金的最大回撤&amp;波动率相对更低。基金业绩表现特征为：中短期的业绩不是最突出的，但是长期来看业绩往往很不错。因此均衡风格基金持有体验相对较好，比较适合普通投资者做底仓基金。 趋势风格：行业趋势投资者擅长根据宏观环境，政策、市场变化、行业景气度、行业周期、市场情绪等变化，优选他们认为的“最强”行业。他们的持仓不限行业，不限风格，重在选择“当前阶段，业绩增速最快”的行业和企业，只看该行业有没有政策支撑或经济逻辑支撑。 ▷ 成长、价值风格的综合指数： 国证价值（399371）：在国证1000指数样本股中，选取每股收益与价格比率、每股经营现金流与价格比率、股息收益率、每股净资产与价格比率综合排名前332只。 国证成长（399370）：在国证1000指数样本股中，选取主营业务收入增长率、净利润增长率和净资产收益率综合排名前332只。 上证50：偏价值 创业板50：偏成长 注：国证1000指数由A股市场中市值大、流动性好的1000只股票构成，反映A股市场大中盘股票的价格变动趋势。 基金的费用@ref: 理财省钱：基金费用是怎么算的 - 知乎 购买基金的费用构成: Example: 假定小明计划今年投入10万元配置股票基金，持仓时间为一年，到期赎回。下面分别是基金三方销售机构推荐的A基金产品和某银行推荐的B基金产品，两只产品为同一类型基金产品。 基金的收益 &amp; 分红如何计算基金成立以来的收益率 =（现在的净值 - 成立时净值）/1×100% ➤ 收益计算：假设我在10月19日下午3：00前用1万元买入农银新能源主题基金，当天单位净值是2.1048，申购费率是0.15%；在11月2日下午三点前赎回农银新能源主题基金，当天单位净值为2.198，赎回费率为0.75%。 申购手续费＝10000.00×0.15％＝15 (元) 申购份额＝(10000.00－15)÷2.1048＝4743.919(份) 赎回总额＝4743.919×2.198＝10427.13(元) 赎回手续费＝10427.13×0.75%＝78.2(元) 赎回净额＝10427.13－78.2＝10348.93(元) 净收益＝10348.93－10000.00＝348.93(元) 所以，在我投资的11天里头，我一共赚到了348.93元。 @ref: 基金的收益是怎么计算的？ - 知乎 量化交易入门指南 - 力扣（LeetCode） ➤ 基金分红： 主动型基金的分红主要来自投资盈利，基金投资股票实现盈利因此产生分红，所以熊市中只能呵呵呵了。 指数型基金，不管指数涨跌，只要成分股有分红，指数基金就能分到钱。而这些钱是否直接当做基金分红给到投资者，由基金管理人安排。由此看，指数基金的分红主要来自成分股分红，不管牛市还是熊市，只要成分股有分红指数基金就有分红，分红的前提是“基金份额净值增长率超过同期指数1%” 基金分红的两种方式：1、现金分红；2、红利再投资。 现金分红：基金份额不会有变化，但是基金的净值会降低。 红利再投资：把分红的钱，转换为相应的基金份额，基金份额增加，基金的净值同样会降低 参考： 基金分红一文搞懂 股票分红还要除权，那分红还有意义吗？ 欢迎关注公众号：大马哈投资 - 雪球","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"入门101","slug":"入门101","permalink":"https://beefyheisenberg.github.io/tags/入门101/"},{"name":"基金","slug":"基金","permalink":"https://beefyheisenberg.github.io/tags/基金/"}]},{"title":"F11.理财101","slug":"52.Financing/F11.理财101","date":"2024-01-24T01:27:53.251Z","updated":"2024-01-24T01:27:53.251Z","comments":true,"path":"52.Financing/F11.理财101/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F11.理财101/","excerpt":"@tag: #入门101 资产配置方法➤ 目前我在用的资产配置方式： 先说存量的资金，主要按3部分配置（1-3）： 用于应急的钱：活期（货币基金-余额宝这类T+0产品），不按家庭资产的百分比计算，取值为大约2-3个月生活费开销，或 4-5w（取高的那一个）。 用于未来消费的钱：这部分是未来会花掉的钱(车房首付/旅游/教育/全家保费)，也大概知道什么时候会花掉这笔钱；主要是固收类、稳健类，可以选风险等级 R2-R3的银行理财，ps不要选久期太长的，除非你精确知道什么时候要用到这部分钱； 用于增值投资的钱：也就是我们的“金鹅”，生钱的钱，主要是基金/股票 根据当前风险做股/债的平衡（我用万得全A指数的股债收益差，例如 股债收益差百分位到70%，意味着需要调整偏股:偏债=7:3） 偏股基金部分，遵循核心:卫星=7:3的比例（也就是混合类基金占70%，行业基金占30%。对于占3成行业基金，如果你也不知道现在什么行业是赛道，还是每个行业平均分配） 核心（混合基金）部分，主要主动混合基金，也不都买一个基，按风格做平衡（成长风格、价值风格，大盘风格、中小盘风格） 此外我在场内账户有一部分资金做行业ETF轮动（实验性质，比例不大）@link: F52c.轮动策略 上面是存量部分，增量部分，也即每月的收入，用 x + ½ +½的方式分配： 其中 x = 生活必要支出，这部分尽量压缩，只保留真正必要的支出，对于弹性的支出（请客吃饭等…）从应急的钱里扣除，下次发工资的时候再补上； 扣除必要支出后，剩下的1/2作为“未来要花掉的钱”（2提到的），另外1/2作为“增值的钱”（3提到的）用于基金定投（偏股型和偏债型基金的比例，用“股债收益差”的方式做平衡）","text":"@tag: #入门101 资产配置方法➤ 目前我在用的资产配置方式： 先说存量的资金，主要按3部分配置（1-3）： 用于应急的钱：活期（货币基金-余额宝这类T+0产品），不按家庭资产的百分比计算，取值为大约2-3个月生活费开销，或 4-5w（取高的那一个）。 用于未来消费的钱：这部分是未来会花掉的钱(车房首付/旅游/教育/全家保费)，也大概知道什么时候会花掉这笔钱；主要是固收类、稳健类，可以选风险等级 R2-R3的银行理财，ps不要选久期太长的，除非你精确知道什么时候要用到这部分钱； 用于增值投资的钱：也就是我们的“金鹅”，生钱的钱，主要是基金/股票 根据当前风险做股/债的平衡（我用万得全A指数的股债收益差，例如 股债收益差百分位到70%，意味着需要调整偏股:偏债=7:3） 偏股基金部分，遵循核心:卫星=7:3的比例（也就是混合类基金占70%，行业基金占30%。对于占3成行业基金，如果你也不知道现在什么行业是赛道，还是每个行业平均分配） 核心（混合基金）部分，主要主动混合基金，也不都买一个基，按风格做平衡（成长风格、价值风格，大盘风格、中小盘风格） 此外我在场内账户有一部分资金做行业ETF轮动（实验性质，比例不大）@link: F52c.轮动策略 上面是存量部分，增量部分，也即每月的收入，用 x + ½ +½的方式分配： 其中 x = 生活必要支出，这部分尽量压缩，只保留真正必要的支出，对于弹性的支出（请客吃饭等…）从应急的钱里扣除，下次发工资的时候再补上； 扣除必要支出后，剩下的1/2作为“未来要花掉的钱”（2提到的），另外1/2作为“增值的钱”（3提到的）用于基金定投（偏股型和偏债型基金的比例，用“股债收益差”的方式做平衡） @ref: 积累财务自由的第一桶金 - 知乎 ➤ 上面提到的（3）用于增值的部分，是做了股/债比例平衡的，关于股债比例如何调整可参考的几种方法： 根据市场估值（PE百分位、股债收益差、格雷厄姆指数.. ）： =&gt; F30d.股市择时指标 100-年龄法：例如当期30岁，100-30=70，那么风险收益类（偏股基金）占70% 偏股基金的“核心+卫星”分配：//@ref: 蚂蚁金选建议的配置 核心（比例70-80%）包括成长、价值、均衡等多元布局基金 卫星（20-30%）包括医药、消费、制造、科技等赛道行业基金 股债再平衡：股债动态再平衡增厚长期收益是真的吗？ - 雪球 从凯利公式看仓位配置，为什么不要一次梭哈： =&gt; F59.凯利公式 ➤ 根据更长的全球经济周期，配置不同时期的全球资产，包括：A股、美股、美债、黄金、发达国家股票、新兴市场股票、大宗商品等 @ref: 潮水退去，谨慎裸泳 - 2022年全球大类资产展望 美国滞胀预期与股债双杀的演变 - 2022年Q3 关于「普林格周期」、「美林时钟」 =&gt; F21.经济的周期性 关于“标普家庭资产配置”： 请问《标准普尔家庭资产象限图》出处在哪里？ - 知乎 ： 结论：大概率是国内保险公司搞出来的概念😆 要把 20%的资产用于买保险 emmm….另外“短期消费”的钱也不合理，这部分应该按金额而不是按比例，“生钱的钱”这部分占比太低并且是静态的。以及里面提到的%占比也没说是增量or 存量（不考虑增量/存量，这是个大问题） 附图-标普家庭资产配置： 可投资的金融产品参考=&gt; F31.可投资的金融产品Index 银行理财风险等级(R1~R5) R1型产品：代表产品余额宝。同风险等级的产品还有银行的 现金管理产品、储蓄 和 国债等。 R2型产品：代表产品是 多数的银行理财产品 和 部分债券基金。权益类投资（股票等）的比重不超过20%。 R3型产品：代表产品是 少部分银行理财产品 和 平衡型基金。这类产品中权益类投资的比重更高，在50%左右。所以亏损的概率更大，历史收益率也更高。 R4和R5型产品：代表产品是：偏股混合型基金（R4）、灵活配置型基金（R4）和股票型基金（R5），这类产品的权益类投资的比重分别不低于60%和80%，可能在较短的时间内出现较大的亏损。 七日年化&amp;万份收益理财产品的指标: 七日年化/年利率/年化收益率/万份收益 ➤「七日年化收益率」:如果按照最近七天的收益来算，存一年的话得到的收益指将货币基金过去7天所获的总收益进行年化计算之后得出的数据。具体的操作方法是将7天的总收益率除以7，得到过去7天的平均日收益率，再乘上365天，得到七日年化收益率。 90 天的理财产品, 银行称为年化收益4%, 买10w, 问所得利息?实际只有1%的收益率 银行所公布的利率，都是年化利率, =一年的利息/本金, 月利率=年利率/12 半年期的年化利率是4%，但因为只存了半年，那么半年期的收益率就是2%，或者称半年化利率是2%，不过一般不这么叫，还是称年化收益率是4%，因为银行的理财产品有不同的期限，如果只标出收益率的话，虽说计算起来比较方便，但不利于进行整体统一对比。 ➤ 每万份收益:每一万份货币基金每天产生多少收益，即货币基金持有人每天能够真实得到的收益。举个例子，假如某只货币基金的每万份收益是1元，就是说投资者持有1万份该货币基金，每天能够获取1元的收益，按单日年化其实就是3.65%; 科学刷(信用)卡➤ 招商信用卡如何积分: @ref: https://zhuanlan.zhihu.com/p/409977265 线下POS刷卡，按每20元1分给永久积分（超市、加油、医院等特殊类型商户或商户被招行拉黑的情况除外）； 支付宝，招行和支付宝有着非常深厚的PY关系，因此在支付宝用招行付款无脑有分，而且是永久积分，哪怕你在医院付款都有分 微信，默认情况下微信支付招行是一分不给的，只有每月领取积分资格后才给区区500！！！非永久积分！ 领取路径：掌上生活APP-右上角小招猫图像-我的客服，输入“微信支付领积分” 云闪付二维码被扫，包括云闪付APP、各个银行APP的付款码都属于这个范畴，注意是被扫，也就是你出示付款码，店员扫你。你主动扫店家的云闪付二维码是没分的 ➤ 云闪付活动 云闪付大招_什么值得买 云闪付可以把信用卡&amp;移动积分兑换成红包 ➤ 微信 &amp; 支付宝 哪些信用卡有积分: @ref: 收藏！微信、支付宝刷信用卡，快速撸积分的方法 - 知乎 微信：有积分的信用卡格外少，只有中信的网购类联名信用卡、浦发信用卡以及兴业Pass卡才有积分。招行、农行等银行，用财付通支付是没有积分的。 ➤ POS机刷卡手续费: 由 卡组织、发卡行、收单机构、商户合作完成支付的过程称为「四方模式」, 每一方都会收手续费. 收单机构主要为商户提供安装 POS 机、清算等服务， 银行卡组织，比如银联、VISA、MasterCard ，它们本身通常不发卡，主要是为成员银行提供信息交换、资金清算等服务。 POS机刷卡手续费由发卡行服务费、银联网络服务费、收单服务费三部分组成，对于标准类商户而言，信用卡刷卡费率 = 发卡行0.45%+银联清算费率0.065%+收单服务费(市场调节价，一般不低于0.085%) &lt;= 0.6%。 @ref: 最新pos机费率详解 - 知乎 ➤ 信用卡分期: 信用卡账单分期的真实年化利率 - 知乎 假设1.2w, 分12期, 月利率 0.66%, 告诉你信用卡分期有多坑 - 知乎 信用卡利息原来是这么计算的！信用卡攻略信用卡攻略 - 融360","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"入门101","slug":"入门101","permalink":"https://beefyheisenberg.github.io/tags/入门101/"},{"name":"理财","slug":"理财","permalink":"https://beefyheisenberg.github.io/tags/理财/"},{"name":"资产配置","slug":"资产配置","permalink":"https://beefyheisenberg.github.io/tags/资产配置/"}]},{"title":"F10.经济学101","slug":"52.Financing/F10.经济学101","date":"2024-01-24T01:27:53.246Z","updated":"2024-01-24T01:27:53.246Z","comments":true,"path":"52.Financing/F10.经济学101/","link":"","permalink":"https://beefyheisenberg.github.io/52.Financing/F10.经济学101/","excerpt":"@todo: 宏观经济： IS-LM模型_百度百科：IS曲线的移动、LM曲线的移动 哈耶克vs凯恩斯：https://zhuanlan.zhihu.com/p/94305265 哈耶克与凯恩斯究竟谁对谁错？ - 知乎 微观经济： 微观经济学相关主题列表 - 维基百科，自由的百科全书 边际成本是什么？ - 知乎 边际成本递减 - MBA智库百科 宏观经济学（Macro-economics）是以国民经济总过程的活动为研究对象，着重考察和说明国民收入、就业水平、价格水平等经济总量是如何决定的、如何波动的，故又被称为总量分析或总量经济学。宏观经济学以整个国民经济为考察对象，研究经济中各有关总量的决定及其变动，以解决失业、通货膨胀、经济波动、国际收支等问题，实现长期稳定的发展。// @link: F20.宏观经济框架 微观经济学（Micro-economics）又称个体经济学，小经济学，是宏观经济学的对称。微观经济学主要以单个经济单位(单个的生产者、单个的消费者，例如消费者或企业，以及单个市场的经济活动)作为研究对象。微观经济学侧重于研究单个的消费者和企业行为，又分为消费者需求理论、生产理论（也称之为企业理论），分析单个消费者如何将有限的收入分配在各种商品的消费上以获得最大的满足；单个生产者如何将有限的资源分配在各种商品的生产上以取得最大的利润。同时，微观经济学还分析单个生产者的产量、成本、使用的生产要素数量和利润如何确定；生产要素供应者的收入如何决定；单个商品的效用、供给量、需求量和价格如何确定等等。微观经济学又分为贸易、工业组织和市场结构、劳动力经济学、公共财政和福利经济学。","text":"@todo: 宏观经济： IS-LM模型_百度百科：IS曲线的移动、LM曲线的移动 哈耶克vs凯恩斯：https://zhuanlan.zhihu.com/p/94305265 哈耶克与凯恩斯究竟谁对谁错？ - 知乎 微观经济： 微观经济学相关主题列表 - 维基百科，自由的百科全书 边际成本是什么？ - 知乎 边际成本递减 - MBA智库百科 宏观经济学（Macro-economics）是以国民经济总过程的活动为研究对象，着重考察和说明国民收入、就业水平、价格水平等经济总量是如何决定的、如何波动的，故又被称为总量分析或总量经济学。宏观经济学以整个国民经济为考察对象，研究经济中各有关总量的决定及其变动，以解决失业、通货膨胀、经济波动、国际收支等问题，实现长期稳定的发展。// @link: F20.宏观经济框架 微观经济学（Micro-economics）又称个体经济学，小经济学，是宏观经济学的对称。微观经济学主要以单个经济单位(单个的生产者、单个的消费者，例如消费者或企业，以及单个市场的经济活动)作为研究对象。微观经济学侧重于研究单个的消费者和企业行为，又分为消费者需求理论、生产理论（也称之为企业理论），分析单个消费者如何将有限的收入分配在各种商品的消费上以获得最大的满足；单个生产者如何将有限的资源分配在各种商品的生产上以取得最大的利润。同时，微观经济学还分析单个生产者的产量、成本、使用的生产要素数量和利润如何确定；生产要素供应者的收入如何决定；单个商品的效用、供给量、需求量和价格如何确定等等。微观经济学又分为贸易、工业组织和市场结构、劳动力经济学、公共财政和福利经济学。 宏观部分IS-LM模型是由英国现代著名的经济学家约翰·希克斯（John Richard Hicks）和美国凯恩斯学派的创始人汉森（Alvin Hansen），在凯恩斯宏观经济理论基础上概括出的一个经济分析模式，即”希克斯-汉森模型”。 ➤ 模型简介： IS-LM模型描述 产品市场和 货币市场之间相互联系的理论结构。 在产品市场上，国民收入决定于 消费C、投资I、政府支出G、净出口X-M 加合起来的 总支出 或者说 总需求水平，而总需求（尤其是投资需求）要受到利率r影响，利率则由货币市场供求情况决定，就是说，货币市场要影响产品市场； 另一方面，产品市场上所决定的国民收入又会影响货币需求，从而影响利率，这又是产品市场对货币市场的影响。 可见在IS-LM模型中，产品市场和货币市场是相互联系、相互作用的。 ▷ IS模型：Investment-Saving（投资-储蓄），IS模型是描述 产品市场 均衡的模型 $$ I（r） = S（Y） $$ I为投资，S为储蓄； r为利率，且有 I=I（r），投资与利率相关； Y为国民收入，Y（国民收入）=C（消费）+I（投资）+G（政府支出），且有 C=C（Y），消费水平随收入正向变化； ▷ LM模型：Liquidity preference-Money Supply（流动性偏好货币供给），LM模型是描述 货币市场 均衡的模型 $$ M/P = L1（Y） + L2（r） $$ M为名义货币量，P为物价水平，M/P为实际货币量； L是货币需求，Y为总产出，r为利率； 通常将M/P视为由中央银行确定的定值，货币量L1和国民收入Y和呈正向关系，而货币量L2和利率r呈反向关系，从而得出“国民收入Y” 与 “利率r”的关系曲线（是一条斜率为正的直线），斜率大小由实际货币量对利率和收入分别的敏感度决定，而位置由实际货币量决定。 将IS-LM移至同一图上，二者交点便反应了产品市场和货币市场同时达到均衡时的利率水平和收入水平，对于分析宏观经济问题很有意义。 通胀（inflation）通货膨胀是指一个经济体中各种商品和服务的总价格水平在一段时间内上升的速度。 什么导致通货膨胀？我们可以相对轻松地定义通胀，但什么导致通胀的问题要复杂得多。凯恩斯主义经济学家认为，通胀源于生产成本增加等经济压力，并将政府干预视为解决办法；货币主义经济学家认为，通胀源于货币供应量的扩张，各国央行应保持货币供应量与GDP相一致的稳定增长。 温和通货膨胀：各国央行希望维持高达3%的温和通胀，以帮助刺激经济增长，但如果通胀远远超过这一水平，可能导致恶性通胀或滞胀等残酷局面。 恶性通货膨胀：在经济学上，恶性通货膨胀（hyperinflation）是一种不能控制的通货膨胀，在物价急速上涨的情况下，就使货币很快失去价值。恶性通货膨胀没有一个普遍公认的标准界定。一般界定为每月通货膨胀50%或更多，但很多时候会采取宽松界定，使用的比率会更低。 恶性通货膨胀的共同特征之一是货币供给的大量增加，这是由于政府需要为其巨额预算赤字融资。 预算赤字与通货膨胀之间具有一种双向的互动关系。通过迫使政府为赤字融资而发行钞票，巨额预算赤字可以导致快速的通货膨胀。高通货膨胀反过来又增加了赤字。如果必须以货币手段融资的赤字非常之大，则因此而发生的通货膨胀会发展为恶性通货膨胀。 需求拉动型通货膨胀：又叫超额需求拉动通货膨胀，又称菲利普斯曲线型通货膨胀。是凯恩斯先提出来的，认为总需求超过了总供给，拉开“膨胀性缺口”，造成物价水平普遍持续上涨，即以“过多货币追求过少商品”。引起需求拉动型通货膨胀的实际因素主要有： ①政府财政支出超过财政收入而形成财政赤字，并主要依靠财政透支来弥补； ②国内投资总需求超过国内总储蓄和国外资本流入之和，形成所谓的“投资膨胀”； ③国内消费总需求超过消费品供给和进口消费品之和，形成所谓的“消费膨胀”。 上述三个因素中任何一个发生作用，在其他条件不变时都会导致总需求与总供给的缺口，这种缺口只能通过物价上涨才能弥合，这就引起了通货膨胀。 成本推动通货膨胀又称成本通货膨胀或供给通货膨胀，是指在没有超额需求的情况下由于供给方面成本的提高所引起的一般价格水平持续和显著的上涨。由于成本上升时的原因不同，可以分为三种类型：工资推动、利润推动(寡头提高利润..)、进口和出口推动(进口原材料价格上涨) 输入型通货膨胀：与开放经济有密切的关系,开放的程度越大,发生的概率越大. 输入型通货膨胀的传导途径主要有三个： 国外商品的价格传导途径：当国外出现通货膨胀、价格上涨时，在价格机制的作用下，一方面，由于国外商品的价格上涨，会导致该国对外商品出口的增加，从而增加该国的对外贸易出口需求；另一方面，由于国外商品的价格上涨，又会减少本国居民对国外进口商品的消费，而转为增加对本国商品的消费，由此一增一减，最终引起整个社会总需求的增加。 货币供给途径：当国外存在通货膨胀和价格上涨时，由于国外商品的价格上涨，使得该国的对外贸易将出现大量顺差，而大量贸易顺差的存在，又会使该国的外汇储备大量增加。在固定汇率制下，大量的外汇储备将导致国内货币供给大大增加，从而引起国内利率降低、投资增加，并最终导致「需求拉上型通货膨胀」。 成本传导途径：由于国际市场上石油、原材料等价格上涨，导致国内这些基础产品的输入价格增加，从而引起国内的价格上涨，并最终引发「成本推动型通货膨胀」。 财政性通货膨胀：当巨额财政赤字通过发行国债弥补时,国债利率的提高，会带动社会利率总水平上升。另一方面，国债在金融市场上会部分替代其他金融资产（存款、有价证券），并在总储蓄中产生“挤出效应”，使生产性投资率下降。这时,赤字虽然没有直接引起通货膨胀,但因资金来源减少而引起的产业部门投资减少会影响长期资本积累，从而影响未来生产能力和供给水平。而未来的供给不足仍是引起下一轮通货膨胀的隐患。如果要保持一定的社会投资水平，国债利率便不能过高，而这样国债就可能发不出去；但靠中央银行购进大量国债，扩大货币供应来压低利率，又可能使通货膨胀恶化。由此可能形成恶性循环：赤字扩大──增发国债 ──利率上升和“排挤”社会投资──投资下降或停滞──供给不足──税收和收入减少──赤字进一步扩大。 结构型通货膨胀：结构型通货膨胀指物价上涨是在总需求并不过多的情况下，而对某些部门的产品需求过多造成部分产品的价格上涨现象，如钢铁、猪肉、楼市、食用油等。如果结构性通胀没能有效抑制就会变成成本推动型通胀，进而造成全面通胀。 判断通胀的经济指标：PPI、CPI、进口价格指数 // @link: F23.经济指标和历史数据 放水一定引起通胀吗？ @link: F28.费雪公式 滞胀（stagflation）滞胀（停滞性通货膨胀），指的是通货膨胀居高不下的同时，经济放缓甚至停滞的情况。其影响包括失业率攀升、消费疲弱、成本增加等。 滞胀对各国央行构成了特别严峻的挑战： 中央银行通常加息对抗高通胀，在滞胀时期这样做可能会导致失业率进一步上升。 同时又无法通过降息刺激经济，因为这样做可能导致通胀进一步上升。 美国1970年代大滞胀的来龙去脉 | 民生策略： 当下市场投资者认知中的“滞胀”，似乎总是基于着美林时钟的框架，固化在需求驱动下的“滞胀期”，认为物价的上行最终只是滞后于经济总量的上行而见顶，滞胀期是如此短暂且最终可以走向没有通胀的衰退。我们希望投资者通过1970s的经验认识到，通胀的成因并非只有需求的上升，而滞胀的“梦魇”也可以持续如此之久。 1970s美国走不出的“滞胀”循环：迟钝的货币政策&amp;无效的价格管制和不断加强的通胀预期,原因主要有三点： （1）过剩货币量是导致滞胀的主要原因； （2）价格管制使得价格信号不能正确地反映市场供求，从而导致资源的错误配置，造成供给面的效率损失，进而削弱供给面的活力； （3）宽松的货币政策导致通胀预期上升先于供给冲击，使得高通胀不可避免，食品与能源价格冲击只是在其中扮演了并不重要的角色。 如何走出“滞胀”： 结合沃尔克紧缩的货币政策与对待工会更为严厉的态度，里根政府与美联储合力打破了“工资—通胀”螺旋的恶性循环，在较短的时间内控制住美国公众对通胀的预期，逐步解决滞胀中“胀”的问题。 里根政府的新政（大规模减税、放松政策管制）激发经济活力, 也逐步让经济走出了“滞”。 上世纪80年代初，时任美联储主席保罗·沃尔克通过持续激进加息将美国通胀水平从1980年初的两位数降了下来，但代价是美国经济两年内两次陷入衰退，被称为“沃尔克时刻”。 衰退、通缩、萧条衰退 表现为普遍性的经济活力下降，和随之产生的大量工人失业。严重的经济衰退会被定义为经济 萧条。衰退过程可能会导致多项经济指标同时出现下滑，比如就业、投资和公司盈利，其它伴随现象还包括下跌的物价（通货紧缩）。当然，如果经济处于滞胀（Stagflation）的状态下物价也可能快速上涨。 政府通常会采取扩张性的经济政策应对经济衰退：如增加货币供应量（货币政策）、增加政府支出和减少税收（财政政策）。 通缩 表现为经济衰退过程中导致需求不足、同时货币供应不足导致的物价下跌 // 在有宏观调控的情况下，衰退过程中往往会实行宽松货币政策（放水），并且现代生产国大部分产能都是过剩的，所以很少出现这种情况 微观部分▷ 微观经济学相关主题：https://zh.wikipedia.org/zh-cn/微观经济学相关主题列表 消费者理论：效用（边际效用） 生产者理论：生产可能性边际、成本（机会成本）、利润与利润函数 一般均衡理论：帕累托最优 博弈论：静态博弈、动态博弈、纳什均衡… 边际效应微观经济学里非常重要的概念，边际（margin），在某个模型中，发生变化的那部分就叫作边际。有点像摊烙饼，烙饼变大的过程中，变化的是其边缘部分的扩张（变化一定发生在边际） 在经济学和金融学中，边际成本（Marginal Cost）指的是每一单位新增生产的产品带来到总成本的增量，就是产量变化时发生变化的那部分的成本。一般来说，在传统生产力，大规模生产可以拉低边际成本，使之趋近于原材料成本价。边际收益，就是数量变化时变化部分的收益。 边际成本递减（Diminishing Marginal Costs） 边际成本递减是指随着产量增加，成本将越来越小，例如规模效应，这是几乎每种商品的普遍规律，但应明确，对于一般商品而言，其递减的范围是有限的，即超过一定的限度，生产一单位商品的边际成本将出现上升。 边际成本通常只按变动成本计算。边际成本用以判断增减产量在经济上是否合算。例如，生产某种产品100个单位时，总成本为5000元，单位产品成本为50元。若生产101个时，其总成本5040元，则所增加一个产品的成本为40元，即边际成本为40元。当实际产量未达到一定限度时，边际成本随产量的扩大而递减。 当产量超过一定限度时，边际成本随产量的扩大而递增。因为，当产量超过一定限度时，总固定成本就会递增。由此可见影响边际成本的重要因素就是产量超过一定限度（生产能力）后的不断扩大所导致的总固定费用的阶段性增加。 @ref: https://www.zhihu.com/question/20105864","categories":[{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"}],"tags":[{"name":"入门101","slug":"入门101","permalink":"https://beefyheisenberg.github.io/tags/入门101/"},{"name":"宏观经济","slug":"宏观经济","permalink":"https://beefyheisenberg.github.io/tags/宏观经济/"}]},{"title":"习惯的力量：富兰克林的自我修养","slug":"51.Productivity/习惯的力量：富兰克林的自我修养","date":"2024-01-24T01:27:53.242Z","updated":"2024-01-24T01:27:53.242Z","comments":true,"path":"51.Productivity/习惯的力量：富兰克林的自我修养/","link":"","permalink":"https://beefyheisenberg.github.io/51.Productivity/习惯的力量：富兰克林的自我修养/","excerpt":"从富兰克林到 2021，他们都在工程化自己的习惯 - 少数派 富兰克林的自我修炼方法 - 通约智库 富兰克林的行为准则和习惯培养《本杰明·富兰克林自传》中写到，人的习惯的惰性总是于人不备时乘虚而入，而人们的习性往往强于理智。这是习惯的 2 个特性，既能击败自己又能帮助自己。坏的习惯必须打破，好的习惯必须加以培养。富兰克林的树立目标就是不断增多好的习惯，减少坏的习惯，在更大范围内寻求最佳结果。 为了实现这一目标，他拟定了方法，给自己设定了 13 个戒律，带着道德层面完善自己的心态出发，制定养成习惯的关键性的行为。他认为培养习惯的时候应该循序渐进，看哪一个习惯是哪一个习惯的基石，一个周期培养一次。 一、节制。食不过饱；饮酒不醉。 二、沉默寡言。言必于人于己有益；避免无益的聊天。 三、生活秩序。每一样东西应有一定的安放的地方；每件日常事务当有一定的时间。 四、决心。当做必做；决心要做的事应坚持不懈。 五、俭朴。用钱必须于人或于己有益，换言之，切戒浪费。 六、勤勉。不浪费时间；每时每刻做些有用的事，戒掉一切不必要的行动。 七、诚恳。不欺骗人；思想要纯洁公正；说话也要如此。 八、公正。不做不利于人的事，不要忘记履行对人有益而又是你应尽的义务。 九、中庸适度。避免极端；人若给你应得处罚，你当容忍之。 十、清洁。身体、衣服和住所力求清洁。 十一、镇静。勿因小事或普通的不可避免的事故而惊慌失措。 十二、贞节。除了为了健康或生育后代起见，不常举行房事，切戒房事过度，伤害身体或损害你自己或他人的安宁或名誉。 十三、谦虚。仿效耶稣和苏格拉底。","text":"从富兰克林到 2021，他们都在工程化自己的习惯 - 少数派 富兰克林的自我修炼方法 - 通约智库 富兰克林的行为准则和习惯培养《本杰明·富兰克林自传》中写到，人的习惯的惰性总是于人不备时乘虚而入，而人们的习性往往强于理智。这是习惯的 2 个特性，既能击败自己又能帮助自己。坏的习惯必须打破，好的习惯必须加以培养。富兰克林的树立目标就是不断增多好的习惯，减少坏的习惯，在更大范围内寻求最佳结果。 为了实现这一目标，他拟定了方法，给自己设定了 13 个戒律，带着道德层面完善自己的心态出发，制定养成习惯的关键性的行为。他认为培养习惯的时候应该循序渐进，看哪一个习惯是哪一个习惯的基石，一个周期培养一次。 一、节制。食不过饱；饮酒不醉。 二、沉默寡言。言必于人于己有益；避免无益的聊天。 三、生活秩序。每一样东西应有一定的安放的地方；每件日常事务当有一定的时间。 四、决心。当做必做；决心要做的事应坚持不懈。 五、俭朴。用钱必须于人或于己有益，换言之，切戒浪费。 六、勤勉。不浪费时间；每时每刻做些有用的事，戒掉一切不必要的行动。 七、诚恳。不欺骗人；思想要纯洁公正；说话也要如此。 八、公正。不做不利于人的事，不要忘记履行对人有益而又是你应尽的义务。 九、中庸适度。避免极端；人若给你应得处罚，你当容忍之。 十、清洁。身体、衣服和住所力求清洁。 十一、镇静。勿因小事或普通的不可避免的事故而惊慌失措。 十二、贞节。除了为了健康或生育后代起见，不常举行房事，切戒房事过度，伤害身体或损害你自己或他人的安宁或名誉。 十三、谦虚。仿效耶稣和苏格拉底。 在循序渐进列出习惯的具体方法之后，他又想到毕达哥拉斯《黄金诗篇》里提出的忠告，有必要逐日对自己的行为进行反省，这样才能优化整个系统，就像生物新陈代谢一样能适应环境变化更好的生存下去。于是他想到设计了一个用表格的形式来检查习惯的方法。 每一列是一种塑造美德的习惯，每一行是这个星期的一天。每天检查自己的所作所为，如果违反了哪几项习惯，就在相应的格子中打上小黑点。他决心照此顺序对每一种习惯进行一星期的严密监控。这样，第一周特别注意避免发生任何违反「节制」 的行为，而对另外的只能是一般的关注，只是每天晚上就这一天的错误做上标记。假如第一个星期，能够使标有节制的一行里没有黑点，就认为对这一习惯已经加强，与它相反的陋习已经大为削弱。如果达到这种程度，就将注意力扩展到下面的一项，争取在下一周内两行都没有黑点，直到完成最后一项习惯。顺利的话，每过 13 个星期（一个季度）就可以走完一周期，一年可以循环 4 个周期。 富兰克林的作息表 毕达哥拉斯-金诗被归到毕达哥拉斯名下的著名的《金诗》（或译《黄金韵文》）可能并不是毕达哥拉斯所创作的，正如多数批评家所说的那样，但是，这些诗句包含了毕达哥拉斯哲学的摘要，它以和谐、优美和简洁的形式清楚地阐述了他的主要训诫。如果这些训诫得到实践，那么结果会在人生中导致一种道德和理智上的革新，这会带给人类不可估量的益处。《金诗》已经被广泛编辑和翻译成多种语言。 Golden Verses - Wikipedia 《金诗》中文翻译： https://www.douban.com/group/topic/31694245/?_i=0245217kQHWhAK","categories":[{"name":"51.Productivity","slug":"51-Productivity","permalink":"https://beefyheisenberg.github.io/categories/51-Productivity/"}],"tags":[{"name":"习惯","slug":"习惯","permalink":"https://beefyheisenberg.github.io/tags/习惯/"},{"name":"富兰克林","slug":"富兰克林","permalink":"https://beefyheisenberg.github.io/tags/富兰克林/"},{"name":"毕达哥拉斯","slug":"毕达哥拉斯","permalink":"https://beefyheisenberg.github.io/tags/毕达哥拉斯/"}]},{"title":"可借鉴的资料归类法-图书馆分类系统","slug":"51.Productivity/可借鉴的资料归类法-图书馆分类系统","date":"2024-01-24T01:27:53.238Z","updated":"2024-01-24T01:27:53.238Z","comments":true,"path":"51.Productivity/可借鉴的资料归类法-图书馆分类系统/","link":"","permalink":"https://beefyheisenberg.github.io/51.Productivity/可借鉴的资料归类法-图书馆分类系统/","excerpt":"","text":"@ref: 世界主要图书馆分类系统概况 - 知乎 一、杜威十进制图书分类法(Dewey Decimal Classification) 二、美国国会图书馆图书分类法(Library of Congress Classification)","categories":[{"name":"51.Productivity","slug":"51-Productivity","permalink":"https://beefyheisenberg.github.io/categories/51-Productivity/"}],"tags":[{"name":"生产力","slug":"生产力","permalink":"https://beefyheisenberg.github.io/tags/生产力/"},{"name":"知识管理","slug":"知识管理","permalink":"https://beefyheisenberg.github.io/tags/知识管理/"},{"name":"PKM","slug":"PKM","permalink":"https://beefyheisenberg.github.io/tags/PKM/"},{"name":"笔记","slug":"笔记","permalink":"https://beefyheisenberg.github.io/tags/笔记/"},{"name":"分类法","slug":"分类法","permalink":"https://beefyheisenberg.github.io/tags/分类法/"}]},{"title":"一些有效的学习 & 笔记法","slug":"51.Productivity/一些有效的学习&笔记法","date":"2024-01-24T01:27:53.232Z","updated":"2024-01-24T01:27:53.232Z","comments":true,"path":"51.Productivity/一些有效的学习&笔记法/","link":"","permalink":"https://beefyheisenberg.github.io/51.Productivity/一些有效的学习&笔记法/","excerpt":"SQ3RSQ3R方法是一种提升研习能力的方法，为美国俄亥俄州州立大学心理学教授罗宾逊（F. P. Robinson）所设计的一套有效读书方法，于1946年在他的著作《Effective Study》有所提及，主要用于精读课文。 “SQ3R”来自以下五个英语词语的字首，即：综览（Survey）、发问（Question）、阅读（Read）、背诵（Recite）、复习（Review）。 综览（Survey，为时约1分钟）：在详读文章之前，先概览文章一番：留意文章内的标题及结构，以控制阅读的目的、方向和注意力。细阅文章的引言、总结及参考，但不要阅读文章的内容，试试能否从所得的资料略知文章的主题。目标为掌握文章主题的3个至6个要点。 发问（Question，为时不超过半分钟）：主要利用每个章节的标题和 六何法来对要研习的题目自行拟定问题。 阅读（Read，不设时限，但以个人步伐）：指专心注意于找出发问问题的答案。阅读者需要逐一章节细阅，而不是一次过细阅整个篇章。阅读时应用主动阅读技巧，尝试在内文中找寻先前拟定问题的答案。 “背诵”（Recite）：能够在阅读时利用各种阅读技巧以帮助记忆，例如：做重点画线、口头复诵或笔记摘要。 复习（Review）：回忆所记忆的重点。 六何法，又称6W分析法或5W1H，即何人（Who）、何时（When)、何事（What）、何地（Where）、为何（Why）及如何（How）。 由这六个疑问词所组成的问句，都不是是非题，而是需要一或多个事实佐证的应用题。 有时“如何”不计在内，因为“如何”可以被“何事”、“何时”和“何地”描述，变成“五何法”。即何人（Who）、何事（What）、何时（When）、何地（Where）及为何（Why）。","text":"SQ3RSQ3R方法是一种提升研习能力的方法，为美国俄亥俄州州立大学心理学教授罗宾逊（F. P. Robinson）所设计的一套有效读书方法，于1946年在他的著作《Effective Study》有所提及，主要用于精读课文。 “SQ3R”来自以下五个英语词语的字首，即：综览（Survey）、发问（Question）、阅读（Read）、背诵（Recite）、复习（Review）。 综览（Survey，为时约1分钟）：在详读文章之前，先概览文章一番：留意文章内的标题及结构，以控制阅读的目的、方向和注意力。细阅文章的引言、总结及参考，但不要阅读文章的内容，试试能否从所得的资料略知文章的主题。目标为掌握文章主题的3个至6个要点。 发问（Question，为时不超过半分钟）：主要利用每个章节的标题和 六何法来对要研习的题目自行拟定问题。 阅读（Read，不设时限，但以个人步伐）：指专心注意于找出发问问题的答案。阅读者需要逐一章节细阅，而不是一次过细阅整个篇章。阅读时应用主动阅读技巧，尝试在内文中找寻先前拟定问题的答案。 “背诵”（Recite）：能够在阅读时利用各种阅读技巧以帮助记忆，例如：做重点画线、口头复诵或笔记摘要。 复习（Review）：回忆所记忆的重点。 六何法，又称6W分析法或5W1H，即何人（Who）、何时（When)、何事（What）、何地（Where）、为何（Why）及如何（How）。 由这六个疑问词所组成的问句，都不是是非题，而是需要一或多个事实佐证的应用题。 有时“如何”不计在内，因为“如何”可以被“何事”、“何时”和“何地”描述，变成“五何法”。即何人（Who）、何事（What）、何时（When）、何地（Where）及为何（Why）。 康奈尔笔记法5R笔记法，又叫做康奈尔笔记法，特别适用于听课笔记 5R记录法： 记录（Record）。在听讲或阅读过程中，在主栏（将笔记本的一页分为左小右大两部分，右侧为主栏，左侧为副栏）内尽量多记有意义的论据、概念等讲课内容。 简化（Reduce）。下课以后，尽可能及早将这些论据、概念简明扼要地概括（简化）在回忆栏，即副栏。 背诵（Recite）。把主栏遮住，只用回忆栏中的摘记提示，尽量完满地叙述课堂上讲过的内容。 思考（Reflect）。将自己的听课随感、意见、经验体会之类的内容，与讲课内容区分开，写在卡片或笔记本的某一单独部分，加上标题和索引，编制成提纲、摘要，分成类目。并随时归档。 复习（Review）每周花十分钟左右时间，快速复习笔记，主要是先看回忆栏，适当看主栏。这种做笔记的方法初用时，可以以一科为例进行训练。在这一科不断熟练的基础上，然后再用于其他科目。 康奈尔笔记系统把一页纸分成了三部分：","categories":[{"name":"51.Productivity","slug":"51-Productivity","permalink":"https://beefyheisenberg.github.io/categories/51-Productivity/"}],"tags":[{"name":"生产力","slug":"生产力","permalink":"https://beefyheisenberg.github.io/tags/生产力/"},{"name":"知识管理","slug":"知识管理","permalink":"https://beefyheisenberg.github.io/tags/知识管理/"},{"name":"PKM","slug":"PKM","permalink":"https://beefyheisenberg.github.io/tags/PKM/"},{"name":"笔记","slug":"笔记","permalink":"https://beefyheisenberg.github.io/tags/笔记/"},{"name":"SQ3R","slug":"SQ3R","permalink":"https://beefyheisenberg.github.io/tags/SQ3R/"},{"name":"康奈尔笔记法","slug":"康奈尔笔记法","permalink":"https://beefyheisenberg.github.io/tags/康奈尔笔记法/"}]},{"title":"高效学习法（费曼、SQ3R）","slug":"51.Productivity/高效学习法","date":"2024-01-24T01:27:53.227Z","updated":"2024-01-24T01:27:53.228Z","comments":true,"path":"51.Productivity/高效学习法/","link":"","permalink":"https://beefyheisenberg.github.io/51.Productivity/高效学习法/","excerpt":"SQ3RSQ3R来自以下五个英语词语的字首，即：综览（Survey）、发问（Question）、阅读（Read）、背诵（Recite）、复习（Review） 综览（Survey，为时约1分钟）：在详读文章之前，先概览文章一番：留意文章内的标题及结构，以控制阅读的目的、方向和注意力。细阅文章的引言、总结及参考，但不要阅读文章的内容，试试能否从所得的资料略知文章的主题。目标为掌握文章主题的3个至6个要点。 发问（Question，为时不超过半分钟）：主要利用每个章节的标题和六何法来对要研习的题目自行拟定问题。 阅读（Read，不设时限，但以个人步伐）：指专心注意于找出发问问题的答案。阅读者需要逐一章节细阅，而不是一次过细阅整个篇章。阅读时应用主动阅读技巧，尝试在内文中找寻先前拟定问题的答案。 “背诵”（Recite）：能够在阅读时利用各种阅读技巧以帮助记忆，例如：做重点画线、口头复诵或笔记摘要。 复习（Review）：回忆所记忆的重点。 @ref: https://zh.wikipedia.org/zh-cn/SQ3R%E6%96%B9%E6%B3%95 费曼学习法","text":"SQ3RSQ3R来自以下五个英语词语的字首，即：综览（Survey）、发问（Question）、阅读（Read）、背诵（Recite）、复习（Review） 综览（Survey，为时约1分钟）：在详读文章之前，先概览文章一番：留意文章内的标题及结构，以控制阅读的目的、方向和注意力。细阅文章的引言、总结及参考，但不要阅读文章的内容，试试能否从所得的资料略知文章的主题。目标为掌握文章主题的3个至6个要点。 发问（Question，为时不超过半分钟）：主要利用每个章节的标题和六何法来对要研习的题目自行拟定问题。 阅读（Read，不设时限，但以个人步伐）：指专心注意于找出发问问题的答案。阅读者需要逐一章节细阅，而不是一次过细阅整个篇章。阅读时应用主动阅读技巧，尝试在内文中找寻先前拟定问题的答案。 “背诵”（Recite）：能够在阅读时利用各种阅读技巧以帮助记忆，例如：做重点画线、口头复诵或笔记摘要。 复习（Review）：回忆所记忆的重点。 @ref: https://zh.wikipedia.org/zh-cn/SQ3R%E6%96%B9%E6%B3%95 费曼学习法 获取：即获得并初步吸收自己获得的知识 教学：向他人讲解你所获得的知识 回顾：对自己的教学进行评价，并回顾讲的不好的地方和漏洞 简化：简化知识，成为你自己的话术","categories":[{"name":"51.Productivity","slug":"51-Productivity","permalink":"https://beefyheisenberg.github.io/categories/51-Productivity/"}],"tags":[{"name":"生产力","slug":"生产力","permalink":"https://beefyheisenberg.github.io/tags/生产力/"},{"name":"学习法","slug":"学习法","permalink":"https://beefyheisenberg.github.io/tags/学习法/"}]},{"title":"如何写论文","slug":"51.Productivity/如何写论文","date":"2024-01-24T01:27:53.216Z","updated":"2024-01-24T01:27:53.217Z","comments":true,"path":"51.Productivity/如何写论文/","link":"","permalink":"https://beefyheisenberg.github.io/51.Productivity/如何写论文/","excerpt":"「IMRAD 」方法What is the structure of research papers/article? - Quora 常规的研究论文包含以下9个部分: Title, Abstract, Introduction, Materials &amp; Methods, Results, Discussion, Conclusion, Acknowledgements, References。其中，IMRAD（引言、方法、结果、讨论）则是整篇文章最重要的主体部分。IMRAD在目前的科技论文结构中占据主导地位，无论是写作前的构思还是在实际写作过程中，通过IMRAD法则来架构你的论文会让逻辑结构更为清晰，也有利于论文的规范化。 IMRAD是研究论文中一种常用的写作逻辑结构，每个字母分别代表：Introduction（前言），Methods（研究方法），Results（研究结果）以及Discussion（讨论）。 Academics丨论文——IMRAD格式 - 知乎","text":"「IMRAD 」方法What is the structure of research papers/article? - Quora 常规的研究论文包含以下9个部分: Title, Abstract, Introduction, Materials &amp; Methods, Results, Discussion, Conclusion, Acknowledgements, References。其中，IMRAD（引言、方法、结果、讨论）则是整篇文章最重要的主体部分。IMRAD在目前的科技论文结构中占据主导地位，无论是写作前的构思还是在实际写作过程中，通过IMRAD法则来架构你的论文会让逻辑结构更为清晰，也有利于论文的规范化。 IMRAD是研究论文中一种常用的写作逻辑结构，每个字母分别代表：Introduction（前言），Methods（研究方法），Results（研究结果）以及Discussion（讨论）。 Academics丨论文——IMRAD格式 - 知乎 SCI写作黄金法则：用IMRAD架构论文的技巧 - 知乎","categories":[{"name":"51.Productivity","slug":"51-Productivity","permalink":"https://beefyheisenberg.github.io/categories/51-Productivity/"}],"tags":[{"name":"生产力","slug":"生产力","permalink":"https://beefyheisenberg.github.io/tags/生产力/"},{"name":"知识管理","slug":"知识管理","permalink":"https://beefyheisenberg.github.io/tags/知识管理/"},{"name":"PKM","slug":"PKM","permalink":"https://beefyheisenberg.github.io/tags/PKM/"},{"name":"论文","slug":"论文","permalink":"https://beefyheisenberg.github.io/tags/论文/"},{"name":"IMRAD","slug":"IMRAD","permalink":"https://beefyheisenberg.github.io/tags/IMRAD/"}]},{"title":"管理方法论(SWOT/PDCA/SMART/6W2H)","slug":"51.Productivity/管理方法论(SWOT-PDCA-SMART)","date":"2024-01-24T01:27:53.209Z","updated":"2024-01-24T01:27:53.210Z","comments":true,"path":"51.Productivity/管理方法论(SWOT-PDCA-SMART)/","link":"","permalink":"https://beefyheisenberg.github.io/51.Productivity/管理方法论(SWOT-PDCA-SMART)/","excerpt":"SWOT 分析法 Strengths:优势 （内部因素） Weaknessen:劣势 （内部因素） Opportunities:机会（外部因素） Treats:威胁（外部因素） 从整体上看，SWOT 可以分为两部分：第一部分为 S/W，主要用来分析内部条件；第二部分为 O/T，主要用来分析外部条件。 SWOT 分析法即强弱机危综合分析法，经常被用于企业战略制定、竞争对手分析等场合，","text":"SWOT 分析法 Strengths:优势 （内部因素） Weaknessen:劣势 （内部因素） Opportunities:机会（外部因素） Treats:威胁（外部因素） 从整体上看，SWOT 可以分为两部分：第一部分为 S/W，主要用来分析内部条件；第二部分为 O/T，主要用来分析外部条件。 SWOT 分析法即强弱机危综合分析法，经常被用于企业战略制定、竞争对手分析等场合， PDCA 循环规则 Plan： Do： Check：对阶段成果进行检查 Action：纠正偏差，对成果标准化，确定新目标，制定下一轮计划 注意“循环”，PDCA 并不是运行一次，而是周而复始: 一次 PDCA 循环结束，未解决的问题进入下次 PDCA 循环 6W2H 通用决策 6W： What 项目的内容是什么，达成什么目标 Why 为什么要做？ Who 负责人、执行人、验收方 When 开始、结束，以及每个阶段的的时间点 Where 项目发生的地点、范围边界、环境如何，资源在哪 Which 技术方案有哪些 2H： How 如何实现目标，如何更高效更节省资源、如何改进、如何降低风险 How much 预算、成本 6W2H 通用决策为我们提供了科学的决策和工作分析方法，常常被运用到企业战略的决策和制定计划以及对工作的规划与分析， 6w2h 通用决策的核心在于：对选择的任何目标（which）都可以对功能（what）、场地（where）、时间（when）、人物（who）四个价值要素进行剔除、减少、增加、创造四个动作并围绕如何提高效率（how to do）这一永恒主题进行整合就能产生不同的价值，进而可以根据价值的大小确定最佳目标和最优路径 SMART 原则 Specific 具体的，目标是具体的，人员、资源也是具体的 Measurable 可测量的，阶段成果、最终结果都是可测量的 Attainable 可达到的，具备可执行性 Relevant 相关的，可联动相关的资源，必要的时候获得外部的支持 Time based 有时间边界的 保证任务和目标具有可实施性 四象限原则A、重要且紧急 B、重要不紧急 C、紧急不重要 D、不重要不紧急 合理有序安排工作顺序、优先级 任务分解法 WBS工作分解结构（Work Breakdown Structure，简称 WBS），就是把一个项目，按一定的原则分解，项目分解成任务，任务再分解成一项项工作，再把一项项工作分配到每个人的日常活动中，直到分解不下去为止。 目标→任务→工作→活动 ![[../_images/管理方法论(SWOT-PDCA-SMART)-2023-09-18-5.png]] ![[../_images/管理方法论(SWOT-PDCA-SMART)-2023-09-18-6.png]] 二八原则巴列特定律：总结果的 80%是由总消耗时间中的 20%所形成的抓主要矛盾，把资源用在最重要最紧迫的事情上","categories":[{"name":"51.Productivity","slug":"51-Productivity","permalink":"https://beefyheisenberg.github.io/categories/51-Productivity/"}],"tags":[]},{"title":"开始使用Obsidian","slug":"51.Productivity/开始使用Obsidian","date":"2024-01-24T01:27:53.203Z","updated":"2024-01-24T01:27:53.203Z","comments":true,"path":"51.Productivity/开始使用Obsidian/","link":"","permalink":"https://beefyheisenberg.github.io/51.Productivity/开始使用Obsidian/","excerpt":"有用的链接 特性介绍: Features - Obsidian 版本发布: Latest Announcements topics - Obsidian Forum Feature requests: Latest Feature requests topics - Obsidian Forum Graph View（关系图谱）关系图谱是Obsidian的特色功能，展示笔记的引用关系，也是一种‘网状的MOC’ Graph view 支持进阶设定，例如展示时排除路径带index的文件夹下的笔记，语法1-path:index除了上面的path外，还支持 tag、file、path 等变量","text":"有用的链接 特性介绍: Features - Obsidian 版本发布: Latest Announcements topics - Obsidian Forum Feature requests: Latest Feature requests topics - Obsidian Forum Graph View（关系图谱）关系图谱是Obsidian的特色功能，展示笔记的引用关系，也是一种‘网状的MOC’ Graph view 支持进阶设定，例如展示时排除路径带index的文件夹下的笔记，语法1-path:index除了上面的path外，还支持 tag、file、path 等变量 Vault（库）每个vault下有单独的.obsidian文件夹: .obsidian/thems/: CSS主题目录 .obsidian/snippets/: CSS代码片段目录 .obsidian/config: .obsidian/workspace: For example YourOwnVault/.obsidian/.trash is the trash folder,YourOwnVault/.obsidian/config stores things like your own custom hotkeys,YourOwnVault/.obsidian/workspace saves things like the most recent files, and the window layout (I think). App系统文件夹: macOS: ~/Library/Application\\ Support/obsidian, 文件缓存在ObsidianCache/ 和 IndexedDB/ Win: %APPDATA%\\Obsidian\\ Plugins（插件） obsidian-excalidraw-plugin: The Obsidian-Excalidraw plugin integrates Excalidraw, a feature rich sketching tool. You can store and edit Excalidraw files in your vault, you can embed drawings into your documents, and you can link to documents and other drawings to/and from Excalidraw obsidian-reveal-active-file: 打开一个mkd时, 自动在文件树导航到这个文件 obsidian-switcher-plus: 类似Sublime的Symbol搜索, 自定义快捷键Cmd+R, 呼出搜索框，直接是文件名模糊搜索， 输入@触发当前文件内搜索Heading, 输入#触发全库内搜索Heading obsidian-mind-map: 为当前笔记生成 mind map advanced-tables-obsidian: 表格编辑, 输入|就可以进入表格编辑, 按Tab编辑下一个表格的内容 obsidian-linter: 格式化md文件, 更新yaml头 OliverBalfour/obsidian-pandoc: 导出为pdf、doc、html等格式 Obsidian-Html: 将Obsidian笔记导出为网站html, 网站样例: https://obsidian-html.github.io/?path=%2FInstructions%2FUsage.html/ obsidian-calendar-plugin: 给Obs增加一个日历widget用以显示每天的笔记, 依赖于Obs的Core插件Daily Note, 是按照mkd的文件名区分日期的, 对于我来说大部分mkd文件都不是日期命名所以也没多大用处, 希望能改成通过yaml头或者文件modify属性识别日期 Templater： 更好的模板管理 easy-typing-obsidian：自动格式化 md wikilinks-to-mdlinks-obsidian：Obsidian 默认的附件（PDF or 贴图）都是 [[ ]]，这种图片格式在其他支持 mkd 的笔记、以及 Hexo 博客里并不支持，这个插件可以一键切换 [[ ]] 和 ![]() 两种 link 格式 obsidian-paste-image-rename:：Obsidian 的贴图自动命名为“pasted image 日期” 这种带空格的格式，对 URL 显示并不友好，这个插件可以自动按规则重命名图片文件，支持 dirName 、fileName、date 等变量； Quiet Outline：更好的显示文件大纲（outline） obsidian-custom-attachment-location: Customize attachment location with variables($filename, $data, etc) like typora. 自定义粘贴附件的存储位置 如果在Ob 中已经打开了 fileA，再通过 “快速打开” or “点击双链” 进入 fileA，Ob会重复再开一个标签页： Quicker Switcher++： 替换自带的“快速切换” obsidian-no-dupe-leaves：解决从双链进入的重复打开； bug：导致 graph view 中的点击行为不正常 obsidian-open-in-new-tab：解决从文件管理器的重复打开； Themes（主题） whyt-byte/Blue-Topaz_Obsidian-css: A blue theme for Obsidian.：很全面的主体，其他主题多有些小瑕疵（Header字体过大、行间距过大、图片hover有问题、妖艳突兀的配色），Blue Tapaz 可定制化的细节非常多，我一般不用主题自带的霞鹜文楷，非代码字体一律&#39;Sarasa Mono SC&#39;, &#39;Source Han Mono&#39;, var(--font-default)，代码字体&#39;Sarasa Mono SC&#39;, Inconsolata, monospace kepano/obsidian-minimal: Minimal theme for Obsidian：极简主题，如果不喜欢花里胡哨 —— Minimal，如果为选哪个主题犹豫 —— Minimal mediapathic/obsidian-arsmagna-theme: A theme for Obsidian, inspired by the works of Athanasius Kircher：以卡尔达诺的《Ars Magna》命名的主体，不过已经停更多年 手机版Obsidian适用的主体： Atom Horizon：停更 Dracula Slim：停更 CSS SnippetsCSS Snippets 可以载入自定义CSS， 自定义 Obsidian 的外观，例如自定 Heading 的显示样式.. 在 设置 =&gt; 外观 =&gt; CSS 代码片段 管理， 更多可用的 Snippet可以在这里找到： https://github.com/deathau/obsidian-snippets YAML front matter由于 Markdown 官方标准不支持存储 metadata（例如笔记更新日期、分类等），所以 Obsidian 通过支持 YAML front matter 来解决，目前受 Obsidian 支持的有： aliases: [别名1, 别名2]tags:- 标签1- 标签2publish: false Ob 从v1.4.5之后开始支持文件 properties， 支持的属性有： title: 笔记标题 date: 创建日期 categories：分类 aliases: 别名 tags：标签 cssclasses: 笔记使用的 CSS Snippets @ref: https://help.obsidian.md/Editing+and+formatting/Properties Alias（别名）在 md文件的 YAML front matter加入： alias: this's alias example 那么在引用这个文件时，键入[后再输入‘this’s alias example’ 即可， 实际上Ob把 这个语法替换为 [[file-name|alias]]，显示为‘alias’而不是文件名。 Callout（标注）在标准 Markdown GFM 规范中，对于“标注框”都没有明确的定义。因此关于标注框这件事，各家都是采用各自的语法来实现，不同语法之间互不通用。标注框有点类似 Markdown 中的 &gt; 引言块，但更加醒目。往往用于诸如提示、警告之类的用途，也经常被称为“谏言块”（admonition）。 Obsidian 在引用块上加了一些特殊的语法： &gt; [!标注类型]&gt; 这里是标注内容... 支持的“标注类型”有：info 、tip、warning、note、todo、question、danger、bug 等，不同的标注类型，渲染出的 icon 和背景色不同： [!warning]这是一个警告标注 数学公式Ob同大部分扩展Markdown一样，也使用 LaTeX 的数学公式语法： $ 和 $$ 例： 上标、下标、函数 $$\\sum_&#123;n=1&#125;^\\infty k$$$\\sqrt&#123;3x-1&#125;+\\sqrt[5]&#123;2y^5-4&#125;$$$\\cos (2\\theta) = \\cos^2 \\theta - \\sin^2 \\theta$$ 快捷键Obsidian内建功能快捷键： 快速打开：cmd + O 命令面板：cmd + P 编辑/预览: cmd + E 返回：cmd + alt + ← 访问光标处的链接： alt + Enter 播放关系图谱生长动画： cmd + shift + P 查看关系图谱： cmd + G 查看局部关系图谱： cmd + shift + G 插件快捷键： 插件-Advanced Tables插入表格： 按|，再按Tab 插件-Linter 格式化当前文件： cmd + alt + L 插件-Quick Switcher： cmd + R，再按#进入 Heading 搜索 插件-Templater 插入YAML（自定义）：cmd + shift + Y 调试模式进入调试模式快捷键： option-cmd-i（或 Ctrl+shift+I for Win） 新特性 Using obsidian URI YAML front matter Add aliases to note Link to blocks Link to headings Workspace 添加自定义CSS 问题 &amp; feature requests 在 Graph View使用H1标题替代 filename https://forum.obsidian.md/t/show-title-of-zettelkasten-notes-in-graph-view/683 https://forum.obsidian.md/t/use-h1-or-front-matter-title-instead-of-or-in-addition-to-filename-as-display-name/687 Custom Attachment location 相对路径的问题： 如果路径设置为./开头意为使用相对路径，如果设置为 ./../_images 插件会抛错 并不是插件代码问题，在调用app.fileManager.generateMarkdownLink的时候抛错，没有继续跟 generateMarkdownLink 的代码 Reference1.https://help.obsidian.md/Plugins/Search ↩","categories":[{"name":"51.Productivity","slug":"51-Productivity","permalink":"https://beefyheisenberg.github.io/categories/51-Productivity/"}],"tags":[{"name":"生产力","slug":"生产力","permalink":"https://beefyheisenberg.github.io/tags/生产力/"},{"name":"知识管理","slug":"知识管理","permalink":"https://beefyheisenberg.github.io/tags/知识管理/"},{"name":"PKM","slug":"PKM","permalink":"https://beefyheisenberg.github.io/tags/PKM/"},{"name":"笔记","slug":"笔记","permalink":"https://beefyheisenberg.github.io/tags/笔记/"}]},{"title":"看板（Kanban）","slug":"51.Productivity/看板（Kanban）","date":"2024-01-24T01:27:53.198Z","updated":"2024-01-24T01:27:53.198Z","comments":true,"path":"51.Productivity/看板（Kanban）/","link":"","permalink":"https://beefyheisenberg.github.io/51.Productivity/看板（Kanban）/","excerpt":"如何使用看板（Trello）@tag: #方法论 #看板 看板历史： 丰田生产模式，解决生产线不同车间（流式生产线）库存和消耗量对齐的问题。 例子: 车间1 → 车间2 → 车间3 … 看板例子（流式任务）：参考 Trello 等任务管理工具体验如何？ - 知乎 bug处理： bug汇集池 → bug处理（Tips 用标签区分不同产品） 待办： 收集箱 → Doing → Done（Tips 用标签作为优先级标识） 项目： 需求TODO → 开发ing → 测试ing → 已完成/被阻塞 里程碑/周报： 第一周 → 第二周 （完成的留在本周，未完成流向下一周） 追踪多个项目： 除了解决“任务流转”，看板还可以： 解决列表结构的局限性： 列表是单线结构，并单向生长。如果需要关注多个并行的列表 &amp; 某个列表过长.. 模板整理 IT Project Workflow: TODO、IN PROGRESS、BLOCKING 4 L’s exercise： 此看板包括四个列表，记录发生的事情：里程碑，喜欢的，想做的，不喜欢的 Books Club：列表1=好书待读，列表2=book1，列表3=book2 … 马克安德森生产力体系：此看板用于GTD，TODO、Today、Later… Life Goals： 此看板包括几个列表：已计划事件、1月完成、2月完成…","text":"如何使用看板（Trello）@tag: #方法论 #看板 看板历史： 丰田生产模式，解决生产线不同车间（流式生产线）库存和消耗量对齐的问题。 例子: 车间1 → 车间2 → 车间3 … 看板例子（流式任务）：参考 Trello 等任务管理工具体验如何？ - 知乎 bug处理： bug汇集池 → bug处理（Tips 用标签区分不同产品） 待办： 收集箱 → Doing → Done（Tips 用标签作为优先级标识） 项目： 需求TODO → 开发ing → 测试ing → 已完成/被阻塞 里程碑/周报： 第一周 → 第二周 （完成的留在本周，未完成流向下一周） 追踪多个项目： 除了解决“任务流转”，看板还可以： 解决列表结构的局限性： 列表是单线结构，并单向生长。如果需要关注多个并行的列表 &amp; 某个列表过长.. 模板整理 IT Project Workflow: TODO、IN PROGRESS、BLOCKING 4 L’s exercise： 此看板包括四个列表，记录发生的事情：里程碑，喜欢的，想做的，不喜欢的 Books Club：列表1=好书待读，列表2=book1，列表3=book2 … 马克安德森生产力体系：此看板用于GTD，TODO、Today、Later… Life Goals： 此看板包括几个列表：已计划事件、1月完成、2月完成… 选型： Trello vs Google Keep Google Keep： n个笔记组成一个看板，笔记本即“列表” 笔记本支持颜色 Trello： 看板-列表-卡片 卡片支持标签（例如用来标注优先级） 卡片支持Due时间 卡片支持添加Checklist 卡片支持评论 Example案例：用看板作为 Read-it-laterTODO 案例：用看板作为 工作管理 看板1（里程碑或周报）： 第一周、第二周… 看板2（多项目追踪）：项目1、项目2… 案例：用看板作为 个人目标管理参考 “Life Goals”模板","categories":[{"name":"51.Productivity","slug":"51-Productivity","permalink":"https://beefyheisenberg.github.io/categories/51-Productivity/"}],"tags":[{"name":"项目管理","slug":"项目管理","permalink":"https://beefyheisenberg.github.io/tags/项目管理/"}]},{"title":"Zotero简单试用","slug":"51.Productivity/Using Zotero","date":"2024-01-24T01:27:53.194Z","updated":"2024-01-24T01:27:53.194Z","comments":true,"path":"51.Productivity/Using Zotero/","link":"","permalink":"https://beefyheisenberg.github.io/51.Productivity/Using Zotero/","excerpt":"","text":"Zotero 可以单独建立笔记：笔记内容存储在 zotero.sqlite文件的itemNotes表 用 dropbox 同步 Zotero 文件夹的问题：https://blog.yesmryang.net/tags/Zotero/ zotero.sqlite 在打开的时候会被 zotero 锁定，此时 Dropbox 就认为这个文件已经有了修改，经过二进制对比，Dropbox 会把修改部分上传并同步。如果两台电脑同时打开 zotero 的话，Dropbox 会认为两边都是在更新这个文件，于是他会把对应修改的二进制文件合并到一块去，如果不能合并到一块去的话就生成冲突文件，在这个过程中很有可能就造成数据库文件的损坏 处理方法：让 zotero 自己提供的网络同步功能同步数据库文件即可，然后存储在 zotero 里面的附件文件夹用符号链接的方式放到 Dropbox 目录里就可以了，这样把数据库和外部附件分开，以免 Dropbox 去处理 zotero.sqlite 在Microsoft Word中成功安装了Zotero插件后，就可以直接将Zotero中的引文插入文档。点击Word文档菜单栏中的“Zotero”，然后点击“Add/Edit Citation”。 @ref: 文献管理神器 Zotero 学习路径指南 - 少数派 Zotero, Mendeley, Papers比较 | 大家都叫我老杨 如何在Zotero中设置webdav连接到坚果云？ | 坚果云帮助中心","categories":[{"name":"51.Productivity","slug":"51-Productivity","permalink":"https://beefyheisenberg.github.io/categories/51-Productivity/"}],"tags":[{"name":"文献管理","slug":"文献管理","permalink":"https://beefyheisenberg.github.io/tags/文献管理/"}]},{"title":"TaskPaper","slug":"51.Productivity/Using TaskPaper","date":"2024-01-24T01:27:53.190Z","updated":"2024-01-24T01:27:53.190Z","comments":true,"path":"51.Productivity/Using TaskPaper/","link":"","permalink":"https://beefyheisenberg.github.io/51.Productivity/Using TaskPaper/","excerpt":"TaskPaper is a plain-text to-do list that’s surprisingly adept. Thoroughly modernized. TaskPaper 3 is all new, while still retaining the same plain-text design that’s been getting things done since 2006. What’s New in 3 All new app More powerful searches Flexible and unique folding interface More powerful text editor and outliner Saved searches; one click away in sidebar Relative date and time based searches LESS/CSS powered themes Extensive Javascript API Key Features Plain text files; edit anywhere Type and your lists are auto formatted Projects- tasks, notes, and @tags Text editor speed with outliner power Lists within lists within lists Fold, focus, and filter to make big list small Drag and drop to organize your list Fully scriptable and themable Getting things done since 2006 TaskPaper 是一款基于纯文本的 Todo 应用，它有一个 “看起来像个文本编辑器”的 GUI，实际上它的存储格式也是纯文本。官网 TaskPaper – Plain text to-do lists for Mac 也正是因为纯文本，Taskpaper 的存储文件可以用 dropbox &amp; iCloud 同步，用你喜欢的任意的文本编辑器来编辑。 iOS 上的 Mkd 编辑器 Editorial 支持高亮 .taskpaper 格式的文件；Atom 上也有一些第三方制作的主题，可以高亮 taskpaper 的语法 GitHub - jasonshanks/TaskPaper-Atom-One-Dark: v2 of a theme for TaskPaper 3 by pslobo and inspired by Atom One Dark Syntax；","text":"TaskPaper is a plain-text to-do list that’s surprisingly adept. Thoroughly modernized. TaskPaper 3 is all new, while still retaining the same plain-text design that’s been getting things done since 2006. What’s New in 3 All new app More powerful searches Flexible and unique folding interface More powerful text editor and outliner Saved searches; one click away in sidebar Relative date and time based searches LESS/CSS powered themes Extensive Javascript API Key Features Plain text files; edit anywhere Type and your lists are auto formatted Projects- tasks, notes, and @tags Text editor speed with outliner power Lists within lists within lists Fold, focus, and filter to make big list small Drag and drop to organize your list Fully scriptable and themable Getting things done since 2006 TaskPaper 是一款基于纯文本的 Todo 应用，它有一个 “看起来像个文本编辑器”的 GUI，实际上它的存储格式也是纯文本。官网 TaskPaper – Plain text to-do lists for Mac 也正是因为纯文本，Taskpaper 的存储文件可以用 dropbox &amp; iCloud 同步，用你喜欢的任意的文本编辑器来编辑。 iOS 上的 Mkd 编辑器 Editorial 支持高亮 .taskpaper 格式的文件；Atom 上也有一些第三方制作的主题，可以高亮 taskpaper 的语法 GitHub - jasonshanks/TaskPaper-Atom-One-Dark: v2 of a theme for TaskPaper 3 by pslobo and inspired by Atom One Dark Syntax； 下面是 taskpaper 文本格式的例子： TaskPaper Mode:Editorial supports the .taskpaper plain text todo list format, invented by Jesse Grosjean of Hog Bay Software (see http://hogbaysoftware.com/products/taskpaper ). （一）添加一个 task，就像 markdown 里的一行列表一样The TaskPaper “markup” is very simple: To create a task, just start a line with a dash and a following space. This is a taskEditorial automatically shows a checkbox instead of the dash, but the file is still saved as plain text, and you can open it in any other editor. （二）用 “@tag” 这样的语法给一个任务加标签，这有点像 Java 里的注解语法，例如“@done”表示完成的任务，此外 Taskpaper 支持@due、@flagged 和@today 等标签Tasks can be tagged, using the @ symbol. Another task @homeThe special @done tag is used to mark finished tasks. A finished task @done(2015-02-21)(Tags can contain additional information, like the completion date in parentheses.)You can quickly add or remove the @done tag by tapping the checkbox. （三）如果一行用 “项目名:”开头，表示下面的 task 都是属于该项目的，缩进 2 空格表示子项目To insert a project header, simply type a line that ends with a colon (‘:’). Everything that isn’t a task or project header is considered a note. Color Labels:In Editorial’s settings, you can associate tags with color labels. Some tags, like @due, @flagged, and @today have default colors, but you can easily change this. This task should be blue @today This one is red @flagged @done(2018-12-17) Tips: You can rearrange tasks by dragging the right margin (tap and hold the gray box). Tap the triangle next to a project header to hide (“fold”) its content. The label next to a folded project shows the number of tasks that are hidden. Project: Project2: 序章 | TaskPaper 原理 - 少数派 和你一样，有个外国的小伙子也想要一款称心的任务管理工具。他曾打算做一款「完美的信息管理应用（Mori）」，但他自己尚不能满意这个工具；最后他卖掉了 Mori，用纯文本来记录任务。为了让自己的任务列表保持有序、便于管理，他开始为之添加最简单基本的结构——不破坏这一点的前提下，不断丰富这一系统，最后我们看到了 TaskPaper。","categories":[{"name":"51.Productivity","slug":"51-Productivity","permalink":"https://beefyheisenberg.github.io/categories/51-Productivity/"}],"tags":[{"name":"GTD","slug":"GTD","permalink":"https://beefyheisenberg.github.io/tags/GTD/"}]},{"title":"Spacemacs","slug":"51.Productivity/Using Spacemacs","date":"2024-01-24T01:27:53.185Z","updated":"2024-01-24T01:27:53.186Z","comments":true,"path":"51.Productivity/Using Spacemacs/","link":"","permalink":"https://beefyheisenberg.github.io/51.Productivity/Using Spacemacs/","excerpt":"安装Spacemacs 是一份 emacs 的配置文件，想要使用它，你先要有 emacs。 安装 Emacs： brew tap railwaycat/emacsmacportbrew install --cask emacs-mac 安装 Spacemacs 配置：","text":"安装Spacemacs 是一份 emacs 的配置文件，想要使用它，你先要有 emacs。 安装 Emacs： brew tap railwaycat/emacsmacportbrew install --cask emacs-mac 安装 Spacemacs 配置： $ git clone https://github.com/syl20bnr/spacemacs ~/.emacs.d$ emacs 启动Spacemacs 会在启动时启动 emacs server，这个服务器会在 Spacemacs 关闭的时候被杀掉。 当 Emacs 服务器启动的时候，我们可以在命令行中使用 emacsclient 命令： $ emacsclient -c 用 Emacs GUI 来打开文件 $ emacsclient -t 用命令行中 Emacs 来打开文件 我们可以持久化 Emacs 服务器，在 Emacs 关闭的时候，服务器不被杀掉。只要设置 ~/.spacemacs 中 dotspacemacs-persistent-server 为 t 即可。 但这种情况下，我们只可以通过以下方式来杀掉服务器了： SPC q q 退出 Emacs 并杀掉服务器，会对已修改的 Buffer 给出保存的提示。 SPC q Q 同上，但会丢失所有未保存的修改。 快捷键配置文件管理SPC f e d 快速打开配置文件 .spacemacsSPC f e R 同步配置文件 文件管理SPC f f 打开文件（夹），相当于 $ open xxx 或 $ cd /path/to/projectSPC p f 搜索文件名，相当于 ST / Atom 中的 Ctrl + pSPC s a p 搜索内容，相当于 $ ag xxx 或 ST / Atom 中的 Ctrl + Shift + f SPC b k 关闭当前 bufferSPC SPC 搜索当前文件 窗口管理SPC f t 打开/关闭侧边栏，相当于 ST / Atom 中的 Ctrl(cmd) + k + b SPC 0 光标跳转到侧边栏（NeoTree）中SPC n(数字) 光标跳转到第 n 个 buffer 中 SPC w s | SPC w - 水平分割窗口SPC w v | SPC w / 垂直分割窗口SPC w c 关闭当前窗口 对齐SPC j = 自动对齐，相当于 beautify 配置文件Spacemacs 的配置文件位于 ~/.spacemacs 中，我们只需要修改这个文件就可以制定自己的配置了。 一般情况下，只需要在 dotspacemacs-configuration-layers 中添加自己需要的 layer 。 evil modeEvil，全称 Emulation vim layer。作为 emacs 的扩展插件，它可以模拟绝大多数 vim 的键位和指令。 启用 evil mode 只需要把 .spacemacs 文件中的 dotspacemacs-editing-style 设定为 ‘vim 即可。","categories":[{"name":"51.Productivity","slug":"51-Productivity","permalink":"https://beefyheisenberg.github.io/categories/51-Productivity/"}],"tags":[]},{"title":"Logseq简单试用","slug":"51.Productivity/Using Logseq","date":"2024-01-24T01:27:53.181Z","updated":"2024-01-24T01:27:53.181Z","comments":true,"path":"51.Productivity/Using Logseq/","link":"","permalink":"https://beefyheisenberg.github.io/51.Productivity/Using Logseq/","excerpt":"","text":"Logseq书写方式类似于 WorkFlowy，一种可以无限缩进的、且支持折叠的列表作为书写方式 大纲笔记软件 Workflowy 综合评测； Logseq同时支持 Markdown 以及 Org-mode； Logseq把一个“笔记本库”叫Graph（图谱），Obsidian里则是“Vault”； 块（Block）是一段文字，也是 Logseq 的最小内容单位，可以认为 Markdown语法的 “列表”的一行就是一个 Block ，按回车键会自动创建一个新块 页（Page）包含许多块，一个页对应“pages”文件夹下的一个md文件； Logseq似乎完全放弃了文件夹层级这种结构，上面的操作只能创建一个一个新页面%2F一个子页面为名的md文件，在“全部页面”里二者是并列的，也没有显示上的层级性 如果想用 Logseq但又不想放弃树状文件夹层级，可以建一个索引页，用 list 和 sub-list模拟树状关系 Card（记忆卡片） 和 Journals（日志）是两个内置功能，可以选择开启或关闭 如何使用 Logseq 的卡片功能： 这是一个卡片的例子，带有#card标签的块，会变成一个卡片 卡片支持完形填空（cloze）的功能，输入/cloze即可进入 从左侧导航栏里的“卡片”可以列出所有的卡片 如何使用 Logseq 的日志功能： 每天自动生成一个新日志页面，点击左侧的“日志”即可开始书写，日志存储在 “journals”文件夹下，每天的日志对应一个md文件，例如“2022_09_15.md” 其他功能： 同步： Logseq 不包括云端服务，全部笔记都存储在本地库文件夹，可以使用 Dropbox、Git对笔记文件夹进行同步 Logseq（桌面版）还提供了周期 git commit 的功能 Logseq 有 iOS客户端，如果要同步数据，目前只能用 iCloud Drive（2022-09-15） 页面引用： Logseq 使用[[wikilink]]的方式来引用另一个页 块引用： 输入 ((括号，然后输入以关联某块，例如 ((6322ef12-1529-4939-af2a-7840675787df))，可以看到(())里是一段类似uuid的代码，同时 Logseq会在被引用的块下面增加一行 id:: 6322ef12-1529-4939-af2a-7840675787df用以标注该块的唯一ID 标签： 在 Logseq 中使用#tag来增加一个标签，与 Mkd 语法一致，例如： #Markdown 在创建一个标签后，Logseq 自动在“全部页面”里增加一个该标签为名的页面 测试 Markdown 中的标题# ： 一级标题 Markdown中的层级可以理解为一级标题 &gt; 二级标题 &gt; n级标题，内容的容器（包括列表块、代码块、普通文字块）都隶属于标题之下。但 Logseq的页面里，列表才是第一层级的容器 测试贴图：默认图片附件在库的根目录下的assets文件夹 @ref: GitHub - logseq/logseq: A privacy-first, open-source platform for knowledge management and collaboration. Desktop app download link: https://github.com/logseq/logseq/releases, roadmap: https://trello.com/b/8txSM12G/roadmap 双链笔记软件推荐：Logseq 和它的五种用法 - 少数派","categories":[{"name":"51.Productivity","slug":"51-Productivity","permalink":"https://beefyheisenberg.github.io/categories/51-Productivity/"}],"tags":[{"name":"生产力","slug":"生产力","permalink":"https://beefyheisenberg.github.io/tags/生产力/"},{"name":"知识管理","slug":"知识管理","permalink":"https://beefyheisenberg.github.io/tags/知识管理/"},{"name":"PKM","slug":"PKM","permalink":"https://beefyheisenberg.github.io/tags/PKM/"},{"name":"笔记","slug":"笔记","permalink":"https://beefyheisenberg.github.io/tags/笔记/"}]},{"title":"PKM.03|什么是卡片盒笔记法","slug":"51.Productivity/PKM.03.什么是卡片盒笔记法","date":"2024-01-24T01:27:53.177Z","updated":"2024-01-24T01:27:53.178Z","comments":true,"path":"51.Productivity/PKM.03.什么是卡片盒笔记法/","link":"","permalink":"https://beefyheisenberg.github.io/51.Productivity/PKM.03.什么是卡片盒笔记法/","excerpt":"@tag: #Zettelkasten #卡片盒笔记法 #Luhmann 这里只讨论什么是 “符合原旨主义的卡片盒笔记法”？ 换句话是卢曼怎么做的。从以下几个方面评估： 单篇笔记格式：Atomicity，遵循原子笔记（Anatomy of Zettel） 笔记间互相引用 以带序号的文件名，表示笔记之间的层级关系、生长关系： “第一条笔记的地址为数字1。如果你想添加一个与第一条笔记无关的笔记，那么将新笔记的地址设为数字2” “如果你想写一条与笔记1有关的新笔记，那么你应该以笔记1为起点产生一条分支，此时新笔记的地址被设为1a” 卢曼的 Communicating with Slip Boxes by Niklas Luhmann 1文章里说明了这种命名方式，笔记通过命名组成了虚拟的slip（滑道），实现了 internal growth（内在生长） 国内介绍的文章，大都把 Zettelkasten 翻译为卡片盒，特性介绍里只保留了“原子笔记”，但丢掉了“slip” 放入哪个盒子？即盒子是如何分类的，以及盒子无法实现“大盒子套小盒子”的情况下，如何应对树形概念？ google图片搜索 “Luhmann box Stock Photos”：卢曼的盒子是有纸条的，但也可能是后人加上去的 卡片盒不是双链笔记，只是卢曼的时代很难实现反链 以上部分概念来自 https://zettelkasten.de/introduction/zh/","text":"@tag: #Zettelkasten #卡片盒笔记法 #Luhmann 这里只讨论什么是 “符合原旨主义的卡片盒笔记法”？ 换句话是卢曼怎么做的。从以下几个方面评估： 单篇笔记格式：Atomicity，遵循原子笔记（Anatomy of Zettel） 笔记间互相引用 以带序号的文件名，表示笔记之间的层级关系、生长关系： “第一条笔记的地址为数字1。如果你想添加一个与第一条笔记无关的笔记，那么将新笔记的地址设为数字2” “如果你想写一条与笔记1有关的新笔记，那么你应该以笔记1为起点产生一条分支，此时新笔记的地址被设为1a” 卢曼的 Communicating with Slip Boxes by Niklas Luhmann 1文章里说明了这种命名方式，笔记通过命名组成了虚拟的slip（滑道），实现了 internal growth（内在生长） 国内介绍的文章，大都把 Zettelkasten 翻译为卡片盒，特性介绍里只保留了“原子笔记”，但丢掉了“slip” 放入哪个盒子？即盒子是如何分类的，以及盒子无法实现“大盒子套小盒子”的情况下，如何应对树形概念？ google图片搜索 “Luhmann box Stock Photos”：卢曼的盒子是有纸条的，但也可能是后人加上去的 卡片盒不是双链笔记，只是卢曼的时代很难实现反链 以上部分概念来自 https://zettelkasten.de/introduction/zh/ 如何用好 Roam Research ？（三）：Roam 不是卡片盒 - 少数派卡片盒为什么这么受到追捧？这和它的提出者社会学家尼古拉斯卢曼分不开。关于卢曼的生平，我在这篇文章里面已经和你谈过了。卢曼的学术发表记录，相信已经给你留下了很深刻的印象。但是，你千万不要把 Roam Research 和卡片盒直接画上等号。不要小瞧概念的力量，一旦画上等号，你就会偏执的以一种「原教旨主义」的方式来记笔记。你会坚定认为每一则笔记(对应 Roam Research 中的一个页面)不应该超过一定的字数限制(比如说200个字)，而且还必须保证它谈论的，必须只有一个主题。另外，还需要根据类别，手动对于页面赋予独特的标记。因为，卢曼就是这样做的啊！ 什么是 Zettelkasten 卡片盒笔记法？ - 知乎 卡片笔记写作法是否被过誉了？ - 知乎 卡片笔记写作法 (豆瓣) 英文版： Take Smart Notes — Sönke Ahrens 1.wiki里也提到了这种slip命名： Zettelkasten - Wikipedia ↩","categories":[{"name":"51.Productivity","slug":"51-Productivity","permalink":"https://beefyheisenberg.github.io/categories/51-Productivity/"}],"tags":[{"name":"生产力","slug":"生产力","permalink":"https://beefyheisenberg.github.io/tags/生产力/"},{"name":"知识管理","slug":"知识管理","permalink":"https://beefyheisenberg.github.io/tags/知识管理/"},{"name":"PKM","slug":"PKM","permalink":"https://beefyheisenberg.github.io/tags/PKM/"},{"name":"笔记","slug":"笔记","permalink":"https://beefyheisenberg.github.io/tags/笔记/"}]},{"title":"PKM.03|数字花园","slug":"51.Productivity/PKM.03.数字花园","date":"2024-01-24T01:27:53.173Z","updated":"2024-01-24T01:27:53.173Z","comments":true,"path":"51.Productivity/PKM.03.数字花园/","link":"","permalink":"https://beefyheisenberg.github.io/51.Productivity/PKM.03.数字花园/","excerpt":"何谓数字花园 数字花园 是介于笔记应用和博客应用之间的半公开数字展览馆，半公开指的不是读者没有权限阅览，而是很多想法只是相互关联的半成品，令他人难以轻易看懂。因为数字花园降低了对内容的要求，不强求作者将所有内容都打磨成文章级的成果，数字花园就会鼓励作者产出更多的内容，不拘一格降笔记。 菲尔德的隐喻：花园、溪流和篝火 在2015年数字学习研究网络上，迈克·考菲尔德（Mike Caufield）发表了关于《花园与溪流：技术田园》的主题演讲。它后来成为一篇重要的文章，为我们现在对这个词语的理解奠定了基础。如果说有谁应该被认为是最早提出了数字花园的话，那就是考菲尔德。他是第一个用诗意的、连贯的文字来阐述整个想法的人。 麦克·考菲尔德认为，互联网有两种形态，一种是“花园”，一种是“溪流”。花园（Garden）是说，互联网就像一块土地，上面有小路，有花草树木，它们皆有所指。小路就是超链接，让我们在不同网页穿梭，花花草草则是不同的网站。这的确和早期的互联网形态很像，和上面提到的1998年的超文本花园联系上了。","text":"何谓数字花园 数字花园 是介于笔记应用和博客应用之间的半公开数字展览馆，半公开指的不是读者没有权限阅览，而是很多想法只是相互关联的半成品，令他人难以轻易看懂。因为数字花园降低了对内容的要求，不强求作者将所有内容都打磨成文章级的成果，数字花园就会鼓励作者产出更多的内容，不拘一格降笔记。 菲尔德的隐喻：花园、溪流和篝火 在2015年数字学习研究网络上，迈克·考菲尔德（Mike Caufield）发表了关于《花园与溪流：技术田园》的主题演讲。它后来成为一篇重要的文章，为我们现在对这个词语的理解奠定了基础。如果说有谁应该被认为是最早提出了数字花园的话，那就是考菲尔德。他是第一个用诗意的、连贯的文字来阐述整个想法的人。 麦克·考菲尔德认为，互联网有两种形态，一种是“花园”，一种是“溪流”。花园（Garden）是说，互联网就像一块土地，上面有小路，有花草树木，它们皆有所指。小路就是超链接，让我们在不同网页穿梭，花花草草则是不同的网站。这的确和早期的互联网形态很像，和上面提到的1998年的超文本花园联系上了。 溪流（Stream）指的就是线性的信息流，各种关注、算法推荐、通知产生的信息流，就像一条条小溪不停流淌。溪流里的信息，上一条和下一条可能并不相关，只是被聚合到了一起。甚至社交网络号称是网络，但呈现在大家面前的还是一条条的信息流。 考菲尔德得出结论：在溪流模式中，无法承载系统化的知识。如果互联网只剩下溪流模式，那么它迟早会变成充斥知识碎片的混沌之地。如果每一个人都只投身于溪流当中，也无法收获真正的成长。考菲尔德认为，我们应该像园丁维护花园一样去学习和探索知识。 2018年，一个叫汤姆·克里奇洛的软件工程师写了一篇博客《数字溪流、篝火与花园》，在继承了考菲尔德所提出的两种意象之外，还创造了一个新的意象：数字篝火（Digital Campfire）@ref: Of Digital Streams, Campfires and Gardens 克里奇洛说，数字溪流的例子就像推特，数字花园的例子有维基百科，而数字篝火介于两者之间：像是博客、一些slack社群。博客中的知识之光就像篝火一样，随时间逐渐熄灭，社群中的讨论也随时间消逝，但在写博客、参与社群的过程中，他自己获得了成长。 Digital Garden 的特点： 不断生长：数字花园里的文章需要不断打磨和更新（就像打理花园），也意味着数字花园里的文章可以是半成品 数字花园有“小径”：文章是有关联的，双链or传统的目录 数字花园同博客的区别：博文一旦发布很少会再更新/打磨内容（不是说功能上不能够，而是用户的使用的习惯），对于文章的索引，博客更强调时间序，数字花园似乎是不喜欢“timeline”式的（时间序的更像是 Stream的特征），并且强调文章之间的引用关联 搭建自己的数字花园@toc： Hexo: Hugo: TiddlyWiki: 使用 HexoHexo默认主题和 NexT是按照修改时间排序，如果要实现 order by Name：参考 Hexo部署和使用指北(Windows) | 扔掉笔记 ᐛ/自定义post排序 使用 Hugo@todo 使用 TiddlyWikiHow to build a digital garden with TiddlyWiki - Ness Labs @ref 什么是数字花园（Digital Garden）？ – 酷 壳 – CoolShell 3F 什么是数字花园（Digital Garden）？ - 知乎","categories":[{"name":"51.Productivity","slug":"51-Productivity","permalink":"https://beefyheisenberg.github.io/categories/51-Productivity/"}],"tags":[{"name":"生产力","slug":"生产力","permalink":"https://beefyheisenberg.github.io/tags/生产力/"},{"name":"知识管理","slug":"知识管理","permalink":"https://beefyheisenberg.github.io/tags/知识管理/"},{"name":"PKM","slug":"PKM","permalink":"https://beefyheisenberg.github.io/tags/PKM/"},{"name":"笔记","slug":"笔记","permalink":"https://beefyheisenberg.github.io/tags/笔记/"}]},{"title":"PKM.02|笔记分类法.PARA-and-IARP","slug":"51.Productivity/PKM.02.笔记分类法.PARA-and-IARP","date":"2024-01-24T01:27:53.167Z","updated":"2024-01-24T01:27:53.168Z","comments":true,"path":"51.Productivity/PKM.02.笔记分类法.PARA-and-IARP/","link":"","permalink":"https://beefyheisenberg.github.io/51.Productivity/PKM.02.笔记分类法.PARA-and-IARP/","excerpt":"P.A.R.AP.A.R.A 是一个通用且简单的数字资料分类方法 一个好的个人知识管理体系，应该可以支持并帮助你的工作，它应该让你在放置信息时准确知道放置的位置，以及在需要信息时能准确查找到信息的位置。 这个系统应该有如下特点：","text":"P.A.R.AP.A.R.A 是一个通用且简单的数字资料分类方法 一个好的个人知识管理体系，应该可以支持并帮助你的工作，它应该让你在放置信息时准确知道放置的位置，以及在需要信息时能准确查找到信息的位置。 这个系统应该有如下特点： 通用，能涵盖任何来源的任何信息 灵活，能够处理各种现在在做的和将来要做的项目和活动。 简单，无需超出最低要求的任何耗时维护、编目、标记或重新整理 可操作，与任务管理和项目管理方法无缝集成 跨平台，可与任何应用程序一起使用，包括已存应用在或未来的应用 以结果为导向，以支持交付有价值的工作为目的来构建信息 模块化，允许根据当前任务的需求隐藏或揭示不同级别的细节 机会主义，最好能够在已经完成的工作的基础上进行，而不是占用额外时间。 P.A.R.A. 代表项目（Projects）— 领域(Areas) — 资源(Resources) — 档案(Archives)，四个顶级类别， 包括您在工作和生活中可能遇到的每种类型的信息。 P：Project，有目标、有交付日期、会结束 A：Area of responsibility，是”需要一直负责和维护的活动领域”, 例如工作中需要持续关注的领域, 或者打算持续发展兴趣（健康/写作/营销等） R：Resource，是”持续感兴趣的话题或主题” A：Archive，存档，示例包括：已完成或非活动的项目;不再承诺维护的Areas;不再感兴趣的resources Area与Project：二者的区别是，项目有DDL或明确的结束的日期而Area没有，Project的里更多属于”可操作的”, Area里更多的是”不可操作的信息”。二者的联系：项目总是属于一个领域，例如: 参加马拉松是一个项目，而健康是一个领域 出版一本书是一个项目，而写作是一个领域 Area与Resource:Area（注意是 Are of responsibility）, 是您在生活中扮演的角色和您所负责的职位（配偶、母亲/父亲、团队负责人、足球教练）、您承担责任的现行标准（产品开发、公司通讯、法律），以及需要持续关注的事情（锻炼、财务、公寓、宠物）。Area 强调的是需要”负责的领域”，而Resource仅仅是”感兴趣的主题”, 这是二者的主要区分点。Resource 里可以是任何感兴趣的主题的文章、资料甚至代码片段。另外作者还提到自己私人信息也会放入Area，这样可以随时放心的分享Resource，例如体检报告、就诊记录放在名为“健康”的Area中，而Resource中存放的是运动、健康的有趣文章或者推荐的训练方案。 @ref: The PARA Method: A Universal System for Organizing Digital Information - Forte Labs PARA Part 2: Operations Manual - Forte Labs P.A.R.A. 是什么及在 Notion 中的应用 - 少数派 I.A.R.PI.A.R.P 是一组缩写，即： Inbox（收件箱）：我会将所有临时性的，还未消化的内容放置于此，定期来进行归档、整理或者删除。可以当做大脑的缓存，避免记录的时候纠结放在哪里。 Area（领域）：这是最重要的概念，即日常你需要精进的「领域」，比如健康就是一个领域，而跑步则是项目；写作是一个领域，而写一篇公众号文章则是一个项目； Resource（资源）：对应到卢曼的 Zettelkasten 方法中，更像是永久笔记。一般来说是兴趣、主题、资产等内容。注意是自己消化过的内容，而非机械的收藏。 Project（项目）：是指一个将要发生的独立事件，并且这个事件不是一次性就能完成的，至少需要多个动作才能完成。比如要写一本书，需要整理资料，罗列提纲，撰写内容，联系出版社。类似生活中还有组织一次旅游，录制一期播客等。 这里面最难的其实是 Area（领域） ，即你最关注的领域是什么。我们的一生中由许多事件构成。只是对于大多数人来说，他们其实并没有一个关于自己生活和工作的完整的项目清单。但是他们却会告诉你，有太多的事情要做。当这样忙忙碌碌多年以后，其实发现自己可能做了许多事，但是却「样样稀松」。这就是只有项目，而缺乏 Area（领域）聚焦带来的问题。 @ref: I.A.R.P: https://help.flomoapp.com/thinking/iarp.html","categories":[{"name":"51.Productivity","slug":"51-Productivity","permalink":"https://beefyheisenberg.github.io/categories/51-Productivity/"}],"tags":[{"name":"生产力","slug":"生产力","permalink":"https://beefyheisenberg.github.io/tags/生产力/"},{"name":"知识管理","slug":"知识管理","permalink":"https://beefyheisenberg.github.io/tags/知识管理/"},{"name":"PKM","slug":"PKM","permalink":"https://beefyheisenberg.github.io/tags/PKM/"},{"name":"笔记","slug":"笔记","permalink":"https://beefyheisenberg.github.io/tags/笔记/"},{"name":"分类法","slug":"分类法","permalink":"https://beefyheisenberg.github.io/tags/分类法/"}]},{"title":"PKM.02|笔记分类法.ACCESS","slug":"51.Productivity/PKM.02.笔记分类法.ACCESS","date":"2024-01-24T01:27:53.163Z","updated":"2024-01-24T01:27:53.163Z","comments":true,"path":"51.Productivity/PKM.02.笔记分类法.ACCESS/","link":"","permalink":"https://beefyheisenberg.github.io/51.Productivity/PKM.02.笔记分类法.ACCESS/","excerpt":"Folders or Links? The key to both is A.C.C.E.S.S. - YouTube Folders &amp; links can work together—not as an afterthought—but as a fundamental part of the design. A.C.C.E.S.S. helps you achieve a system to manage knowledge—and action—in the digital age. 视频中 Nick Milo 提出的 A.C.C.E.S.S. 笔记组织法： （1） Atlas，通常是笔记的 MOC（map of contents）/Dashboard/Overview 等… 作用：为笔记提供一个鸟瞰图，Maps to your world of knowledge （2） Calender，时间轴的视角（time-based），通常是每日笔记/会议纪要/计划(plan)/Review(回顾)/Journals 等… 作用：作为一种日志（Log）追踪 &amp; 回顾曾经感兴趣的（笔记）","text":"Folders or Links? The key to both is A.C.C.E.S.S. - YouTube Folders &amp; links can work together—not as an afterthought—but as a fundamental part of the design. A.C.C.E.S.S. helps you achieve a system to manage knowledge—and action—in the digital age. 视频中 Nick Milo 提出的 A.C.C.E.S.S. 笔记组织法： （1） Atlas，通常是笔记的 MOC（map of contents）/Dashboard/Overview 等… 作用：为笔记提供一个鸟瞰图，Maps to your world of knowledge （2） Calender，时间轴的视角（time-based），通常是每日笔记/会议纪要/计划(plan)/Review(回顾)/Journals 等… 作用：作为一种日志（Log）追踪 &amp; 回顾曾经感兴趣的（笔记） （3） Card，通常是 Ideas/Things/People/概念/状态等… （4） Extras，支持材料，通常是笔记附件/图片/手册/模板… （5） Source，资源，文章/书籍/论文/在线课程/Talks… （6） Space，空间，通常是一个“领域”，例如 Life/Work… 每个空间下又按“M.A.P.S”分类（maps、areas、project、support note） Nick Milo 还发布了一个 Obsidian 库来阐述 A.C.C.E.S.S. 的使用： LYT Kit 7 - NEW Version Sep 13th! - Share &amp; showcase - Obsidian Forum About LYTIf you want to take notes that compound in value over your lifetime, it’s not enough to rely solely on direct links, tags, and folders. In the Age of the Linked Note, we have access to powerful thinking tools. The LYT System explores how to use Fluid Frameworks like MOCs (Maps of Content) and a Home note to elevate your thinking today—and years from now.","categories":[{"name":"51.Productivity","slug":"51-Productivity","permalink":"https://beefyheisenberg.github.io/categories/51-Productivity/"}],"tags":[{"name":"生产力","slug":"生产力","permalink":"https://beefyheisenberg.github.io/tags/生产力/"},{"name":"知识管理","slug":"知识管理","permalink":"https://beefyheisenberg.github.io/tags/知识管理/"},{"name":"PKM","slug":"PKM","permalink":"https://beefyheisenberg.github.io/tags/PKM/"},{"name":"笔记","slug":"笔记","permalink":"https://beefyheisenberg.github.io/tags/笔记/"},{"name":"分类法","slug":"分类法","permalink":"https://beefyheisenberg.github.io/tags/分类法/"}]},{"title":"PKM.01|我的笔记系统实践","slug":"51.Productivity/PKM.01.我的笔记系统实践","date":"2024-01-24T01:27:53.157Z","updated":"2024-01-24T01:27:53.158Z","comments":true,"path":"51.Productivity/PKM.01.我的笔记系统实践/","link":"","permalink":"https://beefyheisenberg.github.io/51.Productivity/PKM.01.我的笔记系统实践/","excerpt":"@tag: #PKM #知识管理 #Zettelkasten #卡片盒笔记法 #Luhmann @link: PKM.03.什么是卡片盒笔记法 sspai链接： https://sspai.com/post/75940 01.从这里开始","text":"@tag: #PKM #知识管理 #Zettelkasten #卡片盒笔记法 #Luhmann @link: PKM.03.什么是卡片盒笔记法 sspai链接： https://sspai.com/post/75940 01.从这里开始目前我在用的笔记系统，用一句很简单的话概括就是：本地markdown文件 +Dropbox网盘同步，同时用 Vscode 项目把整个笔记目录管理起来。 大概几年前，我正在 Evernote 、有道云笔记、OneNote之间反复横跳。当时还没有 Notion，也没有RoamResearch，甚至PKM（个人知识管理）都很少有人提及。 最后还是选择了本地 Markdown这种“看似不便”的方式，毕竟原生的 Markdown有种种缺点（图片管理、没有 Metadata、不支持复杂排版），本地文件的方式摆脱不了树状文件夹的笔记结构… 甚至在当时缺少非常顺手的编辑器。但这些年修修补补也一直用下来了，上面提到的种种缺点也都改善或规避，期间也尝试过 Notion、RoamResearch、Logseq，但这种 “基于本地 Markdown”的笔记一直都是我的笔记系统基本盘。 这种方案的好处是： 数据完全属于自己，Dropbox网盘 + 自己写的定时脚本备份到 Git ，双重措施可以确保笔记不会丢失，也能通过 Git的历史追溯修改历史、查看笔记系统的生长过程； 最好的同步体验（Dropbox） + 最好的现代编辑器（Vscode）：Dropbox的多设备同步近乎实时，并且增量同步非常适合 Markdown 这种轻量文本，如果上网不便可以用坚果等其他同步盘替代，如果你用 苹果全家桶且能忍受 iCloud Drive的同步1，它也是可以的 。至于最好的编辑器…. 还是看个人习惯吧，现代的编辑器诸如 Sublime、Atom，以及 编辑器原旨主义宗教继承人 NeoVim、Spacemacs… 它们都非常棒，这些 「Code Editor」 功能大同小异，看自己习惯和信仰； 除了传统编辑器，笔记文件库还可以用多种软件打开：如果要书写体验可以用 Typora（我现在正用 Typora 写这篇文章），如果需要双链的鸟瞰图可以用 Obsidian（借助 Obsidian的双链实现网状结构），同时也有基于文件夹的树形结构。在网状结构笔记大行其道的今日，树形结构依然是人类的对知识的最佳认知结构2。 Markdown是一种“源文件”，可以转换为各种格式输出。我会把笔记通过 Hexo生成博客（需要一些脚本做 Markdown的转换，例如修改图片路径适应Hexo的目录3，从而实现 笔记到博客的一键发布），这种“笔记即发布为博客”也是一种 数字花园4的实践，我的笔记公开部分放在了gitee上。此外，使用 pandoc 将 Markdown 导出为PDF、PPT、DOC等等格式应付各种场合，「一处写作，多处发布」。 当然 “本地 Markdown 文件”这种方案也有一些不便： 块引用：Vscode 和 Obsidian都已经支持了使用#标题作为块引用的最小单元（例如[[笔记名字#标题名]]这样 ） ，但不能支持更细粒度的块了， 相比较 Logseq 和 RoamResearch等等都支持的“行级别的块引用”； 缺少好用的移动端（iOS/Android），不过我在手机上很少直接编辑笔记，如果有突然的想法我会记录到 Drafts，所以对于手机端的要求是方便查/阅： 如果你用 Dropbox同步，1Writer（Android ） 、MWeb（iOS）、Editorial（iOS） 都可以； 如果你用 Git同步，Working Copy （iOS）是我的第一选择，Noteshub作为替补（iOS） 图片管理：早年的 Markdown编辑器贴图很麻烦， 但借助插件和更新的编辑器，无论 Vscode 或者 Obsidian 都支持使用Ctrl+v的傻瓜方式贴图，和富文本编辑器相比，对图片的使用已经不那么麻烦了。我把图片存储在项目下的image文件夹，用dropbox一起同步。好处是笔记无论搬到 Git 还是 Hexo博客，这些都能很好的支持本地图片，也不担心图床失效的问题。 Markdown的表达能力的缺陷： 没有Metadata：比如 Evernote的笔记里还记录了 创建位置、修改时间等等Metadata的， 虽然说修改时间也能从文件属性里读出来，但如果换新电脑or 移动一下文件夹这个时间戳就失灵了。Markdown 的话只能通过 YAML Front Matter 存储这类信息，但这玩意不属于原生语法，各家App 的支持也不尽相同，会造成显示的混乱。 不支持复杂排版，例如双列、图文混排等等样式。公平的说，复杂排版本来就不是 Markdown 该做的事情，Markdown 实现的是易记且便于书写的标记语言，换个角度说，支持复杂排版的标记语言写起来一定不方便（诸如 LaTex、HTML等等）。当然实现图片排版可以通过往 Markdown 里加一些 HTML 来支持，例如 Obsidian的主题 Blue-Topaz 提供了类似的功能，但我不用，这些不是原生的 Markdown 语法，可能这个 App 里支持但换另一个 App 就不识别了 关于云笔记服务的数据安全多说几句，大厂的笔记产品，虽然有靠谱的技术保证服务稳定性，但也有潜在的不便： 内容审核：国内大厂头上的达摩克利斯之剑，具体可以参考金山删除用户文档的事儿，以及早年的坊间传闻“百度云和谐了我的正常视频！”，为什么是传闻，因为没人能拿出证据证明视频的清白🤓 产品生命周期：我也在BAT工作过，了解一个产品的出生到下线整个过程和决策，大厂产品也会有下线的那一天。当然下线前会给用户充分的迁移时间，but， 迁移也是成本！。此外，国外大厂也好不到哪儿去，比如Google 关闭过的一众服务（Reader、Picasa、Wave等等…），以及因为服务条款变更而关闭国内服务等等（Yahoo就是你！） 02.笔记的目录结构 我的笔记系统有6个目录（如上图），分别存储不同的笔记： ① Inbox/：临时笔记，很多情况下一篇笔记不会立刻写完，可能需要几天的酝酿和资料收集，在这一阶段的笔记存储在这里，进一步组装和成型。每天我只需要关注这里就可以想起最近在学哪些东西； ② Project/：项目笔记，“万事皆可当项目！”，除了我们的工作，其他的个人事务也可以用项目管理的方式：有最终目标、有最终完成时间（DDL）、有阶段性时间和关键成果（KP）。项目笔记的特点是：没有过多的知识性信息，大都是时间点和具体操作； ③ Personal/：带有个人信息的笔记，例如一些账单、体检报告、会员卡号、甚至旅行箱密码等等… 这里存储的更像是“备忘录”而非“知识性笔记”。把这部分单独存放的好处是，当要分享自己的笔记时，我可以很放心的分享另外几个笔记目录，这是一种信息隔离的思想； ④ Code Primer/： 永久笔记1（专业知识的笔记放这里）。题主是一个程序员，从编程语言、架构设计、中间件、大数据等等都有涉及，这个目录下的笔记数量是最多的，子分类也是最多的。后面会说这部分如何分类； ⑤ Scriptorium/：永久笔记2（专业知识之外的关注），比如作为一个喜欢文史哲的码农，这个文件夹下面有生产力工具、财经、摄影、流行文化、心理学和哲学等等.. ⑥ Archive/： 归档，对于上面1/2/3/4不再感兴趣的、长期用不到 或者不再维护的，都丢这里； ▷ 关于 2.Project 和 6.Archive 的分类：是参考了 P.A.R.A 分类法5，但没有完全照搬，只采用了两个原则，1有时间节点的是项目，应该独立出来，2不再有兴趣不再维护的资料放入归档。另外，P.A.R.A 的提出者还提到自己私人信息也会放入Area，这样可以随时放心的分享Resource，“例如体检报告、就诊记录放在名为“健康”的Area中，而Resource中存放的是运动、健康的有趣文章或者推荐的训练方案”。 ▷ 对于“闪念笔记”，我是不放入这套笔记里的，我会在手机上用 Drafts 记录下来，然后 闪念笔记 要每天清空一次，有保留价值的会稍加整合放在 “①Inbox”文件夹下继续组装和完善，无保留价值的闪念笔记直接删除（像一些无价值的呓语和仅仅带有情绪抒发的碎碎念，是无继续写的价值的）；用完的闪念笔记也可以不删而是归档，这样在 Drafts的归档里还是可以保留时间序的碎片的。 ▷ 上面提到的 ④ 和 ⑤ 都是一个独立的 Obsidian库，为什么作为知识积累的永久笔记，不放在一个文件夹而是分开？ 原因一是 如果合并，子目录就会太多，不便管理；并且 ④ 和 ⑤ 中的笔记几乎没有互相引用，所以分为两个库（ Obsidian 管理引用链接的范围是库，库外的文件无法引用，属于不同库的笔记是“引用隔离”的 ） ▷ 关于临时笔记（Fleeting notes）、永久笔记（Permanent notes）的概念：参考了Luhmann 的笔记分类 。但我的笔记里没有“文献笔记（Literature notes6）”这一类， 对于文献的记录和总结，我习惯都放永久笔记。这个视个人分类习惯而定，有时候把类型分的太细致反而阻碍写作的积极性。 ▷ 永久笔记并不“永久”：永久笔记也在一直被更新和完善，拆成小文件、合并成大文件、增加引用链接等等。这也正是 Andy Matuschak 在常青笔记中的描述：“常青笔记的编写和组织是为了随着时间的推移不断进化、贡献和积累”，卢曼提到他的卡片盒笔记是内生长(internal growth)7的。 ▷ 关于永久笔记奇怪的命名： “Code Primer” 来自于我的编程启蒙书《C++ Primer》， “Scriptorium”意为缮写室，中世纪制作书籍的地方8 03.永久笔记的结构上面提到了两个永久笔记目录，如下图，左边是专业知识的笔记，右边是兴趣爱好的笔记： 笔记结构和格式有一套守则： 每篇笔记的格式，遵循“原子笔记”：即一篇笔记说明白一件事情。 但是不强制要求每篇笔记都是“原子”的。 当我们刚涉及一个领域时，可以只从一篇记录开始，这时候笔记中各种信息可能混杂在一起，并不“原子”。随着对这个了领域的深入，笔记的内容也会不断增加，同时对这个领域也有了初步了解，知道大概如何归类了，那这篇可能会被拆分开。 常青笔记9中提到，笔记是生长的，一篇笔记不仅可以添加内容、当然也可以再拆分、以及与其他笔记建立引用，总之让笔记体系变成更充实、更合理的形态，这样的笔记是具有生长性的。 一篇完整的原子笔记应该包括：唯一标识、正文（自己的理解，避免复制粘贴）、参考文献列表 分类文件夹只有一级，不建立二级分类文件夹：如果某个文件夹下的笔记非常多，不得不建立二级分类的时候，我的选择是仍旧新建一级文件夹，例如 📂 11.Programming-Language 文件夹下是编程语言的笔记，因为我一直都在用Java，所以Java相关笔记的积累也非常多了，这时并不在 📂 11.Programming-Language 的下层再建立子文件夹，而是与之平级建立了📂 12.Java文件夹。 虽然听起来不符合“分类的层级”的常识，但是好处也很明显： 可以避免树状结构太深，笔记被藏在很深的文件夹里容易被遗忘。对于树形的层级结构，思考 “我应该把笔记放在哪个层级下面？” 也是一种思维消耗，分类强迫症患者们会因此陷入到不停的分类工作里； 文件夹带数字前缀，让显示顺序符合自己的需求，同时也方便目录的扩展，父类别的子类可以从1a扩充到1a、1b… 它们依然有序 这套带序号的文件夹分类参照自杜威十进制分类法10，同样可以套用到 Evernote、Cubox、Zotero等等其他软件中，包括知乎收藏夹、浏览器收藏夹等等，这样自己所有的资料都用一套命名体系，很方便； 这种平铺单层文件夹更像卢曼的卡片盒，没见过卢曼用大盒套小盒吧，小盒套小小盒吧？ 但是如果确实需要树形结构怎么办？看下面的文件命名规则 笔记文件的命名：文件名加类别前缀，例如Java.03b.GC案例分析.md 这样一个文件名。可能有人会问，父文件夹名字叫12.Java，文件名里就不用以“Java”开头了吧？这样文件名里的“Java”是冗余信息啊。其实这里是特意而为，有个具体操作案例：Vscode里有个“文件名模糊搜索”功能，快捷键“Cmd + P”，我只需要搜索“Java GC”，这样文件名里带“Java”和“GC”的所有笔记都会被搜出来，当然 Obsidian里也有类似功能，快捷键 Cmd + O。文件名的构成里除了表意的前缀，接下来还有序号，作用也是为了让相关联的笔记排序能凑在一起，同时递也方便笔记的“生长”，例如一个笔记内容太大需要拆分成2个笔记，新笔记的序号从1递增到1a即可，如果1a笔记又变大需要拆分，增加1b笔记即可。这些从一个笔记拆出来的众多子笔记，依然是保持有序的； 图： 左边是 卢曼的笔记编号系统说明（笔记是如何通过前缀保持有序增长的），右边是我的笔记编号：上图说明了通过卢曼的编号体系，如何在同一层笔记中表示不同的层级关系： 第一层概念：0 → 1 → 2 → 3， 这几个笔记是平级的概念 当“笔记1”有了子类别：1 → 1a → 1b，其中1a、1b都“笔记1”的子笔记，若1a也有了子笔记，就用1a1、1a2继续。 通过这种命名方式组织笔记，文件夹下面的所有笔记看起来都“平铺”了，但仍可以通过文件名表达出分层的关系，也不会出现“深藏在某个子子子文件夹中的笔记”这种问题了。wiki百科里详细说明的这种方式 https://en.wikipedia.org/wiki/Zettelkasten, 卢曼的 Communicating with Slip Boxes by Niklas Luhmann 卢曼把上面的编号构成的“层” 成为slip（滑道） “不过早对知识进行分类”，这也符合学习的习惯，刚开始接触某个领域可能只有一篇笔记，我们也不知道这个领域改如何分类，所以开始就不要想“刚开始就把笔记放在合适的分类层级上”，当随着学习的深入，笔记逐渐变大，这时候自然会拆分出新的子类别，让笔记“自然的生长”。 Markdown 中的章节是用# Heading来划分的，对于 Heading 的命名也有技巧，Vscode 里支持一种“Symbol 搜索”，Symbol 是什么呢？ 对于代码，Symbol 可以理解为函数名字，这个功能可以方便的在一个大的代码工程里快速搜索某个函数。Vscode里把 Markdown 的 Heading（标题） 当做 Symbol，所以在 Vscode里 按 “Cmd + T”，也可以进入 Markdown 标题的模糊搜索，快速定位 Heading。相对于上面的“文件名模糊搜索”，“标题模糊搜索”提供了比文件级别更细粒度的检索。至于如何用好这个功能，这就要求我们在书写笔记的时候，对 Heading的命名用一些心思了，要“言之有物”。除了Vscode，像Atom、Sublime 等一众现代编辑器都有这个功能（标配），而 Obsidian 则需要通过插件 obsidian-switcher-plus11 来实现。 双链引用：笔记的引用我用Obsidian 提供的[[ ]] ，Obsidian 默认是用 文件名作为链接名的，同时也提供对文件内的 Heading作为引用块，例如 [[文件名.md#标题名]]，如果修改文件名、或者拆分合并笔记，我就不用Vscode了，而是在 Obsidian里操作，让Obsidian 帮我自动更新引用。 笔记建立引用要克制，只有「笔记A」真的需要引用到「笔记B」的时候才建立两篇笔记的连接，“必要时”才链接，这也符合笔记“自然生长”的概念。本来网状结构也是一种 MOC（map of content），帮自己理清思路的，胡乱建立双链是在毁掉自己的笔记系统，就像无章法的标签体系——最后只能废弃。这不叫自然生长，这叫胡乱配对； 标签：我不太用标签，也不强制标签的规则。但有个原则：如果通过文件夹已经是“明确的一个类别”，就不需要用这个类再建立标签了，这属于冗余信息。例如上面提到的，已经有了Java文件夹，就没必要再建立“Java”标签了，但“Java”表示不了的子分类，例如 Java下面还有更细的子类别：JVM、ClassLoader等等，这些倒是可以建标签 枢纽笔记：“除了索引表，卢曼还有另外一种非常重要的笔记：枢纽笔记(hub notes)12。枢纽笔记中列出了许多其他同属于某个主题的其他笔记”。说白了枢纽笔记就是一个索引，指向一组某主题的笔记。在 Obsidian 的 关系图谱里，枢纽笔记是一个中心化的节点，它本身没多少信息，只起一个索引的作用。但文件夹分类默认已经起到相同的作用了，每个文件夹下自然就是一个专题，所以对于这种情况就没必要建枢纽笔记，除非笔记跨了文件夹。对于这类枢纽笔记，我都放在📂 _index文件夹中，在 Obsidian 的 关系图谱中，枢纽笔记向外的连线会很多，让整个图谱显得杂乱，这时候可以在图谱设置里排除掉这个 📂 _index文件夹（语法-path:_index），让关系图谱清爽一些。除了按“某个主题”索引的枢纽笔记，也可以有按“时间线”索引的枢纽笔记，可以方便的看“我这个月记了什么”，当然这种笔记也不是一定要有的，看自己需求，同样也是放在📂 _index文件夹； 至此，我的笔记体系的规则说完了，为什么要给自己的笔记格式立那么多规矩？ 不累么…无论树状结构、网状结构、或者标签体系，如果管理不好最终都变垃圾场。还记得当年第一个笔记 App里加过的标签吗？ 现在看都不会再看一眼吧。 03a.为什么用这样的笔记结构综上，我的永久笔记的结构是：“单层目录的矮树状结构，同时使用双链构成稀疏的网状”。 至于为什么用这样的结构，还是要从传统的树状结构 和最近时兴的网状结构比较说起。 03a1.网状结构 vs 树状结构像 RoamResearch、Logseq 这些笔记似乎已经完全放弃了目录，完全采取完全平铺的方式，通过网状结构展示各个笔记的关系，在笔记系统中，网状结构的特点： 便于发现不同知识点的潜在联系，可以打破固有的树形概念结构，跨领域寻找联系； 创造和寻找灵感，发现新的研究方向； 劣势1，在树型层级中，我们很清楚知道两个节点表示上下级关系，但是在网状结构里，无法表示这种父子关系，仅仅知道二者“有关系”，这是纯网装结构在表达上的一种语义丢失。 Notion、OneNote、Evernote、Trilium依然采用传统的属性结构，不同的是 EverNote的“文件夹”就是个“真文件夹”，什么信息都不能存储，而 Notion 的无限层级结构里，每个节点都是可以存储信息的。除了笔记之外还有思维导图，也算是树状拓扑结构，总结一下树状结构的特点： 在学习过程中，树状层级有利于理清概念，通过层级关系，我知道概念A是上义或整体性概念，概念B则是下义或更细小的概念； 树状分类方便检索，树状的生长方向是单向的，总是从“更上层的父级概念” =&gt; “子概念”，这种单向也方便概念的回溯（相比较而言，网状的方向的可能性就太多了） 树状结构的劣势1，所有新建的笔记都要思考一个问题：我要把它放哪个概念层才更合理？尤其对于刚刚开始入门的领域，上来就思考怎么分类是本末倒置的，当对这个领域逐渐掌握和熟悉，自然会知道“它属于哪儿” 树形结构的劣势2：严格的树形目录无法表示“一个笔记同时属于多个主题文件夹”的情况，如下图，这样用引用可以解决：“笔记1a”还是在“类别1”下面，但从“类别2”到“笔记1a”建立一个引用 不好的例子1：过于繁杂的树形结构，笔记很容易被遗忘在很深的目录中（试想这种情况下，当我们回顾笔记的时候，需要一层层打开目录，也不知道下一层还有什么），另外“分类再分类”也是一种心智负担： 不好的例子2：这样的网状结构，不是有效的MOC（Map of Content），这是细菌培养皿： 03a2.结论是：两种结构我都要树状结构便于检索和理清概念层级，很像我们理解知识的过程；网状结构可以打破固有的层级结构，发现不同领域和层次知识间的联系，同时网状拓扑的建立也像新学习某个知识的过程。这两种结构对于笔记体系都是有帮助的，所以都要。 同时通过上面不好的案例，我们发现，树状和网状的劣势都始于 用力过猛：比如过深的树状文件夹，比如迷宫一样的网状链接。所以，回到 03a这一章节的开始：我的永久笔记这部分的结构是 “单层目录的矮树状结构，同时使用双链构成稀疏的网状” 04.其他使用技巧 笔记除了书写，更多的使用场景是阅读，如果是在电脑上，我会用 Chrome 直接打开笔记目录，这里还需要一个 Chrome扩展：Markdown Preview Plus，可以把 Markdown 预览出来，支持多种主题。还支持 TOC 大纲，笔记的结构一目了然 笔记里我还会用一些“注解”，就是一些特殊语法，来帮助检索，比如如果我引用到了其他网页，会加 @ref标注一下，例如 @ref: [巧用分类法解决使用卡片笔记时遇到的困境](https://sspai.com/post/71274)，这样有什么好处呢，比如我想统计我的整个笔记库有多少网页引是来自sspai的文章，可以用 Shell命令行，在笔记根目录执行grep -irn &quot;@ref&quot; **/*.md | grep &#39;sspai&#39; | wc -l： 同样双链的[[ ]]也可以这样搜索：egrep -irn &quot;\\\\[\\\\[.+\\\\]\\\\]&quot; **/*.md 此外，我会用其他的注解，例如 @todo =待办，@toc =内容大纲，@tldr=笔记精要… 等等，这些注解都不是标准的 Markdown 语法，这样写只是为了让自己的笔记有统一的格式，以及检索方便，因为 Vscode 的搜索都是基于单行的。 05.最后关于 #PKM (个人知识管理)，这个话题很大也很难用几篇文章说清楚，个人的知识管理体系可能终生都在更新迭代。除了笔记还包括工作流、文献管理等等太多的话题，这里只写一点跟“笔记”相关的，抛砖引玉。 1.iCloud Drive的同步问题：如果发生了同步冲突，iCloud Drive的默认做法是存为一个快照，但并不通知用户发生了冲突，这会导致冲突的内容被吞掉了。对比 Dropbox的做法是生成一个“xxx的冲突版本”文件，提示让用户自己合并。显然 Dropbox的做法更适合做严格的文档同步器 ↩2.MIT 认知科学家Joshua B. Tenenbaum 发表在PNAS 的论文中，比较了抽象知识的不同表征结构，如星形结构、聚类结构、环形结构等等，最终还是意识到人类的最佳知识结构是树形结构： The discovery of structural form | PNAS ↩3.Hexo要求引用图片路径是绝对路径，我的笔记中引用图片用了相对路径，需要通过sed进行批处理转换：这是脚本 Gist：https://gitee.com/beefyheisenberg/codes/6oetg9d8mu3qh45fnvwzl79 ↩4.什么是数字花园（Digital Garden）？ - 知乎 对数字花园做了很好的诠释：“数字花园是介于笔记应用和博客应用之间的半公开数字展览馆，半公开指的不是读者没有权限阅览，而是很多想法只是相互关联的半成品，令他人难以轻易看懂。因为数字花园降低了对内容的要求，不强求作者将所有内容都打磨成文章级的成果，数字花园就会鼓励作者产出更多的内容，不拘一格降笔记”。 ↩5.P.A.R.A. 四个字母分别代表 项目（Projects）— 领域(Areas) — 资源(Resources) — 档案(Archives) 四个顶级类别， 包括您在工作和生活中可能遇到的每种类型的信息。例如 Project类别的特点是有目标、有交付日期、会结束；Area 类别则是&quot;需要一直负责和维护的活动领域&quot;，例如工作中需要持续关注的领域，或者打算持续发展兴趣（健康/写作/营销等）。Forte上的原文链接：The PARA Method: A Universal System for Organizing Digital Information - Forte Labs ↩6.卢曼的文献笔记样例和使用： Luhmann’s Literatur Note Examples — Zettelkasten Forum ↩7.卢曼提到卡片盒笔记是内增长的（internal growth）：Communicating with Slip Boxes by Niklas Luhmann ↩8.赫尔博斯说：“天堂是图书馆的模样”， 《缮写室》中说 “天堂是缮写室的模样” ，作者在外公那阴暗、并不宽绰的书房里遇到了各类文学作品。她将这里比喻为生命中的第一个缮写室（缮写室是欧洲中世纪制作书籍的场所） ↩9.常青笔记 的概念来自Andy Matuschak的笔记： Evergreen notes ，Andy本人可能在Obsidian上发布了常青笔记，将上面的笔记转为了 Obsidian库：https://publish.obsidian.md/andymatuschak/Start+Here, 也可能是Anthony Gold获得授权后转置的 ↩10.杜威十进制图书分类法百度百科 ↩11.使用Obsidian 插件 switcher++实现 Vscode的符号搜索： 我给了快捷键 Cmd + R，呼出搜索框，直接是文件名模糊搜索， 输入@触发当前文件内搜索Heading, 输入#触发全库内搜索Heading ↩12.对卢曼的“枢纽笔记”的说明： The Money Is in the Hubs: Johannes Schmidt on Luhmann’s Zettelkasten • Zettelkasten Method ↩","categories":[{"name":"51.Productivity","slug":"51-Productivity","permalink":"https://beefyheisenberg.github.io/categories/51-Productivity/"}],"tags":[{"name":"生产力","slug":"生产力","permalink":"https://beefyheisenberg.github.io/tags/生产力/"},{"name":"知识管理","slug":"知识管理","permalink":"https://beefyheisenberg.github.io/tags/知识管理/"},{"name":"PKM","slug":"PKM","permalink":"https://beefyheisenberg.github.io/tags/PKM/"},{"name":"笔记","slug":"笔记","permalink":"https://beefyheisenberg.github.io/tags/笔记/"},{"name":"卡片笔记","slug":"卡片笔记","permalink":"https://beefyheisenberg.github.io/tags/卡片笔记/"}]},{"title":"PKM.00|个人知识管理-索引","slug":"51.Productivity/PKM.00.Index","date":"2024-01-24T01:27:53.153Z","updated":"2024-01-24T01:27:53.153Z","comments":true,"path":"51.Productivity/PKM.00.Index/","link":"","permalink":"https://beefyheisenberg.github.io/51.Productivity/PKM.00.Index/","excerpt":"相关笔记：Meditations / Thinking-知识管理 @tag: #_Index 开始：PKM 的定义，包括什么中文wiki 个人知识管理 - 维基百科，自由的百科全书","text":"相关笔记：Meditations / Thinking-知识管理 @tag: #_Index 开始：PKM 的定义，包括什么中文wiki 个人知识管理 - 维基百科，自由的百科全书 个人知识管理（英语：Personal Knowledge Management，简称PKM）是指个人对知识的搜集、分类、存储、索引等一系列过程。通过这个过程实现对个人行动更好的指引。个人知识管理反映了知识工作者对于个人学习和成长的诉求，属于信息学、知识管理的范畴。 搜索引擎出现之后，知识的本体记忆变得不那么重要，而快速搜集资料并内化学习的能力越来越成为学习者的重要技能，这种技能就属于个人知识管理（PKM）。 英文wiki 个人知识管理 - 维基百科 个人知识管理( PKM ) 是一个收集信息的过程，人们在日常活动中使用这些信息来 “gather, classify, store, search, retrieve and share” （收集、分类、存储、搜索、检索和共享知识）( Grundspenkis 2007 ) 以及这些过程支持工作活动的方式 ( Wright 2005）。这是对知识工作者需要对自己的成长和学习负责的想法的回应（Smedley 2009）。它是一种自下而上的知识管理(KM) 方法（Pollard 2008）。 目前尚不清楚 PKM 是否仅仅是围绕个人信息管理(PIM) 的新包装。 01工作流施工中 // 下面要写的注意区分“写作”和“学习”，二者可能有不同的工作流 开始 Read it Later （Cubox，Safari的”阅读列表”，Pocket(已经很少使用)，甚至微信的群聊） 闪念笔记 （Drafts） 处理 阅读&amp;学习 （SQ3R） 初步笔记 （Inbox） 知识回顾和内化 =&gt; 永久笔记 （Obsidian） 02笔记系统=&gt; @link: PKM.01.我的笔记系统实践 03学习法学习方法： 研究如何将知识内化的方法论，费曼学习法/SQ3R/SQ5R… =&gt; @link: 高效学习法 归档Part.1已整理至 [[PKM.01.我的笔记系统实践.md]] 我在用的解决方案: 笔记: 一句话概括，基于本地Markdown + 网盘同步，编辑使用VsCode/Atom/Sublime/Typora 优点: 数据完全属于自己，不用担心产品停止运营(经营不善)，退出中国市场(Google/Yahoo) 基于本地文件，很方便的使用网盘(Dropbox &gt; 坚果云 &gt; iCloud)同步 基于本地文件，很方便的使用Git同步，以及发布到支持Git Page的博客(Hexo等) 支持多种格式的导出，使用pandoc导出为各种格式(PDF/DOC/HTML等) 综上，「一处写作，多处发布」 打开的自由度: 比如在Chrome 里阅读，和网页没什么不同，网页打开的优点是 对于一个长网页，浏览器可以打开两个完全一样的窗口，但很多笔记App不支持同一篇笔记在两个窗口打开 使用专业文本编辑器(VsCode..)的强大功能 // 正则搜索,多行编辑,”Symbol”搜索 或者使用Typora这类支持“WYSIWYG”所见即所得、注重书写体验的编辑器 对于双链功能的支持，使用Obsidian打开笔记目录即可 (因为Mkd的表达能力，双链的最小支持单位，一般叫做”Block”，只支持文件级和”#”标题级) 缺点: Markdown表达能力的不足，不支持复杂一点的排版(例如OneNote..) 笔记无法记录复杂一些的metadata（创建时间、修改时间、创建地点等），不过可以通过YAML Header解决 基于网盘 or git同步，没有现成的移动端App，解决方案如下: 基于Git: WorkingCopy 基于Dropbox: Editorial，1Writer，Mweb 基于iCloud: 直接使用 iA Writer..等即可 基于坚果云: 直接使用坚果云网盘的Mkd预览功能 笔记原则: 每篇笔记做到“原子化”，即每篇笔记阐述明白一个问题。如果写作过程中，发现笔记越写越大， 笔记的Link“克制化”，只有「笔记A」真的需要引用到「笔记B」的时候才建立两篇笔记的连接，胡乱建立双链是在毁掉自己的笔记系统（Obsidian-find-unlinked-files这种插件就是多余的） 笔记还是传统的文件夹进行分类，每个文件夹是一个“一级分类”，比如哲学、心理学、文化艺术、健康等…… 规定“一级分类文件夹”下面不能再有子文件夹。不使用过深的文件夹也不必纠结分类的层级，因为层级过深的笔记会被遗忘 文件的命名，使用二级类别-三级标题-笔记标题的格式，当然这么多层级不是必须的。这样命名的好处是，只要按文件名排序，笔记就自动“聚类”排列了。另一个实际操作的便利是，在VSCode里按下cmd+p （文件名模糊搜索），我可以输入二级标题就可以列出相关的笔记，输入三级标题同样 当对一个领域的知识了解更加全面时，原来一个“一级分类”的文件夹不够用了，需要更细的分类。我的做法是，拆分。例如原来一个文件夹叫“亿级流量架构设计”，随着笔记类别的增多，这个文件夹分成两个更细粒度的文件夹“缓存设计”和“消息队列”，原来的“亿级流量架构设计”文件夹就没了，保证“库跟目录-分类目录-mkd文件”这种单层文件夹结构 笔记内的#标题也提供了一种层级，我只在永久笔记（Permanent notes）里使用#，这样的一个方便之处是，VSCode、Atom会把 mkd的标题解析为 Symbol，按下cmd+T（VSCode） 或者 cmd+R（Atom）可以在整个库模糊搜索 mkd的标题1 标签：用的时候也要克制，原则是“标签”的范围必须小于“文件夹”，例如“哲学”文件夹下面的 mkd文件，tag可以是“欧陆哲学”、“存在主义”等等，但不允许再出现“哲学”这个标签… 很多人的笔记系统用不好标签是因为没有提前规划，导致各种层级的标签都有。做个比喻，一个笔记库是一棵树的话，一级分类文件夹是主要枝干，一篇笔记是细小的枝干，Tag只能用来标记树叶，而不能标记枝干 @tag: #PKM #知识管理","categories":[{"name":"51.Productivity","slug":"51-Productivity","permalink":"https://beefyheisenberg.github.io/categories/51-Productivity/"}],"tags":[{"name":"生产力","slug":"生产力","permalink":"https://beefyheisenberg.github.io/tags/生产力/"},{"name":"知识管理","slug":"知识管理","permalink":"https://beefyheisenberg.github.io/tags/知识管理/"},{"name":"PKM","slug":"PKM","permalink":"https://beefyheisenberg.github.io/tags/PKM/"},{"name":"笔记","slug":"笔记","permalink":"https://beefyheisenberg.github.io/tags/笔记/"}]},{"title":"开源项目源代码阅读指北","slug":"41.Uncategorized/开源项目源代码阅读指北","date":"2024-01-24T01:27:52.983Z","updated":"2024-01-24T01:27:52.984Z","comments":true,"path":"41.Uncategorized/开源项目源代码阅读指北/","link":"","permalink":"https://beefyheisenberg.github.io/41.Uncategorized/开源项目源代码阅读指北/","excerpt":"本文参考 @ref: Jaison - 阅读开源项目源码的建议姿势 先选择合适的源码版本需要先审视自己的需求：“我阅读源码，是单纯的为了学习？还是希望在业务系统中更好的用好它？” 如果是前者，那完全可以选择最新发布或待发布的稳定版本。 如果是后者，则需要选择自己业务系统中正在使用的版本。 快速了解架构和关键特性","text":"本文参考 @ref: Jaison - 阅读开源项目源码的建议姿势 先选择合适的源码版本需要先审视自己的需求：“我阅读源码，是单纯的为了学习？还是希望在业务系统中更好的用好它？” 如果是前者，那完全可以选择最新发布或待发布的稳定版本。 如果是后者，则需要选择自己业务系统中正在使用的版本。 快速了解架构和关键特性如果有介绍原理的书籍，可以先快速浏览一遍，粗略了解整体架构、关键特性，同类、相似产品性能比较。这些信息也可以从官方资料中一探究竟，尤其是架构介绍相关的章节。 快速试用官方资料中的“Quick Start”章节，先学习如何使用，加强自己对于整体项目的感性认识。基本能摸清楚利用该项目“能做什么”，以及“如何做”。当然，这里仅仅涉及了最基础的功能。学习一个特性要从了解配置和如何使用着手，同时建议阅读相关特性的设计文档或网上已有的源码解析文章，这样可以在阅读源码时避免分散精力去看无关紧要的部分。 开始阅读简单了解代码模块结构快速了解源码的模块组成结构，以及每一个模块的主要作用。这样有助于从源码结构上把握整体项目的结构，而后选择最基本的流程入手。 避免过早陷入旁枝末节摸清主线，避免过早陷入一些旁枝末节，我们在刚开始阅读源码时，会遇到很多”好奇点”： 这个算法居然实现的如此神奇？ 这个数据结构怎么没有见过？ 这个参数是干嘛的？ 我自己也时常经不起这些”诱惑”，陷于对这些细节的考究中，常常”离题”半天以后，才被拉回到主线中。在阅读源码的时候，能遇到一些感兴趣的细节是好事，但建议先将这些细节点记录下来，等过完整体流程以后再回头看这些细节，避免过早陷入。 工具、时序图、日志和Debug 借助合理工具。阅读源码过程中，通常需要动手做一些测试，此时，可以借助jstack工具(针对Java项目)，它能为你提供如下有价值的信息： 线程模型 调用栈: 调用栈信息可以帮你理清整体调用流程(另外，在定位问题时，jstack打印出的信息也时常可以发挥重要作用)。 重视阅读日志信息: 在进程启动或运行过程中，一些关键的操作或处理，都会记录日志信息，因此，阅读日志往往是一条有助于理清流程主线的捷径。 阅读源码过程中，同步绘制时序图，固化对流程的理解。好不容易摸清的主线，建议及时用时序图的方式固化下来，这样可以帮助自己快速回顾整个流程。 阅读源码过程中，不断发现或提出疑问，并且记下来。但不要当时就尝试去解决这些疑问，因为当时对代码的理解还不足以去解释这些疑问，结果很可能是费时费力但没成效，建议理清代码主线后再回头去解决这些疑问。 对于一些”莫名其妙“或”匪夷所思“的设计，请一定要对照参考社区问题单中的描述信息、设计文档或Comments信息。比如JDK源码里HashMap的默认负载因子为什么是0.75的注释。 阅读源码过程中，遇到晦涩难懂的细节，如何应对？此时，建议开启Debug模式，详细跟踪每一步的调用流程， 重视阅读测试用例源码，很多人并不习惯于阅读HBase的测试用例源码，其实，阅读测试用例的源码，可以帮你理解一些正确的行为应该是怎样的。 能力进阶：开始关注社区动态，或尝试为社区贡献Patch。关注社区动态，可以及时获知一些重要的Bugs或社区正在开发的大的Features。关注的方式包括但不限于： 订阅社区的Mail List 关注社区的问题单","categories":[{"name":"41.Uncategorized","slug":"41-Uncategorized","permalink":"https://beefyheisenberg.github.io/categories/41-Uncategorized/"}],"tags":[{"name":"开源","slug":"开源","permalink":"https://beefyheisenberg.github.io/tags/开源/"},{"name":"如何阅读源码","slug":"如何阅读源码","permalink":"https://beefyheisenberg.github.io/tags/如何阅读源码/"}]},{"title":"正则表达式-RegExp","slug":"41.Uncategorized/正则表达式-RegExp","date":"2024-01-24T01:27:52.979Z","updated":"2024-01-24T01:27:52.979Z","comments":true,"path":"41.Uncategorized/正则表达式-RegExp/","link":"","permalink":"https://beefyheisenberg.github.io/41.Uncategorized/正则表达式-RegExp/","excerpt":"正则表达式的流派正则的两个标准： Perl 和 POSIX 标准 Perl标准(PCRE)： 标准概述： perlre - perldoc.perl.org，只关注[The Basics] 和[Metacharacters] （元字符）这两节即可. 正则表达式在线检测： Debuggex Posix标准，包括两个流派：BRE（基本型正则表达式）和ERE（扩展型正则表达式） BRE： grep，sed，vi ERE： egrep，awk，grep -E， Perl正则","text":"正则表达式的流派正则的两个标准： Perl 和 POSIX 标准 Perl标准(PCRE)： 标准概述： perlre - perldoc.perl.org，只关注[The Basics] 和[Metacharacters] （元字符）这两节即可. 正则表达式在线检测： Debuggex Posix标准，包括两个流派：BRE（基本型正则表达式）和ERE（扩展型正则表达式） BRE： grep，sed，vi ERE： egrep，awk，grep -E， Perl正则位置^表示行首，例如 ^abc 表示abc号开头的行; 或者不匹配 [^abc] 任意不是abc的 $表示行尾，例如 333$ 表示已字符&quot;333&quot;结束的行; 次数* 星号表示出现0次或N次，相当于{0,}，比如\\$*b可以匹配&quot;b&quot;或者&quot;$$$b&quot;; ? 表示出现0次~1次，相当于{0,1} + 表示出现大于等于1次，相当于{1,} . 点号表示任何单个字符，换行符(\\n)除外，点号可以与上面的次数符号组合，比如.*表示任何字符或没有字符 .* 与 .*?区别： 前者是贪婪匹配（greedy），后者是非贪婪匹配（lazy） 字符簇例如 [AaEeIiOoUu] 表示一个表示所有元音字符的字符簇 [a-z] // 匹配所有的小写字母 [a-zA-Z] // 匹配所有的字母 [0-9\\.\\-] // 匹配所有的数字，句号和减号 注意： 前面曾经提到^表示字符串的开头，但它在字符簇里使用时，它表示&quot;非&quot;或&quot;排除&quot;的意思，[^0-9]指非数字 分组和其他小括号()表示分组， 例如 gr(a|e)y 匹配 &quot;gray&quot; 和 &quot;grey&quot;， (A\\d){2} 匹配 &quot;A数字A数字&quot;； 中括号[]表示匹配其中一个字符，例如 [Aa]匹配A或a，[3A-Z]匹配3或A~Z; [1-3a-f] 匹配1~3或a~f任意一个字符，[^0-9]表示非数字. 大括号{m}表示出现m次，例如a{3}表示aaa，{n,m} 表示最少n次，最多m次； A|B 表示可能匹配A表达式或B表达式 字符类型 &amp; 特殊转义字符\\w表示一个字母或数字，相当于[a-zA-Z|0-9] \\W表示非一个字符或数字 \\b表示一个单词，位于\\w和\\W之间的东西 \\d表示数字，相当于[0-9] \\D表示非数字，相当于[^0-9] \\s表示空格 \\S表示非空格 \\l表示小写字符，\\u表示大写字符 \\L表示非小写字符，\\U表示非大写字符 \\n 换行符 \\t 制表符 POSIX正则Posix正则标准分为BRE和ERE，vi/grep/sed属于前者，awk属于后者，BRE与Perlb正则标准(PCRE)相差的更多一点，ERE与Perl标准相差比较小.这里只记住几个例子就可以： vi/grep/sed中的正则：[0-9]\\{1,3\\} 表示数字0-9出现1-3次，注意 表示次数的大括号要转义，这点与Perl标准不同 ^[0-9]\\+ 表示数字至少出现一次，注意 这里的+号要加转义符 (星号，问号这些表示数量的符号，在POSIX也要转义) ^[0-9].*[a-z]$ 表示数字开头并且小写字母结尾 \\&lt;ngx 表示ngx开头的单词，注意 perl里没有\\&lt;的语法 arg\\&gt; 表示arg结尾的单词，注意 perl里没有\\&gt;的语法 \\(int\\|char\\) 表示匹配&quot;int&quot;或&quot;char&quot;字符串，等效于perl标准的(int|char)，posix标准里的左右括号和|都要加转义 注： 上面用 []中括号括起来的叫字符簇，参考 [[#字符簇]] 从上面的几个例子可以看出，posix标准比perl标准的语法更繁琐，posix正则标准里的()|{}这些符号前要加转义符(吐槽下，这也是为什么POSIX正则不如Perl流行的原因吧)， 例如： 在vim里想用^[0-9]+搜索数字开头是搜不出来的，因为+号前面要加转义. Java中的正则表达式Java的正则语法与Perl标准基本一致，参考Pattern (Java Platform SE 7 ) 转义符 常见的有\\n，\\t，\\&quot;，\\\\，这些转义字符占1Char; “ab\\n”.length()返回3; java字面表达式的写法和”编译器看到的”不一样，a\\\\b 在Java编译器看来是”a\\b”; 用Java字符串来写正则表达式，需要注意的转义符的使用： 如果要匹配点，中小括号，星号等等，正则要加双转义符， \\\\.匹配点 \\\\[匹配左中括号 如果要匹配斜杠，要写成四个转义符\\\\\\\\ String s1 = \"a\\\\b\"; // 实际字符串是'a\\b',s1.replaceAll(\"\\\\\\\\\"，\"\"); // 要用正则匹配斜杠，正则表达式是双斜杠'\\\\' ，但如果写双斜杠，会被编译器认为是单斜杠，正则编译器并不认识单斜杠 @ref 理解 Java 正则表达式怪异的 \\ 和 \\\\，让您见怪不怪 Pattern &amp; MatcherPattern p=Pattern.compile(\"\\\\d+\");Matcher m=p.matcher(\"ICQ：456456 Tel：6710 Mail：aaa123@aaa.com\");while(m.find()) &#123; System.out.println(m.group());&#125;/* 输出结果4564566710123*/ public static String maskEmoji(String str) &#123; Pattern pattern = Pattern .compile(\"[^(\\u2E80-\\u9FFF\\\\w\\\\s`~!@#\\\\$%\\\\^&amp;\\\\*\\\\(\\\\)_+-？（）——=\\\\[\\\\]&#123;&#125;\\\\|;。，、《》”：；“！……’：‘\\\"&lt;,&gt;\\\\.?/\\\\\\\\*')]\"); Matcher matcher = pattern.matcher(str); StringBuffer sb = new StringBuffer(); while (matcher.find()) &#123; matcher.appendReplacement(sb，\"[emoji：\" + getUnicode(matcher.group(0)) + \"]\"); &#125; matcher.appendTail(sb); return sb.toString(); &#125; Pattern捕获组Pattern用小括号包含的部分叫一个捕获组： String source = \"http：//a.changyan.com/api/2/config/get/cy7hcbyIb?callback=383768658\";String regex = \"(http：//)(.*)/(config/get)/(\\\\w+\\\\?)(.*)\"; // 5个捕获组Pattern pattern = Pattern.compile(regex);Matcher matcher = pattern.matcher(source);System.out.println(\"groupCount()=\" + matcher.groupCount());if(matcher.find() &amp;&amp; matcher.groupCount()&gt;0) &#123; for(int i =0; i &lt;= matcher.groupCount(); i++) &#123; System.out.printf(\"gounp[%d] = %s\\n\"，i，matcher.group(i)); &#125;&#125;/* 输出结果：groupCount()=5group[0] = http：//a.changyan.com/api/2/config/get/cy7hcbyIb?callback=383768658group[1] = http：//group[2] = a.changyan.com/api/2group[3] = config/getgroup[4] = cy7hcbyIb?group[5] = callback=383768658*/ 捕获组可以递归的使用，比如： String reg = \"((A)(B(C)))\"; // 包括4个捕获组，Pattern p = Pattern.compile(reg);Matcher matcher = pattern.matcher(string);// 如果匹配，那么：matcher.group(1) = ((A)(B(C)))matcher.group(2) = (A)matcher.group(3) = (B(C))matcher.group(4) = (C) appendReplacement matcher.find(); matcher.appendReplacement(stringBuff，”xxx”); // 把当前匹配替换为param2，并append到param1字符串后面. 常用正则测试地址 Debuggex： Online visual regex tester. JavaScript，Python，and PCRE. 数字： ^\\d*$N位数字： ^\\d&#123;N&#125;$IP地址： \\d+\\.\\d+\\.\\d+\\.\\d+匹配/attachments目录下所有&quot;php&quot;结尾的行： /attachments/.*\\.(php|php5)$邮箱，邮箱名可以出现.-符号： ^\\w+([-_.]\\w+)*@\\w+([-.]\\w+)*\\.\\w+([-.]\\w+)*$帐号是否合法(字母开头，允许5-16字节，允许字母数字下划线)： ^[a-zA-Z]\\w&#123;4,15&#125;$","categories":[{"name":"41.Uncategorized","slug":"41-Uncategorized","permalink":"https://beefyheisenberg.github.io/categories/41-Uncategorized/"}],"tags":[]},{"title":"安全笔记","slug":"41.Uncategorized/安全笔记","date":"2024-01-24T01:27:52.975Z","updated":"2024-01-24T01:27:52.975Z","comments":true,"path":"41.Uncategorized/安全笔记/","link":"","permalink":"https://beefyheisenberg.github.io/41.Uncategorized/安全笔记/","excerpt":"加密参考 Java Tutorials.md - (十七)安全 Blowfish是1993年布鲁斯·施奈尔(Bruce Schneier)开发的对称密钥区块加密算法，区块长为64位，密钥为1至448位的可变长度。与DES等算法相比，其处理速度较快。因为其无须授权即可使用，作为一种自由授权的加密方式在SSH、文件加密软件等被广泛地使用 bcrypt是根据Blowfish加密算法所设计的密码散列函数 Salt","text":"加密参考 Java Tutorials.md - (十七)安全 Blowfish是1993年布鲁斯·施奈尔(Bruce Schneier)开发的对称密钥区块加密算法，区块长为64位，密钥为1至448位的可变长度。与DES等算法相比，其处理速度较快。因为其无须授权即可使用，作为一种自由授权的加密方式在SSH、文件加密软件等被广泛地使用 bcrypt是根据Blowfish加密算法所设计的密码散列函数 SaltXSS全称(Cross Site Scripting) 跨站脚本攻击 安全/工具: minidwep/aircrack: 破解WEP and WPA-PSK无线密码; ssltrip ssltrip; 碰撞库 cmd5.com SSLOpenSSL心脏出血SSL协议可以看作是一个理论，OpenSSL库用代码实现了这个”理论”。 Goagent的证书是否安全?SSL如何防范中间人攻击?社工长尾关键词 http://blog.jobbole.com/76714/ 在谷歌中如何挖掘长尾关键词-SEO学堂","categories":[{"name":"41.Uncategorized","slug":"41-Uncategorized","permalink":"https://beefyheisenberg.github.io/categories/41-Uncategorized/"}],"tags":[]},{"title":"前端笔记","slug":"41.Uncategorized/前端笔记","date":"2024-01-24T01:27:52.970Z","updated":"2024-01-24T01:27:52.970Z","comments":true,"path":"41.Uncategorized/前端笔记/","link":"","permalink":"https://beefyheisenberg.github.io/41.Uncategorized/前端笔记/","excerpt":"Todo Javascript绝对简明教程 http://wiki.woodpecker.org.cn/moin/jsInAWord 对Web标准的理解, 浏览器差异 HTML / CSS / JavaScript(基础, JS面向对象实现原理/闭包机制/作用域) AngularJS / Ember.js / jQuery Jade / Swig / Handlebars / Mustache 或者其它模板引擎 SASS 或者其它 CSS 预处理器 Js代码混淆 grunt/uglify Content-Type 各浏览器对常用或者错误的 Content-Type 类型处理方式 http://w3help.org/zh-cn/causes/CH9001 or http://www.w3help.org/zh-cn/causes/CH9002 P3P Cookie","text":"Todo Javascript绝对简明教程 http://wiki.woodpecker.org.cn/moin/jsInAWord 对Web标准的理解, 浏览器差异 HTML / CSS / JavaScript(基础, JS面向对象实现原理/闭包机制/作用域) AngularJS / Ember.js / jQuery Jade / Swig / Handlebars / Mustache 或者其它模板引擎 SASS 或者其它 CSS 预处理器 Js代码混淆 grunt/uglify Content-Type 各浏览器对常用或者错误的 Content-Type 类型处理方式 http://w3help.org/zh-cn/causes/CH9001 or http://www.w3help.org/zh-cn/causes/CH9002 P3P Cookie假设这样的情况, 访问网页 a.com, 网页 a.com 通过 jsonp或 iframe访问了 &lt;b.com/set-cookie.php&gt;, 这个php里会set &lt;b.com&gt; 的 cookie.如果 &lt;b.com/set-cookie.php&gt;里没有把 response设置 P3P头, 那么&lt;b.com/set-cookie.php&gt; 种cookie将会不成功 @ref http://www.lovelucy.info/ie-accept-third-party-cookie.html 正确的做法, 如果&lt;b.com/set-cookie.php&gt;是一个(为第三方页面)种cookie的页面, 那么&lt;set-cookie.php&gt;要增加P3P头: header('P3P:CP=\"IDC DSP COR ADM DEVi TAIi PSA PSD IVAi IVDi CONi HIS OUR IND CNT\"'); Java版本的: response.setHeader(\"P3P\",\"CP='IDC DSP COR CURa ADMa OUR IND PHY ONL COM STA'\"); CSP(Content Security Policy) CSP可以防止什么: XSS(跨域脚本攻击) 如何启用CSP: 返回的resp里带header “Content-Security-Policy” Content-Security-Policy: script-src &apos;self&apos;; object-src &apos;none&apos;;style-src cdn.example.org third-party.org; child-src https: 网页的meta标签: &lt;meta http-equiv=&quot;Content-Security-Policy&quot; content=&quot;script-src &apos;self&apos;; object-src &apos;none&apos;; style-src cdn.example.org third-party.org; child-src https:&quot;&gt; @ref: Content Security Policy 入门教程 - 阮一峰的网络日志：http://www.ruanyifeng.com/blog/2016/09/csp.html 跨域浏览器的同源策略 https://developer.mozilla.org/zh-CN/docs/Web/Security/Same-origin_policy a.com/1/xx.html | a.com/2/xx.html 同源 https://a.com | http://a.com 不同源(协议不同) www.a.com | cdn.a.com 不同源(子域不同) www.a.com:8080 | www.a.com:80 不同源(端口不同) 跨域资源共享 CORS 详解 - 阮一峰的网络日志：https://www.ruanyifeng.com/blog/2016/04/cors.html 资源加载跨域原理：所有具有src属性的HTML标签都是可以跨域的限制：需要创建一个DOM对象，只能用于GET方法 &lt;!-- 常用的可以跨域的标签 --&gt;&lt;script src=\"...\"&gt;&lt;/script&gt;&lt;img src=\"...\"/&gt;&lt;iframe src=\"...\" /&gt; document.domain + iframe跨域这种方式只针对相同主域名不同子域名下的页面才有效,以(http://a.com/foo.html)和(http://cdn.a.com/bar.html)为例: // URL http://a.com/foo.htmlvar ifr = document.createElement('iframe');ifr.src = 'http://cdn.a.com/bar.html'; // 这里跨域访问了cdn.a.com/barifr.onload = function()&#123; var ifrdoc = ifr.contentDocument || ifr.contentWindow.document; ifrdoc.getElementsById(\"foo\").innerHTML);&#125;;ifr.style.display = 'none';document.body.appendChild(ifr); 只要在(http://cdn.a.com/bar.html)里加入声明:document.domain = &apos;a.com&apos; // 往上提了一级域名 ajax使用jsonp跨域jsonp 全称是JSON with Padding, 原理是客户端依靠&lt;script src=&quot;...&quot;\\&gt;标签的src发起跨域请求, 远端服务器返回给客户端一段js代码, 这段js代码自动调用客户端的函数 function getBooks()&#123; $.ajax(&#123; type:'get', url:'http://test.com/bookservice.php', dataType:'jsonp', jsonp:'callback', jsonpCallback:'displayBooks' &#125;); &#125; 参考: js中几种实用的跨域方法原理详解 HTML简明参考按钮在一个页面上画一个按钮，有四种办法： &lt;input type=&quot;button&quot; /&gt; 这就是一个按钮。如果你不写javascript 的话，按下去什么也不会发生。 &lt;input type=&quot;submit&quot; /&gt; 这样的按钮用户点击之后会自动提交 form，除非你写了javascript 阻止它。 &lt;button&gt; 这个按钮放在 form 中也会点击自动提交，比前两个的优点是按钮的内容不光可以有文字，还可以有图片等多媒体内容。（当然，前两个用图片背景也可以做到）。它的缺点是不同的浏览器得到的 value 值不同；可能还有其他的浏览器兼容问题。请始终为&lt;button&gt;规定 type 属性。Internet Explorer 的默认类型是 “button”，而其他浏览器中（包括 W3C 规范）的默认值是 “submit”。 其他标签，例如 a, img, span, div，然后用图片把它伪装成一个按钮。 参考&lt;button&gt;和&lt;input type=&quot;button&quot;的区别 (http://www.cnblogs.com/purediy/archive/2012/06/10/2544184.html) JavaScript简明参考参考: JavaScript权威指南(第6版) 匿名 定义并执行 (function(){})(), function的小括号是必须的 定义: var fnB = function(){ } JavaScript事件点击事件: onclick 当用户进入或离开页面时，会触发 onload 和 onunload 事件. onload 事件可用于检查访客的浏览器类型和版本，以便基于这些信息来加载不同版本的网页。 onload 和 onunload 事件可用于处理 cookies。 下面的例子展示了如何使用 onchange。当用户改变输入字段的内容时，将调用 upperCase() 函数。&lt;input type=&quot;text&quot; id=&quot;fname&quot; onchange=&quot;upperCase()&quot;&gt; onmouseover 和 onmouseout 事件可用于在鼠标指针移动到或离开元素时触发函数。 CSSCSS的「空格」和「&gt;」 「&gt;」代表的是css3特有的子元素选择器（element&gt;element ）,「&gt;」是直接子元素 「空格」空格隔开表示从属包含关系，是当前的元素子元素,「空格」是所有子元素 「逗号」逗号隔开表示两个不同类的样式类名用同一个样式, CSS的「点」和「#」 「点」对应class .card &#123;&#125; 「井号」对应id : #Kard &#123;&#125; 不加 对应html标签比如 ul,img,p Class与ID的区别: Class: Class是用来根据用户定义的标准对一个或多个元素进行定义的 ID: ID是定义页面上一个仅出现一次的标记 AJAX（Asynchronous JavaScript And XML）chrome dev tool: console : 输入$ 判断是否有jquery (prototype) console : 输入$(&#39;#user_name&#39;) 判断 $(&#39;#ABC #list_&#39;) 寻找id=ABC, 再在子节点寻找id=list_ $(&#39;.ABC .list_&#39;) 寻找class=ABC 前端调试 chrome调试工具: c-p：打开资源 fiddler替代chrome调试 通过chrome审核元素找div chrome的console交互命令，找jQuery，找各种资源 把js保存位chrome书签 conslole: console : 输入$ 判断是否有jquery console : 输入$(&#39;#user_name&#39;) 判断 js断点： 在chrome设置断点，要求这个js是可以缓存的 debugger console.log(123) 对于压缩的js如何处理 用finddle让浏览器解析本地js 补充: 五个你必须知道的javascript和web-debug技术 自动化 如何用工程手段解决前端开发和部署优化的综合问题","categories":[{"name":"41.Uncategorized","slug":"41-Uncategorized","permalink":"https://beefyheisenberg.github.io/categories/41-Uncategorized/"}],"tags":[{"name":"前端","slug":"前端","permalink":"https://beefyheisenberg.github.io/tags/前端/"},{"name":"Html","slug":"Html","permalink":"https://beefyheisenberg.github.io/tags/Html/"},{"name":"Javascript","slug":"Javascript","permalink":"https://beefyheisenberg.github.io/tags/Javascript/"}]},{"title":"使用jEnv管理Jdk版本","slug":"41.Uncategorized/使用jEnv管理Jdk版本","date":"2024-01-24T01:27:52.964Z","updated":"2024-01-24T01:27:52.965Z","comments":true,"path":"41.Uncategorized/使用jEnv管理Jdk版本/","link":"","permalink":"https://beefyheisenberg.github.io/41.Uncategorized/使用jEnv管理Jdk版本/","excerpt":"","text":"=&gt; [[../50.Farbox-Blog/【开发环境】MacOS开发环境配置#多版本Java共存]]","categories":[{"name":"41.Uncategorized","slug":"41-Uncategorized","permalink":"https://beefyheisenberg.github.io/categories/41-Uncategorized/"}],"tags":[]},{"title":"使用NVM管理Node","slug":"41.Uncategorized/使用NVM管理Node版本","date":"2024-01-24T01:27:52.960Z","updated":"2024-01-24T01:27:52.960Z","comments":true,"path":"41.Uncategorized/使用NVM管理Node版本/","link":"","permalink":"https://beefyheisenberg.github.io/41.Uncategorized/使用NVM管理Node版本/","excerpt":"NVM = Node Version Manager 安装NVM（zsh）参考： install nvm on mac with zsh shell 输入nvm v查看当前 NVM 版本号，如果成功出现版本号，则代表安装成功 输入nvm ls available查看可以安装的 Node 版本 如果返回结果为N/A，解决办法：https://stackoverflow.com/questions/26476744/nvm-ls-remote-command-results-in-n-a","text":"NVM = Node Version Manager 安装NVM（zsh）参考： install nvm on mac with zsh shell 输入nvm v查看当前 NVM 版本号，如果成功出现版本号，则代表安装成功 输入nvm ls available查看可以安装的 Node 版本 如果返回结果为N/A，解决办法：https://stackoverflow.com/questions/26476744/nvm-ls-remote-command-results-in-n-a 安装指定版本 Node：nvm install 12.17.0 切换到指定版本 Node：nvm use 12.17.0 查看 Node版本：node -v 查看已安装的 Node版本： nvm ls","categories":[{"name":"41.Uncategorized","slug":"41-Uncategorized","permalink":"https://beefyheisenberg.github.io/categories/41-Uncategorized/"}],"tags":[{"name":"NodeJS","slug":"NodeJS","permalink":"https://beefyheisenberg.github.io/tags/NodeJS/"}]},{"title":"使用Hugo搭建博客","slug":"41.Uncategorized/使用Hugo搭建博客","date":"2024-01-24T01:27:52.956Z","updated":"2024-01-24T01:27:52.956Z","comments":true,"path":"41.Uncategorized/使用Hugo搭建博客/","link":"","permalink":"https://beefyheisenberg.github.io/41.Uncategorized/使用Hugo搭建博客/","excerpt":"安装参考 https://www.docsy.dev/docs/get-started/other-options/ https://geekdocs.de/usage/getting-started/ 1）首先安装 nvmAfter install zsh- brew update- brew install nvm- mkdir ~/.nvmafter in your ~/.zshrc or in .bash_profile if your use bash shell: export NVM_DIR=~/.nvm source $(brew --prefix nvm)/nvm.sh 2）通过 NVM安装 Node Lts稳定版nvm install --lts","text":"安装参考 https://www.docsy.dev/docs/get-started/other-options/ https://geekdocs.de/usage/getting-started/ 1）首先安装 nvmAfter install zsh- brew update- brew install nvm- mkdir ~/.nvmafter in your ~/.zshrc or in .bash_profile if your use bash shell: export NVM_DIR=~/.nvm source $(brew --prefix nvm)/nvm.sh 2）通过 NVM安装 Node Lts稳定版nvm install --lts 3）安装 Hogo（使用docsy主题） 前置：需要安装一些 npm包，推荐切换到国内的 npm镜像：https://cnodejs.org/topic/4f9904f9407edba21468f31e 前置：安装 hugo + npm（PostCSS等..）：Before you begin | Docsy docsy提供了几种安装方式，”Use Docsy as a Hugo Module”这种最简单：Create a new site: Start a new site from scratch | Docsy docsy 配置，样例网站参考 https://www.docsy.dev/docs/examples/，选了一个最简洁的，也就是 Docsy自己的文档网站，config.yaml 等配置直接从 https://github.com/google/docsy上复制过来 Hugo命令参数说明hugo通用命令参数 -h –help查看特定命令的帮助信息.-D –buildDrafts在生成静态网站, 或预览网站时, 草稿内容也会被展示出来.–config string指定新的配置文件, 在网站骨架根目录下面有一个默认的配置文件config.yaml|json|toml. hugo默认加载这个配置文件, 通过--config 配置文件路径可以指定新的配置文件.-c, –contentDir stringhugo默认的存放内容文件的目录为content目录, -c 新的存放内容文件的目录路径 用于修改默认的存放路径. 也可以用新的内容文件目录生成网站.","categories":[{"name":"41.Uncategorized","slug":"41-Uncategorized","permalink":"https://beefyheisenberg.github.io/categories/41-Uncategorized/"}],"tags":[{"name":"博客","slug":"博客","permalink":"https://beefyheisenberg.github.io/tags/博客/"},{"name":"Hugo","slug":"Hugo","permalink":"https://beefyheisenberg.github.io/tags/Hugo/"},{"name":"Markdown","slug":"Markdown","permalink":"https://beefyheisenberg.github.io/tags/Markdown/"}]},{"title":"开发工具（screen, tmux）、IDE快捷键（Vim, Jetbrains, etc.）速查手册","slug":"41.Uncategorized/Tools-and-IDE","date":"2024-01-24T01:27:52.951Z","updated":"2024-01-24T01:27:52.951Z","comments":true,"path":"41.Uncategorized/Tools-and-IDE/","link":"","permalink":"https://beefyheisenberg.github.io/41.Uncategorized/Tools-and-IDE/","excerpt":"值得尝试的新工具 ag: 比grep、ack更快的递归搜索文件内容。 mycli: mysql客户端，支持语法高亮和命令补全，效果类似ipython，可以替代mysql命令。 shellcheck: shell脚本静态检查工具，能够识别语法错误以及不规范的写法。 cloc: 代码统计工具，能够统计代码的空行数、注释行、编程语言。 Text EditorVim移动/跳转光标:","text":"值得尝试的新工具 ag: 比grep、ack更快的递归搜索文件内容。 mycli: mysql客户端，支持语法高亮和命令补全，效果类似ipython，可以替代mysql命令。 shellcheck: shell脚本静态检查工具，能够识别语法错误以及不规范的写法。 cloc: 代码统计工具，能够统计代码的空行数、注释行、编程语言。 Text EditorVim移动/跳转光标: H J K L: ← ↓ ↑ → 0 : 移动光标至本行开头 $ : 移动光标至本行结尾 w : 移动到下个单词( a.Properties算两个单词) W : 移动到下个单词(空格分隔的单词) 3w : 光标向前移动3个单词 b : 移动到上个单词, 如同w B : 移动到上个单词, 如同W gg : 移动到第一行 G : 移动到最后一行 :133 : 跳到第133行 g; 在最近所有修改处跳转 &#39;. 跳转到最后修改的那一行 编辑: i : 在当前光标前面插入 I : 在当前单词开头插入 a : 在当前光标后面插入 A : 在当前单词尾部插入 x : 删除光标处字母 d0 : 删除到行首 d$ : 删除到行尾 dd : 删除光标所在行 dw : 删除光标所在单词 &gt;&gt; : 增加缩进 &lt;&lt; : 减少缩进 搜索: fX : 在本行搜索X FX : 在本行搜索X(向后搜索) /Word : 全文搜索 ?Word : 全文搜索(向后) 粘贴/复制: y : 复制选中的 yy : 复制整行 p : 粘贴 &quot;+y : 复制到+寄存器 &quot;+p: 粘贴+寄存器的内容 补全: CTRL + N: 智能补全 CTRL + X , CTRL + K : 根据字典补全 CTRL + X , CTRL + U : 用户自定义补全 CTRL + X , CTRL + F : 文件名补全 其他: v : 进入选择模式 Shift + v : 进入选择模式(行) Ctrl + v : 进入选择模式(列) vimdiff: 启动: vimdiff file1 file2 前一个: [ + C 后一个: ] + C 在窗口间切换: C\bTRL + W W 将当前复制到另一个: dp, dp 意为 diff “put” , 也可以使用命令:diffput 将另一个复制到当前: do, do 意为 diff “obtain” , 也可以使用命令:diffget, 之所以不用dg，是因为dg已经被另一个命令占用了 重新比较: :diffupdate VS Code 列模式: shift + option + ↕️ 快速打开: ⌘ + P 连续选中光标所在的单词: ⌘ + D Sublime TextShortcut key: ⌘ + P: 快速打开文件 ⌘ + R: 打开纲要列表 ⌘ + D/G: 同步编辑/类似vim # and * ⌘ + M: 括号跳转 ⌘ + F: Enter查找下一个,Shift + Enter查找上一个 ⌘ + X: 删除当前行 ⌘ + L: 选择整行, 按住⌘继续按L则持续选择 ⌘ + Shift + L: 多行选中后, 同时编辑这些行 ⌘ + 左键点击: 多处同时编辑 Ctrl + G: 跳转到行 Shift + Tab: 折叠, 在看很长的Markdown文档时有用 Plugin: Encoding: GBK Encoding Support, CovertToUTF8 Syntax Checker: Phpcs for sublime2 (http://alfred-long.iteye.com/blog/1668074) SublimeLinter(https://github.com/SublimeLinter) 检测代码语法错误,支持C/Java/Python: sublimelinter-php sublimelinter-py sublimelinter-json sublimelinter-jscs sublimelinter-cppcheck SublimeCodeIntel(https://github.com/SublimeCodeIntel/SublimeCodeIntel) 代码补全, 定义跳转; Alignment:格式化代码Ctrl+Alt+A; SublimeCodeIntel: Jump to definition = Alt+Click Jump to definition = Control+Super+Alt+Up Go back = Control+Super+Alt+Left Manual Code Intelligence = Control+Shift+space neoviminstall neovim on windows：choco sources add -source https://www.myget.org/F/equalsraf/ -name equalsrafchoco install -pre neovim-qt IDEIntelliJ IDEAEditing（编辑） Alt + Enter : 显示建议/导入包 ⭐️ Control + Space : 基本的代码补全（补全任何类、方法、变量）\b\u001b ⭐️ ⌘ + J : 插入自定义动态代码模板 ⌘ + Alt + J : 弹出模板选择窗口，将选定的代码使用动态模板包住 ⌘ + Alt + T : 把代码用if, for等代码块包起来(当前行或选定的行) Ctrl + Alt + O : 优化import ⭐️ ⌘ + Alt + L : 格式化代码 ⭐️ ⌘ + / : 注释/取消注释与行注释 ⌘ + 加号 : 展开当前代码块 ⌘ + 减号 : 折叠当前代码块 ⌘ + Shift + 加号 : 展开所有代码块 ⌘ + Shift + 减号 : 折叠所有代码块 Search/Replace（查询/替换） Shift + Shift: Search anywhere ⭐️ Ctrl + N, Ctrl + Shift + N: 查找类, 查找文件 Ctrl + F, Ctrl + Shift + F: search F2 或 Shift+F2: 上个/下个错误 F3 或 Shift+F3: 上个/下个查找 Alt + F7: find usage Navigation（导航） ⌘ + Alt + ←/→: Navigate back/forward \b⌘ + E : 显示最近打开的文件记录列表 ⌘ + F12: 弹出当前文件结构 Ctrl + H : 显示类的继承层级（列出上下继承结构） ⭐️ ⌘ + Shift + H: 显示方法继承层级（例如显示某个抽象类的所有实现） ⭐️ Ctrl + Alt + H: 显示调用层次结构 ⭐️ VCS/Local History（版本控制/本地历史记录） Command + K : 提交代码到版本控制器 ⭐️ Refactoring（重构） Shift + F6: 重构 UI（界面） ⌘ + 1 : Project ⌘ + 7 : Structure ⌘ + 8 : Hierarchy ⌘ + 9 : Version Control Plugins（插件） Lombok Code iris: 显示类的Diagrams mongo4idea Android Studio 格式化代码 ⌘ + Option + L Ctrl + Alt + L 删除行 ⌘ + Delete Ctrl + Y 快捷生成结构体 ⌘ + Option + T Ctrl + Alt + T 快捷覆写方法 ⌘ + O Ctrl + O 快捷定位到行首/尾 ⌘ + Left/Right Ctrl + Left/Right 文件方法结构 ⌘ + F12 Ctrl + F12 查找调用的位置 Ctrl + Option + H Ctrl + Alt + H PHPStorm（Win） Ctrl + j 常用的代码片段 Ctrl + Alt + 左右方向键，定位到上一次编辑的位置 Ctrl + F12，快速查看当前文件的所有方法 Ctrl + Alt + L，格式化代码 Ctrl + N，根据类名称查找 Ctrl + Shift + N，根据文件名查找 Eclipse（Win）快捷键: Alt+/: 补全 Ctrl+1: 快速修复建议 Ctrl+D: 删除当前行 Ctrl+Del: 删单词, 类似VIm的daw Ctrl+E: 打开的标签之间切换 Ctrl+M: 最大化当前的Edit或View, 配合F12(编辑窗口获得焦点), 可以立刻最大化代码编辑栏 Ctrl+L: 定位在某行 Ctrl+K: 选中的单词, 相当于Vim的#, 反向Ctrl+Shift+K Ctrl+Q: 定位到最后编辑的地方 Ctrl+O: 快速显示 OutLine Ctrl+T: 快速显示当前类的继承结构 Ctrl+Shift+P: 匹配括号 Ctrl+Shift+G: 查找调用 F2: 显示提示 F3: 跳转定义 F4/Ctrl+O: 打开继承, 只能看extends, 不能看implements Ctrl+H: 搜索 Ctrl+Alt+H: 调用 Ctrl+Shift+R: 搜索工程中的资源文件 Ctrl+Shift+T: 搜索类（包括工程和关联的第三jar包） Alt+Shift+R: 自动的重命名一个类 Alt+Shift+I: 自动内联选中的属性/方法 Alt+Shift+j: 插入当前类/方法的注释 Ctrl+/ : 对选中的部分进行注释 Ctrl+Shift+/: 对选中的部分块状注释 Ctrl+Shift+F: 格式化代码 Ctrl+Shift+P: 匹配括号 插件: m2e Egit terminal(终端) Ctrl – a ：移到行首 Ctrl – e ：移到行尾 screenScreen一个”会话”包括若干Windows, 每个Windows可被分割, 每个分割的区域可再创建新的Window QuickStart screen -ls 查看已有的session screen -r id 连接已有的session screen -S xx 创建xxx为名字的session c-a &quot; 查看已打开的shell c-a S 上下分割当前Window, 分割出来的新Window没有运行任何Shell c-a Tab 切换到新Windows c-a c 创建新shell c-a &quot; 查看&amp;切换已经打开的shell c-a d 保存session并退出 c-a k 杀死Window, 不可恢复 Window c-a c: 创建一个window c-a &quot;: 查看已创建的windows列表 c-a d: deattach 整个会话, 所有Windows c-a k: 关闭当前windos c-a Tab: 切换 c-a n/p: switch c-a 0~9: 按序号切换到window Split c-a S : 上下分割, c-a tab移动到下面的窗口, 然后c-a c创建新的 c-a | : 垂直分割 翻页&amp;复制 c-a [: 进入复制模式, 之后可以像vim里一样操作h j k l, ctrl-b, ctrl-f, 翻页 进入复制模式后, 空格开始选择, 空格结束 Session screen -S test1 : 创建名为test1的会话 screen -ls ： 查看deattach的会话 screen -r id ： 重新连接 screen -d -r id : 如果上面的命令提示已经attach, 可以加-d参数先deattach再attach screem -X -S session_id quit : 退出session, -X参数是执行的意思,执行quit命令. rm -rf /var/run/screen/S-xxx : 删除会话 tmux `tmux new-session -s “sessionX” 创建会话 `tmux attach -t sessionX 恢复会话 c-b d : 再输入tmux attach可以恢复会话 c-b &quot; : 上下新建一个面板 c-b %: 左右新建一个面板 c-b 方向: 面板切换 c-b Page: 进入翻页模式，此模式下可以用翻页键，q是退出翻页模式 c-b : : 输入setw mode-mouse on 设置鼠标滚轮 [ 复制模式 ] 粘贴模式 svn svn add file svn commit -m &quot;xxx&quot; : 提交修改 svn up: 更新到最新版本 svn revert file: 没commit时的撤销 svn log svn merge -r 28:25 file: 从当前28回滚到25 git=&gt; Git速查手册","categories":[{"name":"41.Uncategorized","slug":"41-Uncategorized","permalink":"https://beefyheisenberg.github.io/categories/41-Uncategorized/"}],"tags":[{"name":"开发环境","slug":"开发环境","permalink":"https://beefyheisenberg.github.io/tags/开发环境/"},{"name":"IDE","slug":"IDE","permalink":"https://beefyheisenberg.github.io/tags/IDE/"},{"name":"Vim","slug":"Vim","permalink":"https://beefyheisenberg.github.io/tags/Vim/"},{"name":"Vimdiff","slug":"Vimdiff","permalink":"https://beefyheisenberg.github.io/tags/Vimdiff/"},{"name":"IDEA","slug":"IDEA","permalink":"https://beefyheisenberg.github.io/tags/IDEA/"},{"name":"Jetbrains","slug":"Jetbrains","permalink":"https://beefyheisenberg.github.io/tags/Jetbrains/"},{"name":"screen","slug":"screen","permalink":"https://beefyheisenberg.github.io/tags/screen/"},{"name":"tmux","slug":"tmux","permalink":"https://beefyheisenberg.github.io/tags/tmux/"}]},{"title":"NPM命令速查","slug":"41.Uncategorized/NPM命令速查","date":"2024-01-24T01:27:52.947Z","updated":"2024-01-24T01:27:52.947Z","comments":true,"path":"41.Uncategorized/NPM命令速查/","link":"","permalink":"https://beefyheisenberg.github.io/41.Uncategorized/NPM命令速查/","excerpt":"npm install安装目录npm install xx # 局部安装到当前目录node_moduels/npm install -g xx # 全局安装到全局目录，见“npm安装路径说明” npm安装路径说明： 默认的，npm 全局安装路径默认是： /usr/local/lib/node_modules 如果用NVM安装的Node，安装路径是 ~/.nvm/versions/node/v16.17.1/lib/node_modules","text":"npm install安装目录npm install xx # 局部安装到当前目录node_moduels/npm install -g xx # 全局安装到全局目录，见“npm安装路径说明” npm安装路径说明： 默认的，npm 全局安装路径默认是： /usr/local/lib/node_modules 如果用NVM安装的Node，安装路径是 ~/.nvm/versions/node/v16.17.1/lib/node_modules # 查看全局安装路径npm root -g# 查看npm的基础设置npm config ls# 查看安装目录路径npm config get prefix 常用命令npm uninstall xxxnpm update xxxnpm cache clear #清空NPM本地缓存# 查看某个模块的版本号$ npm list grunt# 查看所有全局安装的模块npm list -g 代理设置方案1：走代理npm config set proxy socks5://127.0.0.1:7892 &amp;&amp; npm config set https-proxy http://127.0.0.1:7892 需要npm get config registry 确认不是用的国内源.. 使用国内镜像（3选1）1.通过config命令npm config set registry https://registry.npm.taobao.org npm info underscore （如果上面配置正确这个命令会有字符串response）2.命令行指定npm --registry https://registry.npm.taobao.org info underscore 3.编辑 ~/.npmrc 加入下面内容registry = https://registry.npm.taobao.org","categories":[{"name":"41.Uncategorized","slug":"41-Uncategorized","permalink":"https://beefyheisenberg.github.io/categories/41-Uncategorized/"}],"tags":[{"name":"NodeJS","slug":"NodeJS","permalink":"https://beefyheisenberg.github.io/tags/NodeJS/"}]},{"title":"Git速查手册","slug":"41.Uncategorized/Git速查手册","date":"2024-01-24T01:27:52.942Z","updated":"2024-01-24T01:27:52.943Z","comments":true,"path":"41.Uncategorized/Git速查手册/","link":"","permalink":"https://beefyheisenberg.github.io/41.Uncategorized/Git速查手册/","excerpt":"stash git stash: 暂存没有add的修改 git stash list: 查看已经暂存的 git stash apply: 应用暂存的修改到当前分支 工作流 Git 工作流程 - 阮一峰的网络日志 Git flow Github flow checkout &amp; merge","text":"stash git stash: 暂存没有add的修改 git stash list: 查看已经暂存的 git stash apply: 应用暂存的修改到当前分支 工作流 Git 工作流程 - 阮一峰的网络日志 Git flow Github flow checkout &amp; merge1) git clone 检出代码: 显示remote:(origin是远程库的名字) git remote -v 查看可以抓取和推送的origin的地址 git remote show origin, 比上面的更详细, 可以看到git pull/push到的默认是哪个分支. 2) git checkout -b issue3 origin/master, 从远端的master分支创建一个自己的分支issue3 创建新分支并立即切换到新分支： git checkout -b [name] 如果这时候git pull从服务器拉新代码, 会失败并提示服务端的分支没有和新分支对应: git branch --set-upstream-to=origin/master [分支名] 3) 合并源分支(issue3) 到远程目标分支(master)： git pull --rebase origin master // 在issue3分支pull最新的master代码 git checkout master // 切换到目标分支 git merge --no-ff issue3 // --no-ff 禁用 Fast forward模式, 这样删除分支后也不会丢掉分支信息 git push origin master 如果merge时出现冲突: 修改冲突文件, 然后重新git add confilct_file(重新staged), 将把它们标记为已解决状态（译注：实际上就是来一次快照保存到暂存区域）。因为一旦暂存，就表示冲突已经解决。 然后不要忘了: git commit -m &quot;conflict fixed&quot; 解决完冲突, push上去git push origin master 4) 合并完成后, 删除开发分支： git branch -d &lt;branch_name&gt; # 如果这个分支没有被merge,git会提示 git branch -D &lt;branch_name&gt; # -D就是强行删除 git push origin --delete &lt;branch_name&gt;如需要删除远程分支: rebase➤ 用rebase 合并commit记录: 使用git rebase有两种: git rebase -i HEAD~4 // 从HEAD开始往前4次commit合并成一个 git rebase -i star_commit end_commit // 前开后闭区间, 合并范围不包括start_commit, 如果不写end_commit则默认是HEAD 进入vi模式(for example: 第一个commit标记为pick, 后面几个commit标记为squash, 这样会把后几个commit合并到第一个), wq保存退出, git会合并commit历史 git log --graph --pretty=oneline --abbrev-commit 查看结果 如果发生冲突, 修改后 git add ., 然后 git rebase --continue .. rebase完, git log查看一下合并结果, 然后推到远端分支 git push -f origin &lt;branch&gt; ➤ merge之前使用git rebase: 切换到私有分支, 然后 git rebase origin master // 与pull --rebase master的区别? 如果有有冲突: 修改冲突的文件, 然后 git add file 修改完后, 不commit而是 git rebase --continue 撤销此次Merge : git rebase --skip (可能多次) git checkout master git merge issue3 ➤ git rebase master发生了什么? 把issue3分支每个commit取消掉, 并把这些commit保存到.git/rebase下作为临时patch) 把当前分支(issue3)更新到最新的master 把步骤1的patch应用到当前分支 ps: 解决冲突后继续git rebase --continue // 继续应用剩下的patch cherry-pick git cherry-pick &lt;commit_hash&gt; // 把这次commit应用到 当前分支, ps支持多个提交(空格分隔) git cherry-pick &lt;branch&gt; // 把这个分支所有commit应用到 当前分支 如果 cherry-pick 出现冲突, 修改完冲突需要再执行: git add confilct_file git commit -m &quot;conflict fix&quot; 撤销和回滚 修改了文件, 但还没有git add: 输入git status, 会提示用git checkout -- file丢弃工作区, 文件回到服务器状态; 修改并add了README.md, 还没有commit: 输入git status, 提示use git reset HEAD filename to unstage; 如果已commit/已merge: git log -p -n 3 查看最近3次历史, 记录下commit的哈希值, 然后执行 git reset --hard commit_hashid 如果已push: git reflog 查看 commit_hashid git reset --hard commit_hashid git push -f // 把本地的修改强制推送到远程分支上 强制推送到mster可能会报错，意思是没有权限之类的错误，报错如下。 remote: GitLab: You don&apos;t have permissionTo git@10.255.223.213:code-ddreader/media-hapi.git! [remote rejected] master (pre-receive hook declined) 是因为master分支一般会成为保护分支，所以我们首先要去除master为保护分支，才可以强推。 有用的alias设置git config --global alias.co checkoutgit config --global alias.ci commitgit config --global alias.st statusgit config --global alias.br branchgit config --global alias.hist &quot;log --pretty=format:&apos;%h %ad | %s%d [%an]&apos; --graph --date=short&quot; 以及: git config --global core.autocrlf false 使用LR而不是Win系统的CRLF 当你把git弄的一团糟时","categories":[{"name":"41.Uncategorized","slug":"41-Uncategorized","permalink":"https://beefyheisenberg.github.io/categories/41-Uncategorized/"}],"tags":[{"name":"git","slug":"git","permalink":"https://beefyheisenberg.github.io/tags/git/"}]},{"title":"Github-Repo-Starred","slug":"41.Uncategorized/Github-Repo-Starred","date":"2024-01-24T01:27:52.938Z","updated":"2024-01-24T01:27:52.939Z","comments":true,"path":"41.Uncategorized/Github-Repo-Starred/","link":"","permalink":"https://beefyheisenberg.github.io/41.Uncategorized/Github-Repo-Starred/","excerpt":"@todo High-performance event loop : such as libev; PHP Framework; Python mvc; C/C++STL : STL笔记; Protothreads : 针对C语言封装后的宏函数库, 为C语言模拟了一种无堆栈的轻量线程环境, 能够实现模拟线程的条件阻塞、信号量操作等操作系统中特有的机制, 从而使程序实现多线程操作.","text":"@todo High-performance event loop : such as libev; PHP Framework; Python mvc; C/C++STL : STL笔记; Protothreads : 针对C语言封装后的宏函数库, 为C语言模拟了一种无堆栈的轻量线程环境, 能够实现模拟线程的条件阻塞、信号量操作等操作系统中特有的机制, 从而使程序实现多线程操作. LevelDB : 由Google公司所研发的键／值对（Key/Value Pair）嵌入式数据库管理系统编程库. Lua : Lua是一种轻量语言, 它的官方版本只包括一个精简的核心和最基本的库. Nginx : HTTP和反向代理服务器, 另外它也可以作为邮件代理服务器. 多进程模型、epoll异步, timer红黑树. Libev : Libev是一个C语言写的, 只支持linux系统的轻量级网络库. 阅读源码参考(http://dirlt.com/libev.html); Libevent : An event notification library. libevent是一个事件触发的网络库，适用于windows、linux、bsd等多种平台，内部使用select、epoll、kqueue等系统调用管理事件机制。著名分布式缓存软件memcached也是libevent based. Redis : 基于内存、键值对存储数据库, 使用ANSI C编写. memcached : C++ with C style, 多线程网络编程; lpereira/lwan : C实现的Http服务器 JavaSpring Framework : Java EE全功能栈（full-stack）的应用程序框架； PythonPython源码 推荐几个模块: SocketServer(Lib/SocketServer.py) SimpleHTTPServer(Lib/SimpleHTTPServer.py) BaseHTTPServer(Lib/BaseHTTPServer.py) GoAgent : a gae proxy;Gevent : 基于libev的高性能Python并发库,为各种并发和网络相关任务提供了整洁的API;Py-Learn : Fork it and Build your Python-Learning repos;Requests : Http库. Python Web框架Django: Web应用框架,采用了MVC的软件设计模式.Tornado: 可扩展的非阻塞式 web 服务器.flask 爬虫scrapy 自动化fabric Python 微信WeRoBot 网络库requestshttpie PHPhttps://github.com/yiisoft/yii2 https://github.com/laruence/php-yaf https://github.com/WordPress/WordPress Jshttps://github.com/xicilion/fibjs https://github.com/jquery/jquery 其他Markdown语法简历模板","categories":[{"name":"41.Uncategorized","slug":"41-Uncategorized","permalink":"https://beefyheisenberg.github.io/categories/41-Uncategorized/"}],"tags":[]},{"title":"人工智能和神经网络101","slug":"34.Machine-Learning/人工智能和神经网络101","date":"2024-01-24T01:27:52.934Z","updated":"2024-01-24T01:27:52.935Z","comments":true,"path":"34.Machine-Learning/人工智能和神经网络101/","link":"","permalink":"https://beefyheisenberg.github.io/34.Machine-Learning/人工智能和神经网络101/","excerpt":"@ref: 机器能像人一样思考吗？人工智能（一）机器学习和神经网络 - YouTube 人工智能发展史 1950：图灵测试提出（直到2014年才出现第一台通过图灵测试的程序） 1956：马文丶明斯基，约翰丶麦卡锡，香农 =&gt; 达特茅斯会议，第一次提出“AI” 1997：IBM深蓝战胜卡斯帕罗夫 辛顿（BP反向传播算法），杨立昆（CNN卷积神经网络），本吉奥获得2018年图灵奖","text":"@ref: 机器能像人一样思考吗？人工智能（一）机器学习和神经网络 - YouTube 人工智能发展史 1950：图灵测试提出（直到2014年才出现第一台通过图灵测试的程序） 1956：马文丶明斯基，约翰丶麦卡锡，香农 =&gt; 达特茅斯会议，第一次提出“AI” 1997：IBM深蓝战胜卡斯帕罗夫 辛顿（BP反向传播算法），杨立昆（CNN卷积神经网络），本吉奥获得2018年图灵奖 线性拟合 &amp; 梯度下降算法先看一个例子： 给出m组数据（x1,y1）~（xm,ym）, 需要预测出y和x的函数关系. 线性拟合：「曲线拟合就是通过x,y的观测值来寻求参数b的最佳估计值，及寻求最佳的理论曲线y=f(x; b)。当函数y=f(x; b)为关于b的i线性函数时，称这种曲线拟合为线性拟合」$$ y = wx +b $$ 拟合曲线和实际的y的差值是Δy_i，由此给出损失函数J（m是样本个数）：$$ J = 1/2m ∑(Δy_i^2) = 1/2m ∑[y_i - (wx_i + b)]^2 $$ 线性拟合的最优解, 即找到w（这里暂不考虑参数b）使J最小 ，上例中只有2个参数，最小二乘可以解决，但是参数非常多就不适合了，这里需要梯度下降算法 求偏导数: $$ ∂y/∂w =&gt; w_{n+1} = w_n - η ∂y/∂w $$ 通过多次迭代（从w0 →w1 →w2），找到到J最小时的w， 即梯度下降是算法寻找参数最优值，使这也是模型训练的过程 线性拟合_百度百科 最小二乘法 - 维基百科，自由的百科全书微积分中，符号 d 与符号 ∂ 的区别是什么？ - 知乎 神经网络(Neural Network)典型神经元结构 M-P模型：每个神经元都有多个输入端（X1~Xn），W1j~Wnj是每个输入的参数，一个输出端Oj（但可以输出给多个刺激） 上图f即为激活函数（Sigmoid），决定是否向下一层输出，常用的如下： 多个M-P模型的神经元组合为简单神经网络, 以及包含有更多隐层的多层神经网络(DNN): 为了解决DNN调参复杂度(每层的链接对应的参数都需要调), 辛顿提出的反向传播(BP)算法:从最后一层参数开始调, 然后调前一层的参数 深度学习领域最常用的10个激活函数，一文详解数学原理及优缺点 卷积神经网络 - 维基百科，自由的百科全书 反向传播算法 - 维基百科，自由的百科全书 如何直观地解释 backpropagation 算法？ - 知乎 卷积神经网络如何识别简单字母卷积神经网络Convolutional Neural Networks 步骤1：卷积 • 卷积核：通常是3x3 or 5x5 • 原图像，对卷积核做卷积运算（每个位置相乘再相加，得到一个数） • 最终得到“特征图” 步骤2：池化、激活这里用最大池化法，四个为一组（左上角2-0-0-3），选出最大的3，作为新的特征图的一个点： 对池化后的特征图，做激活处理： • 如果第一次卷积运算用了3个卷积核，那么会得到3个特征图（X-Y-Z） • 3个特征图做池化处理，进一步减少数据量 • 3个特征图再次卷积运算(这次用了4个卷积核)，那么得到4个特征图 下图是第二次卷积 （输入=3个特征图，4个卷积核，每个核都是3维，输出=4个特征图） 经过多次卷积，可以找到多种特征（线条、颜色等），输入到全连接网络进行训练","categories":[{"name":"34.Machine-Learning","slug":"34-Machine-Learning","permalink":"https://beefyheisenberg.github.io/categories/34-Machine-Learning/"}],"tags":[]},{"title":"推荐系统","slug":"34.Machine-Learning/RecommenderSystem-推荐系统","date":"2024-01-24T01:27:52.930Z","updated":"2024-01-24T01:27:52.930Z","comments":true,"path":"34.Machine-Learning/RecommenderSystem-推荐系统/","link":"","permalink":"https://beefyheisenberg.github.io/34.Machine-Learning/RecommenderSystem-推荐系统/","excerpt":"系统架构 效果评估先了解一个概念: 混淆矩阵 混淆矩阵是用来总结一个分类器结果的矩阵。对于k元分类，其实它就是一个k x k的表格，用来记录分类器的预测结果。对于最常见的二元分类来说，它的混淆矩阵是2乘2的，如下","text":"系统架构 效果评估先了解一个概念: 混淆矩阵 混淆矩阵是用来总结一个分类器结果的矩阵。对于k元分类，其实它就是一个k x k的表格，用来记录分类器的预测结果。对于最常见的二元分类来说，它的混淆矩阵是2乘2的，如下 TP = True Postive = 真阳性； FP = False Positive = 假阳性FN = False Negative = 假阴性； TN = True Negative = 真阴性 一般来说, 推荐效果的指标有: 准确率（Precision）和召回率（Recall）设R(u)是根据用户在训练集上的行为给用户作出的推荐列表，而T(u)是用户在测试集上的行为列表。对用户u推荐N个物品（记为R(u)），令用户u在测试集上喜欢的物品集合为T(u)，然后可以通过准确率/召回率评测推荐算法的精度： F-score/F-measure这是一种同时考虑准确率和召回率的指标。公式如下：可以看出F的取值范围从0到1。另外还有一种F的变体如下所示：常用的两种设置是和，前者中recall重要程度是precision的两倍，后者则相反，precision重要程度是recall的两倍。 CTR（点击率）: CTR（Click-Through-Rate）即点击通过率，是互联网广告常用的术语，指网络广告（图片广告/文字广告/关键词广告/排名广告/视频广告等）的点击到达率，即该广告的实际点击次数（严格的来说，可以是到达目标页面的数量）除以广告的展现量（Show content）。 CVR（转化率）: CVR (Conversion Rate)即转化率。是一个衡量CPA广告效果的指标，简言之就是用户点击广告到成为一个有效激活或者注册甚至付费用户的转化率。CVR=(转化量/点击量)*100% 停留时间(Duration) @ref: 推荐系统排序（Ranking）评价指标 - CuriousZero - 博客园 推荐算法推荐算法大致可以分为以下几类： ①基于流行度的算法: 简单粗暴，类似于各大新闻、微博热榜等，根据PV、UV、日均PV或分享率等数据来按某种热度排序来推荐给用户。 ②协同过滤算法(Collaborative Filtering, CF): Memory-based推荐：这两种方法都是将用户的所有数据读入到内存中进行运算的，因此成为Memory-based Collaborative Filtering。Memory-based推荐方法通过执行最近邻搜索，把每一个Item或者User看成一个向量，计算其他所有Item或者User与它的相似度。有了Item或者User之间的两两相似度之后，就可以进行预测与推荐了。CF算法简单原理是User喜欢那些具有相似兴趣的Users喜欢过的Items。包括： Item-based方法：基于用户的协同过滤算法（user-based collaboratIve filtering）； User-based方法：基于Item的协同过滤算法（item-based collaborative filtering）； Model-based推荐（Model-based collaborative filtering）包括Aspect Model，pLSA，LDA，聚类，SVD，Matrix Factorization等，这种方法训练过程比较长，但是训练完成后，推荐过程比较快。 Model-based推荐最常见的方法为Matrix factorization. 矩阵分解通过把原始的评分矩阵R分解为两个矩阵相乘，并且只考虑有评分的值，训练时不考虑missing项的值。R矩阵分解成为U与V两个矩阵后，评分矩阵R中missing的值就可以通过U矩阵中的某列和V矩阵的某行相乘得到 矩阵分解的目标函数: U矩阵与V矩阵的可以通过梯度下降(gradient descent)算法求得，通过交替更新u与v多次迭代收敛之后可求出U与V。 矩阵分解背后的核心思想，找到两个矩阵，它们相乘之后得到的那个矩阵的值，与评分矩阵R中有值的位置中的值尽可能接近。这样一来，分解出来的两个矩阵相乘就尽可能还原了评分矩阵R，因为有值的地方，值都相差得尽可能地小，那么missing的值通过这样的方式计算得到，比较符合趋势。 协同过滤中主要存在如下两个问题：稀疏性与冷启动问题。已有的方案通常会通过引入多个不同的数据源或者辅助信息(Side information)来解决这些问题，用户的Side information可以是用户的基本个人信息、用户画像信息等，而Item的Side information可以是物品的content信息等。 ③基于内容的算法: 推荐用户有兴趣的Item在内容上类似的Item。利用word2vec一类工具，可以将文本的关键词聚类，然后根据topic将文本向量化。这种方法可以避免Item的冷启动问题（冷启动：如果一个Item从没有被关注过，其他推荐算法则很少会去推荐，但是基于内容的推荐算法可以分析Item之间的关系，实现推荐），弊端在于推荐的Item可能会重复，典型的就是新闻推荐 ④基于模型的算法: LR, FM, DNN, CNN, RNN 逻辑回归（Logistic Regression）是机器学习中的一种分类模型，由于算法的简单和高效，在实际中应用非常广泛。 因子分解机(Factorization Machine) 以下简称FM，是由Steffen Rendle在2010年提出的，模型主要通过特征组合来解决大规模稀疏数据的分类问题。 基于卷积神经网络（CNN）的推荐系统：此种系统中的卷积神经网络大多是用于特征提取（feature extraction）的； 基于循环神经网络（RNN）的推荐系统：循环神经网络特别适用于处理推荐系统中的评级和序列特征的时序动态； 基于深度语义相似性模型（Deep Semantic Similarity Model）的推荐系统：深度语义相似性模型（DSSM）是一种广泛应用于信息检索领域的深度神经网络。它非常适用于排行榜（top-n）推荐。基础型DSSM由MLP组成，更高级的神经层比如卷积层和最大池化（max-pooling）层可以被很容易地添加进去； 上面的FM, FFM, Deep FM都是基于CTR预估算法的 下图总结了基于深度学习的推荐系统分类的二维体系，左侧部分对神经网络模型进行了说明，右侧部分则说明了整合模型。 ⑤基于知识的推荐（Knowledge-based Recommendation）在某种程度是可以看成是一种推理（Inference）技术，它不是建立在用户需要和偏好基础上推荐的。基于知识的方法因它们所用的功能知识不同而有明显区别。效用知识（Functional Knowledge）是一种关于一个项目如何满足某一特定用户的知识，因此能解释需要和推荐的关系，所以用户资料可以是任何能支持推理的知识结构，它可以是用户已经规范化的查询，也可以是一个更详细的用户需要的表示。 召回召回(recall): 推荐系统往往只推荐有限个（如k个）物品给某个用户。真正相匹配的物品我们称之为 相关物品 （也就是二元分类中的阳性）。 召回率(recall) = 所推荐的k个物品中相关物品的个数 ÷ 所有相关物品的个数 精度(precision) = 所推荐的k个物品中相关物品的个数 ÷ k 比如说，根据你的喜好我们推荐了10个商品，其中真正相关的是5个商品。在所有商品当中，相关的商品一共有20个，那么：召回率 = 5 / 20精度 = 5 / 10 附录推荐系统技能树:","categories":[{"name":"34.Machine-Learning","slug":"34-Machine-Learning","permalink":"https://beefyheisenberg.github.io/categories/34-Machine-Learning/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://beefyheisenberg.github.io/tags/机器学习/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://beefyheisenberg.github.io/tags/Machine-Learning/"},{"name":"推荐系统","slug":"推荐系统","permalink":"https://beefyheisenberg.github.io/tags/推荐系统/"},{"name":"Recommend","slug":"Recommend","permalink":"https://beefyheisenberg.github.io/tags/Recommend/"}]},{"title":"笔记：机器学习","slug":"34.Machine-Learning/MachineLearning-机器学习","date":"2024-01-24T01:27:52.925Z","updated":"2024-01-24T01:27:52.926Z","comments":true,"path":"34.Machine-Learning/MachineLearning-机器学习/","link":"","permalink":"https://beefyheisenberg.github.io/34.Machine-Learning/MachineLearning-机器学习/","excerpt":"机器学习入门 Google机器学习速成课程 机器学习100天 概念 @ref: 机器学习术语表 | Google Developers","text":"机器学习入门 Google机器学习速成课程 机器学习100天 概念 @ref: 机器学习术语表 | Google Developers 基本(feature/label) 特征 (feature) : 在进行预测时使用的输入变量。特征是事物固有属性。 标签 (label): 标签是根据固有属性产生的认知，并不一定是事物本身所具有的属性。在监督式学习中，标签指样本的“答案”或“结果”部分。有标签数据集中的每个样本都包含一个或多个特征以及一个标签。例如，在房屋数据集中，特征可能包括卧室数、卫生间数以及房龄，而标签则可能是房价。在垃圾邮件检测数据集中，特征可能包括主题行、发件人以及电子邮件本身，而标签则可能是“垃圾邮件”或“非垃圾邮件”。 权重 (weight):线性模型中特征的系数，或深度网络中的边。训练线性模型的目标是确定每个特征的理想权重。如果权重为 0，则相应的特征对模型来说没有任何贡献。 标签是一个主观归纳性描述；特征则是一个客观的细节性描述。 监督/非监督(supervised/unsupervised) 监督式机器学习 (supervised machine learning):根据输入数据及其对应的标签来训练模型。监督式机器学习类似于学生通过研究一系列问题及其对应的答案来学习某个主题。在掌握了问题和答案之间的对应关系后，学生便可以回答关于同一主题的新问题（以前从未见过的问题）。请与非监督式机器学习进行比较。 非监督式机器学习 (unsupervised machine learning): 训练模型，以找出数据集（通常是无标签数据集）中的规律。 非监督式机器学习最常见的用途是将数据分为不同的聚类，使相似的样本位于同一组中。例如，非监督式机器学习算法可以根据音乐的各种属性将歌曲分为不同的聚类。所得聚类可以作为其他机器学习算法（例如音乐推荐服务）的输入。在很难获取真标签的领域，聚类可能会非常有用。例如，在反滥用和反欺诈等领域，聚类有助于人们更好地了解相关数据。 半监督式学习 (semi-supervised learning):训练模型时采用的数据中，某些训练样本有标签，而其他样本则没有标签。半监督式学习采用的一种技术是推断无标签样本的标签，然后使用推断出的标签进行训练，以创建新模型。如果获得有标签样本需要高昂的成本，而无标签样本则有很多，那么半监督式学习将非常有用。 监督式机器学习 vs 非监督式机器学习最简单也最普遍的一类机器学习算法就是分类（classification）。对于分类，输入的训练数据有特征（feature），有标签（label）。所谓的学习，其本质就是找到特征和标签间的关系（mapping）。这样当有特征而无标签的未知数据输入时，我们就可以通过已有的关系得到未知数据标签。在上述的分类过程中，如果所有训练数据都有标签，则为有监督学习（supervised learning）。如果数据没有标签，显然就是无监督学习（unsupervised learning）了，也即聚类（clustering）。目前分类算法的效果还是不错的，但相对来讲，聚类算法就有些惨不忍睹了。确实，无监督学习本身的特点使其难以得到如分类一样近乎完美的结果。 特征(feature) 离散特征 (discrete feature)一种特征，包含有限个可能值。例如，某个值只能是“动物”、“蔬菜”或“矿物”的特征便是一个离散特征（或分类特征）。与连续特征相对。 连续特征 (continuous feature)一种浮点特征，可能值的区间不受限制。与离散特征相对。 稀疏特征 (sparse feature):一种特征向量，其中的大多数值都为 0 或为空。例如，某个向量包含一个为 1 的值和一百万个为 0 的值，则该向量就属于稀疏向量。再举一个例子，搜索查询中的单词也可能属于稀疏特征 - 在某种指定语言中有很多可能的单词，但在某个指定的查询中仅包含其中几个。 密集特征 (dense feature)一种大部分值是非零值的特征，通常是浮点值张量。与稀疏特征相对。 样本(example) 有标签样本 (labeled example):包含特征和标签的样本。在监督式训练中，模型从有标签样本中学习规律 无标签样本 (unlabeled example):包含特征但没有标签的样本。无标签样本是用于进行推断的输入内容。在半监督式和非监督式学习中，在训练期间会使用无标签样本。 集(set) 训练集 (training set):数据集的子集，用于训练模型。与验证集和测试集相对。 测试集 (test set):数据集的子集，用于在模型经由验证集的初步验证之后测试模型。 验证集 (validation set):数据集的一个子集，从训练集分离而来，用于调整超参数。 模型(model) 模型 (model): 机器学习系统从训练数据学到的内容的表示形式。多含义术语，可以理解为下列两种相关含义之一： 一种 TensorFlow 图，用于表示预测的计算结构。 该 TensorFlow 图的特定权重和偏差，通过训练决定。 分类模型 (classification model):一种机器学习模型，用于区分两种或多种离散类别。例如，某个自然语言处理分类模型可以确定输入的句子是法语、西班牙语还是意大利语。请与回归模型进行比较。 回归模型 (regression model):一种模型，能够输出连续的值（通常为浮点值）。请与分类模型进行比较，分类模型会输出离散值。 广义线性模型 (generalized linear model)最小二乘回归模型（基于高斯噪声）向其他类型的模型（基于其他类型的噪声，例如泊松噪声或分类噪声）进行的一种泛化。广义线性模型的功能受其特征的限制。与深度模型不同，广义线性模型无法“学习新特征”。广义线性模型具有以下特性： 最优的最小二乘回归模型的平均预测结果等于训练数据的平均标签。 最优的逻辑回归模型预测的平均概率等于训练数据的平均标签。广义线性模型的示例包括： 逻辑回归 /LR (logistic regression): 一种模型，通过将 S 型函数应用于线性预测，生成分类问题中每个可能的离散标签值的概率。虽然逻辑回归经常用于二元分类问题，但也可用于多类别分类问题（其叫法变为多类别逻辑回归或多项回归）。 多类别回归: 最小二乘回归: 宽度模型 (wide model)一种线性模型，通常有很多稀疏输入特征。我们之所以称之为“宽度模型”，是因为这是一种特殊类型的神经网络，其大量输入均直接与输出节点相连。与深度模型相比，宽度模型通常更易于调试和检查。虽然宽度模型无法通过隐藏层来表示非线性关系，但可以利用特征组合、分桶等转换以不同的方式为非线性关系建模。 深度模型 (deep model)一种神经网络，其中包含多个隐藏层。深度模型依赖于可训练的非线性关系。 模型训练(model training) 模型训练 (model training):确定最佳模型的过程。 迭代 (iteration):模型的权重在训练期间的一次更新。迭代包含计算参数在单批次数据上的梯度损失。 批次 (batch):模型训练的一次迭代（即一次梯度更新）中使用的样本集。 批次大小 (batch size): 一个批次中的样本数。例如，SGD 的批次大小为 1，而小批次的大小通常介于 10 到 1000 之间。批次大小在训练和推断期间通常是固定的；不过，TensorFlow 允许使用动态批次大小。 函数(function) 激活函数 (activation function):一种函数（例如 ReLU 或 S 型函数），用于对上一层的所有输入求加权和，然后生成一个输出值（通常为非线性值），并将其传递给下一层。 S 型函数 (sigmoid function):一种函数，可将逻辑回归输出或多项回归输出（对数几率）映射到概率，以返回介于 0 到 1 之间的值。S 型函数的公式如下：在逻辑回归问题中， σ 非常简单：换句话说，S 型函数可将 转换为介于 0 到 1 之间的概率。在某些神经网络中，S 型函数可作为激活函数使用。 修正线性单元 (ReLU, Rectified Linear Unit):一种激活函数，其规则如下： 如果输入为负数或 0，则输出 0。 如果输入为正数，则输出等于输入。 正反(positive/negative) 正类别 (positive class):在二元分类中，两种可能的类别分别被标记为正类别和负类别。正类别结果是我们要测试的对象。（不可否认的是，我们会同时测试这两种结果，但只关注正类别结果。）例如，在电子邮件分类器中，正类别可以是“垃圾邮件”。 负类别 (negative class):在二元分类中，一种类别称为正类别，另一种类别称为负类别。正类别是我们要寻找的类别，负类别则是另一种可能性。例如，在医学检查中，负类别可以是“非肿瘤”。在电子邮件分类器中，负类别可以是“非垃圾邮件”。另请参阅正类别。 正例 (TP, true positive):被模型正确地预测为正类别的样本。例如，模型推断出某封电子邮件是垃圾邮件，而该电子邮件确实是垃圾邮件。 负例 (TN, true negative):被模型正确地预测为负类别的样本。例如，模型推断出某封电子邮件不是垃圾邮件，而该电子邮件确实不是垃圾邮件。 假正例 (FP, false positive):被模型错误地预测为正类别的样本。例如，模型推断出某封电子邮件是垃圾邮件（正类别），但该电子邮件其实不是垃圾邮件。 假负例 (FN, false negative):被模型错误地预测为负类别的样本。例如，模型推断出某封电子邮件不是垃圾邮件（负类别），但该电子邮件其实是垃圾邮件。 混淆矩阵 (confusion matrix):一种 NxN 表格，用于总结分类模型的预测效果；即标签和模型预测的分类之间的关联。在混淆矩阵中，一个轴表示模型预测的标签，另一个轴表示实际标签。N 表示类别个数。在二元分类问题中，N=2。 精确率 (precision):一种分类模型指标。精确率指模型正确预测正类别的频率，即：正例数 / 正例数 + 假正例数 召回率 (recall): 用于回答以下问题：在所有可能的正类别标签中，模型正确地识别出了多少个？即召回率 = 正例数 / (正例数 + 假负例数) 未分类概念 协同过滤 (collaborative filtering): 根据很多其他用户的兴趣来预测某位用户的兴趣。协同过滤通常用在推荐系统中。协同过滤推荐是目前业界常用的推荐算法之一。协同过滤推荐是利用users和items的关系矩阵来对user和item进行建模，从而进行推荐的一类算法。其主要分为两种：基于user的协同过滤推荐和基于item的协同过滤推荐。 DAG: 在图论中，如果一个有向图从任意顶点出发无法经过若干条边回到该点，则这个图是一个有向无环图（DAG图）。 反向传播算法 (backpropagation)在神经网络上执行梯度下降法的主要算法。该算法会先按前向传播方式计算（并缓存）每个节点的输出值，然后再按反向传播遍历图的方式计算损失函数值相对于每个参数的偏导数。 机器学习系统分类机器学习有多种类型，可以根据如下规则进行分类： 是否在人类监督下进行训练（监督，非监督，半监督和强化学习） 是否可以动态渐进学习（在线学习 vs批量学习） 它们是否只是通过简单地比较新的数据点和已知的数据点，或者在训练数据中进行模式识别，以建立一个预测模型，就像科学家所做的那样（基于实例学习 vs基于模型学习） 监督/非监督学习监督学习主要有两个常见的典型的任务–分类和回归。 a.监督学习分类(classification)分类问题主要就是预测新数据的类别问题。例如上文提到的垃圾邮件过滤器就是一个二分类问题，将邮件分为垃圾邮件还是正常的邮件，如下图所示。 回归(regression)回归问题主要是预测目标数值。比如给定预测房价的问题，给定一些特征，如房子大小、房间数量、地理位置等等，然后预测房子的价格。如下图所示： b.非监督学习非监督主要有四个典型的任务，分别是聚类、降维、异常检测和关联规则学习。 聚类 (clustering)聚类就是将数据根据一定的规则分成多个类，通常是采用相似性。比如对于博客访客的聚类，通过聚类算法，检测相似性访客的分组，如下图所示。不需要告诉算法访客是哪个类别，它会自动根据访客的属性找到相互间的关系 降维降维的目的是简化数据、但是不能失去大部分信息。做法之一是合并若干相关的特征。例如，汽车的里程数与车龄高度相关，降维算法就会将它们合并成一个，表示汽车的磨损。这叫做特征提取。 此外，在采用机器学习算法训练的时候，可以对训练集进行降维，这样有助于提高训练速度，降低占用的硬盘和内存空间，有时候也能提高算法的性能，但必须选择合适的降维算法，否则性能实际上是很有可能会下降的。 异常检测另一个重要的非监督任务是异常检测（anomaly detection）。例如，检测异常的信用卡转账以防欺诈，检测制造缺陷，或者在训练之前自动从训练数据集去除异常值。异常检测的系统使用正常值训练的，当它碰到一个新实例，它可以判断这个新实例是像正常值还是异常值。 关联规则学习最后，另一个常见的非监督任务是关联规则学习，它的目标是挖掘大量数据以发现属性间有趣的关系。例如，假设你拥有一个超市。在销售日志上运行关联规则，可能发现买了烧烤酱和薯片的人也会买牛排。因此，你可以将这些商品放在一起。 c.半监督学习一些算法可以处理部分带标签的训练数据，通常是大量不带标签数据加上小部分带标签数据。这称作半监督学习。如下图所示，图中灰色圆点表示没有标签的数据，仅有几个三角形和正方形点表示带标签的数据。 多数半监督学习算法是非监督和监督算法的结合。 例如，深度信念网络（deep belief networks）是基于被称为互相叠加的受限玻尔兹曼机（restricted Boltzmann machines，RBM）的非监督组件。RBM 是先用非监督方法进行训练，再用监督学习方法进行整个系统微调。 如一些图片存储服务，比如 Google Photos，是半监督学习的好例子。一旦你上传了所有家庭相片，它就能自动识别相同的人 A 出现了相片1、5、11 中，另一个人 B 出现在了相片 2、5、7 中。这是算法的非监督部分（聚类）。现在系统需要的就是你告诉这两个人是谁。只要给每个人一个标签，算法就可以命名每张照片中的每个人，特别适合搜索照片。 d.强化学习强化学习和上述三种学习问题是非常不同的。学习系统在这里被称为智能体（ agent），可以对环境进行观察，选择和执行动作，获得奖励（负奖励是惩罚，见下图）。然后它必须自己学习哪个是最佳方法（称为策略，policy），以得到长久的最大奖励。策略决定了智能体在给定情况下应该采取的行动 。 目前强化学习的应用还不算非常广，特别是结合了深度学习的强化学习，主要是应用在机器人方面，当然最著名的一个应用就是 DeepMind 的 AlphaGo 了，它是通过分析数百万盘棋局学习制胜策略，然后自己和自己下棋。要注意，在比赛中机器学习是关闭的；AlphaGo 只是使用它学会的策略。 批量/在线学习第二种分类机器学习的准则是，它是否能从导入的数据流进行持续学习。也就是如果导入的是持续的数据流，机器学习算法能否在不断采用新数据来训练已经训练好的模型，并且新的模型对新旧数据都还有很好的性能。 a.批量学习在批量学习中，系统不能进行持续学习：必须用所有可用数据进行训练。这通常会占用大量时间和计算资源，所以一般是线下做的。首先是进行训练，然后部署在生产环境且停止学习，它只是使用已经学到的策略。这称为离线学习。 对于批量学习算法来说，当获取到新数据的时候，就需要重新重头训练整个数据集，然后更新模型，如果是应用该算法系统，那就相当于需要更新系统，需要停掉旧版本的系统，重新上线新版本的系统。当然，一般训练、评估、部署一套机器学习的系统的整个过程可以自动进行，所以即便是批量学习也可以适应改变。只要有需要，就可以方便地更新数据、训练一个新版本。并且对于更新周期，可以选择每 24 小时或者每周更新一次。 但是，批量学习还是存在下面的缺点： 实时性差，即对于需要快速适应变化的系统，比如预测股票变化、电商推荐系统等，就不适合采用批量学习算法； 耗费大量计算资源，用全部数据训练需要大量计算资源（CPU、内存空间、磁盘空间、磁盘 I/O、网络 I/O 等等），特别是训练集特别大的情况，更加凸显这个问题的严峻性； 无法应用在资源有限的设备上，比如需要自动学习的系统，但是如果采用智能手机，每次采用大量训练数据重新训练几个小时是非常不实际的。 b.在线学习批量学习的缺陷和问题可以通过采用在线学习算法来解决。 在在线学习中，是用数据实例持续地进行训练，可以一次一个或一次几个实例（称为小批量）。每个学习步骤都很快且廉价，所以系统可以动态地学习到达的新数据。在线学习虽然名字带着在线两个字，但是实际上它的训练过程也是离线的，因此应该说是持续学习或者增量学习。 基于实例/基于模型学习第三种分类机器学习的方法是判断它们是如何进行归纳推广的。大多机器学习任务是关于预测的。这意味着给定一定数量的训练样本，系统需要能推广到之前没见到过的样本。对训练数据集有很好的性能还不够，真正的目标是对新实例预测的性能。有两种主要的归纳方法：基于实例学习和基于模型学习。 a.基于实例学习基于实例学习是系统先用记忆学习案例，然后使用相似度测量推广到新的例子，如下图所示： 这种学习算法可以说是机器学习中最简单的算法了，它实际上就是采用存储的数据集进行分类或者回归，典型的算法就是 KNN 算法，即 K 近邻算法，它就是将新的输入数据和已经保存的训练数据采用相似性度量（一般采用欧式距离）得到最近的 K 个训练样本，并采用 K 个训练样本中类别出现次数最多的类别作为预测的结果。 所以，这种算法的缺点就比较明显了： 一是对存储空间的需求很大，需要占用的空间直接取决于实例数量的大小； 二是运行时间比较慢，因为需要需要与已知的实例进行比对。 b.基于模型学习和基于实例学习相反的就是基于模型学习：建立这些样本的模型，然后使用这个模型进行预测。如下图所示： 基于模型学习算法的流程一般如下所示： 研究数据。先对数据进行分析，这可能包含清洗数据、特征筛选、特征组合等等 选择模型。选择合适的模型，从简单的线性回归、逻辑回归，到慢慢复杂的随机森林、集成学习，甚至深度学习的卷积神经网络模型等等 用训练数据进行训练。也就是寻找最适合算法模型的参数，使得代价函数取得最小值。 使用模型对新案例进行预测（这称作推断）。预测结果非常好，就能上线系统；如果不好，就需要进行错误分析，问题出现在哪里，是数据问题还是模型问题，找到问题，然后继续重复这个流程。 训练过程 算法汇总 开发过程 开发过程: 收集数据: 收集样本数据 准备数据: 注意数据的格式 分析数据: 为了确保数据集中没有垃圾数据； 如果是算法可以处理的数据格式或可信任的数据源，则可以跳过该步骤； 另外该步骤需要人工干预，会降低自动化系统的价值。 训练算法: 如果使用无监督学习算法，由于不存在目标变量值，则可以跳过该步骤 测试算法: 评估算法效果 使用算法: 将机器学习算法转为应用程序 算法理论 机器学习中的有监督学习，无监督学习，半监督学习 通俗易懂说数据挖掘十大经典算法 - 知乎 数据挖掘10大算法详细介绍 - 云+社区 机器学习 Algorithm Cheat Sheet： 有监督学习算法LR 逻辑回归(Logistics Regression) 线性回归及梯度下降算法详解 kNN k-近邻算法 KNN算法（有监督学习算法） FM 因子分解机(Factorization Machine) 因子分解机(Factorization Machine, FM) 是由Steffen Rendle提出的一种基于矩阵分解的机器学习算法。目前，被广泛的应用于广告预估模型中 FM算法详解 FFM Field-aware Factorization Machines(FFM) 朴素贝叶斯 Naive Bayes 带你理解朴素贝叶斯分类算法 - 知乎 SVM 支持向量机（Support Vector Machine） 聊聊SVM - 知乎 决策树 决策树（Decision Tree） 决策树算法（有监督学习算法） 随机森林 Random Forest 随机森林算法（有监督学习） boosting 集成学习的两个流派，bagging &amp; boosting派系 bagging和boosting算法（集成学习算法） 无监督学习算法k-均值 k-means 算法 K-means聚类算法（无监督学习算法） 分层聚类PCA 主成分分析（Principal Component Analysis） DBSCAN DBSCAN，英文全写为Density-based spatial clustering of applications with noise ，是在 1996 年由Martin Ester, Hans-Peter Kriegel, Jörg Sander 及 Xiaowei Xu 提出的聚类分析算法， 这个算法是以密度为本的：给定某空间里的一个点集合，这算法能把附近的点分成一组（有很多相邻点的点），并标记出位于低密度区域的局外点（最接近它的点也十分远），DBSCAN 是其中一个最常用的聚类分析算法 机器学习框架 13种主流机器学习的框架 Spark MLlibMLib是主要面向数学和统计用户的平台，它允许 通过持久化管道特性将Spark机器学习工作挂起和恢复。2016年发布的Spark2.0，对Tungsten高速内存管理系统和新的DataFrames流媒体API 进行了改进，这两点都会提升机器学习应用的性能。 TensorFlow一个大型的分布式机器学习平台。该术语还指 TensorFlow 堆栈中的基本 API 层，该层支持对数据流图进行一般计算。虽然 TensorFlow 主要应用于机器学习领域，但也可用于需要使用数据流图进行数值计算的非机器学习任务。 ensorFlow Playground:一款用于直观呈现不同的超参数对模型（主要是神经网络）训练的影响的程序。要试用 TensorFlow Playground，请前往 http://playground.tensorflow.org。 TensorFlow Serving:一个平台，用于将训练过的模型部署到生产环境。 张量 (Tensor):TensorFlow 程序中的主要数据结构。张量是 N 维（其中 N 可能非常大）数据结构，最常见的是标量、向量或矩阵。张量的元素可以包含整数值、浮点值或字符串值。 会话 (tf.session):封装了 TensorFlow 运行时状态的对象，用于运行全部或部分图。在使用底层 TensorFlow API 时，您可以直接创建并管理一个或多个 tf.session 对象。在使用 Estimator API 时，Estimator 会为您创建会话对象。 输入函数 (input function):在 TensorFlow 中，用于将输入数据返回到 Estimator 的训练、评估或预测方法的函数。例如，训练输入函数会返回训练集中的一批特征和标签。 图 (graph):TensorFlow 中的一种计算规范。图中的节点表示操作。边缘具有方向，表示将某项操作的结果（一个张量）作为一个操作数传递给另一项操作。可以使用 TensorBoard 直观呈现图。 Layers API (tf.layers):一种 TensorFlow API，用于以层组合的方式构建深度神经网络。通过 Layers API，您可以构建不同类型的层，例如： 通过 tf.layers.Dense 构建全连接层。 通过 tf.layers.Conv2D 构建卷积层。 Metrics API (tf.metrics):一种用于评估模型的 TensorFlow API。例如，tf.metrics.accuracy 用于确定模型的预测与标签匹配的频率。在编写自定义 Estimator 时，您可以调用 Metrics API 函数来指定应如何评估您的模型。 机器学习相关数学知识高等数学 导数及偏导数，对应机器学习中的梯度，机器学习中学习的参数需要通过梯度下降进行更新； 复合函数的链式法则，同1一样，目的也是为了求出梯度更新参数，但因为深度学习网络有多层，所以模型的预测函数是个复合函数，我们需要通过链式法则从后往前求出每层参数的梯度，进而更新每层里的参数，这也就是“反向传播法”； 了解数学中的最优化问题，大概就是目标函数在什么条件下能够取到最值的问题，因为机器学习的问题到最后都是要转化为一个损失函数最优化的问题。 线性代数 标量、向量、矩阵及张量的定义及运算，机器学习的过程其实也就是矩阵计算的过程(GPU在矩阵计算上天然有很大的优势)。 范数，对应机器学习中正则项，正则项通常会加在已有的损失函数上用来减少训练的过拟合问题； 常见的距离计算方式：欧式距离、曼哈顿距离、余弦距离等，我们之前说过数据样本可以表示为其特征空间里的点，而距离可以用来衡量他们的相似度。 概率论 条件概率、贝叶斯，基于概率论的分类方法经常会用到； 期望与方差，机器学习里一般都会对数据进行normalized的处理，这个时候很可能会用到期望和方差； 协方差，能够表征两个变量的相关性，在PCA降维算法中有用到，变量越相关，我们越可能对他们进行降维处理； 常见分布：0-1分布、二项分布、高斯分布等，高斯分布很重要，数据normalized跟它有关，参数的初始化特跟它有关； 最大似然估计，在推导逻辑回归的损失函数时会用到。 附录：机器学习算法技能树","categories":[{"name":"34.Machine-Learning","slug":"34-Machine-Learning","permalink":"https://beefyheisenberg.github.io/categories/34-Machine-Learning/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://beefyheisenberg.github.io/tags/机器学习/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://beefyheisenberg.github.io/tags/Machine-Learning/"}]},{"title":"笔记：深度学习","slug":"34.Machine-Learning/DeepLearning-深度学习","date":"2024-01-24T01:27:52.920Z","updated":"2024-01-24T01:27:52.921Z","comments":true,"path":"34.Machine-Learning/DeepLearning-深度学习/","link":"","permalink":"https://beefyheisenberg.github.io/34.Machine-Learning/DeepLearning-深度学习/","excerpt":"深度学习入门机器学习 vs 深度学习机器学习 通过算法分析数据，从结果中进行学习，然后将「学习后的算法」用来做出决策或进行预测，例子有我们熟悉的聚类、贝叶斯网络和视觉数据映射等等。 深度学习，深度学习是机器学习的一个子集，和其它所有机器学习一样都是基于算法。然而它并非像「数据分类」一样根据任务选择的算法，而是模仿人类大脑结构与运算过程——识别非结构化输入的数据，输出精确地行为和决策。机器学习可以是监督的也可以是非监督的，这意味着大型神经网络可以接受「标签化输入」，但并不需要。","text":"深度学习入门机器学习 vs 深度学习机器学习 通过算法分析数据，从结果中进行学习，然后将「学习后的算法」用来做出决策或进行预测，例子有我们熟悉的聚类、贝叶斯网络和视觉数据映射等等。 深度学习，深度学习是机器学习的一个子集，和其它所有机器学习一样都是基于算法。然而它并非像「数据分类」一样根据任务选择的算法，而是模仿人类大脑结构与运算过程——识别非结构化输入的数据，输出精确地行为和决策。机器学习可以是监督的也可以是非监督的，这意味着大型神经网络可以接受「标签化输入」，但并不需要。 深度学习是机器学习中一种基于对数据进行表征学习的算法。表征学习的目标是寻求更好的表示方法并创建更好的模型来从大规模未标记数据中学习这些表示方法。一部分最成功的深度学习方法涉及到对人工神经网络的运用。“深度”是一个术语。它指的是一个神经网络中的层的数量。浅层神经网络有一个所谓的隐藏层，而深度神经网络则不止一个隐藏层。当一个神经网络处理输入时，它通过输入数据和输出数据创造层，这种级别的深度学习让神经网络从原始数据中「自动抽取特征」而无需人工来贴标签。神经网络由大量被称为神经元的简单处理器构成，处理器用数学公式模仿人类大脑中的神经元。这些人造神经元就是神经网络最基础的「部件」。简而言之，每一个神经元接受两个或更多的输入，处理它们，然后输出一个结果。一些神经元从额外的传感器接收输入，然后其他神经元被其他已激活的神经元激活。神经元可能激活其它的神经元，或者通过触发的行动影响外部环境。所有的行为都是在「自动生成」的隐藏层中发生的，每个连续的图层都会输入前一层的输出。 @ref: 「机器学习」还是「深度学习」，哪个更适合你？ 深度学习框架 机器学习和深度学习的最佳框架大比拼 - 开源中国 TensorFlowTensorFlow深度学习，一篇文章就够了 Caffe2深度学习框架Caffe开发时秉承的理念是“表达、速度和模块化”，最初是源于2013年的机器视觉项目，此后，Caffe还得到扩展吸收了其他的应用，如语音和多媒体。因为速度放在优先位置 ，所以Caffe完全用C+ +实现，并且支持CUDA加速，而且根据需要可以在CPU和GPU处理间进行切换。分发内容包括免费的用于普通分类任务的开源参考模型，以及其他由Caffe用户社区创造和分享的模型。一个新的由Facebook 支持的Caffe迭代版本称为Caffe2，现在正在开发过程中，即将进行1.0发布。其目标是为了简化分布式训练和移动部署，提供对于诸如FPGA等新类型硬件的支持，并且利用先进的如16位浮点数训练的特性。 MXNetMXNet是一个可移植的、可伸缩的深度学习库，是亚马逊的DNN框架的选择，结合了神经网络几何的象征性声明与张量操作的命令性编程。MXNet可跨多个主机扩展到多个GPU，接近线性扩展效率为85％，具有出色的开发速度、可编程性和可移植性。它支持Python，R，Scala，Julia和C ++，支持程度各不相同，它允许你混合符号和命令式编程风格。 DeepLearning4jJava和Scala在Hadoop和Spark之上的深度学习框架。 神经网络神经网络的种类： 基础神经网络：单层感知器，线性神经网络，BP神经网络，Hopfield神经网络等 进阶神经网络：玻尔兹曼机，受限玻尔兹曼机，递归神经网络等 深度神经网络：深度置信网络，卷积神经网络，深度残差网络，LSTM网络等 神经网络的发展图： 感知机原理小结 深度神经网络（DNN）模型与前向传播算法 积神经网络（CNN） 大话卷积神经网络（CNN） CNN经典模型：LeNet 大话CNN经典模型：LeNet CNN经典模型：AlexNet 大话CNN经典模型：AlexNet CNN经典模型：VGGNet 大话CNN经典模型：VGGNet CNN经典模型：GoogLeNet 大话CNN经典模型：GoogLeNet（从Inception v1到v4的演进） 循环神经网络（RNN） 大话循环神经网络（RNN） 度残差网络（DRN） 大话深度残差网络（DRN）ResNet网络原理 度信念网络（DBN） 大话深度信念网络（DBN）","categories":[{"name":"34.Machine-Learning","slug":"34-Machine-Learning","permalink":"https://beefyheisenberg.github.io/categories/34-Machine-Learning/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://beefyheisenberg.github.io/tags/机器学习/"},{"name":"深度学习","slug":"深度学习","permalink":"https://beefyheisenberg.github.io/tags/深度学习/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://beefyheisenberg.github.io/tags/Machine-Learning/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://beefyheisenberg.github.io/tags/Deep-Learning/"}]},{"title":"Storm","slug":"33.Bigdata/Storm","date":"2024-01-24T01:27:52.914Z","updated":"2024-01-24T01:27:52.915Z","comments":true,"path":"33.Bigdata/Storm/","link":"","permalink":"https://beefyheisenberg.github.io/33.Bigdata/Storm/","excerpt":"概述 Storm是一个开源的分布式实时计算系统，可以简单、可靠的处理大量的数据流。被称作“实时的hadoop”。 Storm有很多使用场景：如实时分析，在线机器学习，持续计算， 分布式RPC，ETL等等。 Storm支持水平扩展，具有高容错性，保证每个消息都会得到处理，而且处理速度很快。 Storm的部署和运维都很便捷，而且更为重要的是可以使用任意编程语言来开发应用。 Storm的特点 简单的编程模型:在大数据处理方面相信大家对 hadoop已经耳熟能详，基于 Google Map/Reduce来实现的 Hadoop为开发者提供了map、reduce原语，使并行批处理程序变得非常地简单。同样，Storm也为大数据 的实时计算提供了一些简单优美的原语，这大大降低了开发并行实时处理的任务的复杂性，帮助你快速、高效的开发应用。 水平扩展:在 Storm集群中真正运行 topology的主要有三个实体：工作进程、线程和任务。Storm集群中的每台机器上都可以运行多个工作进程，每个工作进程又可创建多个线程，每个线程可以执行多个任务，任务是真正进行数据处理的实体，我们开发的 spout、bolt就是作为一个或者多个任务的方式执行的。计算任务在多个线程、进程和服务器之间并行进行，支持灵活的水平扩展。 支持多种编程语言:你可以在Storm之上使用各种编程语言。默认支持 Clojure、Java、Ruby和 Python。要增加对其他语言的支持，只需实现一个简单的 Storm通信协议即可。 高可靠性:Storm保证每个消息至少能得到一次完整处理。任务失败时，它会负责从消息源重试消息。spout发出的消息后续可能会触发产生成千上万条消息，可以形象的理解为一棵消息树，其中 spout发出的消息为树根，Storm会跟踪这棵消息树的处理情况，只有当这棵消息树中的所有消息都被处理了，Storm才会认为 spout发出的这个消息已经被“完全处理”。如果这棵消息树中的任何一个消息处理失败了，或者整棵消息树在限定的时间内没有“完全处理”，那么 spout发出的消息就会重发。 高容错性:Storm会管理工作进程和节点的故障。如果在消息处理过程中出了一些异常，Storm会重新安排这个出问题的处理单元。Storm保证一个处理单元永远运行（除非你显式杀掉这个处理单元）。当然，如果处理单元中存储了中间状态，那么当处理单元重新被Storm启动的时候，需要应用自己处理中间状态的恢复。 本地模式:Storm有一个“本地模式”，可以在处理过程中完全模拟Storm集群。这让你可以快速进行开发和单元测试。","text":"概述 Storm是一个开源的分布式实时计算系统，可以简单、可靠的处理大量的数据流。被称作“实时的hadoop”。 Storm有很多使用场景：如实时分析，在线机器学习，持续计算， 分布式RPC，ETL等等。 Storm支持水平扩展，具有高容错性，保证每个消息都会得到处理，而且处理速度很快。 Storm的部署和运维都很便捷，而且更为重要的是可以使用任意编程语言来开发应用。 Storm的特点 简单的编程模型:在大数据处理方面相信大家对 hadoop已经耳熟能详，基于 Google Map/Reduce来实现的 Hadoop为开发者提供了map、reduce原语，使并行批处理程序变得非常地简单。同样，Storm也为大数据 的实时计算提供了一些简单优美的原语，这大大降低了开发并行实时处理的任务的复杂性，帮助你快速、高效的开发应用。 水平扩展:在 Storm集群中真正运行 topology的主要有三个实体：工作进程、线程和任务。Storm集群中的每台机器上都可以运行多个工作进程，每个工作进程又可创建多个线程，每个线程可以执行多个任务，任务是真正进行数据处理的实体，我们开发的 spout、bolt就是作为一个或者多个任务的方式执行的。计算任务在多个线程、进程和服务器之间并行进行，支持灵活的水平扩展。 支持多种编程语言:你可以在Storm之上使用各种编程语言。默认支持 Clojure、Java、Ruby和 Python。要增加对其他语言的支持，只需实现一个简单的 Storm通信协议即可。 高可靠性:Storm保证每个消息至少能得到一次完整处理。任务失败时，它会负责从消息源重试消息。spout发出的消息后续可能会触发产生成千上万条消息，可以形象的理解为一棵消息树，其中 spout发出的消息为树根，Storm会跟踪这棵消息树的处理情况，只有当这棵消息树中的所有消息都被处理了，Storm才会认为 spout发出的这个消息已经被“完全处理”。如果这棵消息树中的任何一个消息处理失败了，或者整棵消息树在限定的时间内没有“完全处理”，那么 spout发出的消息就会重发。 高容错性:Storm会管理工作进程和节点的故障。如果在消息处理过程中出了一些异常，Storm会重新安排这个出问题的处理单元。Storm保证一个处理单元永远运行（除非你显式杀掉这个处理单元）。当然，如果处理单元中存储了中间状态，那么当处理单元重新被Storm启动的时候，需要应用自己处理中间状态的恢复。 本地模式:Storm有一个“本地模式”，可以在处理过程中完全模拟Storm集群。这让你可以快速进行开发和单元测试。 Storm是如何工作的对于一个Storm集群，有两类节点：主节点master node和工作节点worker nodes。 Master Node ZK Cluster Worker Node Topology v v v v +-----+ +---------------------+ | ZK1 | |Supervisor |Worker*N | --&gt; Spout -&gt; Bolt | | +---------------------++------+ +-----+ ---&gt;|Nimbus| ---&gt; | ZK2 | +---------------------++------+ | | |Supervisor |Worker*N | +-----+ +---------------------+ | ZK..| ---&gt; | | +---------------------+ +-----+ |Supervisor |Worker*N | +---------------------+ 主节点(master node)运行着一个叫做 Nimbus的守护进程。这个守护进程负责在集群中分发代码，为工作节点分配任务，并监控故障。 每个工作节(worker nodes)点都运行着一个 Supervisor守护进程, Supervisor作为拓扑的一部分运行在工作节点上。一个 Storm拓扑结构在不同的机器上运行着众多的工作节点。 每个 Supervisor中运行着多个 Workers进程，每个 Worker进程中运行着多个 Executor线程。每个 Executor线程会循环调用 Task实例(Task是Spout/Bolt的实例)的nextTuple或execute方法。Storm默认是1个(Spout/Bolt)只生成1个 Task。 数据的分发和处理分别是 Spout和 Bolt, Spout和 Bolt由 Stream Grouping连接起来的节点网络被称为: Topology(拓扑)。 下图是Storm各组件之间的数据交互图，可以看出Nimbus和Supervisor之间没有直接交互。Storm所有元数据信息/状态都是保存在Zookeeper上，Nimbus在Zookeeper上保存所有的集群状态，单个守护进程可以是无状态的而且失效或重启时不会影响整个系统的健康。 如果Supervisor因故障出现问题而无法运行Topology，Nimbus会第一时间感知到，并重新分配Topology到其它可用的Supervisor上运行Worker之间则通过Netty传送数据。 Storm主要概念这些术语的字面意义翻译如下，由于这个工具的名字叫Storm，这些术语一律按照气象名词解释 nimbus 雨云，主节点的守护进程，负责为工作节点分发任务。spout 龙卷，读取原始数据为bolt提供数据bolt 雷电，从spout或其它bolt接收数据，并处理数据，处理结果可作为其它bolt的数据源或最终结果 下面的术语跟气象就没有关系了 topology 拓扑结构，Storm的一个任务单元define field(s) 定义域，由spout或bolt提供，被bolt接收 在服务架构上来看, Storm分为 Master Node(即Nimbus), Zookeeper, Worker Node(Supervisor+Worker) 在编程逻辑上来看, Storm分为 Spout(分发Tuple流), Bolt(处理Tupe数据), Stream Grouping(前两者的数据分发规则), 以及Topology Nimbus &amp; Supervisor Storm集群由一个主节点和多个工作节点组成。主节点运行了一个名为“Nimbus”的守护进程，用于分配代码、布置任务及故障检测。每个工作节点都运行了一个名为“Supervisor”的守护进程，用于监听工作，开始并终止工作进程。Nimbus和Supervisor都能快速失败，而且是无状态的，这样一来它们就变得十分健壮，两者的协调工作是由Apache ZooKeeper来完成的。 StreamStream是一个数据流的抽象。这是一个没有边界的 Tuple序列,而这些Tuple序列会以一种分布式的方式并行地创建和处理。 对消息流的定义主要就是对消息流里面的tuple 进行定义，为了更好地使用tuple，需要给tuple 里的每个字段取一个名字，并且不同的tuple 字段对应的类型要相同，即两个tuple 的第一个字段类型相同，第二个字段类型相同。默认情况下，tuple 的字段类型可以为integer、long、short、byte、string、double、float、boolean 和byte array 等基本类型，也可以自定义类型，只需要实现相应的序列化接口。 每一个消息流在定义的时候需要被分配一个id，最常见的消息流是单向的消息流，在Storm 中OutputFieldsDeclarer 定义了一些方法，让你可以定义一个Stream 而不用指定这个id。在这种情况下，这个Stream 会有个默认的id: 1。 TopologiesTopology是由Stream Grouping连接起来的Spout和Bolt节点网络。在 Storm 中，一个实时计算应用程序的逻辑被封装在一个称为Topology 的对象中，也称为计算拓扑。Topology 有点类似于Hadoop 中的MapReduce Job，但是它们之间的关键区别在于，一个MapReduce Job 最终总是会结束的，然而一个Storm 的Topology 会一直运行。在逻辑上，一个Topology 是由一些Spout（消息的发送者）和Bolt（消息的处理者）组成图状结构，而链接Spouts 和Bolts 的则是Stream Groupings。 SpoutsSpout 是一个 topology（拓扑）中 streams 的源头. 通常 Spout 会从外部数据源读取 Tuple，然后把他们发送到拓扑中（如 Kestel 队列, 或者 Twitter API）. Spout 可以是 可靠的 或 不可靠的. 可靠的 Spout 在 Storm 处理失败的时候能够重新发送(emit)失败的 Tuple, 不可靠的 Spout 一旦把一个 Tuple 发送出去就撒手不管了. Spout 可以发送多个流. 可以使用 OutputFieldsDeclarer 的 declareStream 方法定义多个流,在 SpoutOutputCollector 对象的 emit 方法中指定要发送到的 stream . Spout 中的最主要的方法是 nextTuple():nextTuple 要么向 topology（拓扑）中发送一个新的 Tuple,要么在没有 Tuple 需要发送的情况下直接返回.对于任何 Spout 实现, nextTuple 方法都必须非阻塞的, 因为 Storm 在一个线程中调用所有的 Spout 方法. Spout 的另外几个重要的方法是 ack() 和 fail().这些方法在 Storm 检测到 Spout 发送出去的 Tuple 被成功处理或者处理失败的时候调用. Bolts所有消息处理的逻辑都在Bolt 中完成，在Bolt 中可以完成如过滤、分类、聚集、计算、查询数据库等操作。Bolt 可以做简单的消息处理操作，例如，Bolt 可以不做任何操作，只是将接收到的消息转发给其他的Bolt。Bolt 也可以做复杂的消息流的处理，这需要很多个Bolt。在实际使用中，一条消息往往需要经过多个处理步骤，例如，计算一个点击数在前十的广告，首先需要对所有同学的成绩进行排序，然后在排序过的成绩中选出前十名的成绩的同学。所以在一个Topology 中，往往有很多个Bolt，从而形成了复杂的流处理网络。 使用OutputFieldsDeclarer.declareStream定义Stream。 使用OutputCollector.emit来选择要发射的Stream。 Bolts的主要方法是execute()。在该方法里，Bolts以Tuple作为输入, 使用OutputCollector来发送Tuple, 通过调用OutputCollector.ack()通知这个Tuple的发射者Spout。Bolts可以发射多条消息流。 Stream GroupingsStream Grouping 就是用来定义一个Stream 应该如何分配给 Bolts 上面的多个Tasks。Storm里有7种类型的Stream Grouping： Shuffle Grouping 随机分组,随机派发Stream里面的 Tuple ,保证每个Bolt接收到的 Tuple 数量大致相同。 Fields Grouping 按字段分组,以id举例。具有相同id的 Tuple 会被分到相同的Bolt中的一个Task,而不同id的 Tuple 会被分到不同的Bolt中的Task。 Direct Grouping 直接分组,这是一种比较特别的分组方法,用这种分组意味着消息的发送者指定由消息接收者的哪个Task处理这个消息。只有被声明为Direct Stream的消息流可以声明这种分组方法。而且这种消息 Tuple 必须使用emitDirect方法来发射。消息处理者可以通过TopologyContext来获取处理它的消息的Task的id(OutputCollector.emit方法也会返回Task的id)。 All Grouping 广播,对于每一个 Tuple ,所有的 Bolts 都会收到。 Global Grouping 全局分组,这个 Tuple 被分配到Storm中的一个Bolt的其中一个 Task。具体一点就是分配给id值最低的那个 Task。 Non Grouping 不分组,Stream不关心到底谁会收到它的 Tuple 。目前这种分组和Shuffle Grouping是一样的效果,有一点不同的是Storm会把这个Bolt放到这个Bolt的订阅者同一个线程中去执行。 Local or Shuffle Grouping 如果目标Bolt有一个或者多个Task在同一个工作进程中, Tuple 将会被随机发射给这些Tasks。否则,和普通的Shuffle Grouping行为一致。 上面几种Streaming Group的内置实现中，最常用的应该是 Shuffle Grouping、Fields Grouping、Direct Grouping这三种，使用其它的也能满足特定的应用需求。 另外，Storm还提供了用户自定义 Streaming Grouping 接口，如果上述 Streaming Grouping 都无法满足实际业务需求，也可以自己实现，只需要实现backtype.storm.grouping.CustomStreamGrouping接口，该接口定义了如下方法： List&lt;Integer&gt; chooseTasks(int taskId, List&lt;Object&gt; values) APISpoutWordReader类实现了IRichSpout接口。我们将在第四章看到更多细节。WordReader负责从文件按行读取文本，并把文本行提供给第一个bolt。 public class WordReader implements IRichSpout &#123; private SpoutOutputCollector collector; private FileReader fileReader; private boolean completed = false; private TopologyContext context; public boolean isDistributed() &#123;return false;&#125; // 成功会调用ack public void ack(Object msgId) &#123; System.out.println(\"OK:\"+msgId); &#125; public void close() &#123;&#125; // 失败会调用fail public void fail(Object msgId) &#123; System.out.println(\"FAIL:\"+msgId); &#125; /* open是第一个被调用的spout方法 * TopologyContext context: 拓扑的上下文 * SpoutOutputCollector collector: 向Bolt发布数据 * 在这里我们创建了一个FileReader对象，用来读取文件 */ public void open(Map conf, TopologyContext context, SpoutOutputCollector collector) &#123; try &#123; this.context = context; this.fileReader = new FileReader(conf.get(\"wordsFile\").toString()); &#125; catch (FileNotFoundException e) &#123; throw new RuntimeException(\"Error reading file [\"+conf.get(\"wordFile\")+\"]\"); &#125; this.collector = collector; &#125; /* nextTuple()会在同一个循环内被ack()和fail()周期性的调用。没有任务时它必须释放对线程的控制，其它方法才有机会得以执行。 * 读取文件每一行, 调用collector.emit() 向bolts发布待处理的数据 */ public void nextTuple() &#123; /** * 这个方法会不断的被调用，直到整个文件都读完了，我们将等待并返回。 */ if(completed)&#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; //什么也不做 &#125; return; &#125; String str; //创建reader BufferedReader reader = new BufferedReader(fileReader); try&#123; //读所有文本行 while((str = reader.readLine()) != null)&#123; // 按行发布一个新值 this.collector.emit(new Values(str),str); &#125; &#125;catch(Exception e)&#123; throw new RuntimeException(\"Error reading tuple\",e); &#125;finally&#123; completed = true; &#125; &#125; /** * 声明输入域\"word\" */ public void declareOutputFields(OutputFieldsDeclarer declarer) &#123; declarer.declare(new Fields(\"line\")); &#125;&#125; Bolt下面的WordNormalizer实现了接口backtype.storm.topology.IRichBolt，该Bolt负责得到并标准化每行文本。它把文本行切分成单词，大写转化成小写，去掉头尾空白符。 public class WordNormalizer implements IRichBolt&#123; private OutputCollector collector; /** * 这个spout结束时（集群关闭的时候）,调用此方法 */ public void cleanup()&#123;&#125; /** * 声明: 这个bolt只会发布“word”域 */ public void declareOutputFields(OutputFieldsDeclarer declarer) &#123; declarer.declare(new Fields(\"word\")); &#125; /** * collector用来向Bolt发布数据 */ public void prepare(Map stormConf, TopologyContext context, OutputCollector collector) &#123; this.collector=collector; &#125; /** 具体的处理方法 * bolt从单词文件接收到文本行，全部转化成小写，并切分它，从中得到所有单词。 * 最后，每次都调用collector.ack()确认已经处理 */ public void execute(Tuple input)&#123; String sentence = input.getString(0); String[] words = sentence.split(\" \"); for(String word : words)&#123; word = word.trim(); if(!word.isEmpty())&#123; word=word.toLowerCase(); //发布这个单词 List a = new ArrayList(); a.add(input); collector.emit(a,new Values(word)); &#125; &#125; //对collector做出应答 collector.ack(input); &#125;&#125; Topologypublic class TopologyMain &#123; public static void main(String[] args) throws InterruptedException &#123; //Topology definition TopologyBuilder builder = new TopologyBuilder(); builder.setSpout(\"word-reader\",new WordReader()); // 在spout和bolts之间通过shuffleGrouping方法连接: builder.setBolt(\"word-normalizer\", new WordNormalizer()) .shuffleGrouping(\"word-reader\"); builder.setBolt(\"word-counter\", new WordCounter(),1) .fieldsGrouping(\"word-normalizer\", new Fields(\"word\")); //Configuration Config conf = new Config(); conf.put(\"wordsFile\", args[0]); conf.setDebug(false); /* Topology run * 在生产环境中，拓扑会持续运行， * 这里用LocalCluster创建本地调试运行 */ conf.put(Config.TOPOLOGY_MAX_SPOUT_PENDING, 1); LocalCluster cluster = new LocalCluster(); // create and submit: cluster.submitTopology(\"Getting-Started-Toplogie\", conf, builder.createTopology()); Thread.sleep(1000); cluster.shutdown(); &#125;&#125; Worker &amp; Executor &amp; Task 每个 Worker Node 有一个 Supervisor, Supervisor 管理着N个 Worker 进程, 每个 Worker 进程是一个JVM进程, 有自己的端口号。 一个 Topology 可能会在一个或者多个 Worker 进程里面执行，每个工作进程执行整个 Topology 的一部分 每个 Worker进程中运行着多个 Executor 线程。 每个 Executor线程中运行着若干个相同的 Task (可以理解为Spout/Bolt), Executor线程会执行Task 。 用代码说明:// 创建 Topology的配置Config conf = new Config();conf.setNumWorkers(2); // 改Topology使用2个worker进程// 设置Spout/Bolt的并行度(parallelism), 也即每个Spout/Bolt需要几个Executor线程来跑topologyBuilder.setSpout(“blue-spout”, new BlueSpout(), 2); // parallelism hint为2// 这个 Bolt除了设置并行度=2, 还设置了Task数量=4 (这个Bolt生成4个Task对象)topologyBuilder.setBolt(“green-bolt”, new GreenBolt(), 2) .setNumTasks(4) .shuffleGrouping(“blue-spout”);topologyBuilder.setBolt(“yellow-bolt”, new YellowBolt(), 6) .shuffleGrouping(“green-bolt”);// 提交配置StormSubmitter.submitTopology( “mytopology”, conf, topologyBuilder.createTopology() ); 说明: 上面定义了一个 拥有两个Worker进程的 Topology 上面定义了3个Component: 1个spout叫做BlueSpout，2个bolt分别叫 GreenBolt和YellowBolt。BlueSpout发送它的输出到GreenBolt，GreenBolt又把它的输出发到 YellowBolt。 上面3个Component的并行度(线程数)分别是 2 + 2 + 6 = 10, 每个worker进程产生10 / 2 = 5条线程。 GreenBolt特别指定了生成4个Task 下图中可以看到Topology的两个Worker进程平均分配任务;黄/绿/蓝色Task的数量分别是6, 4, 2, 也就是总共12个Task对象;Task外面灰色轮廓是Executor线程, 注意2个绿色Task由一个Executor执行; 安装 准备jdk, zookeeper集群 修改storm.yaml配置文件 storm.zookeeper.servers: Storm集群使用的Zookeeper集群地址。 如果Zookeeper没有使用默认端口,那么还需要修改storm.zookeeper.port。 storm.local.dir: Nimbus和Supervisor进程用于存储少量状态,如jars、confs等的本地磁盘目录,需要提前创建该目录并给予足够的访问权限。 命令行 启动Nimbus: storm nimbus 启动Supervisor: storm supervisor 启动UI: storm ui 提交Topologies: storm jar [jar路径] [拓扑包名.拓扑类名] [storm IP地址] [storm端口] [拓扑名称] [参数] 停止Topologies: storm kill [拓扑名称] 参考: weyo/Storm-Documents: Apache Storm 官方文档翻译 @ref https://www.kancloud.cn/kancloud/getting-started-with-storm/66495 @ref https://sylvanassun.github.io/2016/07/19/2016-07-19-Hadoop06-Storm/ @ref","categories":[{"name":"33.Bigdata","slug":"33-Bigdata","permalink":"https://beefyheisenberg.github.io/categories/33-Bigdata/"}],"tags":[{"name":"后端技术","slug":"后端技术","permalink":"https://beefyheisenberg.github.io/tags/后端技术/"},{"name":"大数据","slug":"大数据","permalink":"https://beefyheisenberg.github.io/tags/大数据/"},{"name":"流式计算","slug":"流式计算","permalink":"https://beefyheisenberg.github.io/tags/流式计算/"},{"name":"Storm","slug":"Storm","permalink":"https://beefyheisenberg.github.io/tags/Storm/"}]},{"title":"Spark","slug":"33.Bigdata/Spark","date":"2024-01-24T01:27:52.910Z","updated":"2024-01-24T01:27:52.910Z","comments":true,"path":"33.Bigdata/Spark/","link":"","permalink":"https://beefyheisenberg.github.io/33.Bigdata/Spark/","excerpt":"什么是Spark概述现如今在大规模数据处理分析的技术领域中，Hadoop及其生态内的各功能组件占据了绝对的统治地位。Hadoop原生的MapReduce计算框架由于任务抽象简单、计算流程固定、计算的中间结果写入磁盘引起大量读写开销等短板，正逐步的被基于内存的分布式计算框架Spark代替，应用于各类大规模数据处理分析的场景中，其优势主要体现在以下5个方面： 1、更快的计算速度。采用计算中间结果的内存缓存机制和基于DAG的数据处理过程优化策略，进一步提升数据处理速率。 2、简单易用的分布式计算。将大规模数据处理任务，抽象为RDD的处理变换操作，将并行实现的分布式计算任务拆分为各自独立的串行计算过程。 3、适合丰富的应用场景。Spark内部集成了SQL、机器学习、流计算、图运算等多种类型计算模型，满足多种大规模数据分析的场景需求。 4、兼容多样的存储系统。满足对包括HDFS、HBase、Hive、S3等多种大规模数据存储系统的高效读写需求，轻松处理TB级以上规模以上的数据。 5、资源管理与高可靠性。结合Yarn、Mesos等多种类型的资源管理器，监控协调各计算子任务的运行状态，失败重启机制确保分布式作业的可靠性。","text":"什么是Spark概述现如今在大规模数据处理分析的技术领域中，Hadoop及其生态内的各功能组件占据了绝对的统治地位。Hadoop原生的MapReduce计算框架由于任务抽象简单、计算流程固定、计算的中间结果写入磁盘引起大量读写开销等短板，正逐步的被基于内存的分布式计算框架Spark代替，应用于各类大规模数据处理分析的场景中，其优势主要体现在以下5个方面： 1、更快的计算速度。采用计算中间结果的内存缓存机制和基于DAG的数据处理过程优化策略，进一步提升数据处理速率。 2、简单易用的分布式计算。将大规模数据处理任务，抽象为RDD的处理变换操作，将并行实现的分布式计算任务拆分为各自独立的串行计算过程。 3、适合丰富的应用场景。Spark内部集成了SQL、机器学习、流计算、图运算等多种类型计算模型，满足多种大规模数据分析的场景需求。 4、兼容多样的存储系统。满足对包括HDFS、HBase、Hive、S3等多种大规模数据存储系统的高效读写需求，轻松处理TB级以上规模以上的数据。 5、资源管理与高可靠性。结合Yarn、Mesos等多种类型的资源管理器，监控协调各计算子任务的运行状态，失败重启机制确保分布式作业的可靠性。 RDD计算模型原理Spark将数据处理过程抽象为对内存中RDD（弹性分布式数据集）的操作，RDD的可以通过从数据源直接读取和集合数据类型封装两种方式创建。针对RDD的操作，根据其结果主要分为如map、flatMap、mapPartition、filter等生成新的RDD的transformation（转换）操作和collect、reduce、foreach等生成集合数据类型或结果写入的action（行为）操作两大类。 下图描述了一个典型的Spark作业基于RDD实现数据的处理过程。其中，Spark对RDD的处理过程是惰性的，只有调用对RDD的action操作才能启动对RDD的计算过程，连续的调用多个transformation操作是无法使数据处理过程真正的执行。在触发RDD计算过程后，根据Spark内置的DAG（有向无环图）引擎将多个对RDD的操作执行策略进行优化。为满足对大规模数据的处理需要，Spark将RDD划分为多个partition（分区），以partition为单位将数据分散到集群上的各个节点中。针对RDD的action操作和transformation操作间的本质区别就是生成的结果是否为RDD。 基于Yarn实现资源管理由于Hadoop的HDFS与Spark的RDD抽象读写具有较为完备的兼容性，各版本Spark均提供对应当前Hadoop版本的安装包。同样，Spark也可以使用Hadoop中的Yarn作为自身的资源管理器，用以完成对Spark集群中是作业管理和任务计算资源调度分配等工作。 在Spark作业的执行过程中，Yarn将在集群中的物理节点上的Executor的JVM进程封装为独立的Container，并提供独立的临时文件目录以及内存和CPU资源。同时，Spark还提供了共享文件依赖的机制将Spark作业执行过程中，各Executor所需的如jar包、.so动态库、py文件及其他格式类型的文件依赖资源与Spark作业自身的执行文件分发到各Container中，使得Spark作业能够具备更为灵活的拓展性。 技术栈现如今，Spark作业支持Java、Scala、Python以及R四种语言编写，Spark自身提供了SQL、机器学习、流计算以及图运算四种类型的计算功能组件，开发人员可根据实际的应用需求和相应组件的功能特性完成Spark作业的开发。但是，其中如GraphX等部分功能组件仅支持Java及Scala语言的调用。 核心组件核心组件如下: Spark Core：包含Spark的基本功能；尤其是定义RDD的API、操作以及这两者上的动作。其他Spark的库都是构建在RDD和Spark Core之上的。 Spark SQL：提供通过Apache Hive的SQL变体Hive查询语言（HiveQL）与Spark进行交互的API。每个数据库表被当做一个RDD，Spark SQL查询被转换为Spark操作。基于对内存中RDD操作和DAG引擎优化，Spark能够实现比基于原生MapReduce的Hive SQL更高效的计算过程。同时，采用DataFrame封装Spark作业能够以函数调用的方式完成SQL操作。 MLlib：一个常用机器学习算法库，算法被实现为对RDD的Spark操作。这个库包含可扩展的学习算法，比如分类、回归等需要对大量数据集进行迭代的操作。之前可选的大数据机器学习库Mahout，将会转到Spark并在未来实现。 Spark Streaming：允许对实时数据流进行处理和控制。很多实时数据库（如Apache Store）可以处理实时数据。Spark Streaming允许程序能够像普通RDD一样处理实时数据。Spark Streaming将数据源抽象为DStream，将各时间窗内持续产生的实时数据切分为不同的RDD，以RDD为单位完成对时间窗内实时数据的处理，但其计算模式仍存在批处理的特性。 GraphX：控制图、并行图操作和计算的一组算法和工具的集合。GraphX扩展了RDD API，包含控制图、创建子图、访问路径上所有顶点的操作。Spark中自带的图运算引擎GraphX采用由并行超步与全局同步组成的Bulk Synchronous Parallell（整体同步并行）模式，将图运算过程抽象为各步的迭代直至符合收敛停止条件。","categories":[{"name":"33.Bigdata","slug":"33-Bigdata","permalink":"https://beefyheisenberg.github.io/categories/33-Bigdata/"}],"tags":[{"name":"后端技术","slug":"后端技术","permalink":"https://beefyheisenberg.github.io/tags/后端技术/"},{"name":"大数据","slug":"大数据","permalink":"https://beefyheisenberg.github.io/tags/大数据/"},{"name":"流式计算","slug":"流式计算","permalink":"https://beefyheisenberg.github.io/tags/流式计算/"},{"name":"Spark","slug":"Spark","permalink":"https://beefyheisenberg.github.io/tags/Spark/"}]},{"title":"MapReduce","slug":"33.Bigdata/MapReduce","date":"2024-01-24T01:27:52.906Z","updated":"2024-01-24T01:27:52.906Z","comments":true,"path":"33.Bigdata/MapReduce/","link":"","permalink":"https://beefyheisenberg.github.io/33.Bigdata/MapReduce/","excerpt":"","text":"","categories":[{"name":"33.Bigdata","slug":"33-Bigdata","permalink":"https://beefyheisenberg.github.io/categories/33-Bigdata/"}],"tags":[]},{"title":"Hive","slug":"33.Bigdata/Hive","date":"2024-01-24T01:27:52.901Z","updated":"2024-01-24T01:27:52.902Z","comments":true,"path":"33.Bigdata/Hive/","link":"","permalink":"https://beefyheisenberg.github.io/33.Bigdata/Hive/","excerpt":"概述 Hive是建立在Hadoop上的数据仓库基础架构。它提供了一系列的工具，用来进行数据提取、转换、加载，这是一种可以存储、查询和分析存储在Hadoop中的大规模数据机制。可以把Hadoop下结构化数据文件映射为一张成Hive中的表，并提供类sql查询功能，除了不支持更新、索引和事务，sql其它功能都支持。可以将sql语句转换为MapReduce任务进行运行，作为sql到MapReduce的映射器。提供shell、JDBC/ODBC、Thrift、Web等接口。 Hive 并不适合那些需要低延迟的应用，例如，联机事务处理（OLTP）。Hive 查询操作过程严格遵守Hadoop MapReduce 的作业执行模型，Hive 将用户的HiveQL 语句通过解释器转换为MapReduce 作业提交到Hadoop 集群上，Hadoop 监控作业执行过程，然后返回作业执行结果给用户。Hive 并非为联机事务处理而设计，Hive 并不提供实时的查询和基于行级的数据更新操作。Hive 的最佳使用场合是大数据集的批处理作业，例如，网络日志分析。 元数据存储 Hive将元数据存储在RDBMS中，有三种方式可以连接到数据库。","text":"概述 Hive是建立在Hadoop上的数据仓库基础架构。它提供了一系列的工具，用来进行数据提取、转换、加载，这是一种可以存储、查询和分析存储在Hadoop中的大规模数据机制。可以把Hadoop下结构化数据文件映射为一张成Hive中的表，并提供类sql查询功能，除了不支持更新、索引和事务，sql其它功能都支持。可以将sql语句转换为MapReduce任务进行运行，作为sql到MapReduce的映射器。提供shell、JDBC/ODBC、Thrift、Web等接口。 Hive 并不适合那些需要低延迟的应用，例如，联机事务处理（OLTP）。Hive 查询操作过程严格遵守Hadoop MapReduce 的作业执行模型，Hive 将用户的HiveQL 语句通过解释器转换为MapReduce 作业提交到Hadoop 集群上，Hadoop 监控作业执行过程，然后返回作业执行结果给用户。Hive 并非为联机事务处理而设计，Hive 并不提供实时的查询和基于行级的数据更新操作。Hive 的最佳使用场合是大数据集的批处理作业，例如，网络日志分析。 元数据存储 Hive将元数据存储在RDBMS中，有三种方式可以连接到数据库。 内嵌模式：元数据保持在内嵌数据库的Derby，一般用于单元测试，只允许一个会话连接。 多用户模式：在本地安装Mysql，把元数据放到Mysql内。 远程模式：元数据放置在远程的Mysql数据库。 数据存储 Hive没有专门的数据存储格式，也没有为数据建立索引，用于可以非常自由的组织Hive中的表，只需要在创建表的时候告诉Hive数据中的列分隔符和行分隔符。 Hive中所有的数据都存储在HDFS中，Hive中包含4中数据模型：Tabel、ExternalTable、Partition、Bucket。 Table 类似与传统数据库中的Table，每一个Table在Hive中都有一个相应的目录来存储数据。例如：一个表zz，它在HDFS中的路径为：/wh/zz，其中wh是在hive-site.xml中由${hive.metastore.warehouse.dir}指定的数据仓库的目录，所有的Table数据（不含External Table）都保存在这个目录中。 Partition 类似于传统数据库中划分列的索引。在Hive中，表中的一个Partition对应于表下的一个目录，所有的Partition数据都存储在对应的目录中。例如：zz表中包含ds和city两个Partition，则对应于ds=20140214，city=beijing的HDFS子目录为：/wh/zz/ds=20140214/city=Beijing。 ExternalTable 指向已存在HDFS中的数据，可创建Partition。和Table在元数据组织结构相同，在实际存储上有较大差异。Table创建和数据加载过程，可以用统一语句实现，实际数据被转移到数据仓库目录中，之后对数据的访问将会直接在数据仓库的目录中完成。删除表时，表中的数据和元数据都会删除。ExternalTable只有一个过程，因为加载数据和创建表是同时完成。时间数据是存储在Location后面指定的HDFS路径中的，并不会移动到数据仓库中。 Bcuket 对指定列计算的hash，根据hash值切分数据，目的是为了便于并行，每一个Buckets对应一个文件。将user列分数至32个Bucket上，首先对user列的值计算hash，比如，对应hash=0的HDFS目录为：/wh/zz/ds=20140214/city=Beijing/part-00000;对应hash=20的，目录为：/wh/zz/ds=20140214/city=Beijing/part-00020。 Hive QL create table create table test_user(id int,name string) // 注释 comment &apos;This is the test table&apos; row format delimited // 指定切分格式规则 fields terminated by &apos;,&apos; // 指定文件格式 stored as textfile; insert select //使用select语句来批量插入数据insert overwrite table test_user select * from tab_user; load data //从本地导入数据到hive的表中（实质就是将文件上传到hdfs中hive管理目录下）load data local inpath &apos;/home/hadoop/test.txt&apos; into table test_user;//从hdfs上导入数据到hive表中（实质就是将文件从原始目录移动到hive管理的目录下）load data inpath &apos;hdfs://ns1/data.log&apos; into table test_user; external table //LOCATION指定的是hdfs路径//如果LOCATION路径有数据,则可以直接映射数据建表CREATE EXTERNAL TABLE test_user_external(id int, name string) ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;,&apos; STORED AS TEXTFILE LOCATION &apos;/external/user&apos;; CTAS //CTAS是通过查询,然后根据查询的结果来建立表格的一种方式。//CTAS会根据SELECT语句创建表结构,并把数据一并复制过来。CREATE TABLE test_user_ctas ASSELECT id new_id, name new_nameFROM test_userSORT BY new_id; Partition //创建一个分区表,以year年份作为分区字段create table test_user_part(id int,name string) partitioned by (year string) row format delimited fields terminated by &apos;,&apos;;//将data.log导入到test_user_part表中,并设置分区为1990 load data local inpath &apos;/home/hadoop/data.log&apos; overwrite into table test_user_part partition(year=&apos;1990&apos;); load data local inpath &apos;/home/hadoop/data2.log&apos; overwrite into table test_user_part partition(year=&apos;2000&apos;); Array&amp;&amp;Map:hive中的列支持使用struct、map和array集合数据类型。大多数关系型数据库中不支持这些集合数据类型，因为它们会破坏标准格式。关系型数据库中为实现集合数据类型是由多个表之间建立合适的外键关联来实现。在大数据系统中，使用集合类型的数据的好处在于提高数据的吞吐量，减少寻址次数来提高查询速度。 //array create table tab_array(a array&lt;int&gt;,b array&lt;string&gt;)row format delimitedfields terminated by &apos;\\t&apos;collection items terminated by &apos;,&apos;;select a[0] from tab_array;select * from tab_array where array_contains(b,&apos;word&apos;);insert into table tab_array select array(0),array(name,ip) from tab_ext t; //mapcreate table tab_map(name string,info map&lt;string,string&gt;)row format delimitedfields terminated by &apos;\\t&apos;collection items terminated by &apos;,&apos;map keys terminated by &apos;:&apos;;load data local inpath &apos;/home/hadoop/hivetemp/tab_map.txt&apos; overwrite into table tab_map;insert into table tab_map select name,map(&apos;name&apos;,name,&apos;ip&apos;,ip) from tab_ext; Hive常用优化方法 join连接时的优化：当三个或多个以上的表进行join操作时，如果每个on使用相同的字段连接时只会产生一个mapreduce。 join连接时的优化：当多个表进行查询时，从左到右表的大小顺序应该是从小到大。原因：hive在对每行记录操作时会把其他表先缓存起来，直到扫描最后的表进行计算。 在where字句中增加分区过滤器。 当可以使用left semi join 语法时不要使用inner join，前者效率更高。原因：对于左表中指定的一条记录，一旦在右表中找到立即停止扫描。 如果所有表中有一张表足够小，则可置于内存中，这样在和其他表进行连接的时候就能完成匹配，省略掉reduce过程。设置属性即可实现，set hive.auto.covert.join=true; * 用户可以配置希望被优化的小表的大小 set hive.mapjoin.smalltable.size=2500000; 如果需要使用这两个配置可置入$HOME/.hiverc文件中。 同一种数据的多种处理：从一个数据源产生的多个数据聚合，无需每次聚合都需要重新扫描一次。 例如:insert overwrite table student select from employee; insert overwrite table person select from employee; 可以优化成 from employee insert overwrite table student select insert overwrite table person select limit调优：limit语句通常是执行整个语句后返回部分结果。set hive.limit.optimize.enable=true; 开启并发执行。某个job任务中可能包含众多的阶段，其中某些阶段没有依赖关系可以并发执行，开启并发执行后job任务可以更快的完成。设置属性：set * hive.exec.parallel=true; hive提供的严格模式，禁止3种情况下的查询模式。 当表为分区表时，where字句后没有分区字段和限制时，不允许执行。 当使用order by语句时，必须使用limit字段，因为order by 只会产生一个reduce任务。 限制笛卡尔积的查询。 合理的设置map和reduce数量。 jvm重用。可在hadoop的mapred-site.xml中设置jvm被重用的次数。","categories":[{"name":"33.Bigdata","slug":"33-Bigdata","permalink":"https://beefyheisenberg.github.io/categories/33-Bigdata/"}],"tags":[{"name":"后端技术","slug":"后端技术","permalink":"https://beefyheisenberg.github.io/tags/后端技术/"},{"name":"大数据","slug":"大数据","permalink":"https://beefyheisenberg.github.io/tags/大数据/"},{"name":"Hive","slug":"Hive","permalink":"https://beefyheisenberg.github.io/tags/Hive/"}]},{"title":"Hadoop","slug":"33.Bigdata/Hadoop","date":"2024-01-24T01:27:52.897Z","updated":"2024-01-24T01:27:52.897Z","comments":true,"path":"33.Bigdata/Hadoop/","link":"","permalink":"https://beefyheisenberg.github.io/33.Bigdata/Hadoop/","excerpt":"Hadoop 安装 &amp; 配置Hadoop &amp; Yarn安装步骤参考: Apache Hadoop 2.9.2 – Hadoop Cluster Setup /etc/hosts, ssh登录 // 使slave可以ssh到master /etc/hosts: 所有slave可互相ping hostname authorized_keys : master可以ssh任意slave hadoop配置文件 hadoop-env.sh : HADOOP_CONF_DIR 指定加载哪个目录下的配置文件 slaves: 只有namenode需配置 core-site.xml:(https://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-common/core-default.xml) fs.defaultFS : hdfs://namenode:9000 ## hdfs文件端口 hadoop.tmp.dir : /opt/data/hadoop/tmp 其它目录会基于此路径 hdfs-site.xml:(https://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml) dfs.namenode.secondary.http-address : 第二NameNode web管理端口 dfs.replication : 3 ## 数据需要备份的数量, 默认是3, 如果此数大于集群的机器数会出错 dfs.namenode.name.dir : /opt/data/hadoop/namenode ## NameNode持久存储名字空间及事务日志的本地文件系统路径 dfs.datanode.data.dir : /opt/data/hadoop/datenode ## DataNode存放块数据的本地文件系统路径 dfs.namenode.http-address : namenode:50070 ## 浏览器可访问管理页面 dfs.webhdfs.enabled : 开启WebHDFS (REST API)功能 mapred-site.xml: mapreduce.framework.name: yarn mapreduce.jobhistory.address: 10020 mapreduce.jobhistory.webapp.address: 19888 yarn-site.xml yarn.resourcemanager.webapp.address: 8088 ## yarn框架中各个 task 的资源调度及运行状况通过通过该web界面访问 格式化namenode: hdfs namenode -format 启动HDFS NameNode: sbin/hadoop-daemon.sh start namenode 启动HDFS DateNode: sbin/hadoop-daemons.sh start datanode 或者在namenode上直接一个脚本启动: sbin/start-dfs.sh namenode和datanode的所有hdfs 启动yarn: sbin/start-yarn.sh脚本一次启动ResourceManager和NodeManager, 如果要分别启动: yarn-daemon.sh --config /opt/conf/hadoop start nodemanager yarn-daemon.sh --config /opt/conf/hadoop start resourcemanager 查看集群状态: bin/hdfs dfsadmin -report 测试hdfs写: echo &quot;hello world&quot; | hadoop fs -put - /dir/hadoop/hello_world.txt &amp;&amp; hadoop fs -cat /dir/hadoop/hello_world.txt 一些web ui: 查看nameNode: http://namenode:50070/ 查看yarn resourcemanager: http://namenode:8088/ MapReduce JobHistory: http://namenode:19888","text":"Hadoop 安装 &amp; 配置Hadoop &amp; Yarn安装步骤参考: Apache Hadoop 2.9.2 – Hadoop Cluster Setup /etc/hosts, ssh登录 // 使slave可以ssh到master /etc/hosts: 所有slave可互相ping hostname authorized_keys : master可以ssh任意slave hadoop配置文件 hadoop-env.sh : HADOOP_CONF_DIR 指定加载哪个目录下的配置文件 slaves: 只有namenode需配置 core-site.xml:(https://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-common/core-default.xml) fs.defaultFS : hdfs://namenode:9000 ## hdfs文件端口 hadoop.tmp.dir : /opt/data/hadoop/tmp 其它目录会基于此路径 hdfs-site.xml:(https://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml) dfs.namenode.secondary.http-address : 第二NameNode web管理端口 dfs.replication : 3 ## 数据需要备份的数量, 默认是3, 如果此数大于集群的机器数会出错 dfs.namenode.name.dir : /opt/data/hadoop/namenode ## NameNode持久存储名字空间及事务日志的本地文件系统路径 dfs.datanode.data.dir : /opt/data/hadoop/datenode ## DataNode存放块数据的本地文件系统路径 dfs.namenode.http-address : namenode:50070 ## 浏览器可访问管理页面 dfs.webhdfs.enabled : 开启WebHDFS (REST API)功能 mapred-site.xml: mapreduce.framework.name: yarn mapreduce.jobhistory.address: 10020 mapreduce.jobhistory.webapp.address: 19888 yarn-site.xml yarn.resourcemanager.webapp.address: 8088 ## yarn框架中各个 task 的资源调度及运行状况通过通过该web界面访问 格式化namenode: hdfs namenode -format 启动HDFS NameNode: sbin/hadoop-daemon.sh start namenode 启动HDFS DateNode: sbin/hadoop-daemons.sh start datanode 或者在namenode上直接一个脚本启动: sbin/start-dfs.sh namenode和datanode的所有hdfs 启动yarn: sbin/start-yarn.sh脚本一次启动ResourceManager和NodeManager, 如果要分别启动: yarn-daemon.sh --config /opt/conf/hadoop start nodemanager yarn-daemon.sh --config /opt/conf/hadoop start resourcemanager 查看集群状态: bin/hdfs dfsadmin -report 测试hdfs写: echo &quot;hello world&quot; | hadoop fs -put - /dir/hadoop/hello_world.txt &amp;&amp; hadoop fs -cat /dir/hadoop/hello_world.txt 一些web ui: 查看nameNode: http://namenode:50070/ 查看yarn resourcemanager: http://namenode:8088/ MapReduce JobHistory: http://namenode:19888 一些重要参数@todo 客户端 API &amp; 命令行Hadoop命令 参考: Apache Hadoop 2.7.3 – Hadoop Commands Guide hadoop dfs: 针对dfs的命令, 已经Deprecated, 推荐使用hdfs dfs hadoop fs: 本地与dfs交互的命令 hadoop fs -cat file:///file3 /user/hadoop/file4 hadoop fs -cp /user/hadoop/file1 /user/hadoop/file2 hadoop dfs -df /user/hadoop/dir1 hadoop fs -du -h /user/hadoop/dir1 hdfs://nn.example.com/user/hadoop/dir1 hadoop fs -put &lt;localsrc&gt; ... &lt;dst&gt; 查看版本： hadoop version 在 Hadoop 集群提交 MR 作业： hadoop jar &lt;jar&gt; [mainClass] arg HDFS命令 参考: Apache Hadoop 2.7.3 – HDFS Commands Guide Yarn命令* 参考: Apache Hadoop 2.7.3 – YARN Commands HDFS 文件系统解析Block size操作系统中都有文件块(Block)的概念，稳健以块的形式存储在磁盘中，文件块是系统读写操作的最小的单位。HDFS 中的 Block 是一种抽象的概念，它比操作系统中的文件块大很多： 从2.7.3版本开始 block size 的默认大小为128M，之前版本的默认值是64M. 可以通过修改 hdfs-site.xml 文件中的 dfs.blocksize 对应的值。 在实际应用中，hdfs block 块的大小设置为多少合适呢？为什么有的是64M，有的是128M、256M、512呢？ 概念： 寻址时间：HDFS 中找到目标文件 block 块所花费的时间。 传输时间： 文件块越大，寻址时间越短，但磁盘传输时间越长；文件块越小，寻址时间越长，但磁盘传输时间越短。 block 不能设置过大，也不要能设置过小 如果块设置过大，一方面从磁盘传输数据的时间会明显大于寻址时间，导致程序在处理这块数据时，变得非常慢；另一方面，MapReduce 中的 map 任务通常一次只处理一个块中的数据，如果块过大运行速度也会很慢。 如果设置过小，一方面存放大量小文件会占用 NameNode 中大量内存来存储元数据，而 NameNode 的内存是有限的，不可取；另一方面块过小，寻址时间增长，导致程序一直在找 block 的开始位置。因此，块适当设置大一些，减少寻址时间，那么传输一个有多个块组成的文件的时间主要取决于磁盘的传输速度。 block 多大合适？ 1）HDFS 中平均寻址时间大概为10ms； 2）经过大量测试发现，寻址时间为传输时间的1%时，为最佳状态，所以最佳传输时间为：10ms/0.01=1000s=1s 3）目前磁盘的传输速度普遍为100MB/s，最佳 block 大小计算：100MB/s*1s=100MB, 所以我们设置 block 大小为128MB. 4）实际中，磁盘传输速率为200MB/s 时，一般设定 block 大小为256MB;磁盘传输速率为400MB/s 时，一般设定 block 大小为512MB. @ref: Hdfs block数据块大小的设置规则 - 学习大数据入门到放弃 - 博客园 副本机制HDFS 的机架感知（rack awareness），又叫机架策略（rack-aware replica placement policy），用来决定副本存放位置，以默认的副本数=3为例： 1）第一个副本块保存在 HDFS Client 同一个的 DataNode ； 2）第二个副本块保存在 HDFS Client 所在 DataNode 同机架的其他 DataNode ； 3）第三个副本块保存不同机架的某个 DataNode ； @ref: Data Replication: HDFS Architecture Guide Rack Awareness in Hadoop HDFS - An Introductory Guide - DataFlair NameNode &amp; DataNode（1）NameNode 节点是 HDFS 中主节点，维护整个 HDFS 文件系统的文件目录树、元数据信息和文件的数据块索引，即每个文件对应的数据块列表。这些信息以 FSImage 和 Edit Log 来组织。 FSImage 中保存着某一时刻的 HDFS 文件目录树、元数据和数据块索引等信息，后续的对这信息系的修改则保存在编辑日志 Edit Log 中； 除了维护 FSImage 和 Edit Log， NameNode 节点还提供对客户端的请求响应。 （2）Secondary NameNode： 主要用于定期合并 NameNode 节点上的 FSImage 和 Edit Log ，每个集群都有一个 Secondary NameNode 的独立节点。 Secondary NameNode 和 NameNode 的区别在于：它不接受或记录 HDFS 的任何实时变化，只是根据集群配置的时间间隔不停的获取 HDFS 的某一个时间节点的 FSImage 和 Edit Log，合并得到一个新的镜像 FSImage，然后该镜像会上传到 NameNode，替换原有的镜像文件，并清空 Edit Log。 NameNode 节点是 HDFS 集群中的单一故障点，通过 Secondary NameNode 的检查点，可以减少停机时间并减低 NameNode 节点中元数据丢失的风险。但是 Secondary NameNode 不支持 NameNode 节点的故障自动恢复，须手人工干预。 （3）DataNode 是 HDFS 集群中的数据节点，所用数据块都存储在 DataNode 节点上，客户端从 DataNode 节点存储或读取数据。在客户端操作文件块 Block 时，先由 NameNode 节点告知客户端数据块所在的 DataNode，然后客户端直接与 DataNode 节点通信， DataNode 节点还会和其他 DataNode 进行通信，复制数据块，保证数据的冗余。 DataNode 作为从节点，会不断地通过“心跳”向 NameNode 节点报告其上的数据信息。 @ref: Hadoop深入学习：HDFS分布式文件系统的体系结构","categories":[{"name":"33.Bigdata","slug":"33-Bigdata","permalink":"https://beefyheisenberg.github.io/categories/33-Bigdata/"}],"tags":[{"name":"后端技术","slug":"后端技术","permalink":"https://beefyheisenberg.github.io/tags/后端技术/"},{"name":"Apache","slug":"Apache","permalink":"https://beefyheisenberg.github.io/tags/Apache/"},{"name":"大数据","slug":"大数据","permalink":"https://beefyheisenberg.github.io/tags/大数据/"},{"name":"批处理计算","slug":"批处理计算","permalink":"https://beefyheisenberg.github.io/tags/批处理计算/"},{"name":"Hadoop","slug":"Hadoop","permalink":"https://beefyheisenberg.github.io/tags/Hadoop/"},{"name":"HDFS","slug":"HDFS","permalink":"https://beefyheisenberg.github.io/tags/HDFS/"},{"name":"MapReduce","slug":"MapReduce","permalink":"https://beefyheisenberg.github.io/tags/MapReduce/"}]},{"title":"OpenTSDB schema 设计","slug":"32.Database/OpenTSDB schema 设计","date":"2024-01-24T01:27:52.893Z","updated":"2024-01-24T01:27:52.893Z","comments":true,"path":"32.Database/OpenTSDB schema 设计/","link":"","permalink":"https://beefyheisenberg.github.io/32.Database/OpenTSDB schema 设计/","excerpt":"TSDB 的一些特点： 一般使用 KV 存储模型，检索的要素都保存在 key 中； TSDB 常用于存储监控数据，其中监控的指标称为“metric”，以及多个 k=v 格式的标签（一般称为 label or tag ），例如 service=service1, ip=10.10.2.58，以及时间戳 例如 Prometheus 的 Key 设计为 http_request_total{status=200,method=&quot;GET&quot;}@timestamp 的格式 OpenTSDB schema 设计Overview","text":"TSDB 的一些特点： 一般使用 KV 存储模型，检索的要素都保存在 key 中； TSDB 常用于存储监控数据，其中监控的指标称为“metric”，以及多个 k=v 格式的标签（一般称为 label or tag ），例如 service=service1, ip=10.10.2.58，以及时间戳 例如 Prometheus 的 Key 设计为 http_request_total{status=200,method=&quot;GET&quot;}@timestamp 的格式 OpenTSDB schema 设计OverviewOpenTSDB 是基于 HBase 设计的，架构设计如下： 图中 TSD 即为(对应实际进程名是 TSDMain) opentsdb 组件。每个实例 TSD 都是独立的。没有 master，没有共享状态(shared state)，因此实际生产部署可能会通过 nginx+Consul 运行多个 TSD 实例以实现负载均衡； Server 通过 TSD RPC 向 TSD 上报数据，TSD 则通过 HBase RPC 与 HBase 进行通讯； 行键的设计OpenTSDB 的 Rowkey 格式为： [salt]&lt;metric_uid&gt;&lt;timestamp&gt;&lt;tagk1&gt;&lt;tagv1&gt;[...&lt;tagkN&gt;&lt;tagvN&gt;] SALT： 为了充分利用 HBase 分布式 Region Server 的能力，SALT 可以有效避免 HBase 的写入热点问题，开启 SALT 后，会对创建的 HBase Scanner 数量有影响，HBase Scanner 数量等于 SALT 的数量； Metric：监控指标名，例如 “sys.cpu.user” timestamp：小时级时间戳 TagK-TagV：由多个标签的 KV 对构成，例如 “ip=10.10.2.58 core=0” 所以一个 Rowkey 的逻辑值看起来如下： sys.cpu.user 1541946115 ip=10.10.2.58 core=0 OpenTSDB 为了减少 Rowkey 的空间占用，Metric、Tag 等都使用 UID（Unique ID）来代替，UID 默认占用3字节，UID 占用字节数可以通过参数调整，OpenTSDB 为每种 Metric、TagK、TagV 都生成一个 UID，Metric、TagK、TagV 各自拥有自己的 UID 空间，换句话说所有 Metric 的 UID 不会出现重复，但 Metric 和 TagK 之间可能有重复的 UID； 我们可以通过分别修改 tsd.storage.uid.width.metric、tsd.storage.uid.width.tagk 以及 tsd.storage.uid.width.tagv 参数来设置对应编码占用的字节数。 所以 Rowkey 实际占用空间如下所示： 列的设计由于 Rowkey 中已经包含了小时级的时间戳，所以需要通过列名（Qualifier）存储相对秒数（或毫秒数） （1）当 OpenTSDB 接收到一个新的 DataPoint 的时候，如果请求中的时间戳是秒，那么列名（Qualifier）将占用 2字节： 低3位表示 Value 的长度，Value 的长度 = (qualifier &amp; 0x07) + 1 中间1位表示 Value 的类型，如果值为1，表示 Value 的类型为 float；如果值为0，表示 Value 的类型为 long。 高12位表示相对于 Rowkey 中小时级时间戳的秒数，最大为 3600 判断请求中的时间戳为秒或毫秒的方法是基于时间戳数值的大小，如果时间戳的值的超过无符号整数的最大值（即4个字节的长度），那么该时间戳是毫秒，否则为秒 （2）如果 OpenTSDB 收到的 DataPoint 时间戳是毫秒，那么列名（Qualifier）将占用 4字节： Value 长度：与秒级时间戳相同； Value 类型：与秒级时间戳相同； 用22位表示相对于 Rowkey 中小时级时间戳的毫秒数 高4位是（标志位）固定全为1； 表的设计由于每种 Metric、TagK、TagV 都被映射为一个 UID，所以 OpenTSDB 还需要一张额外的表存储 UID： （1）表 tsdb：所有的时序数据都存于这张表，Rowkey = [SALT] &lt;metric&gt; &lt;小时级时间戳&gt; &lt;TagK1&gt; &lt;TagV1&gt; ...，列族只有一个 t，列名为数据的时间戳相对于 Rowkey 中小时级时间戳的秒数（or 毫秒数），一个 CF:Qualifier 例如 t:3600 （2）表 tsdb-uid：opentsdb 会将每种 metric、tagk、tagv 都映射成 UID，映射是双向的，比如说既可以根据 tagk 找到对应的 UID，也可以根据 UID 直接找到相应的 tagk。而这些映射关系就记录在 tsdb-uid 表中。该表有两个 ColumnFamily，分别是 name 和 id，另外这两个 ColumnFamily 下都有三列，分别是 metric、tagk、tagv。如下图所示： Reference OpenTSDB原理系列-TSDB数据表设计-云社区-华为云 opentsdb探索之路——部分设计与实现 - 行无际 - 博客园 OpenTSDB 之 HBase的数据模型 – 过往记忆 百度自研 TSDB 底层存储使用 HBase； RowKey = entity_id + metric_id + timebase entity_id 是由 tagK 和 tagV 经过 hash 得到的一个固定长度的值，hash 后原始字符串的自然顺序被打乱，使得 RowKey 能够相对均匀地分布在不同 HRegion 中； metric_id 为 metric 的字符串 hash 值，同样是固定长度； timebase 为 Unix 时间戳按照 1 小时（3600 秒）取整得到的数值，固定 4 个字节的长度 Column： 列名使用相对 Rowkey 小时级时间戳的秒数； 参考： 百度大规模时序数据存储（一）| 监控场景的时序数据 百度大规模时序数据存储（二）| 存储选型及数据模型设计 百度大规模时序数据存储（三）| 核心功能设计-百度开发者中心","categories":[{"name":"32.Database","slug":"32-Database","permalink":"https://beefyheisenberg.github.io/categories/32-Database/"}],"tags":[]},{"title":"MySQL-05架构-高性能和高可用","slug":"32.Database/MySQL-05架构-高性能和高可用","date":"2024-01-24T01:27:52.888Z","updated":"2024-01-24T01:27:52.889Z","comments":true,"path":"32.Database/MySQL-05架构-高性能和高可用/","link":"","permalink":"https://beefyheisenberg.github.io/32.Database/MySQL-05架构-高性能和高可用/","excerpt":"","text":"@toc 主从同步 分库分表 MySQL-05架构-日志","categories":[{"name":"32.Database","slug":"32-Database","permalink":"https://beefyheisenberg.github.io/categories/32-Database/"}],"tags":[]},{"title":"MySQL-05架构-日志","slug":"32.Database/MySQL-05架构-日志","date":"2024-01-24T01:27:52.884Z","updated":"2024-01-24T01:27:52.884Z","comments":true,"path":"32.Database/MySQL-05架构-日志/","link":"","permalink":"https://beefyheisenberg.github.io/32.Database/MySQL-05架构-日志/","excerpt":"@toc: 三种日志的作用分别是什么? 三种日志数据格式有何不同? 分别在MySQL架构哪一层实现; 比较 Redo log/Undo log/Binlog: 作用不同: Redo log是WAL机制的日志, 更新数据先落日志, 防止Crash; Undo log是实现事务回滚和MVCC的; Binlog 是 server层实现的; 数据格式: Redo log是物理日志 … 实现的层级不同: Redo/Undo 是引擎层实现, Binlog是server层实现 写入时机: @ref:","text":"@toc: 三种日志的作用分别是什么? 三种日志数据格式有何不同? 分别在MySQL架构哪一层实现; 比较 Redo log/Undo log/Binlog: 作用不同: Redo log是WAL机制的日志, 更新数据先落日志, 防止Crash; Undo log是实现事务回滚和MVCC的; Binlog 是 server层实现的; 数据格式: Redo log是物理日志 … 实现的层级不同: Redo/Undo 是引擎层实现, Binlog是server层实现 写入时机: @ref:","categories":[{"name":"32.Database","slug":"32-Database","permalink":"https://beefyheisenberg.github.io/categories/32-Database/"}],"tags":[{"name":"后端架构","slug":"后端架构","permalink":"https://beefyheisenberg.github.io/tags/后端架构/"},{"name":"数据库","slug":"数据库","permalink":"https://beefyheisenberg.github.io/tags/数据库/"},{"name":"MySQL","slug":"MySQL","permalink":"https://beefyheisenberg.github.io/tags/MySQL/"}]},{"title":"MySQL-04b-SQL加锁分析","slug":"32.Database/MySQL-04b-SQL加锁分析","date":"2024-01-24T01:27:52.880Z","updated":"2024-01-24T01:27:52.880Z","comments":true,"path":"32.Database/MySQL-04b-SQL加锁分析/","link":"","permalink":"https://beefyheisenberg.github.io/32.Database/MySQL-04b-SQL加锁分析/","excerpt":"在MySQL/InnoDB中，所谓的读不加锁，并不适用于所有的情况，而是隔离级别相关的。Serializable隔离级别，读不加锁就不再成立，所有的读操作，都是当前读。分析SQL语句加锁情况，还要考虑几种情况：当前用什么引擎（InnoDB/MyISAM）？你要当前系统的隔离级别是什么？ id列是不是主键？ id列如果不是主键，那么id列上有索引吗？id列上如果有二级索引，那么这个索引是唯一索引吗？ ➤ SQL语句在不同隔离级别的加锁分析: 如果是 Serializable 级别, 防止了脏读, 读加S锁, 写加X锁; 如果是RC级别, 当前读允许有幻读, 所以上面的”非唯一索引的情形没有加Gap锁; 如果是RR级别: (RR级别解决了幻读问题, 事务中两次当前读, 读出来的数目一致), 以 update T1 set id = 100 where name = ‘d’ 为例, 下面为了简化分析, 只考虑 where =的更新, 不考虑 where between范围更新 : 如果 where条件是=主键: 聚簇索引上加X锁, 由于主键索引的唯一性, 只有一行加X锁; 如果 where条件是=唯一索引, 但非主键: 普通索引上加X锁(只有一行), 聚簇索引对应的行加X锁; 如果 where条件是=非唯一索引, 但非主键: 由于where索引是非唯一, where索引上可能有多行符合条件, 每行都需要加X锁, 同时行之间还需要加 Gap锁 (间隙锁, 解决幻读), 聚簇索引对应的行都要加X锁; 如果 where条件上没有索引: 会导致聚簇索引上每行都加X锁( 相当于锁住了整个表), 并且聚簇索引每行之间都加 Gap锁; 综上, update语句的条件是where=主键时, 需要的锁最少, 如果 update语句的 where条件是无索引列, 会引起整个主键索引树的每行都加X锁, 性能消耗非常大 ➤ 锁优化建议 合理设计索引，让 InnoDB 在索引键上面加锁的时候尽可能准确，尽可能的缩小锁定范围，避免造成不必要的锁定而影响其他 Query 的执行。 尽可能减少基于范围的数据检索过滤条件，避免因为间隙锁带来的负面影响而锁定了不该锁定的记录。 尽量控制事务的大小，减少锁定的资源量和锁定时间长度。 在业务环境允许的情况下，尽量使用较低级别的事务隔离，以减少 MySQL 因为实现事务隔离级别所带来的附加成本。","text":"在MySQL/InnoDB中，所谓的读不加锁，并不适用于所有的情况，而是隔离级别相关的。Serializable隔离级别，读不加锁就不再成立，所有的读操作，都是当前读。分析SQL语句加锁情况，还要考虑几种情况：当前用什么引擎（InnoDB/MyISAM）？你要当前系统的隔离级别是什么？ id列是不是主键？ id列如果不是主键，那么id列上有索引吗？id列上如果有二级索引，那么这个索引是唯一索引吗？ ➤ SQL语句在不同隔离级别的加锁分析: 如果是 Serializable 级别, 防止了脏读, 读加S锁, 写加X锁; 如果是RC级别, 当前读允许有幻读, 所以上面的”非唯一索引的情形没有加Gap锁; 如果是RR级别: (RR级别解决了幻读问题, 事务中两次当前读, 读出来的数目一致), 以 update T1 set id = 100 where name = ‘d’ 为例, 下面为了简化分析, 只考虑 where =的更新, 不考虑 where between范围更新 : 如果 where条件是=主键: 聚簇索引上加X锁, 由于主键索引的唯一性, 只有一行加X锁; 如果 where条件是=唯一索引, 但非主键: 普通索引上加X锁(只有一行), 聚簇索引对应的行加X锁; 如果 where条件是=非唯一索引, 但非主键: 由于where索引是非唯一, where索引上可能有多行符合条件, 每行都需要加X锁, 同时行之间还需要加 Gap锁 (间隙锁, 解决幻读), 聚簇索引对应的行都要加X锁; 如果 where条件上没有索引: 会导致聚簇索引上每行都加X锁( 相当于锁住了整个表), 并且聚簇索引每行之间都加 Gap锁; 综上, update语句的条件是where=主键时, 需要的锁最少, 如果 update语句的 where条件是无索引列, 会引起整个主键索引树的每行都加X锁, 性能消耗非常大 ➤ 锁优化建议 合理设计索引，让 InnoDB 在索引键上面加锁的时候尽可能准确，尽可能的缩小锁定范围，避免造成不必要的锁定而影响其他 Query 的执行。 尽可能减少基于范围的数据检索过滤条件，避免因为间隙锁带来的负面影响而锁定了不该锁定的记录。 尽量控制事务的大小，减少锁定的资源量和锁定时间长度。 在业务环境允许的情况下，尽量使用较低级别的事务隔离，以减少 MySQL 因为实现事务隔离级别所带来的附加成本。 @ref: MySQL innodb中各种SQL语句加锁分析 | | For DBA MySQL · 引擎分析 · InnoDB行锁分析 MySQL 事务隔离级别和锁 MVCC多版本并发控制与Mysql锁 - by 何登成","categories":[{"name":"32.Database","slug":"32-Database","permalink":"https://beefyheisenberg.github.io/categories/32-Database/"}],"tags":[{"name":"后端架构","slug":"后端架构","permalink":"https://beefyheisenberg.github.io/tags/后端架构/"},{"name":"数据库","slug":"数据库","permalink":"https://beefyheisenberg.github.io/tags/数据库/"},{"name":"MySQL","slug":"MySQL","permalink":"https://beefyheisenberg.github.io/tags/MySQL/"},{"name":"乐观锁","slug":"乐观锁","permalink":"https://beefyheisenberg.github.io/tags/乐观锁/"},{"name":"悲观锁","slug":"悲观锁","permalink":"https://beefyheisenberg.github.io/tags/悲观锁/"}]},{"title":"MySQL-04a-锁概念","slug":"32.Database/MySQL-04a-锁概念","date":"2024-01-24T01:27:52.875Z","updated":"2024-01-24T01:27:52.875Z","comments":true,"path":"32.Database/MySQL-04a-锁概念/","link":"","permalink":"https://beefyheisenberg.github.io/32.Database/MySQL-04a-锁概念/","excerpt":"锁的概念@toc: 全局锁/表级锁/行锁; 共享锁/排他锁; 意向锁; 两段锁协议; ➤ 按锁的范围分: 全局锁(数据库锁), 表级锁(表锁, meta锁), 行锁; 全局锁: 锁住整个数据库实例, 例如Flush tables with read lock 整个数据库处于只读状态, 常用于全库备份; 表级锁: 分为 表锁 和 元数据锁 表锁需要显式加锁: 例如 lock table t1 write 即给表t1加写锁, 允许读不允许写; 元数据锁(MDL) 不需要显式加, 当增删改查时, 数据库自动给表加MDL读锁, 可以增删改查数据, 但对修改表结构互斥; 当修改表结构时, 数据库自动给表加MDL写锁; 行锁: 行锁分为S锁/X锁 (类似读写锁), 根据数据库当前隔离级别的不同, 以及sql语句的不同, 加的锁也不同; Serializable级别: 读加S锁, 写加X锁 RR/RC级别: 读不加锁(MVCC), 写可能加 X锁 和 间隙锁","text":"锁的概念@toc: 全局锁/表级锁/行锁; 共享锁/排他锁; 意向锁; 两段锁协议; ➤ 按锁的范围分: 全局锁(数据库锁), 表级锁(表锁, meta锁), 行锁; 全局锁: 锁住整个数据库实例, 例如Flush tables with read lock 整个数据库处于只读状态, 常用于全库备份; 表级锁: 分为 表锁 和 元数据锁 表锁需要显式加锁: 例如 lock table t1 write 即给表t1加写锁, 允许读不允许写; 元数据锁(MDL) 不需要显式加, 当增删改查时, 数据库自动给表加MDL读锁, 可以增删改查数据, 但对修改表结构互斥; 当修改表结构时, 数据库自动给表加MDL写锁; 行锁: 行锁分为S锁/X锁 (类似读写锁), 根据数据库当前隔离级别的不同, 以及sql语句的不同, 加的锁也不同; Serializable级别: 读加S锁, 写加X锁 RR/RC级别: 读不加锁(MVCC), 写可能加 X锁 和 间隙锁 MyISAM 不支持行锁, 不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。 表锁的使用: lock table xxx read； // 读锁// 其他线程只可以对表select查询，查询立刻返回// 但是无法对update/delete，操作会阻塞unlock tables 参考: 表锁/元数据锁 @link: [[../49.Course/course.MySQL实战45讲]] 第6节; 行锁 @link: [[../49.Course/course.MySQL实战45讲]] 第7节; ➤ 按锁的特性分: 共享锁(S锁): S锁类似读锁, 当线程1持有读锁, 不会排斥其他线程加读锁, 但排斥其他线程加写锁 手动加 S 锁: select * from tableName where … lock in share mode 自动加 S 锁: 串行隔离下, select语句加S锁 排他锁(X锁): X锁类似写锁, 当线程1持有写锁, 排斥其他线程加读锁 or 写锁 自动加 X 锁: 执行update, select .. for update, 意向锁: IS锁: 意向共享锁, 事务加”S行锁”前, 必须取得该表的 IS锁; IX锁: 意向独占锁, 事务加”X行锁”前, 必须取得该表的 IX锁; // IS和IX都是表级锁 「IX，IS是表级锁，不会和行级的X，S锁发生冲突。只会和表级的X，S发生冲突。」 @ref: MySQL 8.0 Reference Manual :: InnoDB Locking MySQL 8.0 Reference Manual :: LOCK TABLES and UNLOCK TABLES Statements 什么是两段锁协议 两段锁协议( Two-Phase Locking, 2PL): 事务中, 可以分为加锁阶段 和放锁阶段, 所以叫两段锁协议; 加锁阶段按照语句顺序进行加锁(例如事务中的 insert, update语句 到执行时才加相应的锁); 放锁阶段: 解开所有的锁; 也即行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。 使用MySQL实现乐观锁&amp;悲观锁 悲观锁: 假定会出现冲突, 首先尝试锁定数据(获得锁), 然后修改数据, 通常使用select .. for update进行加锁, 注意, 加锁是执行加锁语句的时候才加锁, 放锁需要等到事务结束后才能放锁. 乐观锁: 假定不会出现冲突, 直接更新数据, 在更新数据的同时做判断是否冲突, 常见的MySQL乐观锁方式: 使用version或timestamp, 先读取当前数据version/timestamp, 然后update .. where version=x的方式进行更新. 以更新商品库存为例( itemId primary key, count )说明乐观锁和悲观锁: 悲观锁更新库存: select * from T where itemId=1 for update # 锁定update T set .. where itemId=1 乐观锁更新库存: 通常使用version 或时间戳 select itemId, count from T where itemId = 1update T set count=count-1 where itemId = 1 and count=x @ref MySQL 乐观锁与悲观锁 - 简书","categories":[{"name":"32.Database","slug":"32-Database","permalink":"https://beefyheisenberg.github.io/categories/32-Database/"}],"tags":[{"name":"后端架构","slug":"后端架构","permalink":"https://beefyheisenberg.github.io/tags/后端架构/"},{"name":"数据库","slug":"数据库","permalink":"https://beefyheisenberg.github.io/tags/数据库/"},{"name":"MySQL","slug":"MySQL","permalink":"https://beefyheisenberg.github.io/tags/MySQL/"},{"name":"乐观锁","slug":"乐观锁","permalink":"https://beefyheisenberg.github.io/tags/乐观锁/"},{"name":"悲观锁","slug":"悲观锁","permalink":"https://beefyheisenberg.github.io/tags/悲观锁/"},{"name":"两段锁","slug":"两段锁","permalink":"https://beefyheisenberg.github.io/tags/两段锁/"}]},{"title":"MySQL-04事务-特性和实现原理","slug":"32.Database/MySQL-03b-事务的特性和实现","date":"2024-01-24T01:27:52.869Z","updated":"2024-01-24T01:27:52.870Z","comments":true,"path":"32.Database/MySQL-03b-事务的特性和实现/","link":"","permalink":"https://beefyheisenberg.github.io/32.Database/MySQL-03b-事务的特性和实现/","excerpt":"数据库事务(transaction)是访问并可能操作各种数据项的一个数据库操作序列，这些操作要么全部执行,要么全部不执行，是一个不可分割的工作单位。事务由事务开始与事务结束之间执行的全部数据库操作组成。 事务的 ACID 特性什么是 ACID: 如果一个数据库声称支持事务的操作，那么该数据库必须要具备以下四个特性（事务的特性）： 原子性 Atomicity：原子性是指一个事务是一个不可分割的工作单位，其中的操作要么都做，要么都不做；如果事务中一个 sql 语句执行失败，则已执行的语句也必须回滚，数据库退回到事务前的状态。 一致性 Consistency：事务执行结束后，数据库的完整性约束没有被破坏，事务执行的前后都是合法的数据状态。假设用户 A 和用户 B 两者的钱加起来一共是 5000，那么不管 A 和 B 之间如何转账，转几次账，事务结束后两个用户的钱相加起来应该还得是 5000，这就是事务的一致性。一致性是通过 AID 特性共同实现的 隔离性 Isolation：数据库允许多个并发事务同时对其数据进行读写和修改，规定并发事务之间的数据互不影响，隔离性用于控制多个事务并发执行结果的可见性。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。 持久性 Durability：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 MySQL 事务如何实现 ACID","text":"数据库事务(transaction)是访问并可能操作各种数据项的一个数据库操作序列，这些操作要么全部执行,要么全部不执行，是一个不可分割的工作单位。事务由事务开始与事务结束之间执行的全部数据库操作组成。 事务的 ACID 特性什么是 ACID: 如果一个数据库声称支持事务的操作，那么该数据库必须要具备以下四个特性（事务的特性）： 原子性 Atomicity：原子性是指一个事务是一个不可分割的工作单位，其中的操作要么都做，要么都不做；如果事务中一个 sql 语句执行失败，则已执行的语句也必须回滚，数据库退回到事务前的状态。 一致性 Consistency：事务执行结束后，数据库的完整性约束没有被破坏，事务执行的前后都是合法的数据状态。假设用户 A 和用户 B 两者的钱加起来一共是 5000，那么不管 A 和 B 之间如何转账，转几次账，事务结束后两个用户的钱相加起来应该还得是 5000，这就是事务的一致性。一致性是通过 AID 特性共同实现的 隔离性 Isolation：数据库允许多个并发事务同时对其数据进行读写和修改，规定并发事务之间的数据互不影响，隔离性用于控制多个事务并发执行结果的可见性。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。 持久性 Durability：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 MySQL 事务如何实现 ACID 事务原子性的实现: Undo log 记录了每次数据修改的记录, 当事务失败时需要回滚, 会根据 Undo log, 如果是 log 记录的是 insert 则回滚执行 delete, 如果 log 里是 delete, 则执行 insert, 如果 log 里是 update, 则执行一次相反的 update, 所以叫 Undo log @link: MySQL-05架构-日志 事务持久性的实现: Redo log(重做日志) 当数据修改时，除了修改 Buffer Pool 中的数据，还会在 Redo log 记录这次操作；Redo log 采用的是 WAL（Write-ahead logging，预写式日志），所有修改先写入日志，再更新到 Buffer Pool，保证了数据不会因 MySQL 宕机而丢失，从而满足了持久性要求。 事务隔离性的实现: 这部分参考→ MySQL-03b-事务的特性和实现 事务 A 的写, 对于事务 B 写操作的影响: 通过「基于锁的并发控制」(LBCC), 写操作加写锁(X 锁, 即排它锁) 事务 A 的写, 对于事务 B 读操作的影响: 通过「多版本并发控制」(MVCC), // 读不加锁, 而是采用读视图(活跃事务数组)+ 数据版本(row trx_id) + Undo log 实现 // MVCC 解决的是 RR 下的读? // Gap 锁? 事务的一致性: 定义: 事务执行结束后，数据库的完整性约束没有被破坏，事务执行的前后都是合法的数据状态。 MySQL 事务一致性的实现: 一致性是事务追求的最终目标：前面提到的原子性、持久性和隔离性，都是为了保证数据库状态的一致性。 如何实现业务数据的一致性: 数据库引擎保证的 A(原子性), I(隔离性), D(持久性), 应用层面代码逻辑正确(比如转账过程做了减扣之后, 逻辑错误导致没有执行增加) @ref 『浅入深出』MySQL 中事务的实现 - 面向信仰编程@ref 深入学习MySQL事务：ACID特性的实现原理 - 编程迷思 - 博客园 事务的隔离级别➤ 什么是脏读、幻读、不可重复读: 脏读: 就是指当一个事务正在访问数据, 并且对数据进行了修改, 而这种修改还没有提交到数据库中, 同时另外一个事务也访问这个数据, 然后读到了这个数据 不可重复读：一个事务前后查询 同一行记录 两次, 两次查询到的记录不一致 (期间另外一个事务对 此行数据 进行了修改并提交); 幻读：一个事务内前后两次查询 (相同的 where 条件), 查询出来记录的数目不一致 (期间有其他事务进行了 del/insert), 两次查询到的结果集不一致, 比如多了一行结果, 多出来的被称为”phantoms row”; @ref: Mysql 官网对幻读行的介绍: Phantom RowsFor example, if a SELECT is executed twice, but returns a row the second time that was not returned the first time, the row is a “phantom” row.给出的例子是 select * where id &gt; 100 执行两次, 第二次查询前, 有另一个事务插入了 id=101 的行, 然后第二次读, 则会在查询返回的结果集中看到 id 为 101 的新行（“幻像”）。如果我们将一组行视为一个数据项，则新的”phantom”记录将违反事务的隔离原则，即事务应该能够运行，以便它读取的数据在事务期间不会更改。 ➤ 事务的隔离级别: 未提交读(Read Uncommitted)：允许脏读, 也就是可能读取到其他事务中”未提交事务”修改的数据; 提交读(Read Committed)：(Oracle 默认级别) 避免了脏读, 仍有”幻读”和”不可重复读”, 即一个事务中能读取到其他事务提交的数据; 可重复读(Repeated Read)：(InnoDB 默认级别) 避免了不可重复读, 在同一个事务内的查询都是事务开始时刻一致的, 同时该级别下通过 Gap 锁机制避免了幻读; 串行读(Serializable)：完全串行化的读，~每次读都需要获得表级共享锁~，写锁排斥读写, 读锁排斥写 // 这里是加表级锁还是行锁? 需要根据 where 条件匹配到的列是主键/唯一/非唯一/非索引几种情况具体分析 隔离级别的实现➤ LBCC 是什么: Lock Based Concurrency Control, 基于锁的并发控制 读的时候加 S 锁(共享锁), 不排斥其他线程读, 但排斥其他线程的写; 写的时候加 x 锁(排他锁), 排斥其他线程的读和写; LBCC 的缺点: 只能读并发, 读写串行化(写会互斥读)，这样就大大降低了数据库的读写性能 ➤ MVCC 是什么: Multiversion Concurrency Control, 多版本并发控制 MySQL 每条记录在更新的时候都会有有一个数据版本号(row trx_id), 所以一条记录可以存在多个版本, 同时每条记录在更新的时候还会记录一条 Undo log; MySQL 通过可见事务 id 组成的视图, 以及”版本号+Undo log” 共同实现了事务的 MVCC, 每个事务中的读操作可以看到不同的 读视图(Read View), 也叫 “快照读” MVCC 的特点: 读不加锁, 读与写不冲突. 读写不冲突极大增加了系统并发性能. ➤ 快照读 vs 当前读: MySQL 的读操作分为 快照读(snapshot read) 和 当前读(current read) 快照读: 如果执行 select 查询的时候, 首先创建读视图, 在读视图中读”当前事务的可见版本”(有可能是历史版本), 不需要加锁; 当前读: 执行 update, delete, insert, 或 select ... for update 的时候, 读出来的是最新的数据版本, 需要加 X 锁. 不是所有 select 语句都是快照读, 还要看隔离级别: 如果在 RR/RC 级别则 select 是基于 MVCC 的快照读, 不加锁; 如果在 Serializable 级别则是当前读, 没有 MVCC 的快照, 是通过加 S 锁进行并发控制(也就是 LBCC) ➤ 事务的四种隔离级别如何实现: @todo: ==RC 级别执行 select，是快照读？ 那么如何实现“读到另外事务的提交”？== Serializable 级别(解决脏读 &amp; 幻读): 基于锁的并发控制(LBCC) 读加 S 锁(排斥其他写), 写加 X 锁(排查其他读写) 因为读写都加锁, 该级别解决了脏读, 幻读 RC(读提交)级别(解决了脏读, 但没有解决幻读): 对于读, RC 是’快照读’, 读不加锁, 基于 MVCC 实现, 在每个语句执行时创建读视图; 对于读, RC 是’当前读”, 在相关的数据行上加’X 锁’, where 条件列不同(主键/非主键索引/非索引) X 锁影响到的行也不同, 详细见→ [[MySQL-04锁-SQL加锁分析]] RR(可重复读)级别: 通过 MVCC 实现, 解决幻读现象 快照读: MVCC, 读视图在事务开始时创建, 注意这里和 RC 级别不同, 因为是事务开始时创建, 所以整个事务过程中的读视图都一样 当前读: 也是通过加 X 锁实现, 不同之处在于, RR 级别为了解决幻读, 还引入了间隙锁(Gap 锁); 总结: Serializable 级别使用 LBCC 进行并发控制, RR/RC 级别使用 MVCC 进行并发控制, MVCC 即通过 “row trx_id” 和 “Undo log”组成一个读视图(Read View), RR 级别的读视图在…时创建, RC 级别的读视图在…时创建","categories":[{"name":"32.Database","slug":"32-Database","permalink":"https://beefyheisenberg.github.io/categories/32-Database/"}],"tags":[{"name":"后端架构","slug":"后端架构","permalink":"https://beefyheisenberg.github.io/tags/后端架构/"},{"name":"数据库","slug":"数据库","permalink":"https://beefyheisenberg.github.io/tags/数据库/"},{"name":"MySQL","slug":"MySQL","permalink":"https://beefyheisenberg.github.io/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"https://beefyheisenberg.github.io/tags/事务/"},{"name":"ACID","slug":"ACID","permalink":"https://beefyheisenberg.github.io/tags/ACID/"},{"name":"MVCC","slug":"MVCC","permalink":"https://beefyheisenberg.github.io/tags/MVCC/"},{"name":"LBCC","slug":"LBCC","permalink":"https://beefyheisenberg.github.io/tags/LBCC/"},{"name":"隔离级别","slug":"隔离级别","permalink":"https://beefyheisenberg.github.io/tags/隔离级别/"}]},{"title":"MySQL-04事务-使用事务","slug":"32.Database/MySQL-03a-使用事务","date":"2024-01-24T01:27:52.865Z","updated":"2024-01-24T01:27:52.865Z","comments":true,"path":"32.Database/MySQL-03a-使用事务/","link":"","permalink":"https://beefyheisenberg.github.io/32.Database/MySQL-03a-使用事务/","excerpt":"本机事务(transaction)start transaction; // 开始一个事务# 开始事务后, 表是没有锁的, 因为start transaction会隐式的unlock表SQL语句...savepoint xxx;SQL语句...rollback to savepoint xxx;// 在commit 之前, 其他线程可以查询表, 但看不到上面的结果commit;// 在commit 之后, 其他线程才可以看到改变 分布式事务(xa)xa start &apos;test&apos;, &apos;db1&apos;; -- 启动xid=&apos;text&apos;, 分支=&apos;db1&apos;的分布式事务SQL 语句...xa end &apos;test&apos;, &apos;db1&apos;;xa prepare &apos;test&apos;, &apos;db1&apos;; -- 分支db1进入prepare状态-- 必须xid=&apos;test&apos;的所有分支都commit, 事务才算完成xa commit &apos;text&apos;, &apos;db1&apos;; DB1 DB2 xa start ‘transxxx’ ‘db1’ xa start ‘transxxx’ ‘db2’ 开始事务 insert db1 .. update db2 … xa end ‘transxxx’ ‘db1’ xa end ‘transxxx’ ‘db2’ xa prepare ‘transxxx’ ‘db1’ xa prepare ‘transxxx’ ‘db2’ 进入Prepare阶段 xa commit ‘transxxx’ ‘db1’ xa commit ‘transxxx’ ‘db2’ 提交事务","text":"本机事务(transaction)start transaction; // 开始一个事务# 开始事务后, 表是没有锁的, 因为start transaction会隐式的unlock表SQL语句...savepoint xxx;SQL语句...rollback to savepoint xxx;// 在commit 之前, 其他线程可以查询表, 但看不到上面的结果commit;// 在commit 之后, 其他线程才可以看到改变 分布式事务(xa)xa start &apos;test&apos;, &apos;db1&apos;; -- 启动xid=&apos;text&apos;, 分支=&apos;db1&apos;的分布式事务SQL 语句...xa end &apos;test&apos;, &apos;db1&apos;;xa prepare &apos;test&apos;, &apos;db1&apos;; -- 分支db1进入prepare状态-- 必须xid=&apos;test&apos;的所有分支都commit, 事务才算完成xa commit &apos;text&apos;, &apos;db1&apos;; DB1 DB2 xa start ‘transxxx’ ‘db1’ xa start ‘transxxx’ ‘db2’ 开始事务 insert db1 .. update db2 … xa end ‘transxxx’ ‘db1’ xa end ‘transxxx’ ‘db2’ xa prepare ‘transxxx’ ‘db1’ xa prepare ‘transxxx’ ‘db2’ 进入Prepare阶段 xa commit ‘transxxx’ ‘db1’ xa commit ‘transxxx’ ‘db2’ 提交事务 命令说明: 开始事务: xa start xid, xid是某个分布式事务的唯一id, xid分三部分: 分布式事务标识+事务分支标识+formatid 上面的例子只有 “分布式事务标识+事务分支标识”, 后者用db1/db2表示在不同库上的事务分支 xa prepare: xa commit: 实现@todo: MySQL分布式事务XA似乎用的是2PC ? 事务管理器组件 atomikos 的实现? @todo @ref MySQL分布式事务（XA事务）-云栖社区-阿里云","categories":[{"name":"32.Database","slug":"32-Database","permalink":"https://beefyheisenberg.github.io/categories/32-Database/"}],"tags":[{"name":"后端架构","slug":"后端架构","permalink":"https://beefyheisenberg.github.io/tags/后端架构/"},{"name":"数据库","slug":"数据库","permalink":"https://beefyheisenberg.github.io/tags/数据库/"},{"name":"MySQL","slug":"MySQL","permalink":"https://beefyheisenberg.github.io/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"https://beefyheisenberg.github.io/tags/事务/"}]},{"title":"MySQL-03b-索引-BTree","slug":"32.Database/MySQL-02b-BTree索引原理","date":"2024-01-24T01:27:52.860Z","updated":"2024-01-24T01:27:52.861Z","comments":true,"path":"32.Database/MySQL-02b-BTree索引原理/","link":"","permalink":"https://beefyheisenberg.github.io/32.Database/MySQL-02b-BTree索引原理/","excerpt":"B-TreeB-Tree 不是 Binary Tree（二叉树，每个节点最多有两个子树），B 的意思是 Balance, 一棵 M 阶的 B-Tree 满足以下条件： B-Tree的节点包含两部分： 关键字，k 个关键字构成了 k+1 个开区间，指向 k+1 个孩子节点 数据 B-Tree的特点：","text":"B-TreeB-Tree 不是 Binary Tree（二叉树，每个节点最多有两个子树），B 的意思是 Balance, 一棵 M 阶的 B-Tree 满足以下条件： B-Tree的节点包含两部分： 关键字，k 个关键字构成了 k+1 个开区间，指向 k+1 个孩子节点 数据 B-Tree的特点： 树的 根节点 拥有的子节点数量子在 2- M 之间； 除根外，每个 非叶子节点 拥有的子节点数量在 M/2 - M 之间； 一个 非叶子节点 如果包含 k 个关键字，那么它有 k+1 个子节点； 所有叶子节点都在相同的深度，且叶子节点不包含关键字信息； 一个 4 阶 B-Tree： 插入过程针对 m 阶高度 h 的 B-Tree，插入一个元素时，首先在 B-Tree中是否存在，如果不存在，即在叶子结点处结束，然后在叶子结点中插入该新的元素。 若该节点元素个数小于m-1，直接插入； 若该节点元素个数等于m-1，引起节点分裂；以该节点中间元素为分界，取中间元素（偶数个数，中间两个随机选取）插入到父节点中； 重复上面动作，直到所有节点符合B-Tree的规则；最坏的情况一直分裂到根节点，生成新的根节点，高度增加1； 插入的例子（为了直观而先插入元素，然后判断是否要分裂）： （1）5 阶 B-Tree，插入前： （2）插入 19，引起 14、16、17、18 的节点分裂，把中间元素【17】上移到父节点中，但是情况来了，父节点中空间已经满了，所以也要进行分裂，将父节点中的中间元素【13】上移到新形成的根结点中，这样具体插入操作的完成。 删除过程首先，查找 B-Tree中需删除的元素，如果该元素在 B-Tree中存在，则将该元素在其节点中进行删除；删除该元素后，首先判断该元素是否有左右孩子节点， 如果有，则上移孩子节点中的某相近元素（「左孩子最右边的节点」或「右孩子最左边的节点」）到父节点中，然后是移动之后的情况；如果没有，直接删除。 某节点中元素数目小于 m/2-1、m/2 向上取整，则需要看其相邻兄弟节点是否丰满。 如果其相邻兄弟都不丰满，即其节点数目刚好等于 m/2-1，则该节点与其相邻的某一兄弟节点进行「合并」成一个节点。 如果其相邻兄弟丰满（节点中元素个数大于 m/2-1），则向父节点借一个元素来满足条件。 接下来用一个 5 阶 B-Tree为例，详细讲解删除的操作。 如图所示，接下来要依次删除 8，20，18，5。 首先要删除元素 8。先查找到元素 8 在叶子节点中，删除 8 后叶子节点的元素个数为 2，符合 B-Tree的规则。然后需要把元素 11 和 12 都向前移动一位。完成后如图所示。 下一步，删除 20，因为 20 没有在叶子节点中，而是在中间节点中找到，可以发现 20 的继承者是 23（字母升序的下个元素），然后需要将 23 上移到 20 的位置，之后将孩子节点中的 23 进行删除。 删除后检查一下，该孩子节点中元素个数大于 2，无需进行合并操作。 所以这一步之后，B-Tree如下图所示。 下一步删除 18，18 在叶子节点中，但是该节点中元素数目为 2，删除导致只有 1 个元素，已经小于最小元素数目 2。而由前面已经知道：如果其某个相邻兄弟节点中比较丰满（元素个数大于 5/2），则可以向父节点借一个元素，然后将最丰满的相邻兄弟节点中上移最后或最前一个元素到父节点中。在这个实例中，右相邻兄弟节点中比较丰满（3 个元素大于 2），所以先向父节点借一个元素 23 下移到该叶子节点中，代替原来 19 的位置。19 前移。然后 24 在相邻右兄弟节点中，需要上移到父节点中。最后在相邻右兄弟节点中删除 24，后面的元素前移。 这一步之后，B-Tree如下图所示。 最后一步需要删除元素 5，但是删除后会导致很多问题。因为 5 所在的节点数目刚好达标也就是刚好满足最小元素个数 2。 而相邻的兄弟节点也是同样的情况，删除一个元素都不能满足条件，所以需要该节点与某相邻兄弟节点进行合并操作；首先移动父节点中的元素（该元素在两个需要合并的两个节点元素之间）下移到其子节点中。 然后将这两个节点进行合并成一个节点。所以在该实例中，首先将父节点中的元素 4 下移到已经删除 5 而只有 6 的节点中，然后将含有 4 和 6 的节点和含有 1，3 的相邻兄弟节点进行合并成一个节点。 这一步之后，B-Tree如下图所示。 但是这里观察到父节点只包含了一个元素 7，这就没有达标（因为非根节点包括叶子节点的元素数量 必须满足于[2, 4] ）。如果这个问题节点的相邻兄弟比较丰满，则可以向父节点借一个元素。而此时兄弟节点元素刚好为 2，刚刚满足，只能进行合并，而根节点中的唯一元素 13 下移到子节点。这样，树的高度减少一层。 所以最终的效果如下图。 B-Tree 的复杂度分析B-Tree高度的证明过程： 结论 对于一颗数阶=M, 高度=h, 索引了 N 个元素的 B-Tree: 树高 h 的上限: $\\log_M ((N+1)/2)$ 查找一个元素的时间复杂度为: $O\\log_M N$ 插入复杂度: 先查找 $O\\log_M N$ 插入会发生结点的分裂操作, 分裂操作可以认为是常数级别, 最坏情况引起 root 以下所有节点分裂 所以插入时间复杂度一般情况下等于 $O\\log_M N$ 删除复杂度: 先查找 $O\\log_M N$ 删除会引起合并操作, 分析同插入情形 所以插入时间复杂度一般情况下等于 $O\\log_M N$ 上面的分析都是基于所有节点都在内存中, 没有访问硬盘. 但实际上基于外部存储的 B-Tree 最耗时的是磁盘的 IO 次数. 如果从磁盘 IO 的角度分析插入和删除的耗时： 删除操作的磁盘 IO 次数: 如果删除引起了节点合并, 最坏情况下磁盘访问次数是 3h ＝（找到包含被删除元素需要 h 次读访问）+（获取第 2 至 h 层的最相邻兄弟需要 h-1 次读访问）+（在第 3 至 h 层的合并需要 h-2 次写访问）+（对修改过的根节点和第 2 层的两个节点进行3次写访问） 插入操作引起的磁盘 IO: 当插入操作引起了 s 个节点的分裂时，磁盘访问的次数为 h(读取搜索路径上的节点)＋2s(更新两个分裂出的新节点)＋1（回写新的根节点或插入后没有导致分裂的节点）。因此，所需要的磁盘访问次数是 h+2s+1，最多可达到 3h+1。因此插入的代价是很大的。 一般实际应用中，M 是非常大的数字，通常超过 100，因此 h 非常小（通常不超过 3），业界公认 MySQL 单表容量在 1KW 以下是最佳状态，因为这时它的 BTREE 索引树高 h = 3~5之间。 B+Tree与B-Tree相比，B+Tree有以下不同点： 有 k 个子树的中间节点包含有 k 个关键字（B-Tree中是 k-1个）@doubt 非叶子节点没有 data, 只存储关键字和关键字对应的指针（非叶子节点仅存索引）; 叶子节点存储了所有的关键字和关键字对应的 data（叶子节点包含所有的关键字和数据）； 相邻的叶子节点按顺序形成单链表（叶子节点在一条链表中）; // @duobt: 单向链表 还是 双向链表？ 各种资料上 B+树的定义各有不同，上面的定义方式是关键字个数和孩子结点个数相同，这里我们采取维基百科上所定义的方式，即关键字个数比孩子结点个数小1，这种方式是和B-Tree基本等价的（B+ tree - Wikipedia）： ➤ 为什么说 B+树比 B-Tree更适合数据库索引？ 1）B+树的磁盘读写代价更低 B+树的内部结点并没有指向关键字具体信息的指针。因此其内部结点相对B-Tree更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了； 2）B+树查询效率更加稳定 由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当； 3）B+树便于范围查询（最重要的原因，范围查找是数据库的常态） B-Tree在提高了IO性能的同时并没有解决元素遍历的我效率低下的问题，正是为了解决这个问题，B+树应用而生。B+树只需要去遍历叶子节点就可以实现整棵树的遍历。 补充：B-Tree的范围查找用的是中序遍历，而B+树用的是在链表上遍历 MySQL如何使用索引MySQL 使用 B+Tree 作为索引，数据库表中每个索引都可以认为是一个 B+Tree 结构 聚集索引，B+Tree 的叶子节点存储的内容是每一行的数据，所以表在磁盘上的存储顺序与索引的顺序一致 非聚集索引，叶子节点存储的内容不是真实行数据，而是主键的值表，所以数据存储顺序与索引顺序无关。通过非聚簇索引查询要再回主键的 B-Tree查询才能得到数据（回表）, 所以也叫二级索引 查询非聚集索引也有不需回表的情况： 覆盖索引（covering index ）：即查询使用的索引，恰好覆盖了查询需求，这种情况下不必再回表 例如： select 查询的列是主键 select 查询的列 = where 条件的列，且这个列上有索引 使用联合索引的情况：例如 A，B 两个列组成联合索引，查询的需求恰好被这个联合索引覆盖（如 select A, B ），这种情况下不需要回表，但是如果 select A,B,C 的情况，联合索引就无法覆盖了 MyISAM和InnoDB索引区别 InnoDB: 主键的索引 B+Tree, 叶子节点存储的数据即一行完整数据(聚集索引), InnoDB 的辅助索引的叶子节点存储的是 主键的值 (非聚集索引) MyISAM 的主键和非主键索引, 叶子节点存储的都是数据行的地址 @ref: notes/B-Tree和B+树详解.md at master · wardseptember/notes B+ 树 - OI Wiki B+树详解 | Ivanzz","categories":[{"name":"32.Database","slug":"32-Database","permalink":"https://beefyheisenberg.github.io/categories/32-Database/"}],"tags":[{"name":"后端架构","slug":"后端架构","permalink":"https://beefyheisenberg.github.io/tags/后端架构/"},{"name":"数据库","slug":"数据库","permalink":"https://beefyheisenberg.github.io/tags/数据库/"},{"name":"MySQL","slug":"MySQL","permalink":"https://beefyheisenberg.github.io/tags/MySQL/"},{"name":"索引","slug":"索引","permalink":"https://beefyheisenberg.github.io/tags/索引/"}]},{"title":"MySQL-03a-索引-高效使用索引","slug":"32.Database/MySQL-02a-高效使用索引","date":"2024-01-24T01:27:52.857Z","updated":"2024-01-24T01:27:52.857Z","comments":true,"path":"32.Database/MySQL-02a-高效使用索引/","link":"","permalink":"https://beefyheisenberg.github.io/32.Database/MySQL-02a-高效使用索引/","excerpt":"创建索引原则 尽量选择区分度高的列作为索引,区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录 限制索引的长度, 尤其是 FULLTEXT索引, 比如只在VARCHAR字段的前20字节做索引; 字符类型和数字类型作为索引的性能差别，肯定是用数字类型索引更好。 用字符串做索引扫描是否会有性能损耗？两者的主要差别就在于，字符类型有字符集的概念，每次从存储端到展现端之间都有一个字符集编码的过程。而这一过程主要消耗的就是CPU资源；对于In-memory的操作来说，这是一个不可忽视的消耗。如果要固化到具体测试结果，我们这边的经验数据是20%，具体值还是和环境和数据有关系。此外，latin1 和 UTF8 之间也有10%左右的性能差别。 时间加索引的话，性能上 TIMESTAMP &gt; DATETIME 高效使用索引 使用覆盖索引(对于非主键的查询条件), 符合覆盖索引的情况: 如果用到了联合索引, 联合索引用到的列, 恰好也是要查询的列( select colA, 且已经在colA创建了联合索引) 这种也是走覆盖索引: select 主键 where 非主键列=X ① 查询尽量使用到索引，避免使用全表扫描","text":"创建索引原则 尽量选择区分度高的列作为索引,区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录 限制索引的长度, 尤其是 FULLTEXT索引, 比如只在VARCHAR字段的前20字节做索引; 字符类型和数字类型作为索引的性能差别，肯定是用数字类型索引更好。 用字符串做索引扫描是否会有性能损耗？两者的主要差别就在于，字符类型有字符集的概念，每次从存储端到展现端之间都有一个字符集编码的过程。而这一过程主要消耗的就是CPU资源；对于In-memory的操作来说，这是一个不可忽视的消耗。如果要固化到具体测试结果，我们这边的经验数据是20%，具体值还是和环境和数据有关系。此外，latin1 和 UTF8 之间也有10%左右的性能差别。 时间加索引的话，性能上 TIMESTAMP &gt; DATETIME 高效使用索引 使用覆盖索引(对于非主键的查询条件), 符合覆盖索引的情况: 如果用到了联合索引, 联合索引用到的列, 恰好也是要查询的列( select colA, 且已经在colA创建了联合索引) 这种也是走覆盖索引: select 主键 where 非主键列=X ① 查询尽量使用到索引，避免使用全表扫描 MySQL中能够使用索引的典型场景: 匹配全值（Match the full value），Where条件中所有列都有索引, 且使用的是= 或者IN。 匹配值的范围查询（Match a range of values），Where条件中所有列都有索引, 且使用的是范围条件。例 where id &gt; 10 and id &lt; 25 使用了联合索引, 且匹配最左前缀（Match a left most prefix），仅仅使用联合索引中的最左边列进行查找，比如在 col1+col2+col3 字段上的联合索引能够被包含col1、（col1+col2）、（col1+col2+col3）的等值查询利用到，可是不能够被col2、（col2+col3）的等值查询利用到； 匹配列前缀（Match a column prefix），仅仅使用索引中的第一列，并且只包含索引第一列的开头一部分进行查找。select title from film_text where title like &#39;AFRICAN%&#39;; 如果列名是索引，那么使用 column_name is null 可以使用索引 ② 注意不同类型的索引对性能有影响 对于频繁写入的情景, 普通索引比唯一索引更快 // why ? 对于查询的情况, 非聚簇索引比聚簇索引多一次回表, 如何避免非聚簇索引的回表? ③ 避免会索引失效的操作 在索引上使用函数: select * from trade where month(data) = 7 索引的类型转换: 字段定义类型varchar, 但是查询语句用 where id &gt; 7, 相当于给id索引加上了CAST函数(隐式类型转换总是低精度类型→高精度类型) 以下where 都不会用到索引: &lt;&gt; 、not in、not exist、!= like, 百分号在前: where col like &quot;%xxxx&quot; 单独引用复合索引里非第一位置的索引列 不要将空的变量值直接与比较运算符（符号）比较, 应使用 IS NULL 或 IS NOT NULL 进行比较 @todo 待整理: 导致索引失效的可能情况","categories":[{"name":"32.Database","slug":"32-Database","permalink":"https://beefyheisenberg.github.io/categories/32-Database/"}],"tags":[]},{"title":"MySQL-01b-SQL语句-JOIN原理及优化","slug":"32.Database/MySQL-01b-SQL语句-JOIN原理及优化","date":"2024-01-24T01:27:52.851Z","updated":"2024-01-24T01:27:52.852Z","comments":true,"path":"32.Database/MySQL-01b-SQL语句-JOIN原理及优化/","link":"","permalink":"https://beefyheisenberg.github.io/32.Database/MySQL-01b-SQL语句-JOIN原理及优化/","excerpt":"➤ Join中的驱动表概念: left join: 左表为驱动表 right join: 右表为驱动表 ➤ InnoDB是如何实现Join的? Mysql的JOIN是通过 Nested-Loop Join 算法实现的(嵌套循环, 如同名字, 循环外层表也即驱动表, 外层表每一行数据再去内层表查找符合条件的数据 ), 有三种: Simple Nested-Loop Join 算法效率最低(Mysql并不使用这种Join算法), 可以认为是: 遍历外层所有符合条件的列, 每一行外层数据都再去遍历内层表, 依次比较, 如果外层表有N行(符合条件的)数据, 内层表有M行数据, 总共需要 N*M 次比较; Index Nested-Loop Join (索引嵌套循环): 需要内层表的条件列有索引, 依然循环外层表所有符合条件的行, 但是由于内层表的条件列有索引, 并不需要对内层表进行全表扫描. (当内层表建立了索引, Mysql优先使用这种方式) Block Nested-Loop Join (缓存块嵌套循环): 如果内层表没有索引会使用这种方式, 思路就是减少外层循环次数, 具体做法是: 外层表查出多条数据, 放入 join buffer, 然后以 join buff里的多条数据作为条件, 对内层表进行全表扫描. 能有效减少外层表的循环次数(也减少了内层表进行全表扫描的次数)","text":"➤ Join中的驱动表概念: left join: 左表为驱动表 right join: 右表为驱动表 ➤ InnoDB是如何实现Join的? Mysql的JOIN是通过 Nested-Loop Join 算法实现的(嵌套循环, 如同名字, 循环外层表也即驱动表, 外层表每一行数据再去内层表查找符合条件的数据 ), 有三种: Simple Nested-Loop Join 算法效率最低(Mysql并不使用这种Join算法), 可以认为是: 遍历外层所有符合条件的列, 每一行外层数据都再去遍历内层表, 依次比较, 如果外层表有N行(符合条件的)数据, 内层表有M行数据, 总共需要 N*M 次比较; Index Nested-Loop Join (索引嵌套循环): 需要内层表的条件列有索引, 依然循环外层表所有符合条件的行, 但是由于内层表的条件列有索引, 并不需要对内层表进行全表扫描. (当内层表建立了索引, Mysql优先使用这种方式) Block Nested-Loop Join (缓存块嵌套循环): 如果内层表没有索引会使用这种方式, 思路就是减少外层循环次数, 具体做法是: 外层表查出多条数据, 放入 join buffer, 然后以 join buff里的多条数据作为条件, 对内层表进行全表扫描. 能有效减少外层表的循环次数(也减少了内层表进行全表扫描的次数) ➤ 如何让Mysql使用 Block Nested-Loop Join: 设置 optimizer_switch的值为 block_nested_loop=on 设置 join_buffer_size大小 ➤ How to 优化 Join: 用小结果集驱动大结果集(减少外循环次数) 为内层表的条件列增加索引(避免内层全表扫描) 增大join buffer size的大小（一次缓存的数据越多，那么外层表循环的次数就越少） 减少不必要的字段查询（字段越少，join buffer 所缓存的数据就越多，外层表的循环次数就越少） 合理使用覆盖索引, 减少回表次数 @ref: MySQL查询优化——连接以及连接原理 - 简书 MySQL Join的底层实现原理 - 掘金","categories":[{"name":"32.Database","slug":"32-Database","permalink":"https://beefyheisenberg.github.io/categories/32-Database/"}],"tags":[{"name":"后端架构","slug":"后端架构","permalink":"https://beefyheisenberg.github.io/tags/后端架构/"},{"name":"数据库","slug":"数据库","permalink":"https://beefyheisenberg.github.io/tags/数据库/"},{"name":"MySQL","slug":"MySQL","permalink":"https://beefyheisenberg.github.io/tags/MySQL/"},{"name":"SQL语句","slug":"SQL语句","permalink":"https://beefyheisenberg.github.io/tags/SQL语句/"}]},{"title":"MySQL-01a-SQL语句-基础和优化","slug":"32.Database/MySQL-01a-SQL语句-基础和优化","date":"2024-01-24T01:27:52.847Z","updated":"2024-01-24T01:27:52.847Z","comments":true,"path":"32.Database/MySQL-01a-SQL语句-基础和优化/","link":"","permalink":"https://beefyheisenberg.github.io/32.Database/MySQL-01a-SQL语句-基础和优化/","excerpt":"SQL基础MySQL官方文档中提供了一套示例数据库 Employees, MySQL官方文档中说明详见 http://dev.mysql.com/doc/employee/en/employee.html。里面详细介绍了此数据库，并提供了下载地址和导入方法。 mysql测试数据库employees一些sql语句_数据库_wepe12的博客-CSDN博客 插入INSERT INTO table_name ( field1, field2,...fieldN ) VALUES ( value1, value2,...valueN ), // 插入多行 ( value1, value2,...valueN );","text":"SQL基础MySQL官方文档中提供了一套示例数据库 Employees, MySQL官方文档中说明详见 http://dev.mysql.com/doc/employee/en/employee.html。里面详细介绍了此数据库，并提供了下载地址和导入方法。 mysql测试数据库employees一些sql语句_数据库_wepe12的博客-CSDN博客 插入INSERT INTO table_name ( field1, field2,...fieldN ) VALUES ( value1, value2,...valueN ), // 插入多行 ( value1, value2,...valueN ); 删除DELETE FROM table_name [WHERE Clause] 更新UPDATE table_name SET field1=new-value1, field2=new-value2[WHERE Clause] 单表查询SELECT column_name,column_nameFROM table_name[WHERE Clause][LIMIT N][ OFFSET M] 子句: WHERE, HAVING, GROUP BY, ORDER BY, LIMIT按照被执行的顺序: from、where、group by、having、select、order by、limit WHERE: 是唯一一个是直接从磁盘获取数据的时候就开始判断的条件, 从磁盘取出一条记录, 开始进行where判断:判断的结果如果成立就保存到内存中, 如果失败则直接放弃 GROUP BY: 根据一个或多个列, 对结果集进行分组, 在分组的列上我们可以使用 COUNT, SUM, AVG,等函数。 支持的聚集函数：SUM() 统计求和, COUNT() 统计分组后每一组有多少个记录, AVG() 统计平均值 示例: 可以GROUP BY多个字段: SELECT user_name, SUM(order_price) FROM ORDER_TAB GROUP BY user_name, order_data \b示例: GROUP BY的回溯统计WITH ROLLUP 可以实现在分组统计数据基础上再进行相同的统计: SELECT user_name, SUM(order_price) FROM ORDER_TAB GROUP BY user_name WITH ROLLUP, 返回的数据会多一行, 该行的SUM等于GROUP返回结果再做一次求和 HAVING: 对GROUP BY的结果进行条件筛选, HAVING子句一般跟在GROUP BY子句后面。在 SQL 中增加 HAVING 子句原因是，WHERE 关键字无法与合计函数一起使用。 HAVING与WHERE的区别: WHERE是直接从磁盘取数据, 查询出的数据放入内存, 然后可以用聚合函数+GROUP BY分组, 分组后的数据用HAVING再筛选 示例: SELECT user_name, SUM(order_price) FROM ORDERS_TAB GROUP BY user_name HAVING SUM(order_price)&gt;100 ORDER BY: 排序 示例: SELECT order_id, order_price FROM ORDER_TAB ORDER BY order_data desc LIMIT：限制 示例: SELECT * FROM table LIMIT 10 # 取出10条 示例: SELECT * FROM table LIMIT 95,-1; # 检索记录行 96-last. 示例: SELECT * FROM table LIMIT 5,10; # 返回第6-15行数据 列去重 DISTINCT 列名: 根据该列名, 在结果中去重 SELECT distinct(task_id), task_name from task; –带有distinct的列必须在第一个 但是上面的语句要id和name都相同的情况下才能虑重, 所以用下面的方式: SELECT task_id, count(DISTINCT task_name) FROM table –与其他函数使用时候，没有位置限制 WHERE的比较WHERE查询支持的条件: 逻辑运算符 与或非: AND, OR, NOT 运算符: &gt;, &lt;, &lt;=, &gt;=, =, like, between ... and, in, not in 下面是例子: NULL: SELECT * FROM 表名 WHERE 字段名 IS NULL; SELECT * FROM 表名 WHERE 字段名 IS NOT NULL; LIKE: SELECT * FROM 表名 WHERE 字段名 LIKE &#39;%COM&#39; # %多个字符，_单个字符 IN： WHERE column_name IN (value1,value2,...) &lt;, &gt;, &gt;=, &lt;=, 可以用于比较时间： select count(*) from sometable where datetimecolumn&gt;=&#39;2010-03-01 00:00:00&#39; select count(*) from sometable where datetimecolumn&gt;=UNIX_TIMESTAMP(&#39;2010-03-01 00:00:00&#39;) 多表查询多表查询包括: 隐性连接和显性连接,WHERE子句中使用的连接语句，在数据库语言中被称为隐性连接。JOIN……ON子句产生的连接称为显性连接。WHERE 和INNER JOIN产生的连接关系，没有本质区别，结果也一样。但是隐性连接随着数据库语言的规范和发展，已经逐渐被淘汰，比较新的数据库语言基本上已经抛弃了隐性连接，全部采用显性连接了。 隐性连接: SELECT T1.ID, T1.COLA, T2.COL2 FROM TABLE1 AS T1, TABLE2 AS T2 WHERE T1.ID=T2.ID JOIN INNER JOIN（内连接,或等值连接）：获取两个表中字段匹配关系的记录。 SELECT T1.ID, T1.COLA, T2.COL2FROM TABLE1 AS T1 INNER JOIN TABLE2 AS T2ON T1.ID=T2.ID LEFT JOIN（左连接）：获取左表所有记录，即使右表没有对应匹配的记录。 RIGHT JOIN（右连接）： 与 LEFT JOIN 相反，用于获取右表所有记录，即使左表没有对应匹配的记录。 多次JOIN: select collum from TABLE1LEFT JOIN TABLE2 ON condition2LEFT JOIN TABLE3 ON condition3 Join 语句的优化 @link: [[MySQL-01-SQL语句-JOIN原理及优化]] UNIONUNION： 操作符用于连接两个以上的 SELECT 语句的结果组合到一个结果集合中。UNION会去掉重复的行, 但UNION ALL不会。 select columnA from table1UNIONselect collumB from table2 columnA和columnB必须是同类型 子查询用括号()括起来的一个完整查询语句相当于一个Table, 子查询不包含 ORDER BY 子句。对一个 SELECT 语句只能用一个 ORDER BY 子句，并且如果指定了它就必须放在主 SELECT 语句的最后。 子查询作为 查询条件: 如果子查询返回单个结果, 可以用 例如 =，&gt;，&lt;等, 与子查询比较 : SELECT customerNumber, checkNumber, amount FROM paymentsWHERE amount = (SELECT MAX(amount) FROM payments); 如果子查询返回多个结果, 可以用 IN和 NOT IN: SELECT customerName FROM customersWHERE customerNumber NOT IN ( SELECT DISTINCT customerNumber FROM orders); FROM子句 + 子查询: SELECT MAX(items), MIN(items), FLOOR(AVG(items))FROM ( SELECT orderNumber, COUNT(orderNumber) AS items FROM orderdetails GROUP BY orderNumber) AS lineitems; EXISTS 和 NOT EXISTS: 当子查询与 EXISTS或 NOT EXISTS运算符一起使用时，子查询返回一个布尔值为TRUE或FALSE的值。以下查询说明了与EXISTS运算符一起使用的子查询： SELECT * FROM tb_students_infoWHERE EXISTS ( SELECT dept_name FROM tb_departments WHERE dept_id=1) 使用Explain分析SQL执行explain显示了mysql如何使用索引来处理select语句以及连接表。可以帮助选择更好的索引和写出更优化的查询语句。使用方法，在select语句前加上explain EXPLAIN SELECT * FROM employees.titlesWHERE emp_no=&apos;10001&apos;AND title IN (&apos;Senior Engineer&apos;, &apos;Staff&apos;, &apos;Engineer&apos;, &apos;Senior Staff&apos;, &apos;Assistant Engineer&apos;, &apos;Technique Leader&apos;, &apos;Manager&apos;)AND from_date=&apos;1986-06-26&apos;;+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+| 1 | SIMPLE | titles | range | PRIMARY | PRIMARY | 59 | NULL | 7 | Using where |+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+ ➤ 关注的列: possible_keys, key, type, 其中 type列表示查询类型, 改列可能的值: system: 表中只有一条数据. 这个类型是特殊的 const 类型. const: 针对主键或唯一索引的等值查询, 最多只返回一行数据. const 查询速度非常快, 因为它仅仅读取一次即可. eq_ref: 此类型通常出现在多表的查询(例如join), 表示对于前表的每一个结果, 都只能匹配到后表的一行结果. 并且查询条件通常是 =, 查询效率较高. ref: All rows with matching index values are read from this table for each combination of rows from the previous tables. 1) 使用了非唯一或非主键索引, 可能匹配到多行(比较eq_ref) 2) 使用到了 最左前缀 规则的查询. 3) 以上两条对多表查询也适用 index_merge: 表示出现了索引合并优化(包括交集，并集以及交集之间的并集)，但不包括跨表和全文索引。这个比较复杂，目前的理解是合并单表的范围索引扫描（如果成本估算比普通的range要更优的话 range: 表示使用索引范围查询, 通过索引字段范围获取表中部分数据记录. 这个类型通常出现在 =, &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=, IS NULL, &lt;=&gt;, BETWEEN, IN() 操作中. index: 表示全索引扫描(full index scan), 和 ALL 类型类似, 只不过 ALL 类型是全表扫描, 而 index 类型则仅仅扫描所有的索引, 而不扫描数据. index 类型通常出现在: 所要查询的数据直接在索引树中就可以获取到(覆盖索引), 而不需要扫描数据. 当是这种情况时, Extra 字段 会显示 Using index. all: 表示全表扫描, 这个类型的查询是性能最差的查询之一 ➤ 性能排序: all &lt; index &lt; range ~ index_merge &lt; ref &lt; eq_ref &lt; const &lt; system ➤ @ref: MySQL 性能优化神器 Explain 使用分析 - 后台开发 - SegmentFault 思否 最官方的 mysql explain type 字段解读 SQL优化 优化select: 优化查询也即”如何高效使用索引”→ [[MySQL-03索引-高效使用索引]] 优化count: → [[../49.Course/course.MySQL实战45讲]] 14节 count的实现: 统计非null行个数, 推荐使用count(*), 最差的是count(非索引列) 优化limit: limit 10000 20 方法1: 记录上次id select * from film where id &gt; LAST_CURSOR limit 10 优化order by: → [[../49.Course/course.MySQL实战45讲]] 第16节 SELECT film_id,description FROM film ORDER BY title LIMIT 50,5 Mysql执行这段语句, 会把符合条件的列放入 order buffer, 排序后再 limit, 如果表数据很多排序会很耗时, 优化思路就是减少排序规模(延迟关联): SELECT film.film_id,film.descriptionFROM film INNER JOIN (SELECT film_id FROM film ORDER BY title LIMIT 50,5) AS tmp USING(film_id); 优化join: 外层表减小数据规模, 内层表尽量走索引 @link: [[MySQL-01-SQL语句-JOIN原理及优化]] 优化union: 原理: 创建临时表, union左右语句符合条件的行, 逐行填充到临时表, 如果用的是union而不是union all, mysql还需要用distinct做唯一过滤 优化: 1 尽量使用union all, 如果一定需要去重, 建议在代码里做. 2 每个union子句里尽量用where/limit减小规模 优化in: 原理: in可以使用索引, 优化器是转化成了n*m种组合方式来进行查询，最终将返回值合并，有点类似union但是更高效 优化: @todo","categories":[{"name":"32.Database","slug":"32-Database","permalink":"https://beefyheisenberg.github.io/categories/32-Database/"}],"tags":[{"name":"后端架构","slug":"后端架构","permalink":"https://beefyheisenberg.github.io/tags/后端架构/"},{"name":"数据库","slug":"数据库","permalink":"https://beefyheisenberg.github.io/tags/数据库/"},{"name":"MySQL","slug":"MySQL","permalink":"https://beefyheisenberg.github.io/tags/MySQL/"},{"name":"SQL语句","slug":"SQL语句","permalink":"https://beefyheisenberg.github.io/tags/SQL语句/"}]},{"title":"MySQL-00基础概念","slug":"32.Database/MySQL-00基础概念","date":"2024-01-24T01:27:52.842Z","updated":"2024-01-24T01:27:52.843Z","comments":true,"path":"32.Database/MySQL-00基础概念/","link":"","permalink":"https://beefyheisenberg.github.io/32.Database/MySQL-00基础概念/","excerpt":"基础概念参考:《深入浅出MySQL》 SCHEMAschema 为数据库对象的集合， schema里面包含了各种对象如tables, views, sequences, 可以视作”数据库”, show database可以看到schema.不同数据库产品的schema概念是不同的:","text":"基础概念参考:《深入浅出MySQL》 SCHEMAschema 为数据库对象的集合， schema里面包含了各种对象如tables, views, sequences, 可以视作”数据库”, show database可以看到schema.不同数据库产品的schema概念是不同的: MySQL: Schema 等同于 Datebase SQL Server: schema中包含了数据库的表，字段，数据类型以及主键和外键的名称。 数据类型 数字: 整数: TINYINT 1, SMALLINT 2, INT 4, BIGINT 8 小数: 浮点数: float, double 定点数: decimal, 常用来表示高精度数据, 比如货币 字符串: CHAR 255, 定长 VARCHAR 65535, 变长 TEXT: 还分为TEXT(65535), MEDIUMTEXT, LONGTEXT BOLB: 还分为BOLB(65535), MEDIUMBOLB, LONGBOLB, 与TEXT的区别是, BOLB可以存储二进制数据, 比如图片 日期: DATE: 2017-07-25 DATETIME: 2017-07-25 21:57 TIMESTAMP: 字符串的”2017-07-25 21:57” DATETIME 和 TIMESTAMP类型的区别: DATETIM 和 TIMESTAMP类型所占的存储空间不同，前者8个字节，后者4个字节，这样造成的后果是两者能表示的时间范围不同。 前者范围为 1000-01-01 00:00:00 ~ 9999-12-31 23:59:59，后者范围为 1970-01-01 08:00:01到2038-01-19 11:14:07。所以可以看到TIMESTAMP支持的范围比DATATIME要小,容易出现超出的情况. TIMESTAMP类型在默认情况下，insert、update 数据时，TIMESTAMP列会自动以当前时间（CURRENT_TIMESTAMP）填充/更新。@ref: MySQL timestamp自动更新时间分享 TIMESTAMP比较受时区timezone的影响以及MYSQL版本和服务器的SQL MODE的影响 运算符 符号 描述 备注 = 等于 > 大于 \\&lt; 小于 != 不等于 不可比较NULL, 例 1 != NULL也返回NULL &lt;&gt; 不等于 同上 &lt;=&gt; 等于 NULL-Safe的比较, NULL&lt;=&gt;NULL为1, 1&lt;=&gt;NULL为0 IS NULL 等于NULL IS NOT NULL 不等于NULL BETWEEN 在两值之间 IN 在集合中 LIKE 模糊匹配 函数 字符串拼接: CONCAT(s1, s2, …) LOWER(s1), UPPER(s1) FLOOR(a): 返回小于a的最大整数 MOD(a,b): 返回x/y的模 字符集(编码)查看数据库使用的字符集: # 方式1mysql&gt; status;# 方式2show variables like &apos;character%&apos;; GBK vs UTF-8 GBK: 扩展了GB2312标准, 无论英文还是汉字都是2字节 UTF-8: 英文1字节, 汉字3字节, 同时也兼容ASCII码 如果数据库只需要支持一般中文，数据量很大，性能要求也很高，那就应该选择双字节定长编码的中文字符集，比如 GBK。 相对于UTF-8而言，GBK比较“小”，每个汉字只占2个字节，而 UTF-8汉字编码需要3个字节，这样可以减少磁盘I/O、数据库Cache以及网络传输的时间，从而提高性能。 如果应用主要处理英文字符，仅有少量汉字数据，那么选择 UTF-8更好，因为UTF-8的西文占1字节, 而GBK西文字符编码都是2个字节(汉字3字节)，会造成很多不必要的开销。 utf8 vs utf8mb4 utf8 表示西文需2字节, 汉字需3字节, 如果在utf8编码上使用vchar(100)这种类型, Mysql会为该列保留 “一个utf8最大占用空间x100” 也即 300字节. utf8 存在的问题: uft8最大能编码的Unicode范围是3字节, 对于超过3字节的无能为力(包括一些汉字, 以及emoji表情) utf8mb4 (后缀mb4意思是”most bytes 4”), “4字节 UTF-8 Unicode 编码”, utf8mb4可以最多表示4字节Unicode编码, utf8是utf8mb4的一个子集, utf8mb4使用与utf8相同的编码值和长度, 此外utf8mb4还包括utf8没有的4字节编码, 因此从旧版本的MySQL UTF8 升级数据时 不用担心字符转换或丢失数据 @ref 全面了解mysql中utf8和utf8mb4的区别 - 谢思华blog - OSCHINA 主键 &amp; 外键 主键: 一个表只能有一个列作为主键, 主键的值不可重复, 不可为空(NULL) 主键一定是唯一性索引，唯一性索引并不一定就是主键 外键: 一个表中的FOREIGN KEY 指向另一个表中的 PRIMARY KEY。 FOREIGN KEY 约束用于预防破坏表之间连接的动作。 FOREIGN KEY 约束也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。 外键约束： (1)插入非空值时，如果主键值中没有这个值，则不能插入。 (2)更新时，不能改为主键表中没有的值。 (3)删除主键表记录时，可以在建外键时选定外键记录一起联删除还是拒绝删除。 (4)更新主键记录时，同样有级联更新和拒绝执行的选择。 @ref: 大家设计数据库时使用外键吗？ - 知乎 互联网行业应用不推荐使用外键： 用户量大，并发度高，为此数据库服务器很容易成为性能瓶颈，尤其受IO能力限制，且不能轻易地水平扩展；若是把数据一致性的控制放到事务中，也即让应用服务器承担此部分的压力，而引用服务器一般都是可以做到轻松地水平的伸缩；所以Hibernate多对一（many-to-one）/一对多（one-to-many）关联也就很少提及了。 Hibernate，JPA 对象关系映射之关联关系映射策略 索引① 按照索引的物理存储来分: 聚集索引 (clustered index)：聚集索引决定数据在磁盘上的物理排序，一个表只能有一个聚集索引，一般用primary key来约束。主键索引对应的B+树, 叶子节点是一行的完整数据 非聚集索引 (non-clustered index)：它并不决定数据在磁盘上的物理排序，其叶子节点的数据是主键的值。所以使用普通索引查询的时候，需要先找到对应的主键值，再回主键索引的B+树上找到行数据（回表） ② 从逻辑角度, MySQL一共有五类索引: 唯一索引(UNIQUE INDEX), 唯一索引是不允许其中任何两行具有相同索引值的索引。主键是一种唯一性索引，它必须指定为“PRIMARY KEY” 主键索引：主键索引是一种特殊的唯一索引，不允许有空值, 主键索引也是聚簇索引 普通索引：非主键索引, 最基本的索引类型，没有唯一性之类的限制。 联合索引：指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用联合索引时遵循最左前缀集合注意：建了一个(a,b,c)的联合索引，那么实际等于建了(a),(a,b),(a,b,c)三个索引，每多一个索引都会增加写操作的开销和磁盘空间的开销。 候选索引：与主索引一样要求字段值的唯一性，并决定了处理记录的顺序。在数据库和自由表中，可以为每个表建立多个候选索引。 空间索引：空间索引是对空间数据类型的字段建立的索引，MYSQL中的空间数据类型有4种，分别是GEOMETRY、POINT、LINESTRING、POLYGON。 MYSQL使用SPATIAL关键字进行扩展，使得能够用于创建正规索引类型的语法创建空间索引。创建空间索引的列，必须将其声明为NOT NULL，空间索引只能在存储引擎为MYISAM的表中创建 ③ 从数据结构角度: BTREE索引: MyISAM和InnoDB存储引擎默认都是BTREE索引 HASH索引： 仅仅能满足”=”,”IN”和”&lt;=&gt;”查询，不能使用范围查询 其检索效率非常高，索引的检索可以一次定位，不像B-Tree 索引需要从根节点到枝节点，最后才能访问到页节点这样多次的IO访问，所以 Hash 索引的查询效率要远高于 B-Tree 索引 只有Memory存储引擎显示支持hash索引 FULLTEXT索引: 全文索引，在 CHAR、VARCHAR ，TEXT 列上可以创建全文索引。FULLTEXT索引也是按照分词原理建立索引的。 RTree索引（空间索引）：空间索引是MyISAM的一个特殊索引类型，主要用于地理空间数据类型，通常使用较少，不做特别介绍。 MySQL引擎 InnoDB 支持事务 支持行级锁 MyISAM 不支持事务 支持表锁, 不支持行级锁 // 并发性能差 设计简单，某些场景下性能很好，例如获取整个表有多少条数据count(*)，性能很高。 Memory 不支持事务 支持哈希索引 MySQL Commands连接mysql -h 127.0.0.1 -u xxx -pXXX -P 3306# --auto-rehash 启用自动补全(但我试了没用)mysql -h主机地址 -P端口 -u用户名 -p密码 -D数据库名 --auto-rehash# Mysql的`schemas`和`数据库名`是等同的# 连接成功后可以输入以下命令, 分号是必须的:show databases;use db_name;show tables;desc table_name; # 查看表结构use table_name;# 如果输入了一半sql命令想要放弃, 加上&apos;\\c&apos;即可select * from table_name \\c# 如果忘记了table在那个database 或schema, 表占用大小以及行数:select * from information_schema.tables where table_name = &apos;xxx&apos; 导出 导出数据库结构,不带数据: mysqldump -h ip_addr -uxxx -pxxx -d DBName &gt; dump.sql 如果要一并导出数据, 去掉-d参数. 导出表, 不带数据: mysqldump -h ip_addr -uxxx -pxxx -d DBName TableName &gt; dump.sql 导入 mysql -u username -p -h localhost DATABASE-NAME &lt; data.sql mycli官网: https://www.mycli.net/ 安装: pip install mycli 或: brew update &amp;&amp; brew install mycli Usage: # 获取帮助mycli --help# 连接数据库mycli -h 主机地址 -p 端口 -u 用户","categories":[{"name":"32.Database","slug":"32-Database","permalink":"https://beefyheisenberg.github.io/categories/32-Database/"}],"tags":[{"name":"后端架构","slug":"后端架构","permalink":"https://beefyheisenberg.github.io/tags/后端架构/"},{"name":"数据库","slug":"数据库","permalink":"https://beefyheisenberg.github.io/tags/数据库/"},{"name":"MySQL","slug":"MySQL","permalink":"https://beefyheisenberg.github.io/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"https://beefyheisenberg.github.io/tags/事务/"}]},{"title":"MongoDB","slug":"32.Database/MongoDB","date":"2024-01-24T01:27:52.836Z","updated":"2024-01-24T01:27:52.837Z","comments":true,"path":"32.Database/MongoDB/","link":"","permalink":"https://beefyheisenberg.github.io/32.Database/MongoDB/","excerpt":"MongoDB是高性能(得益于内存缓存)、无模式的文档型数据库，支持二级索引，类json格式存储(bson)，非常适合文档化格式的存储及查询。适合用来存放评论等半结构化数据;MongoDB的官方定位是通用数据库，与MySQ类似，但跟传统关系型数据库比较，Mongo在事务、join、复杂查询应用下仍旧无法取代关系型数据库。 mongo shellquery ObjectId: db.getCollection(&#39;activities&#39;).find(ObjectId(&#39;5a9f5e7137c65800015df8d0&#39;)) AND: db.collection.find({ &quot;key&quot; : &quot;value&quot;, &quot;key1&quot; : &quot;value1&quot;}) OR:","text":"MongoDB是高性能(得益于内存缓存)、无模式的文档型数据库，支持二级索引，类json格式存储(bson)，非常适合文档化格式的存储及查询。适合用来存放评论等半结构化数据;MongoDB的官方定位是通用数据库，与MySQ类似，但跟传统关系型数据库比较，Mongo在事务、join、复杂查询应用下仍旧无法取代关系型数据库。 mongo shellquery ObjectId: db.getCollection(&#39;activities&#39;).find(ObjectId(&#39;5a9f5e7137c65800015df8d0&#39;)) AND: db.collection.find({ &quot;key&quot; : &quot;value&quot;, &quot;key1&quot; : &quot;value1&quot;}) OR: db.collection.find(&#123; $or : [ &#123;k1:v1&#125;, &#123;k2:v2&#125; ]&#125;) 条件 lt, lte, gt, gte: db.collection.find(&#123; &quot;key&quot; : &#123; $gte : 59&#125;&#125;) not null : db.collection.find({&quot;key&quot;: {$exists:true}}) 排序 升序: db.collection.find({}).sort({&quot;key&quot;: 1}) 降序: db.collection.find({}).sort({&quot;key&quot;: -1}) update格式: db.collection.update( &#123;query&#125;, &#123;update&#125;, &#123; upsert: &lt;boolean&gt;, multi: &lt;boolean&gt;, writeConcern: &lt;document&gt; &#125;) 例子: db.getCollection(&apos;activities&apos;).update( &#123;&quot;dateStart&quot; : &#123;$gte:1514736000000&#125;&#125;, &#123;$set : &#123;&apos;name&apos; : &apos;xxxx&apos;&#125;&#125;, &#123;multi : true&#125;) inc自增: db.getCollection(&apos;activities&apos;).update( &#123; &quot;_id&quot; : ObjectId(&quot;5aa86f063dd35a000113401f&quot;) &#125;, &#123; $inc : &#123; &quot;score&quot; : 10 &#125;&#125;) 数组操作 $push:向文档数组中添加元素，如果没有该数组，则自动添加数组 $addToSet:功能与$push相同，区别在于，$addToSet把数组看作成一个Set,如果数组中存在相同的元素，不会插入。$addToSet : {&#39;displayAttributes&#39; : &#39;totalPvShow&#39;} 数组操作: db.getCollection(&apos;activities&apos;).update( &#123;&quot;dateStart&quot; : &#123;$gte:1514736000000&#125;&#125;, &#123;$addToSet : &#123;&apos;displayAttributes&apos; : &apos;totalPvShow&apos;&#125;&#125;, &#123;multi : true&#125;) aggregate设每个数据包括 { &quot;icq&quot;: &quot;xxx&quot;, &quot;score1&quot; : 1, &quot;score2&quot; : 2 }, 按icq聚合, 求score1和score2的和 db.getCollection(&apos;item&apos;).aggregate([&#123;$match : &#123; &quot;icq&quot; : &quot;xxxx&quot;&#125; &#125;, # 匹配条件&#123;$group : &#123; _id : &quot;$icq&quot; , # `_id`是固定的语法, 按哪一属性聚合 score1_sum : &#123; $sum : &quot;$score1&quot; &#125;, # 自定义结果名: &#123;$操作 : &quot;$属性名&quot;&#125; score2_sum : &#123; $sum : &quot;$channel&quot; &#125; &#125;&#125;]) mongo命令启动数据库并开启权限: /opt/apps/mongodb/bin/mongod --config /opt/conf/mongo/mongo.conf --auth 连接mongo并查询 mongo 127.0.0.1 -u username -p pwd --port 28015 # 连接数据库mongo 127.0.0.1 -u username -p pwd --port 28015 --authenticationDatabase \"admin\" # 指定验证的dbmongo 127.0.0.1:27017/admin -u mongouser -p pwd # 另一种登录格式&gt; show dbs # 列出所有数据库&gt; use db_name&gt; show collections # collection类似表&gt; db.collection_name.find() # 在xxx这个collection里查找&gt; db.collection_name.find(&#123;appid: \"total\", time: \"20170324\"&#125;) # 在xxx里查找appid=total的项 关闭mongo服务: &gt; use admin&gt; db.shutdownServer(); mongoexport mongoexport参数说明: -d: database /c: collection /q: query filter, as a JSON string, e.g., ‘{x:{$gt:1}}’ /sort: sort order, as a JSON string, e.g. ‘{x:1}’ —-authenticationDatabase “admin” : 指定验证db 将info库中student的id,name信息以json格式导出到student_json.dat数据文件中，并且限定“行数”是1 mongoexport -h 127.0.0.1 -u root -p 12345 -d info -c student --type=json -f id,name --limit=1 -o E:\\data\\student_json.dat 将info库student collections的name=a的信息以cvs格式导出到student_cvs.dat数据文件中 mongoexport -h 127.0.0.1 -u root -p 12345 -d info -c student --type=cvs -q{&quot;name&quot;:&quot;a&quot;} -o E:\\data\\student_cvs.dat 权限 在admin数据库里addUser创建的是管理员用户, 可以访问任何数据库 db.addUser(&quot;admin&quot;,&quot;admin&quot;); use DATABASE_NAME : 如果数据库不存在，则创建数据库，否则切换到指定数据库。 在某个数据库里addUser创建的用户, 只有对这个数据库的权限 创建用户: db.addUser(“user”,”pwd”); 删除用户: db.removeUser(“xxx”); 查找用户: db.system.users.find() 创建具有admin权限的用户: &gt; use admin&gt; db.addUser(&quot;admin&quot;,&quot;password&quot;)&#123; &quot;user&quot; : &quot;admin&quot;, &quot;readOnly&quot; : false, &quot;pwd&quot; : &quot;a254f094f02d3c96f4748175cb4b9403&quot;, &quot;_id&quot; : ObjectId(&quot;595afee766c59f7c02021c99&quot;)&#125; 如何使用创建的用户登录: use admin # 授权admin必须切换到admin库db.auth(&quot;admin&quot;,&quot;password&quot;)use db_name # 切换到要查询的库show collections","categories":[{"name":"32.Database","slug":"32-Database","permalink":"https://beefyheisenberg.github.io/categories/32-Database/"}],"tags":[{"name":"后端架构","slug":"后端架构","permalink":"https://beefyheisenberg.github.io/tags/后端架构/"},{"name":"数据库","slug":"数据库","permalink":"https://beefyheisenberg.github.io/tags/数据库/"},{"name":"NoSQL","slug":"NoSQL","permalink":"https://beefyheisenberg.github.io/tags/NoSQL/"},{"name":"Mongo","slug":"Mongo","permalink":"https://beefyheisenberg.github.io/tags/Mongo/"}]},{"title":"LSM Tree","slug":"32.Database/LSM-Tree理论基础","date":"2024-01-24T01:27:52.832Z","updated":"2024-01-24T01:27:52.833Z","comments":true,"path":"32.Database/LSM-Tree理论基础/","link":"","permalink":"https://beefyheisenberg.github.io/32.Database/LSM-Tree理论基础/","excerpt":"LSM-Tree 概览➤ What’s LSM-Tree： Log Structured Merge Trees(LSM) ➤ Google BigTable → LSM-Tree @ref: 全面了解大数据“三驾马车”的开源实现_InfoQ精选文章 作为 Google 的大数据三架马车之一，Bigtable 依托于 Google 的 GFS、Chubby 及 SSTable 而诞生，用于解决 Google 内部不同产品在对数据存储的容量和响应时延需求的差异化，力求在确保能够容纳大量数据的同时减少数据的查询耗时。论文中很多很酷的方面之一就是它所使用的文件组织方式，这个方法更一般的名字叫 Log Structured-Merge Tree。@ref: Bigtable: A Distributed Storage System for Structured Data - OSDI ‘06 Paper","text":"LSM-Tree 概览➤ What’s LSM-Tree： Log Structured Merge Trees(LSM) ➤ Google BigTable → LSM-Tree @ref: 全面了解大数据“三驾马车”的开源实现_InfoQ精选文章 作为 Google 的大数据三架马车之一，Bigtable 依托于 Google 的 GFS、Chubby 及 SSTable 而诞生，用于解决 Google 内部不同产品在对数据存储的容量和响应时延需求的差异化，力求在确保能够容纳大量数据的同时减少数据的查询耗时。论文中很多很酷的方面之一就是它所使用的文件组织方式，这个方法更一般的名字叫 Log Structured-Merge Tree。@ref: Bigtable: A Distributed Storage System for Structured Data - OSDI ‘06 Paper 在BigTable里， SSTable(Sorted Strings Table)是一个基本的单元。每个Tablet有若干个SSTable。论文里面并没有提到SSTable是怎么样实现的。但是根据对开源的LevelDB的代码，可以看出SSTable是LSM-Tree的一种实现。论文→ [Patrick O’Neil, Edward Cheng, Dieter Gawlick, and Elizabeth (Betty) O’Neil, “The Log-Structured Merge-Tree,” patent granted to Digital Equipment Corporation, December 1993; appeared in ActaInformatica 33, pp. 351-385, June 1996]. ➤ LSM-Tree vs B+Tree 传统数据库使用 B-Tree 或 B+Tree 等多叉树实现, 具有较好的随机读, 但是随机写性能比较差(数据在逻辑上相离很近但物理却可能相隔很远), 写耗时远大于读耗时; LSM-Tree 优化了随机写, 最新写入的 KV 在内存中进行排序，为了防止宕机而丢失内存中的数据，LSM-Tree 还使用了 WAL 日志机制，新写入的数据同时还会写入磁盘的 WAL 日志中，用于宕机后的数据恢复。WAL 一般使用磁盘顺序写入，可以提供非常好的写操作性能，大约等于磁盘的理论速度，也就是200~300 MB/s 在内存中排好序的数据，会写入磁盘，与下层的文件合并为更大的文件； 所以说 LSM-Tree 写效率提高，也是有代价的：多了文件的合并操作（compaction），同时上下层的磁盘文件有冗余数据； LSM-Tree 特性解析➤ LSM（The Log-Structured Merge-Tree） 即 日志结构合并树, 有两个特性: 日志结构 + 合并树. OSDI ‘06 Paper 日志: 数据被插入时, 首先写 WAL(Write Ahead Log), WAL 是磁盘顺序写, 写入速度很快 合并树: LSM-Tree 的树结构分两部分, 存储于内存中的 C0层, 以及存储于磁盘的 C1..Ck 层; C0层一般使用 RB-Tree 或 SkipList 实现, WAL 里的数据首先被写入 C0树, C0树按照 Key 有序存储; 当 C0层的大小超过阈值, 会与下一层的 C1层进行合并(Compaction), 成为新的 C1层, 同时清空 C0层, 合并过程类似归并排序中的“归并”过程; 同样 C1层超过大小阈值也会与 C2层的文件进行合并… 所以从 C0-Ck 每层的文件容量逐层增大; C1..Ck 层一般用有序文件（sstable)实现; 写入过程: C0层总是最新写入的数据, Ck 层则包含最旧的数据, 当更新一个 K 对应的 val 时，只会写入最上层, 下层的旧数据并不会更新，而是当上下两层合并时, 上层的新数据会覆盖掉下次的旧数据 ; 查询过程: 从 C0层开始查询, 如果找不到就在下一层查找, 所以相比较 B+Tree, LSM-Tree 的读性能会差一些; 删除过程: 仅在 C0层插入一个带有删除标记的 Entry，并不真正删除下层文件中的数据，而是等待合并时 … Scan过程: @todo LevelDB 如何实现 LSM-TreeLevelDB is a key-value store based on LSM-trees: LevelDB 是如何实现 LSM-Tree 的: LevelDB 的 WAL（图中1） 内存中的 MemTable 层： WAL 的数据首先被写入 memtable, 当 memtable 的数据超过阈值, memtable 变为 immutable memtable(不可写入的), 新创建一个 memtable 用于写入新数据, immutable memtable 中的数据 flush 写入磁盘的 L0层; 把内存里面不可变的 immutable memtable flush 到硬盘上的 SSTable 层中，此步骤也称为 Minor Compaction，这里需要注意在 L0层的 SSTable 是没有进行合并的，所以这里的 key range 在多个 SSTable 中可能会出现重叠，在层数大于 0 层之后的 SSTable，不存在重叠 key。 磁盘中的 SSTable 层： 图中的 L0..L6, 每层都由数个 SStable （Sorted String Table）组成, 每层的总大小是上一层的10倍（图中4~5）, SSTable 的概念来自 google 《BigTable》的论文, [[../_attachments/Persistent Key-Value Stores.pdf|Persistent Key-Value Stores]], 按 Key 顺序存储的键值对集合 此步骤也称为Major Compaction，这个阶段会真正的清除掉被标记删除掉的数据以及多版本数据的合并，避免浪费空间，注意由于 SSTable 都是有序的，我们可以直接采用 merge sort 进行高效合并。 Write &amp; Compaction:![[../_images/LevelDB-LSM-Tree2.png]] Search:![[../_images/LevelDB-LSM-Tree3.png]] 图参考自：http://www.cse.cuhk.edu.hk/~mcyang/csci5550/2020S/Lec09%20Persistent%20Key-Value%20Stores.pdf Delete：目前的 LSM-Tree 写入的时候，会写一条记录，删除的时候，标志一个 tombstone （类似 leveldb 的 type） 对比 B-TreeLSM-Tree 对比 B-Tree，某种程度也相当于对比 HBase 和 MySQL 两种不同的数据库。 LSM-tree 正是能够借助内存缓冲将大量的随机写入转化成批量的顺序写入，使得最终磁盘承载的写入次数对数级减少，极大地提升了写入吞吐量。 此外，当更新一条数据时，B+Tree 采用原地更新方式（in-place update），整个叶子节点对应的数据页都要读取和写回，带来了额外的读写放大。因此，磁盘随机读写成为 B+Tree 的瓶颈，使其适用于读多写少的场景。 数据在 MySQL 和 HBase 中存储差异：即使某列为空，MySQL 依然会为该字段保留空间，因为后续有可能会有 update 语句来更新该记录，填补这列的内容。而 HBase 则是把每一列都看做是一条记录，row+列名作为 key，data 作为 value，依次存放。假如某一行的某一个列没有数据，则直接跳过该列。针对稀疏矩阵的大表，HBase 能大大节省存储空间。 Reference@ref: LSM 算法的原理是什么？ - 知乎 LSM-Tree 的应用及原理 - 知乎 [[../_attachments/Persistent Key-Value Stores.pdf|Persistent Key-Value Stores]] Ssystem|分布式|Bigtable - 知乎","categories":[{"name":"32.Database","slug":"32-Database","permalink":"https://beefyheisenberg.github.io/categories/32-Database/"}],"tags":[]},{"title":"HBase-vs-ES","slug":"32.Database/HBase-vs-ES","date":"2024-01-24T01:27:52.828Z","updated":"2024-01-24T01:27:52.828Z","comments":true,"path":"32.Database/HBase-vs-ES/","link":"","permalink":"https://beefyheisenberg.github.io/32.Database/HBase-vs-ES/","excerpt":"","text":"比较elasticsearch 和 hbase海量日志数据存储用 elasticsearch 和 hbase 哪个好？ - 知乎 1）两者都可以通过扩展集群来加大可存储的数据量。随着数据量的增加，es的读写性能会有所下降 2）数据更新es数据更新是对文档进行更新，需要先将es中的数据取出，设置更新字段后再写入es。hbase是列存储的，可以方便地更新任意字段的值。 3）查询复杂度hbase支持简单的行、列或范围查询，若没有对查询字段做二级索引的话会引发扫全表操作，性能较差。而ES提供了丰富的查询语法，支持对多种类型的精确匹配、模糊匹配、范围查询、聚合等操作，ES对字段做了反向索引，支持全文检索, 即使在亿级数据量下还可以达到秒级的查询响应速度。 4）字段扩展性hbase和es都对非结构化数据存储提供了良好的支持。es可以通过动态字段方便地对字段进行扩展，而hbase本身就是基于列存储的，可以很方便地添加qualifier来实现字段的扩展","categories":[{"name":"32.Database","slug":"32-Database","permalink":"https://beefyheisenberg.github.io/categories/32-Database/"}],"tags":[]},{"title":"HBase-05源码","slug":"32.Database/HBase-05源码","date":"2024-01-24T01:27:52.823Z","updated":"2024-01-24T01:27:52.823Z","comments":true,"path":"32.Database/HBase-05源码/","link":"","permalink":"https://beefyheisenberg.github.io/32.Database/HBase-05源码/","excerpt":"客户端API源码施工中 createConnection()Configuration configuration = HBaseConfiguration.create();Connection connection = ConnectionFactory.createConnection(configuration);connection.getTable(TableName.valueOf(\"tbl_xxx\")); 创建connection过程如下:ConnectionFactory.createConnection(Configuration conf), 返回的是一个HConnectionImplementation的对象, 调用了HConnectionImplementation的构造函数:HConnectionImplementation(Configuration conf, boolean managed, ExecutorService pool, User user)","text":"客户端API源码施工中 createConnection()Configuration configuration = HBaseConfiguration.create();Connection connection = ConnectionFactory.createConnection(configuration);connection.getTable(TableName.valueOf(\"tbl_xxx\")); 创建connection过程如下:ConnectionFactory.createConnection(Configuration conf), 返回的是一个HConnectionImplementation的对象, 调用了HConnectionImplementation的构造函数:HConnectionImplementation(Configuration conf, boolean managed, ExecutorService pool, User user) 看一下HConnectionImplementation构造都做了哪些初始化:&#123; this.asyncProcess = this.createAsyncProcess(this.conf); this.rpcClient = RpcClientFactory.createClient(this.conf, this.clusterId, this.metrics);&#125; getTable()Connection connection = ConnectionFactory.createConnection(configuration);connection.getTable(TableName.valueOf(\"tbl_xxx\")); Connection.getTable()实际调用到了HConnectionImplementation.getTable()返回了一个新对象: new HTable(tableName, this, this.connectionConfig, this.rpcCallerFactory, this.rpcControllerFactory, pool) HTable有几个重要成员: connection, multiAp, locator 在HTable初始化时, 上面几个成员按如下顺序初始化:this.multiAp = this.connection.getAsyncProcess();this.locator = new HRegionLocator(this.tableName, this.connection); put()Put put = new Put(rowKey.getBytes());put.addColumn(family.getBytes(), qualifier.getBytes(), val.getBytes());table.put(put); HTable.put(Put) 并不会立刻发送RPC请求, 而是等多次请求后再一次backgroundFlushCommits,submit(tableName, buffer, true, null, false);","categories":[{"name":"32.Database","slug":"32-Database","permalink":"https://beefyheisenberg.github.io/categories/32-Database/"}],"tags":[]},{"title":"HBase-04行键(Rowkey)设计","slug":"32.Database/HBase-04行键设计","date":"2024-01-24T01:27:52.815Z","updated":"2024-01-24T01:27:52.816Z","comments":true,"path":"32.Database/HBase-04行键设计/","link":"","permalink":"https://beefyheisenberg.github.io/32.Database/HBase-04行键设计/","excerpt":"表的设计在HBase中表的概念并不是那么重要, 数据的物理存储是基于列族的. Row Key设计设计合理的 Row Key设计可以加速scan操作, 还可以在大量写入数据时让多个RegionServer分担负载. Region是 HBase中扩展和负载均衡的基本单元, Region本质上是以 Row Key的字典顺序连续存储的, 这种设计优化了 scan的操作，一个 Table最初只有一个 Region, 当一个 Region过大时, 系统会在中间键(middle key)将这个 Region拆分成两个大致相等的子 Region。Row Key设计不好就会造成读写热点问题，造成大量客户端直接访问集群某一个或者极少数的节点，造成节点性能下降或者Region不可用","text":"表的设计在HBase中表的概念并不是那么重要, 数据的物理存储是基于列族的. Row Key设计设计合理的 Row Key设计可以加速scan操作, 还可以在大量写入数据时让多个RegionServer分担负载. Region是 HBase中扩展和负载均衡的基本单元, Region本质上是以 Row Key的字典顺序连续存储的, 这种设计优化了 scan的操作，一个 Table最初只有一个 Region, 当一个 Region过大时, 系统会在中间键(middle key)将这个 Region拆分成两个大致相等的子 Region。Row Key设计不好就会造成读写热点问题，造成大量客户端直接访问集群某一个或者极少数的节点，造成节点性能下降或者Region不可用 Rowkey 会占用 HBase 存储空间（包括在内存中的 MemStore，和 HFile 文件），所以 Rowkey 应尽量简短。 Rowkey 设计需要考虑的几点: Rowkey 的设计要避免写入热点，即短时间内大量的写入落到一个Region 业务数据查询场景是什么? 只是常规的 K-V get 操作？是否需要 scan？是否需要经常查询最新数据？ 几种 Rowkey 设计方案: Rowkey 前缀加盐, 通常做法是对 Region 进行预分区指定 startKey，然后对 Rowkey 某部分进行 Hash + 取余操作，可得到 salt 前缀，通过 slat 前缀将 rowkey 分散到各个 Region； Rowkey Hash, 具体做法是使用 Rowkey 里一部分(例如 uid) 进行 hash, 截取 hash 的一部分, 作为 rowkey 前缀, 缺点是无法 scan Rowkey 反转, 对于前缀几乎相同, 仅后缀变化的 rowkey (时间戳, 手机号), 缺点也是无法 scan 另一种”反转”, 例如时间戳, rowkey 设计为 Long.MAX- timestamp, 并不具备”打散”的作用, 而是让最后的(时间戳最大)的排序最靠前, 适用于经常取“当前最新”的场景：例如 [key][reverse_timestamp], 最新值可以通过 scan [key] 获得最新记录，因为 HBase 中 RowKey 是有序的，第一条记录是最后录入的数据 案例： 电商： 查询需求：展示卖家最近一段时间的订单（scan） Rowkey 设计： salt + sellerID + timestamp + orderId 监控： 查询需求：展示最新 or 最近一段时间（scan） Rowkey 设计：参考 「OpenTSDB 的 Rowkey 设计」 推荐feed case： 查询需求：某用户某一天进行的 feed 请求，也需要scan Rowkey 设计： uid + timestamp 用户画像： 查询需求：根据 uid 查询，无需 scan Rowkey 设计：prefix + uid，其中 prefix = substr(md5(uid), 0 ,x) 参考： 大白话彻底讲透 HBase Rowkey 设计和实现！-腾讯云开发者社区-腾讯云 案例篇-HBase RowKey 设计指南-阿里云开发者社区","categories":[{"name":"32.Database","slug":"32-Database","permalink":"https://beefyheisenberg.github.io/categories/32-Database/"}],"tags":[]},{"title":"HBase-03架构和原理","slug":"32.Database/HBase-03架构和原理","date":"2024-01-24T01:27:52.810Z","updated":"2024-01-24T01:27:52.811Z","comments":true,"path":"32.Database/HBase-03架构和原理/","link":"","permalink":"https://beefyheisenberg.github.io/32.Database/HBase-03架构和原理/","excerpt":"HBase 架构简介 HBase包含3个重要组件：Zookeeper、HMaster和 HRegionServer。 （1）Zookeeper： 为整个 HBase集群提供协助服务，包括： a. 存放整个 HBase集群的元数据以及集群的状态信息。 b. 实现 HMaster主从节点的 failover。 ZooKeeper为 HBase集群提供协调服务，它管理着 HMaster和 HRegionServer的状态(available/alive等)，并且会在它们宕机时通知给 HMaster，从而 HMaster可以实现 HMaster之间的 failover，或对宕机的 HRegionServer中的 HRegion集合的修复(将它们分配给其他的 HRegionServer)。","text":"HBase 架构简介 HBase包含3个重要组件：Zookeeper、HMaster和 HRegionServer。 （1）Zookeeper： 为整个 HBase集群提供协助服务，包括： a. 存放整个 HBase集群的元数据以及集群的状态信息。 b. 实现 HMaster主从节点的 failover。 ZooKeeper为 HBase集群提供协调服务，它管理着 HMaster和 HRegionServer的状态(available/alive等)，并且会在它们宕机时通知给 HMaster，从而 HMaster可以实现 HMaster之间的 failover，或对宕机的 HRegionServer中的 HRegion集合的修复(将它们分配给其他的 HRegionServer)。 （2）HMaster： 主要用于监控和操作集群中的所有 HRegionServer。HMaster没有单点问题，HBase中可以启动多个HMaster，通过 Zookeeper的 MasterElection机制保证总有一个Master在运行，HMaster 主要负责 Table和 Region的管理工作： a. 管理用户对表的增删改查操作 b. 管理 HRegionServer的负载均衡，调整Region分布 c. Region Split后，负责新 Region的分布 d. 在 HRegionServer停机后，负责失效 HRegionServer上Region迁移 （3）HRegion Server： HBase中最核心的模块，主要负责响应用户I/O请求，向HDFS文件系统中读写数据。 a. 存放和管理本地 HRegion。 b. 读写HDFS，管理Table中的数据。 c. Client直接通过 HRegionServer读写数据（从HMaster中获取元数据，找到RowKey所在的 HRegion/HRegionServer后）。 HDFS底层的存储都是基于 Hadoop HDFS 的： Hadoop NameNode 维护了所有 HDFS 物理 Data block 的元信息。 Hadoop DataNode 负责存储 Region Server 所管理的数据。所有的 HBase 数据都存储在 HDFS 文件中。Region Server 和 HDFS DataNode 往往是一起部署的，这样 Region Server 就能够实现数据本地化（data locality） 在 Region 的监控页面，可以看到一个监控指标 “Locality（本地化率）”，是一个百分比，表示 region 管理的数据即位于本地的百分比（“本地”指：数据所在的 HDFS DataNode 和 Region Server 在一个节点 ） 本地化率低产生的问题：因为大量 HFile 数据和 Region 不在同一个节点上，会产生大量的网络 IO，导致读请求延迟较高； 引起 RegionServer 数据本地化率低的几种可能原因： 1) Balance 引起的：当数据持续写入，单个 region 的大小达到 hbase.hregion.max.filesize(默认值10GB)会自动进行 Split,假如一直向 RegionA 持续写入数据，当 RegionA 大小超过10GB，会分离成两个子 RegionB、RegionC，如果我们集群开启了负载均衡，当前节点 Region 比较多，其他节点 Region 数量少的时候就会把 RegionB 或 RegionC 迁移到 Region 相对比较少的节点上去。 2) RegionServer 宕机，手动 move 使 region 迁移到其他节点，导致数据本地化率降低。 Region 迁移如何导致 Locality 下降： 在 hadoop 生产环境中， hdfs 通常为设置为三个副本，假如当前 RegionA 处于 datanode1，当数据 a 通过从 Memstore 中 Flush 到 HFile 时,三副本分别在(datanode1,datanode2,datanode3),数据 b 写入三副本：(datanode1,datanode3,datanode5),数据 c 写入三副本：(datanode1,datanode4,datanode6),可以看出来 a、b、c 三份数据写入的时候肯定会在本地 datanode1上写入一份，其他两份按照 datanode 的写入机制进行分配;数据都在本地可以读到，因此数据本地率是100%。现在假设 RegionA 被迁移到了 datanode2上，只有数据 a 有一份数据在该节点上，其他数据(b 和 c)读取只能远程跨节点读，本地率就为33% (假设 a，b 和 c 的数据大小相同)。 如何提高 RegionServer 数据的本地化率： RegionServer 重启后，手动 move 到原来节点（如果生产 region 比较多，这个操作比较繁琐） 定期执行 major compaction（尤其对于 Locality 低的 RegionServer，如果不做 major compaction 会非常影响读写性能 ） @ref: Healing HBase Locality At Scale HDFS 三副本机制 @link [[../33.Bigdata/Hadoop#副本机制]] 1）第一个副本块保存在 HDFS Client 同一个的 DataNode ； 2）第二个副本块保存在 HDFS Client 所在 DataNode 同机架的其他 DataNode ； 3）第三个副本块保存不同机架的某个 DataNode ； ZookeeperZookeeper 用来协调分布式系统中集群状态信息的共享。Region Servers 和在线 HMaster（active HMaster）和 Zookeeper 保持会话（session）。Zookeeper 通过心跳检测来维护所有临时节点（ephemeral nodes）。 每个 Region Server 都会创建一个 ephemeral 节点。HMaster 会监控这些节点来发现可用的 Region Servers，同样它也会监控这些节点是否出现故障。 HMaster 们会竞争创建 ephemeral 节点，而 Zookeeper 决定谁是第一个作为在线 HMaster，保证线上只有一个 HMaster。在线 HMaster（active HMaster） 会给 Zookeeper 发送心跳，不在线的待机 HMaster （inactive HMaster） 会监听 active HMaster 可能出现的故障并随时准备上位。 如果有一个 Region Server 或者 HMaster 出现故障或各种原因导致发送心跳失败，它们与 Zookeeper 的 session 就会过期，这个 ephemeral 节点就会被删除下线，监听者们就会收到这个消息。Active HMaster 监听的是 region servers 下线的消息，然后会恢复故障的 region server 以及它所负责的 region 数据。而 Inactive HMaster 关心的则是 active HMaster 下线的消息，然后竞争上线变成 active HMaster。 META 表当 Client 发起的每个 RPC 请求，实际上都需要发送到对应的 RegionServer 上执行，所以第一步是通过 Table 和 Rowkey 定位 Region ，对应关系存储在 hbase:meta 表： hbase:meta 是一个比较特殊的 hbase 表，也叫元数据表（不能切分，只保存在一台 RegionServer 上） 在0.96之后元数据的查询模型由3层结构变成2层，即： 首先查询 zk 获取 hbase:meta 所在的 regionserver； 然后去对应的 RegionServer 上查询表对应的 region 信息。region 信息中会包含开始的 rowkey，regionserver 的地址等信息。 hbase:meta 表中的一个 Rowkey 就代表了一个 region。Rowkey 主要由以下几部分组成： table_name,start_rowkey,create_timestamp.EncodedName.table_name: 表名start_rowkey 是table 在 Region上的 起始rowkey，为空的，说明这是该table的第一个region。若对应region中startkey为空的话，表明这个table只有一个region；create_timestamp ： region 创建时间； meta 表只有一个列簇 info，并且包含四列： regioninfo ：当前 region 的 startKey 与 endKey，name 等 seqnumDuringOpen： server：region 所在服务器及端口 serverstartcode：服务开始的时候的 timestamp 为了避免每次 Client 执行 RPC 都要查询 Zk，Client 会缓存 meta 的数据： Meta 缓存的数据结构采用了 copy on write 的思想，自定义了一个 CopyOnWriteArrayMap。copy on write 即可以支持并发读，当写的时候采用拷贝引用的方式快速变更。HBase 自定义了一个数组 Map，其中数组结构第一层为表，数组部分的查询采用二分查找；第二层是 startkey；当有 RegionLocation 信息需要更新时，采用 System.arraycopy 实现快速拷贝更新。 图: 通过 table 和 rowkey 快速定位到对应的 Region: @ref: HBase源码：Region的定位与优化 - 知乎 HBase meta表介绍 - 简书 HBase Meta表结构组成 - 个人文章 - SegmentFault 思否 HMasterHMaster 负责 Region 的分配，DDL（创建，删除表）等操作： 统筹协调所有 region server： 启动时分配 regions，在故障恢复和负载均衡时重分配 regions 监控集群中所有 Region Server 实例（从 Zookeeper 获取通知信息） 管理员功能： 提供创建，删除和更新 HBase Table 的接口 HRegion ServerRegionServer: ➤ HRegion Server 的构成： BlockCache: Region Server 的读缓存。保存使用最频繁的数据，使用 LRU 算法换出不需要的数据; HLog: WAL(Write-Ahead-Log), 为数据提供 Crash-Safe, 以及读一致性及 undo/redo 回滚等数据恢复操作; HRegion: 即子表, 每个子表都关联一个 [StartKey, EndKey] 的存储区间, 每个 HRegion Server 管理多个”子表”; HStore: 每个 Region 包括多个 HStore, 每个 HStore 由 1 * MemStore + n * StoreFile 组成 (LSM-Tree 的 C0..Ck 层) MemStore: LSM-Tree的 C0层, 存储于内存的有序K-V结构, 使用ConcurrentSkipList实现, 当 MemStore（默认 64MB）写满之后，会开始 flush 到磁盘上的 StoreFile StoreFile（HFile）: LSM-Tree 的 Ck 层, StoreFile 是对 HFile 做了一层简单封装 ➤ 从逻辑存储看 HRegion Server: HBase 表的逻辑存储: Table, Family, Qualifier 每个 HRegion 存储一张 Table 的一段 Key 区间 每个 HStore 存储一个 Family(列族)的一段 Key 区间 ➤ HBase 如何实现 LSM-Tree: 每个 HStore 都有1个 MemStore (C0层) 和 N 个 StoreFile (C1..Ck 层) MemStore: 跳表实现, MemStore 的数据超过阈值(默认64MB)后会刷写到磁盘, 生成 StoreFile StoreFile(HFile): HBase 会自动合并一些小的 HFile，重写成少量更大的 HFiles。这个过程被称为 Minor Compaction。它使用归并排序算法，将小文件合并成大文件，有效减少 HFile 的数量。Major Compaction 合并重写每个 Column Family 下的所有的 HFiles，成为一个单独的大 HFile，在这个过程中，被删除的和过期的 cell 会被真正从物理上删除，这能提高读的性能。 有关LSM-Tree, 参考: LSM-Tree理论基础 HLog (WAL)HLog 是 WAL(Write-Ahead-Log)的具体实现，数据的更新首先被写入 HLog，在 Region Server 宕机时可以通过回放 Hlog 实现 Crash-safe HLog 实现细节： 每个 Region Server 可以有一个 or 多个 HLog 文件（默认只有1个，1.x 版本可以开启 MultiWAL 功能，允许多个 HLog） // @doubt: 这几个 HLog 文件是顺序的？ 一个 HLog 是被多个 Region（子表）共享的，也即当前所有子表的写入，都落到一个 HLog 文件中； HLog 中，一个基本数据单元为 HLogKey + WALEdit HLogKey：包含 table name、region name、sequenceid 等 WALEdit：WALEdit用来表示一个事务中的更新集合，一次行级事务可以原子操作同一行中的多个列。上图中WALEdit包含多个KeyValue 由上可知，HLog 中每个基本单元代表一次事务中的所有更新集合，HLogKey 中的 sequenceid 是单增整数，可以认为是一次行级事务的自增 ID HBase 为每个 Region （实际是每个 Store，对应某个列族）维护了一个 oldestUnflushedSequenceId，最新未落盘的 sequenceid，每次 MemStore flush 到 HFlie 后，更新每个 Region 的 oldestUnflushedSequenceId 在 Region Server 的情况下，HLog 中哪些日志需要回放，哪些需要 skip？ 因为 Region Server 已经宕机，所以 Region 对应的 oldestUnflushedSequenceId 也无法获取，实际上每次 HFile 落盘时，会把 oldestUnflushedSequenceId 以元数据的形式写入 HFile，所以在宕机迁移时，只需要重新读取 HFile 中的元数据即可恢复出这个核心变量oldestUnflushedSequenceId 下图是中三个 Region（A、B、C）共享一个 HLog，日志最小单元是 HlogKey + WALEdit： @ref: HBase原理－要弄懂的sequenceId – 有态度的HBase/Spark/BigData MemStore 一个子表可能包括多个列族，即一个 Region 可能包括多个 MemStore； MemStore 和列族是一一对应的； MemStore 基于跳表实现，元素通过 KeyValue 对象的 key 进行排序，而不简单的通过 Rowkey 排序； 当 MemStore（默认 64MB）写满之后，会 flush 到 HDFS 上生成 StoreFile，MemStore 相当于 LSM-Tree 结构中的 C0层，这一步叫做 Region flush ； ➤ KV 在 MemStore 中的排序： 构成 HBase 的 KV 在同一个文件中都是有序的，但规则并不是仅仅按照 rowkey 排序，而是按照 KV 中的 key 进行排序——先比较 rowkey，rowkey 小的排在前面；如果 rowkey 相同，再比较 column，即 column family:qualifier，column 小的排在前面；如果 column 还相同，再比较时间戳 timestamp，即版本信息，timestamp 大的排在前面。KV 结构参考 「HFile」 一节 ➤ 为什么不建议使用过多的列族： Flush 操作时 Region 级别的（也就是为什么叫 Region Flush 而不是 “MemStore Flush”），Region 中某个 Memstore 被 Flush，同一个 Region 的其他 Memstore 也会进行 Flush 操作。当表有很多列族，且列族之间数据不均匀，例如一个列族有100W 行，一个列族只有10行，列族1很容易触发 Flush，列族2虽然数据不多但也需要进行 Flush，而且每次 Flush 操作都涉及到一定的磁盘 IO。例如基于 HBase 的 OpenTSDB，存放数据的表只有一个列族。 过多的列族也即意味着更多的 MemStore，占用更多的 JVM 内存。 ➤ MemStore 的内部实现： HBase 的 MemStore 基于 ConcurrentSkipListMap 跳表实现，由于 KeyValue 是存储于内存中的，对于很多写入吞吐量几万每秒的业务来说，每秒就会有几万个内存对象产生，这些对象会在内存中存在很长一段时间，对应的会晋升到老生代，一旦执行了 flush 操作，老生代的这些对象会被 GC 回收掉，导致 JVM 的 GC 压力非常大。 GC 压力主要来源于：这些内存对象一旦晋升到老生代，执行完 OldGen GC 后会存在大量的非常小的内存碎片（例如老年代的回收器 CMS，是不带内存压缩的），这些内存碎片会引起频繁的 Full GC，而且每次 Full GC 的时间会异常的长。 ➤ 一个 KV 在 MemStore 中的写入过程： 在 ChunkPool 中申请一个 Chunk（2M），在 Chunk 中分配一段与 KV 相同大小的内存空间将 KV 拷贝进去。一旦 Chunk 写满，再申请下一个 Chunk; 待插入的 KV 生成一个 Cell 对象，该对象包含指向 Chunk 中对应数据块的指针、offsize 以及 length; 将这个 Cell 对象分别作为 Key 和 Value 插入到 ConcurrentSkipListMap 跳表中； HBase 在 MemStore 设计中的改进 @ref : HBase内存管理之MemStore进化论 – 有态度的HBase/Spark/BigData HFileV1-V2的改进HFile 是 HBase 存储数据的文件组织形式，参考 BigTable 的 SSTable 和 Hadoop 的 TFile 实现。 从 HBase 开始到现在，HFile 经历了三个版本，其中 V2在0.92引入，V3在0.98引入。HFileV1版本的在实际使用过程中发现它占用内存多，HFile V2版本针对此进行了优化，HFile V3版本基本和 V2版本相同，只是在 cell 层面添加了 Tag 数组的支持。 ➤ V1的 HFile，参考了 Bigtable 的 SSTable 以及 Hadoop 的 TFile(HADOOP-3315)： Data Block：每个 Data 块默认为64KB，存储 KV 数据，由于 KV 数据在 MemStore 已经进行排序，所以 Data Block 中的 KV 也是有序的 Data Block Index：这部分存储了每一个 Data Block 的索引信息 {Offset，Size，FirstKey} Meta Block：主要是 Bloom Filter，用来快速定位 Key 是否在 HFile Meta Block Index： 每个 Meta Block 的索引 Tailer：存储了上面几个段的索引，例如 Data Block Index 的索引信息，{Data Index Offset, Data Block Count} Bloom filter 主要用来快速定位 Key 是否在 HFile。Bloom Block 的数据是在启动的时候就已经加载到内存里，除了 Block Cache 和 MemStore 以外，这个也对 HBase 随机读性能的优化起着至关重要的作用。生成 HFile 的时候，会将 key 经过三次 hash 最终落到 Bloom Block 位数组的某三位上，并将其由0更改成1，以此标记该 key 的确存在这个 HFile 文件之中，查询的时候不需要将文件打开并检索，避免了一次 I/O 操作。然而随着 HFile 的膨胀，Bloom Block 会越来越大。 HDFS 中定义的 Block size 是 64~128MB，HFile 中的 Block 大小 = 64KB，区别 Linux 文件系统（Ext4等）定义的块大小 = 4KB ； 下图更直观的表达出了 HFile V1中的数据组织结构： V1 的设计简单、直观。但缺点也很明显，HFile 中的 Bloom Filter 包括了该 HFile 中所有的 KV，加载一个 HFile 需要占用很大的内存来存储 Bloom Filter、Data Block Index。Region Open 的时候，需要加载所有的 Data Block Index 数据，另外，第一次读取时需要加载所有的 Bloom Filter 数据到内存中。一个 HFile 中的 Bloom Filter 的数据大小可达百 MB 级别，一个 RegionServer 启动时可能需要加载数 GB 的 Data Block Index 数据。这在一个大数据量的集群中，几乎无法忍受。 ➤ HFile V2 的改进： 在 V2中，无论是 Data Block Index 还是 Bloom Filter，都采用了分层索引的设计。 Data Block 的索引，在 HFile V2中做多可支持三层索引，每层的索引都在单独的 Block 中存储：Root Data Index -&gt; Intermediate Index Block -&gt; Leaf Index Block，最底层的 Data Block Index 称之为 Leaf Index Block，可直接索引到 Data Block； 索引逻辑为：由 Root Data Index 索引到 Intermediate Block Index，再由 Intermediate Block Index 索引到 Leaf Index Block，最后由 Leaf Index Block 查找到对应的 Data Block。在实际场景中，Intermediate Block Index 基本上不会存在，因此，索引逻辑被简化为：由 Root Data Index 直接索引到 Leaf Index Block，再由 Leaf Index Block 查找到的对应的 Data Block。 Root Data index 存放在一个称之为”Load-on-open Section“区域，在 Region Open 时会被加载到内存中，而 Intermediate &amp; Leaf Index Block 则按需加载。 Bloom Block 也采用了分层设计，整个 HFile 的 Bloom Filter 也被拆成了多个 Bloom Block ，在”Load-on-open Section”区域中存放了所有 Bloom Block 的索引，而 Bloom Block （数据块）按需加载。 总结：V2通过分层索引，无论是 Data Block 的索引数据，还是 Bloom Filter 数据，都被拆成了多个 Block 当中，可以按需读取，避免在 Region Open 阶段或读取阶段一次读入大量的数据，降低了阶段耗时，也解决了 V1内存占用高的问题。 图-HFile V2的 Block 组织，右边是 Data Index 的三层索引结构： Data Block 的三层索引➤ Data Block Index 的三层索引： 图中上面三层为索引层，在数据量不大的时候只有最上面一层，数据量大了之后开始分裂为多层，最多三层，如图所示。最下面一层为数据层，存储用户的实际 keyvalue数据。这个索引树结构类似于 InnoSQL的聚集索引，只是 HBase并没有辅助索引的概念。 图中红线表示一次查询的索引过程（HBase中相关类为 HFileBlockIndex和 HFileReaderV2），基本流程可以表示为： 用户输入rowkey为fb，在root index block中通过二分查找定位到fb在’a’和’m’之间，因此需要访问索引’a’指向的中间节点。因为root index block常驻内存，所以这个过程很快。 将索引’a’指向的中间节点索引块加载到内存，然后通过二分查找定位到fb在index ‘d’和’h’之间，接下来访问索引’d’指向的叶子节点。 同理，将索引’d’指向的中间节点索引块加载到内存，一样通过二分查找定位找到fb在index ‘f’和’g’之间，最后需要访问索引’f’指向的数据块节点。 将索引’f’指向的数据块加载到内存，通过遍历的方式找到对应的keyvalue。 上述流程中因为 中间节点、 叶子节点 和 数据块 都需要加载到内存，所以 IO 次数最大为3次。但是实际上 HBase 为 block 提供了缓存机制，可以将频繁使用的 block 缓存在内存中，可以进一步加快实际读取过程。所以，在 HBase 中，通常一次随机读请求最多会产生3次 io，如果数据量小（只有一层索引），数据已经缓存到了内存，就不会产生 io。 Data Block 的 KV 结构➤ Data Block 的结构： DataBlock 是 HBase 中数据存储的最小单元。DataBlock 中主要存储用户的 KeyValue 数据，KeyValue 结构在内存和磁盘中可以表示为： 可以看到，在 KeyValue 结构中， key 是一个复杂的结构，首先是 rowkey 的长度，接着是 rowkey，然后是 ColumnFamily 的长度，再是 ColumnFamily，之后是 ColumnQualifier，最后是时间戳和 KeyType（keytype 有四种类型，分别是 Put、Delete、 DeleteColumn 和 DeleteFamily） value 就没有那么复杂，就是一串纯粹的二进制数据 BloomFilter#BloomFilter 对于 HBase 的随机读性能至关重要，对于 get 操作以及部分 scan 操作可以剔除掉不会用到的 HFile 文件，减少实际 IO 次数，提高随机读性能。 BloomFilter 使用 bit 数组实现，KeyValue 在写入 HFile 时，会经过3个 Hash 函数，生成3个不同的 hash 值，映射到 bit 数组上3个不同的位置，接下来将对应的 bit 置为1； 下图中，两个元素 x 和 y，分别被3个 hash 函数进行映射，映射到的位置分别为（0，3，6）和（4，7，10），对应的位会被置为1: 查找时，元素要进行3次 hash 映射，如果3个位置上都是1，那么元素可能存在于这个 DataBlock；如果有一个位置是0，那么元素肯定不存在于这个 DataBlock； @ref: HBase高性能随机查询之道 – HFile原理解析-云社区-华为云 HBase – 存储文件HFile结构解析 – 有态度的HBase/Spark/BigData HBase – 探索HFile索引机制 – 有态度的HBase/Spark/BigData Minor/Major Compaction Minor Compaction： HBase 会自动合并一些小的 HFile，重写成少量且更大的 HFiles。这个过程被称为 Minor Compaction。它使用归并排序算法，将小文件合并成大文件，有效减少 HFile 的数量。 Major Compaction ：合并每个 Column Family 下的所有的 HFiles，生成一个大的 HFile，在这个过程中，被删除的和过期的 cell 会被真正删除。因为 major compaction 会重写所有的 HFile，会产生大量的硬盘 I/O 和网络开销。这被称为写放大（Write Amplification）。 默认情况下 Minor Compaction 也会删除数据，但只是删除合并 HFile 中的 TTL 过期数据。Major Compaction 是完全删除无效数据，包括被删除的数据、TTL 过期数据以及版本号过大的数据。 下图直观描述了 Flush 与 Minor &amp; Major Compaction 流程：Region 级别的 Memstore flush 触发会触发 Minor Compaction 条件检查，符合条件则进行小合并，Minor Compaction 还可能触发 Major Compaction Minor Compaction 的检查条件有三种：MemStore Flush、后台线程周期性检查、手动触发； MemStore flush：MemStore 的 size 达到一定阈值或其他条件时就会触发 flush 刷写到磁盘生成 HFile 文件， HFile 文件越来越多则触发 compact。HBase 每次 flush 之后，都会判断是否要进行 compaction，一旦满足 minor compaction 或 major compaction 的条件便会触发执行。 后台线程周期性检查： 后台线程 CompactionChecker 会定期检查是否需要执行 compaction，检查周期为 hbase.server.thread.wakefrequency*hbase.server.compactchecker.interval.multiplier，这里主要考虑的是一段时间内没有写入请求仍然需要做 compact 检查。其中参数 hbase.server.thread.wakefrequency 默认值 10000 即 10s，是 HBase 服务端线程唤醒时间间隔，用于 log roller、memstore flusher 等操作周期性检查；参数 hbase.server.compactchecker.interval.multiplier 默认值1000，是 compaction 操作周期性检查乘数因子。10 * 1000 s 时间上约等于2小时46分钟。 手动触发：是指通过 HBase Shell、Master Web UI 或者 HBase API 等任一种方式执行 compact、major_compact 等命令。 触发 Minor Compaction 检查后，会根据下列参数决定哪些文件进入候选队列： hbase.hstore.compaction.min：一次 minor compaction 最少合并的 HFile 数量，默认值 3。表示至少有3个符合条件的 HFile，minor compaction 才会启动。一般情况下不建议调整该参数。 hbase.hstore.compaction.max：一次 minor compaction 最多合并的 HFile 数量，默认值 10。这个参数也是控制着一次压缩的时间。一般情况下不建议调整该参数。调大该值意味着一次 compaction 将会合并更多的 HFile，压缩时间将会延长。 hbase.hstore.compaction.min.size：文件大小 ＜ 该参数值的 HFile 一定是适合进行 minor compaction 文件，默认值 128M（memstore flush size）。意味着小于该大小的 HFile 将会自动加入（automatic include）压缩队列。一般情况下不建议调整该参数。 hbase.hstore.compaction.max.size：文件大小 ＞ 该参数值的 HFile 将会被排除，不会加入 minor compaction，默认值 Long.MAX_VALUE，表示没有限制。一般情况下也不建议调整该参数。 hbase.hstore.compaction.ratio：这个 ratio 参数的作用是判断文件大小 ＞ hbase.hstore.compaction.min.size 的 HFile 是否也是适合进行 minor compaction 的，默认值1.2。 Major Compaction 是 Minor Compaction 升级而来的，检查周期同 Minor，Minor 首先对 HFile 进行筛选，是否进入候选队列，接下来会再判断是否满足 major compaction 条件，满足一条即进行 Major Compact： 用户强制执行 major compaction 长时间没有进行 compact（见下面 hbase.hregion.majorcompaction 解析）且候选文件数小于 hbase.hstore.compaction.max（默认10） Store 中含有 Reference 文件，Reference 文件是 split region 产生的临时文件，只是简单的引用文件，一般必须在 compact 过程中删除 如何判断“长时间没有进行 compact” ？ 两次 major compactions 间隔 ＞ majorcompaction x majorcompaction.jitter： hbase.hregion.majorcompaction：major Compaction 发生的周期，单位是毫秒，默认值是7天。 hbase.hregion.majorcompaction.jitter ：0~1.0的一个指数。调整这个参数可以让 Major Compaction 的发生时间更灵活，默认值是0.5。 这个参数是为了避免 major compaction 同时在各个 regionserver 上同时发生，避免此操作给集群带来很大压力。这样节点 major compaction 就会在 + 或 - 两者乘积的时间范围内随机发生。 @TLDR：Minor &amp; Major Compaction、Region split 检查周期、触发条件- Minor 检查的触发：Memstore flush（默认64M）会触发 minor compact 检查，此外 CompactionChecker 线程也会定期检查（≈ 2小时）- Minor 条件：根据 HFile 的大小决定是否进入 compact 队列，候选文件数过多则触发 minor compact；- Major 一般由 Minor 触发：如果此次 minor compact 进入候选文件数 ＜ `hbase.hstore.compaction.max` ，且距上次 major compact 足够的时间间隔（≈7day），则触发 major compact；- Region split：Region 中的 store 大小，超过阈值 `hbase.hregion.max.filesize`，切分对象是整个 region； 因为 Major Compaction 存在 write amplification 的问题，所以 major compaction 一般都手动执行，安排在写入量的低峰期（例如周末和半夜）。Major compaction 还能将因为 RegionServer crash 或者 Balance 导致的数据迁移重新移回到与 RegionServer 相同的节点，这样就能恢复 data locality。 LSM树读写放大问题及KV分离技术解析_InfoQ写作社区 LSM 树的读放大主要来源于读操作需要从 C0~Ck（自顶向下）一层一层查找，直到找到目标数据。这个过程可能需要不止一次 I/O，特别是对于范围查询，读放大非常明显。 采用 LSM 树思想的 KV 数据库的实现中，通常需要启用后台线程周期检查或者手动 flush 等方式触发 Compaction 来减少读放大（减少 SSTable 文件数量）和空间放大（清理过期数据），但也因此带来了严重的写放大问题。 查询流程 （1）查询 meta 表：Client 发送请求给 Zk, 获取 hbase:meta 表在哪个 RegionServer，hbase:meta 存储了每个表在每个 Region 上的 start/end Key， Client 向该 RegionServer 发送请求, 查询 meta 表, 获取 Key 在哪个 Region 上, 同时也确定了 RegionServer 查询 hbase:meta 表的步骤可以在 Client 本地进行缓存, 不必每次都去查 Zk； （2）从 RegionServer 进行合并读： 尝试从 BlockCache 查询（最近读取的 KeyValue 都被缓存在这里，这是 一个 LRU 缓存） 尝试从 MemStore 查询（即写缓存，包含了最近更新的数据） 从 StoreFile（HFile） 查询： 尝试从内存中已加载的 Data Block 索引 和 布隆过滤器 中查询 找到 Rowkey 对应的 Cell 每个列族的 MemStore 可能对应多个 HFile，所以一次查询可能会需要读取多个 HFile，这被称为读放大（read amplification），尤其是不满足 data locality 时（Region Server 和 HFile 在不同的节点），读放大带来的影响会更严重 @ref： HBase原理－数据读取流程解析 – 有态度的HBase/Spark/BigData HBase原理－迟到的‘数据读取流程’部分细节 – 有态度的HBase/Spark/BigData HBase – 探索HFile索引机制 – 有态度的HBase/Spark/BigData 写入流程 （1）Region Server 定位过程与度读流程类似； （2）put 请求到 Region Server ，数据被写入 WAL 后，会被加入到 MemStore 即写缓存。然后服务端就可以向客户端返回 ack 表示写数据完成。 每个 RegionServer 一般只有一个 WAL，不同子表、不同列族的数据都被写入这一个 WAL, 同时 WAL 中每个最小单元都有唯一递增的seqId @ref: [[#HLog (WAL)]] 每个 Column Family 都有一个 MemStore，不同的列族被写入其对应的 MemStore，在 MemStore 中按 KeyValue 进行排序（见MemStore）； 当某个 Column Family 的 MemStore 中，累积了足够多的的数据后，整个有序数据集就会被写入一个新的 HFile 文件到 HDFS； 当 HFile 越来越多，会触发 Compact 合并操作，把过多的 HFile 合并成一个大的 HFile; 当 Region 越来越大，达到阈值后，还会触发 Split； @ref: 一条数据的HBase之旅，简明HBase入门教程-Write全流程-云社区-华为云 高可用 &amp; 宕机恢复HBase 的高可用是通过 Zookeeper 实现，见「Zookeeper」一节： Master 的宕机发现 &amp; 选主； Region Server 宕机发现； HDFS 的多副本机制保证 HFile 在不同的 Region Server 上存在冗余副本； Region Server 宕机恢复： Region Server 因某些原因宕机，与 Zk 失去心跳，超时后临时节点被移除； HMaster 检测到 Region Server 临时节点被移除，开始执行宕机恢复，切分 Region Server 的 HLog（WAL），分发给其他 Region Server 进行回放。HFile 中保存了该 File 中最大的 seqId，所以只需要找到宕机 RS 上 HFile 最大的 seqId，回放大于该 seqId 的日志记录； HLog 的切分和回放，有如下几种策略，LogSplitting、Distributed Log Splitting、Distributed Log Replay （1）LogSplitting 策略，HLog 的切分和落盘完全由 HMaster 完成： HMaster 启动一个读线程依次顺序读出每个 HLog 中所有 &lt;HLogKey,WALEdit&gt; 数据对，根据 HLogKey 中包含的 Region 字段，将不同的 Region 数据写入不同的内存 buffer 中，HLog 一节已经介绍过，HLog 文件可以有多个，且当前所有 Region 子表的写入，都落到一个 HLog 文件中； HMaster 为每个 buffer 会对应启动一个写线程，负责将 buffer 中的数据写入 hdfs 中，每个 hdfs 文件对应一个 Region（子表），然后把 hdfs 文件分配给存活的 Region Server 进行回放； 这种日志切分可以完成最基本的任务，但是只有 HMaster 进行 HLog 的切分和落盘，在某些场景下（集群整体宕机）进行恢复可能需要 N 个小时！也因为恢复效率太差，所以开发了 Distributed Log Splitting 策略 （2）Distributed Log Splitting 策略，利用了所有 Region Server 的算力对 HLog 进行切分，效率更高 Master 会将待切分日志路径发布到 Zookeeper 节点上（/hbase/splitWAL），每个日志作为一个任务，每个任务都会有对应状态，起始状态为 TASK_UNASSIGNED； 所有 RegionServer 启动之后都注册在这个节点上等待新任务，一旦 Master 发布任务之后，RegionServer 就会抢占该任务； RegionServer 抢占任务成功之后，会分发给 hlogsplitter 线程切分处理，切分策略同上，也是将 HLog 中的数据按 Region 分类，写入不同的 hdfs 文件中； Region Server 被分配到不同的 hdfs 文件（对应不同的 Region）,进行回放； Distributed Log Splitting 策略利用 RS 的算力加快故障恢复进程，可以将故障恢复时间降到分钟级别。但会产生很多小文件。小文件数量 = HLog 文件数量 x 宕机 RS 上 Region 个数，例如一台 region server 上有200个 region，90个 hlog 文件。恢复过程会在 hdfs 上创建18000个小文件。 （3）Distributed Log Replay: 在（2）文件的写入，而是读取出数据后直接进行回放 @doubt 遗留问题： 宕机恢复过程中，meta 表如何更新？ Distributed Log Replay 策略中，RS 抢到某个 HLog 的切分任务，切分后并没有落盘，那么这个 RS 要独自承担这个 HLog 文件中所有 region 的回放？ @ref： HBase原理－RegionServer宕机数据恢复 – 有态度的HBase/Spark/BigData HBase宕机恢复 - 个人文章 - SegmentFault 思否 Region 拆分HBase 中，一张表由多个子表(regions)组成，这些 regions 分布在多个 Region Server 上面，如果一个表有多个列族，那么每个 region 还分为多个 store，每个 store 对应一个列族。 一旦 Region 的负载过大或者超过阈值时，它就会被分裂成两个新的 Region。Region 的拆分分为自动拆分和手动拆分。自动拆分可以采用不同的策略。 Region 的拆分过程是由 Region Server 完成的，其拆分流程如下： 将需要拆分的 Region 下线，客户端对该 Region 的请求会被拒绝，Master 会检测到 Region 的状态为 SPLITTING； 开始拆分 Region，原 Region 被均分为2个子 Region； 完成子 Region 创建后，向 Meta 表发送新产生的 Region 的元数据信息； 将 Region 的拆分信息更新到 HMaster，并且每个 Region 进入可用状态； @doubt： 拆分后的子 Region ，还是在原来的 RS 上提供服务，拆分并不能起到降低 RS 负载的作用？ Region 的 自动拆分主要根据拆分策略进行，Region 的拆分逻辑是通过 CompactSplitThread 线程的 requestSplit 方法来触发的，每当执行 Memstore Flush 操作时都会调用该方法进行判断，看是否有必要对目标 Region 进行拆分。 ➤ 自动拆分的触发有三种策略： ConstantSizeRegionSplitPolicy：在0.94之前只有这个策略。当 region 中的一个 store（对应一个 columnfamily 的一个 storefile）超过了配置参数 hbase.hregion.max.filesize 时拆分成两个，该配置参数默认为10GB。region 拆分线是最大 storefile 的中间 rowkey。从字面意思来看，当 region 大小大于某个阈值（hbase.hregion.max.filesize）之后就会触发切分，实际上并不是这样，真正实现中这个阈值是对于某个 store （列族）来说的，即一个 region 最大的 store 的大小 大于设置阈值之后才会触发切分。 该策略不是很灵活，如果参数设置的过大，对于写入量大的表可能会触发拆分，但小表在极端情形下，可能永远都无法达到这个阈值 IncreasingToUpperBoundRegionSplitPolicy 0.94版本~2.0版本默认切分策略。总体来看和 ConstantSizeRegionSplitPolicy 思路相同，一个 region 中最大 store 大小大于设置阈值就会触发切分。但是这个阈值并不是固定值，而是会在一定条件下不断调整，调整规则和 region 所属表在当前 regionserver 上的 region 个数有关系. 当然阈值并不会无限增大，最大值为用户设置的 MaxRegionFileSize。 SteppingSplitPolicy: 2.0版本默认切分策略。这种切分策略的切分阈值又发生了变化，相比 IncreasingToUpperBoundRegionSplitPolicy 简单了一些，依然和待分裂 region 所属表在当前 regionserver 上的 region 个数有关系，如果 region 个数等于1，切分阈值为 flush size x 2，否则为 MaxRegionFileSize。 这种切分策略对于大集群中的大表、小表会比 IncreasingToUpperBoundRegionSplitPolicy 更加友好，小表不会再产生大量的小 region，而是适可而止。 ➤ 手动拆分： split &apos;regionName&apos; # format: &apos;tableName,startKey,id&apos; @ref: HBase原理 – 所有Region切分的细节都在这里了 – 有态度的HBase/Spark/BigData Region 合并目前只有手动合并，当删除大量数据后，HBase 中会存在数量很多的小 Region，MemStore 的数量也会变多，数据频繁从内存 Flush 到 HFile，影响用户请求，可能阻塞该 Region 服务器上的更新操作。 合并过程 客户端发起 Region 合并处理，并发送 Region 合并请求给 Master。 Master 在 Region 服务器上把 Region 移到一起，并发起一个 Region 合并操作的请求。 Region 服务器将准备合并的 Region下线，然后进行合并。 从 Meta 表删除被合并的 Region 元数据，新的合并了的 Region 的元数据被更新写入 Meta 表中。 合并的 Region 被设置为上线状态并接受访问，同时更新 Region 信息到 Master。 Region 负载均衡当 Region 进行拆分之后，Region Server 之间可能会出现 Region 数量 不均衡的问题，Master 便会执行负载均衡来调整部分 Region 的位置，使每个 Region 服务器的 Region 数量保持在合理范围之内，负载均衡会引起 Region 的重新定位，使涉及的 Region 不具备数据本地性。 Region 的负载均衡由 Master 来完成，Master 有一个内置的负载均衡器，在默认情况下，均衡器每 5 分钟运行一次，用户可以配置。负载均衡操作分为两步进行：首先生成负载均衡计划表， 然后按照计划表执行 Region 的分配。 执行负载均衡前要明确，在以下几种情况时，Master 是不会执行负载均衡的。 均衡负载开关关闭。 Master 没有初始化。 当前有 Region 处于拆分状态。 当前集群中有 Region 服务器出现故障。 Master 内部使用一套集群负载评分的算法，来评估 HBase 某一个表的 Region 是否需要进行重新分配。这套算法分别从 Region 服务器中 Region 的数目、表的 Region 数、MenStore 大小、 StoreFile 大小、数据本地性等几个维度来对集群进行评分，评分越低代表集群的负载越合理。 确定需要负载均衡后，再根据不同策略选择 Region 进行分配，负载均衡策略有三种，如下表所示。 策略 原理 RandomRegionPicker 随机选出两个 Region 服务器下的 Region 进行交换 LoadPicker 获取 Region 数目最多或最少的两个 Region 服务器，使两个 Region 服务器最终的 Region 数目更加平均 LocalityBasedPicker 选择本地性最强的 Region 根据上述策略选择分配 Region 后再继续对整个表的所有 Region 进行评分，如果依然未达到标准，循环执行上述操作直至整个集群达到负载均衡的状态。","categories":[{"name":"32.Database","slug":"32-Database","permalink":"https://beefyheisenberg.github.io/categories/32-Database/"}],"tags":[]},{"title":"HBase-02运维和部署","slug":"32.Database/HBase-02运维和部署","date":"2024-01-24T01:27:52.803Z","updated":"2024-01-24T01:27:52.804Z","comments":true,"path":"32.Database/HBase-02运维和部署/","link":"","permalink":"https://beefyheisenberg.github.io/32.Database/HBase-02运维和部署/","excerpt":"安装 &amp; 部署为了保证 Region Server 读写性能，需要和 HDFS 的 NameNode 部署在同一台机器上，实现数据的本地性 Hadoop &amp; HBase Hadoop集群: 1x NameNode, 2x DataNode, 共7T HBase集群: 1x Master, 2x RegionServer 服务分布情况: ip6 : hbase master, hadoop name_node, Zookeeper ip7 : hbase region ip8 : hbase region hadoopssh ip6, 执行:","text":"安装 &amp; 部署为了保证 Region Server 读写性能，需要和 HDFS 的 NameNode 部署在同一台机器上，实现数据的本地性 Hadoop &amp; HBase Hadoop集群: 1x NameNode, 2x DataNode, 共7T HBase集群: 1x Master, 2x RegionServer 服务分布情况: ip6 : hbase master, hadoop name_node, Zookeeper ip7 : hbase region ip8 : hbase region hadoopssh ip6, 执行: cd /data1 &amp;&amp; mkdir -p hadoop/tmp &amp;&amp; mkdir -p hadoop/hdf/data &amp;&amp; mkdir -p hadoop/hdf/name 编辑 /etc/profile: export HADOOP_HOME=/data0/hadoop-2.8.3export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATHexport HADOOP_LOG_DIR=$HADOOP_HOME/logsexport YARN_LOG_DIR=$HADOOP_LOG_DIR 并执行 source /etc/profile 停止: cd /data0/hbase-1.3.2/bin &amp;&amp; sh stop-hbase.shcd /data0/hadoop-2.8.3/sbin &amp;&amp; sh stop-dfs.sh &amp;&amp; sh stop-yarn.sh 启动: cd /data0/hadoop-2.8.3/sbin &amp;&amp; start-dfs.sh &amp;&amp; start-yarn.shcd /data0/hbase-1.3.2/bin &amp;&amp; start-hbase.sh zktouch /data1/zookeeper/myid &amp;&amp; echo 1 &gt; /data1/zookeeper/myid/data0/zookeeper-3.4.12/bin/zkServer.sh start 性能优化① Server端优化: JVM 内存优化: export HBASE_REGIONSERVER_OPT=&quot;-Xmx8g -Xms8g -Xmn128m -XX:+UseParNewGC -XX:UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -verbose:gc -XX:+printGCDetails -XX:+PrintGCTimeStamps -Xloggc:${HBASE_HOME}/logs/gc-${hostname}-hbase.log&quot; 使用压缩: GZIP, LZO, Zippy/Snappy, 创建表的时候指定列族的压缩格式：create &#39;testtable&#39;,{NAME =&gt; &#39;colfam1&#39;,COMPRESSION =&gt; &#39;GZ&#39;} 预分 Region: 在建表的时候预先创建多个 Region, 并规定好每个 Region 存储的 Rowkey 范围, 通过对数据的特性进行分析预先创建分区可以有效的解决 HBase 中的数据倾斜问题 @ref: HBase-03架构和原理 防止拆分风暴: Hbase 自动处理 region 拆分，一旦达到阀值 region 将会拆分成两个。当用户的 region 大小以恒定的速度保持增长时，region 拆分会在同一时间发生，因为同时需要压缩 region 中的存储文件，这个过程或重写拆分后的 region，导致磁盘 IO 上升。这种情况被称为拆分风暴 如何防止：与其依赖 HBase 的自动拆分，还不如手动使用 split 和 major_compact 命令来管理，因为手动管理的话可以将这些 region 的拆分/ HFile 的合并时机分割开来，尽量分散 IO 负载。可以设置 hbase.hregion.max.filesize 为非常大，避免触发自动拆分的阈值。 region 热点问题: 通过合理设计 row key 解决; @ref: HBase-04行键设计 ② 客户端API优化: 禁用自动刷写 Table.setAutoFlush(false) 最佳实践-集群规划 一个 HBase 集群上，如果给多个业务方使用，如何做业务之间的隔离？ 共享情况下如何使得系统资源利用率最高，理想情况下当然希望集群中所有软硬件资源都得到最大程度利用。 使得集群系统资源最大化利用，那首先要看业务对系统资源的需求情况。经过对线上业务的梳理，通常可将这些业务分为如下几类： 硬盘容量敏感型业务：这类业务对读写延迟以及吞吐量都没有很大的要求，唯一的需要就是硬盘容量。比如大多数离线读写分析业务，上层应用一般每隔一段时间批量写入大量数据，然后读取也是定期批量读取大量数据。特点：离线写、离线读，需求硬盘容量 带宽敏感型业务：这类业务大多数写入吞吐量很大，但对读取吞吐量没有什么要求。比如日志实时存储业务，上层应用通过kafka将海量日志实时传输过来，要求能够实时写入，而读取场景一般是离线分析或者在上次业务遇到异常的时候对日志进行检索。特点：在线写、离线读，需求带宽 IO 敏感型业务：相比前面两类业务来说，IO 敏感型业务一般都是较为核心的业务。这类业务对读写延迟要求较高，尤其对于读取延迟通常在100ms 以内，部分业务可能要求更高。比如在线消息存储系统、历史订单系统、实时推荐系统等。特点：在（离）线写、在线读，需求内存、高 IOPS 介质 每个季度公司都会要求采购新机器，一般情况下机器的规格（硬盘总容量、内存大小、CPU规格）都是固定的。假如现在一台RegionServer的硬盘规格是3.6T x 12，总内存大小为128G，从理论上来说这样的配置是否会有资源浪费？如果有的话是硬盘浪费还是内存浪费？那合理的硬盘/内存搭配应该是什么样？ 这里需要提出一个 Disk / Java Heap Ratio 的概念，即一台 RegionServer “磁盘容量 / JVM 内存” 的比值，这个比值多少最合理？ 在给出合理的解释在前，先把结果给出来： Disk Size / Java Heap = RegionSize / (MemstoreSize * ReplicationFactor * HeapFractionForMemstore * 2) 按照默认配置:RegionSize = 10G，对应参数为 hbase.hregion.max.filesize；MemstoreSize = 128M，对应参数为 hbase.hregion.memstore.flush.size；ReplicationFactor = 3，对应参数为 dfs.replication；HeapFractionForMemstore = 0.4，对应参数为 hbase.regionserver.global.memstore.lowerLimit； 计算为：10G / 128M * 3 * 0.4 * 2 = 192，意思是说一台 RegionServer 上1bytes 的 Java 内存大小需要搭配192bytes 的硬盘大小最合理，再回到之前给出的问题，128G 的内存总大小，拿出96G 作为 Java 内存用于 RegionServer，那对应需要搭配 96G ＊ 192 = 18T 硬盘容量，而实际采购机器配置的是36T，说明在默认配置条件下会有几乎一半硬盘被浪费。 @ref: HBase最佳实践－集群规划 – 有态度的HBase/Spark/BigData 最佳实践-内存规划@ref： HBase最佳实践－内存规划 – 有态度的HBase/Spark/BigData 最佳实践-读性能优化HBase最佳实践－读性能优化策略 – 有态度的HBase/Spark/BigData 最佳实践-写性能优化 是否需要 WAL？ WAL 是否需要同步写入？ Put 批量提交 Region 写入负载是否均衡 Key 大小 HBase最佳实践－写性能优化策略 – 有态度的HBase/Spark/BigData","categories":[{"name":"32.Database","slug":"32-Database","permalink":"https://beefyheisenberg.github.io/categories/32-Database/"}],"tags":[]},{"title":"HBase-02API简介","slug":"32.Database/HBase-02API简介","date":"2024-01-24T01:27:52.797Z","updated":"2024-01-24T01:27:52.798Z","comments":true,"path":"32.Database/HBase-02API简介/","link":"","permalink":"https://beefyheisenberg.github.io/32.Database/HBase-02API简介/","excerpt":"客户端API: 基础包括hbase shell命令行 和Java API 命令行 hbase shell: 进入 hbase shell, 然后可以用以下的 hbase 命令行 help &#39;list&#39; : 查看帮助 status : 查看状态 表级命令： list : list all table create &#39;table1&#39;,&#39;col_family1&#39;,&#39;col_family2&#39; : 创建表, 并包含两个列族 alter &#39;table1&#39;, NAME =&gt; &#39;col_family1&#39;, TTL =&gt; &#39;604800&#39; : 修改列族的TTL(秒) describe &#39;table1&#39; : 查看表描述 deleteall &#39;table1&#39;, &#39;rowkey1&#39;, &#39;column&#39; : 删除该行键下”column”列的数据 deleteall &#39;table1&#39;, &#39;rowkey1&#39; : 删除所有该行键下的数据 truncate &#39;table1&#39; 清空表 disable &#39;table1&#39; 然后 drop &#39;table1&#39; : 删除表 count &#39;table1&#39; : 统计表的行数 基本查询 &amp; 删除： put &#39;table1&#39;, &#39;rowkey1&#39;, &#39;col_family1:col111&#39;, &#39;value&#39; : 插入一条数据, 格式为put 表名, 行键, 列族:列, 值 get &#39;table1&#39;, &#39;rowkey1&#39; : 查询记录, 格式为get 表名, 行键 get &#39;table1&#39;, &#39;rowkey1&#39;, &#39;col_family1:col111&#39; : 查询记录, 格式为get 表名, 行键, 列族:列 get &#39;table1&#39;, &#39;rowkey1&#39;, { COLUMN =&gt; &#39;col_family1:col111&#39;, VERSIONS=&gt;1}: 查询记录, 格式为get 表名, 行键, {条件}, 其中COLUMN和VERSIONS是预定义的, 分别表示列和版本号 扫描： scan &#39;table1&#39; , {&#39;LIMIT&#39; =&gt; 5} : 扫描一个表, {&#39;LIMIT&#39; =&gt; 5}是可选的 scan &#39;table1&#39;, {COLUMNS =&gt; &#39;fam:col&#39;, STARTROW =&gt; &#39;executed|1530226272&#39;, STOPROW =&gt; &#39;executed|1530233472&#39;} : 带条件的扫描 scan &#39;hbase:meta&#39; 扫描 hbase:meta 表, 旧的HBase版本里该表叫: .META. scan &#39;hbase:meta&#39;, {COLUMNS =&gt; &#39;info:regioninfo&#39;} 参考 # META表 Java API","text":"客户端API: 基础包括hbase shell命令行 和Java API 命令行 hbase shell: 进入 hbase shell, 然后可以用以下的 hbase 命令行 help &#39;list&#39; : 查看帮助 status : 查看状态 表级命令： list : list all table create &#39;table1&#39;,&#39;col_family1&#39;,&#39;col_family2&#39; : 创建表, 并包含两个列族 alter &#39;table1&#39;, NAME =&gt; &#39;col_family1&#39;, TTL =&gt; &#39;604800&#39; : 修改列族的TTL(秒) describe &#39;table1&#39; : 查看表描述 deleteall &#39;table1&#39;, &#39;rowkey1&#39;, &#39;column&#39; : 删除该行键下”column”列的数据 deleteall &#39;table1&#39;, &#39;rowkey1&#39; : 删除所有该行键下的数据 truncate &#39;table1&#39; 清空表 disable &#39;table1&#39; 然后 drop &#39;table1&#39; : 删除表 count &#39;table1&#39; : 统计表的行数 基本查询 &amp; 删除： put &#39;table1&#39;, &#39;rowkey1&#39;, &#39;col_family1:col111&#39;, &#39;value&#39; : 插入一条数据, 格式为put 表名, 行键, 列族:列, 值 get &#39;table1&#39;, &#39;rowkey1&#39; : 查询记录, 格式为get 表名, 行键 get &#39;table1&#39;, &#39;rowkey1&#39;, &#39;col_family1:col111&#39; : 查询记录, 格式为get 表名, 行键, 列族:列 get &#39;table1&#39;, &#39;rowkey1&#39;, { COLUMN =&gt; &#39;col_family1:col111&#39;, VERSIONS=&gt;1}: 查询记录, 格式为get 表名, 行键, {条件}, 其中COLUMN和VERSIONS是预定义的, 分别表示列和版本号 扫描： scan &#39;table1&#39; , {&#39;LIMIT&#39; =&gt; 5} : 扫描一个表, {&#39;LIMIT&#39; =&gt; 5}是可选的 scan &#39;table1&#39;, {COLUMNS =&gt; &#39;fam:col&#39;, STARTROW =&gt; &#39;executed|1530226272&#39;, STOPROW =&gt; &#39;executed|1530233472&#39;} : 带条件的扫描 scan &#39;hbase:meta&#39; 扫描 hbase:meta 表, 旧的HBase版本里该表叫: .META. scan &#39;hbase:meta&#39;, {COLUMNS =&gt; &#39;info:regioninfo&#39;} 参考 # META表 Java API增删：get &amp; putConfiguration conf = HBaseConfiguration.create();HTable table = new HTable(conf,\"test_table\");// Instantiating Put by rowkeyPut p = new Put(Bytes.toBytes(\"row1\"));// family name, qualifier ,valuep.add(Bytes.toBytes(\"personal\"), Bytes.toBytes(\"name\"),Bytes.toBytes(\"raju\"));// Write the datatable.put(p);// Instantiating Get by rowkeyGet g = new Get(Bytes.toBytes(\"row1\"));// Reading the dataResult result = table.get(g);// Reading values from Resultbyte [] value = result.getValue(Bytes.toBytes(\"personal\"),Bytes.toBytes(\"name\"));System.out.println(\"personal.name=\" + Bytes.toString(value))table.close(); 扫描：scanScan 属于不稳定接口，如扫描范围过大或设置不准会导致性能下降，使用时强烈建议设置 startKey 与 endKey，同时 start 与 end 之间不要超过100条数据。 Scan scan = new Scan();scan.setLimit(10)// Set start &amp; stop Rowkey If Need//scan.setStartRow(startRow); //scan.setStopRow(stopRow);// Scanning the required columnsscan.addColumn(Bytes.toBytes(\"personal\"), Bytes.toBytes(\"name\"));scan.addColumn(Bytes.toBytes(\"personal\"), Bytes.toBytes(\"city\"));// Getting the scan resultResultScanner scanner = table.getScanner(scan);// Reading values from scan resultfor (Result result = scanner.next(); result != null; result = scanner.next()) System.out.println(\"Found row : \" + result);// Closing the scannerscanner.close(); ➤ scan 的 setCaching 与 setBatch 方法的区别: setCaching 设置的值为每次 rpc 的请求记录数，默认是1，设置更大的 cache 可以减少 RPC 次数来优化性能，但是一次传输的耗时也增加； setBatch 设置每次取的 column size；有些 row 特别大，所以需要分开传给 client，就是一次传一个 row 的几个 column。 batch 和 caching 和 hbase table column size 共同决定了 rpc 的次数。 @ref: https://blog.csdn.net/caoli98033/article/details/44650497 ➤ scan 的实现: HBase 已经迭代了多个版本，不保证 scan 的实现在每个版本都一样 for 循环中每次遍历 ResultScanner 对象获取一行记录，实际上在客户端层面都会调用一次 next 请求。next 请求整个流程可以分为如下几个步骤： next请求首先会检查客户端缓存中是否存在还没有读取的数据行，如果有就直接返回，否则需要将next请求给HBase服务器端（RegionServer）。 如果客户端缓存已经没有扫描结果，就会将next请求发送给HBase服务器端。默认情况下，一次next请求仅可以请求100行数据（或者返回结果集总大小不超过2M） 服务器端接收到 next 请求之后就开始从 BlockCache、HFile 以及 MemStore 中一行一行进行扫描，扫描的行数达到100行之后就返回给客户端，客户端将这100条数据缓存到内存并返回一条给上层业务。 上层业务不断一条一条获取扫描数据，在数据量大的情况下实际上 HBase 客户端会不断发送 next 请求到 HBase 服务器。 @ref: HBase最佳实践 – Scan用法大观园 – 有态度的HBase/Spark/BigData 批处理：bacth批量处理操作：可以批量处理跨多行的不同操作,许多基于列表的操作，如delete、get的列表操作都是基于batch 方法实现的. Configuration conf = HBaseConfiguration.create();HTable table = new HTable(conf,\"test_table\");List&lt;Row&gt; batch = new ArrayList&lt;&gt;();Put put = new Put(Bytes.toBytes(\"row_key1\"));put.addColumn(Bytes.toBytes(\"col_fam1\"), Bytes.toBytes(\"col_qual3\"), Bytes.toBytes(\"test_data3\"));batch.add(put);// 添加更多...Object[] results = new Object[batch.size()];try&#123; table.batch(batch, results);&#125;catch(Exception e)&#123; System.err.println(e);&#125;for(int i=0;i&lt;results.length;i++)&#123; System.out.println(\"result\"+\"[\"+i+\"]:\"+results[i]);&#125;table.close(); Table vs BufferedMutatorIn the new API, BufferedMutator is used.You could change Table t = connection.getTable(TableName.valueOf(&quot;foo&quot;)) to BufferedMutator t = connection.getBufferedMutator(TableName.valueOf(&quot;foo&quot;)). And then change t.put(p) to t.mutate(p) 行锁(RowLock)行锁在客户端 API 中仍然存在，但是不鼓励使用，因为管理不好会锁定整个 RegionServer. 客户端API: 高级特性过滤器(Filter)Get 和 Scan 实例可以用 filters 配置，以应用于 RegionServer.所有的过滤器都在服务端生效, 叫做”谓词下推”（ predicate push down）。这样可以保证过滤掉的数据不会被传送到客户端.过滤器在客户端被创建, 通过RPC传送到服务器端, 然后在服务器端执行. Hbase客户端api提供了几种过滤器: SingleColumnValueFilter : 列值过滤, 用于测试值的情况（相等，不等，范围） RegexStringComparator: 支持正则表达式的值比较 SubstringComparator: 用于检测一个子串是否存在于值中。大小写不敏感。 FamilyFilter: 用于过滤列族。 通常，在Scan中选择ColumnFamilie优于在过滤器中做。 QualifierFilter: 用于基于列名(即 Qualifier)过滤. ColumnPrefixFilter: 可基于列名(即Qualifier)前缀过滤。 RowFilter: 通常认为行选择时 Scan 采用 startRow/stopRow 方法比较好。然而 RowFilter 也可以用。 PageFilter：用于实现分页，它可以限制返回结果的最大行数。一旦达到该限制，过滤器就会停止扫描并返回结果。 下面是分页过滤器的一个例子: Scan scan = new Scan(); scan.setStartRow(Bytes.toBytes(startRowKey)); Filter pageFilter = new PageFilter(10); scan.setFilter(pageFilter);ResultScanner resultScanner = table.getScanner(scan); for (Result result : resultScanner) &#123; resultList.add(result); &#125; resultScanner.close(); 下面是列值过滤器的一个例子: SingleColumnValueFilter filter = new SingleColumnValueFilter( cf, column, CompareOp.EQUAL, Bytes.toBytes(\"my value\") );scan.setFilter(filter); 计数器(Increment)一种支持的数据类型，值得一提的是“计数器”(如, 具有原子递增能力的数值)。参考 HTable的 Increment .同步计数器在区域服务器中完成，不是客户端。 incr '&lt;table&gt;', '&lt;row&gt;', '&lt;column&gt;', |&lt;increment-value&gt;| 协处理器(Coprocessor)HBase 的协处理器是从 0.92.0 开始引入的，参见 HBASE-2000。它的实现灵感来源于 Jeff Dean 在 LADIS 2009 分享主题《Designs, Lessons and Advice fromBuilding LargeDistributed Systems》中关于 Google 的 BigTable 协处理器的分享。当时的 BigTable 协处理器具有以下功能： 每个表服务器的任意子表都可以运行代码； 客户端的高层调用接口； 跨多行的调用会自动拆分为多个并行化的 RPC 请求； 通过协处理器可以非常灵活的构建分布式服务模型，能够自动化扩展、负载均衡、应用请求路由等。 HBase 当然也想要一个这么好的功能，因为通过这个功能我们可以实现二级索引（secondary indexing）、复杂过滤（complex filtering） 比如谓词下推（push down predicates）以及访问控制等功能。虽然 HBase 协处理器受 BigTable 协处理器的启发，但在实现细节方面存在差异。HBase 为我们建立了一个框架，并提供类库和运行时环境，使得我们可以在 HBase RegionServer 和 Master 上运行用户自定义代码； 协处理器框架已经为我们提供了一些实现类，我们可以通过继承这些类来扩展自己的功能。这些类主要分为两大类，即 Observer 和 Endpoint。 Observer 和 RDMBS 的触发器很类似，在一些特定的事件发生时被执行。这些事件包括用户产生的事件，也包括服务器内部产生的事件。目前 HBase 内置实现的 Observer 主要有以下几个： WALObserver：提供控制 WAL 的钩子函数； MasterObserver：可以被用作管理或 DDL 类型的操作，这些是集群级的事件； RegionObserver：用户可以用这种处理器处理数据修改事件，它们与表的 Region 联系紧密； BulkLoadObserver：进行 BulkLoad 的操作之前或之后会触发这个钩子函数； RegionServerObserver ：RegionServer 上发生的一些操作可以触发一些这个钩子函数，这个是 RegionServer 级别的事件； EndpointObserver：每当用户调用 Endpoint 之前或之后会触发这个钩子，主要提供了一些回调方法。 Endpoint 和 RDMBS 的存储过程很类似，用户提供一些自定义代码，并在 HBase 服务器端执行，结果通过 RPC 返回给客户。比较常见的场景包括聚合操作（求和、计数等）。 使用协处理器 （1）编写协处理器代码，自定义的类继承一些框架类，例如 BaseRegionObserver （2）将项目打成 jar 包，上传到 HDFS （3）Hbase server 端加载 jar， hbase shell 执行 alter &#39;table1&#39;,METHOD =&gt; &#39;table_att&#39;,&#39;Coprocessor&#39;=&gt;&#39;hdfs://linux121:9000/processor/processor.jar|com.xx.hbase.processor.TestProcessor|1001|&#39;，其中1001是优先级，该数字越小，优先级越高。如果同一个钩子函数有多个协处理器实现，那么将按照优先级执行 执行完可使用 describe &#39;table1&#39; 命令查看，可以看到挂载的协处理器信息 (4) 使用协处理器：大部分协处理器可以自动触发执行，例如如果重写了 BaseRegionObserver.prePut，则在 put 之前触发 Example：加盐后数据如何 scan 为了避免写入热点，rowkey 加盐后会变成如 salt- 开头，同时对 Region 进行预分区，打散后的 rowkey 写入对应的 Region； 这时候如果要执行 scan，一种方法是在 client 端组装出多个 rowkey，Region 数量越多，需要组装的 Rowkey、并发发出的 RPC 请求也越多； 另一种方式就是使用协处理器的方式： 无需客户端组装加盐后的 Rowkey，客户端直接使用原始不带 salt 前缀的 Rowkey 进行 scan； scan 时，通过 HTable 的 coprocessorService 触发协处理器的代码，通过 env.getRegion().getRegionInfo().getStartKey() 可以拿到当前 Region 的 StartKey，生成 salt- 前缀，再与客户端传输过来的 StartKey 参数拼接，生成真正的 Rowkey； 客户端获取到每个 Region 返回的 Map results，再进行处理 @ref: HBase 协处理器入门及实战 批处理客户端HiveHive+HBase: 使用Hive读取Hbase中的数据。我们可以使用HQL语句在HBase表上进行查询、插入操作；甚至是进行Join和Union等复杂查询。此功能是从Hive 0.6.0开始引入的，详情可以参见HIVE-705。Hive与HBase整合的实现是利用两者本身对外的API接口互相进行通信，相互通信主要是依靠hive-hbase-handler-1.2.0.jar工具里面的类实现的。 参考: Hive和HBase整合用户指南 Apache Pig如果不满足Hvie提供的HQL查询, 还可以用Pig Latin脚本实现更复杂的MapReduce Job,Pig支持对Hbase表的读写, Hbase表中的”列”可以映射到Pig的元组 MapReduce与Hadoop MapReduce Java API的整合 参考: 使用MapReduce APIs读写HBase","categories":[{"name":"32.Database","slug":"32-Database","permalink":"https://beefyheisenberg.github.io/categories/32-Database/"}],"tags":[]},{"title":"HBase-00基础概念","slug":"32.Database/HBase-00基础概念","date":"2024-01-24T01:27:52.793Z","updated":"2024-01-24T01:27:52.793Z","comments":true,"path":"32.Database/HBase-00基础概念/","link":"","permalink":"https://beefyheisenberg.github.io/32.Database/HBase-00基础概念/","excerpt":"HBase是一个分布式的、面向列的开源数据库，该技术来源于 Fay Chang 所撰写的Google论文“Bigtable：一个结构化数据的分布式存储系统”。就像Bigtable利用了Google文件系统（File System）所提供的分布式数据存储一样，HBase在Hadoop之上提供了类似于Bigtable的能力。HBase是Apache的Hadoop项目的子项目。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。另一个不同的是HBase基于列的而不是基于行的模式。与FUJITSU Cliq等商用大数据产品不同，HBase是Google Bigtable的开源实现，类似Google Bigtable利用GFS作为其文件存储系统，HBase利用Hadoop HDFS作为其文件存储系统；Google运行MapReduce来处理Bigtable中的海量数据，HBase同样利用Hadoop MapReduce来处理HBase中的海量数据；Google Bigtable利用 Chubby作为协同服务，HBase利用Zookeeper作为对应。 HBase适用于简单数据写入（如“消息类”应用）和海量、结构简单数据的查询（如“详单类”应用），适合稀疏表； 作为大数据MapReduce的后台数据源，以支撑离线分析型应用； 基于HDFS分布式文件系统, 可扩展性+； Facebook的消息类应用，包括Messages、Chats、Emails和SMS系统，用的都是HBase； 使用场景： 对象存储：不少的头条类、新闻类的新闻、网页、图片存储在 HBase 之中，一些病毒公司的病毒库也是存储在 HBase 之中。 时序数据：HBase 之上有 OpenTSDB 模块，可以满足时序类场景的需求。 时空数据：不少车联网企业，数据都是存在 HBase 之中。 消息/订单：Facebook 用 HBase 存储在线消息，每天数据量近百亿，每月数据量250 ~ 300T， HBase 读写比基本在1:1，吞吐量150w qps。 Feeds 流：典型的应用如微信朋友圈。","text":"HBase是一个分布式的、面向列的开源数据库，该技术来源于 Fay Chang 所撰写的Google论文“Bigtable：一个结构化数据的分布式存储系统”。就像Bigtable利用了Google文件系统（File System）所提供的分布式数据存储一样，HBase在Hadoop之上提供了类似于Bigtable的能力。HBase是Apache的Hadoop项目的子项目。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。另一个不同的是HBase基于列的而不是基于行的模式。与FUJITSU Cliq等商用大数据产品不同，HBase是Google Bigtable的开源实现，类似Google Bigtable利用GFS作为其文件存储系统，HBase利用Hadoop HDFS作为其文件存储系统；Google运行MapReduce来处理Bigtable中的海量数据，HBase同样利用Hadoop MapReduce来处理HBase中的海量数据；Google Bigtable利用 Chubby作为协同服务，HBase利用Zookeeper作为对应。 HBase适用于简单数据写入（如“消息类”应用）和海量、结构简单数据的查询（如“详单类”应用），适合稀疏表； 作为大数据MapReduce的后台数据源，以支撑离线分析型应用； 基于HDFS分布式文件系统, 可扩展性+； Facebook的消息类应用，包括Messages、Chats、Emails和SMS系统，用的都是HBase； 使用场景： 对象存储：不少的头条类、新闻类的新闻、网页、图片存储在 HBase 之中，一些病毒公司的病毒库也是存储在 HBase 之中。 时序数据：HBase 之上有 OpenTSDB 模块，可以满足时序类场景的需求。 时空数据：不少车联网企业，数据都是存在 HBase 之中。 消息/订单：Facebook 用 HBase 存储在线消息，每天数据量近百亿，每月数据量250 ~ 300T， HBase 读写比基本在1:1，吞吐量150w qps。 Feeds 流：典型的应用如微信朋友圈。 概念: 表, 行, 列族, 列, 版本 行（Row）: HBase 中的一行包含一个行键和一个或多个与其相关的值的列。在存储行时，行按字母顺序排序。出于这个原因，行键的设计非常重要。目标是以相关行相互靠近的方式存储数据。常用的行键模式是网站域。如果你的行键是域名，则你可能应该将它们存储在相反的位置（org.apache.www，org.apache.mail，org.apache.jira）。这样，表中的所有 Apache 域都彼此靠近，而不是根据子域的第一个字母分布。 列（Column）: HBase 中的列由一个列族和一个列限定符组成，它们由:字符分隔。 列族（Column Family）: 出于性能原因，列族在物理上共同存在一组列和它们的值。在 HBase 中每个列族都有一组存储属性，例如其值是否应缓存在内存中，数据如何压缩或其行编码是如何编码的等等。表中的每一行都有相同的列族，但给定的行可能不会在给定的列族中存储任何内容。列族一旦确定后，就不能轻易修改，因为它会影响到 HBase 真实的物理存储结构，但是列族中的列标识(Column Qualifier)以及其对应的值可以动态增删。 列限定符（Column Qualifier）: 列限定符被添加到列族中，以提供给定数据段的索引。鉴于列族的content，列限定符可能是content:html，而另一个可能是content:pdf。虽然列族在创建表时是固定的，但列限定符是可变的，并且在行之间可能差别很大。 单元格（Cell） 单元格是行、列族和列限定符的组合，并且包含值和时间戳，它表示值的版本。 时间戳（Timestamp） 时间戳与每个值一起编写，并且是给定版本的值的标识符。默认情况下，时间戳表示写入数据时 RegionServer 上的时间，但可以在将数据放入单元格时指定不同的时间戳值。 概念视图 上面的数据有相同的Row key = “com.cnn.www”, 每行表示一个数据版本, 共有5个版本(Time Stamp表示),有两个列族 contents 和 anchor, 两个列族下分别有contents:html, anchor:cnnsi.com, anchor:my.look.ca三个列, 用json格式表示概念视图: &quot;com.cnn.www&quot;: [ // 行键 &quot;t9&quot; : &#123; // 版本=9 &quot;contents:html&quot; : &quot;&lt;html&gt;...&quot;, // 列1 : value &quot;anchor:cnnsi.com&quot; : &quot;CNN...&quot;, // 列2 : value &#125;, &quot;t8&quot; : &#123; // 版本=8 &quot;contents:html&quot; : &quot;&lt;html&gt;...&quot;, // 列1 : value &quot;anchor:cnnsi.com&quot; : &quot;CNN...&quot;, // 列2 : value &#125;] 物理视图物理存储是按照列族(family)分布的, 相同的列族在连续的物理空间存储. 如下图, 一张表里有不同的列族 CF1, CF2, 每个列族下面有自己的qualifier, 可以看到一张表的数据被按照列族分布在不同的物理位置。 TTLHBase的生存时间(TTL)是针对列族设置的, 一旦达到到期时间，HBase 将自动删除行。修改一个列族的TTL如下:disable 'table1' #先禁用表alter 'table1', &#123;NAME=&gt;'col_family1', TTL =&gt; '100'&#125; #指明修改哪个列族, 100的单位是秒enable 'table1' 从上面可以看到, TTL虽然是针对列族的参数, 但是给某个列族修改/增加TTL需要暂时disable表, 所以在生产环境里最好还是在建表的时候就给每个列族指定好TTL","categories":[{"name":"32.Database","slug":"32-Database","permalink":"https://beefyheisenberg.github.io/categories/32-Database/"}],"tags":[]},{"title":"DB.01-数据库分类 - OLTP、OLAP、TSDB","slug":"32.Database/DB.01-数据库分类","date":"2024-01-24T01:27:52.787Z","updated":"2024-01-24T01:27:52.788Z","comments":true,"path":"32.Database/DB.01-数据库分类/","link":"","permalink":"https://beefyheisenberg.github.io/32.Database/DB.01-数据库分类/","excerpt":"按存储模型分类按数据模型分类：关系型 &amp; 非关系型，后者又包括 KV 型、面向文档型、图数据库…… 一般来说，用NoSQL 作为“非关系型数据库”的泛称。 关系型（relational）：关系型数据库模型是把复杂的数据结构归结为简单的二元关系（即二维表格形式）。一般使用 B-Tree 作为索引；典型产品：MySQL、PostgreSQL、SQLite、SqlServer 非关系型（non-relational）： KV 存储：键值数据库将数据存储为键值对集合，其中键作为数据的唯一标识。可以使用哈希表、跳表等构建索引；典型产品：Redis、HBase 列存储数据库：列式存储(column-based)是相对于传统关系型数据库的行式存储(Row-basedstorage)来说的。我们知道，平时的查询大部分都是条件查询，通常是返回某些字段（列）的数据。对于行存储数据，数据读取时通常将一行数据完全读出，存在数据冗余，而列存储，每次读取的数据只是需要的部分，不存在冗余性问题。典型产品：HBase 面向文档数据库（document-based）：此类数据库存储的是文档（XML、JSON、BSON 等格式），这些文档具备可述性（self-describing），呈现分层的树状结构（hierarchical tree data structure）。一般使用倒排索引；典型产品：MongDB、ElasticSearch 图数据库（graph db）：存储图形关系的数据库。一般的图数据库至少包含图存储、图查询、图分析这三种功能，典型产品：Neo4J、InfoGrid等","text":"按存储模型分类按数据模型分类：关系型 &amp; 非关系型，后者又包括 KV 型、面向文档型、图数据库…… 一般来说，用NoSQL 作为“非关系型数据库”的泛称。 关系型（relational）：关系型数据库模型是把复杂的数据结构归结为简单的二元关系（即二维表格形式）。一般使用 B-Tree 作为索引；典型产品：MySQL、PostgreSQL、SQLite、SqlServer 非关系型（non-relational）： KV 存储：键值数据库将数据存储为键值对集合，其中键作为数据的唯一标识。可以使用哈希表、跳表等构建索引；典型产品：Redis、HBase 列存储数据库：列式存储(column-based)是相对于传统关系型数据库的行式存储(Row-basedstorage)来说的。我们知道，平时的查询大部分都是条件查询，通常是返回某些字段（列）的数据。对于行存储数据，数据读取时通常将一行数据完全读出，存在数据冗余，而列存储，每次读取的数据只是需要的部分，不存在冗余性问题。典型产品：HBase 面向文档数据库（document-based）：此类数据库存储的是文档（XML、JSON、BSON 等格式），这些文档具备可述性（self-describing），呈现分层的树状结构（hierarchical tree data structure）。一般使用倒排索引；典型产品：MongDB、ElasticSearch 图数据库（graph db）：存储图形关系的数据库。一般的图数据库至少包含图存储、图查询、图分析这三种功能，典型产品：Neo4J、InfoGrid等 OLTP vs OLAPOLTP(online transcation processing)联机事务处理: 多用来解决业务中的事务(ACID: 原子性,一致性,…)问题, 随机读写, 频繁的更改/删除; 不适合数据分析场景: 场景特点(数据量大), 分析和计算能力(OLTP没有, 只能查询到业务层再处理) // 关系型数据库, count/max/group by的实现? OLAP(online analytical processing)联机分析处理: OLAP不关数据的事务特性, 也不关注数据的频繁删改, 而是关注大量数据的多维度/复杂分析和计算 OLAP的分类: 多维度OLAP（Multi-Dimensional OLAP，简称MOLAP）:对数据需要分析的维度预先建模, 在数据存储的物理层面使用cube的结构进行存储(?) 缺点是数据需要预先建模, 优点比下面的关系型OLAP分析计算更快 关系型OLAP（Relational OLAP，简称ROLAP）:使用类似关系型数据库的存储模型(例如用label取代column), 使用类似SQL的语句进行分析查询, 分析计算更自由(相比多维度OLAP预先建模的方式), 但是海量数据下计分析算速度不如多维度OLAP TSDB(时序数据库)➤ 时序业务的特点： 持续产生海量数据的业务: 持续(每秒都产生,没有突增热点)和海量(每秒千万/亿条) 比如监控系统产生的日志 比如可穿戴设备+物联网设备产生的日志 几乎全都是写入, update/delete操作极少 近期数据价值更高, 久远的数据极少被访问, 所以数据以流式处理居多 没有关系型数据库的列, 一条数据不同维度的数据用标签区别, 可以以标签聚合查询(例如查询监控系统中,统计某API几天内访问量) ➤ TSDB 核心技术： 高吞吐写入能力: 系统具备水平扩展的能力； 单机具备高吞吐量，一般使用 LSM 架构实现； 数据分级存储/数据TTL: x小时内的使用内存, x天内使用SSD, 更久远的使用HDD, 或者根据TTL删除 多标签查询: 多使用位图索引 or 倒排索引 聚合查询: 预聚合 ➤ 常见 TSDB 产品： Influxdb：Influxdb是业界比较流行的一个时间序列数据库，特别是在IOT和监控领域十分常见。其使用go语言开发，突出特点是性能。特性： 自定义 TSM 引擎 简单，高性能的 HTTP 查询和写入 API SQL-like查询语言，简化查询和聚合操作 Opentsdb：一个基于 Hbase 的时间序列数据库（新版也支持 Cassandra）@link 在数据压缩上，时间戳采用 delta 编码进行压缩，数据值采用 XOR 进行压缩； 存储与计算解耦，为 IoT 场景海量数据、动态热点的数据特征量身打造，方便按照并发度和存储量按需独立扩容。采用分布式架构，支持横向水平扩展； 空间聚合，支持按照不同的 tag 进行空间聚合和分组计算。 Prometheus 是一个开源的服务监控系统和时间序列数据库。独立地开源监控系统和告警工具，广泛应用于 Kubernetes 生态 Elasticsearch 是一个分布式的开源搜索和分析引擎，适用于所有类型的数据，包括文本、数字、地理空间、结构化和非结构化数据。Elasticsearch 的时序优化可以参考文章: 《elasticsearch-as-a-time-series-data-store》 @ref: http://hbasefly.com/2017/11/19/timeseries-database-1/?rulkna=n0cfu1","categories":[{"name":"32.Database","slug":"32-Database","permalink":"https://beefyheisenberg.github.io/categories/32-Database/"}],"tags":[{"name":"OLTP","slug":"OLTP","permalink":"https://beefyheisenberg.github.io/tags/OLTP/"},{"name":"OLAP","slug":"OLAP","permalink":"https://beefyheisenberg.github.io/tags/OLAP/"},{"name":"TSDB","slug":"TSDB","permalink":"https://beefyheisenberg.github.io/tags/TSDB/"}]},{"title":"如何画架构图","slug":"31.Backend/如何画架构图","date":"2024-01-24T01:27:52.782Z","updated":"2024-01-24T01:27:52.782Z","comments":true,"path":"31.Backend/如何画架构图/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/如何画架构图/","excerpt":"图是给什么角色看的(客户 运维/实施 &amp; 开发), 即决定了用途, 要表达什么? 对方关注什么, 应该给对方看什么 组件(实体)是什么: 物理硬件、实际集群、中间件（服务）、业务服务 （考虑架构是基于SaaS or PasS平台？ 来决定图中的每个实体是什么） .. ➤ 逻辑视图1(业务向) ➤ 逻辑视图2(技术向)","text":"图是给什么角色看的(客户 运维/实施 &amp; 开发), 即决定了用途, 要表达什么? 对方关注什么, 应该给对方看什么 组件(实体)是什么: 物理硬件、实际集群、中间件（服务）、业务服务 （考虑架构是基于SaaS or PasS平台？ 来决定图中的每个实体是什么） .. ➤ 逻辑视图1(业务向) ➤ 逻辑视图2(技术向) ➤ 物理视图 运维 &amp; 实施 软件到硬件的映射关系 ➤ 时序图 ➤ 场景视图（业务） 非架构、更像业务流程图 参考 架构师必备技能：架构图的构图 – 酷 壳 – CoolShell 3F 如何画架构图？ - 知乎 程序员必知的七个图形工具 亚马逊AWS在线架构图软件 AWS简约图标","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"分布式系统-Consistency","slug":"31.Backend/分布式系统-Consistency","date":"2024-01-24T01:27:52.778Z","updated":"2024-01-24T01:27:52.778Z","comments":true,"path":"31.Backend/分布式系统-Consistency/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/分布式系统-Consistency/","excerpt":"➤ 分布式系统的一致性(概念)： 分布式系统中, 每个节点(或者副本)的数据保持一致; 「数据一致性其实是数据库系统中的概念。我们可以简单的把一致性理解为正确性或者完整性，那么数据一致性通常指关联数据之间的逻辑关系是否正确和完整」 ➤ 强一致性、弱一致性、最终一致性： 强一致性: 当更新操作完成之后，任何多个后续进程或者线程的访问都会返回最新的更新过的值。但是这种实现对性能影响较大，因为这意味着，只要上次的操作没有处理完，就不能让用户读取数据。 弱一致性: 系统并不保证进程或者线程的访问都会返回最新的更新过的值。系统在数据写入成功之后，不承诺立即可以读到最新写入的值，也不会具体的承诺多久之后可以读到。但会尽可能保证在某个时间级别（比如秒级别）之后，可以让数据达到一致性状态。 最终一致性: 弱一致性的特定形式。系统保证在没有后续更新的前提下，系统最终返回上一次更新操作的值。在没有故障发生的前提下，不一致窗口的时间主要受通信延迟，系统负载和复制副本的个数影响。DNS是一个典型的最终一致性系统。 最终一致性模型的变种: 因果一致性：如果A进程在更新之后向B进程通知更新的完成，那么B的访问操作将会返回更新的值。如果没有因果关系的C进程将会遵循最终一致性的规则。 读己所写一致性：因果一致性的特定形式。一个进程总可以读到自己更新的数据。 会话一致性：读己所写一致性的特定形式。进程在访问存储系统同一个会话内，系统保证该进程读己之所写。 单调读一致性：如果一个进程已经读取到一个特定值，那么该进程不会读取到该值以前的任何值。 单调写一致性：系统保证对同一个进程的写操作串行化。 @ref:","text":"➤ 分布式系统的一致性(概念)： 分布式系统中, 每个节点(或者副本)的数据保持一致; 「数据一致性其实是数据库系统中的概念。我们可以简单的把一致性理解为正确性或者完整性，那么数据一致性通常指关联数据之间的逻辑关系是否正确和完整」 ➤ 强一致性、弱一致性、最终一致性： 强一致性: 当更新操作完成之后，任何多个后续进程或者线程的访问都会返回最新的更新过的值。但是这种实现对性能影响较大，因为这意味着，只要上次的操作没有处理完，就不能让用户读取数据。 弱一致性: 系统并不保证进程或者线程的访问都会返回最新的更新过的值。系统在数据写入成功之后，不承诺立即可以读到最新写入的值，也不会具体的承诺多久之后可以读到。但会尽可能保证在某个时间级别（比如秒级别）之后，可以让数据达到一致性状态。 最终一致性: 弱一致性的特定形式。系统保证在没有后续更新的前提下，系统最终返回上一次更新操作的值。在没有故障发生的前提下，不一致窗口的时间主要受通信延迟，系统负载和复制副本的个数影响。DNS是一个典型的最终一致性系统。 最终一致性模型的变种: 因果一致性：如果A进程在更新之后向B进程通知更新的完成，那么B的访问操作将会返回更新的值。如果没有因果关系的C进程将会遵循最终一致性的规则。 读己所写一致性：因果一致性的特定形式。一个进程总可以读到自己更新的数据。 会话一致性：读己所写一致性的特定形式。进程在访问存储系统同一个会话内，系统保证该进程读己之所写。 单调读一致性：如果一个进程已经读取到一个特定值，那么该进程不会读取到该值以前的任何值。 单调写一致性：系统保证对同一个进程的写操作串行化。 @ref: 关于分布式一致性的探究-HollisChuang’s Blog","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"分布式系统-CAP理论","slug":"31.Backend/分布式系统-CAP理论","date":"2024-01-24T01:27:52.773Z","updated":"2024-01-24T01:27:52.773Z","comments":true,"path":"31.Backend/分布式系统-CAP理论/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/分布式系统-CAP理论/","excerpt":"分布式系统的指标: CAP C(Consistency): 一致性 // 分布式系统中多个节点(或多个副本)的数据保持一致, 一致性又分强一致性/弱一致性/最终一致性, CAP里的一致性指强一致性 分布式系统-Consistency A(Availability): 可用性 // 当用户请求节点A, 节点A一定会回应 P(Partition tolerance): 分区容错, 在分布式节点之间网络断开时, 仍旧提供一致性和可用性。// 一般来说，分区容错无法避免，因此可以假定 CAP 的 P 总是成立, 剩下的是选择 AP 还是 CP的问题 (三个指标无法同时做到) Eric Brewer 说，这三个指标不可能同时做到。这个结论就叫做 CAP 定理。 分布式系统只能满足CAP中的两个, 为什么?假设P总是成立, 当写入新数据到node1, 为了实现一致性, 不得不锁定node2 直到数据同步完成, 那么此时node2就不满足可用性 … CAP如何取舍:","text":"分布式系统的指标: CAP C(Consistency): 一致性 // 分布式系统中多个节点(或多个副本)的数据保持一致, 一致性又分强一致性/弱一致性/最终一致性, CAP里的一致性指强一致性 分布式系统-Consistency A(Availability): 可用性 // 当用户请求节点A, 节点A一定会回应 P(Partition tolerance): 分区容错, 在分布式节点之间网络断开时, 仍旧提供一致性和可用性。// 一般来说，分区容错无法避免，因此可以假定 CAP 的 P 总是成立, 剩下的是选择 AP 还是 CP的问题 (三个指标无法同时做到) Eric Brewer 说，这三个指标不可能同时做到。这个结论就叫做 CAP 定理。 分布式系统只能满足CAP中的两个, 为什么?假设P总是成立, 当写入新数据到node1, 为了实现一致性, 不得不锁定node2 直到数据同步完成, 那么此时node2就不满足可用性 … CAP如何取舍: CA without P: 单机系统 // 所以如果舍弃P，意味着要舍弃分布式系统。那也就没有必要再讨论CAP理论了 CP without A: 其中最典型的就是很多分布式数据库，他们都是设计成CP的。在发生极端情况时，优先保证数据的强一致性，代价就是舍弃系统的可用性。如Redis、HBase等，还有分布式系统中常用的Zookeeper也是在CAP三者之中选择优先保证CP的。 AP without C: 如果对可用性要求极高(N个9).. 但也并非完全舍弃C, 退而求其次保证最终一致性即可 @ref: 分布式系统的CAP理论-HollisChuang’s Blog CAP 定理的含义 - 阮一峰的网络日志","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"分布式事务-2PC-and-3PC协议解析","slug":"31.Backend/分布式事务-2PC-and-3PC协议解析","date":"2024-01-24T01:27:52.768Z","updated":"2024-01-24T01:27:52.769Z","comments":true,"path":"31.Backend/分布式事务-2PC-and-3PC协议解析/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/分布式事务-2PC-and-3PC协议解析/","excerpt":"@toc: 分布式事务 → 2PC、3PC协议 2PC协议实现; 3PC协议实现; 2PC &amp; 3PC比较 分布式事务→ 2PC、3PC协议 事务的特性: ACID （👉🏻[[../32.Database/MySQL-03b-事务的特性和实现#ACID特性]]） 分布式事务解决分布式数据的一致性(Consistency)问题 数据库系统保证一致性是「提供正确的增/删/改/查等语义」的基础, 分布式系统一致性问题来自于: 数据多副本存储(每个副本在不同物理机) 需要保证多副本数据一致性; 一个完整事务涉及多个数据库的多表(例如银行转账问题, a和b账户不在一个数据库) 解决分布式一致性的协议和算法: 2PC、3PC、Paxos 分布式事务对比分布式锁: 分布式锁是「多client抢占一个公共资源」, 分布式事务是「一个client操作多个资源, 并保证一致性」 相关阅读:","text":"@toc: 分布式事务 → 2PC、3PC协议 2PC协议实现; 3PC协议实现; 2PC &amp; 3PC比较 分布式事务→ 2PC、3PC协议 事务的特性: ACID （👉🏻[[../32.Database/MySQL-03b-事务的特性和实现#ACID特性]]） 分布式事务解决分布式数据的一致性(Consistency)问题 数据库系统保证一致性是「提供正确的增/删/改/查等语义」的基础, 分布式系统一致性问题来自于: 数据多副本存储(每个副本在不同物理机) 需要保证多副本数据一致性; 一个完整事务涉及多个数据库的多表(例如银行转账问题, a和b账户不在一个数据库) 解决分布式一致性的协议和算法: 2PC、3PC、Paxos 分布式事务对比分布式锁: 分布式锁是「多client抢占一个公共资源」, 分布式事务是「一个client操作多个资源, 并保证一致性」 相关阅读: 分布式系统一致性: 分布式系统-Consistency MySQL的ACID如何实现: [[../32.Database/MySQL-03b-事务的特性和实现]] Raft: Redis-03Raft实现 Paxos: [[分布式系统-Consistency-Paxos]] 2PC2PC(Two Phase Commitment Protocol, 2阶段提交协议)概述: 分布式事务中的角色: 协调者, 事务管理器(TM) 参与者, 资源管理器(RM), 在分布式事务中可能是多个数据库 执行步骤: 1)准备阶段: 事务协调者(事务管理器)给每个参与者(资源管理器)发送Prepare消息; 每个参与者(资源管理器)要么直接返回失败，要么写本地的redo和undo日志并返回成功; 2)提交阶段: 如果协调者(TM)收到了参与者(在第一阶段返回的)失败, 或者超时, 协调者(TM)发送 rollback 消息 给每个参与者; 如果协调者(TM)收到了每个参与者返回的成功消息, 协调者(TM)发送 commit 消息 给每个参与者; 参与者正式完成操作(commit 或 rollback), 释放事务期间占用资源, 并向协调者发布完成消息; 协调者(TM)收到所有参与者的完成消息, 最终完成事务 2PC的问题: 协调者故障: 每个参与者的状态没有超时机制, 在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，这种状态一直阻塞下去; 数据不一致: 当协调者(TM)向参与者(RM)发送commit请求之后，发生了局部网络异常或者在发送commit请求过程中协调者发生了故障，这回导致只有一部分参与者接受到了commit请求。 二阶段无法解决的问题：协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。 3PC3PC协议概述: 步骤: 1)CanCommit: 协调者(TM)向参与者发送 CanCommit请求。询问是否可以执行事务提交操作。然后开始等待参与者的响应。 参与者(RM)接到 CanCommit请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回Yes响应，并进入预备状态。否则反馈No 2)PreCommit: 协调者TM 向参与者发送 PreCommit请求; 参与者RM 接收到 PreCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中。并向协调者返回成功; 协调者TM 未收到某个参与者的确认请求，或者有参与者超时未返回, 协调者向所有参与者发送 abort 3)DoCommit: 协调者(TM)收到了所有参与者的确认请求，且没有参与者超时未返回，协调者向所有参与者发送doCommit请求; 参与者接收到 doCommit请求之后, 执行正式的事务提交. 完成后向协调者发送响应 协调者(TM)接收到所有参与者的确认响应之后，完成事务 协调者(TM)未收到某个参与者的确认请求，或者有参与者超时未返回, 协调者向所有参与者发送abort 在这一阶段, 如果参与者(RM)无法及时接收到来自协调者(TM)的 doCommit或者 rebort请求时, 会在等待超时之后，会继续进行事务的提交。 可能出现的问题:参与者(RM)无法及时收到来自协调者(TM)的信息之后，会默认执行commit。而不会一直持有事务资源并处于阻塞状态。但是这种机制也会导致数据一致性问题，因为，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。 ➤ 2PC &amp; 3PC 比较: 2PC: 协调者只在 Prepare阶段可能发送 rollback指令, 3PC: 协调者在 preCommit 和 doCommit阶段, 都会根据参与者返回决定是否发生abord指令 3PC: 在参与者收到 preCommit指令后, 如果等待协调者超时, 参与者会自动提交commit 2PC: 在参与者收到 Prepare 指令后, 如果等待协调者超时, 参与者会一直等待下去(阻塞) @ref: 2PC之踵？是时候升级二阶段提交协议了 – 后端技术 by Tim Yang 关于分布式事务、两阶段提交协议、三阶提交协议-HollisChuang’s Blog","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"架构案例-混沌工程","slug":"31.Backend/架构案例-混沌工程","date":"2024-01-24T01:27:52.764Z","updated":"2024-01-24T01:27:52.764Z","comments":true,"path":"31.Backend/架构案例-混沌工程/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/架构案例-混沌工程/","excerpt":"","text":"@ref: 混沌工程：苏宁系统稳定性之道_实验 混沌工程是Netflix在 《chaos engineing》提出的，目的是在分布式系统中.. 混沌工程vs故障注入测试: 故障注入测试: 单机: CPU/内存/网卡资源被抢占, 单机进程挂掉 数据库(DB/Redis等): 分库挂掉, 整库挂掉 整个IDC机房故障, 核心网故障","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"消息队列 | Kafka vs RabbitMQ","slug":"31.Backend/消息队列-选型比较(Kafka-vs-RabbitMQ)","date":"2024-01-24T01:27:52.760Z","updated":"2024-01-24T01:27:52.760Z","comments":true,"path":"31.Backend/消息队列-选型比较(Kafka-vs-RabbitMQ)/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/消息队列-选型比较(Kafka-vs-RabbitMQ)/","excerpt":"➤ Kafka 模型: 订阅/发布, 生产者和消费者是多对多 存储: 磁盘 吞吐量/延迟: 10W, 毫秒级 架构: 参考 消息队列-Kafka 高可用机制: 参考 消息队列-Kafka-特性实现 如何保证顺序性: 顺序性指 生产者的(带有顺序性的)消息, 如何保证消费者也按照该顺序消费 生产者: 因为kafka 的topic 存储于多个分区, 为了防止一组顺序消息被投放到不同分区, 可以指定消息的key, 相同k的消息一定被发送到相同分区; 消费者: @todo 防重复消费: 消费者在消费掉某条数据后, 把该条数据的offset提交给zk, 下次消费者请求数据, kafka 从 offset处开始 防消息丢失机制: 因为kafka partition 的多副本机制, 要考虑 如果发生leader-follower切换的情况下, 如何不丢数据 生产者丢数据: 设置acks=all, 生产者投递消息, leader 保证所有 partition 都同步了数据才发送 ack 给生产者, 否则生产者会一直重试投递; 消费者丢数据: 关闭消费者的自动提交offet, 需要消费者业务代码手动的提交offset ➤ RabbitMQ 模型: PTP, 生产者消费者1对1 存储: 非持久化的消息一般只存在于内存中，在内存紧张的时候会被换入到磁盘中，以节省内存。 吞吐量/延迟*: 1W, 微秒级 架构: 基于队列实现, 可以”不同业务使用不同MQ实例”来做MQ的垂直切分, 同时RabbitMQ还提供了镜像模式, 即一个队列有多个镜像, 写入队列的数据会被同步到其他镜像队列上去( RbMQ如何实现主队列失效, 切换镜像队列的? ) 高可用机制: 镜像模式, 每个RabbitMQ节点上都一个queue的镜像 如何保证顺序性机制: 队列的FIFO, 消费者多线程的情况下如何保证顺序? 防重复消费: 防消息丢失机制: 生产者防丢: confirm 模式, MQ Server 收到生产者发送的消息, 会返一个ack MQ Server防丢: 持久化 消费者防丢: 关闭自动ack, 消费者取到消息, 业务代码处理完后, 再调用 ack api通知 MQ Server @ref Java高频面试集-消息队列MQ - 掘金","text":"➤ Kafka 模型: 订阅/发布, 生产者和消费者是多对多 存储: 磁盘 吞吐量/延迟: 10W, 毫秒级 架构: 参考 消息队列-Kafka 高可用机制: 参考 消息队列-Kafka-特性实现 如何保证顺序性: 顺序性指 生产者的(带有顺序性的)消息, 如何保证消费者也按照该顺序消费 生产者: 因为kafka 的topic 存储于多个分区, 为了防止一组顺序消息被投放到不同分区, 可以指定消息的key, 相同k的消息一定被发送到相同分区; 消费者: @todo 防重复消费: 消费者在消费掉某条数据后, 把该条数据的offset提交给zk, 下次消费者请求数据, kafka 从 offset处开始 防消息丢失机制: 因为kafka partition 的多副本机制, 要考虑 如果发生leader-follower切换的情况下, 如何不丢数据 生产者丢数据: 设置acks=all, 生产者投递消息, leader 保证所有 partition 都同步了数据才发送 ack 给生产者, 否则生产者会一直重试投递; 消费者丢数据: 关闭消费者的自动提交offet, 需要消费者业务代码手动的提交offset ➤ RabbitMQ 模型: PTP, 生产者消费者1对1 存储: 非持久化的消息一般只存在于内存中，在内存紧张的时候会被换入到磁盘中，以节省内存。 吞吐量/延迟*: 1W, 微秒级 架构: 基于队列实现, 可以”不同业务使用不同MQ实例”来做MQ的垂直切分, 同时RabbitMQ还提供了镜像模式, 即一个队列有多个镜像, 写入队列的数据会被同步到其他镜像队列上去( RbMQ如何实现主队列失效, 切换镜像队列的? ) 高可用机制: 镜像模式, 每个RabbitMQ节点上都一个queue的镜像 如何保证顺序性机制: 队列的FIFO, 消费者多线程的情况下如何保证顺序? 防重复消费: 防消息丢失机制: 生产者防丢: confirm 模式, MQ Server 收到生产者发送的消息, 会返一个ack MQ Server防丢: 持久化 消费者防丢: 关闭自动ack, 消费者取到消息, 业务代码处理完后, 再调用 ack api通知 MQ Server @ref Java高频面试集-消息队列MQ - 掘金","categories":[],"tags":[]},{"title":"资源调度 | YARN vs Mesos vs k8s","slug":"31.Backend/资源调度-Yarn-Mesos-k8s","date":"2024-01-24T01:27:52.756Z","updated":"2024-01-24T01:27:52.756Z","comments":true,"path":"31.Backend/资源调度-Yarn-Mesos-k8s/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/资源调度-Yarn-Mesos-k8s/","excerpt":"Mesos![[../_images/mesos-arch.png]] ➤ Mesos + Docker:![[../_images/mesos-docker.png]] YARNApache Hadoop YARN （Yet Another Resource Negotiator，另一种资源协调者）是一种新的 Hadoop 资源管理器，它是一个通用资源管理系统，可为上层应用提供统一的资源管理和调度，它的引入为集群在利用率、资源统一管理和数据共享等方面带来了巨大好处。","text":"Mesos![[../_images/mesos-arch.png]] ➤ Mesos + Docker:![[../_images/mesos-docker.png]] YARNApache Hadoop YARN （Yet Another Resource Negotiator，另一种资源协调者）是一种新的 Hadoop 资源管理器，它是一个通用资源管理系统，可为上层应用提供统一的资源管理和调度，它的引入为集群在利用率、资源统一管理和数据共享等方面带来了巨大好处。 术语解释YARN的基本思想是将JobTracker的两个主要功能（资源管理和作业调度/监控）分离，主要方法是创建一个全局的ResourceManager（RM）和若干个针对应用程序的ApplicationMaster（AM）。这里的应用程序是指传统的MapReduce作业或作业的DAG（有向无环图）。 YARN 分层结构的本质是 ResourceManager。这个实体控制整个集群并管理应用程序向基础计算资源的分配。ResourceManager 将各个资源部分（计算、内存、带宽等）精心安排给基础 NodeManager（YARN 的每节点代理）。ResourceManager 还与 ApplicationMaster 一起分配资源，与 NodeManager 一起启动和监视它们的基础应用程序。在此上下文中，ApplicationMaster 承担了以前的 TaskTracker 的一些角色，ResourceManager 承担了 JobTracker 的角色。 ApplicationMaster 管理一个在 YARN 内运行的应用程序的每个实例。ApplicationMaster 负责协调来自 ResourceManager 的资源，并通过 NodeManager 监视容器的执行和资源使用（CPU、内存等的资源分配）。请注意，尽管目前的资源更加传统（CPU 核心、内存），但未来会带来基于手头任务的新资源类型（比如图形处理单元或专用处理设备）。从 YARN 角度讲，ApplicationMaster 是用户代码，因此存在潜在的安全问题。YARN 假设 ApplicationMaster 存在错误或者甚至是恶意的，因此将它们当作无特权的代码对待。 NodeManager 管理一个 YARN 集群中的每个节点。NodeManager 提供针对集群中每个节点的服务，从监督对一个容器的终生管理到监视资源和跟踪节点健康。MRv1 通过插槽管理 Map 和 Reduce 任务的执行，而 NodeManager 管理抽象容器，这些容器代表着可供一个特定应用程序使用的针对每个节点的资源。YARN 继续使用 HDFS 层。它的主要 NameNode 用于元数据服务，而 DataNode 用于分散在一个集群中的复制存储服务。 要使用一个 YARN 集群，首先需要来自包含一个应用程序的客户的请求。ResourceManager 协商一个容器的必要资源，启动一个 ApplicationMaster 来表示已提交的应用程序。通过使用一个资源请求协议，ApplicationMaster 协商每个节点上供应用程序使用的资源容器。执行应用程序时，ApplicationMaster 监视容器直到完成。当应用程序完成时，ApplicationMaster 从 ResourceManager 注销其容器，执行周期就完成了。 主要架构@todo Kubernetes(k8s)容器编排-K8s","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[{"name":"后端架构","slug":"后端架构","permalink":"https://beefyheisenberg.github.io/tags/后端架构/"},{"name":"资源调度","slug":"资源调度","permalink":"https://beefyheisenberg.github.io/tags/资源调度/"},{"name":"YARN","slug":"YARN","permalink":"https://beefyheisenberg.github.io/tags/YARN/"},{"name":"Mesos","slug":"Mesos","permalink":"https://beefyheisenberg.github.io/tags/Mesos/"},{"name":"k8s","slug":"k8s","permalink":"https://beefyheisenberg.github.io/tags/k8s/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://beefyheisenberg.github.io/tags/Kubernetes/"}]},{"title":"反向代理-Nginx","slug":"31.Backend/反向代理-Nginx","date":"2024-01-24T01:27:52.750Z","updated":"2024-01-24T01:27:52.751Z","comments":true,"path":"31.Backend/反向代理-Nginx/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/反向代理-Nginx/","excerpt":"概述Nginx是异步框架的网页服务器，也可以用作反向代理、负载平衡器和HTTP缓存。 与Apache相比Nginx 的编写有一个明确目标就是超越 Apache Web 服务器的性能。Nginx 提供开箱即用的静态文件，使用的内存比 Apache 少得多，每秒可以处理大约四倍于 Apache 的请求。低并发下性能与 Apache 相当，有时候还低于，但是在高并发下 Nginx 能保持低资源低消耗高性能。还有高度模块化的设计，模块编写简单。配置文件简洁。","text":"概述Nginx是异步框架的网页服务器，也可以用作反向代理、负载平衡器和HTTP缓存。 与Apache相比Nginx 的编写有一个明确目标就是超越 Apache Web 服务器的性能。Nginx 提供开箱即用的静态文件，使用的内存比 Apache 少得多，每秒可以处理大约四倍于 Apache 的请求。低并发下性能与 Apache 相当，有时候还低于，但是在高并发下 Nginx 能保持低资源低消耗高性能。还有高度模块化的设计，模块编写简单。配置文件简洁。 命令行# 启动example: /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf# 测试配置文件nginx -t# 平滑重启nginx -s reload# 如何shutdown# 查询 master process主进程号ps -ef | grep nginx# 从容停止kill -QUIT 3266 Nginx支持的几种信号: TERM,INT 快速关闭 QUIT 从容关闭 HUP 平滑重启，重新加载配置文件 USR1 重新打开日志文件，在切割日志时用途较大 USR2 平滑升级可执行程序 WINCH 从容关闭工作进程 nginx.conf配置example@ref: Full Example Configuration | NGINX：https://www.nginx.com/resources/wiki/start/topics/examples/full/ cat nginx.conf : user www www; ## Default: nobodyworker_processes 5; ## Default: 1error_log logs/error.log;pid logs/nginx.pid;worker_rlimit_nofile 8192;events &#123; use epoll; multi_accept on; worker_connections 10240;&#125;http &#123; include /etc/nginx/mime.types; # 设定mime类型 default_type application/octet-stream; access_log /var/log/nginx/access.log; # 设定日志格式 include upstream-servers.conf; # 建议把upstream设置放在单独的文件 # 虚拟服务器, 可以有多个server server&#123; listen 80; server_name s1.xxx.com; index index.shtml index.html index.htm; root /opt/xxx; # upstream定义，上游服务器设置： upstream resin-labs &#123; server 192.168.1.100 weight=3; server 192.168.1.101; # 设置超时时间 proxy_connect_timeout 5s; proxy_read_timeout 10s; &#125; upstream resin-admin &#123; server 192.168.1.109; &#125; # rewrite规则： rewrite ^/help$ /help/ redirect; # location规则，建议顺序：精确匹配=, 前缀匹配^~, 正则匹配~, 普通匹配 location ~ ^/api/labs &#123; access_log /opt/logs/nginx/labs_stat.log labs_stat; # 反向代理到‘resin-labs’的 upstream proxy_pass http://resin-labs; &#125; location /&#123; # 反向代理到‘resin-admin’的 upstream proxy_pass http://resin-admin; &#125; &#125;&#125; httphttp下的Keepalive设置, 是Nginx与客户端（一般为浏览器、APP等）保持的长连接进行限制管理: keepalive_timeout 120s 120s; // keepalive_requests 100; // keepalive_timeout： 第一个参数：客户端连接在服务器端空闲状态下保持的超时值（默认75s）；值为0会禁用keep-alive，也就是说默认不启用长连接；第二个参数：响应的header域中设置“Keep-Alive: timeout=time”；告知浏览器对长连接的维持时间；官方文档：Module ngx_http_core_module keepalive_requests：默认100，某个长连接连续处理请求次数限制，超过次数则该长连接被关闭；如果需要释放某个连接占用的内存，必须关闭该链接，内存不大的情况下，不建议开大该配置；在QPS较高的场景，则有必要加大这个参数；官方文档：Module ngx_http_core_module http/server一个server{} 对应一个port server 下的超时： send_timeout 30s; 用于设置 Nginx 在响应请求时的超时时间。如果在设置的时间内 Nginx 还没有将响应完全发送出去，则会返回 “408 Request Time-out” 错误。上面的例子中，如果 Nginx 在响应请求时超过了 30 秒还没有将响应完全发送出去，则会返回 “408 Request Time-out” 错误。 server/location参考 (http://nginx.org/en/docs/http/ngx_http_core_module.html#location)优先级: 精确匹配: location = /xxx URL完全匹配”/xxx” 前缀匹配: location ^~ /xxx URL”/xxx”开头的前缀, 比如”a.com/xxx/1” 正则匹配: location ~ ^*.php$ 正则(不区分大小写): location ~* ^*.php$ 普通匹配: location / 这样写一般用作其他条件都不符合, 最后的default行为 for Example: # 第一个必选规则#直接匹配网站根, 如果首页访问量很大, 应该首先匹配location = / &#123; root /var/www/; index index.htm index.html;&#125;# 第二个必选规则是处理静态文件请求# 前缀匹配&quot;^~&quot;优先级仅次于精确匹配&quot;=&quot;, 可以用来location ^~ /static/ &#123; root /webroot/static/;&#125;# 如果使用memcached作为缓存, 也可以使用前缀匹配location ^~ /api/services/topic/load &#123; memcached_pass memcached-cluster;&#125;# 前缀匹配^~也可以是转发到应用服务, 但不推荐, 应该让静态文件访问处于更高的优先级# 正则匹配也可以用来处理静态文件location ~* \\.(gif|jpg|jpeg|png|css|js|ico)$ &#123; root /webroot/res/;&#125;# 正则匹配用来转发到后端应用服务location ~ ^/api/v2 &#123; proxy_pass http://tomcat:8080&#125;# 最后普通字符匹配, 用来向后端应用转发# 毕竟目前的一些RESTFUL框架的流行, 带.php,.jsp后缀的情况很少了location / &#123; proxy_pass http://tomcat:8080/ location/proxy_pass 注意区分 ngx_stream_proxy_module 模块的 proxy_pass指令: 指令只能在server段使用使用, 只需要提供域名或ip地址和端口。可以理解为端口转发，可以是tcp端口，也可以是udp端口 这里介绍 ngx_http_proxy_module 模块的 proxy_pass指令, 只能出现在 server/location下, 可以理解为端口转发，可以是tcp端口，也可以是udp端口.proxy_pass 把请求向下一个服务转发, 不影响用户浏览器地址栏的URL // 比如遇到跨域问题，而且客户端无法支持 CORS 时, 最好的办法就是让服务器来做代理. 格式 proxy_pass URL, 其中URL可以是另一个服务的Http地址, 也可以是定义的upstream,需要注意URL后面是否带/, 表示的含义不同: # URL后面没有`/`# proxy_pass相对路径, 将会代理到(http://127.0.0.1:8080/api/**)location /api &#123; proxy_pass http://127.0.0.1:8080 # 结尾没有/, 表示相对路径&#125; # URL后面有`/`# 将会跳转到(http://127.0.0.1:8080/**), 没有&quot;/api&quot;location /api &#123; proxy_pass http://127.0.0.1:8080/ # 结尾有/, 表示绝对路径&#125; location/allow,denyallow,deny 是 ngx_http_access_module 模块提供的,一般用在 location下, 允许/拒绝某些客户端访问location, 示例:allow 192.168.1.0/24deny all; 子网掩码的表示, 使用CIDR ( 参考 [[../22.Network-Protocol/网络协议2-IP]] ) 表示法: /24: 255.255.255.0 /16: 255.255.0.0 /8: 255.0.0.0 deny 和 return 403的区别:webserver - Nginx: Difference between deny all; and return 403; - Stack Overflow server/rewriterewrite用来更改location, 实现跳转到其他location.rewrite只能放在server{},location{},if{}中, 语法为rewrite regex replacement [flag];, 例如: rewrite ^/help(.*) /static/help$1 last; rewrite (.*) http://a.changyan.com$1 last; rewrite的flag标记 last : rewrite之后, 跳出当前location, 并重新走一遍当前server的流程, 浏览器地址栏看起来仍是rewrite之前的URL; break : 请求在这个location终结, 不再重新走server; redirect : 返回302临时重定向, 浏览器地址栏会显示跳转后的地址; permanent : 返回301永久重定向, 浏览器地址栏会显示跳转后的地址; 如果rewrite在location之外, last和break不会有任何区别, 都会跳过后面的rewrite直接进入location: server &#123; rewrite ^/AAA/.* /BBB/$1 last; // 如果命中^AAA规则, 直接进入location, 下面的所有rewrite被跳过; rewrite ^/XXX/.* /ZZZ/$1 last; location ~ /BBB &#123; &#125;&#125; server/upstream示例:proxy_pass http://webapp...upstream webapp &#123; // [均衡方式] server 192.168.1.9:8080;&#125; 负载均衡方式 轮询(默认): 带weight的轮询: 访问后端比例和weight成正比, 用于解决后端服务器性能不均衡 ip_hash: 来访ip hash, 用于解决session问题 url_hash: 后端服务器为缓存时 参考 SystemDesign-负载均衡-Nginx 上游超时upstream backend &#123; # 设置超时时间 proxy_connect_timeout 5s; proxy_read_timeout 10s; proxy_send_timeout&#125; 在上面的示例中，我们将连接超时时间设置为 5 秒，读取响应超时时间设置为 10 秒。如果在这些时间内没有建立连接或者没有接收到响应，nginx 将返回相应的错误码（504）。 log(access,error)log 由 ngx_http_log_module 模块支持. 示例:# log_format 可以在任何位置定义?log_format myLog &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; $host $request_time&apos;; # 可以出现在 http，server，location，limit_except 作用域access_log /opt/logs/nginx/access.log myLog; ## 使用上面定义的format# 可以出现在 main， http, mail, stream, server, location 作用域error_log /opt/logs/nginx/error.log notice; ➤ access_log 格式: access_log path [format] path 指定日志的存放位置。 format 指定日志的格式。格式可以用log_format自定义, 也可以不写, 不写则使用默认使用预定义的”combined”。 access_log作用域:access_log指令的作用域分别有http，server，location，limit_except。也就是说，在这几个作用域外使用该指令，Nginx会报错。 ➤ error_log 格式: error_log path [level] level: debug, info, notice, warn, error, crit, alert,emerg中的任意值 error_log作用域: main, http, mail, stream, server, location @ref: Nginx日志配置详解 - SegmentFault 思否 includeinclude 其他配置文件: include cache.conf; moduleNginx模块一般分为三大类: filter, upstream, handler @todo 需要注意的 if判断字符串(注意是= 而不是==):if ($arg_client_id = &quot;cxsh9byIb&quot;) &#123; return 200 &apos;:)&apos;;&#125; Nginx返回502, 503, 504502: Bad Gateway 作为网关或者代理工作的服务器尝试执行请求时，从上游服务器接收到无效的响应。 什么是无效的响应？与上游服务器无法连接 or 与上游服务器的连接断开 与上游服务器无法连接 =&gt; 上游服务器因连接太多无法处理（例如 req-pre-thread 的服务器，线程池耗尽） 上游服务器断开了连接 =&gt; 上游服务程序执行太久，上游服务终止了此次请求的 Worker 进程，Nginx 发现自己与上游服务断开 503: Service Unavailable 由于临时的服务器维护或者过载，服务器当前无法处理请求。这个状况是临时的，并且将在一段时间以后恢复。如果能够预计延迟时间，那么响应中可以包含一个 Retry-After 头用以标明这个延迟时间。如果没有给出这个 Retry-After 信息，那么客户端应当以处理500响应的方式处理它。 可能的原因： 上游服务器当前因为过载无法处理请求，主动拒绝响应，需要上游服务具备返回“Retry-After”的机制，比较少见到 504: Gateway Timeoua 作为网关或者代理工作的服务器尝试执行请求时，未能及时从上游服务器或者辅助服务器（例如 DNS）收到响应。 可能的原因： 与上游服务的 connect time、send timeout、read time ，在最大等待时间内没有收到返回 参考 http 502 和 504 的区别 - 后端 - 掘金 @ref 代码解读施工中…","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[{"name":"后端架构","slug":"后端架构","permalink":"https://beefyheisenberg.github.io/tags/后端架构/"},{"name":"反向代理","slug":"反向代理","permalink":"https://beefyheisenberg.github.io/tags/反向代理/"},{"name":"Nginx","slug":"Nginx","permalink":"https://beefyheisenberg.github.io/tags/Nginx/"}]},{"title":"消息队列-Kafka","slug":"31.Backend/消息队列-Kafka","date":"2024-01-24T01:27:52.746Z","updated":"2024-01-24T01:27:52.746Z","comments":true,"path":"31.Backend/消息队列-Kafka/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/消息队列-Kafka/","excerpt":"Kafka架构 Kafka存储的消息来自任意多被称为“生产者”（Producer）的进程。数据从而可以被分配到不同的“分区”（Partition）、不同的“Topic”下。在一个分区内，这些消息被索引并连同时间戳存储在一起。其它被称为“消费者”（Consumer）的进程可以从分区查询消息。Kafka运行在一个由一台或多台服务器组成的集群上，并且分区可以跨集群结点分布。 Kafka高效地处理实时流式数据，可以实现与Storm、HBase和Spark的集成。作为群集部署到多台服务器上，Kafka处理它所有的发布和订阅消息系统使用了四个API，即生产者API、消费者API、Stream API和Connector API。它能够传递大规模流式消息，自带容错功能，已经取代了一些传统消息系统，如JMS、AMQP等。","text":"Kafka架构 Kafka存储的消息来自任意多被称为“生产者”（Producer）的进程。数据从而可以被分配到不同的“分区”（Partition）、不同的“Topic”下。在一个分区内，这些消息被索引并连同时间戳存储在一起。其它被称为“消费者”（Consumer）的进程可以从分区查询消息。Kafka运行在一个由一台或多台服务器组成的集群上，并且分区可以跨集群结点分布。 Kafka高效地处理实时流式数据，可以实现与Storm、HBase和Spark的集成。作为群集部署到多台服务器上，Kafka处理它所有的发布和订阅消息系统使用了四个API，即生产者API、消费者API、Stream API和Connector API。它能够传递大规模流式消息，自带容错功能，已经取代了一些传统消息系统，如JMS、AMQP等。 Kafka架构的主要术语包括Topic、Record 和 Broker。Topic 由Record组成，Record持有不同的信息，而Broker则负责复制消息。Kafka有四个主要API： 生产者API：支持应用程序发布Record流。 消费者API：支持应用程序订阅Topic和处理Record流。 Stream API：将输入流转换为输出流，并产生结果。 Connector API：执行可重用的生产者和消费者API，可将Topic链接到现有应用程序。","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[{"name":"后端技术","slug":"后端技术","permalink":"https://beefyheisenberg.github.io/tags/后端技术/"},{"name":"消息队列","slug":"消息队列","permalink":"https://beefyheisenberg.github.io/tags/消息队列/"},{"name":"大数据","slug":"大数据","permalink":"https://beefyheisenberg.github.io/tags/大数据/"},{"name":"Kafka","slug":"Kafka","permalink":"https://beefyheisenberg.github.io/tags/Kafka/"},{"name":"流式计算","slug":"流式计算","permalink":"https://beefyheisenberg.github.io/tags/流式计算/"}]},{"title":"消息队列-Kafka-选举机制","slug":"31.Backend/消息队列-Kafka-选举机制","date":"2024-01-24T01:27:52.742Z","updated":"2024-01-24T01:27:52.742Z","comments":true,"path":"31.Backend/消息队列-Kafka-选举机制/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/消息队列-Kafka-选举机制/","excerpt":"Kafka的”选举”包括: Kafka Controller的选举, Partition Leader的选举, Consumer Group Coordinator(消费组协调者)的选举; ➤ Controller的选举 Controller的作用: 运行 Partition的节点叫 Broker, 其中一个Broker将会被选为Controller, 它负责整个集群中所有分区和副本的管理工作, 其主要职责有: Partition leader的选举, ISR的维护等; 选举触发: Controller(Leader角色)在zk上创建临时节点, 当Leader宕机, 这个临时节点因为心跳检测失败而被删除, 同时zk将消息发送给所有Broker; 选举过程: 收到消息的Broker在zk上创建/controller临时节点, 利用zk的强一致性, 只有一个 Broker能创建成功, 这个节点成为新的Controller; ➤ Partition leader的选举 Partition leader的作用: 每个 Partition都有数个副本(replica), 但消息的读写都是在 Leader Partition上完成的, 然后批量同步到副本; 选举触发: 当有Broker宕机, 这个Broker在zk上的临时节点(znode)也会被删除, zk会通知正在watch的 Controller进行处理; 选举过程: Controller接到通知后, 先选出 set_p(该集合包括了宕机的Broker上包含的所有 Partition), 然后Controller从zk读取 set_p中每一个分区的 ISR, 然后从ISR中选出一个副本作为该Partition的新 Leader, 然后将{新Leader/leader_epoch/controller_epoch} 写入 /brokers/topics/[topic]/partitions/[partition]/state // epoch是需要记录进选举结果的, 任期(term)的概念; 为什么不采用少数服从多数(majority)的选举? (少数服从多数, 类似 Redis Sentinel Leader的选举, 不少于quorum且选票高于一半). Kafka的分区选举, 使用的是 “从ISR中选举”, 而 ISR的可以最多容忍总数“f+1个节点有f个失败”,也即至少有1个在ISR即可. 可以看出, majority的方式(总数2f+1个, 最大容忍f个失败)需要更高的冗余度, 例如能容忍2台机器宕机, 那么majority方式至少需要5台机器. 另外, majority的方式也要求更多的replica “能跟上Partition Leader的写入进度”, 吞吐量也会下降(详见消息的commit机制).","text":"Kafka的”选举”包括: Kafka Controller的选举, Partition Leader的选举, Consumer Group Coordinator(消费组协调者)的选举; ➤ Controller的选举 Controller的作用: 运行 Partition的节点叫 Broker, 其中一个Broker将会被选为Controller, 它负责整个集群中所有分区和副本的管理工作, 其主要职责有: Partition leader的选举, ISR的维护等; 选举触发: Controller(Leader角色)在zk上创建临时节点, 当Leader宕机, 这个临时节点因为心跳检测失败而被删除, 同时zk将消息发送给所有Broker; 选举过程: 收到消息的Broker在zk上创建/controller临时节点, 利用zk的强一致性, 只有一个 Broker能创建成功, 这个节点成为新的Controller; ➤ Partition leader的选举 Partition leader的作用: 每个 Partition都有数个副本(replica), 但消息的读写都是在 Leader Partition上完成的, 然后批量同步到副本; 选举触发: 当有Broker宕机, 这个Broker在zk上的临时节点(znode)也会被删除, zk会通知正在watch的 Controller进行处理; 选举过程: Controller接到通知后, 先选出 set_p(该集合包括了宕机的Broker上包含的所有 Partition), 然后Controller从zk读取 set_p中每一个分区的 ISR, 然后从ISR中选出一个副本作为该Partition的新 Leader, 然后将{新Leader/leader_epoch/controller_epoch} 写入 /brokers/topics/[topic]/partitions/[partition]/state // epoch是需要记录进选举结果的, 任期(term)的概念; 为什么不采用少数服从多数(majority)的选举? (少数服从多数, 类似 Redis Sentinel Leader的选举, 不少于quorum且选票高于一半). Kafka的分区选举, 使用的是 “从ISR中选举”, 而 ISR的可以最多容忍总数“f+1个节点有f个失败”,也即至少有1个在ISR即可. 可以看出, majority的方式(总数2f+1个, 最大容忍f个失败)需要更高的冗余度, 例如能容忍2台机器宕机, 那么majority方式至少需要5台机器. 另外, majority的方式也要求更多的replica “能跟上Partition Leader的写入进度”, 吞吐量也会下降(详见消息的commit机制). ➤ Consumer Group Coordinator的选举 Coordinator的职责: 负责所在的 Consumer Group 的 Rebalance 选举过程: @todo 参考 Kafka科普系列 | 原来Kafka中的选举有这么多？ - 掘金 kafka：leader选举（broker /分区） – Programming language kafka leader选举机制原理_RangeYan-CSDN博客_kafka选主","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"消息队列-Kafka-特性实现","slug":"31.Backend/消息队列-Kafka-特性实现","date":"2024-01-24T01:27:52.735Z","updated":"2024-01-24T01:27:52.736Z","comments":true,"path":"31.Backend/消息队列-Kafka-特性实现/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/消息队列-Kafka-特性实现/","excerpt":"@toc: Kafka高吞吐量的实现? 消息顺序性如何保证? Consumer Group如何防止重复消费? Partition多副本选举机制的实现? ➤ Kafka特性解析: 每个 partition 存于不同的 broker 机器上，一个partition可以有副本存在于多个 broker;每个partition都有一个唯一的leader， 其他的 partition 作为folower, 所有的读写操作都在leader上完成， follower定期从 leader partition 同步数据;每个partition的leader和follower都与zk建立长连接, 如果 leader partition 挂掉, 从 follower上选举出新的 leader; 吞吐量: 因为每条消息都被append到该partition中，是顺序写磁盘，因此效率非常高（经验证，顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。 水平扩展: 每一条消息被发送到broker时，会根据paritition规则选择被存储到哪一个 partition。如果 partition规则设置的合理，所有消息可以均匀分布到不同的partition里，这样就实现了水平扩展。 顺序性: 在发送一条消息时，还可以指定这条消息的key，producer根据这个key和partition机制来判断将这条消息发送到哪个parition。业务上, 多条相关的有顺序的消息, 可以指定同一个Key, 就可以保证都发送到同一个partition并有序; 删除策略: 对于传统的message queue而言，一般会删除已经被消费的消息，而Kafka集群会保留所有的消息，无论其被消费与否。当然，因为磁盘限制，不可能永久保留所有数据（实际上也没必要），因此Kafka提供两种策略去删除旧数据。一是基于时间(固定时间点清理)，二是基于partition文件大小 Consumer Group概念: 一个Consumer Group 可以订阅多个Topic 一个Consumer Group 有唯一的 GroupID, 可以包含多个 Consumer 实例, Topic下某条消息只能给这个Consumer Group其中一个Consumer实例消费( 某 Topic下的一条消息,只能被某个 Consumer Group 消费一次, 但可以被多个 Consumer Group 消费) Consumer Group防重复消费: Consumer Group 中一个实例只能消费某Topic下面的一个分区 (当然其他 Group也可以消费这个分区), 所以记录下这个Group对于某个Topic的某个Partition的消费offset即可, offset的存储是在Zk的节点下 /consumers/&lt;group.id&gt;/offsets/&lt;topic&gt;/&lt;partitionId&gt;; offset的提交: 在旧版本kfk中, 每个Consumer Group的 offset数据是提交到 Zookeeper的, 但是zk并不适合大量写入操作, 所以kafka提供了另一种方案: 额外创建一个叫__consumer_offsets的Topic, 将offset写入这个Topic, 摆脱对Zk的依赖. 由于这个Topic使用了 Compact策略, 该Topic保存的总是最新的offset, 存储格式是顺序的: | GroupId1:Parttion1:offset | GroupId1:Parttion2:offset | ... | Rebalance: 什么是Rebalance? 例如 Consumer Group A下有 20个消费者, 它订阅了一个有 100个分区的 Topic, 每个消费者分配一部分分区, 当这个 Consumer Group中新增或删除了消费者, 就需要给现有的消费者重新分配分区, 这个过程叫做 Rebalance consumer rebalance算法 @link: [[../_attachments/Kafka- a Distributed Messaging System for Log Processing.pdf]]","text":"@toc: Kafka高吞吐量的实现? 消息顺序性如何保证? Consumer Group如何防止重复消费? Partition多副本选举机制的实现? ➤ Kafka特性解析: 每个 partition 存于不同的 broker 机器上，一个partition可以有副本存在于多个 broker;每个partition都有一个唯一的leader， 其他的 partition 作为folower, 所有的读写操作都在leader上完成， follower定期从 leader partition 同步数据;每个partition的leader和follower都与zk建立长连接, 如果 leader partition 挂掉, 从 follower上选举出新的 leader; 吞吐量: 因为每条消息都被append到该partition中，是顺序写磁盘，因此效率非常高（经验证，顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。 水平扩展: 每一条消息被发送到broker时，会根据paritition规则选择被存储到哪一个 partition。如果 partition规则设置的合理，所有消息可以均匀分布到不同的partition里，这样就实现了水平扩展。 顺序性: 在发送一条消息时，还可以指定这条消息的key，producer根据这个key和partition机制来判断将这条消息发送到哪个parition。业务上, 多条相关的有顺序的消息, 可以指定同一个Key, 就可以保证都发送到同一个partition并有序; 删除策略: 对于传统的message queue而言，一般会删除已经被消费的消息，而Kafka集群会保留所有的消息，无论其被消费与否。当然，因为磁盘限制，不可能永久保留所有数据（实际上也没必要），因此Kafka提供两种策略去删除旧数据。一是基于时间(固定时间点清理)，二是基于partition文件大小 Consumer Group概念: 一个Consumer Group 可以订阅多个Topic 一个Consumer Group 有唯一的 GroupID, 可以包含多个 Consumer 实例, Topic下某条消息只能给这个Consumer Group其中一个Consumer实例消费( 某 Topic下的一条消息,只能被某个 Consumer Group 消费一次, 但可以被多个 Consumer Group 消费) Consumer Group防重复消费: Consumer Group 中一个实例只能消费某Topic下面的一个分区 (当然其他 Group也可以消费这个分区), 所以记录下这个Group对于某个Topic的某个Partition的消费offset即可, offset的存储是在Zk的节点下 /consumers/&lt;group.id&gt;/offsets/&lt;topic&gt;/&lt;partitionId&gt;; offset的提交: 在旧版本kfk中, 每个Consumer Group的 offset数据是提交到 Zookeeper的, 但是zk并不适合大量写入操作, 所以kafka提供了另一种方案: 额外创建一个叫__consumer_offsets的Topic, 将offset写入这个Topic, 摆脱对Zk的依赖. 由于这个Topic使用了 Compact策略, 该Topic保存的总是最新的offset, 存储格式是顺序的: | GroupId1:Parttion1:offset | GroupId1:Parttion2:offset | ... | Rebalance: 什么是Rebalance? 例如 Consumer Group A下有 20个消费者, 它订阅了一个有 100个分区的 Topic, 每个消费者分配一部分分区, 当这个 Consumer Group中新增或删除了消费者, 就需要给现有的消费者重新分配分区, 这个过程叫做 Rebalance consumer rebalance算法 @link: [[../_attachments/Kafka- a Distributed Messaging System for Log Processing.pdf]] ➤ Kafka高可用实现: HA:partition多副本同步机制: 方式1: 同步复制, leader要保证所有follower都写入后, 才把这条消息确认为commit, 影响吞吐 方式2: 异步复制, 只需要leader写入完成, 消息就算commit了. 如果leader partition宕机, 可能丢失一部分数据 kafka的多副本同步机制不同于1和2, Kafka在Zookeeper中动态维护了一个ISR（in-sync replicas）列表, 一条消息只有被 in sync列表里所有follower都同步了, 这条消息才算commit.落后太多的follower从ISR列表剔除 HA:partition选举机制: 只有 in sync 列表里的成员才有被选举为leader的可能。在这种模式下，对于f+1个replica，一个Kafka topic能在保证不丢失已经commit的消息的前提下容忍f个replica的失败。ISR可以看成是吞吐量和冗余度的一个平衡. 分区选举机制见: 消息队列-Kafka-选举机制 @ref Kafka消费组(consumer group) - huxihx - 博客园@ref 各消息队列对比，Kafka深度解析，众人推荐，精彩好文！大数据一切依旧的专栏-CSDN博客","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"容器编排-K8s","slug":"31.Backend/容器编排-K8s","date":"2024-01-24T01:27:52.731Z","updated":"2024-01-24T01:27:52.731Z","comments":true,"path":"31.Backend/容器编排-K8s/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/容器编排-K8s/","excerpt":"➤ 什么是Kubernetes: Kubernetes（k8s）是自动化容器操作的开源平台，这些操作包括部署，调度和节点集群间扩展。如果你曾经用过Docker容器技术部署容器，那么可以将Docker看成Kubernetes内部使用的低级别组件。Kubernetes不仅仅支持Docker，还支持Rocket，这是另一种容器技术。使用Kubernetes可以： 自动化容器的部署和复制 随时扩展或收缩容器规模 将容器组织成组，并且提供容器间的负载均衡 很容易地升级应用程序容器的新版本 提供容器弹性，如果容器失效就替换它，等等.. K8s架构","text":"➤ 什么是Kubernetes: Kubernetes（k8s）是自动化容器操作的开源平台，这些操作包括部署，调度和节点集群间扩展。如果你曾经用过Docker容器技术部署容器，那么可以将Docker看成Kubernetes内部使用的低级别组件。Kubernetes不仅仅支持Docker，还支持Rocket，这是另一种容器技术。使用Kubernetes可以： 自动化容器的部署和复制 随时扩展或收缩容器规模 将容器组织成组，并且提供容器间的负载均衡 很容易地升级应用程序容器的新版本 提供容器弹性，如果容器失效就替换它，等等.. K8s架构 上图可以看到如下组件，使用特别的图标表示Service和Label： Kubernetes Master（Kubernetes主节点） Replication Controller（复制控制器） Node（节点） Label: 标签🏷 Service: 服务, 图中红色Service指向带有相同 Label的 Pod ➤ Kubernetes Master:组件包括: Kubernetes API Server/ Replication Controller 等.. ➤ Node:节点（上图橘色方框）是物理或者虚拟机器，作为 Kubernetes worker，通常称为 Minion。每个节点都运行如下 Kubernetes关键组件： Kubelet：是主节点代理, 每个Node运行一个, 作为 Node和 Kubernetes master之间的代理 Kube-proxy：Service使用其将链接路由到Pod Container: Docker 或 Rocket, Kubernetes使用的容器技术来创建容器 ➤ Lable:Label是attach到Pod的一对键/值对，用来传递用户定义的属性。例如通过Label（tier=frontend, app=myapp）来标记前端Pod容器,在deployment描述文件中, 使用Selector: tier=frontend, app=myapp 指定用哪些Pods ➤ Service:Service是将一组Pod公开为网络服务的抽象, Kubernetes 为 Pods 提供自己的 IP 地址，并为一组 Pod 提供相同的 DNS 名， 并且可以在它们之间进行负载均衡。当访问一个Service时，通过 Node上运行的代理（kube-proxy），对 Pod进行负载均衡 ➤ Pod:Pod（上图绿色方框）安排在节点上, 一个Pod内可以包含多个容器和卷, 这些容器共享网络地址和文件系统;Kubernetes 提供了几种资源来管理众多的Pods: Deployment 和 ReplicaSet （替换原来的资源 ReplicationController）。 Deployment 很适合用来管理你的集群上的无状态应用 StatefulSet 让你能够运行一个或者多个以某种方式跟踪应用状态的 Pods。 例如，如果你的负载会将数据作持久存储，你可以运行一个 StatefulSet，将每个 Pod 与某个 PersistentVolume 对应起来 DaemonSet 定义提供节点本地支撑设施的 Pods, 例如作为网络链接的辅助工具或者作为网络 插件 的一部分等等。每次你向集群中添加一个新节点时，如果该节点与某 DaemonSet 的规约匹配，则控制面会为该 DaemonSet 调度一个 Pod 到该新节点上运行。 Job 和 CronJob。 定义一些一直运行到结束并停止的任务。Job 用来表达的是一次性的任务，而 CronJob 会根据其时间规划反复运行。 Deployments@ref: Deployments | Kubernetes ReplicaSet@ref: ReplicaSet | Kubernetes StatefulSets@ref: StatefulSets | Kubernetes Service@ref: 服务 | Kubernetes Ingress@ref: Ingress | Kubernetes K8s命令➤ K8s命令模式: kubectl [command] [TYPE] [NAME] [flags] command: for example create, get, describe, delete TYPE: 描述 resource type, for example pod, pods, app, service, resource type不区分大小写/复数单数/缩写形式 NAME: 描述 resource name, for example kubectl get pod example-pod1 example-pod2 flags: 描述 optional flags, for example -s, --server kubectrl 操作的常用 Resource type, 及缩写形式: cm: configMaps ns: namespaces po: pods rs: replicaSets svc: services sts: statefulSets ing: ingresses deploy: deployments@ref: kubectl 概述 资源类型 ➤ 常用命令: 列出资源: kubectl get pods -o wide: 列出全部Pods kubectl get pods -l app=nginx: 列出具有某label的Pods kubectl get rc,service: 列出全部 rc(replicationControllers) &amp; service kubectl get sts: 列出所有stateful 获取资源描述: kubectl describe nodes: 显示所有Node的详细信息 kubectl describe pods: 显示所有Pod的详细信息 kubectl describe pod ${podname}: 显示某个Pod的详细信息 编辑资源: kubectl delete pod ${podname}: 删除后自动重启pod kubectl edit sts ${stsname}: // edit后不会回写yaml文件 kubectl edit app ${appname}: 发布: kubectl apply -f deployment.yaml kubectl apply -f deployment-update.yaml // 执行后会应用新的yaml配置 对Pod中的容器执行命令: kubectl exec -it ${podname} bash K8s &amp; Docker@ref: 容器技术之容器引擎与江湖门派 - 知乎 容器管理系统分为三层： High-level Container Management：容器管控的UI层。直接实现容器的管控和使用界面，也是用户最熟悉的子系统。 High-level Container Runtime：容器状态及资源供给。包括镜像管理、网络接入、容器状态、调用Low Level Runtime执行容器等功能。习惯上这层称之为容器引擎（Container Engine）。 Low-level Container Runtime：容器执行层。负责具体构建容器运行环境并执行容器进程。习惯上这层直接简称为容器运行时（Container Runtime）。 High-level Container Management和Container Engine之间的接口规范是CRI，Container Engine和Container Runtime之间的接口规范是OCI。支持CRI接口的容器引擎主要有docker、rkt、pouch、containerd和cri-o等 @ref: 为什么 Kubernetes 要替换 Docker-InfoQ Kubernetes 引入容器运行时接口（Container Runtime Interface、CRI）隔离不同容器运行时的实现机制，容器编排系统不应该依赖于某个具体的运行时实现；Docker 没有支持也不打算支持 Kubernetes 的 CRI 接口，需要 Kubernetes 社区在仓库中维护 Dockershim； Deployment.yaml文件解析","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"容器化-Docker-02容器隔离实现原理","slug":"31.Backend/容器化-Docker-02容器隔离实现原理","date":"2024-01-24T01:27:52.727Z","updated":"2024-01-24T01:27:52.727Z","comments":true,"path":"31.Backend/容器化-Docker-02容器隔离实现原理/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/容器化-Docker-02容器隔离实现原理/","excerpt":"Docker容器隔离的实现原理Namespace先认识Linux 提供的Namespace机制: Linux的 Namespace 提供了7种不同的命名空间: PID namespace: 隔离进程ID,每个容器有自己的pid命名空间 UTS namespace: 隔离主机名 &amp; 域名, ….有自己的主机名和NIS域名 IPC namespace: 隔离进程间通信, 相同IPC Ns的进程之间才可以使用(共享内存/信号量/消息队列)通讯 MNT namespace: 隔离文件系统挂载点 … Docker 如何实现进程隔离 (宿主机进程 &amp; 容器内进程的隔离) ?","text":"Docker容器隔离的实现原理Namespace先认识Linux 提供的Namespace机制: Linux的 Namespace 提供了7种不同的命名空间: PID namespace: 隔离进程ID,每个容器有自己的pid命名空间 UTS namespace: 隔离主机名 &amp; 域名, ….有自己的主机名和NIS域名 IPC namespace: 隔离进程间通信, 相同IPC Ns的进程之间才可以使用(共享内存/信号量/消息队列)通讯 MNT namespace: 隔离文件系统挂载点 … Docker 如何实现进程隔离 (宿主机进程 &amp; 容器内进程的隔离) ? 调用clone创建进程时传入 CLONE_NEWPID, 这样创建出的进程PID和宿主机是隔离的 下图中, docker containterd 进程就是在clone时指定CLONE_NEWPID创建的, 所以其子进程和宿主机是隔离的: Linux 两个重要进程: pid=1的init(使用命令ps -p 1可以看到) &amp; pid=2的 kthreadd进程, 前者用于执行一部分内核的初始化和系统配置, 后者负责管理和调度其他内核进程; Docker 的挂载点隔离的实现: 一个容器需要一个rootfs才可以正常启动 (rootfs, 包括/proc, /dev等等..) 调用clone创建进程时传入 CLONE_NEWNS, 这样子进程就能得到父进程挂载点的拷贝, 如果不传入CLONE_NEWNS这个参数, 子进程对文件系统的读写都会同步回父进程以及整个主机的文件系统 Docker 的网络隔离的实现: Docker 提供了四种网络模式(Host、Container、None 和 Bridge) 如果是网桥模式, 除了分配网络的Namespace, 还会给容器分配虚拟网卡, 在宿主机安装虚拟网桥, 虚拟网卡和网桥通过iptables连接; 例如docker run -d -p 6379:6379 redis启动一个容器, 查看 iptables 的 NAT 配置就会看到在 DOCKER 的链中出现了一条新的规则 以上, Docker通过Linux 提供的 Namespace为新创建的进程隔离了 进程ID/网络/文件系统… @ref: Clone()函数: [[../21.Operating-System/APUE.03a.进程#clone]] Namespace: [[../21.Operating-System/APUE.03a.进程#Namespace]] CGroup Docker 对容器的资源使用限额(CPU/RAM..)是通过 Controll Group (简称 CGroup)实现的: 创建一个CGroup 并指定其(CPU/RAM等)限额, 实现不同CGroup 之间资源隔离 进程可以随时加入一个CGroup or 退出 查看当前系统中的CGroup: lssubsys -m $ lssubsys -mcpuset /sys/fs/cgroup/cpusetcpu /sys/fs/cgroup/cpucpuacct /sys/fs/cgroup/cpuacctmemory /sys/fs/cgroup/memory 继续查看 /sys/fs/cgroup/cpu/目录, 下面有个名为docker的文件夹, 再向下层是docker container id命名的目录 创建一个Docker容器并指定配额: docker run -it -d --cpu-quota=50000 image_tag UnionFS综上所述, Namespace解决了…, CGroup解决了… , 还有一个文件系统的隔离问题, 是通过UnionFS实现的 (是一种为 Linux 操作系统设计的用于把多个文件系统『联合』到同一个挂载点的文件系统服务) Dockerfile里每一个命令都会创建一个只读层, 当使用docker run命令启动一个容器时, 会在镜像最上层添加一个可写的层(也就是容器层), 容器运行时对容器的修改都是对这个层的修改; docker镜像的每一个层, 都对应宿主机/var/lib/docker/ 下面的一个目录 通过AUFS(Advanced UnionFS) , 把多个文件目录”联合”到同一个挂载点; 除了AUFS之外, Docker 还支持aufs、devicemapper、overlay2、zfs 和 vfs 等等不同驱动 通过这种层(layer) 的设计, 不同tag的docker镜像, 可以公用同一个层, 减少了镜像的磁盘占用 综述Docker 的隔离技术实现的基础: Namespace/CGroup/UnionFS 参考@ref: Docker 核心技术与实现原理 - 面向信仰编程 Docker运行性能分析 与虚拟机技术不同, Docker使用Ns和CGroup实现隔离和资源配额控制, 不需要用额外的性能消耗运行vm Docker启动的进程和宿主机共享一个内核. 对Docker容器内进程的优化(内核参数优化), 也可以在容器内执行sysctl命令更改, 或者在Docker启动时: docker run --sysctl key=value IMAGE:TAG CMD Docker有一个白名单, 定义哪些sysctl参数可以在docker run时更改, 不在白名单内的参数, 在docker容器内sysctl -a也看不到 有些参数可以在容器内使用 sysctl 更改(如 kernel.pid_max), 但是容器内更改后会影响到主机, 原因是这类参数没有 Namespace 隔离(大部分 kernel 开头的), docker 和宿主机共享内核. 这类参数也不建议通过容器更改, sysctl 命令参考：[[../21.Operating-System/Linux.04a.Sysctl]] 所以针对docker的内核类优化: 最好是在宿主机内修改, 然后作用于docker进程; 如果需要针对docker修改, 可以通过docker run传入参数, 并注意这些参数会不会影响到宿主机 @ref: https://zhuanlan.zhihu.com/p/82488569","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"Docker","slug":"31.Backend/容器化-Docker-01基础","date":"2024-01-24T01:27:52.722Z","updated":"2024-01-24T01:27:52.723Z","comments":true,"path":"31.Backend/容器化-Docker-01基础/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/容器化-Docker-01基础/","excerpt":"安装 &amp; 启动 安装 yum install -y docker 装完之后需要在 /etc/docker/daemon.json 修改image注册地址 &amp; 存储目录 &#123; &quot;insecure-registries&quot; : [&quot;registry.xxx.com&quot;] &quot;graph&quot;: &quot;/data0/docker&quot;&#125; 然后启动 dockerd: systemctl enable dockersystemctl start docker Docker命令参考命令概览","text":"安装 &amp; 启动 安装 yum install -y docker 装完之后需要在 /etc/docker/daemon.json 修改image注册地址 &amp; 存储目录 &#123; &quot;insecure-registries&quot; : [&quot;registry.xxx.com&quot;] &quot;graph&quot;: &quot;/data0/docker&quot;&#125; 然后启动 dockerd: systemctl enable dockersystemctl start docker Docker命令参考命令概览 容器生命周期管理 — docker [run|start|stop|restart|kill|rm|pause|unpause] 容器操作运维 — docker [ps|inspect|top|attach|events|logs|wait|export|port] 容器rootfs命令 — docker [commit|cp|diff] 镜像仓库 — docker [login|pull|push|search] 本地镜像管理 — docker [images|rmi|tag|build|history|save|import] 其他命令 — docker [info|version] 参考: Docker 命令大全 @ref pull镜像获取镜像: docker pull [选项] [Docker Registry地址]&lt;仓库名&gt;:&lt;标签&gt; 可能需要先执行 docker login 管理本地镜像 列出已经下载下来的镜像: docker images -a # 列表包含了仓库名(REPOSITORY)、标签(TAG)、镜像ID(IMAGE ID)、创建时间以及所占用的空间 无标签的镜像很多都是”中间层镜像” 根据仓库名列出镜像: docker images 仓库名 删除镜像: docker rmi 仓库:Tag 运行镜像 docker run --name webserver -d -p 80:80 repoName:tag # 启动镜像 -p host_port:container_port // 端口映射 -v host_path:container_path // 绑定主机目录到… -d: 容器在后台运行, 并不立即进入容器终端 -t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用 -i: 以交互模式运行容器，通常与 -t 同时使用 示例: docker run -d repoName:tag: 后台启动容器(执行后不立刻进入容器) docker run -it repoName:tag /bin/bash: 交互模式启动容器 登录/退出容器 docker exec -it 容器ID /bin/bash : 进入镜像的bash命令行, -i保持STDIN 打开, -t分配一个伪终端 docker attach 容器ID: 如果docker run -d在后台运行的镜像, 需要这样连接上容器 exit 退出容器 镜像修改和提交docker attach or docker exec -it 进入容器后, 可以对正在运行的镜像进行修改, docker cp /Users/xx/xxx/ 容器ID:/tmp : 本地文件拷贝到docker 容器内 然后 exit 退出 .. docker diff # 显示对 docker 镜像做了哪些修改 docker commit --author &quot;xx&quot; --message &quot;xxx&quot; 容器ID 仓库名:TAG # 提交对容器的修改到镜像 docker history 仓库名:TAG # 列出改动历史 docker push 仓库名:TAG # 上传 管理容器运行镜像之后: docker ps -a: 列出容器(不是镜像!) 列出正在运行的 容器ID(CONTAINER ID), 镜像(IMAGE), 状态(STATUS) docker top 容器ID : 显示一个运行的容器里面的进程信息 docker stop 容器ID : 停止容器, 先发送SIGTERM, 再发送SIGKILL, docker内的应用程序可以接收到SIGTERM做处理 docker kill 容器ID : 直接发送SIGKILL docker restart 容器ID : 重启 docker rm 容器ID: 删除容器, 如果加了-f参数则是直接发送SIGKILL 容器日志 docker logs -f 容器ID: 查看log, 类似tailf docker logs --since 30m CONTAINER_ID : 查看近30分钟的日志 创建镜像 &amp; 编译镜像 准备Dockerfile 执行: docker build --build-arg xArg1=$ARG1 -t &lt;image_name&gt;:&lt;tag&gt; . --build-arg xArg1=$ARG1: 把外界参数传入Dockerfile, 在Dockerfile里可以$xArg1取到 -t &lt;image_name&gt;:&lt;tag&gt;: 设置tag Dockerfile 说明Example: FROM xxx.com/REPOSITORY:latestRUN mkdir -p /data/remotedump-controllerCOPY remotedump-controller/* /data/remotedump-controller# 创建两个ARG变量, 只在dockerfile内有效ARG Arg1ARG Arg2# ENV创建的变量可以在docker运行环境使用ENV Arg1=$Arg1ENV Arg2=$Arg2COPY remotedump-controller/start.sh /etc/kickStart.d/RUN chmod +x /etc/kickStart.d/start.shENTRYPOINT command param1 param2 参考: https://docs.docker.com/engine/reference/builder/: Dockerfile 中每一个指令都会建立一层, 新建立一层, 在其上执行这些命令, 执行结束后, commit 这一层的修改, 构成新的镜像. Union FS 是有最大层数限制的, 比如 AUFS, 曾经是最大不得超过 42 层, 现在是不得超过 127 层. RUN: 后面跟shell命令, 在镜像里执行 WORKDIR 指定工作目录, 对后面的RUN都有效 ARG: 指令是定义参数名称, 以及定义其默认值.该默认值可以在构建命令 docker build 中用 --build-arg &lt;参数名&gt;=&lt;值&gt; 来覆盖 ENV: ENV Arg2=$Arg2, 在运行时容器中就可以使用$Arg2这个环境变量了. 用ENV赋值之前, 必须要用ARG声明变量ARG Arg2 COPY: COPY ./package.json /app/ # 拷贝资源 ADD 类似COPY, 但ADD源地址可以是URL EXPOSE: EXPOSE 3306 声明镜像的3306端口要暴露给外面, 仅仅是声明, 真正映射还是在docker run -p 宿主端口:容器端口 CMD: CMD [&quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot;] : 执行sh, 执行完后sh会退出, 容器也退出了 CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;] : CMD的可执行程序必须在前台执行! 否则容器自动退出 ENTRYPOINT: ENTRYPOINT command param1 param2 docker build 编译命令: docker build --build-arg env=${env} -t repository_name:tag_name -f Dockerfile . 注: 最后的.和tar cvzf xxx.tar.gz .类似, 表示打包哪个目录 --build-arg k=v会把参数传入dockerfile, 在dockerfile里 -t repository_name:tag_name: 冒号前面部分是仓库名, 后面是TAG 删除镜像: docker rm IMAGE_ID, 或者 docker rmi repository_name:tag_name注意这样会删除该tag下所有镜像 核心技术与实现原理参考: Docker 核心技术与实现原理","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[{"name":"后端架构","slug":"后端架构","permalink":"https://beefyheisenberg.github.io/tags/后端架构/"},{"name":"容器化","slug":"容器化","permalink":"https://beefyheisenberg.github.io/tags/容器化/"},{"name":"Docker","slug":"Docker","permalink":"https://beefyheisenberg.github.io/tags/Docker/"}]},{"title":"缓存-Memcache","slug":"31.Backend/缓存-Memcache","date":"2024-01-24T01:27:52.718Z","updated":"2024-01-24T01:27:52.718Z","comments":true,"path":"31.Backend/缓存-Memcache/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/缓存-Memcache/","excerpt":"内存分配Memcached默认情况下采用了名为 Slab Allocator的机制分配来避免内存碎片 chunks: 每个chunk中都保存了一个item结构体、一对key和value slab: 一个slab由若干个大小相等的chunk组成 page: 缓存淘汰算法: LRU: Least Recently Used, 最近最不常访问的被淘汰, 访问时间距离现在最久远的被淘汰(较常用) LFU: Least Frequently Used, 在一段时间内访问次数最少( 访问频率最少)的被淘汰 FIFO:","text":"内存分配Memcached默认情况下采用了名为 Slab Allocator的机制分配来避免内存碎片 chunks: 每个chunk中都保存了一个item结构体、一对key和value slab: 一个slab由若干个大小相等的chunk组成 page: 缓存淘汰算法: LRU: Least Recently Used, 最近最不常访问的被淘汰, 访问时间距离现在最久远的被淘汰(较常用) LFU: Least Frequently Used, 在一段时间内访问次数最少( 访问频率最少)的被淘汰 FIFO: 统计 stats: 命中率 stats items: LRU","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[{"name":"后端架构","slug":"后端架构","permalink":"https://beefyheisenberg.github.io/tags/后端架构/"},{"name":"缓存","slug":"缓存","permalink":"https://beefyheisenberg.github.io/tags/缓存/"},{"name":"Memcached","slug":"Memcached","permalink":"https://beefyheisenberg.github.io/tags/Memcached/"},{"name":"LRU","slug":"LRU","permalink":"https://beefyheisenberg.github.io/tags/LRU/"},{"name":"LFU","slug":"LFU","permalink":"https://beefyheisenberg.github.io/tags/LFU/"}]},{"title":"Zookeeper-04应用-分布式锁","slug":"31.Backend/Zookeeper-04应用-分布式锁","date":"2024-01-24T01:27:52.714Z","updated":"2024-01-24T01:27:52.714Z","comments":true,"path":"31.Backend/Zookeeper-04应用-分布式锁/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/Zookeeper-04应用-分布式锁/","excerpt":"@toc: 分布式锁需要具备哪些特性? 如何使用Zookeeper实现分布式锁? 比较Redis分布式锁方案; ➤ 分布式锁特性: 互斥性, 超时放锁 ➤ 使用Zk实现分布式锁: Zk实现分布式锁利用了Zk的诸多特性: 节点有序性, 临时节点, Watch .. 加锁: client 在/lock节点下创建”有序”Znode , 节点id递增由父节点维护, 例如 /lock/node00000 , 如果client的节点是最小的, 则获得锁;获得锁失败的client, 监听 /lock 节点, 当/lock下面节点结构发生变化, zk会通知/lock下全部的node的Client (此处可以改进性能, node00001 只监听 node00000, node00002只监听 node0001 …); 解锁: Client删除自己的节点, zk Watch进行通知 超时: 似乎只能等临时Znode被删除(Client的回话结束, Znode被删除)","text":"@toc: 分布式锁需要具备哪些特性? 如何使用Zookeeper实现分布式锁? 比较Redis分布式锁方案; ➤ 分布式锁特性: 互斥性, 超时放锁 ➤ 使用Zk实现分布式锁: Zk实现分布式锁利用了Zk的诸多特性: 节点有序性, 临时节点, Watch .. 加锁: client 在/lock节点下创建”有序”Znode , 节点id递增由父节点维护, 例如 /lock/node00000 , 如果client的节点是最小的, 则获得锁;获得锁失败的client, 监听 /lock 节点, 当/lock下面节点结构发生变化, zk会通知/lock下全部的node的Client (此处可以改进性能, node00001 只监听 node00000, node00002只监听 node0001 …); 解锁: Client删除自己的节点, zk Watch进行通知 超时: 似乎只能等临时Znode被删除(Client的回话结束, Znode被删除) @ref 10分钟看懂！基于Zookeeper的分布式锁_qiangcuo6087的博客-CSDN博客","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"Zookeeper-03一致性","slug":"31.Backend/Zookeeper-03一致性","date":"2024-01-24T01:27:52.709Z","updated":"2024-01-24T01:27:52.709Z","comments":true,"path":"31.Backend/Zookeeper-03一致性/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/Zookeeper-03一致性/","excerpt":"➤ Zk实现的一致性: Zk实现的是顺序一致性: A/B事务依次被提交, 如果客户端看到了B版本的数据, 一定不会再看到A版本的数据; Zk并不保证强一致性, 如果一个Zk集群有10个节点, 向Leader更新一项数据, 如果有6个节点写入成功则Zk认为此次写入成功, 但如果客户端刚好从另外4个节点读取数据, 读到的还是旧版本数据. 考虑两个客户端A和B的场景。如果客户端A将znode /a的值从0设置为1，此时客户端B读取/a，有可能读取旧值0，读到新值or旧值取决于连接到的服务器。如果客户端A和客户端B读取相同的值很重要，则客户端B应该在执行读取之前调用 ZooKeeper API的 sync() 方法。 ➤ Zk的写入过程: Client向Leader发出写请求。 Leader将数据写入到本节点，并将数据发送到所有的Follower节点； 等待Follower节点返回； 当Leader接收到一半以上节点(包含自己)返回写成功的信息之后，返回写入成功消息给client; 如果第一步, Client连接上的是Follower端, 则由Follower把写请求转发给Leader, Leader进行正常的写流程, 超半数节点写成功后, Leader把结果返回给Follower, Follower把写入成功的结果发送给Client","text":"➤ Zk实现的一致性: Zk实现的是顺序一致性: A/B事务依次被提交, 如果客户端看到了B版本的数据, 一定不会再看到A版本的数据; Zk并不保证强一致性, 如果一个Zk集群有10个节点, 向Leader更新一项数据, 如果有6个节点写入成功则Zk认为此次写入成功, 但如果客户端刚好从另外4个节点读取数据, 读到的还是旧版本数据. 考虑两个客户端A和B的场景。如果客户端A将znode /a的值从0设置为1，此时客户端B读取/a，有可能读取旧值0，读到新值or旧值取决于连接到的服务器。如果客户端A和客户端B读取相同的值很重要，则客户端B应该在执行读取之前调用 ZooKeeper API的 sync() 方法。 ➤ Zk的写入过程: Client向Leader发出写请求。 Leader将数据写入到本节点，并将数据发送到所有的Follower节点； 等待Follower节点返回； 当Leader接收到一半以上节点(包含自己)返回写成功的信息之后，返回写入成功消息给client; 如果第一步, Client连接上的是Follower端, 则由Follower把写请求转发给Leader, Leader进行正常的写流程, 超半数节点写成功后, Leader把结果返回给Follower, Follower把写入成功的结果发送给Client ➤ @ref: ZooKeeper Programmer’s Guide Zookeeper 读写数据流程 - 简书","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"Zookeeper-02部署和运维","slug":"31.Backend/Zookeeper-02部署和运维","date":"2024-01-24T01:27:52.705Z","updated":"2024-01-24T01:27:52.705Z","comments":true,"path":"31.Backend/Zookeeper-02部署和运维/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/Zookeeper-02部署和运维/","excerpt":"zookeeper部署@todo zookeeper命令 连接Zk Server: # 连接 zk Server:bin/zkCli.sh -server 127.0.0.1:2181# 进入zk命令行 ... 列出节点 # 查看根目录下节点列表ls / 创建节点 # 创建节点/zk1, 节点存储值为aaacreate /zk1 &quot;aaa&quot;# -s 顺序节点create -s /zk2 &quot;bbb&quot;# -e 临时节点create -e /zk3 &quot;ccc&quot; get &amp; set # 设置node的值set /zk &quot;ddd&quot;# 获取node的值, 同时返回 mtime/zxid/dataversion等get /zk1# 带版本set, 版本号需要与当前的版本号一致才能设置成功# 命令格式: set &lt;path&gt; &lt;val&gt; [ver]set /zk1 &quot;eee&quot; 2 或者使用socket:","text":"zookeeper部署@todo zookeeper命令 连接Zk Server: # 连接 zk Server:bin/zkCli.sh -server 127.0.0.1:2181# 进入zk命令行 ... 列出节点 # 查看根目录下节点列表ls / 创建节点 # 创建节点/zk1, 节点存储值为aaacreate /zk1 &quot;aaa&quot;# -s 顺序节点create -s /zk2 &quot;bbb&quot;# -e 临时节点create -e /zk3 &quot;ccc&quot; get &amp; set # 设置node的值set /zk &quot;ddd&quot;# 获取node的值, 同时返回 mtime/zxid/dataversion等get /zk1# 带版本set, 版本号需要与当前的版本号一致才能设置成功# 命令格式: set &lt;path&gt; &lt;val&gt; [ver]set /zk1 &quot;eee&quot; 2 或者使用socket: echo stat|nc 127.0.0.1 2181 查看哪个节点被选择作为follower或者leader echo ruok|nc 127.0.0.1 2181 测试是否启动了该Server，若回复imok表示已经启动。 echo dump| nc 127.0.0.1 2181 列出未经处理的会话和临时节点。 echo kill | nc 127.0.0.1 2181 ,关掉server echo conf | nc 127.0.0.1 2181 ,输出相关服务配置的详细信息。 echo cons | nc 127.0.0.1 2181 ,列出所有连接到服务器的客户端的完全的连接 / 会话的详细信息。 echo envi |nc 127.0.0.1 2181 ,输出关于服务环境的详细信息（区别于 conf 命令）。 echo reqs | nc 127.0.0.1 2181 ,列出未经处理的请求。 echo wchs | nc 127.0.0.1 2181 ,列出服务器 watch 的详细信息。 echo wchc | nc 127.0.0.1 2181 ,通过 session 列出服务器 watch 的详细信息，它的输出是一个与 watch 相关的会话的列表。 echo wchp | nc 127.0.0.1 2181 ,通过路径列出服务器 watch 的详细信息。它输出一个与 session 相关的路径。 @ref: https://cloud.tencent.com/developer/article/1781289","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[{"name":"后端架构","slug":"后端架构","permalink":"https://beefyheisenberg.github.io/tags/后端架构/"},{"name":"分布式","slug":"分布式","permalink":"https://beefyheisenberg.github.io/tags/分布式/"},{"name":"Apache","slug":"Apache","permalink":"https://beefyheisenberg.github.io/tags/Apache/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://beefyheisenberg.github.io/tags/Zookeeper/"},{"name":"Paxos","slug":"Paxos","permalink":"https://beefyheisenberg.github.io/tags/Paxos/"},{"name":"ZAB","slug":"ZAB","permalink":"https://beefyheisenberg.github.io/tags/ZAB/"},{"name":"CAP","slug":"CAP","permalink":"https://beefyheisenberg.github.io/tags/CAP/"}]},{"title":"Zookeeper-01基础概念","slug":"31.Backend/Zookeeper-01基础概念","date":"2024-01-24T01:27:52.700Z","updated":"2024-01-24T01:27:52.701Z","comments":true,"path":"31.Backend/Zookeeper-01基础概念/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/Zookeeper-01基础概念/","excerpt":"@toc: Session; 临时Znode; 持久Znode; Watcher; Leader/Follower/Observer; zxid; ZAB; ➤ Zk中的重要概念: Session(会话): Session 是客户端和Zk的一个长连接, 每个客户端的Session 都有一个 唯一id, 客户端定时向zk发送heart_beat , Session在创建的时候可以指定一个sessionTimeout, 如果超时则会断开该Session; ZNode是zk存储数据的节点, ZNode 分为永久节点和临时节点 持久节点是指一旦这个 ZNode 被创建了，除非主动进行 ZNode 的移除操作，否则这个 ZNode 将一直保存在 Zookeeper 上。 临时节点的生命周期和客户端会话(Session)绑定，一旦客户端会话失效，那么这个客户端创建的所有临时节点都会被移除。 Zookeeper 将所有数据存储在内存中，数据模型是一棵树（Znode Tree)，由斜杠（/）的进行分割的路径，就是一个 Znode，例如/foo/path1。每个上都会保存自己的数据内容，同时还会保存一系列属性信息。","text":"@toc: Session; 临时Znode; 持久Znode; Watcher; Leader/Follower/Observer; zxid; ZAB; ➤ Zk中的重要概念: Session(会话): Session 是客户端和Zk的一个长连接, 每个客户端的Session 都有一个 唯一id, 客户端定时向zk发送heart_beat , Session在创建的时候可以指定一个sessionTimeout, 如果超时则会断开该Session; ZNode是zk存储数据的节点, ZNode 分为永久节点和临时节点 持久节点是指一旦这个 ZNode 被创建了，除非主动进行 ZNode 的移除操作，否则这个 ZNode 将一直保存在 Zookeeper 上。 临时节点的生命周期和客户端会话(Session)绑定，一旦客户端会话失效，那么这个客户端创建的所有临时节点都会被移除。 Zookeeper 将所有数据存储在内存中，数据模型是一棵树（Znode Tree)，由斜杠（/）的进行分割的路径，就是一个 Znode，例如/foo/path1。每个上都会保存自己的数据内容，同时还会保存一系列属性信息。 对应于每个 ZNode，Zookeeper 都会为其维护一个叫作 Stat 的数据结构，Stat 中记录了这个 ZNode 的三个数据版本，分别是 version（当前 ZNode 的版本）、cversion（当前 ZNode 子节点的版本）和 cversion（当前 ZNode 的 ACL 版本）。 Zookeeper 采用 ACL（AccessControlLists）策略来进行权限控制，类似于 UNIX 文件系统的权限控制。Zookeeper 定义了如下5种权限： Create：创建子节点权限； READ：读取节点数据、获取子节点列表权限； WRITE：更新节点数据权限； DELETE：删除子节点权限； ADMIN：设置节点 ACL 的权限 创建节点时可以指定 SEQUENTIAL 属性（有序节点，既可以是临时节点也可以是持久节点）, zk 会在创建这个节点的时候加上递增整形序号。当创建一个有序节点时，系统会自动添加一个10位长度的数字来代替原节点。比如创建/sequence，那么系统会自动替换成/sequence0000000001，继续创建/sequence 会生成 /sequence0000000002 &gt;&gt;&gt; zk.create(&apos;/walker/b&apos;, value=&apos;node data&apos;, acl=None, ephemeral=False, sequence=True) u&apos;/walker/b0000000001&apos; &gt;&gt;&gt; zk.create(&apos;/walker/b&apos;, value=&apos;node data&apos;, acl=None, ephemeral=False, sequence=True) u&apos;/walker/b0000000002&apos; &gt;&gt;&gt; zk.create(&apos;/walker/a&apos;, value=&apos;node data&apos;, acl=None, ephemeral=False, sequence=True) u&apos;/walker/a0000000003&apos; &gt;&gt;&gt; zk.create(&apos;/walker/a/du&apos;, value=&apos;node data&apos;, acl=None, ephemeral=False, sequence=True) u&apos;/walker/a/du0000000000&apos; Watcher（事件监听器）: Zookeeper 允许用户在指定节点上注册一些 Watcher，并且在一些特定事件触发的时候，ZooKeeper 服务端会将事件通知到感兴趣的客户端上去，该机制是 Zookeeper 实现分布式协调服务的重要特性。 Zxid: Zookeeper 给每次更新操作都分配一个全局唯一递增编号, 这个编号反映了所有操作的先后顺序, 可以实现更高层次的同步原语，应用程序可以使用 ZooKeeper 这个特性来实现更高层次的同步原语。zxid 即 Zookeeper Transaction Id Zk集群中的节点的角色: Leader, Follower, Observer: Leader 可以提供读/写服务; Follower 和 Observer 都只提供读服务, 不同的是 Follower 参与 Leader 的选举, Observer 不参与选举, 也不参与写的时候”超过半数节点写成功则写入成功”的策略, 可以认为 Obverser 的作用是提高集群的读性能, 且不影响写入性能; Paxos 算法和 Zab 协议: 「ZooKeeper 并没有完全采用 Paxos 算法，而是使用 ZAB 协议作为其保证数据一致性的核心算法。另外，在 ZooKeeper 的官方文档中也指出，ZAB 协议并不像 Paxos 算法那样，是一种通用的分布式一致性算法，它是一种特别为 Zookeeper 设计的崩溃可恢复的原子消息广播算法。」 ZAB(Zookeeper Atomic Broadcast): Zookeeper 通过 ZAB 协议实现了分布式数据的一致性(顺序一致性), 另外 ZAB 还提供了崩溃恢复(Leader 选举); Zab协议中定义的两种集群状态: 崩溃恢复: 当集群在启动过程/Leader 网络断开/异常重启时, ZAB 协议进入崩溃恢复模式, 进行 leader 选举, 然后 Folower 节点与 Leader 节点进行数据同步, 当过半的 Folower 节点都同步完成, ZAB 协议退出崩溃恢复模式, 进入消息广播状态; 消息广播: 在此状态下, 只允许一台 Leader 服务器进行事务请求的处理, 如果 Follower 节点接收到客户端的事务请求也应当转发给 Leader. Leader 收到事务请求后, 会对事务进行提案并进行一轮新的广播 ➤ Zk的以下特性使得其可以作为 1集群管理(Znode watch集群节点状态), 2分布式存储(Zk的数据一致性) 3分布式锁(操作的原子性, Watch特性), 具体使用场景有: Kafka的 Broker节点状态监控利用了 Znode和 Watch; Kafka的 Controller选举利用了Zk实现的分布式锁; Kafka的 Consumer Group对某个 Topic的消费offset记录利用了Zk的一致性存储; @ref 可能是全网把 ZooKeeper 概念讲的最清楚的一篇文章 - JavaGuide - SegmentFault 思否","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"SystemDesign | 秒杀系统","slug":"31.Backend/SystemDesign-秒杀系统设计要点","date":"2024-01-24T01:27:52.696Z","updated":"2024-01-24T01:27:52.696Z","comments":true,"path":"31.Backend/SystemDesign-秒杀系统设计要点/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/SystemDesign-秒杀系统设计要点/","excerpt":"@toc: 高性能:静动分离/热点优化/系统优化; 高可用:削峰/兜底, 库存数据一致性; 一致性; ➤ 高性能: 静动分离: 数据拆分, 数据缓存, 数据整合; 热点优化: 热点识别: 通过链路各节点收集热点key, 识别热点商品, 发送到各订阅模块, 各模块采取各自措施(缓存或限流或熔断) 热点隔离: 系统隔离(怎么做?): 负载均衡层做(热点key如何更新到配置?) 或者端上存储特定cookie, 数据隔离: 热点数据使用单独的Cache/DB 热点优化: 系统层(业务代码)对热点做优化, 本机缓存/ 限流等 系统优化(代码): 减少序列化(多在RPC阶段) 字符串优化: 涉及到字符串的IO, OutputStream() 类函数从而减少数据的编码转换 (由于字符串每个字符需要转字节, 这个过程需要查编码表) 去除不必要组件: 去掉MVC (因为MVC的 Chain) 剪裁异常日志堆栈大小 ➤ 一致性: 库存数据的一致性","text":"@toc: 高性能:静动分离/热点优化/系统优化; 高可用:削峰/兜底, 库存数据一致性; 一致性; ➤ 高性能: 静动分离: 数据拆分, 数据缓存, 数据整合; 热点优化: 热点识别: 通过链路各节点收集热点key, 识别热点商品, 发送到各订阅模块, 各模块采取各自措施(缓存或限流或熔断) 热点隔离: 系统隔离(怎么做?): 负载均衡层做(热点key如何更新到配置?) 或者端上存储特定cookie, 数据隔离: 热点数据使用单独的Cache/DB 热点优化: 系统层(业务代码)对热点做优化, 本机缓存/ 限流等 系统优化(代码): 减少序列化(多在RPC阶段) 字符串优化: 涉及到字符串的IO, OutputStream() 类函数从而减少数据的编码转换 (由于字符串每个字符需要转字节, 这个过程需要查编码表) 去除不必要组件: 去掉MVC (因为MVC的 Chain) 剪裁异常日志堆栈大小 ➤ 一致性: 库存数据的一致性 减库存 在业务层面, 何时减库存? 两种方案 1下单 , 2支付 (两种方案优劣?) 在实际中使用 下单减库存, 下单后有支付超时, 超时后释放库存 如何防止库存为负: 1事务,发现数据为负则回滚, 2数据库字段设置为unsigned, 3 是使用 CASE WHEN 判断语句 一致性的性能优化 读性能: 读链路上可以做”不影响性能”的校验, 一般不在读链路上做一致性校验, 只在写链路做一致性校验 写性能: 1数据库选型(如果不需要事务,或者复杂的减扣逻辑, 可以换内存型KV数据库), 2排队减扣(例如分布式锁) 3专用数据库 ➤ 高可用: 流量削峰: 客户端通过校验等手段, 减少请求 服务端通过 限流 or 消息队列(如何解决积压?) Plan B: 兜底 @ref 从0到1设计一个秒杀系统","categories":[],"tags":[]},{"title":"SystemDesign | 分布式唯一ID方案","slug":"31.Backend/SystemDesign-分布式唯一ID","date":"2024-01-24T01:27:52.692Z","updated":"2024-01-24T01:27:52.693Z","comments":true,"path":"31.Backend/SystemDesign-分布式唯一ID/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/SystemDesign-分布式唯一ID/","excerpt":"","text":"UUID: 版本1: Mac地址+时间戳 版本4: 基于随机数, 可能是伪随机, 例如 java.util.UUID.randomUUID()是版本4的一个实现 Snowflake(Twitter方案): 实现: 64位 = 1位符号 + 41位毫秒时间戳 + 10位机器id + 12序列号 缺陷: 非严格递增, 机器上有多个线程, 如何保证1ms内每个线程生成的序列号不重复? // 可以使用随机数, 时间戳做seed, 多线程使用同一个seed(有没有并发互斥问题?) 实现2: 64位 = 1位符号 + 41位毫秒时间戳 + 10位机器id + 10位进程id + 2位序号 缺陷: 每个线程每毫秒只能生成4个id的限制 mysql自增(Flickr方案): 实现: 8台Mysql, 第一台起始seq=1, 第二台起始seq=2, 每次seq+=8 缺陷: 不是严格递增 @ref: [[SystemDesign-随机数]] 分布式ID生成器 · 系统设计(System Design) 基于Twitter的雪花算法改造，分布式全局唯一ID生成器 - 掘金","categories":[],"tags":[]},{"title":"SystemDesign | 短网址方案","slug":"31.Backend/SystemDesign-短网址方案","date":"2024-01-24T01:27:52.688Z","updated":"2024-01-24T01:27:52.689Z","comments":true,"path":"31.Backend/SystemDesign-短网址方案/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/SystemDesign-短网址方案/","excerpt":"","text":"5个字符的短网址, 能表示多少个URL ? 短网址的构成是大写+小写+数字 = 26+26+10 = 72, 也就是一个字节有72种选择, 假设短网址是5位, 那么能表示多少种网址? $72^5$ 生成方案: 哈希: 缺点冲突 UUID, 存储使用K-v, 短网址是K 常见分布式应用系统设计图解（十三）：短网址系统 – 四火的唠叨","categories":[],"tags":[]},{"title":"SystemDesign | 接口幂等性","slug":"31.Backend/SystemDesign-接口幂等性","date":"2024-01-24T01:27:52.681Z","updated":"2024-01-24T01:27:52.681Z","comments":true,"path":"31.Backend/SystemDesign-接口幂等性/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/SystemDesign-接口幂等性/","excerpt":"","text":"接口幂等性: 多次调用接口, 与调用一次接口最终结果一致(或者说产生相同的作用) RESTful标准的 Http接口 （ =&gt; SystemDesign-RESTful）: GET: 查询, 符合幂等 POST: 创建, 不应设计为幂等 PUT: 更新, 应设计为幂等 DELETE: 删除, 应设计为幂等 工程如何实现: 如果是余额减扣（防止客户端误点击产生重复扣款）: 第一次请求从server端取得唯一id, 第二次请求带着唯一id进行减扣, 服务端可以存Redis或者通过Mysql唯一索引对这个id去重 （或者每次本地动作都用uuid生成一次） 如果订单支付这种有唯一id的场景, 可以使用订单id去重, 或者通过订单的状态机 @ref 理解HTTP幂等性 - Todd Wei - 博客园 SystemDesign-RESTful","categories":[],"tags":[]},{"title":"SystemDesign | 缓存","slug":"31.Backend/SystemDesign-缓存设计","date":"2024-01-24T01:27:52.677Z","updated":"2024-01-24T01:27:52.677Z","comments":true,"path":"31.Backend/SystemDesign-缓存设计/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/SystemDesign-缓存设计/","excerpt":"缓存穿透: 布隆过滤器, 写null数据, 缓存雪崩: 加随机过期时间 缓存击穿: 某条缓存失效的时候, 正好有大量并发读这个key, 访问量都落在了数据库// 解决: 准备load db时, 先 Setnx k, @ref redis缓存穿透，缓存击穿，缓存雪崩原因+解决方案 - 知乎 ➤ 缓存的一致性问题, 指的是Cache/DB出现不一致数据，其根本原因是 “读写Cache” 和”读写DB”不是原子的. ➤ 解决缓存一致性方案: 方案1: 读: 先读cache, 读不到则查db, 然后把db查询结果写入cache; 更新: 更新db, 删除cache; 可能存在的问题: 两个读线程, A读到了V1数据然后休眠, 这时候B线程修改了数据, 版本为V2, 线程A醒来, 把先前读到的V1写入Cache 方案2: 方式1的更新操作改为延迟双删: updateDB, delCache, sleep(1s), delCache 方案3: cache订阅DB的binlog","text":"缓存穿透: 布隆过滤器, 写null数据, 缓存雪崩: 加随机过期时间 缓存击穿: 某条缓存失效的时候, 正好有大量并发读这个key, 访问量都落在了数据库// 解决: 准备load db时, 先 Setnx k, @ref redis缓存穿透，缓存击穿，缓存雪崩原因+解决方案 - 知乎 ➤ 缓存的一致性问题, 指的是Cache/DB出现不一致数据，其根本原因是 “读写Cache” 和”读写DB”不是原子的. ➤ 解决缓存一致性方案: 方案1: 读: 先读cache, 读不到则查db, 然后把db查询结果写入cache; 更新: 更新db, 删除cache; 可能存在的问题: 两个读线程, A读到了V1数据然后休眠, 这时候B线程修改了数据, 版本为V2, 线程A醒来, 把先前读到的V1写入Cache 方案2: 方式1的更新操作改为延迟双删: updateDB, delCache, sleep(1s), delCache 方案3: cache订阅DB的binlog @ref redis 双写一致性 看一篇成高手系列1_数据库_hjm4702192的专栏-CSDN博客","categories":[],"tags":[]},{"title":"SystemDesign | 延迟队列方案","slug":"31.Backend/SystemDesign-延迟队列","date":"2024-01-24T01:27:52.673Z","updated":"2024-01-24T01:27:52.673Z","comments":true,"path":"31.Backend/SystemDesign-延迟队列/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/SystemDesign-延迟队列/","excerpt":"","text":"为什么需要延迟队列? 单机延迟队列: 优先队列 // 该方式, 或者 Redis Zset这种方式的问题? 轮询线程Sleep后, 插入了一个需要马上处理的任务 DelayQueue: @todo HashedWheelTimer(时间轮算法): 环形数组共n个元素, 每个元素表示一个单位时间(例如1s), 同时每个元素是一个”桶”, 指向一个链表, 链表里保存的是该秒要执行的任务. 如果放入一个x秒后执行的新任务, x大于n, 当前运行指针指向第3个元素, 那么放入数组第几个桶里呢? index = x%n + 3, 同时链表中的每个任务都保存圈数这个字段,每次指针经过这个桶, 桶中所有任务的圈数都-1, 如果圈数=0则表示要执行; 分布式延迟队列: Redis : blpop/brpop RabbitMQ : Dead Letter Exchange 关于 HashedWheelTimer:根据 George Varghese 和 Tony Lauck 1996 年的论文《Hashed and Hierarchical Timing Wheels: data structures to efficiently implement a timer facility》提出了一种定时轮的方式来管理和维护大量的 timer 调度。Netty 的定时任务调度就是基于时间轮算法调度 … @ref: https://www.infoq.cn/article/netty-threading-model","categories":[],"tags":[]},{"title":"SystemDesign | 负载均衡 | 总结：方案及算法","slug":"31.Backend/SystemDesign-负载均衡-算法","date":"2024-01-24T01:27:52.668Z","updated":"2024-01-24T01:27:52.669Z","comments":true,"path":"31.Backend/SystemDesign-负载均衡-算法/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/SystemDesign-负载均衡-算法/","excerpt":"➤ 常用LB方案: DNS 负载均衡 四层(传输层)负载均衡: SystemDesign-负载均衡-LVS 七层(应用层)负载均衡: SystemDesign-负载均衡-Nginx] 硬件负载均衡: F5, A10 ➤ 常用LB算法: 静态LB算法 (基于算法, 不考虑后端服务器状态) 随机: Random 轮询: Round Robin 加权轮询: Weighted Round Robin 哈希: HASH, 包括源地址哈希, 目标地址哈希, 应用层LB也可以使用URL或者自定义Key进行哈希 动态LB算法 (基于后端服务器状态动态调整) 最小连接: 最小耗时: ➤ 代码:","text":"➤ 常用LB方案: DNS 负载均衡 四层(传输层)负载均衡: SystemDesign-负载均衡-LVS 七层(应用层)负载均衡: SystemDesign-负载均衡-Nginx] 硬件负载均衡: F5, A10 ➤ 常用LB算法: 静态LB算法 (基于算法, 不考虑后端服务器状态) 随机: Random 轮询: Round Robin 加权轮询: Weighted Round Robin 哈希: HASH, 包括源地址哈希, 目标地址哈希, 应用层LB也可以使用URL或者自定义Key进行哈希 动态LB算法 (基于后端服务器状态动态调整) 最小连接: 最小耗时: ➤ 代码: 加权轮询: → Nginx 平滑基于权重的轮询算法实现 SystemDesign-负载均衡-Nginx","categories":[],"tags":[]},{"title":"SystemDesign | 负载均衡 | Nginx","slug":"31.Backend/SystemDesign-负载均衡-Nginx","date":"2024-01-24T01:27:52.664Z","updated":"2024-01-24T01:27:52.664Z","comments":true,"path":"31.Backend/SystemDesign-负载均衡-Nginx/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/SystemDesign-负载均衡-Nginx/","excerpt":"➤ Nginx(7层反向代理)提供的几种负载均衡算法实现: 随机 : 轮询 : 加权轮询 : 源ip哈希 ip_hash : 使用Client端的IP进行Hash 通用哈希 hash $key : 使用自定义的key进行Hash, 也支持一致性哈希hash $key consistent, 一致性哈希一般用于后端服务器是缓存时, 例如使用请求URL进行一致性Hash: hash $request_uri consistent, 最小连接 least_conn : 请求将被发送给 活动连接数最小的后端服务器 最小耗时 least_time : 请求将被发送给 平均耗时最小的后端服务器, 平均耗时有两种计算方式: 从后端服务器收到第一个字节least_time header, 或从后端服务器收到完整请求least_time last_byte @ref NGINX Docs | HTTP Load Balancing ➤ Nginx 平滑基于权重的轮询算法实现 初始化: 每个节点当前权重 = 初始权重; 第一轮选择节点, 选择当前权重最大的, 被选择的节点的”当前权重”发生变化 = 当前权重-权重总和, 未选中节点的”当前权重”不变; 第二轮选择节点, 每个节点的权重 = 每个节点初始权重+ 上一轮的最终权重; 综上, 每次节点被选中, 它的当前权重会减少(-总权重), 进入下一轮后, 每个节点都把上轮权重+自己的初始权重, 然后开始选择;","text":"➤ Nginx(7层反向代理)提供的几种负载均衡算法实现: 随机 : 轮询 : 加权轮询 : 源ip哈希 ip_hash : 使用Client端的IP进行Hash 通用哈希 hash $key : 使用自定义的key进行Hash, 也支持一致性哈希hash $key consistent, 一致性哈希一般用于后端服务器是缓存时, 例如使用请求URL进行一致性Hash: hash $request_uri consistent, 最小连接 least_conn : 请求将被发送给 活动连接数最小的后端服务器 最小耗时 least_time : 请求将被发送给 平均耗时最小的后端服务器, 平均耗时有两种计算方式: 从后端服务器收到第一个字节least_time header, 或从后端服务器收到完整请求least_time last_byte @ref NGINX Docs | HTTP Load Balancing ➤ Nginx 平滑基于权重的轮询算法实现 初始化: 每个节点当前权重 = 初始权重; 第一轮选择节点, 选择当前权重最大的, 被选择的节点的”当前权重”发生变化 = 当前权重-权重总和, 未选中节点的”当前权重”不变; 第二轮选择节点, 每个节点的权重 = 每个节点初始权重+ 上一轮的最终权重; 综上, 每次节点被选中, 它的当前权重会减少(-总权重), 进入下一轮后, 每个节点都把上轮权重+自己的初始权重, 然后开始选择; @ref nginx平滑的基于权重轮询算法分析 | tenfy’ blog","categories":[],"tags":[]},{"title":"SystemDesign | 负载均衡 | LVS","slug":"31.Backend/SystemDesign-负载均衡-LVS","date":"2024-01-24T01:27:52.660Z","updated":"2024-01-24T01:27:52.660Z","comments":true,"path":"31.Backend/SystemDesign-负载均衡-LVS/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/SystemDesign-负载均衡-LVS/","excerpt":"➤ LVS, Linux Virtual Server, 即Linux虚拟服务器: LVS是工作于 ISO网络模型第四层的反向代理, 核心功能「IPVS」是 Linux Kernel的一个模块; LVS由 「IPVS」和「IPVSADM」组成, 前者工作在内核态负责数据路由, 后者工作在用户态负责选项的设置; LVS工作在 「Director Server」, Director Server对外提供虚拟IP(Virtual IP, 简称VIP), 客户端的请求发往VIP, 请求数据经过 Director Server的内核态, 通过IPVSADM设置的路由规则, 最终被发送给真实服务器IP(Real IP, 简称RIP); 附图: LVS工作原理 &amp; LVS内核模型如下 1.当客户端的请求到达负载均衡器的内核空间时，首先会到达PREROUTING链。2.当内核发现请求数据包的目的地址是本机时，将数据包送往INPUT链。3.LVS由用户空间的ipvsadm和内核空间的IPVS组成，ipvsadm用来定义规则，IPVS利用ipvsadm定义的规则工作，IPVS工作在INPUT链上,当数据包到达INPUT链时，首先会被IPVS检查，如果数据包里面的目的地址及端口没有在规则里面，那么这条数据包将被放行至用户空间。4.如果数据包里面的目的地址及端口在规则里面，那么这条数据报文将被修改目的地址为事先定义好的后端服务器，并送往POSTROUTING链。5.最后经由POSTROUTING链发往后端服务器。 ➤ LVS提供如下几种负载均衡调度算法:","text":"➤ LVS, Linux Virtual Server, 即Linux虚拟服务器: LVS是工作于 ISO网络模型第四层的反向代理, 核心功能「IPVS」是 Linux Kernel的一个模块; LVS由 「IPVS」和「IPVSADM」组成, 前者工作在内核态负责数据路由, 后者工作在用户态负责选项的设置; LVS工作在 「Director Server」, Director Server对外提供虚拟IP(Virtual IP, 简称VIP), 客户端的请求发往VIP, 请求数据经过 Director Server的内核态, 通过IPVSADM设置的路由规则, 最终被发送给真实服务器IP(Real IP, 简称RIP); 附图: LVS工作原理 &amp; LVS内核模型如下 1.当客户端的请求到达负载均衡器的内核空间时，首先会到达PREROUTING链。2.当内核发现请求数据包的目的地址是本机时，将数据包送往INPUT链。3.LVS由用户空间的ipvsadm和内核空间的IPVS组成，ipvsadm用来定义规则，IPVS利用ipvsadm定义的规则工作，IPVS工作在INPUT链上,当数据包到达INPUT链时，首先会被IPVS检查，如果数据包里面的目的地址及端口没有在规则里面，那么这条数据包将被放行至用户空间。4.如果数据包里面的目的地址及端口在规则里面，那么这条数据报文将被修改目的地址为事先定义好的后端服务器，并送往POSTROUTING链。5.最后经由POSTROUTING链发往后端服务器。 ➤ LVS提供如下几种负载均衡调度算法: Round Robin Weight Round Robin Destination Hash: 目标ip地址哈希, LVS采用了素数乘法Hash函数, 如下 static inline unsigned hashkey(unsigned int dest_ip)&#123; // 2654435761UL是2到2^32 (4294967296)间接近于黄金分割的素数 return (dest_ip* 2654435761UL) &amp; HASH_TAB_MASK;&#125; Source Hash: 请求的来源ip哈希 Least Connections: 最小连接 Weight Least Connections: 带权重的最小连接 // LVS默认 Shortest Expected Delay: 最小期望延迟 locality-Based Least Connections: 基于局部性的最少链接 Locality-Based Least Connections with Replication: 带复制的基于局部性最少连接 @ref: 基于局部性的最少链接（Locality-Based Least Connections Scheduling） | LVS中文站点 带复制的基于局部性最少链接（Locality-Based Least Connections with Replication Scheduling） | LVS中文站点 ➤ LVS工作模式 @todo @ref: LVS原理知多少？ - 云+社区 - 腾讯云","categories":[],"tags":[]},{"title":"SystemDesign-熔断器-Polaris","slug":"31.Backend/SystemDesign-熔断器-Polaris","date":"2024-01-24T01:27:52.656Z","updated":"2024-01-24T01:27:52.656Z","comments":true,"path":"31.Backend/SystemDesign-熔断器-Polaris/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/SystemDesign-熔断器-Polaris/","excerpt":"tldr: 客户端上报调用服务端的结果(成功,失败,超时..) 服务端(北极星)为每个提供服务的节点, 维护一个熔断器 熔断器的状态(关闭, 打开)是根据滑动窗口内的成功率计算的 很多时候，服务端（provider）本身并不能检测到自身的异常。如主调方（consumer）调用时不断收到错误返回，但服务端仍旧保持工作状态中。这种情况下应该暂时屏蔽掉此实例，以减少错误返回。由此引入了故障熔断功能。 故障熔断功能主要是为了屏蔽错误实例，防止错误扩散影响整体服务质量。北极星提供的是故障数目的统计与处理，因此强依赖于主调方对调用结果的数据上报。熔断器状态设计参考Martin Fowler提出的熔断器模型，将每一个节点实例与一个熔断器绑定，熔断器状态如下图所示。 @ref: https://martinfowler.com/bliki/CircuitBreaker.html","text":"tldr: 客户端上报调用服务端的结果(成功,失败,超时..) 服务端(北极星)为每个提供服务的节点, 维护一个熔断器 熔断器的状态(关闭, 打开)是根据滑动窗口内的成功率计算的 很多时候，服务端（provider）本身并不能检测到自身的异常。如主调方（consumer）调用时不断收到错误返回，但服务端仍旧保持工作状态中。这种情况下应该暂时屏蔽掉此实例，以减少错误返回。由此引入了故障熔断功能。 故障熔断功能主要是为了屏蔽错误实例，防止错误扩散影响整体服务质量。北极星提供的是故障数目的统计与处理，因此强依赖于主调方对调用结果的数据上报。熔断器状态设计参考Martin Fowler提出的熔断器模型，将每一个节点实例与一个熔断器绑定，熔断器状态如下图所示。 @ref: https://martinfowler.com/bliki/CircuitBreaker.html 熔断器必定处于以下三种状态之一： Closed状态：节点正常工作下熔断器的状态，熔断器处于关闭中，不产生任何效果。 Open状态：当北极星“频繁”接收到主调方上报的调用失败信息后，会将熔断器打开，此时节点已被“熔断”，不再提供服务。频繁的定义取决于下面所介绍的滑桶算法来统计数据。此外，用户主动在北极星上为某个节点实例打开“隔离”选项时，也相当于将熔断器状态设置为Open。 Half Open状态：中间状态，当熔断器Open一段时间后（主动打开隔离选项的除外），北极星会将熔断器设置为半开状态，处理少量的主调方请求，如果正常工作，则后续转变成Close状态，如果失败，则会依旧将其转变为Open状态，然后重复此过程。 滑桶算法:算法维持过去一段时间内的服务调用结果，根据每个时间单元（图示桶单元）统计四项数据：Success，Failure，Timeout，Rejection。将此段时间看作一个滑动窗口，窗口的大小是固定的，因此当一个新的时间单元被创建时，最旧的那个时间单元即被废弃。北极星统计每个窗口的调用失败率，超时量等信息，据此决定熔断器状态。","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"SystemDesign | 熔断器 | Hystrix","slug":"31.Backend/SystemDesign-熔断器-Hystrix","date":"2024-01-24T01:27:52.652Z","updated":"2024-01-24T01:27:52.652Z","comments":true,"path":"31.Backend/SystemDesign-熔断器-Hystrix/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/SystemDesign-熔断器-Hystrix/","excerpt":"@toc: Hystrix [hɪst’rɪks] 提供了哪些功能? 使用 Hystrix API创建隔离器的步骤; Hystrix 熔断的触发判定, 以及半开状态是怎样的? Hystrix 提供的信号量隔离与线程池隔离的比较? ➤ Hystrix [hɪst’rɪks] 提供了哪些功能? 提供线程池隔离 // 信号量隔离 降级: 超时 or 资源不足(线程池,信号量), 降级后可返回降级接口的托底数据 熔断: 错误率达到阈值进行熔断, 触发快速失败, 以及自动回恢复的功能 @ref 《亿级流量》","text":"@toc: Hystrix [hɪst’rɪks] 提供了哪些功能? 使用 Hystrix API创建隔离器的步骤; Hystrix 熔断的触发判定, 以及半开状态是怎样的? Hystrix 提供的信号量隔离与线程池隔离的比较? ➤ Hystrix [hɪst’rɪks] 提供了哪些功能? 提供线程池隔离 // 信号量隔离 降级: 超时 or 资源不足(线程池,信号量), 降级后可返回降级接口的托底数据 熔断: 错误率达到阈值进行熔断, 触发快速失败, 以及自动回恢复的功能 @ref 《亿级流量》 ➤ 创建Hystrix 隔离/熔断器的 API和步骤? 创建 一个 HystrixCommand (cmd的参数有: groupKey, commandKey, threadPoolProperties) 同步调用: HystrixCommand.execute(); 异步调用: Future f = HystrixCommand.queue(); 降级(兜底数据): 覆写 HystrixCommand.getFallback()即可, 返回兜底数据 熔断: 需要设置的参数: circuitBreakerRequestVolumeThreshold, circuitBreakerErrorThresholdPercentage (触发熔断的最少错误的请求个数, 失败比例) 线程池属性: 和Java 线程池稍有不同, Hystrix定义了两个参数 maxQueueSize &amp; queueSizeRejectionThreashold, 前者和后者分别是队列最大大小/队列拒绝上限, 后者可以灵活的设定 ➤ Hystrix 熔断的触发判定, 以及半开状态是怎样的? 使用滑动时间窗口来记录每个时间片内相关熔断计数指标及熔断器状态，时间片段称作为一个bucket，默认维护10个bucket，每1秒一个bucket，随着时间的滚动，最早的bucket抛弃，创建新的bucket到滑动窗口右边。 每个blucket记录请求总数、成功数、超时数、拒绝数及熔断器状态，默认错误超过50％且10秒内超过20个请求进行中断拦截。 当调用的失败比例高出阈值(可能意味着下游服务出现问题, 如果此时再继续正常流程的retry机制, 会进一步恶化下游服务), 触发熔断后, 熔断器开启并休眠一段时间, 此时再调用 HystrixCommand会返回 failfast , 休眠之后熔断器进入 half-open状态, 试探性放过一部分流量, 如果调用成功则关闭熔断器; @ref 微服务熔断隔离机制及注意事项 - 用友云平台 - 博客园 @ref 使用hystrix保护你的应用 - Kris的博客 | Kris’ Blog ➤ Hystrix 提供的信号量隔离与线程池隔离的比较? 除了线程池隔离, Hystrix 还提供了信号量隔离 : 可以创建一个 HystrixProperties, 并设置 IsolationStrategy=SEMAPHORE, 设置 MaxConcurrentRequest=N(信号量大小); 调用者线程不会再往 Hystrix线程池提交任务, 而是直接在调用者线程池直接执行, (每调用一次-1, 调用完成+1); 信号量隔离的作用是限制并发数, 更适合非网络请求; 信号量隔离没有缓冲队列, 无法很好的应对突发流量的情况;","categories":[],"tags":[]},{"title":"SystemDesign | 限流 | 概述","slug":"31.Backend/SystemDesign-限流-算法","date":"2024-01-24T01:27:52.647Z","updated":"2024-01-24T01:27:52.648Z","comments":true,"path":"31.Backend/SystemDesign-限流-算法/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/SystemDesign-限流-算法/","excerpt":"","text":"漏桶: 固定速率出桶, 桶满了再进入的流量被抛弃, 缺点: 队列使请求的处理变成单队列, 有大量突发流量时, 就算桶是空的, 仍需要排队 令牌桶: 固定速率向桶中存放令牌, 如果桶满了令牌会被丢弃, 每个请求到来先从桶里请求令牌 滑动窗口: 防止突发流量 [[SystemDesign-限流-分布式限流]][[SystemDesign-限流-GuavaRateLimiter]]","categories":[],"tags":[]},{"title":"SystemDesign-RESTful","slug":"31.Backend/SystemDesign-RESTful","date":"2024-01-24T01:27:52.643Z","updated":"2024-01-24T01:27:52.644Z","comments":true,"path":"31.Backend/SystemDesign-RESTful/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/SystemDesign-RESTful/","excerpt":"","text":"REST: 把对外提供的服务抽象为某种资源(User/Order), 通过HTTP的 GET/POST/DELETE/PUT方法对资源对象进行操作, 满足这几个条件的服务, 可以称为 #RESTful 的 (Representional State Transfer) @ref: RESTful API 设计指南 - 阮一峰的网络日志：https://www.ruanyifeng.com/blog/2014/05/restful_api.html","categories":[],"tags":[]},{"title":"C100K系统设计","slug":"31.Backend/SystemDesign-01-C100K","date":"2024-01-24T01:27:52.639Z","updated":"2024-01-24T01:27:52.639Z","comments":true,"path":"31.Backend/SystemDesign-01-C100K/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/SystemDesign-01-C100K/","excerpt":"本篇只讨论OS 级别的并发优化，不包括语言层面对并发的支持特性，C10 K / C100 K / C1000 K（百万） 都是指单服务器下，能够支持的空闲长连接的数量。 一般情况下服务端达到 C10K 连接时，大多数连接都是空闲连接，少数的活跃连接有数据读写，这种情况下讨论 C10K 的瓶颈在于“如何管理 10K-100K 级别的连接数”。 如果 C10K 的连接情况下，每个链接还有大量的读写数据，瓶颈就不仅仅是上面的“单机管理 10k-100k 数量级的 Connection”了，这种情况下，网卡、带宽都可能成为瓶颈，所以本文只考虑上面的情况“连接大多空闲、少数活跃”。 有关 Linux 系统的限制服务器能支持建立连接数由几个决定：","text":"本篇只讨论OS 级别的并发优化，不包括语言层面对并发的支持特性，C10 K / C100 K / C1000 K（百万） 都是指单服务器下，能够支持的空闲长连接的数量。 一般情况下服务端达到 C10K 连接时，大多数连接都是空闲连接，少数的活跃连接有数据读写，这种情况下讨论 C10K 的瓶颈在于“如何管理 10K-100K 级别的连接数”。 如果 C10K 的连接情况下，每个链接还有大量的读写数据，瓶颈就不仅仅是上面的“单机管理 10k-100k 数量级的 Connection”了，这种情况下，网卡、带宽都可能成为瓶颈，所以本文只考虑上面的情况“连接大多空闲、少数活跃”。 有关 Linux 系统的限制服务器能支持建立连接数由几个决定： 建立 TCP 连接最大并发数：TCP 连接四元组是由源 IP 地址、源端口、目的 IP 地址和目的端口构成，参考 [[#端口数量限制]] 端口数限制：TCP 协议中使用 Unsigned Short 表示端口，理论最大端口65535，参考 [[#端口数量限制]] 打开文件描述符数量上限：Linux 中每打开一个 Socket 都占用进程的文件描述符，参考 [[#进程最大打开文件数]] 对于多进程/多线程模型的应用，系统能创建的进线程上限也会影响到并发数，参考 [[#最大进线程数]] 建立一条 TCP 连接的内存开销，也影响连接数的上限：Linux 为内核对象申请空间使用 Slab 机制，在 Linux 3.10.0 版本中，创建一个 socket 需要消耗 densty、flip、sock_inode_cache、TCP 四个内核对象。这些对象加起来总共需要消耗大约 3 KB 多一点的内存； 服务器端应用层设置：Nginx、Apache、Tomcat 都有各自的最大并发数限制选项 进程最大打开文件数Linux 中每打开一个 Socket 都占用进程的文件描述符，使用 ulimit 设置最多能打开文件数: ulimit 起作用的范围是”当前 Shell”, 并不是作用于”当前用户”, 即使用 ulimit 修改了当前限制，使用同一个用户在新的 shell 中登录，之前修改的值不生效。 查看所有的限制: ulimit -a 设置最大打开文件句柄数: ulimit -n 65535 设置 每个用户的 最大进程数: ulimit -u 32768 设置线程栈的大小: ulimit -s 10240 设置最大线程数数: ulimit -T (在 Unix 上可能不同) 设置产生 core 文件大小: ulimit -c xxx 不限制 core 的大小: ulimit -c unlimited 如要对”用户”级别做限制, 则需要修改系统文件 /etc/security/limits.conf: # * 表示所有用户, nofile表示限制文件打开数, 限制在100# 注意 [hard nofile]一定要比 fs.nr_open 要小，否则可能导致用户无法登陆* soft nofile 55000 * hard nofile 100 如果是针对整个系统, 则需要使用 sysctl 修改, 命令格式为: sysctl -w fs.nr_open=10000000, 每个系统参数对应一个/proc 下的文件, fs.nr_open 对应的文件路径是 /proc/sys/fs/nr_open系统最大打开文件数相关的参数有两个: fs.nr_open，进程级别 fs.file-max，系统级别 至此总结一下, “Linux 系统最多能打开文件数” 有当前 shell, 进程, 用户, 系统三个级别,shell 级别的更改限制命令是 ulimit,用户级别更改 limits.conf 文件，而更改进程/系统级别限制的命令是 sysctl（fs.nr_open, fs.file-max） 限制优先级最大的是 fs.file-max, 假如 fs.file-max 设置为 100 万, ulimit 是不能超过 100万的. cat /proc/sys/fs/file-nr, 输出 9344 0 592026，分别为：1.已经分配的文件句柄数，2.已经分配但没有使用的文件句柄数，3.最大文件句柄数file-nr 不是单个进程的限制, 是系统级的, 最后一个数字与 file-max 相同 ➤ 系统打开文件数有上限吗？还没查到靠谱的资料，参考 RH6 手册，对于文件的限制，只有最大文件大小、最多子目录的数量等待，没有提到打开文件数 Red Hat Enterprise Linux 的技术能力和限制 - Red Hat Customer Portal ➤ 如何查看已创建文件描述符数? 某进程打开文件数 ll /proc/1599/fd | wc -l 系统全部打开的文件数 lsof | wc -l 某进程打开 socket 的数量: ll /proc/1599/fd | grep socket | wc -l # nginx 一个 worker 打开了 200-300 个 socket 其他： 系统全部打开的 TCP 连接数 lsof | grep TCP | wc -l 查看 TCP 不同状态连接数: netstat -n | awk &#39;/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}&#39; 注意处于 TIME_WAIT 的链接, 如果这个数过高会占用大量连接, 应该调整参数尽快的释放 time_wait 连接 在 Nginx 机器上测试: [@zw_85_63 ~]# netstat -n | awk &apos;/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;&apos;TIME_WAIT 37968SYN_SENT 1FIN_WAIT1 5FIN_WAIT2 4ESTABLISHED 2725SYN_RECV 18LAST_ACK 4 端口数量限制TCP 协议中使用 Unsigned Short 表示端口，所以 TCP 理论最大可用端口数量有 65535 个，但是一般的系统里 1024 以下的端口都是保留的，可用的大约就是 64 k 个. 默认情况下，Linux 只开启了 3 万多个可用端口： #vi /etc/sysctl.confnet.ipv4.ip_local_port_range = 5000 65000 但对于服务端，端口数不是问题，因为一个监听的端口可以复用，对于客户端，端口其实也是可以复用的，但还是有四元组的限制（举例，如果 Client 用一个端口，那么 dst_ip dst_port 的组合不能相同） 四元组相关的代码, 参考 net/ipv4/inet_hashtables.c 下的 INET_MATCH 宏 如果 Client 只连接一个 Server（这种情况下 dst_ip 和 dst_port 被固定了），那么作为 Client 只能一个 port 建立一个连接了，也就受到 TCP 协议端口数上限的限制。如果 Client 启动大量并发线程去连接 Server，这时候可能遇到一个问题：TIME_WAIT 状态的连接过多，当端口资源被耗尽，就无法与这个服务器再建立连接了。 但有个优化选项：打开 net.ipv4.tcp_tw_reuse 这个内核参数，客户端调用 connect 函数时，如果选择到的端口，已经被相同四元组的连接占用的时候，就会判断该连接是否处于 TIME_WAIT 状态，如果该连接处于 TIME_WAIT 状态并且 TIME_WAIT 状态持续的时间超过了 1 秒，那么就会重用这个连接，然后就可以正常使用该端口了。 最大进线程数某些服务程序(Apache, Tomcat) 采用 “Thread Per Request”, 系统的进线程最大数也会影响并发性能. Linux 没有 直接限制 每个进程能够创建线程数, 仅限制了系统最大进线程数, 相关的配置有 : 仅对当前 shell 有效: ulimit -u 102400, -u 表示 “max user processes”; 系统级别有效: 临时生效: echo 102400 &gt; /proc/sys/kernel/threads-max 或 sysctl -w sys.kernel.threads-max=10240 ; 永久生效: 修改 /etc/sysctl.conf 文件; 这里的 threads-max 不是指进程, 是 “maximum number of threads that can be created using fork()”,@ref https://www.kernel.org/doc/Documentation/sysctl/kernel.txt 每个进程能创建的最大线程数, 是由 total virtual memory 和 stack size 共同决定的, number of threads = total virtual memory / stack size这两个参数分别用 ulimit -v xxx 和 ulimit -s xxx 设置 此外系统能创建最大进程数还受 kernel.pid_max 影响: 方式1 运行时限制,临时生效 echo 999999 &gt; /proc/sys/kernel/pid_max 方式2 修改/etc/sysctl.conf，永久生效 sys.kernel.pid_max = 999999 但是线程数没限制不代表”Thread Per Request”可以行得通，如果创建了百万级的线程，上下文切换对 CPU 的调度也是考验 应用程序的设置首先考虑，服务端程序（Ngx、Redis、Tomcat 等）采用哪种 IO 线程模型？ 如果是 BIO（比如较早版本的 Tomcat ，当然现在很少有 BIO 实现的服务了），一般采用的是 Connection pre thread 的方式，意味着需要起 10K-100K 线程，所以 BIO 模式直接 pass 如果是多路复用，那还要看是用的 select ？poll？epoll？select 和 poll 都无法胜任 C10K，只有 epoll 可以，原因见 [[../21.Operating-System/APUE.07b.网络编程-多路复用epoll]]， 当然现在的服务端 Ngx、Redis 、Java 的 Netty 等都用的是 epoll，少数系统上可能会用 select、kqueue 等，Nginx &amp; Redis 的线程模型解析=&gt; [[../21.Operating-System/APUE.07d.服务端常用IO模型]] nginx worker_rlimit_nofile 65535; // 一个 nginx 进程打开的最多文件描述符数目 listen 8080 backlog=168888; // accept 成功队列长度，用于 listen(int sockfd, int backlog)，默认值 511 worker_connections= //每个 worker 线程能创建的连接数 upstream 可以使用 http 1.1的 keepalive //与后端服务器创建的连接池大小 worker_processes 8; // nginx 进程数，一般等于 cpu core 数量 worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000; // 每个进程分配到 cpu 的 core 上 redis@todo apache默认是多进程同步处理 request, 所以思路和 Nginx 每个 Core 一个进程 epoll 轮询的方式不同, apache 应该增加”系统创建进程数上限”, 并且减小进程栈内存 tomcatTomcat 也提供 NIO 模式（epoll + 非阻塞 IO），但 Tomcat 是个“跑业务代码”的服务，业务代码比较耗费时间（各种 CRUD），所以 Tomcat 注定不能像 Nginx 那样，在 epoll 线程里处理所有。 Tomcat 采用的是 1 个线程 accept，多个线程（ core 数的 2 倍个）监听已建连接的 IO 事件，收到一个 Http Req 则扔进线程池处理，线程池大小默认几百。参考 [[../13.JavaEE-Framework/JavaEE.Tomcat]]] maxThreads=500，业务线程池大小，此值限制了 bio 的最大连接数 一般的当一个进程有 500 个线程在跑的话，那性能已经是很低很低了。Tomcat 默认配置的最大请求数是 150。当某个应用拥有 250 个以上并发的时候，应考虑应用服务器的集群。 acceptCount：默认是 100 maxConnection=10000: NIO 模式下的默认值是 1w（可以认为所有 Poller 线程用 epoll 监听）可以适当调大，因为大多数连接都已建立但空闲 Tomcat 的 maxThreads 、acceptCount、maxConnection 的解析参考 @ref [[../13.JavaEE-Framework/JavaEE.Tomcat#性能优化]] 性能优化一节。 FastCGI fastcgi_connect_timeout 300; 高并发配置-无废话总结 应用程序的并发设置: 主要是 timeout, 进/线程数这几类参数 操作系统打开文件数量限制: ulimit -n 单个 Shell 环境的限制, sysctl -w fs.file-max 修改系统打开文件限制 操作系统打开端口数量限制: 最大端口数 65535(2^16), 但 1024 以后的端口是给系统用的 sysctl 修改的 TCP 协议栈参数 并发性能测试工具ab(Apache Bench)1000并发, 总共20000次请求: ab -n 20000 -c 1000 &lt;url&gt; http_load30个并发线程, 共60秒测试: http_load -p 30 -s 60 Url.txt JMeter配置@todo 测试@todo 报告在聚合报告中，会显示一行数据，共有 10 个字段，含义分别如下。 Label：每个 JMeter 的 element（例如 HTTP Request）都有一个 Name 属性，这里显示的就是 Name 属性的值 Samples：表示你这次测试中一共发出了多少个请求，如果模拟 10 个用户，每个用户迭代 10 次，那么这里显示 100 Average：平均响应时间——默认情况下是单个 Request 的平均响应时间，当使用了 Transaction Controller 时，也可以以 Transaction 为单位显示平均* 响应时间 Median：中位数，也就是 50％ 用户的响应时间 90% Line：90％ 用户的响应时间 Min：最小响应时间 Max：最大响应时间 Error%：本次测试中出现错误的请求的数量/请求的总数 Throughput：吞吐量——默认情况下表示每秒完成的请求数（Request per Second） KB/Sec：每秒从服务器端接收到的数据量，相当于 LoadRunner 中的 Throughput/Sec 参考: 使用JMeter进行负载测试——终极指南 - ImportNew @ref wrkwg/wrk: Modern HTTP benchmarking tool 参考 系统负载能力浅析 一台主机上只能保持最多 65535 个 TCP 连接吗？ - 知乎 通过 ulimit 改善系统性能 @Archived 怎样增大 Linux 系统的 open file(s) 上限 nginx优化 突破十万并发 Linux IO模式及 select、poll、epoll详解 使用 libevent 和 libev 提高网络应用性能","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[{"name":"后端架构","slug":"后端架构","permalink":"https://beefyheisenberg.github.io/tags/后端架构/"},{"name":"并发","slug":"并发","permalink":"https://beefyheisenberg.github.io/tags/并发/"},{"name":"性能测试","slug":"性能测试","permalink":"https://beefyheisenberg.github.io/tags/性能测试/"},{"name":"C10K","slug":"C10K","permalink":"https://beefyheisenberg.github.io/tags/C10K/"},{"name":"C100K","slug":"C100K","permalink":"https://beefyheisenberg.github.io/tags/C100K/"},{"name":"ulimit","slug":"ulimit","permalink":"https://beefyheisenberg.github.io/tags/ulimit/"}]},{"title":"后端架构：System Design","slug":"31.Backend/SystemDesign-00-亿级流量网站架构","date":"2024-01-24T01:27:52.634Z","updated":"2024-01-24T01:27:52.635Z","comments":true,"path":"31.Backend/SystemDesign-00-亿级流量网站架构/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/SystemDesign-00-亿级流量网站架构/","excerpt":"一些概念和测试基准本章内容包括: 系统可用性的概念和指标, 系统性能的概念和指标, 如何严谨地做性能测试. 系统可用性的概念和指标高可用性（high availability，缩写为 HA），IT术语，指系统无中断地执行其功能的能力，代表系统的可用性程度。是进行系统设计时的准则之一。高可用性系统与构成该系统的各个组件相比可以更长时间运行其度量方式，是根据系统损害、无法使用的时间，以及由无法运作恢复到可运作状况的时间，与系统总运作时间的比较。计算公式为: A（可用性），MTBF(平均故障间隔)，MDT(平均修复时间)在线系统和执行关键任务的系统通常要求其可用性要达到5个9标准(99.999%)。","text":"一些概念和测试基准本章内容包括: 系统可用性的概念和指标, 系统性能的概念和指标, 如何严谨地做性能测试. 系统可用性的概念和指标高可用性（high availability，缩写为 HA），IT术语，指系统无中断地执行其功能的能力，代表系统的可用性程度。是进行系统设计时的准则之一。高可用性系统与构成该系统的各个组件相比可以更长时间运行其度量方式，是根据系统损害、无法使用的时间，以及由无法运作恢复到可运作状况的时间，与系统总运作时间的比较。计算公式为: A（可用性），MTBF(平均故障间隔)，MDT(平均修复时间)在线系统和执行关键任务的系统通常要求其可用性要达到5个9标准(99.999%)。 3个9：(1-99.9%) x 365 x 24 =8.76小时，表示该软件系统在连续运行1年时间里最多可能的业务中断时间是8.76小时。 4个9：(1-99.99%) x 365 x 24 =0.876小时=52.6分钟，表示该软件系统在连续运行1年时间里最多可能的业务中断时间是52.6分钟。 5个9：(1-99.999%) x 365 x 24 x 60 =5.26分钟，表示该软件系统在连续运行1年时间里最多可能的业务中断时间是5.26分钟。 那么X个9里的X只代表数字3~5，为什么没有1~2，也没有大于6的呢？我们接着往下计算： 1个9：(1-90%)x365=36.5天 2个9：(1-99%)x365=3.65天 6个9：(1-99.9999%)x365x24x60x60=31秒 可以看到1个9和、2个9分别表示一年时间内业务可能中断的时间是36.5天、3.65天，这种级别的可靠性或许还不配使用“可靠性”这个词；而6个9则表示一年内业务中断时间最多是31秒，那么这个级别的可靠性并非实现不了，而是要做到从5个9》6个9的可靠性提升的话，后者需要付出比前者几倍的成本，所以在企业里大家都只谈（3~5）个9。 系统性能的概念和指标① 系统延迟(Latency): 系统在处理一个请求或一个任务时的延迟, 有平均值, 中位数, TP 三种衡量指标: 平均值(Avg): 延迟的评测性能指标原则: 不要用平均值! 例如测试了10次，有9次是1ms，而有1次是1s，那么平均数据就是100ms，很明显，这完全不能反应性能测试的情况 中位数（Mean）: 可能会比平均数要稍微靠谱一些，所谓中位数的意就是把将一组数据按大小顺序排列，处在最中间位置的一个数叫做这组数据的中位数 ，这意味着至少有50%的数据低于或高于这个中位数。 TP指标(Top Percentile): 这是最为正确的统计做法 ，也就是英文中的 Top Percentile ，Top百分数，是一个统计学里的术语，与平均数、中位数都是一类。 TP50：指在一个时间段内（如5分钟），统计该方法每次调用所消耗的时间，并将这些时间按从小到大的顺序进行排序，取第50%的那个值作为TP50 值；正确使用TP50做监控: 配置此监控指标对应的报警阀值后，需要保证在这个时间段内该方法所有调用的消耗时间至少有50%的值要小于此阀值，否则系统将会报警。 TP90: 通过上面的定义, 90%的请求中最长耗时; TP90也即要求 比这个耗时还长的请求次数 比例应该在总次数的10%以下 TP99: 与TP50/90值计算方式一致，它们分别代表着对方法的不同性能要求，TP50相对较低，TP90则比较高，TP99，TP999则对方法性能要求很高 Amazon AWS 定义的 P99: https://docs.aws.amazon.com/zh_cn/elasticbeanstalk/latest/dg/health-enhanced-metrics.html ② 吞吐量(Throughput): 每秒可处理的请求数/事务数, 等于并发数/平均响应时间 QPS: Queries Per Second意思是“每秒查询率”，是一台服务器每秒能够响应的查询次数，是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。可用由PV粗略计算QPS的两种方法: 按照每天80%的请求集中在20%的时间, 峰值QPS= (PV*80%) / (24*3600*20%) 按照峰值QPS是评价QPS的三倍计算, 峰值QPS= (PV*3) / (24*3600) TPS: Transactions Per Second, 也就是事务数/秒。它是软件测试结果的测量单位。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数，最终利用这些信息来估计得分。 Java GC回收器的评估指标里也有吞吐量的概念: 系统总运行时间 = 应用程序耗时 + 总GC耗时。 ③ 除了 Latency 和 Throughtput , 其他的性能衡量指标还有: PV: page view UV: user view; VU: 并发用户数, 也叫虚拟用户数(VU), 同时请求系统的用户数. 一般情况下, 大型系统（业务量大、机器多）做性能测试 5000 个并发用户就够了, 中小型系统做性能测试 1000 个并发用户就足够了; 如何严谨地做性能测试一般来说，性能测试要统一考虑这么几个因素：Thoughput吞吐量，Latency响应时间，资源利用（CPU/MEM/IO/Bandwidth…），成功率，系统稳定性。 一，你得定义一个系统的响应时间latency，建议是TP99，以及成功率。比如路透的定义：99.9%的响应时间必需在1ms之内，平均响应时间在1ms以内，100%的请求成功。 二，在这个响应时间的限制下，找到最高的吞吐量。测试用的数据，需要有大中小各种尺寸的数据，并可以混合。最好使用生产线上的测试数据。 三，在这个吞吐量做Soak Test，比如：使用第二步测试得到的吞吐量连续7天的不间断的压测系统。然后收集CPU，内存，硬盘/网络IO，等指标，查看系统是否稳定，比如，CPU是平稳的，内存使用也是平稳的。那么，这个值就是系统的性能 四，找到系统的极限值。比如：在成功率100%的情况下（不考虑响应时间的长短），系统能坚持10分钟的吞吐量。 五，做Burst Test。用第二步得到的吞吐量执行5分钟，然后在第四步得到的极限值执行1分钟，再回到第二步的吞吐量执行5钟，再到第四步的权限值执行1分钟，如此往复个一段时间，比如2天。收集系统数据：CPU、内存、硬盘/网络IO等，观察他们的曲线，以及相应的响应时间，确保系统是稳定的。 六、低吞吐量和网络小包的测试。有时候，在低吞吐量的时候，可能会导致latency上升，比如TCP_NODELAY的参数没有开启会导致latency上升（详见TCP的那些事），而网络小包会导致带宽用不满也会导致性能上不去，所以，性能测试还需要根据实际情况有选择的测试一下这两咱场景。 @ref 性能测试应该怎么做？ | | 酷 壳 - CoolShell 高可用方案本章内容包括: 负载均衡, 限流, 隔离, 降级, 超时与重试, 回滚, 压测与预案. 负载均衡与反向代理(Nginx)这里不再介绍Nginx的具体配置 负载均衡(loadbalance)Nginx目前提供了HTTP七层负载均衡(ngx_http_upstream_module), 意思是在OSI第七层应用层的负载均衡, 1.9版本也开始提供TCP四层负载均衡(ngx_stream_upstream_module) upstream服务器配置略 负载均衡算法几种负载均衡算法: 轮询（Round Robin） 加权轮询（Weight Round Robin） 随机（Random） 加权随机（Weight Random） 源地址哈希（Hash） 一致性哈希（ConsistentHash） 最小连接数（Least Connections） 低并发优先（Active Weight） Nginx配置中常用的负载均衡: round robin(轮询): 默认的 ip哈希:ip_hash, 根据客户端ip 哈希: hash $uri:根据uri进行哈希 hash $key consistent:一致性哈希 一致性哈希(consistent hashing):在使用一致哈希算法后，哈希表槽位数（大小）的改变平均只需要对K/n个关键字重新映射，其中K是哈希关键字的数量(也就是Key)，n是槽位数量(槽位指的是Node的槽位)。然而在传统的哈希表中，添加或删除一个槽位的几乎需要对所有关键字进行重新映射。 一致性哈希vs传统哈希的优势: 新增/减少节点, 传统哈希需要对全部Key做rehash, 一致性哈希只需… 新增/减少节点, rehash影响的节点少, 理论上只影响相邻的节点 一致性哈希过程: 首先求出服务器（节点）的哈希值，并将其配置到0～2^32的圆（continuum）上。// 为什么哈希范围是2^32? 当服务节点太少时，容易因为节点分部不均匀而造成数据倾斜。这种一般通过增加虚拟节点的方式解决 然后采用同样的方法求出存储数据的键的哈希值，并映射到相同的圆上。 然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第一个服务器上。如果超过2^32仍然找不到服务器，就会保存到第一台memcached服务器上。 如果增加一个服务器节点, 如下图, 新增 node5 节点, 只有在圆（continuum）上增加服务器的地点逆时针方向的第一台服务器上的键会受到影响 失败重试机制主要针对在Nginx的upstream和proxy_pass进行配置, 作用是实现”多少时间内失败多少次, 则从upstream列表里摘除” upstream心跳检查失败重试是被动的去摘除upstream无效机器, 心跳检测可以认为是一种主动的检查并摘除无效机器, 主要在upstream的check里, 有http和tcp两种 长连接(keepalive) client 与 nginx之间的长连接: http里的keepalive_timeout 300s 300s; 第一个参数: client和nginx建立的长连接, 如果在此时间内没有实际消息发送, nginx将主动关闭此连接（默认是75秒) 第二个参数: nginx向client发送response的http头, 其中的Keep-Alive: timeout=xx nginx 与 upstream之间的长连接: upstream里的keepalive 100这里的100指的是”每个Worker与upstream服务器可缓存的最大连接数” 参考: 反向代理-Nginx 降级服务降级，当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行。 降级预案即可以降级的功能点, 降级服务需要从服务端链路考虑, 根据用户访问的服务调用链路决定哪里可以降级. 一般情况下可以考虑降级的点有: 页面降级(整个页面or页面片段):非核心业务的页面, 在紧急情况下可以降级, 可以利用nginx把该页面直接跳转一个静态页 页面异步请求:比如异步加载的信息, 在紧急情况下可以降级 非核心功能降级:比如商品详情页的推荐/热销 读降级:紧急情况下只读缓存, 适用于一致性要求不高的情况 写降级:在高并发抢购这种情景下, 可以先更新cache, 然后异步写回数据库 风控降级:识别机器人, 根据用户画像和用户风控等级降级, 需要提前做好用户风控等级的功能 降级后的处理方式一般有:返回默认值, 返回静态页面, 从缓存读数据而不是数据库 自动降级 超时降级: 访问数据库 或 非本地接口(RPC, HTTP)超时, 需要提前设置合理的超时时间/重试机制/重试次数 故障降级: 远程调用的接口RPC抛异常, HTTP服务500错误等, 流量降级: 超过限流阈值时.. 手动开关降级开关可以放在Redis, Zookeeper上. 读写服务降级 库存扣减案例: 正常情况下扣减Redis, 同步扣减DB, 当流量过大时, 降级为发送一条扣减消息, 然后异步写入DB实现最终一致性 多级降级从用户到系统, 降级离用户越近, 最终落到后端系统的QPS越低, 对后端系统的保护就越好 页面JS降级开关 接入层降级开关, 一般是Nginx 后端应用降级开关 通过 Hystrix实现熔断降级@todo Dubbo@todo 集群容错几种常用容错策略： 失效转移（failover）: 当出现失败，重试其他服务器，通常用于读操作等幂等行为(保证调用 1 次与 N 次效果相同)，重试会带来更长延迟。 快速失败（failfast）: 只发起一次调用，失败立即报错，通常用于非幂等性的写操作。 失效安全（failsafe）: 出现异常时忽略，但记录这一次失败，存入日志中。// 失败安全策略的核心是即使失败了也不会影响整个调用流程。通常情况下用于旁路系统或流程中，它的失败不影响核心业务的正确性。在实现上，当出现调用失败时，会忽略此错误，并记录一条日志，同时返回一个空结果，在上游看来调用是成功的。 失败通知（failback）: 客户端需要能够获取到服务调用失败的具体信息，通过对失败错误码等异常信息的判断，决定后续的执行策略，例如非幂等性的服务调用。// Dubbo中的Failback策略中，如果调用失败，则此次失败相当于Failsafe，将返回一个空结果。而与Failsafe不同的是，Failback策略会将这次调用加入内存中的失败列表中，对于这个列表中的失败调用，会在另一个线程中进行异步重试，重试如果再发生失败，则会忽略，即使重试调用成功，原来的调用方也感知不到了。因此它通常适合于，对于实时性要求不高，且不需要返回值的一些异步操作。 超时与重试在实际开发过程中，笔者见过太多故障是因为没有设置超时或者设置得不对而造成的。而这些故障都是因为没有意识到超时设置的重要性而造成的。如果应用不设置超时，则可能会导致请求响应慢，慢请求累积导致连锁反应，甚至造成应用雪崩。而有些中间件或者框架在超时后会进行重试（如设置超时重试两次），读服务天然适合重试，但写服务大多不能重试（如写订单，如果写服务是幂等的，则重试是允许的），重试次数太多会导致多倍请求流量，即模拟了DDoS攻击，后果可能是灾难，因此，务必设置合理的重试机制，并且应该和熔断、快速失败机制配合。 Nginx超时设置 客户端超时设置: 对于客户端超时主要设置有读取请求头超时时间、读取请求体超时时间、发送响应超时时间、长连接超时时间。 keepalive_timeout time [header_timeout]： time默认是75s, 表示长连接的超时时间(客户端在75s期间没有任何请求, Nginx将会主动发送FIN关闭连接); header_timeout会通过HTTP头Keep-Alive: timeout=xx告知客户端长连接超时时间, 上游服务器(upstream)超时: 超时设置:proxy_connect_timeout time：与后端/上游服务器建立连接的超时时间，默认为60s，此时间不超过75s。 重试设置: proxy_next_upstream_tries number：设置重试次数，默认0表示不限制，注意此重试次数指的是所有请求次数（包括第一次和之后的重试次数之和）。 proxy_next_upstream_timeout time：设置重试最大超时时间，默认0表示不限制。 DNS解析超时: @todo Web容器超时设置以Tomcat为例: connectionTimeout: 当client与tomcat建立连接之后, 在”connectionTimeout”时间之内, 仍然没有得到client的请求数据, 此时连接将会被断开, connectionTimeout只会在链接建立之后, 得到client发送http-request信息前有效. socket.soTimeout: 从收到client请求后, 到返回数据, 这段超时时间 @doubt keepAliveTimeout: 当无实际数据交互时，连接被保持的时间，单位：毫秒。在未指定此属性时，将使用connectionTimeout作为keepAliveTimeout。 不过我们通常在tomcat前面还有nginx等代理服务器，我们通常希望链接keepAlive的机制由代理服务器控制，比如nginx来决定链接是否需要“保持活性”（注意，与keep_alive不同），当然nginx服务器只会保留极少的长连接，几乎所有的链接都会在使用结束后主动close；有nginx与client保持，而不再是tomcat与client保持。 Apache HttpClient(客户端)超时设置 connectionTimeout: 建立连接超时时间, 指Client发出请求后, 到建立连接这段超时时间, 如果在该时间仍没有完成连接的建立会抛出connectionTimeout异常; socketTimeout: 等待响应超时时间, 指Client对Url发起请求(连接已经建立), 到收到服务端的Response这段超时时间 数据库客户端连接超时设置@todo 总结本章主要介绍了如何在Web应用访问的整个链路上进行超时时间设置。通过配置合理的超时时间，防止出现某服务的依赖服务超时时间太长且响应慢，以致自己响应慢甚至崩溃。客户端和服务器端都应该设置超时时间，而且客户端根据场景可以设置比服务器端更长的超时时间。如果存在多级依赖关系，如A调用B，B调用C，则超时设置应该是A&gt;B&gt;C，否则可能会一直重试，引起DDoS攻击效果。不过最终如何选择还是要看场景，有时候客户端设置的超时时间就是要比服务器端的短，可以通过在服务器端实施限流/降级等手段防止DDoS攻击。 超时之后应该有相应的策略来处理，常见的策略有重试（等一会儿再试、尝试其他分组服务、尝试其他机房服务，重试算法可考虑使用如指数退避算法）、摘掉不存活节点（负载均衡/分布式缓存场景下）、托底（返回历史数据/静态数据/缓存数据）、等待页或者错误页。对于非幂等写服务应避免重试，或者可以考虑提前生成唯一流水号来保证写服务操作通过判断流水号来实现幂等操作。在进行数据库/缓存服务器操作时，记得经常检查慢查询，慢查询通常是引起服务出问题的罪魁祸首。也要考虑在超时严重时，直接将该服务降级，待该服务修复后再取消降级。 对于有负载均衡的中间件，请考虑配置心跳/存活检查，而不是惰性检查。超时重试必然导致请求响应时间增加，最坏情况下的响应时间=重试次数×单次超时时间，这很可能严重影响用户体验，导致用户不断刷新页面来重复请求，最后导致服务接收的请求太多而挂掉，因此除了控制单次超时时间，也要控制好用户能忍受的最长超时时间。超时时间太短会导致服务调用成功率降低，超时时间太长又会导致本应成功的调用却失败了，这也要根据实际场景来选择最适合当前业务的超时时间，甚至是程序动态自动计算超时时间。比如商品详情页的库存状态服务，可以设置较短的超时时间，当超时时降级返回有货，而结算页服务就需要设置稍微长一些的超时时间保证确实有货。在实际开发中，不要轻视超时时间，很多重大事故都是因为超时时间不合理导致的，设置超时时间一定是只有好处没有坏处的，请立即Review你的代码吧。 回顾: TCP协议里的重试机制:Client发给Server端SYN包后, Server端要返给Client一个SYN-ACK, 然后Server要等待Client发过来的ACK,Server发送SYN-ACK并等待ACK的过程是有重试机制的, 重试的间隔时间从1s开始每次都翻倍，5次的重试时间间隔为1s, 2s, 4s, 8s, 16s。 隔离 进线程隔离 集群隔离 机房隔离 读写隔离 动静隔离: 静态资源放CDN 爬虫隔离 热点隔离: 诸如秒杀, 抢购做成独立系统 资源隔离 限流限流算法 令牌桶: 漏桶: 应用级限流 限制总并发数/连接数: Tomcat的几个参数 acceptCount, maxConnections, maxThreads 限制单个接口的请求数: 限制某个时间窗口的请求数:用Guava的Cache, 时间戳做Key, 访问次数AtomicLong做Value. . . 缺点是无法应对突发流量, 瞬时请求可能都被允许 平滑限流:Guava的RateLimiter提供的令牌桶算法可以对请求进行速率平均化, 比如5request/秒, 每隔200ms处理一个请求 Nginx层限流Nginx提供了两个限流模块: 限制总并发数的ngx_http_limit_conn_module 漏桶算法的ngx_http_limit_req_module 高性能方案本章内容: 缓存, 连接池, 异步并发, 数据库拆分, 任务系统拆分, 队列. 有关C10K、C100K单机系统，参考： 架构-并发系统-C100K 应用级缓存本章以Java应用缓存为例. 缓存回收策略 基于空间和容量: 超过xx时回收 基于存活时间(TTL): 缓存数据从创建开始计算, 过期则清除 基于Java GC: 软引用 弱引用 基于回收算法: FIFO LRU: Least Recently Used, 最近最不常访问的被淘汰, 访问时间距离现在最久远的被淘汰(较常用) LFU: Least Frequently Used, 在一段时间内访问次数最少的被淘汰, 访问频率最少的被淘汰(可能需要预热) Java应用级缓存的类型 堆内缓存: 用Java软引用/弱引用对象作为缓存, 不需要序列化. Guava的Cache, Ehcache3.x 堆外缓存: 缓存在JVM内存之外, 减少GC次数, 但是需要序列化的时间开销, Ehcache3.x, MapDB 缓存的设计模式首先介绍三个名词: SoR(SystemofRecord): 记录系统, 一般是DB; Cache: Cache的访问速度比SoR要快, 数据放在Cache中可以提升访问速度, 减少回源次数; 回源: 缓存没有命中, 需要去SoR取数据, 这叫做回源; Cache Aside即代码围绕着缓存写, 由业务层的代码读取/更新缓存. 读:先读Cache, 没有读到再读SoR, 并更新Cache 写(更新): 方案1: 先更新SoR, 再更新Cache 方案2: 先更新SoR, 再失效Cache, 读取的时候再把SoR的数据写入Cache CacheAside存在的问题:如果并发更新Cache, 会出现Cache和SoR数据不一致的情况(A更新了SoR, 还没来得及更新Cache, B线程插入进来更新SoR并更新Cache, 之后A线程更新Cache), 这种有两种解决方式: 用canal订阅数据库(SoR)的 binlog, 增量更新Cache, 缓存的更新会有延迟; 通过对请求合理的hash, 让同一个读服务落到同一个实例; Cache as SoR即Cache和SoR是一个整体, 业务层代码只对Cache进行读写, 然后Cache再委托给SoR进行真实的读写. 有三种实现模式: Read-Throught, Write-Throught, Write-Behind: Read-Throught: 读cache, 如果没有读到, 由cache把SoR的数据更新到缓存里. GuavaCache提供了此模式, 创建Cache时需要指定一个CacheLoader, 从Cache未能读到数据时, GuavaCache委托CacheLoader从SoR读取, 用户代码只需要调用cache.get() Write-Throught: 用户调用cache.set(), 缓存更新后, 同步写到SoR, 不需要用户代码干预 Write-Behind: 与上面的区别是, Write-Behind是异步批量写SoR Copy Pattern Copy-On-Read: 读时复制 Copy-On-Write: 写时复制 数据库拆分(分库分表) 垂直切分: 一般根据业务来 垂直分表: 通俗的说法叫做“大表拆小表”，拆分是基于关系型数据库中的“列”（字段）进行的。通常情况，某个表中的字段比较多，可以新建立一张“扩展表”，将不经常使用或者长度较大的字段拆分出去放到“扩展表”中 垂直分库: 按照业务模块来划分出不同的数据库，而不是像早期一样将所有的数据表都放到同一个数据库中。 水平切分: 哈希分库: 比如根据自增主键对库的总数取余操作, 可以多次哈希, 第一次哈希分库, 第二次分表: 例子: UserId后四位mod32分到32个库中，同时再将UserId后四位Div32Mod32将每个库分为32个表，共计分为1024张表。 范围分库: 比如根据自增主键范围切分, 优点: 单表大小可控，天然水平扩展。 缺点: 无法解决集中写入瓶颈的问题。 分库分表带来的问题 跨库join的问题解决方案: 字段冗余 Redis存储索引 夸库事务: @todo 唯一ID 利用数据库自增ID: 优点：最简单。 缺点：单点风险、单机性能瓶颈。 TwitterSnowflake 优点：高性能高可用、易拓展。 缺点：需要独立的集群以及ZK。 UUID, GUID 案例这里是一些”一句话解决方案”. 最佳实践list LVS/F5/HAProxy负载均衡 -&gt; Nginx/Apache -&gt; Redis/Memcached Kafka，ActiveMQ负责解耦的消息队列 RPC框架Thrift, 序列化Protobuf 分布式框架Zookeeper Mysql分表分库的Cobar 通用搜索引擎ElasticSearch 如何存储密码 bcrypt:带盐的散列算法, 可以指定costfactor, 10表示2^10次方次运算, 返回的散列值包括盐和加密后的文本 Dropbox是如何安全地存储用户密码的 : AES256(bcrypt(SHA512(pwd), salt(10))) 加盐密码保存的最通用方法是？ - 知乎 @todo 附录:名词解释 高可用High-Availability、高可扩展性(高可伸缩性)High-Scalability 解耦LooselyCoupled 吞吐量Throughput（QPS/TPS)、并发量C10K 冗余Redundancy、分区Partitions、缓存Caches、代理Proxies、索引Indexes、队列Queues 集群Cluster、主从Master-Slave、水平/垂直切分Sharding 请求负载均衡LoadBalancing、请求路由Route、状态复制Replication 故障转移Failover、故障回复Failback、心跳检测Healthcheck/Heartbeat 纵向扩展Scale-up、横向扩展Scale-out 自动升降级Auto-upgrade/downgrade scaleup:纵向扩展, 指提高单台机器的存储(RAM, HD)上限 scaleout:横向扩展, 多台主机 参考 酷壳 《亿级流量网站架构核心技术》","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[{"name":"后端架构","slug":"后端架构","permalink":"https://beefyheisenberg.github.io/tags/后端架构/"},{"name":"缓存","slug":"缓存","permalink":"https://beefyheisenberg.github.io/tags/缓存/"},{"name":"架构","slug":"架构","permalink":"https://beefyheisenberg.github.io/tags/架构/"},{"name":"System Design","slug":"System-Design","permalink":"https://beefyheisenberg.github.io/tags/System-Design/"},{"name":"高可用","slug":"高可用","permalink":"https://beefyheisenberg.github.io/tags/高可用/"},{"name":"高性能","slug":"高性能","permalink":"https://beefyheisenberg.github.io/tags/高性能/"},{"name":"负载均衡","slug":"负载均衡","permalink":"https://beefyheisenberg.github.io/tags/负载均衡/"},{"name":"限流","slug":"限流","permalink":"https://beefyheisenberg.github.io/tags/限流/"},{"name":"分库分表","slug":"分库分表","permalink":"https://beefyheisenberg.github.io/tags/分库分表/"},{"name":"消息队列","slug":"消息队列","permalink":"https://beefyheisenberg.github.io/tags/消息队列/"}]},{"title":"Serverless","slug":"31.Backend/Serverless","date":"2024-01-24T01:27:52.629Z","updated":"2024-01-24T01:27:52.629Z","comments":true,"path":"31.Backend/Serverless/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/Serverless/","excerpt":"","text":"serverless Serverless ≈ BaaS+ FaaS 区分IaaS、PaaS、SaaS、BaaS、FaaS IaaS(Infrastructure as a Service)：提供服务器/vm等 PaaS(Platform as a Service)：提供运行平台，与IaaS相比，对用户屏蔽了基础性能监控/维护等，docker是PaaS使用最多的技术 SaaS(Software as a Service)：提供完成的业务服务 BaaS：后端即服务，提供如DB/MQ等 FaaS：函数即服务 架构变迁史： C/S，MVC，SOA，微服务，云原生，Serverless 使用Serverless架构的优势: 降低支出成本: 无需考虑为一个小型服务申请IaaS/PaaS资源 降低维护/开发成本(开发中无需做devOps, 也无需了解Spring完整服务框架, 仅维护一个function) @ref 理解 Serverless · Kubernetes Handbook - Kubernetes 中文指南/云原生应用架构实践手册 · Jimmy Song：https://jimmysong.io/kubernetes-handbook/usecases/understanding-serverless.html 爱奇艺内容中台之Serverless应用与实践：https://mp.weixin.qq.com/s/v1lEayBx9C_SeQcnh4ek4g","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"Redis-04消息队列","slug":"31.Backend/Redis-04消息队列","date":"2024-01-24T01:27:52.625Z","updated":"2024-01-24T01:27:52.625Z","comments":true,"path":"31.Backend/Redis-04消息队列/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/Redis-04消息队列/","excerpt":"@toc: Redis方案实现延时队列有哪些? 优缺点比较? 使用 lpush/rpop 或者 rpush/lpop // 缺点: 循环pop会导致增加无用的qps 客户端 使用 blpop 或者 brpop // 缺点: 没有消息时超时后断开(超过客户端的soTimeout), 需要保证重连 zadd k time field , time是消息要被处理的时间, 先 get k判断时间, 然后 zrem 掉这个key, 每个争抢的客户端通过 zrem返回值确认自己是否抢到 使用zadd 作为消息队列仍然有问题: 多个客户端争用一个消息, 没有消息的确认模式(ack) @ref: Redis学习笔记之十：Redis用作消息队列_数据库_yamikaze的博客-CSDN博客 Redis 异步消息队列与延时队列_数据库_wzbwzh的专栏-CSDN博客","text":"@toc: Redis方案实现延时队列有哪些? 优缺点比较? 使用 lpush/rpop 或者 rpush/lpop // 缺点: 循环pop会导致增加无用的qps 客户端 使用 blpop 或者 brpop // 缺点: 没有消息时超时后断开(超过客户端的soTimeout), 需要保证重连 zadd k time field , time是消息要被处理的时间, 先 get k判断时间, 然后 zrem 掉这个key, 每个争抢的客户端通过 zrem返回值确认自己是否抢到 使用zadd 作为消息队列仍然有问题: 多个客户端争用一个消息, 没有消息的确认模式(ack) @ref: Redis学习笔记之十：Redis用作消息队列_数据库_yamikaze的博客-CSDN博客 Redis 异步消息队列与延时队列_数据库_wzbwzh的专栏-CSDN博客","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"Redis-04分布式锁","slug":"31.Backend/Redis-04分布式锁","date":"2024-01-24T01:27:52.620Z","updated":"2024-01-24T01:27:52.620Z","comments":true,"path":"31.Backend/Redis-04分布式锁/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/Redis-04分布式锁/","excerpt":"@toc: 分布式锁的使用场景? 分布式锁的设计要点? 如何用Redis实现分布式锁? ➤ 什么情况需要分布式锁: 多个Client操作一个资源并保证互斥性, 进程内的锁机制无法实现 ➤ 设计要点:","text":"@toc: 分布式锁的使用场景? 分布式锁的设计要点? 如何用Redis实现分布式锁? ➤ 什么情况需要分布式锁: 多个Client操作一个资源并保证互斥性, 进程内的锁机制无法实现 ➤ 设计要点: 互斥性: A/B Client 同时只能有一个抢占到锁; 锁超时: 如果抢到锁的Client挂掉, 锁仍能在超时后被解锁; 高可用: Redis节点宕机仍能保证上述特性; ➤ 方案1: 加锁: SET k random_val NX PX 3000, 加锁失败: 失败后休眠一段时间再尝试 放锁: 释放前先Get, 如果值等于自己的 random_val, 才可以删除K // 避免线程1醒来后, 已经超时的情况, 另一个线程2已经SET了锁, 线程1误删Key的情况 释放前为什么要先get, 考虑如下情况, A获取到了锁, 但A处理过程耗时很长(A的锁超时了,但A还在正常运行), A的锁过期并被清理, 线程B抢占到锁, 这时候A处理完任务开始尝试 Del自己的锁… 问题: SET NX PX这种方式也有潜在的问题, 因为是在单Redis上加锁, 如果master上获取了锁, 但slave还没来得及同步锁, master就宕机了, slave成为新master, 这时候其他Client是可以抢到锁的; ➤ 方案2: // 不推荐 加锁: SETNX k &lt;timestamp + timeout&gt;, 成功则获得锁; 超时: 加速的指令可以看到K没有设置过期, 如果获得锁的Client挂掉或者休眠, 需要其他线程来删除K, 具体做法: 其他没抢到锁的客户端, Get K发现已经超时, 则发起 GETSET k &lt;timestamp + timeout&gt; , GETSET会返回K之前的值(上个K的过期时间), 考虑多个线程同时去GETSET的情况: GETSET 返回的时间比当前时间更小, 获取锁成功; 如果已经有另个线程GETSET了Key, GETSET 返回的时间比当前时间更大, 获取锁失败, 继续等待; 放锁: 删除Key 问题: SETNX 获得锁的线程A因为其他原因阻塞很久, 直到锁已经超时并被其他客户端 GETSET掉, 这时候线程A恢复并del了k ➤ RedLock方案: RedLock为了解决什么: 上面提到的分布式锁是基于单Redis实例, RedLock是在多Redis实例上实现的分布式锁(更可靠) RedLock还可保证当大多数Redis节点可用, 就可以正常加锁放锁 加锁(无锁状态下抢占到锁): 客户端向所有Redis 都发起 SET k client_random_val NX PX 3000, 这个例子里锁的总超时是3秒, 假设这一阶段消耗了x秒, 那么锁的实际可用时间=3-x, 如果大多数(N/2 + 1)实例都返回成功, 并且锁的有效时间大于0, 才算是获取锁成功; 测锁(尝试去加锁,有没有其他Client已经获取了锁): @todo 加锁失败: 如果无法在多数实例上获取到锁, 则加锁失败, Client应向已经成功的实例发起 DEL k, 为了防止过多重试, 客户端获取锁失败需要稍等一会才能再次发起锁请求; 解锁: 向所有Redis发起 DEL … 问题: 假设5个实例, Client从3个实例都取得了锁, 但这时候某个实例重启了且丢失了锁, 解决方法是: redis开启fsync, 同步到磁盘, 这样重启的时候可以从磁盘备份恢复数据(但一般情况下锁超时时间远小于重启耗时) Client尝试抢锁, 如果发现有实例宕机, 则等待一段时间(大于锁的TTL) ➤ @ref: 基于 Redis 的分布式锁 Redlock - 知乎 通过 Redlock 实现分布式锁 | Brickgao’s","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"Redis-04过期删除和内存淘汰","slug":"31.Backend/Redis-04a过期删除和内存淘汰","date":"2024-01-24T01:27:52.612Z","updated":"2024-01-24T01:27:52.612Z","comments":true,"path":"31.Backend/Redis-04a过期删除和内存淘汰/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/Redis-04a过期删除和内存淘汰/","excerpt":"原文： https://xiaolincoding.com/redis/module/strategy.html 过期删除策略Redis 是可以对 key 设置过期时间的，因此需要有相应的机制将已过期的键值对删除，而做这个工作的就是过期键值删除策略。 如何设置过期时间？先说一下对 key 设置过期时间的命令。 设置 key 过期时间的命令一共有 4 个：","text":"原文： https://xiaolincoding.com/redis/module/strategy.html 过期删除策略Redis 是可以对 key 设置过期时间的，因此需要有相应的机制将已过期的键值对删除，而做这个工作的就是过期键值删除策略。 如何设置过期时间？先说一下对 key 设置过期时间的命令。 设置 key 过期时间的命令一共有 4 个： expire &lt;key&gt; &lt;n&gt;：设置 key 在 n 秒后过期，比如 expire key 100 表示设置 key 在 100 秒后过期； pexpire &lt;key&gt; &lt;n&gt;：设置 key 在 n 毫秒后过期，比如 pexpire key2 100000 表示设置 key2 在 100000 毫秒（100 秒）后过期。 expireat &lt;key&gt; &lt;n&gt;：设置 key 在某个时间戳（精确到秒）之后过期，比如 expireat key3 1655654400 表示 key3 在时间戳 1655654400 后过期（精确到秒）； pexpireat &lt;key&gt; &lt;n&gt;：设置 key 在某个时间戳（精确到毫秒）之后过期，比如 pexpireat key4 1655654400000 表示 key4 在时间戳 1655654400000 后过期（精确到毫秒） 当然，在设置字符串时，也可以同时对 key 设置过期时间，共有 3 种命令： set &lt;key&gt; &lt;value&gt; ex &lt;n&gt; ：设置键值对的时候，同时指定过期时间（精确到秒）； set &lt;key&gt; &lt;value&gt; px &lt;n&gt; ：设置键值对的时候，同时指定过期时间（精确到毫秒）； setex &lt;key&gt; &lt;n&gt; &lt;valule&gt; ：设置键值对的时候，同时指定过期时间（精确到秒）。 如果你想查看某个 key 剩余的存活时间，可以使用 TTL &lt;key&gt; 命令。 # 设置键值对的时候，同时指定过期时间位 60 秒&gt; setex key1 60 value1OK# 查看 key1 过期时间还剩多少&gt; ttl key1(integer) 56&gt; ttl key1(integer) 52 如果需要取消 key 的过期时间，则可以使用 PERSIST &lt;key&gt; 命令。 # 取消 key1 的过期时间&gt; persist key1(integer) 1# 使用完 persist 命令之后，# 查下 key1 的存活时间结果是 -1，表明 key1 永不过期&gt; ttl key1(integer) -1 如何判定 key 已过期了？每当我们对一个 key 设置了过期时间时，Redis 会把该 key 带上过期时间存储到一个过期字典（expires dict）中，也就是说「过期字典」保存了数据库中所有 key 的过期时间。 过期字典存储在 redisDb 结构中，如下： typedef struct redisDb &#123; dict *dict; /* 数据库键空间，存放着所有的键值对 */ dict *expires; /* 键的过期时间 */ ....&#125; redisDb; 过期字典数据结构结构如下： 过期字典的 key 是一个指针，指向某个键对象； 过期字典的 value 是一个 long long 类型的整数，这个整数保存了 key 的过期时间； 过期字典的数据结构如下图所示： 当我们查询一个 key 时，Redis 首先检查该 key 是否存在于过期字典中： 如果不在，则正常读取键值； 如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期。 过期删除策略有哪些？在说 Redis 过期删除策略之前，先跟大家介绍下，常见的三种过期删除策略： 定时删除； 惰性删除； 定期删除； （1）定时删除策略是怎么样的？ 定时删除策略的做法是，在设置 key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作。 定时删除策略的优点：可以保证过期 key 会被尽快删除，也就是内存可以被尽快地释放。因此，定时删除对内存是最友好的。 定时删除策略的缺点：在过期 key 比较多的情况下，删除过期 key 可能会占用相当一部分 CPU 时间，在内存不紧张但 CPU 时间紧张的情况下，将 CPU 时间用于删除和当前任务无关的过期键上，无疑会对服务器的响应时间和吞吐量造成影响。所以，定时删除策略对 CPU 不友好。 （2）惰性删除策略是怎么样的？ 惰性删除策略的做法是，不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。 惰性删除策略的优点：因为每次访问时，才会检查 key 是否过期，所以此策略只会使用很少的系统资源，因此，惰性删除策略对 CPU 时间最友好。 惰性删除策略的缺点：如果一个 key 已经过期，而这个 key 又仍然保留在数据库中，那么只要这个过期 key 一直没有被访问，它所占用的内存就不会释放，造成了一定的内存空间浪费。所以，惰性删除策略对内存不友好。 （3）定期删除策略是怎么样的？ 定期删除策略的做法是，每隔一段时间删除一些 Key，Redis 的定期删除做法是 每隔一段时间「随机」从数据库的过期字典中取出一定数量的 key 进行检查，并删除其中的过期 key。 定期删除策略的优点：通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用。 定期删除策略的缺点： 内存清理方面没有定时删除效果好，同时没有惰性删除使用的系统资源少。 难以确定删除操作执行的时长和频率。如果执行的太频繁，定期删除策略变得和定时删除策略一样，对CPU不友好；如果执行的太少，那又和惰性删除一样了，过期 key 占用的内存不会及时得到释放。 Redis 使用的过期删除策略是？前面介绍了三种过期删除策略，每一种都有优缺点，仅使用某一个策略都不能满足实际需求。所以 Redis 选择「惰性删除+定期删除」这两种策略配和使用，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡。 （1）Redis 是怎么实现惰性删除的？ Redis 的惰性删除策略由 db.c 文件中的 expireIfNeeded 函数实现，代码如下： int expireIfNeeded(redisDb *db, robj *key) &#123; // 判断 key 是否过期 if (!keyIsExpired(db,key)) return 0; .... /* 删除过期键 */ .... // 如果 server.lazyfree_lazy_expire 为 1 表示异步删除，反之同步删除； return server.lazyfree_lazy_expire ? dbAsyncDelete(db,key) : dbSyncDelete(db,key);&#125; Redis 在访问或者修改 key 之前，都会调用 expireIfNeeded 函数对其进行检查，检查 key 是否过期： 如果过期，则删除该 key，至于选择异步删除，还是选择同步删除，根据 lazyfree_lazy_expire 参数配置决定（Redis 4.0版本开始提供参数），然后返回 null 客户端； 如果没有过期，不做任何处理，然后返回正常的键值对给客户端； （2）Redis 是怎么实现定期删除的？ Redis 每隔一段时间「随机」从数据库的过期字典中取出一定数量的 key 进行检查，并删除其中的过期 key。 检查的间隔：在 Redis 中，默认每秒进行 10 次过期检查一次数据库，此配置可通过 Redis 的配置文件 redis.conf 进行配置，配置键为 hz 它的默认值是 hz 10。 每次检查抽取 Key 的数量：20 个，定期删除的实现在 expire.c 文件下的 activeExpireCycle 函数中，其中随机抽查的数量是 ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 定义的，代码写死了 20。 ➤ 接下来，详细说说 Redis 的定期删除的流程： 从过期字典中随机抽取 20 个 key； 检查这 20 个 key 是否过期，并删除已过期的 key，并记录此次删除的过期 key数量； 如果本轮检测，过期 key 的数量超过 5 个（占比超过 25%），则继续重复步骤 1；如果已过期的 key 比例小于 25%，则停止继续删除过期 key，然后等待下一轮再检查。 可以看到，定期删除是一个循环的流程。那 Redis 为了保证定期删除不会出现循环过度，导致线程强占CPU，为此增加了定期删除循环流程的时间上限，默认不会超过 25ms，超过这个阈值则终止此轮清理。 针对定期删除的流程，我写了个伪代码： do &#123; //已过期的数量 expired = 0； //随机抽取的数量 num = 20; while (num--) &#123; //1. 从过期字典中随机抽取 1 个 key //2. 判断该 key 是否过期，如果已过期则删除，同时对 expired++ &#125; // 超过时间限制则退出（默认25ms） if (timelimit_exit) return;&#125; while (expired &gt; 20/4); // 如果本轮检查的已过期 key 的数量，超过 25%，则继续随机抽查 从库过期策略当主库键 key 过期时时，会同步一个 DEL 操作到从库，从库不会自己删除过期 key，只会应用从主库同步过来的 DEL 操作，这样就避免了缓存一致性的错误。 内存淘汰策略(Key eviction)前面说的过期删除策略，是删除已过期的 key，而当 Redis 的运行内存已经超过 Redis 设置的最大内存之后，则会使用内存淘汰策略删除符合条件的 key，以此来保障 Redis 高效的运行。 详细可参考 Key eviction | Redis 如何设置 Redis 最大运行内存？在配置文件 redis.conf 中，可以通过参数 maxmemory &lt;bytes&gt; 来设定最大运行内存，只有在 Redis 的运行内存达到了我们设置的最大运行内存，才会触发内存淘汰策略。 在 64 位操作系统中，maxmemory 的默认值是 0，表示没有内存大小限制，那么不管用户存放多少数据到 Redis 中，Redis 也不会对可用内存进行检查，直到 Redis 实例因内存不足而崩溃也无作为。 在 32 位操作系统中，maxmemory 的默认值是 3G，因为 32 位的机器最大只支持 4GB 的内存，而系统本身就需要一定的内存资源来支持运行，所以 32 位操作系统限制最大 3 GB 的可用内存是非常合理的，这样可以避免因为内存不足而导致 Redis 实例崩溃。 Redis 内存淘汰策略有哪些？Redis 内存淘汰策略共有八种，这八种策略大体分为「不进行数据淘汰」和「进行数据淘汰」两类策略。 1、不进行数据淘汰的策略： noeviction（Redis3.0之后，默认的内存淘汰策略）：它表示当运行内存超过最大设置内存时，不淘汰任何数据，但新增操作会报错。 2、进行数据淘汰的策略 针对「进行数据淘汰」这一类策略，又可以细分为「在设置了过期时间的数据中进行淘汰」和「在所有数据范围内进行淘汰」这两类策略。 仅对设置了过期时间的在过期字典中的数据中进行淘汰： volatile-random：随机淘汰设置了过期时间的任意键值； volatile-ttl：优先淘汰更早过期的键值。 volatile-lru（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最久未使用的键值； volatile-lfu（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用的键值； 在所有数据范围内进行淘汰： allkeys-random：随机淘汰任意键值; allkeys-lru：淘汰整个键值中最久未使用的键值； allkeys-lfu（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。 设置内存淘汰策略有两种方法： 方式一：通过“config set maxmemory-policy &lt;策略&gt;”命令设置。它的优点是设置之后立即生效，不需要重启 Redis 服务，缺点是重启 Redis 之后，设置就会失效。 方式二：通过修改 Redis 配置文件修改，设置“maxmemory-policy &lt;策略&gt;”，它的优点是重启 Redis 服务后配置不会丢失，缺点是必须重启 Redis 服务，设置才能生效。 Redis 内存淘汰的 LRU 算法LRU 全称是 Least Recently Used 翻译为最近最久未使用，会选择淘汰最近最久没用到的数据。 传统 LRU 算法的实现是基于「链表」结构，链表中的元素按照操作顺序从前往后排列，最新操作的键会被移动到表头，当需要内存淘汰时，只需要删除链表尾部的元素即可，因为链表尾部的元素就代表最久未被使用的元素。 但传统的 LRU 算法存在两个问题： 需要用链表管理所有的缓存数据，这会带来额外的空间开销； 当有数据被访问时，需要在链表上把该数据移动到头端，如果有大量数据被访问，就会带来很多链表移动操作，会很耗时，进而会降低 Redis 缓存性能。 Redis 是如何实现 LRU 算法的？ Redis 实现的是一种近似 LRU 算法，目的是为了更好的节约内存，它的 实现方式是在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间。 当 Redis 进行内存淘汰时，会使用随机采样的方式来淘汰数据，它是随机取 5 个值（此值可配置），然后淘汰最久没有使用的那个。 设置采样数目的配置：maxmemory-samples 5 Redis 实现的 LRU 算法的优点： 不用为所有的数据维护一个大链表，节省了空间占用； 不用在每次数据访问时都移动链表项，提升了缓存的性能； 但是 LRU 算法有一个问题，无法解决缓存污染问题，比如应用一次读取了大量的数据，而这些数据只会被读取这一次，那么这些数据会留存在 Redis 缓存中很长一段时间，造成缓存污染。 因此，在 Redis 4.0 之后引入了 LFU 算法来解决这个问题。 Redis 内存淘汰的 LFU 算法LFU 全称是 Least Frequently Used 翻译为最近最不常用，LFU 算法是根据数据访问次数来淘汰数据的，它的核心思想是“如果数据过去被访问多次，那么将来被访问的频率也更高”。 所以 LFU 算法会记录每个数据的访问次数。当一个数据被再次访问时，就会增加该数据的访问次数。这样就解决了偶尔被访问一次之后，数据留存在缓存中很长一段时间的问题，相比于 LRU 算法也更合理一些。 Redis 是如何实现 LFU 算法的？ LFU 算法相比于 LRU 算法的实现，多记录了「数据的访问频次」的信息。Redis 对象的结构如下： typedef struct redisObject &#123; ... // 24 bits，用于记录对象的访问信息 unsigned lru:24; ...&#125; robj; Redis 对象头中的 lru 字段，在 LRU 算法下和 LFU 算法下使用方式并不相同。 在 LRU 算法中，Redis 对象头的 24 bits 的 lru 字段是用来记录 key 的访问时间戳，因此在 LRU 模式下，Redis可以根据对象头中的 lru 字段记录的值，来比较最后一次 key 的访问时间长，从而淘汰最久未被使用的 key。 在 LFU 算法中，Redis对象头的 24 bits 的 lru 字段被分成两段来存储，高 16bit 存储 ldt(Last Decrement Time)，低 8bit 存储 logc(Logistic Counter)。 ldt 是用来记录 key 的访问时间戳； logc 是用来记录 key 的访问频次，它的值越小表示使用频率越低，越容易淘汰，每个新加入的 key 的logc 初始值为 5。 注意，logc 并不是单纯的访问次数，而是访问频次（访问频率），因为 logc 会随时间推移而衰减的。 在每次 key 被访问时，会先对 logc 做一个衰减操作，衰减的值跟前后访问时间的差距有关系，如果上一次访问的时间与这一次访问的时间差距很大，那么衰减的值就越大，这样实现的 LFU 算法是根据访问频率来淘汰数据的，而不只是访问次数。访问频率需要考虑 key 的访问是多长时间段内发生的。key 的先前访问距离当前时间越长，那么这个 key 的访问频率相应地也就会降低，这样被淘汰的概率也会更大。 对 logc 做完衰减操作后，就开始对 logc 进行增加操作，增加操作并不是单纯的 + 1，而是根据概率增加，如果 logc 越大的 key，它的 logc 就越难再增加。 所以，Redis 在访问 key 时，对于 logc 是这样变化的： 计算间隔（上次访问-当前的时长），来对 logc 进行衰减； 然后，再按照一定概率增加 logc 的值 redis.conf 提供了两个配置项，用于调整 LFU 算法从而控制 logc 的增长和衰减： lfu-decay-time 用于调整 logc 的衰减速度，它是一个以分钟为单位的数值，默认值为1，lfu-decay-time 值越大，衰减越慢； lfu-log-factor 用于调整 logc 的增长速度，lfu-log-factor 值越大，logc 增长越慢。","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"Redis-03c集群-Cluster方案","slug":"31.Backend/Redis-03c集群-Cluster方案","date":"2024-01-24T01:27:52.607Z","updated":"2024-01-24T01:27:52.607Z","comments":true,"path":"31.Backend/Redis-03c集群-Cluster方案/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/Redis-03c集群-Cluster方案/","excerpt":"集群概述对客户端来说，整个 cluster 被看做是一个整体，客户端可以连接任意一个节点（node）进行操作，就像操作单一 Redis 实例一样，当客户端操作的 key 没有分配到该 node 上时，Redis 会返回转向指令，指向正确的 node，这有点像浏览器页面的302 redirect 跳转。客户端不需要连接集群所有节点,只要连接集群中任意一个节点即可。 Redis Cluster 中，每个 Redis 实例被称为节点（node），整个集群被 Sharding 为 16384个 slot(槽)； 对于每个写入的键值对，根据 key 进行散列，分配到这16384个 slot 中的某一个中。通过 CRC16(key)%16384 计算 Key 属于哪个槽；如果 key 中包含{}，那么集群在计算哈希槽的时候只会使用{}中的内容，而不是整个键，{}内的内容称为 hash_tag，这个机制可以让客户端可以控制哪些 key 落入同一个槽； Redis 集群中的每个 node(节点)负责分摊这16384个 slot 中的一部分。当动态添加或减少 node 节点时，需要将16384个槽做个再分配，槽中的键值也要迁移； 为了增加集群的可访问性，官方推荐的方案是将 node 配置成主从结构，即每个 master 都配置 n 个 slave ； 如果主节点失效，Redis Cluster 会根据选举算法从 slave 中选择一个上升为主节点。这非常类似前篇文章提到的 Redis Sharding 场景下服务器节点通过 Sentinel 监控架构成主从结构，只是 Redis Cluster 本身提供了故障转移容错的能力。 集群安装","text":"集群概述对客户端来说，整个 cluster 被看做是一个整体，客户端可以连接任意一个节点（node）进行操作，就像操作单一 Redis 实例一样，当客户端操作的 key 没有分配到该 node 上时，Redis 会返回转向指令，指向正确的 node，这有点像浏览器页面的302 redirect 跳转。客户端不需要连接集群所有节点,只要连接集群中任意一个节点即可。 Redis Cluster 中，每个 Redis 实例被称为节点（node），整个集群被 Sharding 为 16384个 slot(槽)； 对于每个写入的键值对，根据 key 进行散列，分配到这16384个 slot 中的某一个中。通过 CRC16(key)%16384 计算 Key 属于哪个槽；如果 key 中包含{}，那么集群在计算哈希槽的时候只会使用{}中的内容，而不是整个键，{}内的内容称为 hash_tag，这个机制可以让客户端可以控制哪些 key 落入同一个槽； Redis 集群中的每个 node(节点)负责分摊这16384个 slot 中的一部分。当动态添加或减少 node 节点时，需要将16384个槽做个再分配，槽中的键值也要迁移； 为了增加集群的可访问性，官方推荐的方案是将 node 配置成主从结构，即每个 master 都配置 n 个 slave ； 如果主节点失效，Redis Cluster 会根据选举算法从 slave 中选择一个上升为主节点。这非常类似前篇文章提到的 Redis Sharding 场景下服务器节点通过 Sentinel 监控架构成主从结构，只是 Redis Cluster 本身提供了故障转移容错的能力。 集群安装 使用redis-trib.rb创建集群redis-trib.rb create --replicas 1 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 添加主节点: redis-trib.rb add-node 127.0.0.1:7007 127.0.0.1:7001 当添加了一个主节点后,需要重新分配哈希槽: redis-trib.rb reshard 127.0.0.1:7001 添加从节点, 添加一个port为7008的Redis实例做为7007的从节点: redis-trib.rb add-node --slave --master-id cad9f7413ec6842c971dbcc2c48b4ca959eb5db4 127.0.0.1:7008 127.0.0.1:7001 注: 主节点id可以在client中使用 cluster nodes 命令查询。 删除节点: redis-trib.rb del-node 要删除的节点的ip和端口 节点id Redis Cluster 架构概述节点间通讯： 所有的 redis 节点彼此互联(PING-PONG 机制),内部使用二进制协议优化传输速度和带宽，详见「Gossip 协议解析」 节点和槽： 将所有数据分为16384个槽(Slot), 每个 redis 节点分得一部分槽, 每个 redis 节点都存储了槽和节点的对应关系, 客户端也会缓存槽和节点的对应关系 槽的编号从 0~0x3FFF, 所以槽的总数 = 16384 = 0x3FFF+1 查询过程： 客户端与 redis 节点直连,不需要中间 proxy 层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可 客户端(以JedisCluster为例)读写时, 首先计算出Key在哪个槽: Slot = crc(Key) &amp; 0x3FFF , 然后根据”槽-节点”的表直接访问Redis节点 // 在JedisClusterInfoCache类中，slots这个Map本地缓存保存的也是slot槽和主节点的连接池; 如果Redis节点包含查询的Key, 直接返回数据, 如果不包含, 则返回’MOVED’重定向错误 客户端收到 MOVED 响应, 使用 cluster slots 命令更新 slots 缓存（renewSlotCache 方法） 客户端重复上述查询过程 如果 slot 正在向别的节点迁移中，返回的是 ASK（类似临时重定向） 一些查询命令的优化： 如果是 keys 这种涉及所有节点的命令, 通过 Spring 的 AsyncTaskExecutor 发送命令给所有节点, 然后处理异步返回的结果 如果是 mget 这种可能涉及部分节点的命令, 先把所有的 key 按节点分组, 然后异步执行 故障转移/投票机制: Redis 集群中每一个节点都会参与投票,如果当半数以上的节点认为一个节点通信超时,则该节点 fail。 当集群中任意节点的 master(主机)挂掉, 且这个节点没有 slave(从机),则整个集群进入 fail 状态。 Gossip协议解析Gossip 是一个p2p模式的协议, 节点之间不断交换彼此的元数据信息, 元数据信息包括自己和已知其他节点的状态, 交换一段时间后最终每个节点都可以同步到最新的状态数据, Gossip主要有以下4类消息: MEET: 类似”握手”, 消息中包括作为发送者的 Redis节点的信息 以及其他已知 Redis节点信息（节点id，负责槽位，节点标识等等） PING: 消息中包含内容同MEET消息, PING作为节点之间信息交换 &amp; 心跳检查 PONG: 接收到MEET/PING后, 需要返回一个PONG, 告知对方自己状态正常 FAIL: 节点发现另外某节点不可用时(没收到PONG), 会向自己已知的所有节点发送FAIL广播 考虑到频繁地交换信息会加重带宽（集群节点越多越明显）和计算的负担，Redis Cluster内部的定时任务每秒执行10次，每次遍历本地节点列表，对最近一次接受到pong消息时间大于cluster_node_timeout / 2的节点立马发送ping消息，此外每秒随机找5个节点，选里面最久没有通信的节点发送ping消息。同时 ping 消息的消息投携带自身节点信息，消息体只会携带1/10的其他节点信息，避免消息过大导致通信成本过高。 故障发现、故障转移 如果某个主节点宕机, 集群内的其他机器通过 PING-PONG 很快发现宕机, 并通过广播 FAIL 消息，当超过半数的主节点认为宕机，则确认是”客观下线”； 宕机主节点对应的从节点，收到主节点宕机的消息, 发起选举广播，请求其他具有投票权的主节点给自己投票； 选举过程和 Redis Sentinel 方式类似，超过半数的选票则认为自己当选, 需要注意的是从当选为主节点之后的操作: 自己变为主节点, 停止从原主节点复制工作 让原主的其他从节点变为自己的从 更新槽-节点的配置, 并广播给其他节点 槽位迁移、数据伸缩无论是集群扩容还是收缩，本质上都是槽及其对应数据在不同节点上的迁移。一般情况下，槽迁移完成后，每个节点负责的槽数量基本上差不多，保证数据分布满足理论上的均匀。 常用的有关槽的命令如下： CLUSTER ADDSLOTS slot1 [slot2]...[slotN] —— 为当前节点分配要负责的槽，一般用于集群创建过程。 CLUSTER DELSLOTS slot1 [slot2]...[slotN] —— 将特定槽从当前节点的责任区移除，和ADDSLOTS命令一样，执行成功后会通过节点间通信将最新的槽位信息向集群内其他节点传播。 CLUSTER SETSLOT slotNum NODE nodeId —— 给指定ID的节点指派槽，一般迁移完成后在各主节点上执行，告知各主节点迁移完成。 CLUSTER SETSLOT slotNum IMPORTING sourceNodeId —— 在槽迁移的目标节点上执行该命令，意思是这个槽将由原节点迁移至当前节点，迁移过程中，当前节点（即目标节点）只会接收asking命令连接后的被设为IMPORTING状态的slot的命令。 CLUSTER SETSLOT slotNum MIGRATING targetNodeId —— 在槽迁移的原节点上执行该命令，意思是这个槽将由当前节点迁移至目标节点，迁移过程中，当前节点（即原节点）依旧会接受设为MIGRATING的slot相关的请求，若具体的key依旧存在于当前节点，则处理返回结果，若不在，则返回一个带有目标节点信息的ASK重定向错误。其他节点在接受到该槽的相关请求时，依旧会返回到原节点的MOVED重定向异常。 在完成 slot 在原节点和目标节点上状态设置（即上面最后两条命令）后，就要开始进行具体 key 的迁移。 CLUSTER GETKEYSINSLOT slot total —— 该命令返回指定槽指定个数的key集合 MIGRATE targetNodeIp targetNodePort key dbId timeout [auth password] —— 该命令在原节点执行，会连接到目标节点，将key及其value序列化后发送过去，在收到目标节点返回的ok后，删除当前节点上存储的key。整个操作是原子性的。由于集群模式下使用各节点的0号db，所以迁移时dbId这个参数只能是0。 MIGRATE targetNodeIp targetNodePort &quot;&quot; 0 timeout [auth password] keys key1 key2... —— 该命令是上面迁移命令基于pipeline的批量版本。 在整个slot的key迁移完成后，需要在各主节点分别执行CLUSTER SETSLOT slotNum NODE nodeId来通知整个slot迁移完成。redis-trib.rb 提供的reshard功能便是基于官方提供的上述命令实现的。 集群的扩展过程实际上就是启动一个新节点，加入集群（通过 gossip 协议进行节点握手、通信），最后从之前各节点上迁移部分 slot 到新节点上。 集群的收缩过程除了除了将待下线节点的槽均匀迁移到其他主节点之外，还有对节点的下线操作。官方提供了 CLUSTER FORGET downNodeId 命令，用于在其他节点上执行以忘记下线节点，不与其交换信息，需要注意的是该命令有效期为60s，超过时间后会恢复通信。一般建议使用 redis-trib.rb 提供的 del-node 功能。 客户端 jedis-clusterJedis 是 redis 的 java 客户端，JedisCluster 则是 Jedis 根据 Redis 集群的特性提供的集群客户端。 上文介绍过了 redis 集群下操作 key 的详细流程，一般通过 redis-cli 启动客户端连接具体的节点时，要操作的 key 若不在这个节点上时，服务端会返回 MOVED 重定向错误，这时需要手动连接至重定向节点才能继续操作。或者 redis-cli 连接服务节点时加上-c 参数，就可以使用 redis-cli 提供的自动重定向机制，在操作其他服务节点的 key 时会进行自动重定向，避免客户端手动重定向。 JedisCluster 作为操作 Redis 集群的 java 客户端，同样遵守 RedisCluster 提供的客户端连接规范，本节从源码的角度去看其具体是怎么做的。 @ref: 你不知道的Redis：RedisCluster与JedisCluster - 掘金 Jedis cluster命令执行流程剖析 - 大鹏的个人空间 - OSCHINA - 中文开源技术交流社区 Reference 全面剖析Redis Cluster原理和应用 Redis 集群规范 — Redis 命令参考","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"Redis-03b-集群-Sharding方案","slug":"31.Backend/Redis-03b集群-Sharding方案","date":"2024-01-24T01:27:52.603Z","updated":"2024-01-24T01:27:52.603Z","comments":true,"path":"31.Backend/Redis-03b集群-Sharding方案/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/Redis-03b集群-Sharding方案/","excerpt":"客户端shardingJava redis客户端驱动jedis，已支持Redis Sharding功能，即ShardedJedis以及结合缓存池的ShardedJedisPool, jedis的特点: 采用一致性哈希算法(consistent hashing)，将key和节点name同时hashing，采用的算法是MURMUR_HASH。采用一致性哈希而不是采用简单类似哈希求模映射的主要原因是当增加或减少节点时，不会产生由于重新匹配造成的rehashing。一致性哈希只影响相邻节点key分配，影响量小。 ShardedJedis支持keyTagPattern模式，即抽取key的一部分keyTag做sharding，这样通过合理命名key，可以将一组相关联的key放入同一个Redis节点，这在避免跨节点访问相关数据时很重要。 ➤ Redis Sharding 方案: 通过客户端进行Sharding, 在Client侧做Sharding, 比如 Jedis 提供的 ShardedJedis: ShardedJedis特性: 使用虚拟节点, 使Key在Redis节点的分布更均匀, 如果一个节点挂掉, 不再是相邻的节点受影响. 每个实体节点默认有160个虚拟节点, ShardedJedis还支持权重, 虚拟节点个数 = 节点权重 x 160 ShardedJedis使用了MurMur Hash做Hash函数, MurMur Hash相比较一般Hash算法, 对于规律性较强的Key随机分布的表现更好. 支持keyTagPattern模式, 只抽取Key的一部分做Hash, 通过合理命名Key, 可以将相关的Key放入同一个Redis节点. 扩容问题 – presharding: 需要扩容时, 实际是把小的Redis实例数据复制到大的Redis实例, 复制完成后, 大的Redis实例替换小的Redis实例; 需要扩容的Redis设为主, 新Redis设置为从, 完成数据同步后, 原实例的Shard给新实例用","text":"客户端shardingJava redis客户端驱动jedis，已支持Redis Sharding功能，即ShardedJedis以及结合缓存池的ShardedJedisPool, jedis的特点: 采用一致性哈希算法(consistent hashing)，将key和节点name同时hashing，采用的算法是MURMUR_HASH。采用一致性哈希而不是采用简单类似哈希求模映射的主要原因是当增加或减少节点时，不会产生由于重新匹配造成的rehashing。一致性哈希只影响相邻节点key分配，影响量小。 ShardedJedis支持keyTagPattern模式，即抽取key的一部分keyTag做sharding，这样通过合理命名key，可以将一组相关联的key放入同一个Redis节点，这在避免跨节点访问相关数据时很重要。 ➤ Redis Sharding 方案: 通过客户端进行Sharding, 在Client侧做Sharding, 比如 Jedis 提供的 ShardedJedis: ShardedJedis特性: 使用虚拟节点, 使Key在Redis节点的分布更均匀, 如果一个节点挂掉, 不再是相邻的节点受影响. 每个实体节点默认有160个虚拟节点, ShardedJedis还支持权重, 虚拟节点个数 = 节点权重 x 160 ShardedJedis使用了MurMur Hash做Hash函数, MurMur Hash相比较一般Hash算法, 对于规律性较强的Key随机分布的表现更好. 支持keyTagPattern模式, 只抽取Key的一部分做Hash, 通过合理命名Key, 可以将相关的Key放入同一个Redis节点. 扩容问题 – presharding: 需要扩容时, 实际是把小的Redis实例数据复制到大的Redis实例, 复制完成后, 大的Redis实例替换小的Redis实例; 需要扩容的Redis设为主, 新Redis设置为从, 完成数据同步后, 原实例的Shard给新实例用 代理中间件（Tair/Codis）上面分别介绍了多Redis服务器集群的两种方式，它们是基于客户端sharding的Redis Sharding，和基于服务端sharding的Redis Cluster。 Pre-Sharding方案实际上可以理解为预先分配一个相当大的集合，对Key哈希的结果落在这个集合中，集合的每个元素又与具体的物理节点存在多对一的路由映射关系，这张路由表由一个配置中心进行维护。回过头来再细想下，一致性哈希中的虚拟节点，实际上也可以归类到Pre-Sharding方案中。换句话说，只要是key经过两次哈希，第一次Hash到虚拟节点，第二次Hash到物理节点，都可以算作Pre-Sharding。只不过区别在于，一致性哈希的第二次Hash其路由表是按照算法固定的，Tair/Codis的第二次Hash其路由表是第三方可配的。 扩容详见: Redis集群的数据划分与扩容探讨 - Xueqiu Engineering Blog @Archived","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"Redis-03a2-哨兵（Sentinel）","slug":"31.Backend/Redis-03a2哨兵-Sentinel","date":"2024-01-24T01:27:52.597Z","updated":"2024-01-24T01:27:52.598Z","comments":true,"path":"31.Backend/Redis-03a2哨兵-Sentinel/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/Redis-03a2哨兵-Sentinel/","excerpt":"Redis-Sentinel 简介Redis-Sentinel是Redis官方推荐的高可用性(HA)解决方案，可以实现： Master宕机时自动切换到从 如果发现某个redis节点运行出现状况，能够通知另外一个进程(例如它的客户端); 运行sentinel有两种方式:redis-sentinel /path/to/sentinel.confredis-server /path/to/sentinel.conf --sentinel","text":"Redis-Sentinel 简介Redis-Sentinel是Redis官方推荐的高可用性(HA)解决方案，可以实现： Master宕机时自动切换到从 如果发现某个redis节点运行出现状况，能够通知另外一个进程(例如它的客户端); 运行sentinel有两种方式:redis-sentinel /path/to/sentinel.confredis-server /path/to/sentinel.conf --sentinel ➤ Sentinel 特性： 多个 Sentinel 实例组成一个集群，一个 Sentinel 集群可监视多个 Redis Master 实例； Sentinel 的数据通信： Sentinel 通过向 Redis Master 发送 INFO 命令, 获取它所有的 Slava Sentinel 会订阅自己监视的 Redis Master 的 sentilel:hello 频道, 同时向该 Redis 的频道发送消息, 消息包括 Sentinel 自己的 IP:Port 等, 这样其他的 Sentinel 也会收到此消息, Sentinel 通过发布/订阅的广播方式感知其他 Sentinel 的存在 ➤ 配置文件解读： # 定义一个&apos;mymaster&apos;, 2表示两个Sentinel认为Master挂掉了才算sentinel monitor mymaster 127.0.0.1 6379 2# 在6000ms内ping不通, 则主观认为该实例下线sentinel down-after-milliseconds mymaster 60000sentinel failover-timeout mymaster 180000#表示如果master重新选出来后，其它slave节点能同时并行从新master同步缓存的台数有多少个sentinel parallel-syncs mymaster 1# 当使用了sentinel时，master可能会变成一个slave，slave也可能会变成master ..sentinel auth-pass &lt;master_name&gt; xxxxx Sentinel 如何执行主从 fail-overSentinel 发现主节点宕机, 将会执行主从的 fail-over、并通知 Client 变更: 发现并判断宕机: Sentinel 每秒向监控的 Redis master实例发送PING命令测试其是否宕机, 如果某个主Redis节点返回了错误结果或者Timeout, Sentinel 认为该节点是”主观下线”（SDOWN）, 如果 quorum个 Sentinel都把这个节点标记为下线, 那么 Sentinel master将把这个 Redis节点的状态则被标记为”客观下线”（ODOWN）, 这时才开始执行fail-over; 执行 fail-over：所有 Sentinel 选举出一个 Leader，由 Sentinel Leader 执行 redis 主节点的 fail-over （1）从 Slave 中选取 master：首先按照所有 Slave 的优先级, 如果优先级相同, 则比较 Slave 的复制的下标, 哪个 Slave 复制进度最接近则选举为 Master, 如果优先级和复制下标都相同, 则选进程 ID 较小的，作为新 Master； （2）Sentinel 向新的 Master 发送 SLAVEOF NO ONE, 然后依次向其他的 Slave 发送 SLAVEOF 命令让其跟随新的 Master, 然后 Slave 向新 Master 发送 SYNC 指令开始同步数据, 一个 Slave 完成上述操作后, 开始下一个 Slave… Sentinel leader 把最新的 Redis 配置广播给其他 Sentinel Sentinel 通知调用方: Sentinel 提供了很多频道，例如 +switch-master 频道，主从切换完成后，会在这个频道发布新主的 IP:Port； 客户端（jedis）订阅这些频道，即可获取 Redis 集群的变更消息； Sentinel 如何选举 leader➤ Sentinel的选举何时触发: 在某个 Redis Master节点被认定客观下线后, Sentinel需要选举出一个 Leader, 由 Leader完成 故障转移(从一堆Redis 的Slave节点中选出master, 以及 Slave的重新配置和同步). 或者当 Leader Sentinel节点失效时, 也会开始一轮选举 无论哪种选举, 当选举完成后, 配置纪元(configuration epoch)都会增加一次, 表示一轮选举完成 ➤ Sentinel Leader选举步骤: 当某个 Sentinel 节点认为 “Sentinel master” 客观下线后, 它会做下面几件事情: 把故障转移状态设置为true 自己从 Follower 角色变为 Candidate(候选者) 给自己投一票 当前的配置纪元+1, 并向其他 Sentinel节点发送 SENTINEL is-master-down-by-addr &lt;ip&gt; &lt;port&gt; &lt;current_epoch&gt; &lt;runid&gt; 指令, 解释一下这个指令, &lt;ip&gt; &lt;port&gt; 表示客观下线的 master, &lt;current_epoch&gt;表示配置纪元, 后面的&lt;runid&gt;就是这个Sentinel自己的 runid(唯一标识) 当其他的 Sentinel 节点收到 is-master-down-by-addr 指令后, 会比较指令发来的配置纪元(epoch)和自己保存的配置纪元, 如果发来的配置纪元比自己存储的 epoch 更大(表示这是一次新的投票纪元), 收到 is-master-down-by-addr 指令的节点会把自己的选票投给这个发出 is-master-down-by-addr 指令的 Candidate, 并更新自己的配置纪元, 在一个配置纪元内一个 Follower 只能投一篇. 然后 Follower 给这个 Candidate 回复, 回复内容就是 Candidate 的 runid Candidate 等待来自 Follower 的回复, 如果发现回复内容就是自己的 runid, 会给本轮选举(当前配置纪元)自己选票+1. 如果自己的选票大于半数(这里应该 can-failover 的节点数的一半), 并且选票大于 quorum, 则认为自己当选； @tldr：当选条件是票数＞半数的哨兵实例数，且选票数＞ quorum（客观下线） Reference Redis 高可用部署方案 | hoxis’ blog Redis 哨兵节点之间相互自动发现机制（自动重写哨兵节点的配置文件） - MSSQL123 - 博客园 在Redis Sentinel环境下，jedis该如何配置 - iVictor - 博客园 redis实现HA（High Available）的两种实现方式-Sentinel与Keepalived_数据库_路漫漫，水迢迢-CSDN博客 Redis 高可用部署方案 | hoxis’ blog 浅谈Redis Sentinel 哨兵-选举领头Sentinel和故障转移 - 知乎 Raft协议实战之Redis Sentinel的选举Leader源码解析 - 云+社区 - 腾讯云","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"Redis-03a1-主从","slug":"31.Backend/Redis-03a1主从","date":"2024-01-24T01:27:52.593Z","updated":"2024-01-24T01:27:52.593Z","comments":true,"path":"31.Backend/Redis-03a1主从/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/Redis-03a1主从/","excerpt":"建立主从集群SLAVEOF 命令可以将当前服务器转变为指定服务器的从属服务器(slave server)。注意: 从 Redis 5 起使用 REPLICAOF 替代 SLAVEOF e.g.在从实例执行：replicaof 192.168.0.1 6379 主从间的数据同步➤ 2.8版本之前, Redis 的主从同步分为”全量同步”和”命令传播”两个阶段","text":"建立主从集群SLAVEOF 命令可以将当前服务器转变为指定服务器的从属服务器(slave server)。注意: 从 Redis 5 起使用 REPLICAOF 替代 SLAVEOF e.g.在从实例执行：replicaof 192.168.0.1 6379 主从间的数据同步➤ 2.8版本之前, Redis 的主从同步分为”全量同步”和”命令传播”两个阶段 当slave实例执行SLAVEOF命令时, 会向master发送SYNC命令 master收到命令开始执行BGSAVE, 把内存数据存为RDB格式的文件, 同时在一个缓冲区记录从当前以后的所有写命令. master把RDB文件发送给slave, 然后再将缓冲区的数据发送给slave. Slave写入完成, 主从数据一致, 进入传播阶段, 每当master有数据更新, 把更新的数据传播给Slave 2.8版本的主从同步存在的问题: 每次从服务器发送SYNC命令都会导致主服务器执行BGSAVE, 主服务器生成和传输RDB文件的消耗巨大; ➤ 2.8版本之后的同步: 完整的同步过程仍是分为”全量同步”和”命令传播”两个状态, 但并不是每次同步过程都会执行’BGSAVE 同步’的步骤, 可能直接进入’命令传播’阶段’; 判断是否执行”全量同步”, 是由 “复制偏移量 Offset” / “复制积压缓冲区 ReplicationBacklog” / runnid 共同决定的 master/slave服务器都会存储复制偏移量, master存储的是”向从服务器发送了多少字节”, slave存储的是”从主服务器同步了多少字节”; master还有一个默认1MB大小的”复制积压缓冲区“, 每次master有数据更新, 除了向slave传播, 还会向这个缓冲区写入, 缓冲区大小固定,先进先出 缓冲区存储了每个偏移量和偏移量对应的字节; slave还会存储已同步的master的 run id; slave 向 master 发送 PSYNC 开始同步（例如 psync runID offset，同时还包括了已同步的主实例 runnid 和 offset ）, 同时还将存储的 run id 发送给 master, 如果 runid 和 master 的不一样, 则 master 开始完整同步的第一步骤; 如果 runnid一致, master开始检查 slave发来的偏移量n, 检查n+1是否在缓冲区, 如果n+1不在缓冲区内(主从复制差距大于1MB), 则开始完整同步第一个步骤; master/slave同步完成, slave每秒向master发送REPLCONF ACK &lt;replication_offset&gt;, 其中 replication_offset 是从服务器当前的复制偏移量, 这个命令有三个作用 作为主从服务器的心跳检查 同步复制偏移量 辅助实现 min-slaves 选项: min-slaves-to-write 3, min-slaves-max-lag 10, 这两个配置选项表示: 从服务器数量小于3, 且从服务器写入延迟大于10s, 主拒绝写入 主节点为保障数据稳定性，当从节点挂掉的数量或者延迟过高时。将会拒绝信息同步。 这里有2个参数可以进行配置调整，e.g. min-slaves-to-write 2min-slaves-max-lag 8 表示从节点的数量就剩余2个，或者从节点的延迟大于8秒时，主节点就会强制关闭maste功能，停止数据同步。 复制积压缓冲区（ReplicationBacklog）： 复制缓冲积压区是一个先进先出的队列，用户存储 master 收集数据的命令记录。复制缓冲区的默认存储空间是1M,可以在配置文件修改 repl-backlog-size 1mb 来控制缓冲区大小； 复制缓冲区存储的内容和 AOF 文件相同： 那 repl_backlog_buffer 缓冲区具体要调整到多大呢？ 估算公式：write_size_per_second * second second 为从服务器断线后重新连接上主服务器所需的平均时间(以秒计算)。 write_size_per_second 则是主服务器平均每秒产生的写命令数据量大小。 举个例子，如果主服务器平均每秒产生 1 MB 的写命令，而从服务器断线之后平均要 5 秒才能重新连接主服务器。那么 repl_backlog_buffer 大小就不能低于 5 MB。 @ref: 一文让你明白Redis主从同步 - 知乎 主从切换如果主实例挂掉，主从实例的切换依赖于 Sentinel（哨兵） @link: Redis-03a2哨兵-Sentinel 主从一致性Redis 的主/从一致性分析: 非强一致性: 向 Master 进行写操作, 与”Master 向 Slave 同步数据”操作, 是异步的. 客户端向 Master 写数据并成功返回时, 不能保证 Slave 也同步了刚写入的数据, 故非强一致性; 符合最终一致性: 即使主从网络断开或从宕机, 当恢复后 Slave 会采取多种策略追赶主节点的数据. 哪些情况可能导致主从不一致： 主→从的广播是异步的，见上； Sentinel + Master/Slave 模式下，可能产生脑裂（brain split）的问题，哨兵正在进行主从切换，但… ； Cluster 模式下，","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"Redis-03Raft实现","slug":"31.Backend/Redis-03Raft实现","date":"2024-01-24T01:27:52.588Z","updated":"2024-01-24T01:27:52.589Z","comments":true,"path":"31.Backend/Redis-03Raft实现/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/Redis-03Raft实现/","excerpt":"@toc: Raft协议简述(角色, 任期Term, 发起投票); Redis中是如何实现的Raft? ➤ Raft协议简介: Raft协议是用来解决分布式系统一致性的, 协议包括 选举leader/日志复制-提交机制等等,除Raft外还有 Google的 Paxos协议, 但 Paxos协议难以理解, 更难以实现(仅仅有论文),但 Raft协议正好相反, 易于理解且有实际工程的代码实现 (Redis Sentinel的选举 就是通过Raft协议实现的) Raft协议中的角色: Leader, Follower, Candidate(候选者), 在系统正常状态下只有 Leader和 Follower两种角色, 当有 Follower角色发现 Leader下线(心跳异常), 这个 Follower会暂时变为 Candidate, 然后这个Candidate 向其他 Follower发起给自己的投票, 当有超过半数的Follower给这个Candidate投票, 这个Candidate即成为新的Leader. 在选举过程中, 还有一个需要解决的问题: 选举的时间有效性 (在选举过程中, 除了节点之间交换选举人的信息, 还需要表名这是在进行第几期选举), Raft协议使用 Term(任期)来表示这次选举, 在每次Term中, Follower只有一次投票机会. 当一次选举结束后, 所有节点保存的 Term将会更新, 当下一次某个 Candidate发起选举的时候, 会将 Term + 1 ➤ Redis实现Raft协议:","text":"@toc: Raft协议简述(角色, 任期Term, 发起投票); Redis中是如何实现的Raft? ➤ Raft协议简介: Raft协议是用来解决分布式系统一致性的, 协议包括 选举leader/日志复制-提交机制等等,除Raft外还有 Google的 Paxos协议, 但 Paxos协议难以理解, 更难以实现(仅仅有论文),但 Raft协议正好相反, 易于理解且有实际工程的代码实现 (Redis Sentinel的选举 就是通过Raft协议实现的) Raft协议中的角色: Leader, Follower, Candidate(候选者), 在系统正常状态下只有 Leader和 Follower两种角色, 当有 Follower角色发现 Leader下线(心跳异常), 这个 Follower会暂时变为 Candidate, 然后这个Candidate 向其他 Follower发起给自己的投票, 当有超过半数的Follower给这个Candidate投票, 这个Candidate即成为新的Leader. 在选举过程中, 还有一个需要解决的问题: 选举的时间有效性 (在选举过程中, 除了节点之间交换选举人的信息, 还需要表名这是在进行第几期选举), Raft协议使用 Term(任期)来表示这次选举, 在每次Term中, Follower只有一次投票机会. 当一次选举结束后, 所有节点保存的 Term将会更新, 当下一次某个 Candidate发起选举的时候, 会将 Term + 1 ➤ Redis实现Raft协议: Redis实现的Raft协议中, 使用 configuration epoch (配置纪元)来表示 Term, 在Sentinel的配置文件中, 有can-failover参数, 这个参数表示该节点能否参与选举Leader, 也即是否有可能成为Candidate, 如果can-failover是 false, 表示这个节点用于只能作为 Follower , 此外, Redis 配置中的quorum不仅可以控制认为某个节点”SDOWN”时, 最少确认节点的个数, 也表示成为Leader所需的最小选票数.","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"Redis-02部署和运维","slug":"31.Backend/Redis-02部署和运维","date":"2024-01-24T01:27:52.582Z","updated":"2024-01-24T01:27:52.583Z","comments":true,"path":"31.Backend/Redis-02部署和运维/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/Redis-02部署和运维/","excerpt":"安装&amp;配置 启动: /opt/apps/redis/bin/redis-server /opt/conf/redis/${port}.conf conf文件: http://yijiebuyi.com/blog/bc2b3d3e010bf87ba55267f95ab3aa71.html 命令行 连接本地: redis-cli -p 6379 连接远程: redis-cli -h host -p port -a pwd","text":"安装&amp;配置 启动: /opt/apps/redis/bin/redis-server /opt/conf/redis/${port}.conf conf文件: http://yijiebuyi.com/blog/bc2b3d3e010bf87ba55267f95ab3aa71.html 命令行 连接本地: redis-cli -p 6379 连接远程: redis-cli -h host -p port -a pwd 以下参考: http://redisdoc.com/index.html sys/info类命令 SELECT: 选择数据库, 比如SELECT 0选择0号数据库(默认的) INFO : 返回信息, @ref: http://redisdoc.com/server/info.html MONITOR : 可以看到实时的查询信息(查询来源IP.), 注意这个命令对性能有影响 DBSIZE : 返回当前库Key的数量 FLUSHDB/FLUSHALL: 清空当前库, 清空整个Redis的数据 CLIENT LIST : 获取连接到服务器的客户端连接列表 CLIENTKILL [ip:port] [ID client-id] : 关闭客户端连接 CONFIG GET * 获取所有参数 CONFIG SET 参数 值 BGSAVE: 异步持久化, 不要用SAVE! key类命令 TYPE key 返回 key 所储存的值的类型。 DEL key [key ...]: 删除给定的一个或多个 key 。时间复杂度：O(N)， N 为被删除的 key 的数量 EXISTS key: 检查给定 key 是否存在 RANDOMKEY: 从当前数据库中随机返回(不删除)一个 key 。 KEYS pattern: 查找所有符合给定模式 pattern 的 key（慎用！） 。时间复杂度： O(N)， N 为数据库中 key 的数量。 KEYS * 匹配数据库中所有 key 。 KEYS h?llo 匹配 hello ， hallo 和 hxllo 等。 SCAN 0 增量迭代式获取，返回的游标被用作下一次SCAN X，每次执行都只会返回少量元素， 所以可以用于生产环境 SORT key DESC: 返回键值从大到小排序的结果。 EXPIRE key seconds: 为给定 key 设置生存时间，当 key 过期时(生存时间为 0 )，它会被自动删除。 生存时间可以通过使用 DEL 命令来删除整个 key 来移除，或者被 SET 和 GETSET 命令覆写(overwrite) 对一个 key 执行 INCR 命令，对一个列表进行 LPUSH 命令，或者对一个哈希表执行 HSET 命令，这类操作都不会修改 key 本身的生存时间。 TTL key : 以秒为单位，返回给定 key 的剩余生存时间(TTL, time to live)。 慢查询 SLOWLOG GET 1000: 获取1000条慢查询 SLOWLOG RESET 可以清空 slow log CONFIG GET slowlog-log-slower-than 获取慢查询设置, 单位是微秒, 默认10,000(10毫秒), 超过10毫秒需关注 CONFIG SET slowlog-log-slower-than 10000 性能测试 redis 性能测试的基本命令如下：redis-benchmark [option] [option value] 以下实例同时执行 10000 个请求来检测性能：redis-benchmark -n 10000 -q -c: 指定并发连接数 -n: 指定请求数 -d: 以字节的形式指定 SET/GET 值的数据大小 持久化Redis 分别提供了 RDB 和 AOF 两种持久化模式 RDB: http://redisbook.readthedocs.io/en/latest/internal/rdb.html 在不同的时间点，将redis存储的数据生成快照并存储到磁盘等介质上； 对于RDB方式，redis会单独创建（fork）一个子进程来进行持久化，而主进程是不会进行任何IO操作，保证性能 在默认情况下， Redis 将数据库快照保存在名字为 dump.rdb 的二进制文件中。你可以对 Redis 进行设置， 让它在“ N 秒内数据集至少有 M 个改动”这一条件被满足时， 自动保存一次数据集。你也可以通过调用 SAVE 或者 BGSAVE ， 手动让 Redis 进行数据集保存操作。 AOF: https://redisbook.readthedocs.io/en/latest/internal/aof.html Append Only File，即只允许追加不允许改写的文件 AOF 持久化记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。 AOF 的默认策略为每秒钟 fsync 一次，在这种配置下，Redis 仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据 Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作。 RDB-AOF混合持久化: Redis 4.0 新功能简介：RDB-AOF 混合持久化 — blog.huangz.me INFO返回信息 server 部分记录了 Redis 服务器的信息，它包含以下域： * redis_version : Redis 服务器版本* redis_git_sha1 : Git SHA1* redis_git_dirty : Git dirty flag* os : Redis 服务器的宿主操作系统* arch_bits : 架构（32 或 64 位）* multiplexing_api : Redis 所使用的事件处理机制* gcc_version : 编译 Redis 时所使用的 GCC 版本* process_id : 服务器进程的 PID* run_id : Redis 服务器的随机标识符（用于 Sentinel 和集群）* tcp_port : TCP/IP 监听端口* uptime_in_seconds : 自 Redis 服务器启动以来，经过的秒数* uptime_in_days : 自 Redis 服务器启动以来，经过的天数* lru_clock : 以分钟为单位进行自增的时钟，用于 LRU 管理 clients 部分记录了已连接客户端的信息，它包含以下域： * connected_clients : 已连接客户端的数量（不包括通过从属服务器连接的客户端）* client_longest_output_list : 当前连接的客户端当中，最长的输出列表* client_longest_input_buf : 当前连接的客户端当中，最大输入缓存* blocked_clients : 正在等待阻塞命令（BLPOP、BRPOP、BRPOPLPUSH）的客户端的数量 memory 部分记录了服务器的内存信息，它包含以下域： * used_memory : 由 Redis 分配器分配的内存总量，以字节（byte）为单位* used_memory_human : 以人类可读的格式返回 Redis 分配的内存总量* used_memory_rss : 从操作系统的角度，返回 Redis 已分配的内存总量（俗称常驻集大小）。这个值和 top 、 ps 等命令的输出一致。* used_memory_peak : Redis 的内存消耗峰值（以字节为单位）* used_memory_peak_human : 以人类可读的格式返回 Redis 的内存消耗峰值* used_memory_lua : Lua 引擎所使用的内存大小（以字节为单位）* mem_fragmentation_ratio : used_memory_rss 和 used_memory 之间的比率* mem_allocator : 在编译时指定的， Redis 所使用的内存分配器。可以是 libc 、 jemalloc 或者 tcmalloc 。 在理想情况下， used_memory_rss 的值应该只比 used_memory 稍微高一点儿。当 rss &gt; used ，且两者的值相差较大时，表示存在（内部或外部的）内存碎片。内存碎片的比率可以通过 mem_fragmentation_ratio 的值看出。当 used &gt; rss 时，表示 Redis 的部分内存被操作系统换出到交换空间了，在这种情况下，操作可能会产生明显的延迟。Because Redis does not have control over how its allocations are mapped to memory pages, high used_memory_rss is often the result of a spike in memory usage. 当 Redis 释放内存时，分配器可能会，也可能不会，将内存返还给操作系统。如果 Redis 释放了内存，却没有将内存返还给操作系统，那么 used_memory 的值可能和操作系统显示的 Redis 内存占用并不一致。查看 used_memory_peak 的值可以验证这种情况是否发生。 persistence 部分记录了跟 RDB 持久化和 AOF 持久化有关的信息，它包含以下域： * loading : 一个标志值，记录了服务器是否正在载入持久化文件。* rdb_changes_since_last_save : 距离最近一次成功创建持久化文件之后，经过了多少秒。* rdb_bgsave_in_progress : 一个标志值，记录了服务器是否正在创建 RDB 文件。* rdb_last_save_time : 最近一次成功创建 RDB 文件的 UNIX 时间戳。* rdb_last_bgsave_status : 一个标志值，记录了最近一次创建 RDB 文件的结果是成功还是失败。* rdb_last_bgsave_time_sec : 记录了最近一次创建 RDB 文件耗费的秒数。* rdb_current_bgsave_time_sec : 如果服务器正在创建 RDB 文件，那么这个域记录的就是当前的创建操作已经耗费的秒数。* aof_enabled : 一个标志值，记录了 AOF 是否处于打开状态。* aof_rewrite_in_progress : 一个标志值，记录了服务器是否正在创建 AOF 文件。* aof_rewrite_scheduled : 一个标志值，记录了在 RDB 文件创建完毕之后，是否需要执行预约的 AOF 重写操作。* aof_last_rewrite_time_sec : 最近一次创建 AOF 文件耗费的时长。* aof_current_rewrite_time_sec : 如果服务器正在创建 AOF 文件，那么这个域记录的就是当前的创建操作已经耗费的秒数。* aof_last_bgrewrite_status : 一个标志值，记录了最近一次创建 AOF 文件的结果是成功还是失败。 如果 AOF 持久化功能处于开启状态，那么这个部分还会加上以下域： * aof_current_size : AOF 文件目前的大小。* aof_base_size : 服务器启动时或者 AOF 重写最近一次执行之后，AOF 文件的大小。* aof_pending_rewrite : 一个标志值，记录了是否有 AOF 重写操作在等待 RDB 文件创建完毕之后执行。* aof_buffer_length : AOF 缓冲区的大小。* aof_rewrite_buffer_length : AOF 重写缓冲区的大小。* aof_pending_bio_fsync : 后台 I/O 队列里面，等待执行的 fsync 调用数量。* aof_delayed_fsync : 被延迟的 fsync 调用数量。 stats 部分记录了一般统计信息，它包含以下域： * total_connections_received : 服务器已接受的连接请求数量。* total_commands_processed : 服务器已执行的命令数量。* instantaneous_ops_per_sec : 服务器每秒钟执行的命令数量。* rejected_connections : 因为最大客户端数量限制而被拒绝的连接请求数量。* expired_keys : 因为过期而被自动删除的数据库键数量。* evicted_keys : 因为最大内存容量限制而被驱逐（evict）的键数量。* keyspace_hits : 查找数据库键成功的次数。* keyspace_misses : 查找数据库键失败的次数。* pubsub_channels : 目前被订阅的频道数量。* pubsub_patterns : 目前被订阅的模式数量。* latest_fork_usec : 最近一次 fork() 操作耗费的毫秒数。 replication : 主/从复制信息 * role : 如果当前服务器没有在复制任何其他服务器，那么这个域的值就是 master ；否则的话，这个域的值就是 slave。注意，在创建复制链的时候，一个从服务器也可能是另一个服务器的主服务器。* 如果当前服务器是一个从服务器的话，那么这个部分还会加上以下域： * master_host : 主服务器的 IP 地址。 * master_port : 主服务器的 TCP 监听端口号。 * master_link_status : 复制连接当前的状态， up 表示连接正常， down 表示连接断开。 * master_last_io_seconds_ago : 距离最近一次与主服务器进行通信已经过去了多少秒钟。 * master_sync_in_progress : 一个标志值，记录了主服务器是否正在与这个从服务器进行同步。* 如果同步操作正在进行，那么这个部分还会加上以下域： * master_sync_left_bytes : 距离同步完成还缺少多少字节数据。 * master_sync_last_io_seconds_ago : 距离最近一次因为 SYNC 操作而进行 I/O 已经过去了多少秒。* 如果主从服务器之间的连接处于断线状态，那么这个部分还会加上以下域： * master_link_down_since_seconds : 主从服务器连接断开了多少秒。 cpu 部分记录了 CPU 的计算量统计信息，它包含以下域： * used_cpu_sys : Redis 服务器耗费的系统 CPU 。* used_cpu_user : Redis 服务器耗费的用户 CPU 。* used_cpu_sys_children : 后台进程耗费的系统 CPU 。* used_cpu_user_children : 后台进程耗费的用户 CPU 。 commandstats 部分记录了各种不同类型的命令的执行统计信息，比如命令执行的次数、命令耗费的 CPU 时间、执行每个命令耗费的平均 CPU 时间等等。对于每种类型的命令，这个部分都会添加一行以下格式的信息： * cmdstat_XXX:calls=XXX,usec=XXX,usecpercall=XXX cluster 部分记录了和集群有关的信息，它包含以下域： * cluster_enabled : 一个标志值，记录集群功能是否已经开启。* keyspace 部分记录了数据库相关的统计信息，比如数据库的键数量、数据库已经被删除的过期键数量等。对于每个数据库，这个部分都会添加一行以下格式的信息： dbXXX:keys=XXX,expires=XXX 参考 Redis 设计与实现 Redis 命令参考 Redis 源码日志","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[{"name":"后端架构","slug":"后端架构","permalink":"https://beefyheisenberg.github.io/tags/后端架构/"},{"name":"缓存","slug":"缓存","permalink":"https://beefyheisenberg.github.io/tags/缓存/"},{"name":"数据库","slug":"数据库","permalink":"https://beefyheisenberg.github.io/tags/数据库/"},{"name":"NoSQL","slug":"NoSQL","permalink":"https://beefyheisenberg.github.io/tags/NoSQL/"},{"name":"Redis","slug":"Redis","permalink":"https://beefyheisenberg.github.io/tags/Redis/"},{"name":"K-V","slug":"K-V","permalink":"https://beefyheisenberg.github.io/tags/K-V/"}]},{"title":"Redis-01b数据结构-内部实现","slug":"31.Backend/Redis-01b数据结构的实现","date":"2024-01-24T01:27:52.577Z","updated":"2024-01-24T01:27:52.578Z","comments":true,"path":"31.Backend/Redis-01b数据结构的实现/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/Redis-01b数据结构的实现/","excerpt":"键值对数据库 每个 redisServer 实例包含多个 DB，每个 DB 在内存中使用 redisDb 结构体表示； 每个 redisDb 包含2个 dictht（dict hashtable）字典，字典中包含了所有的键值对，我们也称该字典为键空间(key space)。其中第二个字典 ht[1] 指向 null，只在rehash 过程中才会被分配内存； 每个键值对 对应的数据结构是 dictEntry，其主要包含三个成员：key、value、next，其中 key 和 value 的类型都是 void*，该指针指向类型是 redisObject； redisObject 是 Redis 中各种数据类型的抽象，主要包含三个成员：type、encoding、ptr，根据不同的 type 和 encoding，ptr 可以指向 String，List，Hash，Set，SortedSet 等… typedef struct redisObject &#123; unsigned type; unsigned encoding; unsigned lru; int refcount; void *ptr;&#125;robj; redisObject","text":"键值对数据库 每个 redisServer 实例包含多个 DB，每个 DB 在内存中使用 redisDb 结构体表示； 每个 redisDb 包含2个 dictht（dict hashtable）字典，字典中包含了所有的键值对，我们也称该字典为键空间(key space)。其中第二个字典 ht[1] 指向 null，只在rehash 过程中才会被分配内存； 每个键值对 对应的数据结构是 dictEntry，其主要包含三个成员：key、value、next，其中 key 和 value 的类型都是 void*，该指针指向类型是 redisObject； redisObject 是 Redis 中各种数据类型的抽象，主要包含三个成员：type、encoding、ptr，根据不同的 type 和 encoding，ptr 可以指向 String，List，Hash，Set，SortedSet 等… typedef struct redisObject &#123; unsigned type; unsigned encoding; unsigned lru; int refcount; void *ptr;&#125;robj; redisObjectredisObject 主要成员： unsigned type：存储对象的类型，也即 ptr 指针指向的数据类型（String、List、Hash、Set、ZSet 中的一种） unsigned encoding：存储对象使用的编码方式，也即 ptr 指针指向的数据块用何种编码，不同的编码方式使用不同的数据结构进行存储。例如 String 类型的对象，可能的编码方式有 REDIS_ENCODING_INT、REDIS_ENCODING_EMBSTR、REDIS_ENCODING_RAW 三种； unsigned lru：存储 redisObject 上次被访问的时间戳，详见「Key过期」 void *ptr：根据 type+encodng，可能指向不同的数据结构 type 和 encoding 的组合： 数据类型（type） 编码格式（encoding） REDIS_STRING REDIS_ENCODING_INT REDIS_ENCODING_EMBSTR REDIS_ENCODING_RAW REDIS_LIST REDIS_ENCODING_LINKEDLIST REDIS_ENCODING_ZIPLIST（压缩列表） REDIS_ENCODING_QUICKLIST（3.2新增） REDIS_SET REDIS_ENCODING_INTSET REDIS_ENCODING_HT（哈希表） REDIS_ZSET REDIS_ENCODING_ZIPLIST REDIS_ENCODING_SKIPLIST（跳表） REDIS_HASH REDIS_ENCODING_ZIPLIST REDIS_ENCODING_HT Redis 数据类型的底层数据结构随着版本的更新也有所不同，比如： 在 Redis 3.0 版本中 List 对象的底层数据结构由「双向链表」或「压缩表列表」实现，但是在 3.2 版本之后，List 数据类型底层数据结构是由 quicklist 实现的； 在最新的 Redis 代码（还未发布正式版本）中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。 数据结构的实现StringRedis 的字符串被称为 SDS（Simple Dynamic String，简单动态字符串） ➤ redisObject.type = REDIS_STRING, 支持 INT、EMBSTR、RAW 三种编码， 如果字符串的值是整数，同时可以使用 long 来进行表示，那么 Redis 将会使用 INT 编码方式，INT 编码方式会将 RedisObject 中的 *ptr 指针直接改写成 long ptr，ptr 属性直接存储字面量：![[../_images/Redis-01b数据结构-内部实现-2023-07-05-1.png]] 如果字符串的值是字符，同时字符串的大小 ＜ 32个字节，那么 Redis 将会使用 EMBSTR 编码方式，RedisObject 和 SDS 共同使用同一块内存单元，Redis 内存分配器只需要分配一次内存：![[../_images/Redis-01b数据结构-内部实现-2023-07-05-2.png]] 如果字符串的值是字符，同时字符串的大小＞32个字节，那么 Redis 将会使用 RAW 编码方式。RedisObject 和 SDS 是分开申请的两块内存：![[../_images/Redis-01b数据结构-内部实现-2023-07-05-3.png]] ➤ 编码转换 &amp; 升级： 如果字符串的值不再是整数或者用 long 无法进行表示，那么 INT 编码方式将会转换成 RAW 编码方式。 如果字符串的值其大小大于32个字节，那么 EMBSTR 编码方式将会转换成 RAW 编码方式。 INT 编码方式不能转换成 EMBSTR 编码方式。 ➤ 字符串类型的 redisObject，其 ptr 指向的是 SDS 类型（simple dynamic string）的实现（Redis 5.0）： struct __attribute__ ((__packed__)) sdshdr5 &#123; unsigned char flags; /* 3 lsb of type, and 5 msb of string length */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr8 &#123; uint8_t len; /* used */ uint8_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;; len，记录了字符串长度。这样获取字符串长度的时候时间复杂度只需要 O（1）； alloc，分配给字符数组的空间长度。这样在修改字符串的时候，可以通过 alloc - len 计算出剩余的空间大小，可以用来判断空间是否满足修改需求，如果不满足的话，就会自动将 SDS 的空间扩展至执行修改所需的大小，然后才执行实际的修改操作； flags，用来表示不同类型的 SDS。一共设计了 5 种类型，分别是 sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64，区别是 len 和 alloc 成员变量的类型不同； buf，字符数组，用来保存实际数据。不仅可以保存字符串，也可以保存二进制数据； ➤ SDS 设计解析： 字符串结尾判断使用 len，而不是 &#39;\\0&#39;，这样可以让 sds 也可以存储二进制数据； sds 的 buf 数组有冗余的空间，减少了内存分配频率； 之所以 SDS 设计不同类型的结构体，是为了能灵活保存不同大小的字符串，从而有效节省内存空间。比如，在保存小字符串时，结构头占用空间也比较少； 指定了对齐方式 __attribute__ ((packed)) ，它的作用是：告诉编译器取消结构体在编译过程中的优化对齐，按照实际占用字节数进行对齐 // 默认情况下编译器按照“字段相对于结构体首地址的偏移，能够被该字段的 size 整除”， ListredisObject.type = REDIS_LIST，支持 ZIPLIST、LINKEDLIST 两种编码方式： 如果列表对象保存的元素的数量少于512个，同时每个元素的大小都小于64个字节，那么 Redis 将会使用 ZIPLIST 编码方式： ![[../_images/Redis-01b数据结构-内部实现-2023-07-05-4.png]] 如果列表对象保存的元素的数量多于512个，或者元素的大小大于64个字节，那么 Redis 将会使用 LINKEDLIST 编码方式：![[../_images/Redis-01b数据结构-内部实现-2023-07-05-5.png]] ➤ 编码转换和升级：如果列表对象保存的元素的数量多于512个，或者元素的大小大于64个字节，那么 Redis 将会使用 LINKEDLIST 编码方式。 ➤ zlist （ZIPLIST 编码）的实现：连续的内存块 ![[../_images/Redis-01b数据结构-内部实现-2023-07-05-12.png]] uint32_t zlbytes：保存了 ziplist 占用的字节数，包含 zlbytes 字段本身占用的4个字节。 uint32_t zltail：最后一个entry的字节偏移量(非zlend)。用于从list的另一端执行pop操作(即倒序遍历) uint16_t zllen：entry 的数目。当保存的 entry 大于2^16-2个 entry 时，则将该值设置为2^16-1，此时需要遍历整个 entry list 来计算 list 中的 entry 数目 uint8_t zlend：表示ziplist中的最后一个entry。字节编码等同于255(即FF)。表示ziplist的结束符 zlist 节点包含三部分内容： prevlen，记录了「前一个节点」的长度，目的是为了实现从后向前遍历； encoding，记录了当前节点实际数据的 类型和长度，类型主要有两种：字符串和整数。 data，记录了当前节点的实际数据，类型和长度都由 encoding 决定； 相比较链表型，zlist 节点没有 next 指针，并且根据 encoding 灵活决定 data 的大小，但是缺点也很明显： 连锁更新：一个 entry 被更新，假如长度发生变化，后续 entry 也都受影响，需要对 zlist 进行重新内存分配； zlist 除了用在 LIST，还可能用在 HashMap、Set 中，查找效率较差 ➤ list （LINKEDLIST 编码）的实现： typedef struct list &#123; //链表头节点 listNode *head; //链表尾节点 listNode *tail; //节点值复制函数 void *(*dup)(void *ptr); //节点值释放函数 void (*free)(void *ptr); //节点值比较函数 int (*match)(void *ptr, void *key); //链表节点数量 unsigned long len;&#125; list;typedef struct listNode &#123; //前置节点 struct listNode *prev; //后置节点 struct listNode *next; //节点的值 void *value;&#125; listNode; ➤ 设计解析： list 结构为链表提供了链表头指针 head、链表尾节点 tail、链表节点数量 len、以及可以自定义实现的 dup、free、match 函数。 list 结构因为提供了链表节点数量 len，所以获取链表中的节点数量的时间复杂度只需 O(1)； Redis 3.0 的 List 对象在数据量比较少的情况下，会采用 Zlist「压缩列表」作为底层数据结构的实现，它的优势是节省内存空间，并且是内存紧凑型的数据结构。 HashMapredisObject.type = REDIS_HASH，支持 ZIPLIST 和 HASHTABLE 两种编码方式： 如果哈希对象保存的键值对的数量少于512个，同时每个键值对中的键和值的大小都小于64个字节，那么 Redis 将会使用 ZIPLIST 编码方式： ![[../_images/Redis-01b数据结构-内部实现-2023-07-05-6.png]] 如果哈希对象保存的键值对的数量多于512个，或者键值对中的键或值的大小大于64个字节，那么 Redis 将会使用 HASHTABLE 编码方式： ![[../_images/Redis-01b数据结构-内部实现-2023-07-05-7.png]] ➤ 编码转换：如果哈希对象保存的键值对的数量多于512个，或者键或值中的键和值的字符串的大小大于64个字节，那么 Redis 将会使用 HASHTABLE 编码方式。 ➤哈希表的桶数组中的元素类型是 dictEntry：typedef struct dictEntry &#123; //键值对中的键 void *key; //键值对中的值 union &#123; void *val; uint64_t u64; int64_t s64; double d; &#125; v; //指向下一个哈希表节点，形成链表 struct dictEntry *next;&#125; dictEntry; dictEntry 结构里不仅包含指向键和值的指针，还包含了指向下一个哈希表节点的指针，这个指针可以将多个哈希值相同的键值对链接起来，以此来解决哈希冲突的问题，这就是链式哈希。 dictEntry 结构里键值对中的值是一个「联合体 v」定义的，因此，键值对中的值可以是一个指向实际值的指针，或者是一个无符号的 64 位整数或有符号的 64 位整数或 double 类的值。这么做的好处是可以节省内存空间，因为当「值」是整数或浮点数时，就可以将值的数据内嵌在 dictEntry 结构里，无需再用一个指针指向实际的值，从而节省了内存空间。 ➤ 哈希冲突： HashMap 使用链表法解决 hash 冲突 ➤ Rehash： 触发条件： 当负载因子大于等于 1 ，并且 Redis 没有在执行 bgsave 命令或者 bgrewiteaof 命令，也就是没有执行 RDB 快照或没有进行 AOF 重写的时候，就会进行 rehash 操作。负载因子 = ht[0].used / ht[0].size 当负载因子大于等于 5 时，此时说明哈希冲突非常严重了，不管有没有有在执行 RDB 快照或 AOF 重写，都会强制进行 rehash 操作。 渐进式 Rehash 过程： 给 ht[1] 分配空间，一般比 ht[0] 大 2 倍； 在字典中维持一个索引计数器变量 rehashidx ，并将它的值设置为 0 ，表示 rehash 工作正式开始 在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一 随着字典操作的不断执行， 最终在某个时间点上， ht[0] 的所有键值对都会被 rehash 至 ht[1] ， 这时程序将 rehashidx 属性的值设为 -1 ， 表示 rehash 操作已完成。 SetredisObject type = REDIS_SET，支持INTSET和HASHTABLE两种编码方式。 如果集合对象保存的元素的数量少于512个，同时每个元素都是整数，那么 Redis 将会使用 INTSET 编码方式：![[../_images/Redis-01b数据结构-内部实现-2023-07-05-8.png]] 如果集合对象保存的元素的数量多于512个，或者元素不是整数，那么 Redis 将会使用 HASHTABLE 编码方式： ![[../_images/Redis-01b数据结构-内部实现-2023-07-05-9.png]]➤ 编码转换：如果集合对象保存的元素的数量多于512个，或者元素不是整数，那么Redis将会使用HASHTABLE编码方式。 Sorted SetredisObject type = REDIS_ZSET，支持 ZIPLIST 和 SKIPLIST 两种编码方式： 如果有序集合对象保存的元素的数量少于128个，同时每个元素的大小都小于64个字节，那么 Redis 将会使用 ZIPLIST 编码方式：![[../_images/Redis-01b数据结构-内部实现-2023-07-05-10.png]] 如果有序集合对象保存的元素的数量多于128个，或者元素的大小大于64个字节，那么 Redis 将会使用 SKIPLIST 编码方式：![[../_images/Redis-01b数据结构-内部实现-2023-07-05-11.png]] 注意 ZSET 的实现中，除了 skiplist，还有一个哈希表，当向 ZSET 插入数据的时候，会向 skiplist 和哈希表依次插入，哈希表是为了让 ZSCORE 等命令可以实现常数级复杂度； ➤ 编码转换：如果有序集合对象保存的元素的数量多于128个，或者元素的大小大于64个字节，那么Redis将会使用SKIPLIST编码方式。 ➤ 跳表的实现： typedef struct zset &#123; dict *dict; zskiplist *zsl; &#125; zset;typedef struct zskiplist &#123; struct zskiplistNode *header, *tail; unsigned long length; int level;&#125; zskiplist;typedef struct zskiplistNode &#123; //Zset 对象的元素值 sds ele; //元素权重值 double score; //后向指针 struct zskiplistNode *backward; //节点的level数组，保存每层上的前向指针和跨度 struct zskiplistLevel &#123; struct zskiplistNode *forward; // 同一层的后续节点 unsigned long span; // 跨度，用来记录两个节点之间的距离 &#125; level[]; &#125; zskiplistNode; zset 包含一个 dict 和一个 skiplist； zskiplist 包含 header 和 tail，指向头尾节点，level 记录当前跳表的最大层数； node 的 backward 指针，指向前面一个节点，方便倒序遍历； level 的 span （跨度），是为了快速计算该节点的 rank，forward 指向下个节点，正向遍历时使用； ![[../_images/Redis-01b数据结构-内部实现-2023-07-06-1.png]] 查询过程： 从最高层的头结点开始； 如果当前节点的权重「小于」要查找的权重时，跳表就会访问该层的下一个节点； 如果当前节点的权重「等于」要查找的权重时，并且当前节点的 SDS 类型数据「小于」要查找的数据时，跳表就会访问该层上的下一个节点； 如果上面两个条件都不满足，或者下一个节点为空时，跳表就会使用目前遍历到的节点的 level 数组里的下一层指针，然后沿着下一层指针继续查找； 复杂度分析： 查找的平均复杂度：O(logN) 构建过程： 插入一个 （ele，score） 对，首先计算在哪一层插入, 层数的计算代码，层数越高的概率越小，该层也就越稀疏： #define ZSKIPLIST_MAXLEVEL 32 //最大层数#define ZSKIPLIST_P 0.25 //Pint zslRandomLevel(void) &#123; int level = 1; while ((random()&amp;0xFFFF) &lt; (ZSKIPLIST_P * 0xFFFF)) level += 1; return (level&lt;ZSKIPLIST_MAXLEVEL) ? level : ZSKIPLIST_MAXLEVEL;&#125; 随机生成的值（介于1到32之间）也即层数K，同时也是 level 数组的大小 确定了层数 K，则需要更新 K-1层上的索引； @ref: 跳表复杂度分析：Redis 为什么用跳表而不用平衡树？ - 掘金 HBase 的 MemStore 使用了 JDK 中的跳表 ConcurrentSkipListMap @ref: https://juejin.cn/post/7084811033549733902 BitMap@todo","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"Redis-01a数据结构","slug":"31.Backend/Redis-01a数据结构","date":"2024-01-24T01:27:52.573Z","updated":"2024-01-24T01:27:52.573Z","comments":true,"path":"31.Backend/Redis-01a数据结构/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/Redis-01a数据结构/","excerpt":"Redis是一个K-V的数据库，“V” 的数据类型分为：String、Hash、List、Set、Sorted Set。 StringString 数据结构是简单的 key-value 类型，value 不仅可以是 String，也可以是数字（当数字类型用 Long 可以表示的时候encoding 就是整型，其他都存储在 sdshdr 当做字符串）。 sds是在Redis中被广泛使用的字符串结构，它的全称是Simple Dynamic String。参考 Redis内部数据结构详解(2)——sds @ref","text":"Redis是一个K-V的数据库，“V” 的数据类型分为：String、Hash、List、Set、Sorted Set。 StringString 数据结构是简单的 key-value 类型，value 不仅可以是 String，也可以是数字（当数字类型用 Long 可以表示的时候encoding 就是整型，其他都存储在 sdshdr 当做字符串）。 sds是在Redis中被广泛使用的字符串结构，它的全称是Simple Dynamic String。参考 Redis内部数据结构详解(2)——sds @ref String相关命令包括 SET/GET类命令，对字符串的值APPEND/SETRANGE操作，还包括 同时设置值和过期时间的原子操作SETEX，但是其他数据类型没有类似SETEX的原子操作。 SET key value：设置key关联的字符串 GET key：返回key关联的字符串 APPEND key value：在字符串后追加value STRLEN key： 返回字符串长度 SETRANGE key 0 &quot;xxx&quot;： 把key对应的字符串从0开始，用“xxx”覆盖。时间复杂度O(M)， M 为 value 参数的长度。 INCR key：将 key 中储存的数字值+1，数字范围是有符号long INCRBY key increment：将 key 所储存的值加上增量 increment DECR key：将 key 中储存的数字值减一。 DECRBY by decrement：将 key 所储存的值减去减量 decrement 。 过期时间： SETEX key seconds value：将值 value 关联到 key ，并将 key 的生存时间设为 seconds (以秒为单位)。 SETEX 是一个原子性(atomic)操作 批量操作： MGET key1 key2：返回所有(一个或多个)给定 key 的值。时间复杂度O(N) ，N 为给定 key1..key2 的数量。 MSET key1 value2 key1 value2： 设置key1…key2对应的字符串。时间复杂度：O(N)， N 为要设置的 key 数量。 BIT操作： SETBIT key offset value：对key所储存的字符串值，设置或清除指定偏移量上的位(bit)，value只能是0或1，offset小于2^32（512MB） GETBIT key offset：返回offset位上的值（0/1） BITCOUNT key ： 计算给定字符串中，被设置为 1 的比特位的数量。 HashMap字典实现，key对应的内容是由field-value组成的键值对。 HSET key field value：将哈希表 key 中的域 field 的值设为 value，O(1) HGET key field：返回哈希表 key 中给定域 field 的值。 HKEYS key：返回哈希表 key 中的所有域。时间复杂度：O(N)， N 为哈希表的大小。 HGETALL key ：返回哈希表 key 中所有的域和值。时间复杂度：O(N)， N 为哈希表的大小。 HVALS key：返回哈希表 key 中所有域的值。时间复杂度：O(N)， N 为哈希表的大小。 HEXISTS key field：查看哈希表 key 中，给定域 field 是否存在。 HSCAN key cursor：命令用于迭代哈希键中的键值对。具体信息请参考 SCAN 命令。 HDEL key field [field ...]：删除哈希表 key 中的一个或多个指定域，不存在的域将被忽略。时间复杂度：O(N)， N 为要删除的域的数量。 HLEN key： 返回键值对数量 HINCRBY key field increment ：为哈希表 key 中的域 field 的值加上增量 increment 。 批量操作： HMSET key field1 value1 field2 value2： 同时将多个 field-value (域-值)对设置到哈希表 key 中。O(N)， N 为 field-value 对的数量。 HMGET field1 field2： 返回哈希表 key 中，一个或多个给定域的值。O(N)， N 为 field-value 对的数量。 List双向队列，队列的 L/R 端都可以进行 POP 和 PUSH 操作： LPOP key ：移除并返回列表 key 的头元素。 LPUSH key value [value ...] ：将一个或多个值 value 插入到列表 key 的表头 RPUSH key value [value ...]：将一个或多个值 value 插入到列表 key 的表尾(最右边)。 RPOP key：移除并返回列表 key 的尾元素。 LLEN key ：返回列表 key 的长度。 随机查询 &amp; 插入： LINDEX key index ：返回列表 key 中，下标为 index 的元素。时间复杂度：O(N)， N 为到达下标 index 过程中经过的元素数量。 LINSERT key BEFORE|AFTER pivot value ：将值 value 插入到列表 key 当中，位于值 pivot 之前或之后。时间复杂度：O(N)， N 为寻找 pivot 过程中经过的元素数量。 LINSERT mylist BEFORE &quot;World&quot; &quot;There&quot; ：会先在List寻找”World”，找到后在”World”之前插入”There” 阻塞L/R端弹出： BLPOP key [key ...] timeout ：BLPOP 是列表的阻塞式(blocking)弹出原语。它是 LPOP 命令的阻塞版本，当给定列表内没有任何元素可供弹出的时候，连接将被 BLPOP 命令阻塞，直到等待超时或发现可弹出元素为止。 BRPOP key [key ...] timeout ：参考如上 Set不重复元素的集合 SADD key v1 v2 ：添加多个值到集合key之中，时间复杂度：O(N)， N 是被添加的元素的数量。 SPOP key ：移除并返回集合中的一个随机元素。 SMEMBERS key：返回集合 key 中的所有成员。时间复杂度：O(N)， N 为集合的元素数量。 SSREM key member [member ...]：移除集合 key 中的一个或多个 member 元素，时间复杂度：O(N)， N 为给定 member 元素的数量。 SISMEMBER key member：判断 member 元素是否集合 key 的成员。时间复杂度：O(1) SCARD key：返回集合中元素的数量。时间复杂度：O(1) SSCAN key cursor：详细信息请参考 SCAN 命令。 交/并/差集： SINTER key1 [key ...]：返回 key.. 对应集合的交集，时间复杂度为 O(N * M)， N 为给定集合当中基数最小的集合， M 为给定集合的个数。 SUNION key1 [key ...]：返回 key.. 对应集合的并集。时间复杂度为 O(N)， N 是所有给定集合的成员数量之和。 SDIFF key1 [key ...]：用第一个集合与第二个集合做差集，所得结果再与第三个集合做差集，依次向后类推。 ➤ 交集的实现： 对各个集合按照元素个数由少到多进行排序。这个排序有利于后面计算的时候从最小的集合开始，需要处理的元素个数较少。 对排序后第一个集合（也就是最小集合）进行遍历，对于它的每一个元素，依次在后面的所有集合中进行查找。只有在所有集合中都能找到的元素，才加入到最后的结果集合中。 ➤ 差集的实现：两种可能的算法，在计算差集的开始部分，会先分别估算一下两种算法预期的时间复杂度，然后选择复杂度低的算法来进行运算。 第一种算法： 对第一个集合进行遍历，对于它的每一个元素，依次在后面的所有集合中进行查找。只有在所有集合中都找不到的元素，才加入到最后的结果集合中。 这种算法的时间复杂度为 O(N*M)，其中N是第一个集合的元素个数，M是集合数目。 第二种算法： 将第一个集合的所有元素都加入到一个中间集合中。 遍历后面所有的集合，对于碰到的每一个元素，从中间集合中删掉它。 最后中间集合剩下的元素就构成了差集。 这种算法的时间复杂度为 O(N)，其中 N 是所有集合的元素个数总和； Sorted SetSorted Sets是将 Set 中的元素增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列 ZADD key score member [[score member] [score member] ...]：将一个或多个 member 元素及其 score 值加入到有序集 key 当中。时间复杂度：O(M*log(N))， N 是有序集的基数， M 为成功添加的新成员的数量。 ZSCORE key member：返回有序集 key中，成员 member的 score值。时间复杂度：O(1) ZRANGE key start stop：返回有序集 key中指定区间内的成员。其中成员的位置按 score值递增(从小到大)来排序。复杂度：O(log(N)+M)， N 为有序集的基数，而 M 为结果集的基数。 ZINCRBY key increment member：为有序集 key的成员 member的 score值加上增量 increment。时间复杂度：O(log(N)) ZREVRANK key member：返回有序集 key中成员 member的排名，score 值最大的成员排名为 0 。复杂度O(log(N)) ZCOUNT key min max： 返回有序集 key 中， score值在 min和 max之间(默认包括)的成员的数量。时间复杂度：O(log(N))， N 为有序集的基数。 ZCARD key：返回key对应的集合的长度。 BitMap@ref: https://www.xiaolincoding.com/redis/data_struct/command.html#bitmap HyperLog@ref: https://www.xiaolincoding.com/redis/data_struct/command.html#hyperloglog GEO@ref: https://www.xiaolincoding.com/redis/data_struct/command.html#geo Stream@ref: https://www.xiaolincoding.com/redis/data_struct/command.html#stream","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"RPC.06-序列化-ProtoBuf","slug":"31.Backend/RPC.06-序列化-ProtoBuf","date":"2024-01-24T01:27:52.567Z","updated":"2024-01-24T01:27:52.568Z","comments":true,"path":"31.Backend/RPC.06-序列化-ProtoBuf/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/RPC.06-序列化-ProtoBuf/","excerpt":"ProtoBuf（Protocol Buffers ）是Google的开源的序列化 &amp; 反序列化工具 https://developers.google.com/protocol-buffers/ ProtoBuf C++使用使用步骤: 定义proto文件，文件的内容就是定义我们需要存储或者传输的数据结构，也就是定义我们自己的数据存储或者传输的协议。 安装protocol buffer编译器来编译自定义的.proto文件，用于生成.pb.h文件（proto文件中自定义类的头文件）和 .pb.cc（proto文件中自定义类的实现文件）。 使用protocol buffer的C++ API来读写消息 protocol buffer 生成的函数, 除了getter和setter之外, 还有:","text":"ProtoBuf（Protocol Buffers ）是Google的开源的序列化 &amp; 反序列化工具 https://developers.google.com/protocol-buffers/ ProtoBuf C++使用使用步骤: 定义proto文件，文件的内容就是定义我们需要存储或者传输的数据结构，也就是定义我们自己的数据存储或者传输的协议。 安装protocol buffer编译器来编译自定义的.proto文件，用于生成.pb.h文件（proto文件中自定义类的头文件）和 .pb.cc（proto文件中自定义类的实现文件）。 使用protocol buffer的C++ API来读写消息 protocol buffer 生成的函数, 除了getter和setter之外, 还有: 标准消息函数（Standard Message Methods）每一个消息（message）还包含了其他一系列函数，用来检查或管理整个消息，包括： bool IsInitialized() const; //检查是否全部的required字段都被置（set）了值。void CopyFrom(const Person&amp; from); //用外部消息的值，覆写调用者消息内部的值。void Clear(); //将所有项复位到空状态（empty state）。int ByteSize() const; //消息字节大小 Debug的API, 包括: string DebugString() const; //将消息内容以可读的方式输出string ShortDebugString() const; //功能类似于，DebugString(),输出时会有较少的空白string Utf8DebugString() const; //Like DebugString(), but do not escape UTF-8 byte sequences.void PrintDebugString() const; //Convenience function useful in GDB. Prints DebugString() to stdout. 解析&amp;序列化(Parsing and Serialization)函数, 包括: bool SerializeToString(string* output) const; //将消息序列化并储存在指定的string中。注意里面的内容是二进制的，而不是文本；我们只是使用string作为一个很方便的容器。bool ParseFromString(const string&amp; data); //从给定的string解析消息。bool SerializeToArray(void * data, int size) const //将消息序列化至数组bool ParseFromArray(const void * data, int size) //从数组解析消息bool SerializeToOstream(ostream* output) const; //将消息写入到给定的C++ ostream中。bool ParseFromIstream(istream* input); //从给定的C++ istream解析消息。 使用示例: //test.cpp#include &lt;iostream&gt;#include &lt;string&gt;#include \"student.pb.h\"using namespace std;int main(int argc, char* argv[])&#123; GOOGLE_PROTOBUF_VERIFY_VERSION; // 创建message实例, 并设置属性: tutorial::Student student; student.set_id(201421031059); student.set_email(\"dablelv@tencent.com\"); // 增加 repeated属性 tutorial::Student::PhoneNumber* phone_number1 = student.add_phone(); phone_number1-&gt;set_number(\"13811112222\"); tutorial::Student::PhoneNumber* phone_number2 = student.add_phone(); phone_number2-&gt;set_number(\"010-1112222\"); // 序列化: string serializedStr; student.SerializeToString(&amp;serializedStr); cout&lt;&lt;\"serialization result:\"&lt;&lt;serializedStr&lt;&lt;endl; cout&lt;&lt;endl&lt;&lt;\"debugString:\"&lt;&lt;student.DebugString(); // 反序列化: tutorial::Student deserializedStudent; if(!deserializedStudent.ParseFromString(serializedStr))&#123; cerr &lt;&lt; \"Failed to parse student.\" &lt;&lt; endl; return -1; &#125; cout&lt;&lt;\"deserializedStudent debugString:\"&lt;&lt;deserializedStudent.DebugString(); cout &lt;&lt;endl&lt;&lt;\"Student ID: \" &lt;&lt; deserializedStudent.id() &lt;&lt; endl; // 判断有无属性 if (deserializedStudent.has_email())&#123; cout &lt;&lt; \"E-mail address: \" &lt;&lt; deserializedStudent.email() &lt;&lt; endl; &#125; // 对 repeated属性进行遍历 for (int j = 0; j &lt; deserializedStudent.phone_size(); j++)&#123; const tutorial::Student::PhoneNumber&amp; phone_number = deserializedStudent.phone(j); cout &lt;&lt;phone_number.number()&lt;&lt;endl; &#125; google::protobuf::ShutdownProtobufLibrary();&#125; @ref: Protocol Buffers C++入门教程 - 云+社区 - 腾讯云 varint@ref: Protobuf 终极教程 @todo","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"RPC.05-腾讯云TSF微服务平台简介","slug":"31.Backend/RPC.05-腾讯云TSF微服务平台简介","date":"2024-01-24T01:27:52.563Z","updated":"2024-01-24T01:27:52.563Z","comments":true,"path":"31.Backend/RPC.05-腾讯云TSF微服务平台简介/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/RPC.05-腾讯云TSF微服务平台简介/","excerpt":"","text":"微服务平台（Tencent Service Framework，TSF）是一个围绕着应用和微服务的 PaaS 平台，提供应用全生命周期管理、数据化运营、立体化监控和服务治理等功能。TSF 拥抱 Spring Cloud 、Service Mesh 微服务框架，帮助企业客户解决传统集中式架构转型的困难，打造大规模高可用的分布式系统架构，实现业务、产品的快速落地。针对原生 Spring Cloud 应用与 Mesh 方式零成本接入。 @ref: https://cloud.tencent.com/document/product/649 Spring Cloud 应用接入TSF: https://cloud.tencent.com/document/product/649/36285 Dubbo 应用接入TSF: https://cloud.tencent.com/document/product/649/13947 TSF Mesh 应用接入TSF: https://cloud.tencent.com/document/product/649/17928 Dubbo &amp; Spring Cloud 微服务介绍, 参考👉🏻 RPC.01-浅谈服务治理-and-微服务(zz)","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"RPC.04-Service Mesh","slug":"31.Backend/RPC.04-Service-Mesh","date":"2024-01-24T01:27:52.559Z","updated":"2024-01-24T01:27:52.559Z","comments":true,"path":"31.Backend/RPC.04-Service-Mesh/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/RPC.04-Service-Mesh/","excerpt":"","text":"什么是Service Mesh？ Service Mesh深度解析 腾讯云微服务平台提供的 TSF Mesh: RPC.05-腾讯云TSF微服务平台简介","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"RPC.03-框架设计概要","slug":"31.Backend/RPC.03-框架设计概要","date":"2024-01-24T01:27:52.554Z","updated":"2024-01-24T01:27:52.555Z","comments":true,"path":"31.Backend/RPC.03-框架设计概要/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/RPC.03-框架设计概要/","excerpt":"RMI早期JDK1.2引入的RMI框架图: （👉🏻[[../@project/Java-RMI]]） RPC通用框架通用RPC框架图:","text":"RMI早期JDK1.2引入的RMI框架图: （👉🏻[[../@project/Java-RMI]]） RPC通用框架通用RPC框架图: serviceClient：这个模块主要是封装服务端对外提供的API，让客户端像使用本地API接口一样调用远程服务。一般使用动态代理机制，当客户端调用api的方法时，serviceClient会走代理逻辑，去远程服务器请求真正的执行方法。类似RMI的stub模块。 processor：在服务端存在很多方法，当客户端请求过来，服务端需要定位到具体对象的具体方法，然后执行该方法，这个功能就由processor模块来完成。一般这个操作需要使用反射机制来获取用来执行真实处理逻辑的方法。类似RMI的skeleton模块。 protocol：协议层，一般协议层包括编码/解码，或者说序列化和反序列化工作；有的时候编解码不仅仅是对象序列化的工作，还有一些通信相关的字节流的额外解析部分。序列化工具有：hessian，Apache avro，G的 protobuf，FB的 Thrift，json系，xml系等等。在RMI中直接使用JDK自身的序列化组件。 Thrift和Protobuf的最大不同，在于Thrift提供了完整的RPC支持，包含了Server/Client，而Protobuf只包括了stub的生成器和格式定义。@ref Protobuf 和 Thrift对比-阿里云开发者社区 transport：传输层，主要是服务端和客户端网络通信相关的功能。这里和下面的IO层区分开，主要是因为传输层处理server/client的网络通信交互，而不涉及具体底层处理连接请求和响应相关的逻辑。 I/O：这个模块主要是为了提高性能可能采用不同的IO模型和线程模型，当然，一般我们可能和上面的transport层联系的比较紧密，统一称为remote模块。 Dubbo框架图参考: RPC.01-浅谈服务治理-and-微服务(zz) RPC技术要点 序列化: JDK内置序列化 👉🏻 [[../12.Java/Java-Tutorials.06.序列化(Serialize)]] Hessian: 在字节流里为每个field存储了类型信息, 可以不依赖serialVersionUID 进行版本匹配(Java类的UID被更改, 反序列化也没有问题) Kryo: “Kryo是一个快速高效的Java对象序列化框架，其在java的序列化上的性能指标甚至优于google著名的序列化框架protobuf，已经在Twitter、Groupon、Yahoo以及多个著名开源项目（如Hive、Storm）中广泛的使用” Json: 编解码: 注意区分序列化的不同, RPC框架基本上都是基于Socket来实现通信层功能，但是在网络传输的数据由于网络链路和协议的问题，会出现半包、分包和粘包情况。这样就需要设计编解码协议头来解码网络流。比如dubbo给出的处理流程，可以清晰的看出序列化和编码之间的区别, 参考[[#Dubbo协议头]] 负载均衡: 一般通过client维护可用服务列表, client通过同server建立心跳 测试server是否存活, 如果server暂时不可用, client会把server暂时放入不可用列表, 一段时间后再次尝试建立心跳(类似熔断) 心跳服务可选的有 netty提供的 HashedWheelTimer, 在不要求高精度定时心跳的情况下提供了很高的性能 Client侧负载均衡算法: 👉🏻 SystemDesign-负载均衡-算法 超时管理: client端的超时处理, 例如 future.get() server端的超时处理, 处理完后, 设定的超时参数比较, 如果发现已经超时则可以直接给client返回 err_code, 省去了序列化的时间 服务发现: 服务注册: server启动后注册服务信息 , 可选的存储服务有 zk/redis 服务感知/维护: 服务端和客户端与注册中心通过心跳上报运行情况 服务提供列表发生变化, 可以通过 client pull 或者 register push的方式 IO模型: 参考 [[../12.Java/Java-Tutorials.09.NIO&amp;Netty##Reactor三种常见线程模型]] Dubbo协议头 协议头固定长度16个字节 Magic: 共2字节 static final short MAGIC = (short) 0xdabb Serialization id: 表示序列化类型ID，Dubbo支持多种序列化工具，比如hessian，jdk，fastjson等 event表示事件，比如这个请求是heartbeat two way表示请求是否是需要交互返回数据的请求 req/res表示该数据是请求还是响应 status表示状态位，当响应数据的时候，根据该字段判断是否成功。 id表示请求id data length则表示正文内容的长度 @ref 深入浅出RPC原理 | 没有期望的分布","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"RPC.02-RMI","slug":"31.Backend/RPC.02-RMI","date":"2024-01-24T01:27:52.545Z","updated":"2024-01-24T01:27:52.545Z","comments":true,"path":"31.Backend/RPC.02-RMI/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/RPC.02-RMI/","excerpt":"RMI@Ref: https://ketao1989.github.io/2016/12/10/2016-12-10-rpc-theory-in-action/ RMI，全称是Remote Method Invocation，也就是远程方法调用。在JDK 1.2的时候引入到Java体系。 下面先看看RMI的调用流程:","text":"RMI@Ref: https://ketao1989.github.io/2016/12/10/2016-12-10-rpc-theory-in-action/ RMI，全称是Remote Method Invocation，也就是远程方法调用。在JDK 1.2的时候引入到Java体系。 下面先看看RMI的调用流程: 有些概念需要说明： stub(桩)：stub实际上就是在客户端上面的一个proxy。当我们的客户端代码调用API接口提供的方法的时候，RMI生成的stub代码块会将请求数据序列化，交给远程服务端处理，然后将结果反序列化之后返回给客户端的代码。这些处理过程，对于客户端来说，基本是透明无感知的。 remote：这层就是底层网络处理了，RMI对用户来说，屏蔽了这层细节。stub通过remote来和远程服务端进行通信。 skeleton(骨架)：和stub相似，skeleton则是服务端生成的一个代理proxy。当客户端通过stub发送请求到服务端，则交给skeleton来处理，其会根据指定的服务方法来反序列化请求，然后调用具体方法执行，最后将结果返回给客户端。 registry(服务发现)：rmi服务，在服务端实现之后需要注册到rmi server上，然后客户端从指定的rmi地址上lookup服务，调用该服务对应的方法即可完成远程方法调用。registry是个很重要的功能，当服务端开发完服务之后，要对外暴露，如果没有服务注册，则客户端是无从调用的，即使服务端的服务就在那里。 RMI Example: /** * 接口必须继承RMI的Remote */public interface RmiService extends Remote &#123; /** * 必须有RemoteException，才是RMI方法 */ String hello(String name) throws RemoteException;&#125;/** * UnicastRemoteObject会生成一个代理proxy */public class RmiServiceImpl extends UnicastRemoteObject implements RmiService &#123; public RmiServiceImpl() throws RemoteException &#123; &#125; public String hello(String name) throws RemoteException &#123; return \"Hello \" + name; &#125;&#125;/** * 服务端server启动 */public class RmiServer &#123; public static void main(String[] args) &#123; try &#123; RmiService service = new RmiServiceImpl(); //在本地创建和暴露一个注册服务实例，端口为9999 LocateRegistry.createRegistry(9999); //注册service服务到上面创建的注册实例上 Naming.rebind(\"rmi://127.0.0.1:9999/service1\",service); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; System.out.println(\"------------server start-----------------\"); &#125;&#125;/** * 客户端调用rmi服务 */public class RmiClient &#123; public static void main(String[] args) &#123; try &#123; // 根据注册的服务地址来查找服务，然后就可以调用API对应的方法了 RmiService service = (RmiService)Naming.lookup(\"rmi://localhost:9999/service1\"); System.out.println(service.hello(\"RMI\")); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125;&#125; @ref: Java remote method invocation - Wikipedia RMI远程调用 - 廖雪峰的官方网站 Java RMI 笔记 | b1ngz","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"RPC.02-ProtoBuf","slug":"31.Backend/RPC.02-ProtoBuf","date":"2024-01-24T01:27:52.538Z","updated":"2024-01-24T01:27:52.539Z","comments":true,"path":"31.Backend/RPC.02-ProtoBuf/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/RPC.02-ProtoBuf/","excerpt":"ProtoBuf C++使用ProtoBuf（Protocol Buffers ）是Google的开源的序列化 &amp; 反序列化工具 https://developers.google.com/protocol-buffers/ 使用步骤: 定义proto文件，文件的内容就是定义我们需要存储或者传输的数据结构，也就是定义我们自己的数据存储或者传输的协议。 安装protocol buffer编译器来编译自定义的.proto文件，用于生成.pb.h文件（proto文件中自定义类的头文件）和 .pb.cc（proto文件中自定义类的实现文件）。 使用protocol buffer的C++ API来读写消息 protocol buffer 生成的函数, 除了getter和setter之外, 还有:","text":"ProtoBuf C++使用ProtoBuf（Protocol Buffers ）是Google的开源的序列化 &amp; 反序列化工具 https://developers.google.com/protocol-buffers/ 使用步骤: 定义proto文件，文件的内容就是定义我们需要存储或者传输的数据结构，也就是定义我们自己的数据存储或者传输的协议。 安装protocol buffer编译器来编译自定义的.proto文件，用于生成.pb.h文件（proto文件中自定义类的头文件）和 .pb.cc（proto文件中自定义类的实现文件）。 使用protocol buffer的C++ API来读写消息 protocol buffer 生成的函数, 除了getter和setter之外, 还有: 标准消息函数（Standard Message Methods）每一个消息（message）还包含了其他一系列函数，用来检查或管理整个消息，包括： bool IsInitialized() const; //检查是否全部的required字段都被置（set）了值。void CopyFrom(const Person&amp; from); //用外部消息的值，覆写调用者消息内部的值。void Clear(); //将所有项复位到空状态（empty state）。int ByteSize() const; //消息字节大小 Debug的API, 包括: string DebugString() const; //将消息内容以可读的方式输出string ShortDebugString() const; //功能类似于，DebugString(),输出时会有较少的空白string Utf8DebugString() const; //Like DebugString(), but do not escape UTF-8 byte sequences.void PrintDebugString() const; //Convenience function useful in GDB. Prints DebugString() to stdout. 解析&amp;序列化(Parsing and Serialization)函数, 包括: bool SerializeToString(string* output) const; //将消息序列化并储存在指定的string中。注意里面的内容是二进制的，而不是文本；我们只是使用string作为一个很方便的容器。bool ParseFromString(const string&amp; data); //从给定的string解析消息。bool SerializeToArray(void * data, int size) const //将消息序列化至数组bool ParseFromArray(const void * data, int size) //从数组解析消息bool SerializeToOstream(ostream* output) const; //将消息写入到给定的C++ ostream中。bool ParseFromIstream(istream* input); //从给定的C++ istream解析消息。 使用示例: //test.cpp#include &lt;iostream&gt;#include &lt;string&gt;#include \"student.pb.h\"using namespace std;int main(int argc, char* argv[])&#123; GOOGLE_PROTOBUF_VERIFY_VERSION; // 创建message实例, 并设置属性: tutorial::Student student; student.set_id(201421031059); student.set_email(\"dablelv@tencent.com\"); // 增加 repeated属性 tutorial::Student::PhoneNumber* phone_number1 = student.add_phone(); phone_number1-&gt;set_number(\"13811112222\"); tutorial::Student::PhoneNumber* phone_number2 = student.add_phone(); phone_number2-&gt;set_number(\"010-1112222\"); // 序列化: string serializedStr; student.SerializeToString(&amp;serializedStr); cout&lt;&lt;\"serialization result:\"&lt;&lt;serializedStr&lt;&lt;endl; cout&lt;&lt;endl&lt;&lt;\"debugString:\"&lt;&lt;student.DebugString(); // 反序列化: tutorial::Student deserializedStudent; if(!deserializedStudent.ParseFromString(serializedStr))&#123; cerr &lt;&lt; \"Failed to parse student.\" &lt;&lt; endl; return -1; &#125; cout&lt;&lt;\"deserializedStudent debugString:\"&lt;&lt;deserializedStudent.DebugString(); cout &lt;&lt;endl&lt;&lt;\"Student ID: \" &lt;&lt; deserializedStudent.id() &lt;&lt; endl; // 判断有无属性 if (deserializedStudent.has_email())&#123; cout &lt;&lt; \"E-mail address: \" &lt;&lt; deserializedStudent.email() &lt;&lt; endl; &#125; // 对 repeated属性进行遍历 for (int j = 0; j &lt; deserializedStudent.phone_size(); j++)&#123; const tutorial::Student::PhoneNumber&amp; phone_number = deserializedStudent.phone(j); cout &lt;&lt;phone_number.number()&lt;&lt;endl; &#125; google::protobuf::ShutdownProtobufLibrary();&#125; @ref: Protocol Buffers C++入门教程 - 云+社区 - 腾讯云 varint@ref: Protobuf 终极教程 @todo 浅谈服务治理、微服务与Service Mesh浅谈服务治理、微服务与Service Mesh（一）：Dubbo的前世今生 - DockOne.io浅谈服务治理、微服务与Service Mesh（二）： Spring Cloud从入门到精通到放弃 - DockOne.io浅谈服务治理、微服务与Service Mesh（三）： Service Mesh与Serverless - DockOne.io RPC通用框架通用RPC框架图: serviceClient：这个模块主要是封装服务端对外提供的API，让客户端像使用本地API接口一样调用远程服务。一般使用动态代理机制，当客户端调用api的方法时，serviceClient会走代理逻辑，去远程服务器请求真正的执行方法。类似RMI的stub模块。 processor：在服务端存在很多方法，当客户端请求过来，服务端需要定位到具体对象的具体方法，然后执行该方法，这个功能就由processor模块来完成。一般这个操作需要使用反射机制来获取用来执行真实处理逻辑的方法。类似RMI的skeleton模块。 protocol：协议层，一般协议层包括编码/解码，或者说序列化和反序列化工作；有的时候编解码不仅仅是对象序列化的工作，还有一些通信相关的字节流的额外解析部分。序列化工具有：hessian，Apache avro，G的 protobuf，FB的 Thrift，json系，xml系等等。在RMI中直接使用JDK自身的序列化组件。 Thrift和Protobuf的最大不同，在于Thrift提供了完整的RPC支持，包含了Server/Client，而Protobuf只包括了stub的生成器和格式定义。@ref Protobuf 和 Thrift对比-阿里云开发者社区 transport：传输层，主要是服务端和客户端网络通信相关的功能。这里和下面的IO层区分开，主要是因为传输层处理server/client的网络通信交互，而不涉及具体底层处理连接请求和响应相关的逻辑。 I/O：这个模块主要是为了提高性能可能采用不同的IO模型和线程模型，当然，一般我们可能和上面的transport层联系的比较紧密，统一称为remote模块。 Dubbo框架图参考: &lt;RPC.01-浅谈服务治理、微服务与Service Mesh(zz)#Dubbo总体架构&gt; RPC技术要点@ref 深入浅出RPC原理 | 没有期望的分布 序列化: JDK内置序列化 Hessian: 在字节流里为每个field存储了类型信息, 可以不依赖serialVersionUID 进行版本匹配(Java类的UID被更改, 反序列化也没有问题) Kryo: “Kryo是一个快速高效的Java对象序列化框架，其在java的序列化上的性能指标甚至优于google著名的序列化框架protobuf，已经在Twitter、Groupon、Yahoo以及多个著名开源项目（如Hive、Storm）中广泛的使用” Json: 编解码: 注意区分序列化的不同, RPC框架基本上都是基于Socket来实现通信层功能，但是在网络传输的数据由于网络链路和协议的问题，会出现半包、分包和粘包情况。这样就需要设计编解码协议头来解码网络流。比如dubbo给出的处理流程，可以清晰的看出序列化和编码之间的区别, 参考 Dubbo协议头 负载均衡: 一般通过client维护可用服务列表, client通过同server建立心跳 测试server是否存活, 如果server暂时不可用, client会把server暂时放入不可用列表, 一段时间后再次尝试建立心跳(类似熔断) 心跳服务可选的有 netty提供的 HashedWheelTimer, 在不要求高精度定时心跳的情况下提供了很高的性能 Client侧负载均衡算法: ==&gt; SystemDesign-负载均衡-算法 超时管理: client端的超时处理, 例如 future.get() server端的超时处理, 处理完后, 设定的超时参数比较, 如果发现已经超时则可以直接给client返回 err_code, 省去了序列化的时间 服务发现: 服务注册: server启动后注册服务信息 , 可选的存储服务有 zk/redis 服务感知/维护: 服务端和客户端与注册中心通过心跳上报运行情况 服务提供列表发生变化, 可以通过 client pull 或者 register push的方式 IO模型: 参考 =&gt; Java Tutorials-09-NIO##Reactor三种常见线程模型 Dubbo协议头 协议头固定长度16个字节 Magic: 共2字节 static final short MAGIC = (short) 0xdabb Serialization id: 表示序列化类型ID，Dubbo支持多种序列化工具，比如hessian，jdk，fastjson等 event表示事件，比如这个请求是heartbeat two way表示请求是否是需要交互返回数据的请求 req/res表示该数据是请求还是响应 status表示状态位，当响应数据的时候，根据该字段判断是否成功。 id表示请求id data length则表示正文内容的长度","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"RPC.01-浅谈服务治理、微服务与Service Mesh(zz)","slug":"31.Backend/RPC.01-浅谈服务治理-and-微服务(zz)","date":"2024-01-24T01:27:52.528Z","updated":"2024-01-24T01:27:52.529Z","comments":true,"path":"31.Backend/RPC.01-浅谈服务治理-and-微服务(zz)/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/RPC.01-浅谈服务治理-and-微服务(zz)/","excerpt":"浅谈服务治理、微服务与Service Mesh（一）：Dubbo的前世今生@ref 浅谈服务治理、微服务与Service Mesh（一）：Dubbo的前世今生 - DockOne.io 服务治理（Service Governance），也称为SOA治理，是指用来管理SOA的采用和实现的过程。以下是在2006年时IBM对于服务治理要点的总结： 服务定义（服务的范围、接口和边界） 服务部署生命周期（各个生命周期阶段） 服务版本治理（包括兼容性） 服务迁移（启用和退役） 服务注册中心（依赖关系） 服务消息模型（规范数据模型） 服务监视（进行问题确定） 服务所有权（企业组织） 服务测试（重复测试） 服务安全（包括可接受的保护范围） 限于当时的技术发展水平，广大软件设计与开发人员对于SOA和服务治理的技术认知还主要停留在Web Service和ESB总线等技术和规范上，并没有真正在软件开发中得以充分落地。","text":"浅谈服务治理、微服务与Service Mesh（一）：Dubbo的前世今生@ref 浅谈服务治理、微服务与Service Mesh（一）：Dubbo的前世今生 - DockOne.io 服务治理（Service Governance），也称为SOA治理，是指用来管理SOA的采用和实现的过程。以下是在2006年时IBM对于服务治理要点的总结： 服务定义（服务的范围、接口和边界） 服务部署生命周期（各个生命周期阶段） 服务版本治理（包括兼容性） 服务迁移（启用和退役） 服务注册中心（依赖关系） 服务消息模型（规范数据模型） 服务监视（进行问题确定） 服务所有权（企业组织） 服务测试（重复测试） 服务安全（包括可接受的保护范围） 限于当时的技术发展水平，广大软件设计与开发人员对于SOA和服务治理的技术认知还主要停留在Web Service和ESB总线等技术和规范上，并没有真正在软件开发中得以充分落地。 Dubbo开源直到2011年10月27日，阿里巴巴开源了自己的SOA服务化治理方案的核心框架Dubbo，服务治理和SOA的设计理念开始逐渐在国内软件行业中落地，并被广泛应用。Dubbo作为阿里巴巴内部的SOA服务化治理方案的核心框架，在2012年时已经每天为2000+个服务提供3,000,000,000+次访问量支持，并被广泛应用于阿里巴巴集团的各成员站点。 Dubbo简介Dubbo是一个高性能服务框架，致力于提供高性能和透明化的RPC远程服务调用方案，以及SOA服务治理方案，使得应用可通过高性能RPC实现服务的输出和输入功能，和Spring框架可以无缝集成。 作为一个分布式服务框架，以及SOA治理方案，Dubbo其功能主要包括：高性能NIO通讯及多协议集成，服务动态寻址与路由，软负载均衡与容错，依赖分析与服务降级等。Dubbo最大的特点是按照分层的方式来架构，使用这种方式可以使各个层之间解耦合（或者最大限度地松耦合）。从服务模型的角度来看，Dubbo采用的是一种非常简单的模型，要么是提供方提供服务，要么是消费方消费服务，所以基于这一点可以抽象出服务提供方（Provider）和服务消费方（Consumer）两个角色。 Dubbo包含远程通讯、集群容错和自动发现三个核心部分。提供透明化的远程方法调用，实现像调用本地方法一样调用远程方法，只需简单配置，没有任何API侵入。同时具备软负载均衡及容错机制，可在内网替代F5等硬件负载均衡器，降低成本，减少单点。可以实现服务自动注册与发现，不再需要写死服务提供方地址，注册中心基于接口名查询服务提供者的IP地址，并且能够平滑添加或删除服务提供者。 Dubbo总体架构Dubbo框架设计共划分了10层，最上面的Service层是留给实际使用Dubbo开发分布式服务的开发者实现业务逻辑的接口层。图中左边淡蓝背景的为服务消费方使用的接口，右边淡绿色背景的为服务提供方使用的接口，位于中轴线上的为双方都用到的接口。 停止维护从2012年10月23日Dubbo 2.5.3发布后，在Dubbo开源将满一周年之际，阿里基本停止了对Dubbo的主要升级。只在之后的2013年和2014年更新过2次对Dubbo 2.4的维护版本，然后停止了所有维护工作。Dubbo对Srping的支持也停留在了Spring 2.5.6版本上。 重获新生经过多年漫长的等待，随着微服务的火热兴起，在国内外开发者对阿里不再升级维护Dubbo的吐槽声中，阿里终于开始重新对Dubbo的升级和维护工作。在2017年9月7日 ，阿里发布了Dubbo的2.5.4版本，距离上一个版本2.5.3发布已经接近快5年时间了。在随后的几个月中，阿里Dubbo开发团队以差不多每月一版本的速度开始快速升级迭代，修补了Dubbo老版本多年来存在的诸多bug，并对Spring等组件的支持进行了全面升级。 Dubbo与Spring Cloud阿里巴巴负责主导了 Dubbo 重启维护的研发工程师刘军在接受采访时表示：当前由于 RPC 协议、注册中心元数据不匹配等问题，在面临微服务基础框架选型时Dubbo与Spring Cloud是只能二选一，这也是为什么大家总是拿Dubbo和Spring Cloud做对比的原因之一。 浅谈服务治理、微服务与Service Mesh（二）： Spring Cloud从入门到精通到放弃@ref 浅谈服务治理、微服务与Service Mesh（二）： Spring Cloud从入门到精通到放弃 - DockOne.io Spring Cloud简介Spring Boot和Spring Cloud都是出自Pivotal公司。 Spring Cloud作为一个微服务的开发框架，其包括了很多的组件，包括：Spring Cloud Netflix（Eureka、Hystrix、Zuul、Archaius）、Spring Cloud Config、Spring Cloud Bus、Spring Cloud Cluster、Spring Cloud Consul、Spring Cloud Security、Spring Cloud Sleuth、Spring Cloud Data Flow、Spring Cloud Stream、Spring Cloud Task、Spring Cloud ZooKeeper、Spring Cloud Connectors、Spring Cloud Starters、Spring Cloud CLI等。 在上述组件中，Spring Cloud Netflix是一套微服务的核心框架，由互联网流媒体播放商Netflix开源后并入Spring Cloud大家庭，它提供了的微服务最基础的功能：服务发现（Service Discovery）、动态路由（Dynamic Routing）、负载均衡（Load Balancing）和边缘服务器（Edge Server）等。 Spring Boot（[[../13.JavaEE-Framework/JavaEE.SpringBoot]]）是Spring的一套快速配置脚手架，可以基于Spring Boot快速开发单个微服务。Spring Boot简化了基于Spring的应用开发，通过少量的代码就能创建一个独立的、生产级别的Spring应用。由于Spring Cloud是基于Spring Boot进行的开发，因此使用Spring Cloud就必须使用到Spring Boot。 Spring Cloud常用组件： Eureka：服务注册中心，一个基于REST的服务，用于定位服务，以实现微服务架构中服务发现和故障转移。 Hystrix：熔断器，容错管理工具，旨在通过熔断机制控制服务和第三方库的节点，从而对延迟和故障提供更强大的容错能力。 Turbine：Turbine是聚合服务器发送事件流数据的一个工具，用来监控集群下Hystrix的Metrics情况。 Zuul：API网关，Zuul是在微服务中提供动态路由、监控、弹性、安全等边缘服务的框架。 Ribbon：提供微服务中的负载均衡功能，有多种负载均衡策略可供选择，可配合服务发现和断路器使用。 Feign：Feign是一种声明式、模板化的HTTP客户端。 Spring Cloud Config：配置管理工具包，让你可以把配置放到远程服务器，集中化管理集群配置，目前支持本地存储、Git以及Subversion。 Spring Cloud Security：基于Spring Security的安全工具包，为微服务的应用程序添加安全控制。 Spring Cloud Sleuth：日志收集工具包，封装了Dapper和log-based追踪以及Zipkin和HTrace操作，为SpringCloud应用实现了一种分布式追踪解决方案。 除了上面介绍的基础组件外，常见的Spring Cloud组件还有非常多种，涉及到了微服务以及应用开发的方方面面： Spring Cloud Starters：Spring Boot式的启动项目，为Spring Cloud提供开箱即用的依赖管理。 Archaius：配置管理API，包含一系列配置管理API，提供动态类型化属性、线程安全配置操作、轮询框架、回调机制等功能。 Consul：封装了Consul操作，Consul是一个服务发现与配置工具，与Docker容器可以无缝集成。 Spring Cloud Stream：数据流操作开发包，封装了与Redis,Rabbit、Kafka等发送接收消息。 Spring Cloud CLI：基于 Spring Boot CLI，可以让你以命令行方式快速建立云组件。 Spring Cloud Task：提供云端计划任务管理、任务调度。 Spring Cloud Bus：事件、消息总线，用于在集群（例如，配置变化事件）中传播状态变化，可与Spring Cloud Config联合实现热部署。 Spring Cloud Data Flow：大数据操作工具，作为Spring XD的替代产品，它是一个混合计算模型，结合了流数据与批量数据的处理方式。 Spring Cloud ZooKeeper：操作ZooKeeper的工具包，用于使用ZooKeeper方式的服务发现和配置管理。 Spring Cloud Connectors：便于云端应用程序在各种PaaS平台连接到后端，如：数据库和消息代理服务。 Spring Cloud之“精通”Spring Cloud虽然集成了众多组件，可以构建一个完整的微服务应用，但是其中的各个组件却并非完美无缺，很多组件在实际应用中都存在诸多不足和缺陷。因此，需要我们对其中的一些组件进行替换和修改，方能构建一个强大、灵活、健壮的微服务架构应用。 配置中心Spring Cloud Config可以说是Spring Cloud家族中实现最Low的一个组件，直接采用了本地存储/SVN/Git的方式进行存储。同时，Spring Cloud Config也缺乏一个完整的可视化管理查询后台，当存在比较复杂的权限管理和版本管理需求时，Spring Cloud Config会显得非常力不从心。如果需要在配置修改后，能自动进行配置信息推送的话，使用Spring Cloud Config也无法满足要求，需要自行编写代码进行实现。 目前开源社区中，已经有了很多的开源配置中心实现方案，同时很多公司也自研了自己的配置中心方案。包括淘宝的统一配置中心Diamond（已经多年未更新）、百度的分布式配置管理平台Disconf、携程的开源分布式配置中心Apollo、360的分布式配置管理工具QConf等等。目前，笔者公司采用的是自己公司自研的配置中心，没有采用开源实现的主要原因是因为需要同时适配Spring Cloud和Dubbo等多种场景的应用。 注册中心作为Spring Cloud的服务注册中心，从分布式CAP理论来看，Eureka采用是AP型设计，强调的是注册中心的高可用性。和Dubbo常用的服务注册中心ZooKeeper相比，ZooKeeper则是采用的CP型设计，强调的是注册中心数据的一致性。 Eureka的设计确实简单易用，但是默认没有实现对注册中心数据的持久化。同时，在极端场景下，也会出现多个Eureka注册中心节点数据不一致，甚至服务注册数据丢失的情况。当然，从分布式CAP理论来看，理论上是没办法做到同时兼顾CAP三点的。目前也有一些互联网公司对Eureka进行了改造，支持了数据的持久化，但是尚不能完整的支持CAP的全部要求。 API网关API网关可以说是微服务需求最多，也是最有难点的一个组件。Spring Cloud中集成的Zuul应该说更多的是实现了服务的路由功能，对于负载均衡等其他功能，需要结合Ribbon等组件来实现。对于很多个性化的需求，需要开发者自己来进行编码实现。 和大部分基于Java的Web应用类似，Zuul也采用了Servlet架构，因此Zuul处理每个请求的方式是针对每个请求是用一个线程来处理。同时，由于Zuul是基于JVM的实现，因此性能也会在高并发访问场景下成为瓶颈。虽然网上一些文章评测Zuul和Nginx性能接近，但是在性能要求较高的场景下，JVM的内存管理和垃圾回收问题，仍然是一个很大的问题。所以在实际的应用场景中，通常会采用在多个Zuul几点前面再添加一层Nginx或者OpenResty来进行代理。 为了解决Zuul的性能问题，Netflix将自己的网关服务Zuul进行了升级，新的Zuul 2将HTTP请求的处理方式从同步变成了异步，并且新增诸如HTTP/2、websocket等功能。但是遗憾的是，开源版本的Zuul 2一直处于难产状态中，始终没有和大家正式见面。 熔断器微服务中对于服务的限流、降级、熔断的需求是多种多样的，需要在API网关和各个具体服务接口中分别进行控制，才能满足复杂场景下微服务架构的应用需求。 单独使用Spring Cloud中的Hystrix无法完整的满足上述的复杂需求，需要结合API网关，并通过Kubernetes对资源、进程和命名空间来提供隔离，并通过部分自定义编码方能实现对全部服务的限流、降级、熔断等需求。 监控系统无论是Spring Cloud中集成的Spring Cloud Sleuth，还是集成经典的ELK，都只是对日志级别的追踪和监控。在大中型微服务应用架构中，尤其是基于JVM的项目，还需要添加APM的监控机制，才能保证及时发现各种潜在的性能问题。 APM整体上主要完成3点功能：1.日志追踪、2.监控报警、3.性能统计。目前，国内外商业版本的APM方案已经有很多，开源版本的APM方案也开始丰富起来。国内开源的APM方案主要有：大众点评的CAT和Apache孵化中的SkyWalking。这里给大家重点推荐下SkyWalking，SkyWalking是针对分布式系统的应用性能监控系统，特别针对微服务、Cloud Native和容器化（Docker、Kubernetes、Mesos）架构，项目的关注度和发展速度都很快，中文文档资料也比较齐全。 Spring Cloud之“放弃”Spring Cloud可以说是一个完美的微服务入门框架，如果你是在一个中小型项目中应用Spring Cloud，那么你不需要太多的改造和适配，就可以实现微服务的基本功能。但是如果是在大型项目中实践微服务，可能会发现需要处理的问题还是比较多，尤其是项目中老代码比较多，没办法全部直接升级到Spring Boot框架下开发的话，你会非常希望能有一个侵入性更低的方案来实施微服务架构。在这种场景下，Service Mesh将会成为你的最佳选择 … Spring Cloud 与 Dubbo实际上，Dubbo的关注点在于服务治理，并不能算是一个真正的微服务框架。包括目前在开发中的Dubbo 3.0，也不能完整覆盖微服务的各项功能需求。而Spring Cloud一方面是针对微服务而设计，另外一方面Spring Cloud是通过集成各种组件的方式来实现微服务，因此理论上可以集成目前业内的绝大多数的微服务相关组件，从而实现微服务的全部功能。 而对Dubbo而言，如果一定要应用到微服务的使用场景中的话，上表中欠缺的大多数功能都可以通过集成第三方应用和组件的方式来实现，跟Spring Cloud相比主要的缺陷在于集成过程中的便利性和兼容性等问题。 Spring Cloud 与 Docker在实际上微服务架构中，Spring Cloud和Docker更多的是一种协作的关系，而不是一种竞争的关系。通过Docker容器化技术，可以更好的解决引入Spring Cloud微服务后带来的部署和运维的复杂性。 Spring Cloud生态圈中的Pivotal Cloud Foundry（PCF）作为PaaS实现，也提供一些类似于Docker的功能支持，但是无论上功能上还是易用性上和Docker还是存在比较大的差异。Pivotal Cloud Foundry和Docker之间的关系更多的是一种兼容关系，而不是竞争关系，Pivotal Cloud Foundry的主要竞争对手是Red Hat的OpenShift。目前，Pivotal Cloud Foundry支持的IaaS包括：AWS、AZURE、GCP、vSphere、OpenStack等。 Spring Cloud 与 Kubernetes网上也有一些“Spring Cloud与Kubernetes哪个更好”，“当已经有了Kubernetes之后，还需要使用Spring Cloud么”之类的文章。首先说笔者并不认为Spring Cloud与Kubernetes是竞争关系，但是也不否认二者确实在诸多功能上存在一些重合。下图是对Spring Cloud与Kubernetes在微服务架构中的一些基础功能上的对比： 通过对比可以看出，Spring Cloud和Kubernetes确实存在一些功能上的重合，但是二者的定位其实差别很大。Spring Cloud是一个基于Java语言的微服务开发框架，而Kubernetes是一个针对容器应用的自动化部署、伸缩和管理的开源系统，它兼容多种语言且提供了创建、运行、伸缩以及管理分布式系统的原语。Spring Cloud更多的是面向有Spring开发经验的Java语言开发者，而Kubernetes不是一个针对开发者的平台，它的目的是供有DevOps思想的IT人员使用。 为了区分Spring Cloud和Kubernetes两个项目的范围，下面这张图列出了几乎是端到端的微服务架构需求，从最底层的硬件，到最上层的DevOps和自服务经验，并且列出了如何关联到Spring Cloud和Kubernetes平台。 浅谈服务治理、微服务与Service Mesh（三）@ref 浅谈服务治理、微服务与Service Mesh（三）： Service Mesh与Serverless - DockOne.io 微服务1.0时代 Dubbo本质上只能算是一个服务治理框架，而不能算是一个微服务框架。虽然在未来的Dubbo 3.0中会提供对Spring Cloud，以及对Service Mesh的支持，但是单凭Dubbo仍然是无法搭建一个完整的微服务体系结构。 Spring Cloud则是通过集成众多的组件的形式实现了相对完整的微服务技术栈，但是Spring Cloud的实现方式代码侵入性较强，而且只支持Java语言，无法支持其他语言开发的系统。Spring Cloud全家桶包括的内容较多，学习成本也相对较高，对老系统而言，框架升级或者替换的成本较高，导致一些开发团队不愿意担负技术和时间上的风险与成本，使得微服务方案在落地时遇到了诸多的困难。 微服务2.0时代 Service Mesh目前比较多的翻译为“服务网格”，也有翻译为“服务啮合”。很多人将之称为下一代微服务，或直接称之为微服务2.0。前两篇文章中介绍的Dubbo和Spring Cloud实际上距离真正意义上的微服务还有一定的距离，本文将带你了解在微服务2.0时代，Service Mesh方式是如何实现下一代微服务标准的，并介绍当前比较常见的几种Service Mesh实现方案。 在介绍Service Mesh（RPC.04-Service-Mesh）概念之前，我们先来了解一下Sidecar。Sidecar是Service Mesh中的重要组成部分。在Service Mesh架构中，给每一个微服务实例部署一个Sidecar Proxy。该Sidecar Proxy负责接管对应服务的入流量和出流量，并将微服务架构中的服务订阅、服务发现、熔断、限流、降级、分布式跟踪等功能从服务中抽离到该Proxy中。 Sidecar以一个独立的进程启动，可以每台宿主机共用同一个Sidecar进程，也可以每个应用独占一个Sidecar进程。所有的服务治理功能，都由Sidecar接管，应用的对外访问仅需要访问Sidecar即可。当该Sidecar在微服务中大量部署时，这些Sidecar节点自然就形成了一个服务网格。 微服务的概念在2014年3月由Martin Fowler首次提出，而Service Mesh的概念则是在2016年左右提出，Service Mesh至今也经历了第二代的发展。 第一代Service Mesh的代表为Linkerd和Envoy。Linkerd基于Twitter的Fingle，使用Scala编写，是业界第一个开源的Service Mesh方案，在长期的实际生产环境中获得验证。Envoy底层基于C++，性能上优于使用Scala的Linkrd。同时，Envoy社区成熟度较高，商用稳定版本面世时间也较长。这两个开源实现都是以Sidecar为核心，绝大部分关注点都是如何做好Proxy，并完成一些通用控制面的功能。但是当你在容器中大量部署Sidecar以后，如何管理和控制这些Sidecar本身就是一个不小的挑战。 第二代Service Mesh主要改进集中在更加强大的控制面功能（与之对应的Sidecar Proxy被称之为数据面），典型代表有Istio和Conduit。Istio是Google、IBM和Lyft合作的开源项目，是目前最主流的Service Mesh方案，也是事实上的第二代Service Mesh标准。在Istio中，直接把Envoy作为Sidecar。除了Sidecar，Istio中的控制面组件都是使用Go语言编写。 stio简介根据Istio官方文档的介绍，Istio在服务网络中主要提供了以下关键功能： 流量管理：控制服务之间的流量和API调用的流向，使得调用更可靠，并使网络在恶劣情况下更加健壮。 可观察性：了解服务之间的依赖关系，以及它们之间流量的本质和流向，从而提供快速识别问题的能力。 策略执行：将组织策略应用于服务之间的互动，确保访问策略得以执行，资源在消费者之间良好分配。策略的更改是通过配置网格而不是修改应用程序代码。 服务身份和安全：为网格中的服务提供可验证身份，并提供保护服务流量的能力，使其可以在不同可信度的网络上流转。 平台支持：Istio旨在在各种环境中运行，包括跨云、Kubernetes、Mesos等。最初专注于Kubernetes，但很快将支持其他环境。 集成和定制：策略执行组件可以扩展和定制，以便与现有的ACL、日志、监控、配额、审核等解决方案集成。 下图为Istio的架构设计图，主要包括了Envoy、Pilot、Mixer和Istio-Auth等 Envoy: 扮演Sidecar的功能，协调服务网格中所有服务的出入站流量，并提供服务发现、负载均衡、限流熔断等能力，还可以收集与流量相关的性能指标。 Pilot: 负责部署在Service Mesh中的Envoy实例的生命周期管理。本质上是负责流量管理和控制，将流量和基础设施扩展解耦，这是Istio的核心。可以把Pilot看做是管理Sidecar的Sidecar, 但是这个特殊的Sidacar并不承载任何业务流量。Pilot让运维人员通过Pilot指定它们希望流量遵循什么规则，而不是哪些特定的pod/VM应该接收流量。有了Pilot这个组件，我们可以非常容易的实现 A/B 测试和金丝雀Canary测试。 Mixer: Mixer在应用程序代码和基础架构后端之间提供通用中介层。它的设计将策略决策移出应用层，用运维人员能够控制的配置取而代之。应用程序代码不再将应用程序代码与特定后端集成在一起，而是与Mixer进行相当简单的集成，然后Mixer负责与后端系统连接。Mixer可以认为是其他后端基础设施（如数据库、监控、日志、配额等）的Sidecar Proxy。 Istio-Auth: 提供强大的服务间认证和终端用户认证，使用交互TLS，内置身份和证书管理。可以升级服务网格中的未加密流量，并为运维人员提供基于服务身份而不是网络控制来执行策略的能力。Istio的未来版本将增加细粒度的访问控制和审计，以使用各种访问控制机制（包括基于属性和角色的访问控制以及授权钩子）来控制和监视访问服务、API或资源的访问者。 目前的Istio大部分能力与Kubernetes是强关联的。而我们在构建微服务的时候往往是希望服务层与容器层是解耦的，服务层在设计上需要能够对接多种容器层平台。 Istio至今未有稳定版本，截至本文编写时为止，Istio的最新版本为0.8版本，预计在2018年内会发布1.0版本。 Conduit简介我们再来看一下Conduit的实现，下图是Conduit的架构设计图，其中重点由Conduit Data Plane和Conduit Control Plane两部分组成： Conduit各方面的设计理念与Istio非常类似，作者使用Rust语言重新编写了Sidecar, 叫做Conduit Data Plane, 控制面则由Go语言编写的Conduit Control Plane接管。从Conduit的架构看，作者号称Conduit吸取了很多Linkerd的教训，比Linkerd更快、更轻、更简单，控制面功能更强。与Istio比较，Conduit的架构一方面比较简单，另一方面对于要解决的问题足够聚焦。 Serverless简介Serverless（Serverless）被翻译为“无服务器架构”，这个概念在2012年时便已经存在，比微服务和Service Mesh的概念出现都要早，但是直到微服务概念大红大紫之后，Serverless才重新又被人们所关注。 Serverless（无服务器架构）并不意味着没有任何服务器去运行代码，Serverless是无需管理服务器，只需要关注代码，而提供者将处理其余部分工作。“无服务器架构”也可以指部分服务器端逻辑依然由应用程序开发者来编写的应用程序，但与传统架构的不同之处在于，这些逻辑运行在完全由第三方管理，由事件触发的无状态（Stateless）暂存于计算容器内。 对于开发者来说，Serverless架构可以将其服务器端应用程序分解成多个执行不同任务的函数，整个应用分为几个独立、松散耦合的组件，这些组件可以在任何规模上运行。 Serverless架构优势： 缩短交付时间：Serverless架构允许开发人员在极短时间内（几小时、几天）交付新的应用程序，而不是像以前一样需要几个星期或几个月。在新的应用程序中，依赖于第三方API提供服务的例子很多，如认证(OAuth)、社交、地图、人工智能等。 增强可伸缩性：所有人都希望自己开发的应用能够快速获取大量的新增用户，但是当活跃用户快速增长的时候，服务器的压力也会激增。使用Serverless架构的体系不再有上述担忧，可以及时、灵活进行扩展来应对快速增长的活跃用户带来的访问压力。 降低成本：Serverless架构模式可以降低计算能力和人力资源方面的成本，如果不需要服务器，就不用花费时间重新造轮子、风险监测、图像处理，以及基础设施管理，操作成本会直线下降。 改善用户体验：用户通常不太关心基础设施，而更注重于功能和用户体验。Serverless架构允许团队将资源集中在用户体验上。 减少延迟及优化地理位置信息：应用规模能力取决于三个方面：用户数量、所在位置及网络延迟。当应用要面向全国甚至全球用户的时候，通常会产生较高的延迟，从而降低用户体验。在Serverless架构下，供应商在每个用户附近都有节点，大幅度降低了访问延迟，因此所有用户的体验都可以得到提升。","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[]},{"title":"RPC.01-从SOA到微服务","slug":"31.Backend/RPC.01-从SOA到微服务","date":"2024-01-24T01:27:52.521Z","updated":"2024-01-24T01:27:52.522Z","comments":true,"path":"31.Backend/RPC.01-从SOA到微服务/","link":"","permalink":"https://beefyheisenberg.github.io/31.Backend/RPC.01-从SOA到微服务/","excerpt":"从SOA到微服务▶ SOA: 面向服务的架构（英语：service-oriented architecture）, 即把后台系统按照功能拆分为不同的服务, 这些服务通过统一接口(RPC 或 Http)提供给调用者.比较容易实现SOA的架构是Web Service, 有几种主流的实现SOA的 Web Service: XML-RPC, SOAP, REST, 其中 XML-RPC 和 SOAP都是通过 “HTTP协议传输XML内容”的方式 参考: [[RESTful]] REST: 把对外提供的服务抽象为某种资源(User/Order), 通过HTTP的 GET/POST/DELETE/PUT方法对资源对象进行操作, 满足这几个条件的服务, 可以称为 #RESTful 的 (Representional State Transfer)","text":"从SOA到微服务▶ SOA: 面向服务的架构（英语：service-oriented architecture）, 即把后台系统按照功能拆分为不同的服务, 这些服务通过统一接口(RPC 或 Http)提供给调用者.比较容易实现SOA的架构是Web Service, 有几种主流的实现SOA的 Web Service: XML-RPC, SOAP, REST, 其中 XML-RPC 和 SOAP都是通过 “HTTP协议传输XML内容”的方式 参考: [[RESTful]] REST: 把对外提供的服务抽象为某种资源(User/Order), 通过HTTP的 GET/POST/DELETE/PUT方法对资源对象进行操作, 满足这几个条件的服务, 可以称为 #RESTful 的 (Representional State Transfer) ▶ 微服务: 微服务是SOA架构演进的结果。两者都是”对外提供接口的”一种架构设计方式，随着互联网架构的发展，更复杂的平台和业务的出现，导致SOA架构向更细粒度、更通用化发展，就演变成所谓的微服务了。微服务是SOA发展出来的产物，它是一种比较现代化的细粒度的SOA实现方式，微服务更强调去中心化分布式部署 SOA与微服务的区别在于如下几个方面： 微服务相比于SOA更加精细，微服务更多的以独立的进程的方式存在，互相之间并无影响； 微服务提供的接口方式更加通用化，例如HTTP RESTful方式，各种终端都可以调用，无关语言、平台限制； 微服务更倾向于分布式去中心化的部署方式，在互联网业务场景下更适合。 @ref: 微服务的定义、优缺点和最佳实践 - InfoQ 阿里P8架构师谈：Restful、SOAP、RPC、SOA、微服务之间的区别 RPCRPC（Remote Procedure Call）—远程过程调用，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。 微服务和RPC的区别: RPC是一种进程远程调用的方式，更强调的是异构平台之间进程通信的机制。SOA是一种产品架构的理念，以服务为中心，松耦合，通过定义严谨明确的接口进行通信。有比较完善的服务管理机制。两者并不是一个层面上的概念，可以说RPC是SOA架构的一种实现。 RPC用到的技术栈: 传输协议: RMI（👉🏻[[../@project/Java-RMI]]）、Dubbo、Hessian、Http、JSON 传输框架：Netty、Mina 序列化：Hessian、Protobuf、dubbo、JSON、SOAP","categories":[{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"}],"tags":[{"name":"后端架构","slug":"后端架构","permalink":"https://beefyheisenberg.github.io/tags/后端架构/"},{"name":"RPC","slug":"RPC","permalink":"https://beefyheisenberg.github.io/tags/RPC/"},{"name":"SOA","slug":"SOA","permalink":"https://beefyheisenberg.github.io/tags/SOA/"},{"name":"微服务","slug":"微服务","permalink":"https://beefyheisenberg.github.io/tags/微服务/"},{"name":"服务治理","slug":"服务治理","permalink":"https://beefyheisenberg.github.io/tags/服务治理/"},{"name":"Motan","slug":"Motan","permalink":"https://beefyheisenberg.github.io/tags/Motan/"},{"name":"IaaS","slug":"IaaS","permalink":"https://beefyheisenberg.github.io/tags/IaaS/"},{"name":"PaaS","slug":"PaaS","permalink":"https://beefyheisenberg.github.io/tags/PaaS/"},{"name":"SaaS","slug":"SaaS","permalink":"https://beefyheisenberg.github.io/tags/SaaS/"}]},{"title":"网络协议：HTTP","slug":"22.Network-Protocol/网络协议3-HTTP","date":"2024-01-24T01:27:52.515Z","updated":"2024-01-24T01:27:52.515Z","comments":true,"path":"22.Network-Protocol/网络协议3-HTTP/","link":"","permalink":"https://beefyheisenberg.github.io/22.Network-Protocol/网络协议3-HTTP/","excerpt":"URLHTTP由URL(统一资源定位符)访问资源，一个完整的URL组成如下: http://user:passwd@www.x.com:80/index.htm?var1=1&amp;var2=2#frag这个真没什么好解释的… 更多有关URL的信息请参考RFC1808 URL编码 &amp; 解码URL中的GET参数和POST内容，除字母数字。 常用编程符号(不含双引)之外，都要Encode处理，空格被转换为+号，+号被转换为%2bEncode处理过的POST内容，Http头会增加content-type: application/x-www-form-urlencoded，参考Content-Type一节。","text":"URLHTTP由URL(统一资源定位符)访问资源，一个完整的URL组成如下: http://user:passwd@www.x.com:80/index.htm?var1=1&amp;var2=2#frag这个真没什么好解释的… 更多有关URL的信息请参考RFC1808 URL编码 &amp; 解码URL中的GET参数和POST内容，除字母数字。 常用编程符号(不含双引)之外，都要Encode处理，空格被转换为+号，+号被转换为%2bEncode处理过的POST内容，Http头会增加content-type: application/x-www-form-urlencoded，参考Content-Type一节。 HTTP Request一个完整的请求分请求头和消息体两部分: 请求头的每一行都是CRLF结尾，和消息体之间有一个空行分隔开，空行只能是一个CRLF而不能带有空格符。 消息体则是也包括头部和内容. 头包括Allow、Content-Type、Content-Encoding、Content-Language、Content-Length、Content-Location、Content-Type、Expires等等。 MethodHTTP请求共有8种Method，Method是区分大小写的: OPTIONS: 查询服务器支持哪些action。 HEAD: 请求服务器返回url对应资源的响应头，并不需要服务器返回响应消息体。 GET: 请求url指定的资源。 POST: 向url指定的位置增加数据。 PUT: 上传/更新资源。 DELETE: 删除资源 TRACE: 多用于诊断 CONNECT: 备用 PUT：client对一个URI发送一个Entity，服务器在这个URI下如果已经又了一个Entity，那么此刻服务器应该替换成client重新提交的，也由此保证了PUT的幂等性。如果服务器之前没有Entity ，那么服务器就应该将client提交的放在这个URI上。因为服务器在实现POST是不可预知，所以将其定义为不安全、不幂等的Verb。基本上不能方便的归纳为“增删改”之类的行为，都可以使用POST方法。 幂等性怎么理解HTTP幂等性:HTTP幂等方法，是指无论调用多少次返回的结果都相同，对资源没有影响。 HTTP GET方法，用于获取资源，不管调用多少次接口，结果都不会改变，所以是幂等的。HTTP POST方法是一个非幂等方法，因为每次调用都将产生新的资源。HTTP PUT直接把实体部分的数据替换到服务器的资源，我们多次调用它，只会产生一次影响，但是有相同结果的 HTTP 方法，所以满足幂等性。HTTP DELETE方法用于删除资源，会将资源删除。调用一次和多次对资源产生影响是相同的，所以也满足幂等性。 Content-type multipart/form-data ： 需要在表单中进行文件上传时，就需要使用该格式 text/html ： HTML格式 text/plain ：纯文本格式 text/xml ： XML格式 image/gif ：gif图片格式 application/xml ： XML数据格式 application/json ： JSON数据格式 application/msword ： Word文档格式 application/octet-stream ： 二进制流数据（如常见的文件下载） POST提交表单几种常见Content-type application/x-www-form-urlencoded: 格式为k=v&amp;k=v, 并且经过encode multipart/form-data: 多用来上传数据 application/json: http的body是json格式 HTTP ResponseCodeResponse Header第一行是服务器返回的状态码: 200: OK 204: No Content 301: 永久重定向 302: 临时 400: Bad Request，比如缺少参数，语法错误 401: Unauthorized 403: Forbidden 404: Not Found 500: Internal Server Error 服务器内部错误 502: Bad Gateway 后端服务返回给网关无效响应 503: Service Unavailable 后端服务由于维护或者过载，积极拒绝服务 504: Gateway Timeout 代理从后端服务器获取超时 [[../31.Backend/反向代理-Nginx#Nginx返回502 503 504]] Http Request和Response的一些常用参数Content-Type:常见的Content-Type: text/html text/plain text/css text/javascript application/x-www-form-urlencoded: 常用的表单发包方式，POST内容做了URLEncode处理会自动加上这个参数 multipart/form-data application/json application/xml Cache-Control:Location:用于将客户端重定向一个新的地址，一般和302状态值相关。 Content-Length:指定response的长度，如果一个response太大服务器无法确定其长度，服务器会在response头部插入一个 Transfer-Encoding: chunked字段，表示需要分块传输. 这个response的消息体包括数个chunk，每个chunk都由本chunk字节数+CRLF + 本chunk内容+CRLF组成，最后会带一个长度为0的chunk表示结束。HTTP/1.1 200 OKContent-Type: text/plainTransfer-Encoding: chunked25This is the data in the first chunk1Aand this is the second one0 HTTPSHTTPS的端口是443，HTTP的端口是80，二者的区别还在于HTTPS是在普通HTTP和TCP之间插入了一个SSL(Secure SocketLaye，基于非对称/对称加密算法的协议)。 SSLSSL使用了RSA非对称加密，SSL握手过程: 客户端发出请求，服务端发送给客户端证书和公钥; 客户端先验证服务端的证书有效性，然后随机生成预备密码(pre-master secret)，用公钥加密发给服务器; 服务器用私钥解密出预备密码，然后双方用预备密码商议出主密码(master secret)，SSL握手结束; 之后C/S端使用主密码做对称加密传输数据。 SSL的证书SSL证书由CA(“证书中心”certificate authority)颁发，CA将网站的的公钥，用CA的私钥加密，生成为数字证书(Digital Certificate). 也就是说网站的数字证书里是含有网站的公钥的，客户端可以从CA处请求验证这个证书是否正确。@ref: 阮一峰:数字签名是什么？ Restful符合Restful风格 URI中只有名词, 表示资源 动词不应该出现在URI中, 而使用HTTP协议里的GET, POST, DELETE, PUT对应查询, 新增, 删除, 更新; 接口返回JSON, 或者XML 返回Code用HTTP状态表示 为什么要采用RESTful架构？·tianlu1677/filemanagerWiki·GitHub Java对Restful的支持 用Java技术创建RESTfulWeb服务（JAX-RS）:https://www.ibm.com/developerworks/cn/web/wa-jaxrs/ Restful框架 Jersey, Restx … 使用Jersey创建RESTful WebService: http://www.importnew.com/7336.html","categories":[{"name":"22.Network-Protocol","slug":"22-Network-Protocol","permalink":"https://beefyheisenberg.github.io/categories/22-Network-Protocol/"}],"tags":[{"name":"网络协议","slug":"网络协议","permalink":"https://beefyheisenberg.github.io/tags/网络协议/"},{"name":"HTTP","slug":"HTTP","permalink":"https://beefyheisenberg.github.io/tags/HTTP/"},{"name":"Restful","slug":"Restful","permalink":"https://beefyheisenberg.github.io/tags/Restful/"}]},{"title":"网络协议2a-TCP的KeepAlive","slug":"22.Network-Protocol/网络协议2a-TCP的KeepAlive","date":"2024-01-24T01:27:52.510Z","updated":"2024-01-24T01:27:52.511Z","comments":true,"path":"22.Network-Protocol/网络协议2a-TCP的KeepAlive/","link":"","permalink":"https://beefyheisenberg.github.io/22.Network-Protocol/网络协议2a-TCP的KeepAlive/","excerpt":"TCP 协议的KeepAliveKeepAlive 并不是 TCP 协议规范的一部分，但在几乎所有的 TCP/IP 协议栈（不管是 Linux 还是 Windows）中，都实现了 KeepAlive 功能。参考 [RFC1122 #TCP Keep-Alives] @ref TCP 协议栈与 KeepAlive 相关的参数有: tcp_keepalive_time: KeepAlive 的空闲时长，或者说每次正常发送心跳的周期，默认值为 7200 s（2 小时）@doubt tcp_keepalive_intvl: KeepAlive 探测包的发送间隔，默认值为 75s tcp_keepalive_probes: 在 tcp_keepalive_time 之后，没有接收到对方确认，继续发送保活探测包次数，默认值为 9（次） 以上参数都可以通过 sysctl 命令修改内核参数实现修改: sysctl -w net.ipv4.tcp_keepalive_time = 7500,更多 sysctl 使用参考 [[../21.Operating-System/Linux.04a.Sysctl]]","text":"TCP 协议的KeepAliveKeepAlive 并不是 TCP 协议规范的一部分，但在几乎所有的 TCP/IP 协议栈（不管是 Linux 还是 Windows）中，都实现了 KeepAlive 功能。参考 [RFC1122 #TCP Keep-Alives] @ref TCP 协议栈与 KeepAlive 相关的参数有: tcp_keepalive_time: KeepAlive 的空闲时长，或者说每次正常发送心跳的周期，默认值为 7200 s（2 小时）@doubt tcp_keepalive_intvl: KeepAlive 探测包的发送间隔，默认值为 75s tcp_keepalive_probes: 在 tcp_keepalive_time 之后，没有接收到对方确认，继续发送保活探测包次数，默认值为 9（次） 以上参数都可以通过 sysctl 命令修改内核参数实现修改: sysctl -w net.ipv4.tcp_keepalive_time = 7500,更多 sysctl 使用参考 [[../21.Operating-System/Linux.04a.Sysctl]] KeepAlive 默认情况下是关闭的，可以被上层应用开启和关闭, 下面介绍在 Java、C 语言和 Nginx 中如何设置 KeepAlive 代码和应用程序如何设置 KeepaliveJava(Netty)设置 KeepAliveServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 100) .childOption(ChannelOption.SO_KEEPALIVE, true) .handler(new LoggingHandler(LogLevel.INFO)); Java 程序只能做到设置 SO_KEEPALIVE 选项，其他配置项只能依赖于 sysctl 配置，系统进行读取。 C 语言 socket 编程设置 KeepAlivesetsockopt 函数原型:#include &lt;sys/socket.h&gt;int setsockopt(int socket, int level, int option_name, const void *option_value, socklen_t option_len); How to use:int socket(int domain, int type, int protocol)&#123; int (*libc_socket)(int, int, int); int s, optval; char *env; *(void **)(&amp;libc_socket) = dlsym(RTLD_NEXT, \"socket\"); if(dlerror()) &#123; errno = EACCES; return -1; &#125; if((s = (*libc_socket)(domain, type, protocol)) != -1) &#123; if((domain == PF_INET) &amp;&amp; (type == SOCK_STREAM)) &#123; if(!(env = getenv(\"KEEPALIVE\")) || strcasecmp(env, \"off\")) &#123; optval = 1; &#125; else &#123; optval = 0; &#125; if(!(env = getenv(\"KEEPALIVE\")) || strcasecmp(env, \"skip\")) &#123; setsockopt(s, SOL_SOCKET, SO_KEEPALIVE, &amp;optval, sizeof(optval)); &#125; // ... &#125; &#125; return s;&#125; 代码摘取自 libkeepalive 源码，C 语言可以设置更为详细的 TCP 内核参数 Nginx 配置 KeepAliveNginx 配置里有两处 KeepAlive, 含义不同: listen 下的 so_keepalive=30m::10: 设置 TCP_KEEPIDLE 为 30 分钟, TCP_KEEPINTVL 默认值, TCP_KEEPCNT 设为 10 probes 注意区分 upstream 下的 keepalive N 这里不是指超时， N 指的是每个 Worker 与 upstream 服务器可缓存的最大连接数, KeepAlive 使用场景常见的几种使用场景： 检测挂掉的连接（导致连接挂掉的原因很多，如服务停止、网络波动、宕机、应用重启等） 防止因为网络不活动而断连（使用 NAT 代理或者防火墙的时候，经常会出现这种问题） TCP 层面的心跳检测 通常很多应用程序也有类似 KeepAlive 的心跳检测, 和 TCP KeepAlive 区别在于: TCP 的 KeepAlive 发送的数据包相比应用层心跳检测包更小，仅提供检测连接功能 应用层心跳包不依赖于传输层协议，无论传输层协议是 TCP 还是 UDP 都可以用 应用层心跳包可以定制，可以应对更复杂的情况或传输一些额外信息 KeepAlive 仅代表 TCP 层连接仍保持着，而心跳包往往还代表客户端可正常工作 比较 Http 协议头中 Keep-Alive在 Http Response 的 http 头可以看到下面的字段:HTTP/1.1 200 OKContent-Type: text/html; charset=utf-8Content-Length: 40026Connection: keep-alive HTTP 协议采用“请求-应答”模式，当使用普通模式，即非 KeepAlive 模式时，每个请求/应答客户和服务器都要新建一个连接，完成之后立即断开连接（HTTP 协议为无连接的协议）；当使用 Keep-Alive 模式（又称持久连接、连接重用）时，Keep-Alive 功能使客户端到服务器端的连接持续有效，当出现对服务器的后继请求时，Keep-Alive 功能避免了建立或者重新建立连接。 http 1.0 中默认是关闭的, http 1.1 中默认启用 Keep-Alive @ref: https://blog.biezhi.me/2017/08/talk-tcp-keepalive.html","categories":[{"name":"22.Network-Protocol","slug":"22-Network-Protocol","permalink":"https://beefyheisenberg.github.io/categories/22-Network-Protocol/"}],"tags":[]},{"title":"网络协议：TCP/IP","slug":"22.Network-Protocol/网络协议2-TCP","date":"2024-01-24T01:27:52.503Z","updated":"2024-01-24T01:27:52.504Z","comments":true,"path":"22.Network-Protocol/网络协议2-TCP/","link":"","permalink":"https://beefyheisenberg.github.io/22.Network-Protocol/网络协议2-TCP/","excerpt":"OSI 七层模型回顾参考: 网络协议1-网络分层模型 TCP 报头 Source Port，Destination Port：TCP 的包是没有 IP 地址的，那是 IP 层上的事。但是有源端口和目标端口。 Sequence Number 是发出包的序号，用来解决网络包乱序（reordering）问题。 Acknowledgement Number：就是回复 ACK 序号，占 32 位，只有 ACK 标志位为 1 时，确认序号字段才有效，Ack=Seq+1。 TCP Flag ，也就是包的类型，主要是用于操控 TCP 的状态机的，Flag 共 6 个，即 URG、ACK、PSH、RST、SYN、FIN 等，具体含义如下： URG：紧急指针（urgent pointer）有效。 ACK：Acknowledgement，确认收到。 SYN：Synchronize Sequence Numbers，一般在发起一个新连接的时候需双方重新同步 Seq Num； PSH：接收方应该尽快将这个报文交给应用层。 RST：RESET，重置连接； FIN：FINISH，释放一个连接。 Window 又叫 Advertised-Window，也就是著名的滑动窗口（Sliding Window），用于解决流控的。","text":"OSI 七层模型回顾参考: 网络协议1-网络分层模型 TCP 报头 Source Port，Destination Port：TCP 的包是没有 IP 地址的，那是 IP 层上的事。但是有源端口和目标端口。 Sequence Number 是发出包的序号，用来解决网络包乱序（reordering）问题。 Acknowledgement Number：就是回复 ACK 序号，占 32 位，只有 ACK 标志位为 1 时，确认序号字段才有效，Ack=Seq+1。 TCP Flag ，也就是包的类型，主要是用于操控 TCP 的状态机的，Flag 共 6 个，即 URG、ACK、PSH、RST、SYN、FIN 等，具体含义如下： URG：紧急指针（urgent pointer）有效。 ACK：Acknowledgement，确认收到。 SYN：Synchronize Sequence Numbers，一般在发起一个新连接的时候需双方重新同步 Seq Num； PSH：接收方应该尽快将这个报文交给应用层。 RST：RESET，重置连接； FIN：FINISH，释放一个连接。 Window 又叫 Advertised-Window，也就是著名的滑动窗口（Sliding Window），用于解决流控的。 Sequence NumberTCP 的三次、四次、数据传输过程中，发送的 Seq Num 和 Ack Num 的变化： 发出数据段 Seq Num = 上次发送报文的 Seq + 上次发送报文的 Len 回复 Ack Num = 上次收到的报文中的 Seq + Len（数据长度） 也就是说，接收方发出的 ACK Num，是下次期望收到的 Seq Num SYN 报文或者 FIN 报文 计算 Seq Num 时按 1 算 对于建链接的 3 次握手，主要是要初始化 Sequence Number 的初始值。通信的双方要互相通知对方自己的初始化的 Sequence Number（缩写为 ISN：Inital Sequence Number） 发送方每发送一个数据包，下个 Seq Num 就增加该次发包的长度，比如第一次发送的包 Seq = 1，长度= 1440，第二次再发送数据包 Seq = 1441；接收方收到 1440 长度的包，回复一个 ACK 消息（ack = 发送方的 Seq Num）； 初始 SN：关于三次握手时，初始的 Seq Num 并不是从 0 开始，RFC793中说，初始 SN 会和一个假的时钟绑在一起，这个时钟会在每4微秒对 SN 做加一操作，直到超过2^32又从0开始。这个周期 ≈ 4.55个小时。举例，在这个连接上（@doubt 唯一四元组？）不断进行握手挥手操作，那么每次握手时的初始 SN（Inital Sequence Number，ISN）是不同的，但每隔4.55个小时再次相同； 这样，一个连接的 Sequence Number 重复周期大约是。因为，我们假设我们的 TCP Segment 在网络上的存活时间不会超过 Maximum Segment Lifetime。所以，只要 MSL 的值小于 4.55 小时，那么，我们就不会重用到 Sequence Number。 如果你用 Wireshark 抓包程序看3次握手，你会发现握手后，初始 SeqNum 总是为0，其实是 Wireshark 为了显示更友好，使用了 Relative SeqNum——相对序号，你只要在右键菜单中的 protocol preference 中取消掉就可以看到“Absolute SeqNum”了 TCP Segment 最大存活时间：Maximum Segment Lifetime（缩写为 MSL – Wikipedia语条），指的是 TCP 数据段在网络上最大存活时间，一般来说 MSL 设置值不能超过上面4.55小时， 三次握手、四次挥手 ➤ 3次握手过程详解：（1）第一次握手： Client 将标志位 SYN 置为 1，随机产生一个值 seq=X，并将该数据包发送给 Server，Client 进入 SYN_SENT 状态，等待 Server 确认。 （2）第二次握手： Server 收到 SYN 数据包后，也会回复一个 SYN（将标志位 SYN 和 ACK 都置为 1，ack=X+1，随机产生一个值 seq=Y），Server 进入 SYN_RCVD （半连接）状态。 （3）第三次握手： Client 收到 SYN 确认后，回复 ACK（ACK 置为 1，ack=Y+1），并将该数据包发送给 Server， Server 进入 ESTABLISHED 状态 ➤ 4次挥手过程详解： （1）第一次挥手： Client 发送一个 FIN，用来关闭 Client 到 Server 的数据传送，Client 进入 FIN_WAIT_1状态； （2）第二次挥手： Server 收到 FIN 后，发送一个 ACK 给 Client，确认序号为收到序号+1（与 SYN 相同，一个 FIN 占用一个序号），Server 进入 CLOSE_WAIT 状态。Client 接收到 ACK 进入 FIN_WAIT_2 状态； （3）第三次挥手： Server 发送一个 FIN，用来关闭 Server 到 Client 的数据传送，Server 进入 LAST_ACK 状态。Client 收到 FIN 进入 TIME_WAIT 状态； （4）第四次挥手： Client 收到 FIN 后，Client 进入 TIME_WAIT 状态，并发送一个 ACK 给 Server，Server 服务端收到后会进入 CLOSED 状态。Client 要等待 Maximum segment lifetime 的时间后也会进入 CLOSED 上面是 Client 主动关闭， Server 被动关闭的情况，实际情况下 Server 主动关闭的情况更多，谁主动关闭谁就有 TIME_WAIT。 为什么挥手是 4 次？由于 TCP 连接是全双工的（每一方都可以收&amp;发），因此每个方向都必须要单独进行关闭，一方发送 FIN 仅仅代表这一方不会再发送数据报文了，但仍可以接收数据报文。当被动关闭的一端（这里是服务端）收到对方的 FIN 时，仅仅表示对方不再发送数据了，但是对方还能接收数据，如果被动方还有数据没发完，需要发完这些数据后，再发出 FIN 报文表示自己不再发数据了。因此，己方 ACK 和 FIN 一般都会分开发送。 关闭时的 TIME_WAIT根据 TCP 状态机的图可知，主动发起断开连接的一端，收到对端的 FIN+ACK 后，会进入 TIME_WAIT 状态，从 TIME_WAIT 状态到 CLOSED 状态，有一个超时设置，这个超时设置是 两个 MSL（Maximum Segment Lifetime）。为什么要这有 TIME_WAIT？为什么不直接给转成 CLOSED 状态呢？ 根据第三版《UNIX 网络编程卷1》2.7节，TIME_WAIT 状态的主要目的有两个： （1）优雅的关闭 TCP 连接，也就是尽量保证被动关闭的一端收到它发出去的 FIN 报文的 ACK 报文； （2）为了避免前后两次 TCP 连接（两个使用相同四元组的）中的旧连接发出去的报文，干扰后面的新连接通讯。等待 2MSL 让旧连接的数据包消逝； 对（1）的解释 ： 如果主动断开方等待的时间不够长，当被动方（服务端） 还没有收到 ACK 消息时，主动断开方又尝试重新与服务端建立 TCP 连接，这种情况下就会造成以下问题： 上次连接的被动断开方因为没有收到 ACK 消息，所以仍然认为当前连接是合法的，主动断开方重新发送的 SYN 消息请求握手时，收到服务端的 RST 消息，连接建立的过程就会被终止; 另外一个原因，如果 被动方（服务端） 没有收到它自己发送的 FIN 的 ACK，那么被动方 会尝试重发一次 FIN，如果主动方 没有 TIME_WAIT 而是直接 Close 了，那就无法处理这个重发的 FIN，会导致被动方进入错误的状态，主动方多等一个 TIME_WAIT，如果这段时间里没有收到重传的 FIN，就说明被动方 正常收到了 ACK（在极端的网络条件下，这个 WAIT 机制也不能一定保证，但能解决大部分情形），所以主动方的 TIME_WAIT 的另一个原因是为了确保被动方正确关闭； 那为什么等待 2 个 MSL？ 对（2）的解释：为了保证新 TCP 连接的数据段不会与还在网络中传输的历史连接的数据段重复，TCP 连接在分配新的序列号之前需要至少静默 MSL： To be sure that a TCP does not create a segment that carries a sequence number which may be duplicated by an old segment remaining in the network, the TCP must keep quiet for a maximum segment lifetime (MSL) before assigning any sequence numbers upon starting up or recovering from a crash in which memory of sequence numbers in use was lost. @ref: “Knowing When to Keep Quiet · Transmission Control Protocol RFC793” https://tools.ietf.org/html/rfc793 下图是一个例子： 服务端发送的 SEQ = 301 消息由于网络延迟直到 TCP 连接关闭后也没有收到；当使用相同端口号的 TCP 连接被重用后，SEQ = 301 的消息才发送到客户端，然而这个过期的消息却可能被客户端正常接收，这就会带来比较严重的问题 ![[../_images/22.Network-Protocol-2023-04-22.png]] RFC 793 中虽然指出了 TCP 连接需要在 TIME_WAIT 中等待 2 倍的 MSL，但是并没有解释清楚这里的两倍是从何而来，比较合理的解释是 — 网络中可能存在来自发起方的数据段，当这些发起方的数据段被服务端处理后又会向客户端发送响应，所以一来一回需要等待 2 倍的时间 参考： 🔗 为什么 TCP 协议有 TIME_WAIT 状态 - 面向信仰编程 🔗 为什么tcp的TIME_WAIT状态要维持2MSL 不为人知的网络编程(三)：关闭TCP连接时为什么会TIME_WAIT、CLOSE_WAIT-网络编程/专项技术区 - 即时通讯开发者社区! 🔗 TIME_WAIT and its design implications for protocols and scalable client server systems 连接时的 SYN 重发在三次握手过程中，Server 发送 SYN-ACK 之后，收到 Client 的 ACK 之前的的 TCP 连接称为半连接（half-open connect），直到 Server 收到 ACK 后才转入 ESTABLISHED 状态。但如果 Server 一直都没收到 ACK，那么 Server 会重发 SYN-ACK。 在 Linux 下，默认情况下 Server 重发 SYN-ACK 的次数为 5 次，重试的间隔时间从 1 s 开始每次都翻倍，5 次的重试时间间隔为 1 s, 2 s, 4 s, 8 s, 16 s，总共 31 s，第 5 次发出后还要等 32 s 才能知道第 5 次也超时了，所以，总共需要 1 s + 2 s + 4 s+ 8 s+ 16 s + 32 s = 63 s 才会断开这个连接（期间 Server 一直处于半连接状态）。 SYN 攻击就是 Client 在短时间内伪造大量不存在的 IP 地址，并向 Server 不断地发送 SYN 包（或者发送完 SYN 包就立刻下线），正常情况 Server 回复 SYN-ACK，并等待 Client 的 ACK。 但如果 Server 端如果在一定时间内没有收到 Client 的 ACK 则会重发 SYN-ACK。由于 CLient 源地址是不存在的（或者已经下线），因此 Server 需要不断重发 SYN-ACK，这些无效的 SYN-ACK 包将长时间占用 Server 机器的SYN 队列，导致正常的 SYN 请求因为队列满而被丢弃，从而引起网络堵塞甚至系统瘫痪。 SYN 攻击时一种典型的 DDOS 攻击，检测 SYN 攻击的方式非常简单，即当 Server 上有大量半连接状态且源 IP 地址是随机的，则可以断定遭到 SYN 攻击了 ： netstat -nat | grep Linux 下给了一个叫 tcp_syncookies 的参数来应对这个问题 —— 当 SYN 队列满了后，TCP 会通过源地址端口、目标地址端口和时间戳打造出一个特别的 Sequence Number 发回去（又叫 cookie），如果是攻击者则不会有响应，如果是正常连接，则会把这个 SYN Cookie 发回来，然后服务端可以通过 cookie 建连接（即使 Client 不在 SYN 队列中）。请注意，请先千万别用 tcp_syncookies 来处理正常的大负载的连接的情况。因为，synccookies 是妥协版的 TCP 协议，并不严谨。 一般情况下为了防范 SYN 攻击，有三个 TCP 参数可供你选择，第一个是：tcp_synack_retries 来减少重试次数；第二个是：tcp_max_syn_backlog 可以增大 SYN 连接数；第三个是：tcp_abort_on_overflow 处理不过来干脆就直接拒绝连接了。 为什么要有半连接队列？ 因为服务端要确保自己的 SYN+ACK 送达客户端，所以 SYN+ACK 会有重发机制，所以就需要暂存半连接。tcp_syncookies 的作用和局限性？ 如果半连接队列满了，且 tcp_syncookies = 1，这时会启用 syn cookie 的机制：服务端根据双方 IP、时间戳、MSS 等创建一个 cookie，并附在 SYN+ACK（二次握手）里，客户端返回的 ACK 需要携带此 cookie 才能成功完成三次握手；但因为服务端并没有像半连接队列那样暂存客户端的信息，所以 syn cookie 机制没有重发功能；虽然 tcp_syncookies 看似解决了 SYN 攻击，但是客户端（攻击者）可以采用另一种策略：伪造第三次的 ACK（里面是无效 cookie），让服务端解码无效的 cookie 浪费 CPU； 重传机制@ref: TCP 的那些事儿（上） | 酷 壳 - CoolShell 发送端发了 Seq Num = 1,2,3,4,5一共五份数据，接收端收到了1，2，于是回 ack 3，然后收到了4（注意此时3没收到），此时的 TCP 会怎么办？ 超时重传如果发送方超过 timeout 还没有收到数据 3（Seq Num =3），会触发超时重传，超时时间（RTO）是动态计算的（参考「动态 RTO」） 发送方计算超时时间是动态的，但重发次数是内核配置的：net.ipv4.tcp_retries2 Fast RetransmitTCP 引入了一种叫快速重传机制 （Fast Retransmit） 的算法。如果包没有连续到达，就 ack 最后那个可能被丢了的包，如果发送方连续收到 3 次相同的 ack，就重传。Fast Retransmit 的好处是不用等 timeout 了再重传。 举例：如果发送方发出了 Seq Num = 1，2，3，4，5 份数据，数据 1 先到送了，于是就接收方 ack 回 2，但数据 2 因为某些原因没收到，3 却到达了，于是接收方还是 ack 回2，后面的 4 和 5 都收到了，接收方还是 ack 回 2，因为数据 2 仍旧没有收到，于是发送端收到了三个 ack=2 的确认。发送方便知道 2 有可能丢了，于是就发送方重发送 2。然后接收端收到了 2，此时因为 3，4，5 都收到了，于是 ack 回6。 Fast Retransmit 的方案，和超时重传机制的区别：不以时间驱动，而以数据驱动，触发重传 SACK有了超时重传和快速重传，可以决定什么情况触发重传了，但此时有个问题：是重传之前的一个还是重传之前的所有？对于上面的示例来说，是只重传2？还是重传 2、3、4 、5？ 为了让需要重传的一方知道具体哪一个数据需要重传，这就需要 Selective Acknowledgment (SACK)机制：这种机制下，ACK 还是 Fast Retransmit 机制的 ACK 一样，接收端缺少哪份数据就回复这份数据的 ACK，此外需要在 TCP 头里加一个 SACK 的东西，而 SACK 则是向发送方汇报收到的数据的 Seq Num 范围，发送方拿到这个 SACK 就知道哪些数据无需重传了。 这个协议需要两边都支持。在 Linux 下，可以通过tcp_sack参数打开这个功能（Linux 2.4后默认打开） 比如发送三分数据：100-299，300-499，500-699，中间一份数据丢失，接收方收到500-699之后，会回复 ACK=300，SACK=500-700，这样发送端通过 SACK 就知道： 500 前面的一段数据需要重发，而 500-700 的不需要重发。 注意：SACK 会消费发送方的资源，试想，如果一个攻击者给数据发送方发一堆 SACK 的选项，这会导致发送方开始要重传甚至遍历已经发出的数据，这会消耗很多发送端的资源。详细的东西请参看《TCP SACK的性能权衡》 Duplicate SACK有了 SACK，还有没解决的问题，那就是接收方已收到了数据，但回复的 ACK 丢了，导致发送方触发了重传（毫无意义）； Duplicate SACK 又称 D-SACK，其主要复用了 SACK 字段来告诉发送方有哪些数据被重复接收了。 D-SACK 使用了 SACK区间范围 的第一个数值来做标志： 如果 SACK 范围的第一个数值，被 ACK 所覆盖，那么就是 D-SACK 如果 SACK 范围的第一个数值，被 SACK 的第二个段覆盖，那么也是 D-SACK Linux 下的 tcp_dsack 参数用于开启这个功能（Linux 2.4后默认打开） 示例一：ACK 丢包 下面的示例中，因为接收端发出的 ACK 丢失，导致发送端重传了数据包（3000-3499），于是接收端发现重复收到，于是回了一个 ACK=4000, SACK=3000-3500，因为 ACK =4000 意味着收到了4000之前的所有数据，4000 范围盖过了 SACK 的第一个数，所以这个 SACK 字段就不是代表SACK，而是 D-SACK。 发送端收到这个 ACK 后，就知道是接收端的 ACK 丢了，但数据已经送到了。 RTT 采样 &amp; 动态 RTO从前面的 TCP 重传机制我们知道 Timeout 的设置对于重传非常重要： 太长的 Timeout 导致传输效率下降； 太短的 Timeout 会导致可能并没有丢就重发。于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。 所以，TCP 的重传 Timeout （Retransmission TimeOut，RTO）是动态计算的，计算方式是采样一段时间的 RTT（Round Trip Time），平滑计算出 RTO。 RTT——Round Trip Time，也就是一个数据包从发出去到回来的时间 计算 RTO 的平滑算法： （1）经典算法（2）Karn / Partridge 算法（3）Jacobson / Karels 算法：今天的 TCP 协议中在用的算法 流控、拥塞控制@ref： TCP 的那些事儿（下） | 酷 壳 - CoolShell @tldr： 流控： 实现方式-滑动窗口（swnd） 流控目的？发送方需要控制给（每个 sock）的对端发送的数据快慢 如果接收方把滑动窗口降维为 0，发送方的处理（Zero Window） 拥塞控制： 拥塞控制解决什么？以及和流控的区别？ 拥塞控制是为了避免所在网络的拥塞，流控是为了保证接收端的接收能力 @doubt 拥塞控制是调节 cwnd，流控是条件 swnd TCP 如何进行拥塞控制：拥塞控制调节的是 cwnd，单位是 MSS 慢热启动：快速提速 拥塞避免：cwnd 达到某个阈值，线性提速 拥塞发生：降速，根据是超时重传 or 快速重传，下降的速度算法有区别 快速恢复：一般和快速重传一起使用 @doubt： 滑动窗口（swnd）控制的是某个 sock 连接的 sendQ，还是 TCP 全局的发送队列（RING BUF？） 有的资料写：swnd = min( rwnd , cwnd * mss)，即滑动窗口= min(接收窗口, 拥塞窗口 x MSS) @ ​TCP 拥塞控制详解 流控TCP 使用 Sliding Window 来做网络流控。前面我们说过，TCP 头里有一个字段叫 Window，又叫 Advertised-Window，这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。 为了说明滑动窗口，我们需要先看一下 TCP 缓冲区的一些数据结构： （1）接收端 LastByteRead 指向了 TCP 缓冲区中读到的位置，NextByteExpected 指向的地方是收到的连续包的最后一个位置，LastByteRcved 指向的是收到的包的最后一个位置，我们可以看到中间有些数据还没有到达，所以有数据空白区： （2）- 发送端的 LastByteAcked 指向了被接收端 Ack 过的位置（表示成功发送确认），LastByteSent 表示发出去了，但还没有收到成功确认的 Ack，LastByteWritten 指向的是上层应用正在写的地方： 于是： 接收端在给发送端回 ACK 中会汇报自己的 AdvertisedWindow = MaxRcvBuffer – LastByteRcvd – 1; 而发送方会根据这个窗口来控制发送数据的大小，以保证接收方可以处理。 下面我们来看一下发送方的滑动窗口示意图： 其中那个黑框就是的滑动窗口，#1 - #4 数据段分别为： Category #1 已收到 ack 确认的数据。 Category #2 发还没收到 ack 的。 Category #3 在窗口中还没有发出的（接收方还有空间）。 Category #4 窗口以外的数据（接收方没空间） 一个处理缓慢的 Server（接收端）是可以把 Client（发送端）的 TCP Sliding Window 给降成0 的，解决这个问题，TCP使用了Zero Window Probe技术，缩写为ZWP，也就是说，发送端在窗口变成0后，会发ZWP的包给接收方，让接收方来ack他的Window尺寸，一般这个值会设置成3次，第次大约30-60秒（不同的实现可能会不一样）。如果3次过后还是0的话，有的TCP实现就会发RST把链接断了。 拥塞控制上面我们知道了，TCP 通过 Sliding Window 来做流控（Flow Control），但是 TCP 觉得这还不够，因为 Sliding Window 需要依赖于连接的发送端和接收端，其并不知道网络中间发生了什么。TCP 的设计者觉得，一个伟大而牛逼的协议仅仅做到流控并不够，因为流控只是网络模型4层以上的事，TCP 的还应该更聪明地知道整个网络上的事。 具体一点，我们知道TCP通过一个timer采样了RTT并计算RTO，但是，如果网络上的延时突然增加，那么，TCP对这个事做出的应对只有重传数据，但是，重传会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，于是，这个情况就会进入恶性循环被不断地放大。试想一下，如果一个网络内有成千上万的TCP连接都这么行事，那么马上就会形成“网络风暴”，TCP这个协议就会拖垮整个网络。这是一个灾难。 所以，TCP不能忽略网络上发生的事情，而无脑地一个劲地重发数据，对网络造成更大的伤害。对此TCP的设计理念是：TCP不是一个自私的协议，当拥塞发生的时候，要做自我牺牲。就像交通阻塞一样，每个车都应该把路让出来，而不要再去抢路了。 拥塞控制调节的是 cwnd（Congestion Window），单位是 MSS 何为 MSS：于以太网来说，MTU 最大是 1500 字节，除去 TCP+IP 头的 40 个字节，真正的数据传输最大 1460 字节，这就是所谓的 MSS（Max Segment Size）； RFC 791 里说了任何一个 IP 设备都得最少接收 576 字节的大小，（实际上来说 576 是拨号的网络的 MTU，而 576 减去 IP 头的 20 个字节就是 536）所以 TCP 的 RFC 定义这个 MSS 的默认值是 536； 拥塞控制主要是四个算法：1）慢启动，2）拥塞避免，3）拥塞发生，4）快速恢复。这四个算法不是一天都搞出来的，这个四算法的发展经历了很多时间，到今天都还在优化中。 （1） 慢热启动算法 – Slow Start（2） 拥塞避免算法 – Congestion Avoidance（3） 拥塞状态时的算法（4） 快速恢复算法 – Fast Recovery 一个简单的图示以同时看一下上面的各种算法的样子： [[../_attachments/TCP 的那些事儿（下） _ 酷 壳 - CoolShell.pdf]] 附：TCP 状态机下图是“TCP 协议的状态机” ：","categories":[{"name":"22.Network-Protocol","slug":"22-Network-Protocol","permalink":"https://beefyheisenberg.github.io/categories/22-Network-Protocol/"}],"tags":[{"name":"网络协议","slug":"网络协议","permalink":"https://beefyheisenberg.github.io/tags/网络协议/"},{"name":"TCP","slug":"TCP","permalink":"https://beefyheisenberg.github.io/tags/TCP/"}]},{"title":"网络协议-IP","slug":"22.Network-Protocol/网络协议2-IP","date":"2024-01-24T01:27:52.497Z","updated":"2024-01-24T01:27:52.497Z","comments":true,"path":"22.Network-Protocol/网络协议2-IP/","link":"","permalink":"https://beefyheisenberg.github.io/22.Network-Protocol/网络协议2-IP/","excerpt":"@todo： DNS、ARP、DHCP、NAT、ICMP、IGMP IP 地址的划分互联网诞生之初，IP 地址显得很充裕，于是计算机科学家们设计了分类地址。IP 地址分类成了 5 种类型，分别是 A 类、B 类、C 类、D 类、E 类： A类地址： 网络地址1字节，主机地址3字节，其中网络地址最高1位必须是0 网络地址占1位，范围是1 — 126（开区间 0000 0000 — 0111 1111）不包括0000 0000 和 0111 111，前者用于表示未知地址，后者表示回环地址 主机地址占3位，表示一个网络地址中最大主机数是2^24 - 2（主机地址全0表示网络地址，全1表示广播地址，所以减2） A类地址范围： 1.0.0.1 — 126.255.255.254 默认子网掩码255.0.0.0 在A类地址中，10.0.0.0到10.255.255.255是私有地址（所谓的私有地址=只能在局域网络中使用） B类地址： 网络地址2字节，主机地址2字节，其中网络地址最高2位必须是10 B类地址范围：128.0.0.1 — 191.255.255.254，每个网络中最大主机数65534 默认子网掩码255.255.0.0 在B类地址中，172.16.0.0 — 172.31.255.255是私有地址 C类地址： 网络地址3字节，主机地址1字节，其中网络地址最高3位必须是110 C类地址范围：192.0.0.1 — 223.255.255.254，每个网络中最大主机数254 默认子网掩码255.255.255.0 在C类地址中，192.168.0.0 — 192.168.255.255是私有地址 而 D 类和 E 类地址是没有主机号的，所以不可用于主机 IP，D 类常被用于多播，E 类是预留的分类，暂时未使用。 因为在 IP 地址中，有两个 IP 是特殊的，分别是主机号全为 1 和全为 0 地址：","text":"@todo： DNS、ARP、DHCP、NAT、ICMP、IGMP IP 地址的划分互联网诞生之初，IP 地址显得很充裕，于是计算机科学家们设计了分类地址。IP 地址分类成了 5 种类型，分别是 A 类、B 类、C 类、D 类、E 类： A类地址： 网络地址1字节，主机地址3字节，其中网络地址最高1位必须是0 网络地址占1位，范围是1 — 126（开区间 0000 0000 — 0111 1111）不包括0000 0000 和 0111 111，前者用于表示未知地址，后者表示回环地址 主机地址占3位，表示一个网络地址中最大主机数是2^24 - 2（主机地址全0表示网络地址，全1表示广播地址，所以减2） A类地址范围： 1.0.0.1 — 126.255.255.254 默认子网掩码255.0.0.0 在A类地址中，10.0.0.0到10.255.255.255是私有地址（所谓的私有地址=只能在局域网络中使用） B类地址： 网络地址2字节，主机地址2字节，其中网络地址最高2位必须是10 B类地址范围：128.0.0.1 — 191.255.255.254，每个网络中最大主机数65534 默认子网掩码255.255.0.0 在B类地址中，172.16.0.0 — 172.31.255.255是私有地址 C类地址： 网络地址3字节，主机地址1字节，其中网络地址最高3位必须是110 C类地址范围：192.0.0.1 — 223.255.255.254，每个网络中最大主机数254 默认子网掩码255.255.255.0 在C类地址中，192.168.0.0 — 192.168.255.255是私有地址 而 D 类和 E 类地址是没有主机号的，所以不可用于主机 IP，D 类常被用于多播，E 类是预留的分类，暂时未使用。 因为在 IP 地址中，有两个 IP 是特殊的，分别是主机号全为 1 和全为 0 地址： 主机号全为 1 指定某个网络下的所有主机，用于广播 主机号全为 0 指定某个网络（子网） ➤ 子网掩码：subnet mask，掩码的意思就是掩盖掉主机号，剩余的就是网络号。将子网掩码和 IP 地址按位计算 AND，就可得到网络号。 子网掩码可以把（一个网络号表示的）网络更加细化：假设对 C 类地址进行子网划分，网络地址 192.168.1.0，使用子网掩码 255.255.255.192 （192 = 1100 0000）对其进行子网划分。C 类地址中前 24 位是网络号，最后 8 位是主机号，根据子网掩码可知从 8 位主机号中借用 2 位作为子网号：所以192.168.1.0这个网络被分为 4 个子网：分别是 00、01、10、11。 ➤ A、B、C 类有个尴尬处境，就是不能很好的与现实网络匹配。 C 类地址能包含的最大主机数量实在太少了，只有 254 个，估计一个网吧都不够用。 而 B 类地址能包含的最大主机数量又太多了，6 万多台机器放在一个网络下面，一般的企业基本达不到这个规模，闲着的地址就是浪费。 这两个缺点，都可以在 CIDR 无分类地址解决 ➤ CIDR(Classless Inter-Domain Routing): 这种方式不再有分类地址的概念，32 比特的 IP 地址被划分为两部分，前面是网络号，后面是主机号。 比如 10.100.122.2/24，这种地址表示形式就是 CIDR，/24 表示前 24 位是网络号，剩余的 8 位是主机号。 IPv6 IPv4 地址是 32 位，8 位为一组，共 4 组，约提供 42 亿个地址，在 2011 年 IPv4 地址已经被分配完了； IPv6 地址是 128 位，16 位为一组，共 8 组，用 : 隔开，如果出现连续的 0 还可以将这些 0 省略，但:不可省略，且一个 IPv6 只能出现一次两个连续 ::","categories":[{"name":"22.Network-Protocol","slug":"22-Network-Protocol","permalink":"https://beefyheisenberg.github.io/categories/22-Network-Protocol/"}],"tags":[{"name":"网络协议","slug":"网络协议","permalink":"https://beefyheisenberg.github.io/tags/网络协议/"},{"name":"IP","slug":"IP","permalink":"https://beefyheisenberg.github.io/tags/IP/"}]},{"title":"网络协议-OSI七层模型","slug":"22.Network-Protocol/网络协议1-网络分层模型","date":"2024-01-24T01:27:52.493Z","updated":"2024-01-24T01:27:52.493Z","comments":true,"path":"22.Network-Protocol/网络协议1-网络分层模型/","link":"","permalink":"https://beefyheisenberg.github.io/22.Network-Protocol/网络协议1-网络分层模型/","excerpt":"@toc: OSI七层模型; 七层、五层、四层对比; ➤ 七层模型: 国际标准组织（ISO）定义的网络互联7层框架, 包括: 7应用层: 该层协议包括 Socket, HTTP, HTTPS, FTP, SSH, POP3, // WebSocket属于哪一层? 6表示层: 格式转换, 把数据转换为应用层能兼容的格式 或 适合传输的格式, 比如: 加密/解密, 压缩/解压 5会话层: 维护和管理数据传输过程中两台计算机之间的连接, 该层协议有: SSL/TLS 4传输层: 传输控制, 例如TCP协议(传输控制协议, 主要实现了传输的可靠性, 例如超时重传), 该层把「传输表头」TH加入数据形成「报文」Segment, 传输表头包括了传输协议等 3网络层: 决定数据的路由, 例如IP/ICMP协议, 该层把「网络表头」NH加入数据形成「包」Packet, 网络表头包括: @todo 2链路层: 负责网络寻找和错误侦测, 该层把「数据链表头」DLH加入数据开头, 以及「数据链表尾」DLT加入数据结尾, 形成「信息框」Data Frame, 数据链表头包括, 该层协议包括WiFi, GPRS(通用分组无线服务) 1物理层: 在局部局域网上传送「数据帧」Data Frame, 该层定义了网络硬件和网络数据之间的互通, 包括: 针脚/电压/集线器/网卡等 ➤ 7,5,4层网络模型的区别与联系:","text":"@toc: OSI七层模型; 七层、五层、四层对比; ➤ 七层模型: 国际标准组织（ISO）定义的网络互联7层框架, 包括: 7应用层: 该层协议包括 Socket, HTTP, HTTPS, FTP, SSH, POP3, // WebSocket属于哪一层? 6表示层: 格式转换, 把数据转换为应用层能兼容的格式 或 适合传输的格式, 比如: 加密/解密, 压缩/解压 5会话层: 维护和管理数据传输过程中两台计算机之间的连接, 该层协议有: SSL/TLS 4传输层: 传输控制, 例如TCP协议(传输控制协议, 主要实现了传输的可靠性, 例如超时重传), 该层把「传输表头」TH加入数据形成「报文」Segment, 传输表头包括了传输协议等 3网络层: 决定数据的路由, 例如IP/ICMP协议, 该层把「网络表头」NH加入数据形成「包」Packet, 网络表头包括: @todo 2链路层: 负责网络寻找和错误侦测, 该层把「数据链表头」DLH加入数据开头, 以及「数据链表尾」DLT加入数据结尾, 形成「信息框」Data Frame, 数据链表头包括, 该层协议包括WiFi, GPRS(通用分组无线服务) 1物理层: 在局部局域网上传送「数据帧」Data Frame, 该层定义了网络硬件和网络数据之间的互通, 包括: 针脚/电压/集线器/网卡等 ➤ 7,5,4层网络模型的区别与联系: 网络设备供应商一般用 5 层网络描述： 路由器是基于 IP 设计的，俗称三层网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址； 而交换机是基于以太网设计的，俗称二层网络设备，交换机的端口不具有 MAC 地址。","categories":[{"name":"22.Network-Protocol","slug":"22-Network-Protocol","permalink":"https://beefyheisenberg.github.io/categories/22-Network-Protocol/"}],"tags":[{"name":"网络协议","slug":"网络协议","permalink":"https://beefyheisenberg.github.io/tags/网络协议/"}]},{"title":"Tcpdump","slug":"22.Network-Protocol/Tcpdump","date":"2024-01-24T01:27:52.487Z","updated":"2024-01-24T01:27:52.487Z","comments":true,"path":"22.Network-Protocol/Tcpdump/","link":"","permalink":"https://beefyheisenberg.github.io/22.Network-Protocol/Tcpdump/","excerpt":"Exampletcpdump -i any port 9542 -w file_name.pcaptcpdump -s0 -i any 'udp and (src port 1719 or 18000) and (src host 9.143.243.8 or 9.143.243.18) and udp[0x10:4]=4444' -w file_name.pcap Tcpdump支持的滚动参数tcpdump [ -AdDefIKlLnNOpqRStuUvxX ] [ -B buffer_size ] [ -c count ][ -C file_size ] [ -G rotate_seconds ] [ -F file ] [ -I interface ] [ -m module ] [ -M secret ] [ -r file ] [ -s snaplen ] [ -T type ] [ -w file ] [ -W filecount ] [ -E spi@ipaddr algo:secret,... ] [ -y datalinktype ] [ -z postrotate-command ] [ -Z user ] [ expression ] -G rotate_seconds: If specified, rotates the dump file specified with the -w option every rotate_seconds seconds. Savefiles will have the name specified by -w which should include a time format as defined by strftime(3). If no time format is specified, each new file will overwrite the previous.If used in conjunction with the -C option, filenames will take the form of &apos;file&lt;count&gt;&apos;. -C file_size: Before writing a raw packet to a savefile, check whether the file is currently larger than file_size and, if so, close the current savefile and open a new one. Savefiles after the first savefile will have the name specified with the -w flag, with a number after it, starting at 1 and continuing upward. The units of file_size are millions of bytes (1,000,000 bytes, not 1,048,576 bytes). -W filecount: Used in conjunction with the -C option, this will limit the number of files created to the specified number, and begin overwriting files from the beginning, thus creating a &apos;rotating&apos; buffer. In addition, it will name the files with enough leading 0s to support the maximum number of files, allowing them to sort correctly.Used in conjunction with the -G option, this will limit the number of rotated dump files that get created, exiting with status 0 when reaching the limit. If used with -C as well, the behavior will result in cyclical files per timeslice. -w file -w /var/tmp/trace-%m-%d-%H-%M-%S-%s will give you %m=month, %d=day of month, %H=hour of day, %M=minute of day, %S=second of day, %s=millisecond of day","text":"Exampletcpdump -i any port 9542 -w file_name.pcaptcpdump -s0 -i any 'udp and (src port 1719 or 18000) and (src host 9.143.243.8 or 9.143.243.18) and udp[0x10:4]=4444' -w file_name.pcap Tcpdump支持的滚动参数tcpdump [ -AdDefIKlLnNOpqRStuUvxX ] [ -B buffer_size ] [ -c count ][ -C file_size ] [ -G rotate_seconds ] [ -F file ] [ -I interface ] [ -m module ] [ -M secret ] [ -r file ] [ -s snaplen ] [ -T type ] [ -w file ] [ -W filecount ] [ -E spi@ipaddr algo:secret,... ] [ -y datalinktype ] [ -z postrotate-command ] [ -Z user ] [ expression ] -G rotate_seconds: If specified, rotates the dump file specified with the -w option every rotate_seconds seconds. Savefiles will have the name specified by -w which should include a time format as defined by strftime(3). If no time format is specified, each new file will overwrite the previous.If used in conjunction with the -C option, filenames will take the form of &apos;file&lt;count&gt;&apos;. -C file_size: Before writing a raw packet to a savefile, check whether the file is currently larger than file_size and, if so, close the current savefile and open a new one. Savefiles after the first savefile will have the name specified with the -w flag, with a number after it, starting at 1 and continuing upward. The units of file_size are millions of bytes (1,000,000 bytes, not 1,048,576 bytes). -W filecount: Used in conjunction with the -C option, this will limit the number of files created to the specified number, and begin overwriting files from the beginning, thus creating a &apos;rotating&apos; buffer. In addition, it will name the files with enough leading 0s to support the maximum number of files, allowing them to sort correctly.Used in conjunction with the -G option, this will limit the number of rotated dump files that get created, exiting with status 0 when reaching the limit. If used with -C as well, the behavior will result in cyclical files per timeslice. -w file -w /var/tmp/trace-%m-%d-%H-%M-%S-%s will give you %m=month, %d=day of month, %H=hour of day, %M=minute of day, %S=second of day, %s=millisecond of day For Example:tcpdump -i en0 -w /var/tmp/trace -W 48 -G 1800 -C 100 This will rotate files (of names trace1, trace2, …) cyclically, with period 48, either every 1800 seconds (=30 minutes) or every 100 MB, whichever comes first. @ref: https://superuser.com/questions/904786/tcpdump-rotate-capture-files-using-g-w-and-c https://linux.die.net/man/8/tcpdump","categories":[{"name":"22.Network-Protocol","slug":"22-Network-Protocol","permalink":"https://beefyheisenberg.github.io/categories/22-Network-Protocol/"}],"tags":[]},{"title":"Linux.06::Sed & Awk & Grep 命令速查","slug":"21.Operating-System/Linux.06.Sed-Awk-Grep","date":"2024-01-24T01:27:52.481Z","updated":"2024-01-24T01:27:52.482Z","comments":true,"path":"21.Operating-System/Linux.06.Sed-Awk-Grep/","link":"","permalink":"https://beefyheisenberg.github.io/21.Operating-System/Linux.06.Sed-Awk-Grep/","excerpt":"sed参数解析 -i : 表示将改变直接写入原文件, sed默认只修改输出到终端上的内容 -f : -f file1 表示将sed 的操作都输出到file1 -n : slient模式, 默认情况下sed所有来自STDIN的数据都会输出到终端,-n只会将”来自sed的操作”输出到终端, 一般和p一起用; -e : 表示使用正则匹配 example 替换全部: sed &quot;s/aaa/bbb/g&quot; -i file 每行开头插入#号: sed &quot;s/^/#/g&quot; -i file 只在3-6行替换: sed &quot;3,6s/aaa/bbb/g&quot; -i file 只替换每行的第1处aaa: sed &quot;s/aaa/bbb/1&quot; -i file 只替换每行的第2处aaa: sed &quot;s/aaa/bbb/2&quot; -i file 替换每行第3-最后一处aaa: sed &quot;s/aaa/bbb/3,g&quot; -i file 正则替换: sed -e &#39;s/^#\\s*\\(.*[0-9].*\\)$/\\1/g&#39; filename 与find联用: find ./ -type f -exec sed -i -e &#39;s/aaa/bbb/g&#39; {} \\;","text":"sed参数解析 -i : 表示将改变直接写入原文件, sed默认只修改输出到终端上的内容 -f : -f file1 表示将sed 的操作都输出到file1 -n : slient模式, 默认情况下sed所有来自STDIN的数据都会输出到终端,-n只会将”来自sed的操作”输出到终端, 一般和p一起用; -e : 表示使用正则匹配 example 替换全部: sed &quot;s/aaa/bbb/g&quot; -i file 每行开头插入#号: sed &quot;s/^/#/g&quot; -i file 只在3-6行替换: sed &quot;3,6s/aaa/bbb/g&quot; -i file 只替换每行的第1处aaa: sed &quot;s/aaa/bbb/1&quot; -i file 只替换每行的第2处aaa: sed &quot;s/aaa/bbb/2&quot; -i file 替换每行第3-最后一处aaa: sed &quot;s/aaa/bbb/3,g&quot; -i file 正则替换: sed -e &#39;s/^#\\s*\\(.*[0-9].*\\)$/\\1/g&#39; filename 与find联用: find ./ -type f -exec sed -i -e &#39;s/aaa/bbb/g&#39; {} \\; awk参数解析 命令格式: awk [options] &#39;script&#39; file_name : awk [options] -f scriptfile file_name cat file_name | awk [options] script [options]选项有: -F : 指定分隔符. 分隔符默认是空格 awk -F: 表示冒号作为分隔; awk -F&quot;[@ /t]&quot; 告诉awk “@符号, 空格和Tab” 都是字段分隔符. -v : 赋值一个用户定义变量, 传递给scripts, 例 -v var=value -f : 从指定文件中读取 awk scripts, 例 -f scripfile awk脚本基本语法 基本用法： awk &#39;script&#39; filename，该脚本 ‘script’ 中内容的格式是 /pattern/ action，其中 pattern 是一个正则表达式，而 action 是当 awk 在该行中找到此模式时应当执行的动作。 例1： awk &#39;/local*/{print $0}&#39; /etc/hosts 例2： 内建变量 NF: 表示目前的记录被分割的字段的数目，NF可以理解为 Number of Field。awk &#39;{print FNR}&#39; data.txt 会打印出字段个数 (默认是任何数量的空格); $NF: 表示的最后一个Field（列）即输出最后一个字段的内容; NR : 已经读出的记录数，即行号，从1开始; $n : 表示目前的记录被分割后, 第n个字段的内容; example 1 提取每行符合正则的字符串awk &#39;match($0, /meeting_code[0-9]+/,a){print a[0]}&#39; test.log // 提取格式如 ‘meeting_code0000’ 的字符串，如果在mac上报错，试试gawk 注: match函数原型 match(string,regexp,array) 每个进程打开的文件数: lsof | awk &#39;{process[$1]++;} END{for(key in process) printf(&quot;%s:%d\\n&quot;, key, process[key])}&#39; 打开TCP连接数量: lsof | awk &#39;{if($8 == &quot;TCP&quot;) opened_tcp++} END{print opened_tcp }&#39; 打开文件按TYPE统计: lsof | awk &#39;{opened_type[$5]++} END{ for(key in opened_type) printf(&quot;%s : %d\\n&quot;, key, opened_type[key])}&#39; example 2 awk多维数组在本质上是一维数组, 因awk在存储上并不支持多维数组, awk提供了逻辑上模拟二维数组的访问方式. 例如, array[2,3] = 1这样的访问是允许的.awk使用一个特殊的字符串SUBSEP (\\034)作为分割字段, 在上面的例子 array[2,3] = 1 中, 关联数组array存储的键值实际上是2\\0343, 2和3分别为下标（2, 3）, \\034为SUBSEP分隔符 类似一维数组的循环访问, 多维数组使用 for ( item in array ) 语法遍历数组. 与一维数组不同的是, 多维数组必须使用split()函数来访问单独的下标分量, 格式： split ( item, subscr, SUBSEP).例如： split (item, array2, SUBSEP); 后, array2[1]为下标“2”, array2[2]为下标“3” # -Fb表示分隔符awk -F '&amp;' 'BEGIN&#123; # 初始化代码块 &#125;&#123; # awk二维数组, 和awk外的数组变量不是一个 # 数组直接使用, 不需初始化 comment[$5, $3]++ &#125; END&#123; printf(\"%d\", length(comment)) # awk内置数组长度 # 循环awk数组 for(ii in comment)&#123; # 这里的ii是key, value是comment[ii] split(ii, strs, SUBSEP) # 对多维数组的key做split操作, 得到的数组strs[1]~strs[n]是数组下标 appid = strs[1] # strs从下标1开始 user = strs[2] printf(\"%d,%d\\n\", strs[1], strs[2], comment[ii]) &gt;&gt; \"'$sqlLoadFile'\" # 类似C的printf &#125; &#125;' $tmpDir/stat-log*.log grep参数解析 用法: grep [参数] [查找字符串] [文件名] 常用参数: -n：显示匹配行及行号. -c：只输出匹配行的计数. -I：不区分大小写(只适用于单字符). -i：不区分大小写. -r：子目录递归查找. -A n：a指after匹配指定行的后n行数据. -B n：b 指before 匹配指定行的前N行数据. -C n：显示匹配行的前后N行, 助记”center”. -w xxx: 全词匹配, 比如 grep -w RUNNING, 参数w保证”RUN”不会被搜出来. example 在指定文件查找字符串: grep &quot;XYZ&quot; /etc/passwd 在指定文件查找多个: grep -e &quot;XYZ&quot; -e &quot;root&quot; /etc/passwd 在指定目录递归查找: grep -r XYZ /etc/ 在指定类型的文件查找字符串: find . -name &#39;*.c&#39; -exec grep -irn &quot;keyword&quot; {} \\; find -name *.c | xargs grep -irwn &quot;keyword&quot; 参考 Sed简明教程 Awk简明教程","categories":[{"name":"21.Operating-System","slug":"21-Operating-System","permalink":"https://beefyheisenberg.github.io/categories/21-Operating-System/"}],"tags":[{"name":"Linux命令行","slug":"Linux命令行","permalink":"https://beefyheisenberg.github.io/tags/Linux命令行/"},{"name":"sed","slug":"sed","permalink":"https://beefyheisenberg.github.io/tags/sed/"},{"name":"awk","slug":"awk","permalink":"https://beefyheisenberg.github.io/tags/awk/"},{"name":"grep","slug":"grep","permalink":"https://beefyheisenberg.github.io/tags/grep/"}]},{"title":"Linux.04::Sysctl命令速查","slug":"21.Operating-System/Linux.04a.Sysctl","date":"2024-01-24T01:27:52.477Z","updated":"2024-01-24T01:27:52.477Z","comments":true,"path":"21.Operating-System/Linux.04a.Sysctl/","link":"","permalink":"https://beefyheisenberg.github.io/21.Operating-System/Linux.04a.Sysctl/","excerpt":"使用Sysctl命令调整内核参数 命令示例 列出所有的参数并查看 sysctl -a | less 获取某个参数值 sysctl kernel.msgmnb 修改参数值 sudo sysctl -w 变量名=变量值 sysctl 变量的设置通常是字符串、数字或者布尔型。 (布尔型用 1 来表示’yes’，用 0 来表示’no’)。 sysctl -w kernel.sysrq=0sysctl -w kernel.core_uses_pid=1sysctl -w net.ipv4.tcp_syncookies=1 sysctl -w设置的参数会在重启后丢失, 永久生效方法：在/etc/sysctl.conf中添加 然后 sysctl -p立刻生效: net.ipv4.icmp_echo_ignore_all=1 常用参数 net.ipv4.ip_local_port_range = 1024 65000 //允许系统打开的端口范围, 操作系统上端口号1024以下是系统保留的，从1024-65535是用户使用的 net.core.netdev_max_backlog = 262144 // 每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目 net.ipv4.tcp_max_tw_buckets = 6000 //timewait 的数量，默认是180000。 net.ipv4.tcp_tw_recycle = 1 // 启用timewait 快速回收 net.ipv4.tcp_tw_reuse = 1 // 开启重用。允许将TIME-WAIT sockets 重新用于新的TCP 连接。 net.ipv4.tcp_syncookies = 1 // 开启SYN Cookies，当出现SYN 等待队列溢出时，启用cookies 来处理。 net.ipv4.tcp_max_orphans = 262144 //系统所能处理不属于任何进程的 socket数量，当我们需要快速建立大量连接时，就需要关注下这个值了. 这个限制仅仅是为了防止简单的DoS 攻击，不能过分依靠它或者人为地减小这个值，更应该增加这个值(如果增加了内存之后)。 net.ipv4.tcp_max_syn_backlog = 262144 // 记录的那些尚未收到客户端确认信息的连接请求的最大值。对于有128M 内存的系统而言，缺省值是1024，小内存的系统则是128。 net.ipv4.tcp_timestamps = 0 //时间戳可以避免序列号的卷绕。一个1Gbps 的链路肯定会遇到以前用过的序列号。时间戳能够让内核接受这种“异常”的数据包。这里需要将其关掉。 net.ipv4.tcp_synack_retries = 1 //为了打开对端的连接，内核需要发送一个SYN 并附带一个回应前面一个SYN 的ACK。也就是所谓三次握手中的第二次握手。这个设置决定了内核放弃连接之前发送SYN+ACK 包的数量。 net.ipv4.tcp_syn_retries = 1 // 在内核放弃建立连接之前发送SYN 包的数量。 net.ipv4.tcp_fin_timeout = 1 //如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2 状态的时间。对端可以出错并永远不关闭连接，甚至意外当机。缺省值是60 秒。2.2 内核的通常值是180 秒，3你可以按这个设置，但要记住的是，即使你的机器是一个轻载的WEB 服务器，也有因为大量的死套接字而内存溢出的风险，FIN- WAIT-2 的危险性比FIN-WAIT-1 要小，因为它最多只能吃掉1.5K 内存，但是它们的生存期长些。 net.ipv4.tcp_keepalive_time = 30 //当keepalive 起用的时候，TCP 发送keepalive 消息的频度。缺省是2 小时。 net.ipv4.tcp_mem = 786432 2097152 3145728 // tcp的内存大小，其单位是页, 当超过第二个值时，TCP进入 pressure模式，此时TCP尝试稳定其内存的使用，当小于第一个值时，就退出pressure模式。当内存占用超过第三个值时，TCP就拒绝分配 socket了 net.ipv4.tcp_rmem = 4096 4096 16777216 # 读缓冲的大小, 三个分别是最小/默认/最大值 net.ipv4.tcp_wmem = 4096 4096 16777216","text":"使用Sysctl命令调整内核参数 命令示例 列出所有的参数并查看 sysctl -a | less 获取某个参数值 sysctl kernel.msgmnb 修改参数值 sudo sysctl -w 变量名=变量值 sysctl 变量的设置通常是字符串、数字或者布尔型。 (布尔型用 1 来表示’yes’，用 0 来表示’no’)。 sysctl -w kernel.sysrq=0sysctl -w kernel.core_uses_pid=1sysctl -w net.ipv4.tcp_syncookies=1 sysctl -w设置的参数会在重启后丢失, 永久生效方法：在/etc/sysctl.conf中添加 然后 sysctl -p立刻生效: net.ipv4.icmp_echo_ignore_all=1 常用参数 net.ipv4.ip_local_port_range = 1024 65000 //允许系统打开的端口范围, 操作系统上端口号1024以下是系统保留的，从1024-65535是用户使用的 net.core.netdev_max_backlog = 262144 // 每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目 net.ipv4.tcp_max_tw_buckets = 6000 //timewait 的数量，默认是180000。 net.ipv4.tcp_tw_recycle = 1 // 启用timewait 快速回收 net.ipv4.tcp_tw_reuse = 1 // 开启重用。允许将TIME-WAIT sockets 重新用于新的TCP 连接。 net.ipv4.tcp_syncookies = 1 // 开启SYN Cookies，当出现SYN 等待队列溢出时，启用cookies 来处理。 net.ipv4.tcp_max_orphans = 262144 //系统所能处理不属于任何进程的 socket数量，当我们需要快速建立大量连接时，就需要关注下这个值了. 这个限制仅仅是为了防止简单的DoS 攻击，不能过分依靠它或者人为地减小这个值，更应该增加这个值(如果增加了内存之后)。 net.ipv4.tcp_max_syn_backlog = 262144 // 记录的那些尚未收到客户端确认信息的连接请求的最大值。对于有128M 内存的系统而言，缺省值是1024，小内存的系统则是128。 net.ipv4.tcp_timestamps = 0 //时间戳可以避免序列号的卷绕。一个1Gbps 的链路肯定会遇到以前用过的序列号。时间戳能够让内核接受这种“异常”的数据包。这里需要将其关掉。 net.ipv4.tcp_synack_retries = 1 //为了打开对端的连接，内核需要发送一个SYN 并附带一个回应前面一个SYN 的ACK。也就是所谓三次握手中的第二次握手。这个设置决定了内核放弃连接之前发送SYN+ACK 包的数量。 net.ipv4.tcp_syn_retries = 1 // 在内核放弃建立连接之前发送SYN 包的数量。 net.ipv4.tcp_fin_timeout = 1 //如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2 状态的时间。对端可以出错并永远不关闭连接，甚至意外当机。缺省值是60 秒。2.2 内核的通常值是180 秒，3你可以按这个设置，但要记住的是，即使你的机器是一个轻载的WEB 服务器，也有因为大量的死套接字而内存溢出的风险，FIN- WAIT-2 的危险性比FIN-WAIT-1 要小，因为它最多只能吃掉1.5K 内存，但是它们的生存期长些。 net.ipv4.tcp_keepalive_time = 30 //当keepalive 起用的时候，TCP 发送keepalive 消息的频度。缺省是2 小时。 net.ipv4.tcp_mem = 786432 2097152 3145728 // tcp的内存大小，其单位是页, 当超过第二个值时，TCP进入 pressure模式，此时TCP尝试稳定其内存的使用，当小于第一个值时，就退出pressure模式。当内存占用超过第三个值时，TCP就拒绝分配 socket了 net.ipv4.tcp_rmem = 4096 4096 16777216 # 读缓冲的大小, 三个分别是最小/默认/最大值 net.ipv4.tcp_wmem = 4096 4096 16777216","categories":[{"name":"21.Operating-System","slug":"21-Operating-System","permalink":"https://beefyheisenberg.github.io/categories/21-Operating-System/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://beefyheisenberg.github.io/tags/Linux/"},{"name":"Linux命令行","slug":"Linux命令行","permalink":"https://beefyheisenberg.github.io/tags/Linux命令行/"},{"name":"sysctl","slug":"sysctl","permalink":"https://beefyheisenberg.github.io/tags/sysctl/"}]},{"title":"Linux.05::系统配置","slug":"21.Operating-System/Linux.04.系统配置","date":"2024-01-24T01:27:52.472Z","updated":"2024-01-24T01:27:52.473Z","comments":true,"path":"21.Operating-System/Linux.04.系统配置/","link":"","permalink":"https://beefyheisenberg.github.io/21.Operating-System/Linux.04.系统配置/","excerpt":"profile相关 bashrc是在系统启动后就会自动运行。 profile是在用户登录后才会运行。 进行设置后，可运用source bashrc命令更新bashrc，也可运用source profile命令更新profile。 /etc/profile: 中设定的变量(全局)的可以作用于任何用户 ~/.bashrc: 等中设定的变量(局部)只能继承/etc/profile中的变量 ~/.bash_profile: 每个用户都可使用该文件输入专用于自己使用的shell信息，当用户登录时，该文件仅仅执行一次!默认情况下,他设置一些环境变量,执行用户的.bashrc文件。 init系统init进程是 Linux系统内核初始化最后一步启动的进程，也是系统的第一个进程，pid=1。","text":"profile相关 bashrc是在系统启动后就会自动运行。 profile是在用户登录后才会运行。 进行设置后，可运用source bashrc命令更新bashrc，也可运用source profile命令更新profile。 /etc/profile: 中设定的变量(全局)的可以作用于任何用户 ~/.bashrc: 等中设定的变量(局部)只能继承/etc/profile中的变量 ~/.bash_profile: 每个用户都可使用该文件输入专用于自己使用的shell信息，当用户登录时，该文件仅仅执行一次!默认情况下,他设置一些环境变量,执行用户的.bashrc文件。 init系统init进程是 Linux系统内核初始化最后一步启动的进程，也是系统的第一个进程，pid=1。 运行级别（Runlevel）指的是Unix或者Linux等类Unix操作系统下不同的运行模式。运行级别通常分为7等，分别是从0到6，但如果必要的话也可以更多。例如在大多数Linux操作系统下一共有如下7个典型的运行级别： 0 停机，关机1 单用户，无网络连接，不运行守护进程，不允许非超级用户登录2 多用户，无网络连接，不运行守护进程3 多用户，正常启动系统4 用户自定义5 多用户，带图形界面6 重启 除了模式 0,1,6外, 每种 Unix 和 Unix-like 系统对运行模式的定义不太一样。通常在 /etc/inittab 文件中定义了各种运行模式的工作范围。当前绝大多数Linux发行版已经基于新的systemd，systemd一般不再使用/etc/inittab文件。 init,sysvinit 和 systemd大多数 Linux 发行版的 init 系统是和 System V 相兼容的，被称为 sysvinit。这是人们最熟悉的 init 系统。Ubuntu 采用 upstart 替代了传统的 sysvinit，RHEL 采用 systemd替代 sysvinit。 关于 System V，参考 [[APUE.00.从Unix到Linux]] sysvinit 本节参考: 浅析Linux初始化init系统, 第1部分: sysvinit @ref sysvinit 运行顺序 读取 /etc/inittab, 获取配置(系统的 runlevel 等) /etc/rc.d/rc.sysinit /etc/rc.d/rc 和 /etc/rc.d/rcX.d/ (X 代表运行级别 0-6) /etc/rc.d/rc.local sysvinit 管理功能sysvinit 软件包包含了一系列的控制启动、运行和关闭所有其他程序的工具： init: 这个就是 sysvinit 本身的 init 进程实体，以 pid1 身份运行，是所有用户进程的父进程。最主要的作用是在启动过程中使用/etc/inittab 文件创建进程。 halt: 停止系统 poweroff: 等于 shutdown -h –p reboot: 等于 shutdown –r killall: 向除自己的会话(session)进程之外的其它进程发出信号，所以不能杀死当前使用的 shell。 last: 回溯/var/log/wtmp 文件(或者-f 选项指定的文件)，显示自从这个文件建立以来，所有用户的登录情况。 chkconfig: RHEL 在 sysvinit 的基础上开发的命令行工具 service: 同上 使用 sysvinit 启动一个服务: $ /etc/init.d/apache2 start# 或者$ service apache2 start 这种方法有两个缺点。 一是启动时间长。init进程是串行启动，只有前一个进程启动完，才会启动下一个进程。 二是启动脚本复杂。init进程只是执行启动脚本，不管其他事情。脚本需要自己处理各种情况，这往往使得脚本变得很长。 Systemd 就是为了解决这些问题而诞生的。它的设计目标是为系统的启动和管理提供一套完整的解决方案。 systemdSystemd 并不是一个命令，而是一组命令，涉及到系统管理的方方面面。 systemctl是 Systemd 的主命令，用于管理系统。 systemd-analyze命令用于查看启动耗时。 … @ref: Systemd 入门教程：命令篇 - 阮一峰的网络日志 浅析Linux初始化init系统, 第3部分: Systemd systemctl 命令systemctl是 Systemd 的主命令，用于管理系统。//区别 sysctl 命令，用于修改 Kernel参数 # 重启系统$ sudo systemctl reboot# 关闭系统，切断电源$ sudo systemctl poweroff# CPU停止工作$ sudo systemctl halt# 暂停系统$ sudo systemctl suspend# 让系统进入冬眠状态$ sudo systemctl hibernate# 让系统进入交互式休眠状态$ sudo systemctl hybrid-sleep# 启动进入救援状态（单用户状态）$ sudo systemctl rescue Systemd 可以管理所有系统资源。不同的资源统称为 Unit（单位）。相关命令： # 列出正在运行的 Unit$ systemctl list-units# 列出所有Unit，包括没有找到配置文件的或者启动失败的$ systemctl list-units --all 启动、重启、停止Unit： # 立即启动一个服务$ sudo systemctl start example.service# 立即停止一个服务$ sudo systemctl stop example.service# 重启一个服务$ sudo systemctl restart example.service# 杀死一个服务的所有子进程$ sudo systemctl kill example.service Example: How to 新加一个 Service（Systemd Unit）: vim /etc/systemd/system/ngx-example.service Systemd 默认从目录/etc/systemd/system/读取配置文件。但是，里面存放的大部分文件都是符号链接，指向目录/usr/lib/systemd/system/，真正的配置文件存放在那个目录。systemctl enable 命令用于在上面两个目录之间，建立符号链接关系。 Description=proxy-nginxAfter=network.target[Service]Type=forkingPIDFile=/data0/www/logs/nginx.pid# 启动进程时执行的命令ExecStart=/usr/local/sbin/proxy-nginx -c /usr/local/etc/proxy-nginx.conf# 重启服务时执行的命令ExecReload=/usr/local/sbin/proxy-nginx -c /usr/local/etc/proxy-nginx.conf -s reload# 停止服务时执行的命令ExecStop=/usr/local/sbin/proxy-nginx -c /usr/local/etc/proxy-nginx.conf -s stopPrivateTmp=True[Install]WantedBy=multi-user.target journald 日志系统 本节参考: centos7的日志系统：journald, rsyslog, logrotate systemd 之 journalctl Systemd 使用 journald 做日志服务，使用 rsyslog 来持久化日志，使用 logrotate 来轮转日志文件。Systemd日志收集流程: systemd --&gt; systemd-journald --&gt; ram DB(/run/log/journal) --&gt; rsyslog -&gt; /var/log/messages;对比 init日志收集: service daemon ---&gt; rsyslog ---&gt; /var/log journalctljournald用二进制格式保存所有日志信息，用户使用 journalctl 命令来查看日志信息。配置文件位置: cat /etc/systemd/journald.conf 使用journalctl命令查看日志: journalctl: 显示所有的日志信息，notice或warning以粗体显示，红色显示error级别以上的信息 journalctl –dmesg: 查看 dmesg 信息。 journalctl -k: 查看 kernel 日志。 journalctl -f: 很像tailf命令 journalctl –since=yesterday: 指定时间段 journalctl -u docker.service: 指定服务，查看docker服务的 journal 日志。查看所有service列表使用命令 systemctl list-units journalctl _PID=8088: 查看指定pid的 journalctl _UID=33: 查看指定用户的 journalctl /usr/bin/bash: 查看某个路径的脚本的日志 journalctl –verify: 检查日志文件的一致性 例如，docker daemon会配置为将所有容器的日志为存储到 journald。/usr/bin/docker-current daemon --exec-opt native.cgroupdriver=systemd --selinux-enabled --log-driver=journald所以，运行中 docker的日志，例如 k8s的 apiserver都会打到 journald日志里去（最终输出到 /var/log/messages） rsyslogrsyslog用来固化journald日志。rsyslog读取 ram DB(/run/log/journal)的数据，并根据优先级排列日志信息，将它们写入到 /var/log目录中永久保存。 默认 journald配置#ForwardToSyslog=no，所以并未将日志转发给syslog。syslog自己去读取的 journald的日志文件(类似journalctl)。 logrotatersyslog的日志存储于/var/log下，显然日志文件不能无限变大，否则磁盘空间会被耗尽。RHEL7使用logrotate来做日志文件轮转。配置文件位置: cat /etc/cron.daily/logrotate 用户组几个常见的用户组: adm/daemon/bin : root:超级用户, 就是管理员, 拥有所有权限 bin:历史遗留用户 daemon:守护进程, 非特权的, 需要对一些以磁盘文件有写权限的daemon以daemon.daemon(portmap,atd,etc)运行；不需要占有任何文件的daemon 以nobody.nogroup运行；比较复杂的, 涉及安全问题的daemon以特定的用户运行. daemon用户也方便本地安装的daemon运行. adm:adm组执行系统监控任务, 组成员可以读取/var/log下的多数文件, 可以使用xconsole. 历史上/var/log来自于/usr/adm, 后来叫/var/adm, 这也是组名称的由来. apache/_www: 用root启动httpd服务, apache的子进程还是用apache(或者_www用户)运行的, 可以通过修改/etc/httpd/conf/httpd.conf指定apache运行的用户组. 用户组常用命令 usermod -a -G daemon XYZ 将用户XYZ加入一个组 id , whoami : who : useradd, userdel 权限相关 /etc/sudoers /etc/hosts.allow: 限制SSH的客户端IP, /etc/hosts.allow 的设定优先于 /etc/hosts.deny /etc/hosts.deny: 限制SSH的客户端IP 文件权限 chmod 400 ~/.ssh/authorized_keys 网络相关 /etc/resolv.conf: 这个文件是用于配置DNS服务器的, 扩展阅读: Ubuntu使用dnsmasq作本地DNS缓存 nameserver 8.8.8.8 /etc/hosts: 设置主机名和IP地址绑定 /etc/hostname: 主机名配置 /etc/sysconfig/network: 主机名和网关NETWORK=yes #网络是否被配置RORWARD_IPV4=yes #是否开启IP转发功能HOSTNAME= localhost.localdomain #表示服务器的主机名GAREWAY=192.168.0.1 #表示网络网关的IP地址GATEWAYDEV=eth0 #网关的设备名，即选择使用哪个网卡 crontab* * * * * * cmd, 分别表示每分/时/每月第几日/月/周几(0~6) 每5分钟: */5 * * * * 每小时: 0 * * * * 每天早上6点10分 10 6 * * * 晚上11点到早上8点之间每两个小时, 和早上8点: 0 23-7/2, 8 * * * 每个用户的crontab文件在 /var/spool/cron/ 终端Terminal Ctrl+r搜索, 输入, 按Ctrl+r继续搜索 Ctrl+a / Ctrl+e : 移动光标开头/末尾m tty/pst/pty 参考 linux - Difference between pts and tty - Unix &amp; Linux Stack Exchange 性能 &amp; 并发相关@link: [[../31.Backend/SystemDesign-01-C100K]]","categories":[{"name":"21.Operating-System","slug":"21-Operating-System","permalink":"https://beefyheisenberg.github.io/categories/21-Operating-System/"}],"tags":[]},{"title":"Linux.03::性能分析命令行 | Performance","slug":"21.Operating-System/Linux.03.命令行-Performance","date":"2024-01-24T01:27:52.468Z","updated":"2024-01-24T01:27:52.469Z","comments":true,"path":"21.Operating-System/Linux.03.命令行-Performance/","link":"","permalink":"https://beefyheisenberg.github.io/21.Operating-System/Linux.03.命令行-Performance/","excerpt":"@tldr cpu: uptime 查看load值, 不高于core数, sar -q也可以查看load值 vmstat: 关注r(同load), 和b(等待资源的进程数), 以及cpu占用(用户进程和内核进程)时间百分比: us%不超过50%, us% + sy%不超过80% sar也可以查看us% sy%占用CPU时间百分比 内存: free: 可用内存小于20%需要关注, sar -r类似 vmstat的si和so: 一般不应该大于0, sar -W也可以查看交换区 I/O: vmstat: 需关注wa(IO等待占用CPU百分比): 大于30%时需关注, bi/bo也需要关注(阈值?) iowait: sar也可以查看iowait% 网络: netstat -antp : 查看所有tcp连接 iperf: 吞吐量(Throughput) , 大约为网卡最大速率的一半 基础性能参数load","text":"@tldr cpu: uptime 查看load值, 不高于core数, sar -q也可以查看load值 vmstat: 关注r(同load), 和b(等待资源的进程数), 以及cpu占用(用户进程和内核进程)时间百分比: us%不超过50%, us% + sy%不超过80% sar也可以查看us% sy%占用CPU时间百分比 内存: free: 可用内存小于20%需要关注, sar -r类似 vmstat的si和so: 一般不应该大于0, sar -W也可以查看交换区 I/O: vmstat: 需关注wa(IO等待占用CPU百分比): 大于30%时需关注, bi/bo也需要关注(阈值?) iowait: sar也可以查看iowait% 网络: netstat -antp : 查看所有tcp连接 iperf: 吞吐量(Throughput) , 大约为网卡最大速率的一半 基础性能参数load如果CPU每分钟最多处理100个进程： 那么系统负荷0.2，意味着CPU在这1分钟里只处理20个进程； 系统负荷1.0，意味着CPU在这1分钟里正好处理100个进程； 系统负荷1.7，意味着除了CPU正在处理的100个进程以外，还有70个进程正排队等着CPU处理。 为了电脑顺畅运行，系统负荷最好不要超过1.0，这样就没有进程需要等待了，所有进程都能第一时间得到处理。很显然，1.0是一个关键值，超过这个值，系统就不在最佳状态了，你要动手干预了。 @ref: http://www.ruanyifeng.com/blog/2011/07/linux_load_average_explained.html uptime uptime返回1/5/15分钟内的load值(进程队列的长度), 对于单核cpu, load值在1.0以下可以接受, 对于多核CPU, load值要除以”核心数” 多核CPU的话, 满负荷状态的数字为 “1.00 * CPU核数”, 这里的CPU核数是processor的数量, 某台服务器举例: 2个物理CPU, 每个物理CPU包括8个Core, 每个Core包括4个Processor(HT超线程), 以上参考Understanding Linux CPU Load - when should you be worried? @ref 1/5/15分钟的load值, 应该参考哪一个? 如下: load值走高也不一定就是cpu资源紧张导致的, 还需要结合vmstat, iostat工具进行确认和判断是cpu不足还是磁盘IO问题又或者是内存不足导致. cat /proc/cpuinfo一个物理封装的CPU（通过physical id区分判断）, 可以有多个”核心”（通过core id区分判断）, 每个核可以有多个”逻辑cpu”（通过processor区分判断） 物理Cpu数: cat /proc/cpuinfo | grep &quot;physical id&quot; | sort -u |wc -l 输出2 核心数: cat /proc/cpuinfo | grep &quot;core id&quot; | sort -u |wc -l 输出8 逻辑Cpu数: cat /proc/cpuinfo | grep &quot;processor&quot; | sort -u | wc -l 输出32 ps ps -ef : e参数列出所有(用户)的进程, f列出PPID; ps aux : 能显示出更多的线程信息, 比如”VSZ”,”RSS”,”TTY”,”STAT”. ps -l : 列出进程优先级(PRI), Nice值(NI),内存占用(SZ) ps -T -p &lt;pid&gt; : 查看进程的所有线程 ps auxUSER PID %CPU %MEM VSZ RSS TT STAT STARTED TIME COMMANDroot 47 0.0 0.0 2502056 1700 ?? Ss 一09上午 0:11.65 /usr/libexec/kextdroot 45 0.0 0.2 2503976 6576 ?? Ss 一09上午 0:29.45 /usr/libexec/UserEventAgent (System)root 44 0.0 0.0 2472460 1204 ?? Ss 一09上午 0:32.91 /usr/sbin/syslogdbeefymiracle 424 98.7 0.1 2507128 4764 ?? R 一09上午 1762:56.80 /System/Library/PrivateFrameworks/ParsecUI.framework/Versions/A/Support/SpotlightNetHelper.app/Contents/MacOS/SpotlightNetHelper VSZ：KB, virtual memory size, Device mappings are currently excluded; RSS：KB, resident set size, 一般作为实际占用内存大小,包括程序二进制映像(binary image), Heap/Stack实际使用(系统为进程分配的堆和栈, 不一定完全用掉), 共享区(shared Library, 也即Memory Mapping)实际使用的空间; 区分VSZ,RSS,SZ http://stackoverflow.com/questions/7880784/what-is-rss-and-vsz-in-linux-memory-management STAT：R/S/D/T/Z/X @ref: http://askubuntu.com/questions/360252/what-do-the-stat-column-values-in-ps-mean 进程状态 R S D T X Z:R: RunningS: Interruptible Sleep, 可中断的睡眠D: Uninterruptible Sleep. 不可中断的睡眠, 比如等待磁盘IO, 这种进程不接受kill,kill -9的信号T: Stoped, 按下Ctrl+Z的状态 ps -elUID PID PPID F CPU PRI NI SZ RSS WCHAN S ADDR TTY TIME CMD 0 1 0 4004 0 37 0 2478772 7372 - Ss 0 ?? 3:01.68 /sbin/launchd 0 44 1 4004 0 4 0 2474032 1228 - Ss 0 ?? 0:32.87 /usr/sbin/syslogd501 424 1 4004 0 4 0 2506604 4952 - R 0 ?? 1757:31.24 /System/Library/PrivateFrameworks/ParsecUI.framework/Versions/A/Support/SpotlightNetHelper.app/Contents/MacOS/SpotlightNetHelper SZ：size in physical pages of the core image of the process. This includes text, data, and stack space. Device mappings are currently excluded PRI：PRI表示线程优先级(数值越小越先执行), 优先级的范围是[0, MAX_PRIO-1], MAX_PRIO 的值一般为140. NI 修正优先级： NI=Nice, 值表示对优先级PRI的修正, 范围从-20~19, Nice越小表示优先级越高. 以指定Nice启动任务: nice -n -5 /usr/bin/mysqld &amp;, 注意这里-5并不是表示负数, 而是正数5, 如果要以高优先级启动某进程(负的Nice值), 则应该为nice -n --5 top. 使用nohup: nohup -n 10 COMMANDS 改变已存在进程的优先级: renice -5 -p 1203注意这里的”-5”表示负数. pstree pstree -apu 显示进程树 -a 显示进程的命令行 -p 显示PID -u 显示UID, 如果子进程和父进程的UID不同, 比如Nginx启动worker线程用nobody top 查看指定进程: top -d 1 -p 1021, 解释: -d 刷新间隔, -p 进程号, 每列”VIRT”, “RES”, “SHR”的表示含义 VIRT: 进程“需要的”虚拟内存大小, 包括库/代码/数据, VIRT = SWP + RES RES: 常驻内存(Resident memory), 包括共享内存, 进程实际占用内存 = RES - SHR SHR: 共享内存(Shared memory), 比如动态库 某个进程占用的CPU和内存也可以用ps -aux查看, 其中RSS(Resident Set Size)表示实际RAM使用, VSZ(Virtual Memory Size)包括程序占用的SWAP空间, 和使用的shared libraries所占用的空间. 或者, 直接查看/proc/PID/status文件也可以得知进程占用RAM的情况. 查看线程: top -H, 查看指定进程的线程: top -H -p &lt;pid&gt; free What is the difference between Buffers and Cached columns in /proc/meminfo output? Buffer 是准备写入块设备的数据, 存储了文件的目录/权限等metadata; Cache 频繁访问的文件都会被cache, 里面只有文件内容数据; vmstat[@tc_157_46 ~]# vmstat 1procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------ r b swpd free buff cache si so bi bo in cs us sy id wa st 3 23 2840 3118492 110100 21213972 0 0 19 201 0 0 1 1 97 1 0 vmstat每列解释: procs列 r 等待cpu时间片的进程数, 如果长期大于1, 说明cpu不足, 需要增加cpu. b (在等待资源的进程数, 比如正在等待I/O, 或者内存交换等). memory列 swpd 虚拟内存大小(交换区). 如果swpd的值不为0, 比如超过了100m, 只要si, so的值长期为0, 系统性能还是正常 free 空闲内存大小 buff 做为buffer的内存大小, 一般对块设备的读写才需要缓冲. cache: 做为page cache的内存大小, 一般做为文件系统的cache, 如果cache较大, 说明用到cache的文件较多, 如果此时IO中bi比较小, 说明文件系统效率比较好. swap列 si 每秒由内存进入内存交换区数量. so 每秒由内存交换区进入内存数量. io列 bi 每秒从块设备读取数据的Blocks, 一个Block =1024byte bo 每秒块设备写入数据的总量 // 这里我们设置的bi+bo参考值为1000, 如果超过1000(1MB), 而且wa值较大应该考虑均衡磁盘负载, 可以结合iostat输出来分析. system列 in 每秒设备中断数. cs 每秒产生的上下文切换次数, 如当cs比磁盘I/O和网络信息包速率高得多, 都应进行进一步调查. cpu列 us 用户进程所占时间的百分比. 如果长期大于50%, 需要考虑优化用户的程序, 比如加密解密等运算. sy 系统进程所占时间的百分比. 这里us+sy的参考值为80%, 如果us+sy大于80%说明可能存在CPU不足. wa IO等待所占用的CPU时间百分比. 这里wa的参考值为30%, 如果wa超过30%, 说明IO等待严重, 这可能是磁盘大量随机访问造成的, 也可能磁盘或者磁盘访问控制器的带宽瓶颈造成的(主要是块操作). id 空闲状态的CPU时间百分比 iostat命令格式: iostat [option] [间隔秒数] [统计次数] , 比如iostat -x 1 10表示1秒打印一次, 共10次 [@tc_157_46 ~]# iostat -x 1 1Linux 2.6.18-274.el5 (tc_157_46) 07/26/2016avg-cpu: %user %nice %system %iowait %steal %idle 1.18 0.00 1.01 1.06 0.00 96.75Device: rrqm/s wrqm/s r/s w/s rsec/s wsec/s avgrq-sz avgqu-sz await svctm %utilsda 1.34 747.37 4.12 55.96 600.54 6426.98 116.95 0.03 0.49 0.38 2.25sda1 0.00 1.56 0.01 0.66 0.25 17.76 26.94 0.03 38.49 11.73 0.78sda2 0.00 0.01 0.00 0.00 0.02 0.04 106.87 0.00 88.03 7.93 0.00sda3 0.01 1.31 0.04 1.94 1.34 26.02 13.83 0.02 11.81 8.91 1.76sda4 0.00 0.00 0.00 0.00 0.00 0.00 7.40 0.00 110.47 110.47 0.00sda5 0.01 0.36 0.02 0.25 0.59 4.84 20.14 0.01 41.69 17.49 0.47sda6 1.32 744.13 4.05 53.12 598.33 6378.33 122.03 0.03 0.52 0.18 1.00 %util: IO操作占用CPU时间的百分比: 如果%util长期接近100%, 说明产生的I/O请求太多, I/O系统已经满负荷, 该磁盘可能存在瓶颈. Idle如果长期大于70% IO压力就比较大了,这时一般读取速度有较多的wait. sar查看系统的不同时间段的状况, CPU, load, 页面交换 CPU sar 或sar -u: 查看CPU占用状况 sar -q 查看任务队列, 同load 内存 sar -r 查看内存使用, 同free sar -W 查看Swap区的数据交换状况, 怀疑Swap频繁导致系统变慢可以使用 IO sar -b sar -d 1 5: 一秒每次, 共5次, 显示实时的信息 网卡 sar -n DEV 1 5: 一秒每次, 共5次, 显示实时的信息 netstat查看TCP的并发数/TCP连接的状态, 以一个Nginx服务器为例: [@zw_85_63 ~]# netstat -n | awk &apos;/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;&apos;TIME_WAIT 37968SYN_SENT 1FIN_WAIT1 5FIN_WAIT2 4ESTABLISHED 2725SYN_RECV 18LAST_ACK 4 → Linux.02.网络命令 sysctl优化内核参数获取当前内核参数的设定值: sysctl -a | grep vm sysctl -a | grep net.ipv4 使用 sysctl 调整内核参数, 例: sysctl -w net.ipv4.tcp_syncookies=0, 更多参考→ Linux.04a.Sysctl @ref 并发相关的内核参数调整参考 : 后端架构-并发(C10K/C100K) | 扔掉笔记 附：Linux Performance Tools（图） 来源: https://colobu.com/2014/09/18/Linux-Performance-Analysis-and-Tools/ 附：线上服务器的数据平均值~峰值: Nginx &amp; Memcache: load少于0.1, iowait少于0.1%, User:System时间大约10%:5%(峰值), 每秒上下文切换(用vmstat查看cs)20-50K, 打开TCP连接4000, 带宽200Mbps （千兆网卡） Redis: load少于0.1, iowait少于0.1%, User:System时间不到0.1%(峰值), 每秒上下文切换2-4K+, 打开TCP连接数600, 带宽2.0Mbps Resin: load少于0.2, iowait少于0.2%, User:System时间大约15%:2%(峰值), 每秒上下文切换30~60K, 打开TCP连接数1500, 带宽40~80Mbps, Hadoop: load大约0.5~1.5, iowait时间2%-20%, 峰值iowait能到35% ( 一般大于30%需要排查 ) User:System时间大约15%:1%, 每秒上下文切换2-7K, 打开TCP连接数, 带宽20-70Mbps Flume: load少于0.1, iowait少于0.1%, User:System时间大约5%:1%, 每秒上下文切换30-60K, 打开TCP连接数, 带宽5-25Mbps 注: 上面Hadoop机器的iowait有问题, 数据选自一台硬盘有问题的机器","categories":[{"name":"21.Operating-System","slug":"21-Operating-System","permalink":"https://beefyheisenberg.github.io/categories/21-Operating-System/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://beefyheisenberg.github.io/tags/Linux/"},{"name":"Linux命令行","slug":"Linux命令行","permalink":"https://beefyheisenberg.github.io/tags/Linux命令行/"},{"name":"后端技术","slug":"后端技术","permalink":"https://beefyheisenberg.github.io/tags/后端技术/"},{"name":"系统性能分析","slug":"系统性能分析","permalink":"https://beefyheisenberg.github.io/tags/系统性能分析/"}]},{"title":"Linux.02::网络命令行","slug":"21.Operating-System/Linux.02.网络命令","date":"2024-01-24T01:27:52.463Z","updated":"2024-01-24T01:27:52.463Z","comments":true,"path":"21.Operating-System/Linux.02.网络命令/","link":"","permalink":"https://beefyheisenberg.github.io/21.Operating-System/Linux.02.网络命令/","excerpt":"pingping是通过发送ICMP报文(回显请求), 并等待回显请求的应答, 目标主机的防火墙可能对ICMP报文做了限制, 所以ping不通不代表无法ssh. ifconfig 启动关闭指定网卡 ifconfig eth0 upifconfig eth0 down 配置IP地址 ifconfig eth0 192.168.2.10 netmask 255.255.255.0 broadcast 192.168.2.255 netstat","text":"pingping是通过发送ICMP报文(回显请求), 并等待回显请求的应答, 目标主机的防火墙可能对ICMP报文做了限制, 所以ping不通不代表无法ssh. ifconfig 启动关闭指定网卡 ifconfig eth0 upifconfig eth0 down 配置IP地址 ifconfig eth0 192.168.2.10 netmask 255.255.255.0 broadcast 192.168.2.255 netstat显示建立的网络连接, 分为三种: tcp/udp/unix(进程通讯) netstat -au : 显示所有udp连接 netstat -at : 显示所有tcp连接 netstat -nlt : -n 显示ip而非域名 -l 显示所有listen状态的连接 -p 显示出连接对应的进程, 需要root权限才能看到 netstat -r : 显示路由表/网关, 同 route返回的 nslookup, dignslookup, dig 都是DNS查询命令: nslookup: 用于对DNS正向解析 &amp; 返向解析; nslookup a.xxx.com 使用默认dns查询网址的dns记录 nslookup a.xxx.com 8.8.8.8 使用指定dns服务器查询dns记录 dig: 是一个用于询问DNS 域名服务器的灵活的工具。它执行DNS 查询，显示从已查询名称服务器返回的应答。 dig: 显示13个根域服务器 dig www.baidu.com: 使用默认dns查询网址的dns记录 dig @8.8.8.8 www.yahoo.com: 使用指定dns服务器查询dns记录 route 命令格式 route add 目标网段 gw 网关地址 dev 设备 增加默认网关 route add default gw 192.168.0.254 增加网关: route add -net 192.168.1.0 netmask 255.255.255.128 gw 192.168.1.129 dev eth0 删除网关: route del -net 192.168.1.0 netmask 255.255.255.128 dev eth0 查看内核路由表: route, 返回如下: Kernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.6.0 * 255.255.255.0 U 0 0 0 eth0link-local * 255.255.0.0 U 1002 0 0 eth0default 192.168.6.253 0.0.0.0 UG 0 0 0 eth0 Destination : 目标网段或者主机，Destination 为 default（0.0.0.0）时，表示这个是默认网关，所有数据都发到这个网关 Gateway : 网关地址。如果是*表示目标是本主机所属的网络不需要路由 Genmask : 网络掩码 Flags : 标记。一些可能的标记如下： U — 路由是活动的 H — 目标是一个主机 G — 路由指向网关 例如，在下面的示例中，本地主机将发送到网络192.19.12的数据包转发到IP地址为192.168.1.1的路由器。 Destination Gateway Genmask Flags Metric Ref Use Iface----------- ------- ------- ----- ----- --- --- -----192.19.12 192.168.1.1 255.255.255.0 UN 0 0 0 eth0 例如，在下面的示例中，默认路由是IP地址为192.168.1.1的路由器。 Destination Gateway Genmask Flags Metric Ref Use Iface----------- ------- ------- ----- ------ --- --- -----default 192.168.1.1 0.0.0.0 UG 0 0 0 eth0 traceroute 当ping不到或者丢包严重时, 使用traceroute可以看到从当前计算机到目标主机每一跳的耗时情况, 在哪一个节点丢包等细节 例子: traceroute -I a.com : 使用ICMP ECHO traceroute -T a.com : 使用TCP SYN traceroute -p 8080 a.com : 查询到主机指定端口的路由 通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的。 linux系统中，我们称之为 traceroute,在MS Windows中为 tracert。 traceroute的工作机制主要是利用使用ICMP报文和和IP首部中的TTL（Time to Live?）字段来实现的。在网络数据包的传输过程中，每个处理处理数据包的路由器都要讲数据包的TTL值减1或者减去数据报在路由器中停留的秒数，由于大多数的路由器转发数据报的延时都小于1秒钟，因此TTL最终成为一个跳站的计数器，所经过的每个路由器都将其值减1。TTL字段的目的是防止数据报在网络中无休止的流动。当路由器收到一份IP数据报，如果TTL字段是0或者1，则路由器不转发该数据报（接收到这种数据报的目的主机可以将它交给应用程序，这是因为不需要转发该数据报。但是，在通常情况下系统不应该接收TTL字段为0的数据报）。通常情况下是，路由器将该数据报丢弃，并给信源主机发送一份ICMP超时信息。tracerouter程序的关键在于，这份ICMP超时信息包含了该路由器的地址。tracerouter利用网络协议的这种机制，TTL值从1开始每次发送一个TTL等于上次值加一的数据包，直到收到目的主机的响应才停止。这样就能拿到数据包经过路径上的每个路由器的地址信息，从而打印路由信息。有些情况下traceroute无法到达最终节点(traceroute一台主机时，会看到有一些行是以星号表示的) 有可能因为主机屏蔽了ICMP回显, 对于有HTTP服务的服务器, 可以使用-p 指定端口使用TCP协议进行探测traceroute -T -p 80 a.xxx.com (在 macOS上好像不支持-T) nmap探测远端机器端口 nmap 192.168.1.1 -p 80 nc(netcat) 接受文件: nc -4 -l -p local_port &gt; file 说明: -4是指IPv4, 如果默认-6有问题就试试这个, -l=listen, -p=port 发送文件: nc dest_ip dest_port &lt; file tcpdump=&gt; [[../22.Network-Protocol/Tcpdump]] 网卡吞吐量(Throughput) iftop iftop底部会显示一些全局的统计数据，peek 是指峰值情况，cumm 是从运行至今的累计情况，而 rates 表示最近 2 秒、10 秒、40 秒内总共接收或者发送的平均网络流量。 TX: cumm: 143MB peak: 10.5Mb rates: 1.03Mb 1.54Mb 2.10MbRX: 12.7GB 228Mb 189Mb 191Mb 183MbTOTAL: 12.9GB 229Mb 190Mb 193Mb 185MbW iperf server: iperf -s client: iperf -c 192.168.0.138 -t 60 -l 8k -i 10 // 进行60秒测试, 缓冲区大小8k, 每10秒打印一次结果 测试阿里云服务器大约67.5 Mbits/sec, 似乎是Mac无线网卡的限制…内网的两台服务器测试(非同一机房) 450 Mbits/sec netperf server端: netserver client端测试tcp: ./netperf -t TCP_STREAM -H 192.168.0.138 -l 60 -- -m 2048 # 测试时长60秒, 发送分组大小2048 Bytes client端测试udp: ./netperf -t UDP_STREAM -H 192.168.0.138 -l 60 -- -m 2048","categories":[{"name":"21.Operating-System","slug":"21-Operating-System","permalink":"https://beefyheisenberg.github.io/categories/21-Operating-System/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://beefyheisenberg.github.io/tags/Linux/"},{"name":"Linux命令行","slug":"Linux命令行","permalink":"https://beefyheisenberg.github.io/tags/Linux命令行/"},{"name":"网络","slug":"网络","permalink":"https://beefyheisenberg.github.io/tags/网络/"}]},{"title":"Linux.01a::常用命令行全称速记","slug":"21.Operating-System/Linux.01a.常用命令行全称速记","date":"2024-01-24T01:27:52.459Z","updated":"2024-01-24T01:27:52.459Z","comments":true,"path":"21.Operating-System/Linux.01a.常用命令行全称速记/","link":"","permalink":"https://beefyheisenberg.github.io/21.Operating-System/Linux.01a.常用命令行全称速记/","excerpt":"","text":"@ref linux命令英文全称 - 知乎 su：Swith user 切换用户，切换到root用户 cat: Concatenate 串联 uname: Unix name 系统名称 df: Disk free 空余硬盘 du: Disk usage 硬盘使用率 chown: Change owner 改变所有者 chgrp: Change group 改变用户组 ps：Process Status 进程状态 tar：Tape archive 解压文件 chmod: Change mode 改变模式 umount: Unmount 卸载 ldd：List dynamic dependencies 列出动态相依 insmod：Install module 安装模块 rmmod：Remove module 删除模块 lsmod：List module 列表模块 alias :Create your own name for a command bash :GNU Bourne-Again Shell linux内核 grep:global regular expression print httpd :Start Apache ipcalc :Calculate IP information for a host ping :Send ICMP ECHO_Request to network hosts reboot: Restart your computer sudo:Superuser do /bin = BINaries /dev = DEVices /etc = ETCetera /lib = LIBrary /proc = PROCesses /sbin = Superuser BINaries /tmp = TeMPorary /usr = Unix Shared Resources /var = VARiable ? FIFO = First In, First Out GRUB = GRand Unified Bootloader IFS = Internal Field Seperators LILO = LInux LOader MySQL = My最初作者的名字SQL = Structured Query Language PHP = Personal Home Page Tools = PHP Hypertext Preprocessor PS = Prompt String Perl = “Pratical Extraction and Report Language” = “Pathologically Eclectic Rubbish Lister” Python Monty Python’s Flying Circus Tcl = Tool Command Language Tk = ToolKit VT = Video Terminal YaST = Yet Another Setup Tool apache = “a patchy” server apt = Advanced Packaging Tool ar = archiver as = assembler bash = Bourne Again SHell bc = Basic (Better) Calculator bg = BackGround cal = CALendar cat = CATenate cd = Change Directory chgrp = CHange GRouP chmod = CHange MODe chown = CHange OWNer chsh = CHange SHell cmp = compare cobra = Common Object Request Broker Architecture comm = common cp = CoPy cpio = CoPy In and Out cpp = C Pre Processor cups = Common Unix Printing System cvs = Current Version System daemon = Disk And Execution MONitor dc = Desk Calculator dd = Disk Dump df = Disk Free diff = DIFFerence dmesg = diagnostic message du = Disk Usage ed = editor egrep = Extended GREP elf = Extensible Linking Format elm = ELectronic Mail emacs = Editor MACroS eval = EVALuate ex = EXtended exec = EXECute fd = file descriptors fg = ForeGround fgrep = Fixed GREP fmt = format fsck = File System ChecK fstab = FileSystem TABle fvwm = F*** Virtual Window Manager gawk = GNU AWK gpg = GNU Privacy Guard groff = GNU troff hal = Hardware Abstraction Layer joe = Joe’s Own Editor ksh = Korn SHell lame = Lame Ain’t an MP3 Encoder lex = LEXical analyser lisp = LISt Processing = Lots of Irritating Superfluous Parentheses ln = LiNk lpr = Line PRint ls = list lsof = LiSt Open Files m4 = Macro processor Version 4 man = MANual pages mawk = Mike Brennan’s AWK mc = Midnight Commander mkfs = MaKe FileSystem mknod = MaKe NODe motd = Message of The Day mozilla = MOsaic GodZILLa mtab = Mount TABle mv = MoVe nano = Nano’s ANOther editor nawk = New AWK nl = Number of Lines nm = names nohup = No HangUP nroff = New ROFF od = Octal Dump passwd = PASSWorD pg = pager pico = PIne’s message COmposition editor pine = “Program for Internet News &amp; Email” = “Pine is not Elm” ping = Packet InterNet Grouper pirntcap = PRINTer CAPability popd = POP Directory pr = pre printf = PRINT Formatted ps = Processes Status pty = pseudo tty pushd = PUSH Directory pwd = Print Working Directory rc = runcom = run command, shell rev = REVerse rm = ReMove rn = Read News roff = RunOFF rpm = RPM Package Manager = RedHat Package Manager rsh, rlogin, = Remote rxvt = ouR XVT sed = Stream EDitor seq = SEQuence shar = SHell ARchive slrn = S-Lang rn ssh = Secure SHell ssl = Secure Sockets Layer stty = Set TTY su = Substitute User svn = SubVersioN tar = Tape ARchive tcsh = TENEX C shell telnet = TEminaL over Network termcap = terminal capability terminfo = terminal information tr = traslate troff = Typesetter new ROFF tsort = Topological SORT tty = TeleTypewriter twm = Tom’s Window Manager tz = TimeZone udev = Userspace DEV ulimit = User’s LIMIT umask = User’s MASK uniq = UNIQue vi = VIsual = Very Inconvenient vim = Vi IMproved wall = write all wc = Word Count wine = WINE Is Not an Emulator xargs = eXtended ARGuments xdm = X Display Manager xlfd = X Logical Font Description xmms = X Multimedia System xrdb = X Resources DataBase xwd = X Window Dump yacc = yet another compiler compiler","categories":[{"name":"21.Operating-System","slug":"21-Operating-System","permalink":"https://beefyheisenberg.github.io/categories/21-Operating-System/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://beefyheisenberg.github.io/tags/Linux/"},{"name":"Linux命令行","slug":"Linux命令行","permalink":"https://beefyheisenberg.github.io/tags/Linux命令行/"}]},{"title":"Linux.01::常用命令行","slug":"21.Operating-System/Linux.01.常用命令行","date":"2024-01-24T01:27:52.454Z","updated":"2024-01-24T01:27:52.455Z","comments":true,"path":"21.Operating-System/Linux.01.常用命令行/","link":"","permalink":"https://beefyheisenberg.github.io/21.Operating-System/Linux.01.常用命令行/","excerpt":"命令全称=&gt; Linux.01a.常用命令行全称速记 使用 manman 可以查看”系统命令/系统调用函数/glibc库函数” 等等共9类内容, 例如 man lsof 第一行是 “LSOF(8)”, 表示是第8类, man man 第一行是”man(8)” 表示man 是第8类, 也可以看到所有9类 “manual”, 如下: 系统命令 系统调用，一般是对应的C封装函数；所有系统调用的函数在调用发生时都会进入内核空间执行 各种库函数手册，例如glibc，pthread库API等，如果是非C库，则会标注出对于的链接选项 特殊设备文件，例如zero, mem等 文件格式手册，描述Linux支持的各种文件系统以及对于的C接口结构，如vfat/iso 游戏程序文档 其它的各种各样不在前边分类的文档（8/9除外） 系统管理员命令，一般仅供root用户使用，如cron/useradd等 Linux内核相关部分的手册，一般情况很少用到，这一节就没有intro介绍页","text":"命令全称=&gt; Linux.01a.常用命令行全称速记 使用 manman 可以查看”系统命令/系统调用函数/glibc库函数” 等等共9类内容, 例如 man lsof 第一行是 “LSOF(8)”, 表示是第8类, man man 第一行是”man(8)” 表示man 是第8类, 也可以看到所有9类 “manual”, 如下: 系统命令 系统调用，一般是对应的C封装函数；所有系统调用的函数在调用发生时都会进入内核空间执行 各种库函数手册，例如glibc，pthread库API等，如果是非C库，则会标注出对于的链接选项 特殊设备文件，例如zero, mem等 文件格式手册，描述Linux支持的各种文件系统以及对于的C接口结构，如vfat/iso 游戏程序文档 其它的各种各样不在前边分类的文档（8/9除外） 系统管理员命令，一般仅供root用户使用，如cron/useradd等 Linux内核相关部分的手册，一般情况很少用到，这一节就没有intro介绍页 man ascii: 该命令用来查看 ASC II表 man malloc: 查看malloc用法, 如果显示 “No manual entry for malloc”, 则需要安装 “man-pages”: yum -y install man-pages ps, top, free, vmstatvmstat, sar, iostat, iotop @link: Linux.03.命令行-Performance sort, uniq, wc, cut sort参数: -t 指定分隔符 -n 按数字大小排序, 如果不加-n默认是ASCII码排序 -r 倒序 -k 1,5 指定按哪一列排序, 默认是从第N列到行尾, -k4指定按第四列排序 例:按进程VSS内存排序: ps aux | tr -s &quot; &quot; | sort -nrk 5 | cut -d &quot; &quot; -f 1,2,5,6,11- | more分隔符为”:”的文件按照第5列数值排序: cat file | sort -t : -nrk 1,5 uniq只能去除相邻行的重复, 所以一般跟sort联用. -c: 去重+统计次数 sort联用: cat /proc/cpuinfo | grep &#39;physical id&#39; | sort | uniq | wc -l wc: -l: 统计行数 -w: 统计单词数 cut用来显示行中的指定部分, 分隔符用-d 参数(如果不加-d参数则分隔符是制表符), 取出第几列用-f 参数(从1开始),例: who | cut -d &#39; &#39; -f 2 注: cut通常和其他命令一起使用, 用来处理其他命令的输出, 但实际情况下很多命令的分隔符并不统一, 所以用 awk比 cut更方便: ls -l | awk &#39;{print $9}&#39; chmod, chown, chgrp通过ls -l查看文件属性: chmod [-R] xyz 文件或目录名: xyz三个数字即 owner/group/other的 rwx属性之和 (r=4, w=2, x=1) chmod 640 file1 // 给user读写权限, group读权限, other无权限 chmod u=rw,g=r,o= file1 // 同chmod 640 chmod -R o-r /home/* // 把other的读权限都去掉. chmod支持+,-,=符号. chown [–R] 属主名 文件名 or chown [-R] 属主名：属组名 文件名 chgrp [-R] 属组名 文件名 注: 目录的x权限指可以cd到这个目录, 目录的r权限指可以遍历目录下的文件,父级目录和子文件的权限互不影响, 例如用户有父级目录的x权限, 但目录下的文件不会继承x权限, 但是如果要执行目录下文件, 前提是能切到父级目录, 意味着父级目录要有x权限 ln 创建软链接: ln -s src target // 记住 ln ... as ... 创建硬链接: ln src target 软链接vs硬链接: 允许对目录创建软链接,硬链接不可以 可以跨文件系统创建软链接, 硬链接不可以 删除源文件, 软链接将失效, 硬链接仍保留删除前源文件内容 理解 Linux 的硬链接与软链接 gzip, bzip2, tar 压缩与读压缩命令:gzip -v file1 # 压缩为gz格式bzip2 -z file1 # 压缩为bz2格式zcat file1.gz # 不解压读取gzbzcat file1.bz2 # 不解压读取bz2gzip -d file1.gz # 解压gzbzip2 -d file1.bz2 # 解压bz2 注意: gzip压缩后不保留源文件, bzip2必须加-k参数才保留源文件 打包与解包:tar cvzf file1 file1.tar.gz # 打包为 tar.gztar cvjf file1 file1.tar.bz2 # 打包为 tar.bz2tar xvzf file1.tar.gztar xvjf file1.tar.bz2 where, which, locate功能和which类似, 也是一种查找, 区别在于locate搜索的是数据库/var/lib/locatedb所以速度更快, 例如locate _vimrc sed, awk@ref: sed &amp; awk &amp; grep find, grep, ack find: 按时间查找, 可用参数有: -mmin 以分钟为单位, -mtime 以天为单位, 后面的数字+表示比该时间更早, -表示该时间之后-当前, 查找N天之前更早的: find . -mtime +3 -name &#39;*.log&#39; 查找N天前~当前时刻的: find . -mtime -3 -name &#39;*.log&#39; 在当前目录及其子目录下查找符号链接文件: find -type l 在当前目录及其子目录下查文件夹: find -type d 在当前目录查找普通文件: find -type f 在root目录下及其最大3层深度的子目录中查找: find / -max-depth 3 -name log 查找特定文件并ls列出: find -name *.java -exec ls -l {} \\; 注意exec的参数必须以”分号”结束,分号还要加转义符.解释: {}是前面find找到的文件, -exec后面的参数后面跟的是command命令, 它的终止是以;为结束标志的, 所以这句命令后面的”分号”是不可缺少的, 考虑到各个系统中分号会有不同的意义, 所以前面加反斜杠. 参考 Using semicolon (;) vs plus (+) with exec in find - Stack Overflow shell的内建命令-exec将并不启动新的shell, 而是用要被执行命令替换当前的shell进程, 并且将老进程的环境清理掉, 而且exec命令后的其它命令将不再执行. 以新的进程去代替原来的进程, 但进程的PID保持不变. 与xargs配合使用: find find -name *.java | xargs rm -f 文件的 atime, mtime,ctimeatime: 文件访问时间, 用touch,vi等命令都会修改这个时间ctime: 文件元数据(所属人,读写权限..) chown,chmod都会…mtime: 文件内容修改时间, ps修改了文件内容, 文件元数据也会变化ls -l 列出来的是ctime命令stat fileName返回如下 grep: 查找某个文件: grep &quot;Invalid user&quot; /var/log/auth.log 查找多个Word: grep -E &quot;word1|word2&quot; 在某个目录下递归查找: grep -irn &quot;xxx&quot; /dir 与find一起使用: find . -name &quot;*.css&quot; | xargs grep &quot;monospac&quot; grep = globally search for regular expression and print out // @ref: https://www.geeksforgeeks.org/grep-command-in-unixlinux/ ack: ack xxxx dir/log1: 在指定文件里搜索xxx ack --java xxxx: 在java文件里搜索xxx ack -i xxx: 不区分大小写 ack -w xxx: 全词匹配 who, w, whoami, last w - Show who is logged on and what they are doing. who - show who is logged on whoami - print effective userid who am i - When a user logs in as a root across the network, both the command whoami and who am i will show you root. However, when a user abc logs in remotelyand runs su – root, whoami will show root whereas who am i will show abc last: 获取每个用户登录的持续时间. 该记录保存在: /var/log/wtmp lsof, fuserfuser:列出哪个进程在使用文件: fuser /etc/filenames lsof: 常用参数: -p 进程id -i :端口号 -P : 默认情况lsof会显示 “端口名字” 而不是 “数字类型的端口号” （如果此端口号有名字的话）, -P可以指定显示数字端口号, 而不是名字 用法示例: 查找已被删除但硬盘空间不释放的文件: lsof |grep delete, 这个文件的innode链接被移除了, 但还没有被删掉 某个端口: lsof -i TCP:8080 or lsof -i :80， -i是列出listening的sock，If -i4 or -i6 is specified with no following address, only files of the indicated IP version 某个进程: lsof -p PID 查看所有活动状态的网络服务: lsof -i 查看某个用户打开的文件: lsof -u ^root, 或者lsof | grep ^root 文件实际上是一个指向inode的链接, inode链接包含了文件的所有属性, 比如权限和所有者, 数据块地址(文件存储在磁盘的这些数据块中). 当你删除(rm)一个文件, 实际删除了指向inode的链接, 并没有删除inode的内容. 进程可能还在使用. 只有当inode的所有链接完全移去, 然后这些数据块将可以写入新的数据. Example: lsof返回数据如下: COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEinit 1 root cwd DIR 8,1 4096 2 /crond 4621 root txt REG 8,5 64096 151941 /usr/sbin/crondcrond 4621 root DEL REG 8,1 115 /lib64/libnss_files-2.12.songinx 42544 root 194u unix 0xffff880012b9a080 0t0 510761950 socketnginx 42544 root 195u unix 0xffff8800cbb99cc0 0t0 510761952 socketjava 27672 root 66u IPv4 41351930 0t0 TCP *:56494 (LISTEN) lsof | awk &#39;{process[$1]++;} END{for(key in process) printf(&quot;%s:%d\\n&quot;, key, process[key])}&#39; // 每个进程打开的文件数 lsof | awk &#39;{if($8 == &quot;TCP&quot;) opened_tcp++} END{print opened_tcp }&#39; //打开TCP连接数量 lsof | awk &#39;{opened_type[$5]++} END{ for(key in opened_type) printf(&quot;%s : %d\\n&quot;, key, opened_type[key])}&#39; // 打开文件按TYPE统计 du, df, fdisk du: 查看当前子目录大小: du -h --max-depth=1 当前目录文件按大小排序: du -s * | sort -n | tail df: （英文全拼：disk free） 显示文件系统的使用情况 &amp; 挂载点 -h：--human-readable fdisk: 创建和维护分区表 -l：列出所有分区表 -exec, xargsxargs的作用一般等同于大多数Unix shell中的反引号, 但更加灵活易用, 并可以正确处理输入中有空格等特殊字符的情况. 对于经常产生大量输出的命令如find、locate和grep来说非常有用: file * |grep ASCII | cut -d&quot;:&quot; -f1 |xargs ls -l -exec查找并grep: find . -name &quot;*.php&quot; -exec grep -in &quot;string&quot; {} \\; 最后的\\;是-exec的结束标识 xargs: find . -name &quot;*.php&quot; | xargs grep -in &quot;string&quot; ulimit 查看所有的限制: ulimit -a set 最大打开文件句柄数: ulimit -n 65535, 查看当前值ulimit -n set 最大进程数: ulimit -u 32768, 查看当前值ulimit -u set 线程栈的大小: ulimit -s 10240 set core文件大小: ulimit -c xxx, 不限制core的大小: ulimit -c unlimited ulimit起作用的范围是当前Shell, 并不是作用于”当前用户”, 如要对”用户”做限制, 则需要修改系统文件/etc/security/limits.conf umaskumask命令用来设置限制新建文件权限的掩码。当新文件被创建时，其最初的权限由文件创建掩码决定。用户每次注册进入系统时，umask命令都被执行， 并自动设置掩码mode来限制新文件的权限。用户可以通过再次执行umask命令来改变默认值，新的权限将会把旧的覆盖掉。 umask 022: 用户权限为755 umask 077: 用户权限为700 su, sudosu: su: 切换到root用户, 切换之前的环境变量一并被带到了新shell里; su - user_name: 切换用户, 切换之后的环境变量会改变为新用户的, su - 同su - root 例: su - root -c commands, 执行完commands之后自动切换会原来的用户. sudo: sudo是受限制的su, 两个命令的最大区别是：sudo 命令需要输入当前用户的密码，su 命令需要输入 root 用户的密码。 sudo -s cmd: 执行cmd命令, 如果是sudo -s则会启动一个可交互shell, 有点类似su, 通过修改/etc/sudoer配置哪些用户具有执行sudo的权限, sudo命令能继承哪些环境变量也是在/etc/sudoer中配置的. export &amp; 环境变量 VAR=hello $VAR scope is restricted to the shell; export VAR=hello makes the $VAR available to child processes; 每个进程的环境变量可以在/proc/$PID/evnrion查看. sh, exec, source的区别 source 和 点命令.是一样的, 不会启动子shell, 不需要script有可执行权限, script里定义的变量也会被导入当前的shell环境. ./script 启动子shell, script里的变量不会被带进当前环境, 相当于fork, 需要脚本有x权限 sh ./script 先启动了一个子shell, 子shell继承父shell的环境变量, 但子shell里新建变量、改变变量 不会被带回父shell, 除非用export VAR=&quot;xxx&quot; exec cmd 产生了新的进程, 新进程会关闭当前shell的进程, 新的进程继承了原shell的PID号, 原shell剩下的内容不会执行, 顺序执行多命令顺序执行: 分号（;）： 顺序执行，命令之间不存在关系，互不影响 例 ls; date; cd /user; pwd 逻辑与（&amp;&amp;）： 只有第一条命令成功执行，才会执行第二条命令 例 cd ~/dir &amp;&amp; git commit -am &quot;u&quot; &amp;&amp; git pull &amp;&amp; git push 逻辑或（||）： 第一条成功执行，第二条不执行; 第一条非正确执行，第二条才会执行 killAPUE.03a.进程 nohup并不是所有的程序都像 Nginx, Redis, httpd一样提供守护进程, 保证在关闭终端会话后正常运行.如果终端会话关闭，那么程序也会被关闭。为了能够后台运行，那么我们就可以使用nohup: nohup cmd &amp; : 后台运行cmd, 程序运行的输出信息放到当前目录的 nohup.out 文件中去 nohup command &gt; myout.log 2&gt;&amp;1 &amp; : 后台运行cmd, 并指定输出的文件 nohup的原理也很简单，终端关闭后会给此终端下的每一个进程发送SIGHUP信号，而使用nohup运行的进程则会忽略这个信号，因此终端关闭后进程也不会退出。 命令重定向 一般情况下，每个 Unix/Linux 命令运行时都会打开三个文件: 文件描述符 0 通常是标准输入（STDIN），1 是标准输出（STDOUT），2 是标准错误输出（STDERR）。 输出重定向# 将输出重定向到 filecommand &gt; file# 将输出追加重定向到 filecommand &gt;&gt; file# 将文件描述符为n的文件重定向到 filen&gt;file# 将文件描述符为 n 的文件以追加的方式重定向到 filen&gt;&gt;file# 将文件描述符为 m 和 n 的内容合并,注意n&gt;&amp;m# 将文件描述符为 m 和 n 的内容合并, 一并输出到 filecommand &gt; file m&gt;&amp;n 有关 command &gt;out.file 2&gt;&amp;1 &amp; 的解释(注意文件描述符和重定向符号之间不能有空格):最后的&amp; 表示后台运行;为什么是 2&gt;&amp;1 而不是 2&gt;1 ? 这样做会直接输出文件名为1的文件;&gt;outfile 和 2&gt;&amp;1 的顺序可以交换吗? 不可以, command 2&gt;&amp;1 &gt;out.file , 先2&gt;&amp;1 的意思是 stderr输出到 stdout, 此时的 stdout是输出到终端的, stderr也就被输出到终端, 然后 &gt;out.file是把 stdout输出到文件, 但是此时 stderr还是输出到终端的; 输入重定向# 将 file的内容作为标准输入command &lt; file# 将 infile的内容作为标准输入, 标准输出写入 outfilecommand &lt; infile &gt; outfile# Here Document 式重定向输入, 将定界符（下面例子中的EOF没有特殊含义, 可以自定义界定符）之间的作为stdincommand &lt;&lt; EOF hello worldEOF 默认情况下，command &gt; file 将 stdout 重定向到 file，command &lt; file 将stdin 重定向到 file。 其他用法 创建一个空文件, 除了touch还可 : &gt; file 用ssh远程执行本地脚本, 不用scp拷贝 : ssh root@host bash &lt; /local/xxx.sh &lt;(COMMAND) 可以作为一个文件 : diff /etc/host &lt;(ssh remote cat /etc/hosts) trap 脚本内执行java -jar ...命令, 通过$!获得子进程ID 脚本执行wait 子进程ID 如下 _term() &#123; kill -TERM \"$child_pid\" wait \"$child_pid\"&#125;trap _term SIGTERMjava -Dspring.profiles.active=test \\ -Dserver.port=9013 \\ -jar wallet-console-2.0.0.jar &amp;child_pid=$!wait \"$child_pid\" 网络相关命令Linux.02.网络命令 常用配置文件Linux.04.系统配置","categories":[{"name":"21.Operating-System","slug":"21-Operating-System","permalink":"https://beefyheisenberg.github.io/categories/21-Operating-System/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://beefyheisenberg.github.io/tags/Linux/"},{"name":"Linux命令行","slug":"Linux命令行","permalink":"https://beefyheisenberg.github.io/tags/Linux命令行/"}]},{"title":"APUE.07d::服务端常用IO模型","slug":"21.Operating-System/APUE.07d.服务端常用IO模型","date":"2024-01-24T01:27:52.448Z","updated":"2024-01-24T01:27:52.448Z","comments":true,"path":"21.Operating-System/APUE.07d.服务端常用IO模型/","link":"","permalink":"https://beefyheisenberg.github.io/21.Operating-System/APUE.07d.服务端常用IO模型/","excerpt":"Nginx: 基于 epoll 监听多个连接(50000 个并发连接数的响应), 当某个连接有数据准备好的时候再通知, 这样一个进程能处理多个连接 大于 5 k 并发的时候, Nginx 才明显比 apache 有更好的表现 Redis Redis 使用单线程的 I/O 复用模型, 自己封装了一个简单的 AeEvent 事件处理框架, 主要实现了 epoll、kqueue 和 select. 优势: 对于单纯只有 I/O 操作来说, 单线程可以将速度优势发挥到最大. 且无需考虑同步问题 缺陷：Redis 排序、聚合、大 Key 操作、Flush 等, 对于这些耗时较高操作, 单线程模型实际会严重影响整体吞吐量, CPU 计算过程中, 整个 I/O 调度都是被阻塞住的 Apache: 默认是每个请求启动一个线程处理, 并不适合高并发","text":"Nginx: 基于 epoll 监听多个连接(50000 个并发连接数的响应), 当某个连接有数据准备好的时候再通知, 这样一个进程能处理多个连接 大于 5 k 并发的时候, Nginx 才明显比 apache 有更好的表现 Redis Redis 使用单线程的 I/O 复用模型, 自己封装了一个简单的 AeEvent 事件处理框架, 主要实现了 epoll、kqueue 和 select. 优势: 对于单纯只有 I/O 操作来说, 单线程可以将速度优势发挥到最大. 且无需考虑同步问题 缺陷：Redis 排序、聚合、大 Key 操作、Flush 等, 对于这些耗时较高操作, 单线程模型实际会严重影响整体吞吐量, CPU 计算过程中, 整个 I/O 调度都是被阻塞住的 Apache: 默认是每个请求启动一个线程处理, 并不适合高并发 缺陷: 有多少并发就需要多少进程, 最大进程数 在进程创建很多的情况下, 系统切换进程的代价很高, 进程运行的时间很少 实际上本机处理数据的时间很短, 大多数时间都是在”等待数据准备好”的阶段, 效率低 新版的 Apache 的改进, 支持多种 MPM(Multi-Processing Model) prefork: 古老 worker: 多进程(注意并不是每个请求一个线程), 每个进程多个线程 event: epoll Tomcat: BIO 模式每个请求启动一个线程处理 但 Tomcat 从 JDK 1.6 支持开始支持 NIO，这种方式同 Netty 的“主从 Reactor” 类似，这种模式下，只有一个 Acceptor 线程用于 accept 新请求，Poller 线程相当于 Netty 的 sub Reactor 线程（默认 process x 2 个）只负责已建立的连接 IO 事件，业务放入 exector 线程池处理业务（包括对 socket 流的 decode，业务代码指的是 servlet.service） @link APUE.07c.网络编程-Reactor&Proactor模型 @ref: 性能追击：万字长文30+图揭秘8大主流服务器程序线程模型","categories":[{"name":"21.Operating-System","slug":"21-Operating-System","permalink":"https://beefyheisenberg.github.io/categories/21-Operating-System/"}],"tags":[]},{"title":"APUE.07c::网络编程-Reactor vs Proactor","slug":"21.Operating-System/APUE.07c.网络编程-Reactor&Proactor模型","date":"2024-01-24T01:27:52.444Z","updated":"2024-01-24T01:27:52.444Z","comments":true,"path":"21.Operating-System/APUE.07c.网络编程-Reactor&Proactor模型/","link":"","permalink":"https://beefyheisenberg.github.io/21.Operating-System/APUE.07c.网络编程-Reactor&Proactor模型/","excerpt":"I/O 多路复用模式：Reactor &amp; Proactor一般地,I/O 多路复用机制（I/O multiplexing mechanisms）都依赖于一个事件多路分离器(Event Demultiplexer)。我们常见的事件多路分用器包括：Linux 的 epoll 和 Windows 的 IOCP。 事件多路分离器（Event Demultiplexer）可将来自事件源的 I/O 事件分离出来，并分发到对应的 事件处理器 (Event Handler)进行 read/write。 两个与事件分离器有关的模式是 Reactor 和 Proactor，Reactor 模式采用同步 IO，而 Proactor 采用异步 IO。 Reactor 模式","text":"I/O 多路复用模式：Reactor &amp; Proactor一般地,I/O 多路复用机制（I/O multiplexing mechanisms）都依赖于一个事件多路分离器(Event Demultiplexer)。我们常见的事件多路分用器包括：Linux 的 epoll 和 Windows 的 IOCP。 事件多路分离器（Event Demultiplexer）可将来自事件源的 I/O 事件分离出来，并分发到对应的 事件处理器 (Event Handler)进行 read/write。 两个与事件分离器有关的模式是 Reactor 和 Proactor，Reactor 模式采用同步 IO，而 Proactor 采用异步 IO。 Reactor 模式在 Reactor 中，事件多路分离器 等待文件描述符状态变为读写操作准备就绪状态，然后将就绪事件传递给对应的 处理器，最后由 处理器 负责完成实际的读写工作。 Linux epoll 使用 Reactor 模式，Reactor 模式使用同步 I/O（一般来说）。Reactor 的标准（典型）的工作方式是： Reactor 线程中, epoll 注册读/写等等事件 epoll 等待事件到来 事件到来，Reactor 把事件分发给处理器(往往使用线程池跑处理器) 处理器线程: 读写数据（调用 read/write, 从内核 buff 将数据拷贝到用户态 buff) 处理器线程进行处理(decode 数据, 执行业务代码, encode 数据) Netty 的 Reactor 线程模型 @link: [[../12.Java/Java-Tutorials.09.NIO&amp;Netty#Reactor三种常见线程模型]] Proactor 模式而在 Proactor 模式中，处理器 只负责发起异步读写操作。 处理器 传递给操作系统 用户态的数据缓冲区，之后的 IO 操作、以及内核态缓冲区→ 用户态缓冲区操作，这些都由操作系统来完成。 比如，在 windows 上，处理器发起一个异步 IO 操作，再由事件分离器等待 IOCompletion 事件。IOCompletion 通知的时候, 数据已经被拷贝到处理器的 buff 了.典型的异步模式实现，都建立在操作系统支持异步 API 的基础之上，我们将这种实现称为“系统级”异步或“真”异步，因为应用程序完全依赖操作系统执行真正的 IO 工作。 Windows IOCP 使用 Proactor 模式，Proactor 模式使用异步 I/O。Proactor 的标准（典型）的工作方式是： 处理器发起异步读操作（注意：操作系统必须支持异步 IO）。在这种情况下，处理器无视 IO 就绪事件，它关注的是完成事件。 事件分离器等待操作完成事件 在分离器等待过程中，操作系统利用并行的内核线程执行实际的读操作，并将结果数据存入用户自定义缓冲区，最后通知事件分离器读操作完成。 事件分离器呼唤处理器。 事件处理器处理用户自定义缓冲区中的数据，然后启动一个新的异步操作，并将控制权返回事件分离器。 以上参考: Reactor VS Proactor 模式 @ref 两种模式的比较比较实现 在 Reactor 模式，用户代码的责任是： 在收到 IO事件后进行实际的 IO 操作； 在 Proactor 模式，用户代码需要负责收到 IO事件后的所有操作； 优势和劣势✔︎ Reactor 优势 Reactor 实现相对简单，对于耗时短的处理场景处理高效； 操作系统可以在多个事件源上等待，并且避免了多线程编程相关的性能开销和编程复杂性； 事件的串行化对应用是透明的，可以顺序的同步执行而不需要加锁； 事务分离：将与应用无关的多路分解和分配机制和与应用相关的回调函数分离开来， × Reactor 劣势 Reactor 处理耗时长的操作会造成事件分发的阻塞，影响到后续事件的处理； ✔︎ Proactor 优势 Proactor 性能更高，能够处理耗时长的并发场景； × Proactor 劣势 Proactor 依赖操作系统对异步的支持，目前实现了纯异步操作的操作系统少，比较优秀的如 windows IOCP（完成端口），但由于其 windows 系统用于服务器的局限性，目前应用范围较小；而 Unix/Linux 系统对纯异步的支持尚不成熟，应用事件驱动的主流还是通过 select/epoll 来实现； 适用场景 Reactor：同时接收多个服务请求，并且依次同步的处理它们的事件驱动程序； Proactor：异步接收和同时处理多个服务请求的事件驱动程序； 在实际工程中的使用 Reactor: libevent / libev /libuv / ZeroMQ / Event Library in Redis Proactor: Windows IOCP / Boost.Asio 参考 System|IO|Proactor - 知乎 System|IO|Reactor - 知乎","categories":[{"name":"21.Operating-System","slug":"21-Operating-System","permalink":"https://beefyheisenberg.github.io/categories/21-Operating-System/"}],"tags":[]},{"title":"APUE.07b::网络编程-多路复用","slug":"21.Operating-System/APUE.07b.网络编程-多路复用epoll","date":"2024-01-24T01:27:52.439Z","updated":"2024-01-24T01:27:52.439Z","comments":true,"path":"21.Operating-System/APUE.07b.网络编程-多路复用epoll/","link":"","permalink":"https://beefyheisenberg.github.io/21.Operating-System/APUE.07b.网络编程-多路复用epoll/","excerpt":"五种 I/O 模型 阻塞 IO: 调用 read, 如果内核数据未就绪, 调用 read 的进程进入阻塞状态。应用程序调用一个 IO 函数，导致应用程序阻塞并等待数据准备就绪。如果数据没有准备好，一直等待。如果数据准备好了，则从内核拷贝到用户空间拷贝数据，IO 函数返回成功指示。 非阻塞 IO: nonblocking IO 的特点是用户进程需要不断的主动询问 kernel 数据是否准备好. 当所请求的 I/O 操作无法完成时，不要将进程睡眠，而是返回一个错误。这样我们的 I/O 操作函数将不断的测试数据是否已经准备好，如果没有准备好，继续测试，直到数据准备好为止。在这个不断测试的过程中，会大量的占用 CPU 的时间。 多路复用 IO: 复用模型会用到 select 或者 poll 函数，这两个函数也会使进程阻塞，但是和阻塞 I/O 所不同的的，这两个函数可以同时阻塞多个 I/O 操作。而且可以同时对多个读操作，多个写操作的 I/O 函数进行检测，直到有数据可读或可写时，才真正调用 I/O 操作函数。从而使得系统在单线程的情况下可以同时处理多个客户端请求. 与传统的多线程/多进程模型比, I/O 多路复用的最大优势是系统开销小。和阻塞 IO 模型相比，selectI/O 复用模型相当于提前阻塞了。等到有数据到来时，再调用 recv 就不会因为要等数据就绪而发生阻塞。 select: 一般采用 select + no-block, select 返回后要遍历所有阻塞在 select 上的 IO 句柄，找到数据就绪的那一个 IO 句柄后, 应用程序调用 recvfrom 将数据从内核区拷贝至用户区； epoll : 比 select 更高效，无需轮询全部句柄，epoll 只返回数据 ready 的 IO 句柄 信号驱动 IO：让内核在数据就绪时用信号 SIGIO 通知我们，将此方法称为信号驱动 I/O。首先，我们允许套接字进行信号驱动 I/O，并通过系统调用 sigaction 安装一个信号处理程序。此系统调用立即返回，进程继续工作，它是非阻塞的。当数据报准备好被读时，就为该进程生成一个 SIGIO 信号。我们随即可以在信号处理程序中调用 recvfrom 来取读数据报。 异步 IO: 我们让内核启动操作，并在整个操作完成后（包括将数据从内核拷贝到我们自己的缓冲区）通知我们。调用 aio_read 函数，告诉内核描述字，缓冲区指针，缓冲区大小，文件偏移以及通知的方式，然后立即返回。当内核将数据拷贝到缓冲区后，再通知应用程序。上面其它四种模型，至少都会在由 kernel copy data to appliction 时阻塞。而该模型是当 copy 完成后才通知 application，可见是纯异步的。很少有 *nix 系统支持，windows 的 IOCP（完成端口）则是此模型 Linux I/O 模型的发展技术是： select -&gt; poll -&gt; epoll -&gt; aio -&gt; libevent -&gt; libuv。另外还有 Windows 的 Completion Port。 提供一致的接口，IO Design Patterns实际上，不管是哪种模型，都可以抽象一层出来，提供一致的接口，广为人知的有 ACE,Libevent 这些，他们都是跨平台的，而且他们自动选择最优的 I/O 复用机制，用户只需调用接口即可。说到这里又得说说2个设计模式，Reactor and Proactor。有一篇经典文章http://www.artima.com/articles/io_design_patterns.html值得阅读，Libevent 是 Reactor 模型，ACE 提供 Proactor 模型。实际都是对各种 I/O 复用机制的封装。 select","text":"五种 I/O 模型 阻塞 IO: 调用 read, 如果内核数据未就绪, 调用 read 的进程进入阻塞状态。应用程序调用一个 IO 函数，导致应用程序阻塞并等待数据准备就绪。如果数据没有准备好，一直等待。如果数据准备好了，则从内核拷贝到用户空间拷贝数据，IO 函数返回成功指示。 非阻塞 IO: nonblocking IO 的特点是用户进程需要不断的主动询问 kernel 数据是否准备好. 当所请求的 I/O 操作无法完成时，不要将进程睡眠，而是返回一个错误。这样我们的 I/O 操作函数将不断的测试数据是否已经准备好，如果没有准备好，继续测试，直到数据准备好为止。在这个不断测试的过程中，会大量的占用 CPU 的时间。 多路复用 IO: 复用模型会用到 select 或者 poll 函数，这两个函数也会使进程阻塞，但是和阻塞 I/O 所不同的的，这两个函数可以同时阻塞多个 I/O 操作。而且可以同时对多个读操作，多个写操作的 I/O 函数进行检测，直到有数据可读或可写时，才真正调用 I/O 操作函数。从而使得系统在单线程的情况下可以同时处理多个客户端请求. 与传统的多线程/多进程模型比, I/O 多路复用的最大优势是系统开销小。和阻塞 IO 模型相比，selectI/O 复用模型相当于提前阻塞了。等到有数据到来时，再调用 recv 就不会因为要等数据就绪而发生阻塞。 select: 一般采用 select + no-block, select 返回后要遍历所有阻塞在 select 上的 IO 句柄，找到数据就绪的那一个 IO 句柄后, 应用程序调用 recvfrom 将数据从内核区拷贝至用户区； epoll : 比 select 更高效，无需轮询全部句柄，epoll 只返回数据 ready 的 IO 句柄 信号驱动 IO：让内核在数据就绪时用信号 SIGIO 通知我们，将此方法称为信号驱动 I/O。首先，我们允许套接字进行信号驱动 I/O，并通过系统调用 sigaction 安装一个信号处理程序。此系统调用立即返回，进程继续工作，它是非阻塞的。当数据报准备好被读时，就为该进程生成一个 SIGIO 信号。我们随即可以在信号处理程序中调用 recvfrom 来取读数据报。 异步 IO: 我们让内核启动操作，并在整个操作完成后（包括将数据从内核拷贝到我们自己的缓冲区）通知我们。调用 aio_read 函数，告诉内核描述字，缓冲区指针，缓冲区大小，文件偏移以及通知的方式，然后立即返回。当内核将数据拷贝到缓冲区后，再通知应用程序。上面其它四种模型，至少都会在由 kernel copy data to appliction 时阻塞。而该模型是当 copy 完成后才通知 application，可见是纯异步的。很少有 *nix 系统支持，windows 的 IOCP（完成端口）则是此模型 Linux I/O 模型的发展技术是： select -&gt; poll -&gt; epoll -&gt; aio -&gt; libevent -&gt; libuv。另外还有 Windows 的 Completion Port。 提供一致的接口，IO Design Patterns实际上，不管是哪种模型，都可以抽象一层出来，提供一致的接口，广为人知的有 ACE,Libevent 这些，他们都是跨平台的，而且他们自动选择最优的 I/O 复用机制，用户只需调用接口即可。说到这里又得说说2个设计模式，Reactor and Proactor。有一篇经典文章http://www.artima.com/articles/io_design_patterns.html值得阅读，Libevent 是 Reactor 模型，ACE 提供 Proactor 模型。实际都是对各种 I/O 复用机制的封装。 selectint select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); select 函数监视的文件描述符分 3 类，分别是 writefds、readfds、和 exceptfds。调用后 select 函数会阻塞，直到有描述副就绪（有数据可读、可写、或者有 except），或者超时（timeout 指定等待时间，如果立即返回设为 null 即可），函数返回。当 select 函数返回后，可以通过遍历 fdset，来找到就绪的描述符。select 目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。select 的一个缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在 Linux 上一般为 1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但是这样也会造成效率的降低。 pollint poll (struct pollfd *fds, unsigned int nfds, int timeout); 不同与 select 使用三个位图来表示三个 fdset 的方式，poll 使用一个 pollfd 的指针实现。pollfd 结构包含了要监视的 event 和发生的 event，不再使用 select“参数-值”传递的方式。同时，pollfd 并没有最大数量限制（但是数量过大后性能也是会下降）。和 select 函数一样，poll 返回后，需要轮询 pollfd 来获取就绪的描述符。 epollepoll 是在 2.6 内核中提出的，是之前的 select 和 poll 的增强版本。相对于 select 和 poll 来说，epoll 更加灵活，没有描述符限制。epoll 使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的 copy 只需一次。 int epoll_create(int size)；//创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); int epoll_create(int size);创建一个 epoll 的句柄，size 用来告诉内核这个监听的数目一共有多大，这个参数不同于 select()中的第一个参数，给出最大监听的 fd+1 的值，参数 size 并不是限制了 epoll 所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。当创建好 epoll 句柄后，它就会占用一个 fd 值，在 linux 下如果查看/proc/进程 id/fd/，是能够看到这个 fd 的，所以在使用完 epoll 后，必须调用 close()关闭，否则可能导致 fd 被耗尽。 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；函数是对指定描述符 fd 执行 op 操作。 epfd：是 epoll_create()的返回值。 op：表示 op 操作，用三个宏来表示：添加 EPOLL_CTL_ADD，删除 EPOLL_CTL_DEL，修改 EPOLL_CTL_MOD。分别添加、删除和修改对 fd 的监听事件。 fd：是需要监听的 fd（文件描述符） epoll_event：是告诉内核需要监听什么事件 int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);等待 epfd 上的 io 事件，最多返回 maxevents 个事件。参数 events 用来从内核得到事件的集合，maxevents 告之内核这个 events 有多大，这个 maxevents 的值不能大于创建 epoll_create()时的 size，参数 timeout 是超时时间（毫秒，0 会立即返回，-1 将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。 select &amp; poll &amp; epoll 内部实现selectselect 的实现： 当用户线程调用完 select 后开始进入阻塞状态，内核 开始轮询遍历 fd数组，查看数组里的每个 fd 对应的 Socket 的接收缓冲区否有数据。如果有数据到来，则将 fd 对应值设置为 1。如果没有数据到来，则保持值为 0。 内核遍历一遍 fd数组 后，如果发现有些 fd 上有 IO 数据到来，则将修改后的 fd数组 返回给用户线程。此时，会将 fd数组 从 内核空间 拷贝到 用户空间。 当内核将修改后的 fd数组 返回给用户线程后，用户线程解除 阻塞，由用户线程开始工作：遍历 fd数组 然后找出 fd数组 中值为 1 的 Socket 文件描述符… 由于内核在遍历的过程中已经修改了 fd数组，所以在用户线程遍历完 fd数组，就需要重置 fd 数组，并重新调用 select 传入重置后的 fd数组，让内核发起新的一轮遍历轮询。 select 的不足： 在发起 select 系统调用以及返回时，用户线程各发生了一次 用户态 到 内核态 以及 内核态 到 用户态 的上下文切换开销。发生 2 次上下文 切换 fd集合 从用户空间 拷贝 到内核空间的拷贝次数： 内核 会对内核态的 fd集合 进行修改。导致每次在用户空间重新发起 select 调用时，都需要对 fd集合 进行 重置。 fd集合 长度为固定的 1024,所以只能监听 0~1023 的文件描述符。 select 系统调用不是线程安全的。 很明显 select 也不能解决 C10K 问题，只适用于 1000 个左右的并发连接场景。 pollpoll 相比 select 的改进： select 中使用的 fd集合 是采用的固定长度为 1024 的数组，而 poll 换成了一个 pollfd 结构没有固定长度的数组，这样就没有了最大描述符数量的限制（当然还会受到系统文件描述符限制） 所以 poll 只解决了 select 最大监听数的限制，但 poll 的 fd 组织是用的线性数据结构，遍历性能在 fd 数量很多的时候不足。依然无法解决 C10K 问题。 epoll复习一下阻塞模式 recv： 阻塞 recv 场景下，服务端 sock 的 等待队列，队列里的 等待项（wait_queue_t）保存了两个重要数据：1）阻塞在此 sock 上的进程描述符， 2）就绪回调函数 autoremove_wake_function，这个函数的作用是当 sock 可读时，调用这个就绪函数；那么当此 sock 的接收队列 有数据时，系统内核会从 等待队列 取出 等待项（wait_queue_t） ，通过 autoremove_wake_function 唤醒线程（注意，即使是有多个进程都阻塞在同一个 sock 上，也只唤醒 1 个进程，避免惊群。） 对于 epoll + 非阻塞 recv 的模式，上面提到的 等待项（wait_queue_t） 的回调函数变成了 epoll 的 ep_poll_callback ➤ epoll 调用过程如下： （1）调用 epoll_create 创建 epoll 对象： struct eventpoll &#123; //等待队列，阻塞在epoll上的进程会放在这里 wait_queue_head_t wq; //就绪队列，IO就绪的socket连接会放在这里 struct list_head rdllist; //红黑树用来管理所有监听的socket连接 struct rb_root rbr;&#125; 等待队列：区别 sock 对象的等待队列，epoll 的等待队列里，存放是阻塞于 epoll 的进程； 就绪队列：只有就绪的 sock 被放入，这也是比 select 效率高的改进； 红黑树： epoll 监听的所有 sock 连接，都存于红黑树里，对于海量链接，红黑树比数组&amp;链表的性能都更好； epoll 的红黑树中保存的是，fd 作为查找 key ? struct epitem &#123; //指向epoll中对应的红黑树节点 struct rb_node rbn; //指向epoll对象中的就绪队列 struct list_head rdllink; //指向epitem所表示的socket-&gt;file结构以及对应的fd struct epoll_filefd ffd; //指向其所属的eventepoll对象 struct eventpoll *ep; //期待的事件类型 struct epoll_event event; //下一个epitem实例 struct epitem *next;&#125;; （2）调用 epoll_ctl 向添加监听的 Socket： sock 对象的 等待队列中，插入等待项（wait_queue_t 对象），这个等待项的回调函数是 epoll 的 ep_poll_callback，而不再是阻塞模式下的 autoremove_wake_function sock 对象被包装为 epitem 类型，加入红黑树管理； （3）调用 epoll_wait 同步阻塞： 用户代码调用 epoll_wait 后，内核首先会查找 epoll 中的就绪队列（rdllist）是否有 IO 就绪的 sock； 如果就绪队列（rdllist）没有就绪的 sock，那么会向 epoll 的等待队列中插入当前用户进程的信息，此等待项（wait_queue_t）的回调是 default_wake_function，然后用户进程让出 CPU，进入阻塞； ➤ sock 的接收队列有数据可读时： 内核调用此 sock 等待队列上等待项的回调函数，这里是 epoll 的 ep_poll_callback，此函数中，把就绪的 sock 插入到 epoll 的就绪队列（rdllist）中 随后查看 epoll 中的等待队列中是否有等待项，也就是说查看是否有进程阻塞在 epoll_wait 上，如果没有等待项，则软中断处理完成。 如果有等待项，则回到注册在等待项中的回调函数 default_wake_function,在回调函数中唤醒 阻塞进程，并将就绪队列 rdllist 中的 epitem 的 IO就绪 socket 信息封装到 struct epoll_event 中返回。 用户进程拿到 epoll_event，取出就绪的socket 下图是 epoll 等待数据到来的完整工作流程： ➤ 为什么是红黑树？ 这里我们再聊聊为啥要用红黑树，很多人说是因为效率高。其实我觉得这个解释不够全面，要说查找效率树哪能比的上 HASHTABLE。我个人认为觉得更为合理的一个解释是为了让 epoll 在查找效率、插入效率、内存开销等等多个方面比较均衡，最后发现最适合这个需求的数据结构是红黑树。 图解 | 深入揭秘 epoll 是如何实现 IO 多路复用的！ 聊聊Netty那些事儿之从内核角度看IO模型 水平触发和边缘触发再谈水平触发（LT）和边缘触发（ET）： 网上有大量的关于这两种模式的讲解，大部分讲的比较模糊，感觉只是强行从概念上进行描述，看完让人难以理解。所以在这里，笔者想结合上边 epoll 的工作过程，再次对这两种模式做下自己的解读，力求清晰的解释出这两种工作模式的异同。 水平触发和边缘触发最关键的区别就在于 当 socket 中的接收缓冲区还有数据可读时。epoll_wait 是否会清空 rdllist。 水平触发（LT）：在这种模式下，用户线程调用 epoll_wait 获取到 IO 就绪的 socket 后，对 Socket 进行系统 IO 调用读取数据，假设 socket 中的数据只读了一部分没有全部读完，用户再次调用 epoll_wait 不会直接清空 rdllist，而是 epoll_wait 会检查这些 Socket 中的接收缓冲区是否还有数据可读，如果还有数据可读，就将 socket 重新放回 rdllist。所以当 socket 上的 IO 没有被处理完时，再次调用 epoll_wait 依然可以获得这些 socket，用户进程可以接着处理 socket 上的 IO 事件。 边缘触发（ET）： 在这种模式下，用户再次 epoll_wait 就会直接清空 rdllist，不管 socket 上是否还有数据可读。所以在边缘触发模式下，当你没有来得及处理 socket 接收缓冲区的剩下可读数据时，再次调用 epoll_wait，因为这时 rdlist 已经被清空了，socket 不会再次从 epoll_wait 中返回，所以用户进程就不会再次获得这个 socket 了，也就无法在对它进行 IO 处理了。除非，这个 socket 上有新的 IO 数据到达，根据 epoll 的工作过程，该 socket 会被再次放入 rdllist 中。 如果你在边缘触发模式下，处理了部分 socket 上的数据，那么想要处理剩下部分的数据，就只能等到这个 socket 上再次有网络数据到达。 在 Netty 中实现的 EpollSocketChannel 默认的就是边缘触发模式。JDK 的 NIO 默认是水平触发模式。 epoll 默认也是 LT https://stackoverflow.com/questions/24400941/how-do-we-know-whether-call-to-epoll-wait-is-edge-triggered-or-level-triggered @ref: 聊聊Netty那些事儿之从内核角度看IO模型 比较 ET 和 LT 的性能： 如果数据处理和 epoll 同一线程，LT 和 ET 区别不大，如果用 LT 会从 epoll_wait 醒来更频繁，对消息处理时效性更好； 如果数据处理和 epoll 不在同一线程（例如更高并发的 RPC 实现中, 为了对大消息的反序列化也可以并行），这种情况下，如果数据处理的线程池被打满，那么 epoll_wait 所在的线程就会陷入疯狂的旋转（醒来-没有空闲的线程可以处理数据-再次 wait-唤醒），而 ET 是有消息来时才触发，和及时处理与否无关，频率低很多。 @ref: epoll的边沿触发模式(ET)真的比水平触发模式(LT)快吗？(当然LT模式也使用非阻塞IO，重点是要求ET模式下的代码不能造成饥饿) - 知乎 水平触发（LT）和边缘触发（ET）名字的来历？： 为了弄明白 LT（Level Triggered，水平触发） 和 ET（Edge Triggered，边沿触发），我们先要了解，这个 Level 和 Edge 是什么涵义，Level 翻译成中文这里准确的涵义应该是电平； Edge 是边沿。 这两个词曾经是电子信号领域的一个专有名词。如果，用时序图来标示一个数字电信号“010”，应该是类似下图所示： 低电平表示0，高电平表示1 0向1变化的竖线就是上升沿，1向0变化的竖线就是下降沿 在0或者1的情况下触发的信号就是 LT（Level Triggered，水平触发） 在0向1、1向0变化的过程中触发的信号就是 和 ET（Edge Triggered，边沿触发） 0或1都是一个状态，在 epoll 中，0表示缓冲区无数据，1表示缓冲区有数据，从无数据→有数据即上升沿，也即边缘触发（ET），我们很直观的就可以得出结论，LT 是一个持续的状态，ET 是个事件性的一次性状态。 二者的差异在于： Level Triggered 模式下只要某个 socket 处于 readable/writable 状态，无论什么时候进行 epoll_wait 都会返回该 socket； 而 Edge Triggered 模式下只有某个 socket 从 unreadable 变为 readable 或从 unwritable 变为 writable 时，epoll_wait 才会返回该 socket。 https://zhuanlan.zhihu.com/p/20315482 epoll examplehttps://github.com/onestraw/epoll-example/blob/master/epoll.c listen_sock = socket(AF_INET, SOCK_STREAM, 0);set_sockaddr(&amp;srv_addr);bind(listen_sock, (struct sockaddr *)&amp;srv_addr, sizeof(srv_addr));setnonblocking(listen_sock);listen(listen_sock, MAX_CONN);epfd = epoll_create(1);epoll_ctl_add(epfd, listen_sock, EPOLLIN | EPOLLOUT | EPOLLET);socklen = sizeof(cli_addr);for (;;) &#123; nfds = epoll_wait(epfd, events, MAX_EVENTS, -1); for (i = 0; i &lt; nfds; i++) &#123; if (events[i].data.fd == listen_sock) &#123; /* handle new connection */ conn_sock = accept(listen_sock, (struct sockaddr *)&amp;cli_addr, &amp;socklen); inet_ntop(AF_INET, (char *)&amp;(cli_addr.sin_addr), buf, sizeof(cli_addr)); printf(\"[+] connected with %s:%d\\n\", buf, ntohs(cli_addr.sin_port)); setnonblocking(conn_sock); epoll_ctl_add(epfd, conn_sock, EPOLLIN | EPOLLET | EPOLLRDHUP | EPOLLHUP); &#125; else if (events[i].events &amp; EPOLLIN) &#123; /* handle EPOLLIN event */ for (;;) &#123; bzero(buf, sizeof(buf)); n = read(events[i].data.fd, buf, sizeof(buf)); if (n &lt;= 0 /* || errno == EAGAIN */ ) &#123; break; &#125; else &#123; printf(\"[+] data: %s\\n\", buf); write(events[i].data.fd, buf, strlen(buf)); &#125; &#125; &#125; else &#123; printf(\"[+] unexpected\\n\"); &#125; /* check if the connection is closing */ if (events[i].events &amp; (EPOLLRDHUP | EPOLLHUP)) &#123; printf(\"[+] connection closed\\n\"); epoll_ctl(epfd, EPOLL_CTL_DEL, events[i].data.fd, NULL); close(events[i].data.fd); continue; &#125; &#125;&#125;","categories":[{"name":"21.Operating-System","slug":"21-Operating-System","permalink":"https://beefyheisenberg.github.io/categories/21-Operating-System/"}],"tags":[]},{"title":"APUE.07a::网络编程API","slug":"21.Operating-System/APUE.07a.网络编程API","date":"2024-01-24T01:27:52.434Z","updated":"2024-01-24T01:27:52.435Z","comments":true,"path":"21.Operating-System/APUE.07a.网络编程API/","link":"","permalink":"https://beefyheisenberg.github.io/21.Operating-System/APUE.07a.网络编程API/","excerpt":"socketint socket(int protofamily, int type, int protocol);//返回sockfd socket 函数的三个参数分别为： protofamily：即协议域，又称为协议族（family）。常用的协议族有，AF_INET(IPV4)、AF_INET6(IPV6)、AF_LOCAL（或称AF_UNIX，Unix域socket）、AF_ROUTE等等。协议族决定了socket的地址类型，在通信中必须采用对应的地址，如AF_INET决定了要用ipv4地址（32位的）与端口号（16位的）的组合、AF_UNIX决定了要用一个绝对路径名作为地址。 type：指定socket类型。常用的socket类型有，SOCK_STREAM、SOCK_DGRAM、SOCK_RAW、SOCK_PACKET、SOCK_SEQPACKET等等。 protocol：就是指定协议。常用的协议有，IPPROTO_TCP、IPPTOTO_UDP、IPPROTO_SCTP、IPPROTO_TIPC等，它们分别对应TCP传输协议、UDP传输协议、STCP传输协议、TIPC传输协议（这个协议我将会单独开篇讨论！）。 注意：并不是上面的type和protocol可以随意组合的，如SOCK_STREAM不可以跟IPPROTO_UDP组合。当protocol为0时，会自动选择type类型对应的默认协议。","text":"socketint socket(int protofamily, int type, int protocol);//返回sockfd socket 函数的三个参数分别为： protofamily：即协议域，又称为协议族（family）。常用的协议族有，AF_INET(IPV4)、AF_INET6(IPV6)、AF_LOCAL（或称AF_UNIX，Unix域socket）、AF_ROUTE等等。协议族决定了socket的地址类型，在通信中必须采用对应的地址，如AF_INET决定了要用ipv4地址（32位的）与端口号（16位的）的组合、AF_UNIX决定了要用一个绝对路径名作为地址。 type：指定socket类型。常用的socket类型有，SOCK_STREAM、SOCK_DGRAM、SOCK_RAW、SOCK_PACKET、SOCK_SEQPACKET等等。 protocol：就是指定协议。常用的协议有，IPPROTO_TCP、IPPTOTO_UDP、IPPROTO_SCTP、IPPROTO_TIPC等，它们分别对应TCP传输协议、UDP传输协议、STCP传输协议、TIPC传输协议（这个协议我将会单独开篇讨论！）。 注意：并不是上面的type和protocol可以随意组合的，如SOCK_STREAM不可以跟IPPROTO_UDP组合。当protocol为0时，会自动选择type类型对应的默认协议。 当我们调用socket创建一个 socket 时，返回的 socket 描述字它存在于协议族（address family，AF_XXX）空间中，但没有一个具体的地址。如果想要给它赋值一个地址，就必须调用 bind()函数，否则就当调用 connect()、listen()时系统会自动随机分配一个端口。 bindint bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 函数的三个参数分别为： sockfd：即socket描述字，它是通过socket()函数创建了，唯一标识一个socket。bind()函数就是将给这个描述字绑定一个名字。 addr：一个const struct sockaddr *指针，指向要绑定给sockfd的协议地址。这个地址结构根据地址创建socket时的地址协议族的不同而不同，如ipv4对应的是： struct sockaddr_in &#123; sa_family_t sin_family; /* address family: AF_INET */ in_port_t sin_port; /* port in network byte order */ struct in_addr sin_addr; /* internet address */&#125;; /* Internet address. */struct in_addr &#123; uint32_t s_addr; /* address in network byte order */&#125;; ipv6对应的是： struct sockaddr_in6 &#123; sa_family_t sin6_family; /* AF_INET6 */ in_port_t sin6_port; /* port number */ uint32_t sin6_flowinfo; /* IPv6 flow information */ struct in6_addr sin6_addr; /* IPv6 address */ uint32_t sin6_scope_id; /* Scope ID (new in 2.4) */ &#125;; struct in6_addr &#123; unsigned char s6_addr[16]; /* IPv6 address */ &#125;; Unix域对应的是： #define UNIX_PATH_MAX 108struct sockaddr_un &#123; sa_family_t sun_family; /* AF_UNIX */ char sun_path[UNIX_PATH_MAX]; /* pathname */ &#125;; addrlen：对应的是地址的长度。 listenint listen(int sockfd, int backlog); listen 函数的第一个参数即为要监听的 socket 描述字，第二个参数为相应 socket 的全连接队列大小 acceptint accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen); //返回连接connect_fd 参数 sockfd：参数 sockfd 就是上面解释中的监听套接字，这个套接字用来监听一个端口，当有一个客户与服务器连接时，它使用这个一个端口号，而此时这个端口号正与这个套接字关联。当然客户不知道套接字这些细节，它只知道一个地址和一个端口号。 参数 addr：这是一个结果参数，它用来接受一个返回值，这返回值指定客户端的地址，当然这个地址是通过某个地址结构来描述的，用户应该知道这一个什么样的地址结构。如果对客户的地址不感兴趣，那么可以把这个值设置为 NULL。 accept 默认会阻塞进程，直到有一个客户连接建立后返回，它返回的是一个新可用的套接字，这个套接字是连接套接字。 监听套接字: 监听套接字正如 accept 的参数 sockfd，它是监听套接字，在调用 listen 函数之后，是服务器开始调用 socket()函数生成的，称为监听 socket 描述字(监听套接字) 连接套接字： accept 函数返回的是已连接 socket 描述字(一个连接套接字)，accept 内部做的是从全连接队列取出一个套接字并返回给用户态。 connectint connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen); send &amp; recvsocket 提供了下面几组读写函数： read()/write() recv()/send() readv()/writev() recvmsg()/sendmsg() recvfrom()/sendto() #include &lt;unistd.h&gt; ssize_t read(int fd, void *buf, size_t count);ssize_t write(int fd, const void *buf, size_t count); #include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt; ssize_t send(int sockfd, const void *buf, size_t len, int flags);ssize_t recv(int sockfd, void *buf, size_t len, int flags);ssize_t sendto(int sockfd, const void *buf, size_t len, int flags,const struct sockaddr *dest_addr, socklen_t addrlen);ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags,struct sockaddr *src_addr, socklen_t *addrlen); ssize_t sendmsg(int sockfd, const struct msghdr *msg, int flags);ssize_t recvmsg(int sockfd, struct msghdr *msg, int flags); close#include &lt;unistd.h&gt;int close(int fd); close 一个 TCP socket 的缺省行为时把该 socket 标记为以关闭，然后立即返回到调用进程。该描述字不能再由调用进程使用，也就是说不能再作为 read 或 write 的第一个参数。 close操作只是使相应socket描述字的引用计数-1，只有当引用计数为0的时候，才会触发TCP客户端向服务器发送终止连接请求。 网络字节序 &amp; 主机字节序 主机字节序就是我们平常说的大端和小端模式：不同的CPU有不同的字节序类型，这些字节序是指整数在内存中保存的顺序，这个叫做主机序。引用标准的Big-Endian和Little-Endian的定义如下： Little-Endian 就是低位字节排放在内存的低地址端，高位字节排放在内存的高地址端。 Big-Endian 就是高位字节排放在内存的低地址端，低位字节排放在内存的高地址端。 网络字节序：4个字节的32 bit 值以下面的次序传输：首先是0～7bit，其次8～15bit，然后16～23bit，最后是24~31bit。这种传输次序称作大端字节序。由于 TCP/IP 首部中所有的二进制整数在网络中传输时都要求以这种次序，因此它又称作网络字节序。 字节序，顾名思义字节的顺序，就是大于一个字节类型的数据在内存中的存放顺序，一个字节的数据没有顺序的问题了。 所以：在将一个地址绑定到socket的时候，请先将主机字节序转换成为网络字节序，而不要假定主机字节序跟网络字节序一样使用的是Big-Endian。由于这个问题曾引发过血案！公司项目代码中由于存在这个问题，导致了很多莫名其妙的问题，所以请谨记对主机字节序不要做任何假定，务必将其转化为网络字节序再赋给socket。","categories":[{"name":"21.Operating-System","slug":"21-Operating-System","permalink":"https://beefyheisenberg.github.io/categories/21-Operating-System/"}],"tags":[]},{"title":"APUE.06a::线程","slug":"21.Operating-System/APUE.06a.线程","date":"2024-01-24T01:27:52.430Z","updated":"2024-01-24T01:27:52.430Z","comments":true,"path":"21.Operating-System/APUE.06a.线程/","link":"","permalink":"https://beefyheisenberg.github.io/21.Operating-System/APUE.06a.线程/","excerpt":"","text":"","categories":[{"name":"21.Operating-System","slug":"21-Operating-System","permalink":"https://beefyheisenberg.github.io/categories/21-Operating-System/"}],"tags":[]},{"title":"APUE.05a::信号","slug":"21.Operating-System/APUE.05a.信号","date":"2024-01-24T01:27:52.426Z","updated":"2024-01-24T01:27:52.426Z","comments":true,"path":"21.Operating-System/APUE.05a.信号/","link":"","permalink":"https://beefyheisenberg.github.io/21.Operating-System/APUE.05a.信号/","excerpt":"Linux 支持的全部信号 kill -l 可以查看所有支持的信号和其对应值： Linux 共有 64 种信号，前 32 种为不可靠信号，后 32 种为可靠信号。 信号 值 类型 说明 SIGHUP 1 Term 终端控制进程结束(终端连接断开) SIGINT 2 Term 用户发送 INTR 字符(Ctrl+C)触发 SIGQUIT 3 Core 用户发送 QUIT 字符(Ctrl+/)触发 SIGILL 4 Core 非法指令(程序错误、试图执行数据段、栈溢出等) SIGABRT 6 Core 调用 abort 函数触发 SIGFPE 8 Core 算术运行错误(浮点运算错误、除数为零等) SIGKILL 9 Term 无条件结束程序(不能被捕获、阻塞或忽略) SIGSEGV 11 Core 无效内存引用(试图访问不属于自己的内存空间、对只读内存空间进行写操作) SIGPIPE 13 Term 消息管道损坏(FIFO/Socket 通信时，管道未打开而进行写操作) SIGALRM 14 Term 时钟定时信号 SIGTERM 15 Term 结束程序(可以被捕获、阻塞或忽略) SIGUSR1 30,10,16 Term 用户保留 SIGUSR2 31,12,17 Term 用户保留 SIGCHLD 20,17,18 Ign 子进程结束(由父进程接收) SIGCONT 19,18,25 Cont 继续执行已经停止的进程(不能被阻塞) SIGSTOP 17,19,23 Stop 停止进程(不能被捕获、阻塞或忽略) SIGTSTP 18,20,24 Stop 停止进程(可以被捕获、阻塞或忽略) SIGTTIN 21,21,26 Stop 后台程序从终端中读取数据时触发 SIGTTOU 22,22,27 Stop 后台程序向终端中写数据时触发 SIGTRAP 5 Core Trap 指令触发(如断点，在调试器中使用) SIGBUS 0,7,10 Core 非法地址(内存地址对齐错误) SIGPOLL Term Pollable event (Sys V). Synonym for SIGIO SIGPROF 27,27,29 Term 性能时钟信号(包含系统调用时间和进程占用 CPU 的时间) SIGSYS 12,31,12 Core 无效的系统调用(SVr4) SIGURG 16,23,21 Ign 有紧急数据到达 Socket(4.2BSD) SIGVTALRM 26,26,28 Term 虚拟时钟信号(进程占用 CPU 的时间)(4.2BSD) SIGXCPU 24,24,30 Core 超过 CPU 时间资源限制(4.2BSD) SIGXFSZ 25,25,31 Core 超过文件大小资源限制(4.2BSD) 信号的分类：","text":"Linux 支持的全部信号 kill -l 可以查看所有支持的信号和其对应值： Linux 共有 64 种信号，前 32 种为不可靠信号，后 32 种为可靠信号。 信号 值 类型 说明 SIGHUP 1 Term 终端控制进程结束(终端连接断开) SIGINT 2 Term 用户发送 INTR 字符(Ctrl+C)触发 SIGQUIT 3 Core 用户发送 QUIT 字符(Ctrl+/)触发 SIGILL 4 Core 非法指令(程序错误、试图执行数据段、栈溢出等) SIGABRT 6 Core 调用 abort 函数触发 SIGFPE 8 Core 算术运行错误(浮点运算错误、除数为零等) SIGKILL 9 Term 无条件结束程序(不能被捕获、阻塞或忽略) SIGSEGV 11 Core 无效内存引用(试图访问不属于自己的内存空间、对只读内存空间进行写操作) SIGPIPE 13 Term 消息管道损坏(FIFO/Socket 通信时，管道未打开而进行写操作) SIGALRM 14 Term 时钟定时信号 SIGTERM 15 Term 结束程序(可以被捕获、阻塞或忽略) SIGUSR1 30,10,16 Term 用户保留 SIGUSR2 31,12,17 Term 用户保留 SIGCHLD 20,17,18 Ign 子进程结束(由父进程接收) SIGCONT 19,18,25 Cont 继续执行已经停止的进程(不能被阻塞) SIGSTOP 17,19,23 Stop 停止进程(不能被捕获、阻塞或忽略) SIGTSTP 18,20,24 Stop 停止进程(可以被捕获、阻塞或忽略) SIGTTIN 21,21,26 Stop 后台程序从终端中读取数据时触发 SIGTTOU 22,22,27 Stop 后台程序向终端中写数据时触发 SIGTRAP 5 Core Trap 指令触发(如断点，在调试器中使用) SIGBUS 0,7,10 Core 非法地址(内存地址对齐错误) SIGPOLL Term Pollable event (Sys V). Synonym for SIGIO SIGPROF 27,27,29 Term 性能时钟信号(包含系统调用时间和进程占用 CPU 的时间) SIGSYS 12,31,12 Core 无效的系统调用(SVr4) SIGURG 16,23,21 Ign 有紧急数据到达 Socket(4.2BSD) SIGVTALRM 26,26,28 Term 虚拟时钟信号(进程占用 CPU 的时间)(4.2BSD) SIGXCPU 24,24,30 Core 超过 CPU 时间资源限制(4.2BSD) SIGXFSZ 25,25,31 Core 超过文件大小资源限制(4.2BSD) 信号的分类： Type Desc Term Default action is to terminate the process. Ign Default action is to ignore the signal. Core Default action is to terminate the process and dump core (see core(5)). Stop Default action is to stop the process. Cont Default action is to continue the process if it is currently stopped. 产生信号的几种方式 用户按键产生信号, 运行在 shell 终端的进程，通过键盘输入某些组合键给进程发送信号: Ctrl-C : SIGINT, 中断(Interrupt), 只能向前台进程发送, 可忽略 Ctrl-\\ : SIGQUIT, 退出(Quit), 可忽略 Ctrl-Z : SIGSTP, 停止(Stop), 挂起的进程可以 fg 恢复 硬件产生信号 除 0: SIGFPE, CPU 运算单元产生异常并发送给进程, 内存非法访问: SIGSEGV, 内存控制单元 MMU 产生 通过 kill() 函数产生信号 kill : SIGTERM, 可被忽略 kill -2 : SIGINT, 同 Ctrl-C kill -9 : SIGKILL, 不可忽略, 但导致进程无法完成清理? kill -17 : SIGCHLD, 子进程死掉, 系统会向父进程发生 SIGCHLD 信号, 父进程可以选择是否处理 SIGCHLD: 子进程死掉, 系统会向父进程发生 SIGCHLD 信号, 父进程可以选择是否处理 SIGHUP: 在终端启动一个回话(session), 在这个终端里再启动的命令, 都是这个回话的子进程, 如果回话进程关闭, SIGHUP 会被发送到所有子进程 … ➤ 区分 Ctrl+z 和 Ctrl+c 的不同： Ctrl+z 产生 SIGTSTP (挂起进程),但还未结束. 进程收到 SIGTSTP 后, 用 bg 1 可以让被挂起的程序在后台继续执行, 命令中的”1”是 job(作业号); 命令 fg 1 重新让进程切换到前台运行. 命令 jobs 查看在后台运行的任务. Ctrl+c 产生 SIGINT (中断进程) 信号 一些常用信号➤ kill 和 kill -9的区别： kill -9是发送SIGKILL信号给进程，不支持被捕获和忽略，会导致进程直接退出。 kill 等价于 kill -15, 是发送 SIGTERM 信号给进程，可以被捕获和忽略，可以实现让进程优雅退出。 ➤ SIGHUP 信号 SIGHUP信号在用户终端连接(正常或非正常)结束时发出。SIGHUP信号的默认处理是终止收到该信号的进程。所以若程序中没有捕捉该信号，当收到该信号时，进程就会退出。 终端关闭时，操作系统会向与其关联的进程组发送 SIGHUP 信号。 session首进程退出时(如远程ssh登录),该信号会发送给与会话关联的各个进程。 如果父进程退出导致子进程称为孤儿进程，且该进程组中有进程处于停止状态。该信号会被发送到该进程组中的每一个进程。 对于 SIGHUP 信号，使用 nohup xxx &amp; 可以让终端退出后不发送 SIGHUP 信号，使其成为常驻进程。 Linux环境进程间通信（二）: 信号（上） @Archived Linux环境进程间通信（二）: 信号（下） @Archived","categories":[{"name":"21.Operating-System","slug":"21-Operating-System","permalink":"https://beefyheisenberg.github.io/categories/21-Operating-System/"}],"tags":[]},{"title":"APUE.04a::进程通信(IPC)","slug":"21.Operating-System/APUE.04a.进程通信(IPC)","date":"2024-01-24T01:27:52.422Z","updated":"2024-01-24T01:27:52.422Z","comments":true,"path":"21.Operating-System/APUE.04a.进程通信(IPC)/","link":"","permalink":"https://beefyheisenberg.github.io/21.Operating-System/APUE.04a.进程通信(IPC)/","excerpt":"@ref 深刻理解Linux进程间通信（IPC） 进程间通信（IPC，InterProcess Communication）:Linux 下的进程通信手段基本上是从 Unix 平台上的进程通信手段继承而来的。而对 Unix 发展做出重大贡献的两大主力 AT&amp;T 的贝尔实验室及 BSD（加州大学伯克利分校的伯克利软件发布中心）在进程间通信方面的侧重点有所不同。前者对 Unix 早期的进程间通信手段进行了系统的改进和扩充，形成了“system V IPC”，通信进程局限在单个计算机内；后者则跳过了该限制，形成了基于套接口（socket）的进程间通信机制。Linux 则把两者继承了下来，如图示： 最初 Unix IPC 包括：管道、FIFO、信号；System V IPC 包括：System V 消息队列、System V 信号灯、System V 共享内存区；Posix IPC 包括： Posix 消息队列、Posix 信号灯、Posix 共享内存区。 这里主要介绍 POSIX 标准的 IPC:","text":"@ref 深刻理解Linux进程间通信（IPC） 进程间通信（IPC，InterProcess Communication）:Linux 下的进程通信手段基本上是从 Unix 平台上的进程通信手段继承而来的。而对 Unix 发展做出重大贡献的两大主力 AT&amp;T 的贝尔实验室及 BSD（加州大学伯克利分校的伯克利软件发布中心）在进程间通信方面的侧重点有所不同。前者对 Unix 早期的进程间通信手段进行了系统的改进和扩充，形成了“system V IPC”，通信进程局限在单个计算机内；后者则跳过了该限制，形成了基于套接口（socket）的进程间通信机制。Linux 则把两者继承了下来，如图示： 最初 Unix IPC 包括：管道、FIFO、信号；System V IPC 包括：System V 消息队列、System V 信号灯、System V 共享内存区；Posix IPC 包括： Posix 消息队列、Posix 信号灯、Posix 共享内存区。 这里主要介绍 POSIX 标准的 IPC: 管道（Pipe）及有名管道（named pipe）：管道可用于具有亲缘关系进程间的通信，有名管道克服了管道没有名字的限制，因此，除具有管道所具有的功能外，它还允许无亲缘关系进程间的通信； 报文（Message）队列（消息队列）：消息队列是消息的链接表，包括 Posix 消息队列 system V 消息队列。有足够权限的进程可以向队列中添加消息，被赋予读权限的进程则可以读走队列中的消息。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。 共享内存：使得多个进程可以访问同一块内存空间，是最快的可用 IPC 形式。是针对其他通信机制运行效率较低而设计的。往往与其它通信机制，如信号量结合使用，来达到进程间的同步及互斥。 信号量（semaphore）：主要作为进程间以及同一进程不同线程之间的同步手段。 套接字（Socket）：更为一般的进程间通信机制，可用于不同机器之间的进程间通信。起初是由 Unix 系统的 BSD 分支开发出来的，但现在一般可以移植到其它类 Unix 系统上：Linux 和 System V 的变种都支持套接字。 信号（Signal）：信号是比较复杂的通信方式，用于通知接受进程有某种事件发生，除了用于进程间通信外，进程还可以发送信号给进程本身；linux 除了支持 Unix 早期信号语义函数 sigal 外，还支持语义符合 Posix.1 标准的信号函数 sigaction（实际上，该函数是基于 BSD 的，BSD 为了实现可靠信号机制，又能够统一对外接口，用 sigaction 函数重新实现了 signal 函数）； 管道Linux的进程间通信：管道(转) - 简书 Linux 上的管道分两种类型： 匿名管道、命名管道 匿名管道(PIPE): 最常见的形态就是我们在 shell 操作中最常用的”|” 只能在父子进程中使用 系统调用: int pipe(int pipefd[2]) 命名管道(FIFO): 命名管道在底层的实现跟匿名管道完全一致，区别只是命名管道会有一个全局可见的文件名以供别人 open 打开使用 系统调用: int mkfifo(const char *pathname, mode_t mode) 共享内存 Linux环境进程间通信（五）: 共享内存（上） Linux环境进程间通信（五）: 共享内存（下）","categories":[{"name":"21.Operating-System","slug":"21-Operating-System","permalink":"https://beefyheisenberg.github.io/categories/21-Operating-System/"}],"tags":[]},{"title":"APUE.03b::进程的虚拟内存管理","slug":"21.Operating-System/APUE.03b.进程的虚拟内存管理","date":"2024-01-24T01:27:52.418Z","updated":"2024-01-24T01:27:52.418Z","comments":true,"path":"21.Operating-System/APUE.03b.进程的虚拟内存管理/","link":"","permalink":"https://beefyheisenberg.github.io/21.Operating-System/APUE.03b.进程的虚拟内存管理/","excerpt":"@todo： OneNote 笔记 copy 过来（内核如何使用 task_struct -&gt; mm_struct 管理进程内存布局） 进程的内存布局（32位）在32位 Linux 系统中，每个进程都有4GB 的虚拟地址空间，其中0-3GB 是用户空间，3-4GB 是内核空间。每个进程都以为自己独占整个4GB 的地址空间，但实际上1GB 的内核空间是所有进程共享的，独占的3GB 用户空间也只是虚拟的。 +---+--------------------+---------------------- 0xFFFF FFFF 高地址1 GB | Kernel | 内核空间 +------------------------+---------------------- 0xC000 0000 | | Random stack offset| 用户空间 ↓ | +--------------------+ | | Stack↓ | 进程中的所有的线程共享相同的地址空间 | | | | +--------------------+ | | | | | | | +--------------------+ | | Mem Mapping ↓ | 文件映射,动态链接库（.so文件） | | | mmap() | +--------------------+ + | |3 GB | | + +--------------------+ | | Heap↑ | 用户通过 malloc()分配的内存 | | | | +--------------------+ | | Random stack offset| | +--------------------+ | | BSS Seg. | | +--------------------+ | | Data Seg. (+rodata)| | +--------------------+ | | Text Seg. | 用户空间 ↑ +---+--------------------+---------------------- 0x00000000 低地址 内存布局从高地址到低地址:","text":"@todo： OneNote 笔记 copy 过来（内核如何使用 task_struct -&gt; mm_struct 管理进程内存布局） 进程的内存布局（32位）在32位 Linux 系统中，每个进程都有4GB 的虚拟地址空间，其中0-3GB 是用户空间，3-4GB 是内核空间。每个进程都以为自己独占整个4GB 的地址空间，但实际上1GB 的内核空间是所有进程共享的，独占的3GB 用户空间也只是虚拟的。 +---+--------------------+---------------------- 0xFFFF FFFF 高地址1 GB | Kernel | 内核空间 +------------------------+---------------------- 0xC000 0000 | | Random stack offset| 用户空间 ↓ | +--------------------+ | | Stack↓ | 进程中的所有的线程共享相同的地址空间 | | | | +--------------------+ | | | | | | | +--------------------+ | | Mem Mapping ↓ | 文件映射,动态链接库（.so文件） | | | mmap() | +--------------------+ + | |3 GB | | + +--------------------+ | | Heap↑ | 用户通过 malloc()分配的内存 | | | | +--------------------+ | | Random stack offset| | +--------------------+ | | BSS Seg. | | +--------------------+ | | Data Seg. (+rodata)| | +--------------------+ | | Text Seg. | 用户空间 ↑ +---+--------------------+---------------------- 0x00000000 低地址 内存布局从高地址到低地址: Kernel: 内核空间在页表中拥有较高的特权级（ring 2或以下）, 因此只要用户态的程序试图访问这些页, 就会导致一个页错误（page fault）, 用户程序不可访问内核页 Stack: 自高地址向低地址增长, 每个进程都有一个自己的栈, 当不断压栈直到超过了最大的栈空间, 将会引起Stack Overflow, 进程中的每一个线程都有属于自己的栈 Memory Mapping Segment: mmap()实现”文件-内存映射”, 它被用于加载动态库, 大多数实际的malloc实现会考虑通过mmap分配较大块的内存区域, 这个区域自高地址向低地址增长 Heap: malloc()分配的内存空间, 如果堆中有足够的空间来满足内存请求, 它就可以被语言运行时库处理而不需要内核参与. 否则堆会被扩大, 通过brk()系统调用来分配请求所需的内存块, 堆自低地址向高地址增长 BSS Segment: 未赋初始值的static变量, 包括全局的static变量和函数内定义的static变量(全局变量默认就是static) Data Segment: 有初始值的static变量, 程序bin映像的一部分 还包括一个叫 rodata 的区域, 存储”字面量字符串”(包括全局/局部定义的字面量字符串), 以及”const 常量” Text Segment: 这里存放的是二进制代码 C 代码中的 const、static 在 Data Segment 的存储细节，解释参考 GNU的obj分析工具的使用 - nm/objdump | 扔掉笔记 ᐛ 其中高地址的 1GB Kernel Space 结构如下（左边）： 进程的内存布局（64位） 64位架构下内存布局与32位类似, 可寻址64TB(Intel架构下是46个地址线, 2^46) How to 查看某个进程的内存分布命令行：cat /proc/xxx/maps","categories":[{"name":"21.Operating-System","slug":"21-Operating-System","permalink":"https://beefyheisenberg.github.io/categories/21-Operating-System/"}],"tags":[]},{"title":"APUE.03a::进程","slug":"21.Operating-System/APUE.03a.进程","date":"2024-01-24T01:27:52.411Z","updated":"2024-01-24T01:27:52.412Z","comments":true,"path":"21.Operating-System/APUE.03a.进程/","link":"","permalink":"https://beefyheisenberg.github.io/21.Operating-System/APUE.03a.进程/","excerpt":"创建进程fork 返回0: 子进程 返回&gt;0: 父进程, 返回值是子进程pid 子进程会得到父进程的堆(IO缓存, malloc的内存)、栈(局部变量)、数据空间(Data Segment)的拷贝, 在子进程里修改这些变量并不会影响父进程中的值, 注意这种拷贝是“写时复制”（Copy On Write，COW）; fork前打开的文件句柄, 其偏移量会在父子进程间共享, 原因是进程内存中仅保存了文件句柄的fd指针, 指针指向的结构体(也就是文件表,保存了文件标准和位移)是共享的. @doubt 那么”文件表”是存储在哪里的? 另外需要注意的是, 因为堆内存也将被拷贝(IO缓存在堆里), 所以如果在创建子进程之前这个IO缓存中就有数据, 那么也会带入子进程, 导致子进程的IO缓存里”多”出一些数据. int main()&#123; // child process because return value zero if (fork() == 0) &#123; printf(\"Hello from Child!\\n\"); &#125; // parent process because return value non-zero. else &#123; printf(\"Hello from Parent!\\n\"); &#125; return 0;&#125; vfork","text":"创建进程fork 返回0: 子进程 返回&gt;0: 父进程, 返回值是子进程pid 子进程会得到父进程的堆(IO缓存, malloc的内存)、栈(局部变量)、数据空间(Data Segment)的拷贝, 在子进程里修改这些变量并不会影响父进程中的值, 注意这种拷贝是“写时复制”（Copy On Write，COW）; fork前打开的文件句柄, 其偏移量会在父子进程间共享, 原因是进程内存中仅保存了文件句柄的fd指针, 指针指向的结构体(也就是文件表,保存了文件标准和位移)是共享的. @doubt 那么”文件表”是存储在哪里的? 另外需要注意的是, 因为堆内存也将被拷贝(IO缓存在堆里), 所以如果在创建子进程之前这个IO缓存中就有数据, 那么也会带入子进程, 导致子进程的IO缓存里”多”出一些数据. int main()&#123; // child process because return value zero if (fork() == 0) &#123; printf(\"Hello from Child!\\n\"); &#125; // parent process because return value non-zero. else &#123; printf(\"Hello from Parent!\\n\"); &#125; return 0;&#125; vfork 返回值同 fork 不同点1: vfork创建的子进程与父进程共享数据段, 在子进程中修改变量也会影响到父进程中的变量 不同点2: vfork的子进程优先于父进程执行, 当子进程明确_exit() 或者exit()之后, 父进程才会继续执行. cloneclone可以看成是fork的升级版, 不仅可以创建进程或者线程, 还可以指定创建新的命名空间（namespace）、有选择的继承父进程的内存、甚至可以将创建出来的进程变成父进程的兄弟进程等等 int clone(int (*fn)(void *), void *child_stack, int flags, void *arg); 终止进程 正常三种: return 语句, exit() 或 _exit(), 非正常: abort(), 调用该函数之后, 调用者会收到 SIGABRT wait/waitpid pit_t wait(int *status): 父进程调用后立刻阻塞, 直到第一个子进程结束, 子进程结束后系统会发送SGICHLD信号, 收到这个信号后, 父进程从wait返回 pid_t waitpid(pid_t pid, siginfo_t *infop, int options), 等待指定的进程 execfork 或者 vfork之后往往需要再调用 exec启动另一个新程序, 因为 exec不创建新进程, 所以pid不会变, 原程序的 Text Seg, Data Seg, Heap/Stack会被替换 僵尸进程和孤儿进程 僵尸进程(zombie process): ps显示stat为”z”的进程 产生原因: 子进程退出后(exit, 或发生错误), 子进程仍存在于进程表, 当父进程调用wait之后才会从进程表删除. 如果子进程死掉但是父进程没有调用wait, 子进程就变成了僵尸进程; 正确做法: 子进程死后, 系统会向父进程发生SIGCHLD信号, 父进程收到此信号后应该用wait处理子进程; 如果父进程没有处理SIGCHLD信号, 那么只能kill父进程, 让init成为子进程的父进程, init进程会周期性调用wait清理Zombie进程. 处理SIGCHLD信号示例代码: https://docs.oracle.com/cd/E19455-01/806-4750/signals-7/index.html 孤儿进程(orphan process): 父进程死掉, 子进程被init进程接管 守护(Daemon)进程: 守护进程就是后台服务进程, 因为它会有一个很长的生命周期提供服务, 关闭终端不会影响服务, 也就是说可以忽略某些信号 如何实现Deamon进程: 父进程exit command &amp; nohup command 守护进程（daemon）Linux 守护进程原理及实例（Redis、Nginx） - CSDN博客 守护进程不属于任何一个控制终端, 不属于任何一个会话(Session) 守护进程没的父进程是0 @doubt 守护进程会忽略一些signal（包括处理信号SIGHUP（进程和控制终端分离时收到SIGHUP）、 SIGTERM（系统关机之前收到SIGTERM） Namespace@ref: 浅谈Linux Namespace机制（一） - 知乎 [Docker基础技术：Linux Namespace（上） | 酷 壳 - CoolShell] 对于Namespace的操作有以下方式： 可以在进程刚创建的时候通过clone系统调用为新进程分配一个或多个新的Namespace。 通过setns()将进程加入到已有的Namespace中。 通过unshare()为已存在的进程创建一个或多个新的Namespace。","categories":[{"name":"21.Operating-System","slug":"21-Operating-System","permalink":"https://beefyheisenberg.github.io/categories/21-Operating-System/"}],"tags":[]},{"title":"APUE.01a::文件和IO","slug":"21.Operating-System/APUE.01a.文件和IO","date":"2024-01-24T01:27:52.407Z","updated":"2024-01-24T01:27:52.407Z","comments":true,"path":"21.Operating-System/APUE.01a.文件和IO/","link":"","permalink":"https://beefyheisenberg.github.io/21.Operating-System/APUE.01a.文件和IO/","excerpt":"文件系统分层 另一张图，侧重点是编程实体（库、函数）在 Linux 存储中的位置： page cache（页缓冲）","text":"文件系统分层 另一张图，侧重点是编程实体（库、函数）在 Linux 存储中的位置： page cache（页缓冲）@Inbox 缓存 I/O vs 直接 I/O内核将文件的 IO 操作根据是否使用内核缓冲区（页高速缓存 page cache），将文件 IO 分为：Buffered IO 和 Direct IO 两种类型。进程在通过系统调用 open() 打开文件的时候，可以通过将参数 flags 赋值为 O_DIRECT 来指定文件操作为 Direct IO。默认情况下为 Buffered IO。 缓存 I/O：对数据的读写，实际上是对内核的缓冲区直接进行读写 缓存 I/O 的优点：1）在一定程度上分离了内核空间和用户空间，保护系统本身的运行安全；2）可以减少读盘的次数，从而提高性能。 缓存 I/O 的缺点：在缓存 I/O 机制中，DMA 方式可以将数据直接从磁盘读到页缓存中，或者将数据从页缓存直接写回到磁盘上，而不能直接在应用程序地址空间和磁盘之间进行数据传输，这样，数据在传输过程中需要在应用程序地址空间（用户空间）和缓存（内核空间）之间进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。 直接 I/O 就是应用程序直接访问磁盘数据，而不经过内核缓冲区 直接 IO 的优点：减少一次从内核缓冲区到用户程序缓存的数据复制。比如说数据库管理系统这类应用，它们更倾向于选择它们自己的缓存机制，因为数据库管理系统往往比操作系统更了解数据库中存放的数据，数据库管理系统可以提供一种更加有效的缓存机制来提高数据库中数据的存取性能。以及在文件随机读写时，也会用直接 IO 直接 IO 的缺点：如果访问的数据不在应用程序缓存中，那么每次数据都会直接从磁盘加载，这种直接加载会非常缓存。通常直接 IO 与异步 IO 结合使用，会得到比较好的性能。（异步 IO：当访问数据的线程发出请求之后，线程会接着去处理其他事，而不是阻塞等待） 文件系统：inode 和 dentry➤ Linux 文件系统会为每个文件分配两个数据结构：索引节点（index node）和 目录项（directory entry），它们主要用来记录文件的元信息和目录层次结构。 索引节点，即 inode，用来记录文件的元信息，比如 inode 编号、文件大小、访问权限、创建时间、修改时间、数据在磁盘的位置等等。索引节点是文件的唯一标识，inode 也同样都会被存储在硬盘中； 目录项，也就是 dentry，用来记录文件的名字、索引节点指针、以及与其他目录项的层级关联关系。多个目录项关联起来，就会形成目录结构，但它与索引节点不同的是，目录项是由内核维护的一个数据结构，不存放于磁盘，而是缓存在内存。目录项这个数据结构不只是表示目录，也是可以表示文件。 由于索引节点唯一标识一个文件，而目录项记录着文件的名字，所以 目录项和索引节点的关系是多对一，也就是说，一个文件可以有多个别名。比如，硬链接的实现就是多个目录项中的索引节点指向同一个文件。 ➤ 磁盘读写的最小单位是扇区，扇区的大小只有 512B 大小，很明显，如果每次读写都以这么小为单位，那这读写的效率会非常低。所以，文件系统把多个扇区组成了一个逻辑块，每次读写的最小单位就是逻辑块（数据块），Linux 中的逻辑块大小为 4KB，也就是一次性读写 8 个扇区，这将大大提高了磁盘的读写的效率。 以上就是索引节点、目录项以及文件数据的关系，下面这个图就很好的展示了它们之间的关系： 索引节点是存储在硬盘上的数据，那么为了加速文件的访问，通常会把索引节点加载到内存中。 另外，磁盘进行格式化的时候，会被分成三个存储区域，分别是超级块、索引节点区和数据块区。 超级块，用来存储文件系统的详细信息，比如块个数、块大小、空闲块等等。 索引节点区，用来存储索引节点； 数据块区，用来存储文件或目录数据； 我们不可能把超级块和索引节点区全部加载到内存，这样内存肯定撑不住，所以只有当需要使用的时候，才将其加载进内存，它们加载进内存的时机是不同的： 超级块：当文件系统挂载时进入内存； 索引节点区：当文件被访问时进入内存； 文件系统：块组和块结构 上面提到 Linux 磁盘读写最小单位是 逻辑块（size = 4KB），但这个管理粒度太小了，EXT文件系统使用 块组 来管理更多的逻辑块 一般磁盘经过分区后，由 MBR + MBR GAP + 若干分区组成. MBR固定是512字节，446(引导写入区域)+64(分区表)+2(固定55aa) MBR+MBR GAP一般是2048bytes, 主要用于写入引导程序（如grub、LILO等），引导系统启动; 分区进行格式化后，在分区的开头会预留空间作为 Boot sector（一般1024bytes），剩下的空间切成若干个 块组，下图给出了 Linux Ext2 分区的 块组 示意图： 引导块，在系统启动时用于启用引导，每个分区都有一个，引导块后面接着就是一个一个连续的块组了，块组的内容如下： 超级块，包含的是文件系统的重要信息，比如 inode 总个数、块总个数、每个块组的 inode 个数、每个块组的块个数等等； 块组描述符，包含文件系统中各个块组的状态，比如块组中空闲块和 inode 的数目等，每个块组都包含了文件系统中「所有块组的组描述符信息」； 数据位图 和 inode 位图，用于表示对应的 数据块 或 inode 是空闲的，还是被使用中。位图也占用1个逻辑块，因此以默认文件系统块大小计算，一个块组可以有32768(4096*8)个逻辑块； inode 列表，列表的形式保存了文件的元数据信息，包括文件的inode id、大小、扩展属性和访问时间等内容。通常占用若干个逻辑块的大小； 数据块，上面元数据之外的存储区域都成为数据块区域，这些区域作为文件扩展属性和文件内数据的存放容器。 一个块组里是有重复的冗余数据的，比如 超级块 和 块组描述符表，这两个都是全局信息，这么做是有两个原因： 如果系统崩溃破坏了超级块或块组描述符，有关文件系统结构和内容的所有信息都会丢失。如果有冗余的副本，该信息是可能恢复的。 通过使文件和管理数据尽可能接近，减少了磁头寻道和旋转，这可以提高文件系统的性能。 不过，Ext2 的后续版本采用了稀疏技术。该做法是，超级块和块组描述符表不再存储到文件系统的每个块组中，而是只写入到块组 0、块组 1 和其他 ID 可以表示为 3、 5、7 的幂的块组中。 @ref: Linux文件系统-EXT文件系统结构及基本原理 - 简书 Ext4文件系统的块组 - 知乎 IO 系统调用解析openopen 负责在内核生成与文件相对应的 struct file 元数据结构，并且与文件系统中该文件的 struct inode 进行关联，装载对应文件系统的操作回调函数，然后返回一个 int fd 给用户进程。后续用户对该文件的相关操作，会涉及到其相关的 struct file、struct inode、inode-&gt;i_op、inode-&gt;i_fop 和 inode-&gt;i_mapping-&gt;a_ops 等。 注：文件操作对应的偏移存储于struct file中，每个open的文件单独维护一份，同一个文件的读写操作共享同一个偏移。 其整个内核逻辑流程可以用下图来表示： writewrite 的写逻辑路径有好几条，最常使用的就是利用 pagecache 延迟写的这条路径，所以主要分析这个。在 write 调用的调用、返回之间，其负责分配新的 pagecache，将数据写入 pagecache，同时根据系统参数，判断 pagecache 中的脏数据占比来确定是否要触发回写逻辑。其详细的代码分析可以参考：《Linux 内核写文件过程》和 《Linux 内核延迟写机制》。 其整个内核逻辑流程可以用下图来表示： readread 的读逻辑中包含预期 readahead 的逻辑，其可以通过与 fadvise 的配合达到文件预取的效果。这部分的代码分析可以参考：《Linux 内核读文件过程》 其整个内核逻辑流程可以用下图来表示： fwrite &amp; fflush &amp; fsync fwrite &amp; fflush：标准 IO 函数（如 fread，fwrite 等）会在内存（用户空间）中建立缓冲，该函数刷新用户空间的内存缓冲，将内容写入内核缓冲，要想将其真正写入磁盘，还需要调用 fsync。（即先调用 fflush 然后再调用 fsync，否则不会起作用）。fflush 以指定的文件流描述符为参数（对应以 fopen 等函数打开的文件流），仅仅是把上层缓冲区中的数据刷新到内核缓冲区就返回。 write 函数，默认使用 Buffered IO 方式，该函数只是把用户 buff 内的数据写入文件的页缓存（page cache） sync 函数只是将所有修改过的块缓冲区排入写队列，然后就返回，它并不等待实际写磁盘操作结束。通常称为 update 的系统守护进程会周期性地（一般每隔 30 秒）调用 sync 函数。这就保证了定期冲洗内核的块缓冲区。命令 sync(1)也调用 sync 函数。 fsync 函数只对由文件描述符 filedes 指定的单一文件起作用，并且等待写磁盘操作结束，然后返回。 fsync 可用于数据库这样的应用程序，这种应用程序需要确保将修改过的块立即写到磁盘上。 fdatasync 函数类似于 fsync，但它只影响文件的数据部分。而除数据外，fsync 还会同步更新文件的属性。对于提供事务支持的数据库，在事务提交时，都要确保事务日志（包含该事务所有的修改操作以及一个提交记录）完全写到硬盘上，才认定事务提交成功并返回给应用层。 下图中的 stdio buff 即 fwrite 在用户空间使用的缓冲： 借助 GDB 即可看到 fflush 时的调用栈:(gdb) bt#0 0x00007ffff72e0840 in **write** () from /lib64/libc.so.6#1 0x00007ffff726cfb3 in _IO_new_file_write () from /lib64/libc.so.6#2 0x00007ffff726e41c in __GI__IO_do_write () from /lib64/libc.so.6#3 0x00007ffff726c810 in **__GI_****_IO_file_sync** () from /lib64/libc.so.6#4 0x00007ffff72620a2 in **fflush** () from /lib64/libc.so.6#5 0x00000000004007bd in main () at ggg.cpp:12 mmap用户调用 mmap 将文件映射到内存时，内核进行一系列的参数检查，然后创建对应的 vma，然后给该 vma 绑定 vma_ops。当用户访问到 mmap 对应的内存时，CPU 会触发 page fault，在 page fault 回调中，将申请 pagecache 中的匿名页，读取文件到其物理内存中，然后将 pagecache 中所属的物理页与用户进程的 vma 进行映射。 其整个内核逻辑流程可以用下图来表示，其中 page fault 部分比较简略，可以参考 Linux Page Fault(缺页异常)： io_submit对于非 O_DIRECT 标记打开的文件，其内部逻辑与 write 流程基本一致，最终将数据拷贝到 pagecache 中，整个调用实际都是同步阻塞的。 对于O_DIRECT标记打开的文件，在文件系统层(vfs/ext4等)仍然是同步的，在一些文件系统日志、文件系统数据块与磁盘映射、bio 请求队列满等情况下，仍然会被同步阻塞。当经过文件系统层后，被封装成一个bio请求时，且 bio 请求队列未满时，该请求进入 bio 请求队列后即刻返回，从而形成一个异步写事件。 目前异步 IO 使用最多的是 linux native aio，不幸的是，其存在着诸多约束（io_uring 新异步 IO 机制，性能提升超 150%，堪比 SPDK）： 最大的限制无疑是仅支持 direct io。而 O_DIRECT 存在 bypass 缓存和 size 对齐等限制，直接影响了 aio 在很多场景的使用。而针对 buffered io，其表现为同步。 即使满足了所有异步 IO 的约束，有时候还是可能会被阻塞。例如，等待元数据 IO，或者等待 block 层 request 的分配等。 存在额外的拷贝开销，每个 IO 提交需要拷贝 64+8 字节(iocb 64 字节，iocbpp 指针 8 字节)，每个 IO 完成需要拷贝 32 字节，这 104 字节的拷贝在大量小 IO 的场景下影响很可观。同时，需要非常小心地使用完成事件以避免丢事件。 IO 需要至少 2 个系统调用（submit + wait-for-completion)，这在 spectre/meltdown 开启的前提下性能下降非常严重。 参考文件IO系统调用内幕 — 源代码","categories":[{"name":"21.Operating-System","slug":"21-Operating-System","permalink":"https://beefyheisenberg.github.io/categories/21-Operating-System/"}],"tags":[]},{"title":"APUE.00::从Unix到Linux（Gnu、Posix是什么）","slug":"21.Operating-System/APUE.00.从Unix到Linux（Gnu、Posix是什么）","date":"2024-01-24T01:27:52.402Z","updated":"2024-01-24T01:27:52.403Z","comments":true,"path":"21.Operating-System/APUE.00.从Unix到Linux（Gnu、Posix是什么）/","link":"","permalink":"https://beefyheisenberg.github.io/21.Operating-System/APUE.00.从Unix到Linux（Gnu、Posix是什么）/","excerpt":"Unix的诞生：从SystemV 到 Unix-like UNIX：1969，贝尔实验室的工程师，肯·汤普逊（Ken Thompson）和丹尼斯·里奇，在此时自行开发了Unix。 当时的UNIX拥有者AT&amp;T公司以低廉甚至免费的许可将Unix源码授权给学术机构做研究或教学之用，最著名的变种之一是由加州大学柏克莱分校开发的伯克利软件套件(BSD)产品 1983年，AT&amp;T发布了Unix最新版System V，这是一个商业化版本，付费才能使用，并且不得传播源码。 AT&amp;T同BSD的官司…这场著作权官司一直打到AT&amp;T将自己的Unix系统实验室卖掉，新接手的Novell采取了一种比较开明的做法，允许柏克莱分校自由发布自己的Unix变种 System V 和 BSD的分化：其他一些公司也开始为其自己的小型机或工作站提供商业版本的UNIX系统，有些选择System V作为基础版本，有些则选择了BSD。4.4 BSD又是所有自由版本Unix的基础。 Unix除了System V 和 BSD两大分支，还有后来的的 Unix-like系统（GNU /Linux） System V 第四版的发布，其特性成为一些UNIX共同特性的源头，例如 “SysV 初始化脚本” （/etc/init.d），用来控制系统启动和关闭，System V Interface Definition (SVID) 是一个System V 如何工作的标准定义。 GNUGNU是一个自由的操作系统，其内容软件完全以GPL方式发布。这个操作系统是GNU计划的主要目标，名称来自GNU is Not Unix的递归缩写，因为GNU的设计类似Unix，但它不包含具著作权的Unix代码。","text":"Unix的诞生：从SystemV 到 Unix-like UNIX：1969，贝尔实验室的工程师，肯·汤普逊（Ken Thompson）和丹尼斯·里奇，在此时自行开发了Unix。 当时的UNIX拥有者AT&amp;T公司以低廉甚至免费的许可将Unix源码授权给学术机构做研究或教学之用，最著名的变种之一是由加州大学柏克莱分校开发的伯克利软件套件(BSD)产品 1983年，AT&amp;T发布了Unix最新版System V，这是一个商业化版本，付费才能使用，并且不得传播源码。 AT&amp;T同BSD的官司…这场著作权官司一直打到AT&amp;T将自己的Unix系统实验室卖掉，新接手的Novell采取了一种比较开明的做法，允许柏克莱分校自由发布自己的Unix变种 System V 和 BSD的分化：其他一些公司也开始为其自己的小型机或工作站提供商业版本的UNIX系统，有些选择System V作为基础版本，有些则选择了BSD。4.4 BSD又是所有自由版本Unix的基础。 Unix除了System V 和 BSD两大分支，还有后来的的 Unix-like系统（GNU /Linux） System V 第四版的发布，其特性成为一些UNIX共同特性的源头，例如 “SysV 初始化脚本” （/etc/init.d），用来控制系统启动和关闭，System V Interface Definition (SVID) 是一个System V 如何工作的标准定义。 GNUGNU是一个自由的操作系统，其内容软件完全以GPL方式发布。这个操作系统是GNU计划的主要目标，名称来自GNU is Not Unix的递归缩写，因为GNU的设计类似Unix，但它不包含具著作权的Unix代码。 作为操作系统，GNU的发展仍未完成，其中最大的问题是具有完备功能的内核尚未被开发成功。GNU的内核，称为Hurd，是自由软件基金会发展的重点，但是其发展尚未成熟。在实际使用上，多半使用Linux内核、FreeBSD等替代方案，作为系统核心，其中主要的操作系统是Linux的发行版。Linux操作系统包涵了Linux内核与其他自由软件项目中的GNU组件和软件，可以被称为GNU/Linux @ref: https://zh.wikipedia.org/zh-cn/GNU GNU的协议： GPL：GNU通用公共许可证（GNU General Public License），由于GPL很难被商业软件所应用，它要求调用它的库的代码也得GPL，全部开放，并且一同发布，不能直接连接。 LGPL：GNU较宽松公共许可证 (GNU Lesser General Public License ) ，在GPL与LGPL许可证保护下发布源代码的结果很相似，对旧代码所做的任何修改对于想知道这些代码的人必须是公开的，唯一真正的不同之处在于私人版权代码是否可以与开放源代码相互连接，LGPL允许实体连接私人代码到开放源代码，并可以在任何形式下发布这些合成的二进制代码。只要这些代码是动态连接的就没有限制。 从 GNU 到 Linux 到了1990年，GNU计划已经开发出的软件包括了一个功能强大的文字编辑器Emacs、GCC（GNU Compiler Collection，GNU编译器集合）； 1991年 Linus Torvalds编写出了与 UNIX兼容的 Linux操作系统内核并在 GNU GPL协议条款下发布； 如今，GNU的基本组成包括GNU编译器套装（GCC）、GNU的C库（glibc）、以及GNU核心工具组（coreutils），另外也是GNU除错器（GDB）、GNU二进制实用程序（binutils）的GNU Cashshell中和GNOME桌面环境； C 标准函数库、POSIX、GNU C库的区别 标准函数库通常会随附在编译器上。windows系统和Linux系统下都可以尽情使用。是最基本的C函数库，也叫ANSI C。直到最新版的C11，C标准函数库共有29个头文件； ISO C是从ANSI C继承而来，也可以叫Standard C，同时ISO C也是POSIX的一个子集，除此之外，它还包含各种系统服务接口，如socket等。但是ISO C还是领先于POSIX的，很多C的新标准并没有进入POSIX中，比如线程相关部分。 POSIX是 Portable Operating System Interface(可移植操作系统接口) 的缩写，X表示UNIX，而X则表明其对Unix API的传承。它是 ISO C 的延伸，明定了一个 Unix-like的可移植的操作系统所应具备的种种条件。POSIX包括的标准有：进程控制、信号（Signal）、文件、管道、IO、线程、Shell、实用程序（包括awk、echo、ed）、还包括一个完整的 C Library (Standard C) ；20世纪80年代中期，为了提高兼容性和应用程序的可移植性，阻止这种趋势， IEEE(电气和电子工程师协会)开始努力标准化Unix的开发，后来由 Richard Stallman命名为“Posix”。Linux基本上逐步实现了POSIX兼容，但并没有参加正式的POSIX认证。 @ref: https://en.wikipedia.org/wiki/POSIXC POSIX library是C语言的POSIX系统下的标准库。包含了一些在C语言标准库之外的函数。 GNU C库（英语：GNU C Library，常简称为 glibc）：是一种按照LGPL许可协议发布的、自由的、公开源代码的函数库。既包含C标准库，也包含POSIX库。glibc是linux下面c标准库的实现，即 GNU C Library。 Unix &amp; Linux 分支： System V： BSD： 主要分支 FreeBSD、OpenBSD和NetBSD macOS：这是Apple发布的类Unix的操作系统, 内核由XNU构成, 而XNU是基于NeXTSTEP和FreeBSD混合开发组成. 架构图如下: Unix-like：Gnu/Linux RH =&gt; Fedora Debian =&gt; Ubuntu Unix-Linux家族树：","categories":[{"name":"21.Operating-System","slug":"21-Operating-System","permalink":"https://beefyheisenberg.github.io/categories/21-Operating-System/"}],"tags":[]},{"title":"01.RAM.2.内存对齐","slug":"21.Operating-System/01.RAM.2.内存对齐","date":"2024-01-24T01:27:52.398Z","updated":"2024-01-24T01:27:52.398Z","comments":true,"path":"21.Operating-System/01.RAM.2.内存对齐/","link":"","permalink":"https://beefyheisenberg.github.io/21.Operating-System/01.RAM.2.内存对齐/","excerpt":"➤ 从硬件角度说明为什么需要内存对齐 内存条上的黑色颗粒，被称为 Chip，每个 Chip 内部又是由 8 个 Bank 组成； 每个 Bank 可以看做是一个矩阵，矩阵上每个元素可以存储1字节（8bit，也就是说包含了8个小电容）","text":"➤ 从硬件角度说明为什么需要内存对齐 内存条上的黑色颗粒，被称为 Chip，每个 Chip 内部又是由 8 个 Bank 组成； 每个 Bank 可以看做是一个矩阵，矩阵上每个元素可以存储1字节（8bit，也就是说包含了8个小电容） 对于我们在应用程序中内存中地址连续的8个字节,例如0x0000-0x0007，是从位于 bank 上的呢？直观感觉，应该是在第一个 bank 上吗？其实不是的，程序员视角看起来连续的地址0x0000-0x0007，实际上是位于8个 bank 中的，每一个 bank 只保存了一个字节。在物理上，他们并不连续。下图很好地阐述了实际情况，一个 64 bits 连续的空间，对应到每个 Bank 上的一个元素（8 bits）： 这样设计的原因是电路工作效率。内存中的8个 bank 是可以并行工作的。上面的例子中读取 8 字节，只需要 1 个周期，如果设计为连续地址存储在一个 bank 里，只能串行进行读取，需要读8次，这样速度会慢很多。 所以，内存对齐最最底层的原因是内存的 IO 是以8个字节64bit 为单位进行的。对于64位数据宽度的内存，假如 cpu 也是64位的 cpu（现在的计算机基本都是这样的），每次内存 IO 获取数据都是从同行同列的8个 bank 中各自读取一个字节拼起来的。从内存的0地址开始，0-7字节的数据可以一次 IO 读取出来，8-15字节的数据也可以一次读取出来。 换个例子，假如你指定要获取的是0x0001-0x0008，也是8字节，但是不是0开头的，内存需要怎么工作呢？没有好办法，内存只好先工作一次把0x0000-0x0007取出来，然后再把0x0008-0x0015取出来，把两次的结果都返回给你。CPU和内存IO的硬件限制导致没办法一次跨在两个数据宽度中间进行IO。 事实上，编译和链接器会自动替开发者对齐内存的，尽量帮你保证一个变量不跨列寻址。但是他不能做到十分完美。CPU 缓存的最小单元是 Cache Line，size 是 64 字节，可以整除 8 字节（内存的 IO 单位） 当数据存储在成倍数据大小的地址中时，CPU 会更有效地读取和写入内存。例如，如果数据存储在倍数为 4 的地址中，则会更有效地访问 4 字节整数。如果数据未对齐，则 CPU 需要执行更多地址计算工作来访问数据。 默认情况下，编译器会根据数据的大小对齐数据：char 在 1 字节的边界上对齐，short 在 2 字节的边界上对齐，int、long 和 float 在 4 字节的边界上对齐，double 在 8 字节的边界上对齐，依次类推。 通常，无需担心对齐方式。编译器通常在基于目标处理器和数据大小的自然边界上对齐数据。在 32 位处理器上，数据最多在 4 字节的边界上对齐，在 64 位处理器上，数据最多在 8 字节的边界对齐。但是，在某些情况下，你可以通过指定数据结构的自定义对齐方式获得性能提升或节约内存。 另外，通过将常用数据与处理器的缓存行大小对齐，可以提高缓存性能。例如，假设定义了一个大小小于 32 个字节的结构。可能需要使用 32 字节对齐方式，以确保有效缓存结构的所有实例。 使用 C 11 关键字 _Alignof 来获取类型或变量的首选对齐方式。 @ref: 对齐 (C11) | Microsoft Learn 对于 C/C++中的基本数据类型，假设它的长度为 n 字节，那么该类型的变量会被编译器默认分配到 n 字节对齐的内存上。例如，char 的长度是 1 字节，char 类型变量的地址将是 1 字节对齐的（任意值均可）；int 的长度是 4 字节，所以 int 类型变量将被分配到 4 字节对齐的地址上。这种默认情况下的变量对齐方式又称作自然对齐（naturally aligned） What is natural alignment? Why should a generic pointer be aligned? - Quora struct 以及含位域的结构体对齐 =&gt; C-Tutorials.01.基础 因为 RISC CPU 的设计，大多精简指令集的指令长就是字长。而指令还需区分取立即数和各种 action, 一字长的指令无法全部用来表示地址空间。综上，大多 RISC CPU 强制地址对齐，地址的低位补成 0。顺便也减少了地址线的宽度。 基于此，一般的 RISC CPU 的地址线宽度为 $wordSize - log_2\\frac{wordSize}{byteSize}$.比如一个 32 位 CPU 的字长是 32 bit, 字节大小为 8 bit, 那么地址线宽度为 $32 - log_2\\frac{32}{8} = 30$ ，可选择 2^30 个地址单位，每个单位的大小是 4 字节，于是总共可管理 2^{30+2} 字节的内存。这也是逻辑地址最低位总是为 0 的来历了（对于 32 bit 字长的 CPU, 逻辑地址的最低 2 位为 0） CPU 总是以 word size （32 位上 = 4）为单位从内存中读取数据，对于没有对齐的数据，例如在4 字节的 RISC CPU 上，读一个未对齐的 int，需要读两次 word size 的数据 @ref: 如何理解 struct 的内存对齐？ - 張道遠 的回答 - 知乎 @ref: 对内存对齐的深一步理解_12935177的技术博客_51CTO博客 ARM CPU 有以下几条指令： LDR/STR： address must be 4-byte aligned LDRH/STRH： address must be 2-byte aligned // H=Half LDRB/STRB： address must be byte aligned // B = Byte reinterpret_cast&lt;int*&gt; ptr 将调用 LDR, 但如果 ptr 不是 4 字节对齐，则会报错。例如： char *buffer[1024]; // 假设buff地址是0x0000,0000char ch = *buffer; // 调用LDBint i = *reinterpret_cast&lt;int*&gt;(buffer+1); //在0x0001地址使用LDR，没有对齐，报错 从 buff+1 取 4 字节，正确做法是 memcpy： memcpy(&amp;i, buffer+1, 4)，memcpy 是如何实现的？ memcpy （ARM 平台的实现）先检测是 dst 地址否 4 字节对齐，如果是，则直接 LDR 逐 4 字节读取，如果没有对齐，则先用 LDRB 逐字节读取，到对齐后再 LDR 面试题场景的手写 memcpy 实现（通常没有用到逐 word 拷贝，而是用 char* 逐 byte 拷贝） // 链接：https://www.nowcoder.com/questionTerminal/9602083ec8d749999d86adf8a725b4f7// 来源：牛客网void *memmove(void *dest, const void *src, size_t n)&#123; char *tmp, *s; if (dest &lt;= src) //没有内存重叠，从低地址开始复制 &#123; tmp = (char *) dest; s = (char *) src; while (n--) *tmp++ = *s++; &#125; else //有内存重叠，从高地址开始复制 &#123; tmp = (char *) dest + n; s = (char *) src + n; while (n--) *--tmp = *--s; &#125; return dest;&#125;","categories":[{"name":"21.Operating-System","slug":"21-Operating-System","permalink":"https://beefyheisenberg.github.io/categories/21-Operating-System/"}],"tags":[]},{"title":"01.RAM.1.内存寻址","slug":"21.Operating-System/01.RAM.1.内存寻址","date":"2024-01-24T01:27:52.393Z","updated":"2024-01-24T01:27:52.393Z","comments":true,"path":"21.Operating-System/01.RAM.1.内存寻址/","link":"","permalink":"https://beefyheisenberg.github.io/21.Operating-System/01.RAM.1.内存寻址/","excerpt":"内存寻址(Memory Addressing): 分段机制把 逻辑地址 转换为 线性地址, 分页机制进一步把该 线性地址 再转换为 物理地址. 段式内存管理 内存可寻址范围总是跟”地址总线宽度”和”寄存器宽度”相关 实模式的诞生（16位处理器及寻址） 在8086处理器诞生之前, 内存寻址方式就是直接访问物理地址. 8086处理器为了寻址1M的内存空间, 把地址总线扩展到了20位. 但是, 一个尴尬的问题出现了, ALU的宽度只有16位, 也就是说, ALU不能计算20位的地址. 为了解决这个问题, 分段机制被引入 为了支持分段, 8086处理器设置了四个段寄存器：CS, DS, SS, ES每个段寄存器都是16位的, 同时访问内存的指令中的地址也是16位的. 在送入地址总线之前(20位), 要将端寄存器(16位)的值与内存地址(16位, 即段内偏移值)相加 端寄存器的值左移4位, 低位补0, 然后加上内存地址","text":"内存寻址(Memory Addressing): 分段机制把 逻辑地址 转换为 线性地址, 分页机制进一步把该 线性地址 再转换为 物理地址. 段式内存管理 内存可寻址范围总是跟”地址总线宽度”和”寄存器宽度”相关 实模式的诞生（16位处理器及寻址） 在8086处理器诞生之前, 内存寻址方式就是直接访问物理地址. 8086处理器为了寻址1M的内存空间, 把地址总线扩展到了20位. 但是, 一个尴尬的问题出现了, ALU的宽度只有16位, 也就是说, ALU不能计算20位的地址. 为了解决这个问题, 分段机制被引入 为了支持分段, 8086处理器设置了四个段寄存器：CS, DS, SS, ES每个段寄存器都是16位的, 同时访问内存的指令中的地址也是16位的. 在送入地址总线之前(20位), 要将端寄存器(16位)的值与内存地址(16位, 即段内偏移值)相加 端寄存器的值左移4位, 低位补0, 然后加上内存地址 +-----------------+| 20 | 20位地址总线+-----------------++------------+| 16 | 16位段地址+------------+ +-------------+ | 12 | 4 | 16位内存地址（段内偏移量） +--------+----+实际物理地址 = （段寄存器地址 &lt;&lt; 4） + （CPU 提交的访存地址） 保护模式的诞生（32位处理器及寻址） 80286处理器的地址总线为24位, 寻址空间达16M, 同时引入了保护模式（内存段的访问受到限制） 80386处理器是一个32位处理器, ALU和地址总线都是32位的, 寻址空间达 4G. 也就是说它可以不通过分段机制, 直接访问4G的内存空间. 但它必须支持实模式和保护模式. 所以, 80386在段寄存器的基础上构筑保护模式, 并且保留16位的段寄存器. 从80386之后的处理器, 架构基本相似, 统称为IA32（32 Bit Intel Architecture）. IA32的内存寻址机制IA32的三种地址 逻辑地址: 每个逻辑地址都由一个”段的选择符”和”偏移量组成”. IA32中有六个16位段寄存器 线性地址：线性地址是一个32位的无符号整数, 可以表达高达2^32（4GB）的地址. 通常用16进制表示线性地址, 其取值范围为0x00000000～0xffffffff. 物理地址：也就是内存单元的实际地址, 用于芯片级内存单元寻址. 物理地址也由32位无符号整数表示. MMUMMU是一种硬件电路, 它包含两个部件, 一个是分段部件, 一个是分页部件, 在此, 我们把它们分别叫做分段机制和分页机制, 内存寻址分两个步骤:分段机制把一个逻辑地址转换为线性地, 接着, 分页机制把一个线性地址转换为物理地址. IA32的段寄存器IA32中有六个段寄存器(16 bit)：CS, DS, SS, ES, FS, GS.跟8086的段寄存器不同的是, 这些寄存器存放的不再是某个段的基地址, 而是某个段的选择符（Selector）. IA32(硬件)分段机制的实现段描述符段是虚拟地址空间的基本单位, 段描述符 是一个8字节的数据结构, 包括以下几个属性: 段的界限(Limit)：在虚拟地址空间中, 段内可以使用的最大偏移量. 段的基地址(Base Address)：在线性地址空间中段的起始地址. 段的保护属性(Attribute)：表示段的特性. 例如, 该段是否可被读出或写入, 或者该段是否作为一个程序来执行, 以及段的特权级等等. 上面的数据结构我们称为段描述符，多个段描述符组成的表称为段描述符表 从图可以看出，一个段描述符指出了段的 32 位基地址和 20 位段界限(即段长)。这里我们只关注基地址和段界限，其他的属性略过。 段描述符表描述符表(即段表)定义了IA32系统的所有段的情况. 所有的描述符表本身都占据一个字节为8的倍数的存储器空间, 空间大小在8个字节(至少含一个描述符)到64K字节(至多含8K)个描述符之间. 全局描述符表(GDT)全局描述符表 GDT(Global Descriptor Table)，除了任务门，中断门和陷阱门描述符外，包含着系统中所有任务都共用的那些段的描述符。它的第一个 8 字节位置没有使用。 中断描述符表 IDT(Interrupt Descriptor Table)中断描述符表 IDT(Interrupt Descriptor Table)，包含 256 个门描述符。IDT 中只能包含任务门、中断门和陷阱门描述符，虽然 IDT 表最长也可以为 64 K 字节，但只能存取 2 K 字节以内的描述符，即 256 个描述符，这个数字是为了和 8086保持兼容。 局部描述符表(LDT)局部描述符表 LDT(local Descriptor Table)，包含了与一个给定任务有关的描述符，每个任务各自有一个的 LDT。有了 LDT，就可以使给定任务的代码、数据与别的任务相隔离。每一个任务的局部描述符表 LDT 本身也用一个描述符来表示，称为 LDT 描述符，它包含了有关局部描述符表的信息，被放在全局描述符表 GDT 中。 总结IA32的内存寻址机制完成从逻辑地址–线性地址–物理地址的转换. 其中, 逻辑地址的段寄存器中的值提供段描述符, 然后从段描述符中得到段基址和段界限, 然后加上逻辑地址的偏移量, 就得到了线性地址, 线性地址通过分页机制得到物理地址.首先, 我们要明确, 分段机制是IA32提供的寻址方式, 这是硬件层面的. 就是说, 不管你是windows还是linux, 只要使用IA32的CPU访问内存, 都要经过MMU的转换流程才能得到物理地址, 也就是说必须经过逻辑地址–线性地址–物理地址的转换. Linux系统(软件)分段机制的实现Linux基本不使用分段的机制, 或者说, Linux中的分段机制只是为了兼容IA32的硬件而设计的. 在 IA32 上任意给出的地址都是一个虚拟地址, 即任意一个地址都是通过选择符:偏移量的方式给出的, 这是段机制存访问模式的基本特点.所以在IA32上设计操作系统时无法回避使用段机制. 一个虚拟地址最终会通过段基地址＋偏移量的方式转化为一个线性地址.但是, 由于绝大多数硬件平台都不支持段机制, 只支持分页机制, 所以为了让 Linux 具有更好的可移植性, 我们需要去掉段机制而只使用分页机制. 但不幸的是, IA32规定段机制是不可禁止的, 因此不可能绕过它直接给出线性地址空间的地址.万般无奈之下, Linux的设计人员干脆让段的基地址为0, 而段的界限为4GB, 这时任意给出一个偏移量, 则等式为0+偏移量=线性地址, 也就是说“偏移量＝线性地址”. 另外由于段机制规定“偏移量&lt;4GB”, 所以偏移量的范围为0H～FFFFFFFFH, 这恰好是线性地址空间范围, 也就是说虚拟地址直接映射到了线性地址, 我们以后所提到的虚拟地址和线性地址指的也就是同一地址. 看来, Linux在没有回避段机制的情况下巧妙地把段机制给绕过去了. 特权等级(CPU Rings)和分段机制由于IA32段机制还规定, 必须为代码段和数据段创建不同的段, 所以Linux必须为代码段和数据段分别创建一个基地址为0, 段界限为4GB的段描述符.不仅如此, 由于Linux内核运行在特权级0, 而用户程序运行在特权级别3, 根据IA32段保护机制规定, 特权级3的程序是无法访问特权级为0的段的,所以Linux必须为内核用户程序分别创建其代码段和数据段. 这就意味着Linux 必须创建4个段描述符: 特权级0的代码段和数据段, 特权级3的代码段和数据段 存疑: 在Ring0和Ring3的, 相同的的逻辑地址, 是对应不同的线性地址 [?] @ref 参考: Linux内存寻址之分段机制 | ShareHub 页式内存管理硬件分页 分页机制在段机制之后进行, 以完成线性—物理地址的转换过程. 段机制把逻辑地址转换为线性地址, 分页机制进一步把该线性地址再转换为物理地址. 分页机制管理的对象是固定大小的存储块, 称之为页(page). 分页机制把整个线性地址空间及整个物理地址空间都看成由页组成, 在线性地址空间中的任何一页, 可以映射为物理地址空间中的任何一页, 我们把物理空间中的一页叫做 页框(page frame) 80386使用4K(0xFFF)字节大小的页. 每一页都有4K字节长, 并在4K字节的边界上对齐(即每一页的起始地址都能被4K整除). 因此, 80386把最大可寻址4G字节的线性地址空间划分为1M个Page 线性地址的page, 与物理地址的page是多对一的关系, 也就是两个不同线性地址页, 可能指向同一个物理地址页 两级分页为什么使用两级页表：假设每个进程都占用了 4 G 的线性地址空间，页表共含 1 M 个表项，每个表项占 4 个字节，那么每个进程的页表要占据 4 M 的内存空间。为了节省页表占用的空间，我们使用两级页表。每个进程都会被分配一个页目录，但是只有被实际使用页表才会被分配到内存里面。一级页表需要一次分配所有页表空间，两级页表则可以在需要的时候再分配页表空间。 两级页表结构： 页目录(Page Directory): 两级表结构的第一级称为页目录，存储在一个 4 K 字节的页面中。页目录表共有 1 K 个表项，每个表项为 4 个字节，并指向第二级表。线性地址的最高 10 位(即位 31~位 32)用来产生第一级的索引，由索引得到的表项中，指定并选择了 1 K 个二级表中的一个表。 页表(Page Table): 两级表结构的第二级称为页表，也刚好存储在一个 4 K 字节的页面中，包含 1 K 个字节的表项，每个表项包含一个页的物理基地址。第二级页表由线性地址的中间 10 位(即位 21~位 12)进行索引，以获得包含页的物理地址的页表项，这个物理地址的高 20 位与线性地址的低 12 位形成了最后的物理地址，也就是页转化过程输出的物理地址。 Linux 中的分页机制Linux 使用了一个适合 32 位和 64 位系统的分页机制。把二级分页机制中的”目录项”分三部分：页全局目录、页顶级目录、页中间目录，加上页表，以及每个页表项指向的页框，分为 5 级。 对于没有启用物理地址扩展的 32 位系统，两级页表已经足够了。从本质上说 Linux 通过使“页上级目录”位和“页中间目录”位全为 0，彻底取消了页上级目录和页中间目录字段。不过，页上级目录和页中间目录在指针序列中的位置被保留，以便同样的代码在 32 位系统和 64 位系统下都能使用。内核为页上级目录和页中间目录保留了一个位置，这是通过把它们的页目录项数设置为 1，并把这两个目录项映射到页全局目录的一个合适的目录项而实现的。 启用了物理地址扩展的 32 位系统使用了三级页表。Linux 的页全局目录对应 80×86 的页目录指针表（PDPT），取消了页上级目录，页中间目录对应 80×86 的页目录，Linux 的页表对应 80×86 的页表。 最后，64 位系统使用三级还是四级分页取决于硬件对线性地址的位的划分。 无论是32 or 64 位 Linux 系统，虚拟内存线性地址都可以看做 “n 位页号 + 12位页内偏移”，通过页号来管理一个个 2^12大小的页（所以内存页 size = 4k） 64 位 Linux 4 级分页： 一级页表（47-39）：Page Global Dir，简称 PGD 二级页表（38-30）：Page Upper Dir，简称 PUD 三级页表（29-21）：Page Mid Dir，简称 PMD 四级页表（20-12）：Page Table，简称 PTE 页帧 &amp; 页框四级页表（PTE）里每一项，都指向一个4K大小的内存页，内存页在不同语境翻译可能不一样：页框/ 页帧/ page frame 内存页：可能更偏向于虚拟内存里的最小单位； 页框 / 页帧/ page frame：倾向于描述物理内存的最小单位； 对于这个4K大小的单位（无论是虚拟内存层面 or 物理内存层面），Linux 内核中使用 struct page表示 区分缓冲IO里的 “page cache” TLB存储计算值的高速缓存称为 Translation Look-Aside Buffer（TLB）。它通常是一个小缓存，但是它必须非常快。如果 TLB 查找未命中，处理器必须执行页表遍历；这可能相当昂贵。每个程序员都应该了解的内存知识4 - 虚拟内存 参考 Linux内存寻址之分段机制 - Sharehub Linux内存寻址之分页机制 - Sharehub","categories":[{"name":"21.Operating-System","slug":"21-Operating-System","permalink":"https://beefyheisenberg.github.io/categories/21-Operating-System/"}],"tags":[]},{"title":"01.CPU是怎么制造出来的","slug":"21.Operating-System/01.CPU是怎么制造出来的","date":"2024-01-24T01:27:52.389Z","updated":"2024-01-24T01:27:52.389Z","comments":true,"path":"21.Operating-System/01.CPU是怎么制造出来的/","link":"","permalink":"https://beefyheisenberg.github.io/21.Operating-System/01.CPU是怎么制造出来的/","excerpt":"@ref: 中兴禁令之芯片为什么这么难做？芯片的基本原理是什么？ PN结：p型和n型半导体之间的接触面即称为PN结 • N型：掺入磷元素(5电子) • P型：掺入硼元素(3电子) PN结特点：只有P加正极，N加负极，电流才能通过 二极管：二极管就是由一个PN结加上相应的电极引线及管壳封装而成的。","text":"@ref: 中兴禁令之芯片为什么这么难做？芯片的基本原理是什么？ PN结：p型和n型半导体之间的接触面即称为PN结 • N型：掺入磷元素(5电子) • P型：掺入硼元素(3电子) PN结特点：只有P加正极，N加负极，电流才能通过 二极管：二极管就是由一个PN结加上相应的电极引线及管壳封装而成的。 逻辑与门：输入A、B，输出Y; 两个二极管组成最简单的与门： • 5v供电 • A=5v，B=5v时：输出Y=5v • A=0v，B=5v时，输出Y=0v","categories":[{"name":"21.Operating-System","slug":"21-Operating-System","permalink":"https://beefyheisenberg.github.io/categories/21-Operating-System/"}],"tags":[]},{"title":"01.上下文切换（Context_Switch）","slug":"21.Operating-System/01.CPU_Context_Switch","date":"2024-01-24T01:27:52.383Z","updated":"2024-01-24T01:27:52.384Z","comments":true,"path":"21.Operating-System/01.CPU_Context_Switch/","link":"","permalink":"https://beefyheisenberg.github.io/21.Operating-System/01.CPU_Context_Switch/","excerpt":"内核态和用户态现代的计算机体系结构中存储管理通常都包含保护机制。提供保护的目的，是要避免系统中的一个任务访问属于另外的或属于操作系统的存储区域。如在 IntelX86体系中，就提供了特权级这种保护机制：CPU 的指令分为特权级指令和非特权级指令, 特权级指令通常是一些比较危险的指令（for example？）, Intel X86架构的 CPU 将特权等级分为4个级别：RING0, RING1, RING2, RING3. Linux 仅仅使用了 RING0和 RING3，来分别运行内核态（0）和用户态（3），来保证特权级指令不被错误的使用。 内核态（Ring 0）的进程具有最高权限，可以直接访问所有资源（@doubt 调用内核代码、访问硬件寄存器… ） 用户态（Ring 3）的进程只能访问受限资源，不能直接访问内存等硬件设备，必须通过系统调用（System Call）陷入到内核中，才能访问这些特权资源。 通过系统调用，用户空间的应用程序就会进入内核空间，由内核代表该进程运行于内核空间，这就涉及到上下文的切换 在”32 位 Linux 进程内存布局”一章，有些资料会把内存地址高位的 1G 称为“内核空间” 关于 X 86 系统的细节，请查阅参考资料1 一般的硬件体系机构都提供一种“门”机制。“门”的含义是指在发生了特定事件的时候低特权的应用程序可以通过这些“门”进入高特权的内核空间。 ![[../_images/2023-04-13.png]]","text":"内核态和用户态现代的计算机体系结构中存储管理通常都包含保护机制。提供保护的目的，是要避免系统中的一个任务访问属于另外的或属于操作系统的存储区域。如在 IntelX86体系中，就提供了特权级这种保护机制：CPU 的指令分为特权级指令和非特权级指令, 特权级指令通常是一些比较危险的指令（for example？）, Intel X86架构的 CPU 将特权等级分为4个级别：RING0, RING1, RING2, RING3. Linux 仅仅使用了 RING0和 RING3，来分别运行内核态（0）和用户态（3），来保证特权级指令不被错误的使用。 内核态（Ring 0）的进程具有最高权限，可以直接访问所有资源（@doubt 调用内核代码、访问硬件寄存器… ） 用户态（Ring 3）的进程只能访问受限资源，不能直接访问内存等硬件设备，必须通过系统调用（System Call）陷入到内核中，才能访问这些特权资源。 通过系统调用，用户空间的应用程序就会进入内核空间，由内核代表该进程运行于内核空间，这就涉及到上下文的切换 在”32 位 Linux 进程内存布局”一章，有些资料会把内存地址高位的 1G 称为“内核空间” 关于 X 86 系统的细节，请查阅参考资料1 一般的硬件体系机构都提供一种“门”机制。“门”的含义是指在发生了特定事件的时候低特权的应用程序可以通过这些“门”进入高特权的内核空间。 ![[../_images/2023-04-13.png]] 如何在 Linux 内核中增加自定义的系统调用？ 参考 🔗《使用 Linux 系统调用的内核命令【转】-阿里云开发者社区》: https://developer.aliyun.com/article/383766 当加载了系统的 C 库调用索引和参数时，就会调用一个软件中断（0x80 中断），它将执行 system_call 函数（通过中断处理程序），这个函数会按照 eax 寄存器（eax 寄存器用来标识应当调用的某个系统调用）中的标识处理所有的系统调用。在经过几个简单测试之后，使用 system_call_table 和 eax 中包含的索引来执行真正的系统调用了。从系统调用中返回后，最终执行 syscall_exit，并调用 resume_userspace 返回用户空间。然后继续在 C 库中执行，它将返回到用户应用程序中。 用户态到内核态的切换用户空间和内核空间具有不同的地址映射，通用或专用的寄存器组，而用户空间的进程要传递很多变量、参数给内核，内核也要保存用户进程的一些寄存器、变量等，以便系统调用结束后回到用户空间继续执行，所谓的进程上下文，就是一个进程在执行的时候，CPU 的所有寄存器中的值、进程的状态以及堆栈中的内容，当内核需要切换到另一个进程时，它需要保存当前进程的所有状态，即保存当前进程的进程上下文，以便再次执行该进程时，能够恢复切换时的状态，继续执行。 引起用户态到内核态切换的几种可能： 普通程序进行系统调用 时主动要求切换到内核态, 此时用户态进程要向内核态传递参数, 同时保存用户进程的寄存器、变量等, 以便切换回来时能正确继续执行, 这个过程就是进程 上下文切换 ; 异常事件：当 CPU 在执行运行在用户态下的程序时, 发生了某些事先不可知的异常, 这时会触发由当前运行进程切换到处理此异常的内核相关程序中, 也就转到了内核态, 比如缺页异常; 硬件中断:当外围设备完成用户请求的操作后, 会向 CPU 发出相应的中断信号, 这时 CPU 会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序, 如果先前执行的指令是用户态下的程序, 那么这个转换的过程自然也就发生了由用户态到内核态的切换; 上下文切换 vs 模式切换➤ 何为”上下文切换” 「A context is the contents of a CPU’s registers and program counter at any point in time」：上下文 是 CPU 寄存器和程序计数器在任何时间点的内容。 「Context switching can be described in slightly more detail as the kernel (i.e., the core of the operating system) performing the following activities with regard to processes (including threads) on the CPU: (1) suspending the progression of one process and storing the CPU’s state (i.e., the context) for that process somewhere in memory, (2) retrieving the context of the next process from memory and restoring it in the CPU’s registers and (3) returning to the location indicated by the program counter (i.e., returning to the line of code at which the process was interrupted) in order to resume the process」：上下文切换 可以更详细地描述为操作系统的内核对 CPU 上的进程（包括线程）执行以下活动：（1） 暂停一个进程的进程并将该进程的 CPU 状态（即上下文）存储在内存中的某个位置，（2） 从内存中检索下一个进程的上下文并将其恢复到 CPU 的寄存器中，（3） 返回到程序计数器指示的位置（即返回到进程中断的代码行），以便恢复进程。 「Context Switches and Mode Switches：system call causes the CPU to shift to kernel mode. This is referred to as a mode switch rather than a context switch, because it does not change the current process.」区分“上下文切换” 和 “模式切换”： 系统调用过程通常称为模式切换，而不是上下文切换，系统调用过程中一直是同一个进程在运行； 上下文切换一般指多任务切换（多进程和多线程）时，对于进程和线程的上下文切换代价; 🔗《Context Switch definition》: http://www.linfo.org/context_switch.html 回顾：CPU 寄存器知识 通用寄存器：寄存器是 CPU 内部的少量非常快的内存（与 CPU 外部较慢的 RAM 主内存相反），用于通过提供对常用值（通常是计算过程中的值）的快速访问来加速计算机程序的执行； 程序计数器（Program Counter）：是一个专用寄存器，用于指示 CPU 在其指令序列中的位置，并保存正在执行的指令的地址或要执行的下一条指令的地址； ![[../_images/2023-04-13-1.png]]","categories":[{"name":"21.Operating-System","slug":"21-Operating-System","permalink":"https://beefyheisenberg.github.io/categories/21-Operating-System/"}],"tags":[]},{"title":"01.CPU缓存相关知识","slug":"21.Operating-System/01.CPU_Cache","date":"2024-01-24T01:27:52.379Z","updated":"2024-01-24T01:27:52.379Z","comments":true,"path":"21.Operating-System/01.CPU_Cache/","link":"","permalink":"https://beefyheisenberg.github.io/21.Operating-System/01.CPU_Cache/","excerpt":"@ref: 与程序员相关的CPU缓存知识 | 酷 壳 - CoolShell CPU Cache基础 一般来说, CPU Cache分三级: L1/L2/L3 CPU Cache大小: L1 &lt; L2 &lt; L3 例如：Intel Core i7-8700K ，是一个6核的CPU，每核上的L1是64KB（数据和指令各32KB），L2 是 256K，L3有2MB 读取速度: L1&gt; L2&gt; L3 L1 = 4个时钟 L2 = 11个时钟 L3 = 39个时钟 内存= 107个时钟 L1 分指令和数据Cache, 每个Core各一个指令和数据Cache, 每个Core一个L2, 所有Core 共享L3(见下图) CPU Cache命中","text":"@ref: 与程序员相关的CPU缓存知识 | 酷 壳 - CoolShell CPU Cache基础 一般来说, CPU Cache分三级: L1/L2/L3 CPU Cache大小: L1 &lt; L2 &lt; L3 例如：Intel Core i7-8700K ，是一个6核的CPU，每核上的L1是64KB（数据和指令各32KB），L2 是 256K，L3有2MB 读取速度: L1&gt; L2&gt; L3 L1 = 4个时钟 L2 = 11个时钟 L3 = 39个时钟 内存= 107个时钟 L1 分指令和数据Cache, 每个Core各一个指令和数据Cache, 每个Core一个L2, 所有Core 共享L3(见下图) CPU Cache命中➤ Cache Line 和N-Way查找策略 当要读取某个变量的值, 首先从CPU的L1 Cache里读, 读不到则取L2 Cache读…这样需要把内存地址映射到CPU Cache的某个地址 Cache Line: CPU把数据从内存加载到CPU Cache 并不是逐个字节加载的, Cache Line 是一次加载的最小单位, 一个主流的CPU的Cache Line 是 64 Bytes（也有的CPU用32Bytes和128Bytes） CPU 一般使用”N-Way 关联” (N-Way Associative)方式, 比如8-Way : 如果某CPU的L1 Cache有32KB, 则共有32KB/64 Bytes = 512个Line 因为是 8 way，故每一 Way 的 Line 数有: 512/8= 64个 此外,每个 Cache Line 前都有独立的 24 bit 来存”tag”, 也即内存地址的前 24 bit ➤ 【图】8-Way Associative 如何对 Cache 进行查找（36 bits 的物理内存地址，映射到 L1 Cache 的过程） 内存地址(36bit)分三部分: 24bit, 6bit, 6bit Index: 中间6bit 可以索引 2^6 = 64 行 (下图每行是一组, Set), 中间6位也叫做”Set Index”, 该 Set 有8个 Line Tag: 然后对这8个 Line(所以叫8Way) 进行 O(n) / n=8的遍历, 如果内存地址前24bit, 等于 Line 的 tag, 则找到了 Cache Line Offset: 内存地址后6位, 是在该 Line 内的偏移 通过内存的中间 6 位，寻找对应的 Set Index ，这一步是 O(1)的，然后通过前 24 位的 Tag 进行匹配，这一步是 O(n) n=8 的 当 CPU Cache 未命中时, 会从内存(以 Cache Line 为最小单位)加载到 Cache, 但每次并不仅仅加载一个 Cache Line 的数据, 因为访问内存太慢了, CPU 会通过”预加载” (Prefetching)技术预先加载更多的内存到 CPU Cache. 比如，你在 for-loop 访问一个连续的数组，你的步长是一个固定的数，内存就可以做到 prefetching。 缓存一致性@todo 未完待续","categories":[{"name":"21.Operating-System","slug":"21-Operating-System","permalink":"https://beefyheisenberg.github.io/categories/21-Operating-System/"}],"tags":[{"name":"CPU","slug":"CPU","permalink":"https://beefyheisenberg.github.io/tags/CPU/"}]},{"title":"01.与程序员相关的CPU基础知识","slug":"21.Operating-System/01.CPU_Basics","date":"2024-01-24T01:27:52.375Z","updated":"2024-01-24T01:27:52.375Z","comments":true,"path":"21.Operating-System/01.CPU_Basics/","link":"","permalink":"https://beefyheisenberg.github.io/21.Operating-System/01.CPU_Basics/","excerpt":"➤ 超线程(有时又叫对称多线程，SMT)是一种比较特殊的情况，每个线程并不能真正并发地运行。它们共享着除寄存器外的绝大多数处理资源。过到目前为止，Intel 的 CPU 最多只有两个线程。CPU 负责对各线程进行时分复用，CPU 可以在当前运行的超线程发生延迟时，调度另一个线程。这种延迟一般由内存访问引起。 随着 CPU 的核心频率大幅上升，缓存与核心的速度差越拉越大，CPU 的处理开始管线化。也就是说，指令的执行分成若干阶段。首先，对指令进行解码，随后，准备参数，最后，执行它。这样的管线可以很长(例如，Intel 的 Netburst 架构超过了20个阶段)。在管线很长的情况下，一旦发生延误(即指令流中断)，需要很长时间才能恢复速度。管线延误发生在这样的情况下: 下一条指令未能正确预测，或者装载下一条指令耗时过长(例如，需要从内存读取时) 内存以比 cache line 还小的块从主存储器向缓存传送。如今64位可一次性传送，cache line 的大小为64或128比特。这意味着每个 cache line 需要8或16次传送。内存控制器可以按不同顺序去请求 cache line 中的字。当处理器告诉它，程序需要缓存中具体某个字，即「关键字(critical word)」时，内存控制器就会先请求这个字。一旦请求的字抵达，虽然 cache line 的剩余部分还在传输中，缓存的状态还没有达成一致，但程序已经可以继续运行。这种技术叫做关键字优先及较早重启(Critical Word First &amp; Early Restart) ➤ 指令缓存随着 CPU 的核心频率大幅上升，缓存与核心的速度差越拉越大，CPU 的处理开始管线化。也就是说，指令的执行分成若干阶段。首先，对指令进行解码，随后准备参数，最后执行它。这样的管线可以很长(例如，Intel 的 Netburst 架构超过了20个阶段)。在管线很长的情况下，一旦发生延误(即指令流中断)，需要很长时间才能恢复速度。管线延误发生在这样的情况下: 下一条指令未能正确预测，或者装载下一条指令耗时过长(例如，需要从内存读取时)。","text":"➤ 超线程(有时又叫对称多线程，SMT)是一种比较特殊的情况，每个线程并不能真正并发地运行。它们共享着除寄存器外的绝大多数处理资源。过到目前为止，Intel 的 CPU 最多只有两个线程。CPU 负责对各线程进行时分复用，CPU 可以在当前运行的超线程发生延迟时，调度另一个线程。这种延迟一般由内存访问引起。 随着 CPU 的核心频率大幅上升，缓存与核心的速度差越拉越大，CPU 的处理开始管线化。也就是说，指令的执行分成若干阶段。首先，对指令进行解码，随后，准备参数，最后，执行它。这样的管线可以很长(例如，Intel 的 Netburst 架构超过了20个阶段)。在管线很长的情况下，一旦发生延误(即指令流中断)，需要很长时间才能恢复速度。管线延误发生在这样的情况下: 下一条指令未能正确预测，或者装载下一条指令耗时过长(例如，需要从内存读取时) 内存以比 cache line 还小的块从主存储器向缓存传送。如今64位可一次性传送，cache line 的大小为64或128比特。这意味着每个 cache line 需要8或16次传送。内存控制器可以按不同顺序去请求 cache line 中的字。当处理器告诉它，程序需要缓存中具体某个字，即「关键字(critical word)」时，内存控制器就会先请求这个字。一旦请求的字抵达，虽然 cache line 的剩余部分还在传输中，缓存的状态还没有达成一致，但程序已经可以继续运行。这种技术叫做关键字优先及较早重启(Critical Word First &amp; Early Restart) ➤ 指令缓存随着 CPU 的核心频率大幅上升，缓存与核心的速度差越拉越大，CPU 的处理开始管线化。也就是说，指令的执行分成若干阶段。首先，对指令进行解码，随后准备参数，最后执行它。这样的管线可以很长(例如，Intel 的 Netburst 架构超过了20个阶段)。在管线很长的情况下，一旦发生延误(即指令流中断)，需要很长时间才能恢复速度。管线延误发生在这样的情况下: 下一条指令未能正确预测，或者装载下一条指令耗时过长(例如，需要从内存读取时)。 为了解决这个问题，CPU 的设计人员们在分支预测上投入大量时间和芯片资产(chip real estate)，以降低管线延误的出现频率。 在 CISC 处理器上，指令的解码阶段也需要一些时间。x86及 x86-64处理器尤为严重。近年来，这些处理器不再将指令的原始字节序列存入 L1i，而是缓存解码后的版本。这样的 L1i 被叫做“追踪缓存(trace cache)”。追踪缓存可以在命中的情况下让处理器跳过管线最初的几个阶段，在管线发生延时时尤其有用。L2 以上的缓存是统一缓存，既保存代码，也保存数据。这里保存的代码是原始字节序列，而不是解码后的形式。 每个程序员都应该了解的内存知识-1 : https://lrita.github.io/2018/06/30/programmer-should-know-about-memory-1/#334-%E5%A4%9A%E5%A4%84%E7%90%86%E5%99%A8%E6%94%AF%E6%8C%81 ➤ 高速缓存 -&gt; 01.CPU_Cache","categories":[{"name":"21.Operating-System","slug":"21-Operating-System","permalink":"https://beefyheisenberg.github.io/categories/21-Operating-System/"}],"tags":[{"name":"CPU","slug":"CPU","permalink":"https://beefyheisenberg.github.io/tags/CPU/"}]},{"title":"Alg.22.递归","slug":"19.Algorithm/Alg.22.递归","date":"2024-01-24T01:27:52.371Z","updated":"2024-01-24T01:27:52.371Z","comments":true,"path":"19.Algorithm/Alg.22.递归/","link":"","permalink":"https://beefyheisenberg.github.io/19.Algorithm/Alg.22.递归/","excerpt":"递归特征： 自身调用：原问题可以分解为子问题，子问题和原问题的求解方法是一致的，即都是调用自身的同一个函数。 终止条件：递归必须有一个终止的条件，即不能无限循环地调用本身。 public int sum(int n) &#123; if (n &lt;= 1) &#123; return 1; &#125; return sum(n - 1) + n; &#125; 递归经典问题","text":"递归特征： 自身调用：原问题可以分解为子问题，子问题和原问题的求解方法是一致的，即都是调用自身的同一个函数。 终止条件：递归必须有一个终止的条件，即不能无限循环地调用本身。 public int sum(int n) &#123; if (n &lt;= 1) &#123; return 1; &#125; return sum(n - 1) + n; &#125; 递归经典问题 阶乘问题 汉诺塔问题 斐波那契数列 青蛙跳台阶 二叉树深度 快速排序、归并排序（分治算法体现递归） https://mp.weixin.qq.com/s?__biz=Mzg3Mzc0NjUzMQ==&amp;mid=2247497052&amp;idx=2&amp;sn=14aca9fdb86d38b8765d6440a7600240&amp;source=41#wechat_redirect","categories":[{"name":"19.Algorithm","slug":"19-Algorithm","permalink":"https://beefyheisenberg.github.io/categories/19-Algorithm/"}],"tags":[]},{"title":"影响程序员发展的十类算法（zz）","slug":"19.Algorithm/Alg.20a.IntroductionToAlgorithm","date":"2024-01-24T01:27:52.366Z","updated":"2024-01-24T01:27:52.367Z","comments":true,"path":"19.Algorithm/Alg.20a.IntroductionToAlgorithm/","link":"","permalink":"https://beefyheisenberg.github.io/19.Algorithm/Alg.20a.IntroductionToAlgorithm/","excerpt":"基本思想（时空复杂度，规约，枚举，贪心，分治，递推与递归，构造，模拟） 排序（冒泡，选择，插入，归并，堆，快速，桶，基数，希尔，Timsort）（Top K） 经典数据结构（栈，队列，链表，哈希，单调队列，优先队列，平衡树，线段树，并查集） 搜索（BFS，DFS，A*搜索) 基础数学算法（二分查找算法，欧几里得算法，快速幂算法） 图论基础算法（拓扑排序，最小生成树算法，最短路径算法） 动态规划算法（最长上升子序列，最长公共子序列，最大连续子段和，背包问题） 计算几何算法（线段交，凸包，平面最近点对） 字符串匹配算法（KMP算法，Trie树） 网络流算法（最大流算法，最小费用最大流算法） 基本思想时空复杂度归约","text":"基本思想（时空复杂度，规约，枚举，贪心，分治，递推与递归，构造，模拟） 排序（冒泡，选择，插入，归并，堆，快速，桶，基数，希尔，Timsort）（Top K） 经典数据结构（栈，队列，链表，哈希，单调队列，优先队列，平衡树，线段树，并查集） 搜索（BFS，DFS，A*搜索) 基础数学算法（二分查找算法，欧几里得算法，快速幂算法） 图论基础算法（拓扑排序，最小生成树算法，最短路径算法） 动态规划算法（最长上升子序列，最长公共子序列，最大连续子段和，背包问题） 计算几何算法（线段交，凸包，平面最近点对） 字符串匹配算法（KMP算法，Trie树） 网络流算法（最大流算法，最小费用最大流算法） 基本思想时空复杂度归约问题：如果某个问题已经找到了一种解法，如何证明这个问题可解决的时间下界。解法：用归约，从已知证未知。A问题可以线性归约到B问题的转化是单向的，是从已知问题到未知问题，从难度更低的问题转化为难度更高的问题。如：一元一次方程可以归约到一元二次方程。题目：使用排序算法对求凸包下界进行评估： 枚举贪心分治 递推与递归题目：求第$n$个斐波那契数$$ f(n)=f(n-1)+f(n-2), f(1)=1, f(2)=1 $$ 构造题目：各阶幻方的构造算法 模拟题目：给定麻将规则，问至少还需几轮能够胡牌 排序 冒泡排序 选择排序 插入排序 归并排序 堆排序 快速排序 桶排序：将数组分到有限数量的桶里，每个桶再个别排序。题目：小学生成绩排名 基数排序：将整数按位数切割成不同的数字，然后按每个位数分别比较。可以看做是从低位到高位进行的桶排序。 希尔排序：也称递减增量排序算法，是插入排序的一种更高效的改进版本。 Timsort：一种混合的稳定的排序算法，派生自归并排序和插入排序。 Pyhton自从2.3版以来一直采用Timsort算法排序，Java SE7，Android，GNU Octave也采用Timsort算法对数组排序。 题目：从$n$个数中找到前$k$大的数 经典数据结构栈队列链表哈希题目：存在一个系数和变量都是整数的等式:$$ a_1 x_1^3 + a_2 x_2^3 + a_3 x_3^3 + a_4 x_4^3 + a_5 x_5^3 = 0 $$$\\forall i∈{1,2,3,4,5}, x_i∈[-50,50], a_i∈[-50,50]$，问有多少组解。解法：将变量分成两部分，先hash一部分的结果，另一部分计算出结果再去查找。 单调队列题目：长度为$n$的数组上有个长度为$k$的滑窗从左向右移动，求每次移动后滑窗区间的最小值和最大值。输出两行，第一行所有最小值，第二行所有最大值。 解法：可以用线段树来做，复杂度O(nlogn)，但是使用单调队列更简单，复杂度是O(n)。 优先队列堆的核心操作函数，维护堆: BUILD: O(n), for (i=n/2; i&gt;0; i–) max_heap(i);UPDATE: O(logn)INSERT: 先插入到堆的最后一个元素，然后不断和其父亲(/2)比较大小，一个for循环维护堆DELETE: O(logn) 删除堆顶元素，把最后一个元素拿到堆顶，然后维护堆 平衡树AVL一种典型适度平衡的二叉搜索树。需要为其中的每一个节点引入一个名为平衡因子的指标，节点的平衡因子是它的左子树的高度减去它的右子树的高度。带有平衡因子1、0或 -1的节点被认为是平衡的。带有平衡因子 -2或2的节点被认为是不平衡的，并需要重新平衡这个树。 高度为$h$的AVL树，至少包含$S(h)=fib(h+3)-1$个节点 INSERT: O(1)DELETE: O(logn)优点: 无论查找、插入或删除，最坏情况下的复杂度均为O(logn)时间复杂度,O(n)的存储空间。缺点: 借助高度或平衡因子，为此需改造元素结构，或额外封装； 实测复杂度与理论值尚有差距； 单次动态调整后，全数拓扑结构的变化量可能高达O(logn) 。 RB-Tree（红黑树，即是B-树(2,4)）引入“颜色”的目的在于使得红黑树的平衡条件得以简化，与B树对应。INSERT: O(logn)DELETE: O(logn)优点: 任何一次动态操作引发的结构变化量不超过O(1)，特别适合用来实现持久化的搜索树，作为可持久化数据结构比较好； 红黑树每个节点只需要1-bit附加空间。 缺点: 太复杂，插入有5种情况，删除有6种情况，代码量大，编写容易出错。 红黑树并不是真正的平衡二叉树，但在实际应用中，红黑树的统计性能要高于平衡二叉树，但极端性能略差。 Splay节点$V$一旦被访问，随即转移至树根，“一步一步往上爬”。效率取决于：树的初始形态以及节点访问次序。可以做到单趟伸展操作，分摊O(logn)时间！INSERT:O(logn)DELETE:O(logn)优点: 无需记录节点高度或平衡因子； 编程实现简单易行–优于AVL树，分摊复杂度O(logn)。 局部性强、缓存命中率极高时，效率更好。 缺点: 仍不能杜绝单次最坏情况的出现，不适用于对效率敏感的场合。 线段树也叫区间树，是一棵二叉树，适用于和区间统计有关的问题。 经典的问题模型： 单点修改，区间查询 区间修改，单点查询 区间修改，区间查询 题目：给定原始数组$a[]={2,5,3,4,1}, a[i] &lt;= n$，求$b[i]$=位置$i$左边小于等于$a[i]$的数的个数。如样例中$b[]={0,1,1,2,0}$。 解法：初始化线段树$1..n$位置上的数都为$0$，然后从左到右遍历数组，对于每个位置的数$a[i]$，$b[i]=sum(1, a[i]-1)$，然后在$a[i]$值所在的位置增加1。 并查集并查集是一种树型的数据结构，用于处理一些不相交集合（Disjoint Sets）的合并及查询问题。经典应用：Kruskal算法求最小生成树中判断新加入的边是否在同一棵树内部。 搜索BFSDFSA*搜索In the standard terminology used when talking about A, $g(n)$ represents the exact cost of the path from the starting point to any vertex $n$, and $h(n)$ represents the heuristic estimated cost from vertex $n$ to the goal.A balances the two as it moves from the starting point to the goal. Each time through the main loop, it examines the vertex $n$ that has the lowest $f(n) = g(n) + h(n)$.A*算法和DFS、BFS有着较深关系，其中的$g(n)$和$h(n)$作为两个不同的代价: 在DFS的搜索中，其关注的主要是邻居节点与当前节点的距离开销，此时可将$g(n)$认为是0； 在BFS中进行分层搜索时，以层次距离为主，此时可将$h(n)$认为是0。而且，当$h(n)$认为是0，则转换为单源最短路径计算。 题目：八数码问题 基础数学算法二分查找算法问题：在一个给定的升序数组array中，找到第一个大于或者等于x的数的位置，没有则返回-1。 int search(int[] array, int low, int high, int x) &#123; int ans = -1; while (low &lt;= high) &#123; int mid = low + (high - low) / 2; if (judge(mid)) &#123; ans = mid; high = mid - 1; &#125; else low = mid + 1; &#125; return ans;&#125; 问题变形： 求第一个大于x的数的位置 求最后一个小于x的数的位置 求最后一个小于或者等于x的数的位置 如果当前数组不是升序而是降序的话 题目：给定$n$个木棍，每个木棍有一个长度（精确到两位小数），需要把他们截成$k$个长度相同的小木棍，求小木棍的最大长度。 解答：把最大长度的小木棍的值作为二分变量，进行浮点数的二分。 题目：一条长为L（1~1,000,000,000）的河中，有$n$(1~50,000)块可垫脚的石头，给出它们与起始点的距离$rock[i]$，移除其中的$m$块使得具有最小间距的相邻两块石头之间的距离最大。 解答：二分最终的结果，用上述整数二分的写法进行处理，每一次判断使用贪心策略，记录每次符合条件的策略，二分最后得到的就是最终的答案。 二分经典应用：求上（下）界的最小（大）值 欧几里得算法求两个整数的最大公约数－－辗转相除法 int gcd(int a, int b) &#123; if (a == 0) return b; return gcd(b, a % b);&#125; 快速幂算法问题：$a, b$都是整数，如何快速求$a^b$ int fpow(int a, int b)&#123; int result = 1; for (; b; b &gt;&gt;= 1) &#123; if (b &amp; 1) result = result * a; a = a * a; ｝ return result;&#125; 题目：快速求第$n$个斐波那契数。 解法：经典的矩阵快速幂，下面这个式子是成立的：不停地利用这个式子迭代右边的列向量，会得到下面的式子：这样，问题就转化为如何计算这个矩阵的$n$ 次方了。 图论基础算法拓扑排序在图论中，如果一个有向图从任意顶点出发无法经过若干条边回到该点，则这个图是一个有向无环图（DAG图）。 最小生成树算法Prim算法 最小边、权的数据结构 时间复杂度（总计） 邻接矩阵、搜索 $O(V^2)$ 二叉堆（后文伪代码中使用的数据结构）、邻接表 $O((V + E) log(V)) = O(E log(V))$ 斐波那契堆、邻接表 $O(E + V log(V))$ Kruskal算法kruskal算法的基本思想（使用到了并查集）： 首先将$G$的$n$个顶点看成$n$个孤立的连通分支（$n$个孤立点）并将所有的边按权从小大排序。 按照边权值递增顺序，如果加入边后存在圈则这条边不加，直到形成连通图 时间复杂度：$\\mathrm {O} (Elog_{2}E) E$为图中的边数 最短路径算法Dijkstra算法对于不含负权的有向图，这是目前已知的最快的单源最短路径算法。不采用最小优先级队列，时间复杂度是 ${\\displaystyle O(|V|^{2})} )$(其中 $\\displaystyle |V|$为图的顶点个数)。用邻接表+二叉堆或者斐波纳契堆用作优先队列来查找最小的顶点时，时间复杂度是$O(|E|+|V|\\log |V|) $(其中$\\displaystyle |E|$是边数) Floyd-Warshall算法任意两点间的最短路径的一种算法，可以正确处理有向图或负权（但不可存在负权回路）的最短路径问题，同时也被用于计算有向图的传递闭包。Floyd-Warshall算法的时间复杂度为 $\\displaystyle O(N^{3})$，空间复杂度为 $\\displaystyle O(N^{2})$。 核心思想是动态规划算法，其中$dist[i][j]$表示由点 $\\displaystyle i$到点 $\\displaystyle j$的代价，∞ 表示两点之间没有任何连接。 动态规划算法数字三角形[IOI 1994]题目：有一个数字三角形，从最顶层出发，每一步只能向左下或右下方向走。编程求从最顶层到最底层的一条路所经过位置上的数字之和的最大值。 动态规划核心思想： 最优子结构：如果问题的最优解所包含的子问题的解也是最优的，我们就称该问题具有最优子结构性质（即满足最优化原理）。 重叠子问题：子问题重叠性质是指在用递归算法自顶向下对问题进行求解时，每次产生的子问题并不总是新问题，有些子问题会被重复计算多次。动态规划算法正是利用了这种子问题的重叠性质，对每一个子问题只计算一次，然后将其计算结果保存起来，当再次需要计算已经计算过的子问题时，从保存的记录中查看一下结果，从而获得较高的效率。 最长上升子序列最长公共子序列最大连续子段和背包问题 01背包 完全背包 多重背包 混合三种背包 二维费用背包 分组背包 计算几何算法向量性质向量点积向量的点积结果跟两个向量之间的角度有关 向量叉积向量积可以被定义为：$a \\times b = absin\\theta$（在这里$θ$表示两向量之间的夹角(共起点的前提下)（$0° ≤ θ ≤ 180°$） $c$的长度在数值上等于以$a$，$b$，夹角为$θ$组成的平行四边形的面积。 To-Left Test问题：给定三个二维平面的点，$p,q,r$，问$\\overrightarrow{pr}$向量是否在$\\overrightarrow{pq}$向量的左侧 解答：使用叉乘，结果大于0时在左侧，等于0时共线，小于0时在右侧。 问题：如何判断一个点是否在一个三角形内部 解答：$InTriangle(p,q,r,k)$当且仅当$$ToLeft(p,q,k) == ToLeft(q,r,k) == ToLeft(r,p,k)$$问题：如何判断一个点是否在一个凸多边形内部 解答：看所有的ToLeft值是否都大于0问题：求给定多边形的面积 解答：把多边形分成若干个三角形，按照逆时针依次求每个三角形的有向面积。对用 $\\displaystyle (x_{1},y_{1}),(x_{2},y_{2}),\\dots ,(x_{n},y_{n})$（按逆时针排列）描述的多边形，其面积为：$$\\displaystyle A={\\frac {1}{2}}\\left({\\begin{vmatrix}x_{1}&amp;y_{1}\\x_{2}&amp;y_{2}\\end{vmatrix}}+{\\begin{vmatrix}x_{2}&amp;y_{2}\\x_{3}&amp;y_{3}\\end{vmatrix}}+\\dots +{\\begin{vmatrix}x_{n}&amp;y_{n}\\x_{1}&amp;y_{1}\\end{vmatrix}}\\right)$$ 凸包点集Q的凸包（convex hull）是指一个最小凸多面体，满足Q中的点或者在多面体边上或者在其内。 经典算法： 增量式算法：逐次将点加入，然后检查之前的点是否在新的凸包上，时间复杂度为 $\\displaystyle O(n^{2})$。 包裹法（Jarvis步进法）。时间复杂度为 $\\displaystyle O(kn)$，$k$表示输出的面的数量，$n$表示点集的个数，复杂度与输出凸包的面相关。 葛立恒（Graham）扫描法，算法的整体时间复杂度是 $\\displaystyle O(n\\log {n})$，缺点是只能处理二维情况。 分治法：将点集$X$分成两个不相交子集。求得两者的凸包后，计算这两个凸包的凸包，该凸包就是$X$的凸包。时间复杂度是$\\displaystyle O(n\\log {n})$。 解决三维凸包问题，主要有包裹法、分治法、随机增量算法、快速凸包算法。 平面最近点对给定平面上$n$个点，找其中的一对点，使得在$n$个点的所有点对中，该点对的距离最小。经典算法： 分治法，时间复杂度O(nlogn) 随机增量法，时间复杂度O(n)，且向高维扩展容易 字符串匹配算法KMP算法问题：在一个主文本字符串S内查找一个词W的出现位置。思想：通过运用对这个词在不匹配时本身就包含足够的信息来确定下一个匹配将在哪里开始的发现，从而避免重新检查先前匹配的字符。next[j]取决于模式串中T[0 ~ j-1]中前缀和后缀相等部分的长度，并且next[j]恰好等于这个最大长度；此外在j位匹配出错，刚好是从next[j]位开始重新匹配；next[j]在j-1处产生。 void getnxt(char *t,int *f)&#123; //字符串长度至少为1，求nxt数组 int i,j,len=strlen(t); f[0]=f[1]=0; for (i=1; i&lt;len; i++)&#123; j=f[i]; while (j &amp;&amp; t[i]!=t[j]) j=f[j]; f[i+1]= t[i]==t[j] ? j+1 : 0; &#125;&#125;int kmp(char *s,char *t,int *f)&#123; //这里肯定是O(n+m)的 int i,j,tem,n=strlen(s),m=strlen(t); getnxt(t,f); for (i=j=0; i&lt;n; i++)&#123; while (j &amp;&amp; s[i]!=t[j]) j=f[j]; if (s[i]==t[j]) j++; if (j==m) return i-m+1; //if (j==m) num++,j=f[j]; //若统计有多少个 &#125; return -1;&#125; 时间复杂度分析：在kmp函数中，每一次while 循环$j$的值都会减小（至少为1），然而每一次j++都伴随一次i++，所以总的复杂度是O(n)。在getnxt函数中过程类似。 题目：找出第一个字符串在第二个字符串中出现次数。 题目：求既是前缀串儿又是后缀串儿的不同子串的长度，长度从小到大输出。 解答：next数组的性质是，该字符之前的字符串的最大相同前缀后缀。既然知道了最大的，即next[len]，递归一次next[ next[len] ]，就能求得更小的前缀。不断的递归把所有所有可能的长度找出来，然后递归输出即可。 题目：给出一个字符串，求出这个字符串最多能够由多少个子串首尾连接而成。比如“ababab”就是由3个“ab”相连而成，所以输出3，“abcdef”只能看作一个“abcdef”所以输出1。 解答：KMP中next数组的巧妙运用。在这里我们假设这个字符串的长度是len，那么如果len可以被len-next[len]整除的话，我们就可以说len-next[len]就是那个最短子串的长度。 Trie树问题：给你100000个长度不超过10的单词。对于每一个单词，我们要判断他出没出现过，如果出现了，求第一次出现在第几个位置。又称前缀树或字典树，是一种有序树，用于保存关联数组，其中的键通常是字符串。题目：设计一个算法可以自动列出以输入字符串为前缀的单词中最频繁查找的前10个单词。 注：类似google搜索框中输入要查找的单词，输入前缀google会自动列出同一前缀的所有查找单词中top 10的 解答： 节点上记录每个单词被查找的次数 对于给定的输入词，找到其在Trie中的位置，设为节点K 搜索以节点K为根的子树，用一个最小堆记录top10 Trie树＋KMP问题：在输入的一串字符串中匹配有限组“字典”中的子串。AC自动机算法算是比较简单直观的字符串匹配自动机，它其实就是在一颗Trie树上建一些失配指针，当失配时只要顺着失配指针走，就能避免一些重复的计算。算法均摊情况下具有近似于线性的时间复杂度。 应用：多模式串匹配问题。当一个字典串集合是已知的(例如一个计算机病毒库), 就可以以离线方式先将自动机求出并储存以供日后使用。 UNIX系统中的一个命令fgrep就是以AC自动机算法作为基础实现的。 nginx模块用于判断User-Agent（用户的浏览器信息）的核心算法就是AC自动机 网络流算法最大流算法在优化理论中,最大流问题涉及到在一个单源点、单汇点的网络流中找到一条最大的流。 经典算法核心是将一条边的单向残留容量的减少看做反向残留流量的增加，然后每次寻找增广路径（就是新的流量），直到无法找到增广路径为止。 Edmonds–Karp算法：使用广度优先搜索寻找增广路径。 Dinic算法 SAP算法 题目：有N个牛，F个食物，D个饮料，每个牛喜欢一些食物和饮料，现在要给牛分发食物和饮料，当一个牛得到一个喜欢的食物和一个喜欢的饮料的时候，就说这个牛被满足了。求最多可以满足多少个牛。每个饮料和食物只能被分给一个牛，每个牛也只能拿到一个饮料和食物。 解法：一头牛贡献一单位的流量，所以把牛拆了，中间加一个1容量的边，然后起点到所有饮料连1容量边，饮料到喜欢自己的牛连1容量边，牛到他喜欢的食物连1容量的边，所有食物向终点连1容量的边。 题意：有N个农场，P条无向路连接。要从1到N不重复走一条路地走T次，求所经过的直接连接两个区域的道路中最长道路的最小值。 解法：源点向1连容量T的边。二分最小长度，长度超过mid的边容量为0，否则为1，用最大流判可行性。 最小费用最大流算法最小费用最大流问题是经济学和管理学中的一类典型问题。在一个网络中每段路径都有“容量”和“费用”两个限制的条件下，此类问题的研究试图寻找出：流量从A到B，如何选择路径、分配经过路径的流量，可以达到所用的费用最小的要求。在实际中：$n$辆卡车要运送物品，从A地到B地。由于每条路段都有不同的路费要缴纳，每条路能容纳的车的数量有限制，如何分配卡车的出发路径可以达到费用最低，物品又能全部送到。 最小费用最大流与一般增广路的区别在于，每次寻找的增广路都是代价最小的路径。以代价为边的权重，求单源最短路径。 题目：给出一个无向图，求从1到N走两次的最短路，每条路不能重复走。 解法：S向1连容量2，费用0的边，N向T连容量2，费用0的边，节点间连容量1，费用为边权的边。一次费用流。 题目：给出一个n*n的矩阵,每一格有一个非负整数Aij,(Aij &lt;= 1000)现在从(1,1)出发,可以往右或者往下走,最后到达(n,n),每达到一格,把该格子的数取出来,该格子的数就变成0,这样一共走K次,现在要求K次所达到的方格的数的和最大 解法：$k$为１或者２时可以动态规划 $k$为２时： 四维dp，$dp[x_1][y_1][x_2][y_2]$表示从起点（1，1）开始到点$（x_1，y_1）（x_2，y_2）$的最优路线 三维dp，因为$x_1+y_1=x_2+y_2=k$(当前走的步数)，所以$dp[k][x_1][x_2]$表示走了$k$步第一个人停留在$x_1$位置，第二个人停留在$x_2$的位置（对应的$y$值可以算出来）。 解法：用最小费用最大流来解对于每一个格子，我们拆成两个点（因为要限制流量）；每一个格子可以取一次，但是每一个格子是可以走多次的，那么我们在两个点中建两种边： 费用为权值，流量为１ 费用为0，流量为$\\infty$（或$k-1$, $k$都行）","categories":[{"name":"19.Algorithm","slug":"19-Algorithm","permalink":"https://beefyheisenberg.github.io/categories/19-Algorithm/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://beefyheisenberg.github.io/tags/数据结构与算法/"},{"name":"动态规划","slug":"动态规划","permalink":"https://beefyheisenberg.github.io/tags/动态规划/"},{"name":"二分查找","slug":"二分查找","permalink":"https://beefyheisenberg.github.io/tags/二分查找/"},{"name":"优先队列","slug":"优先队列","permalink":"https://beefyheisenberg.github.io/tags/优先队列/"},{"name":"平衡树","slug":"平衡树","permalink":"https://beefyheisenberg.github.io/tags/平衡树/"},{"name":"线段树","slug":"线段树","permalink":"https://beefyheisenberg.github.io/tags/线段树/"},{"name":"并查集","slug":"并查集","permalink":"https://beefyheisenberg.github.io/tags/并查集/"},{"name":"BFS","slug":"BFS","permalink":"https://beefyheisenberg.github.io/tags/BFS/"},{"name":"DFS","slug":"DFS","permalink":"https://beefyheisenberg.github.io/tags/DFS/"},{"name":"欧几里得算法","slug":"欧几里得算法","permalink":"https://beefyheisenberg.github.io/tags/欧几里得算法/"},{"name":"拓扑排序","slug":"拓扑排序","permalink":"https://beefyheisenberg.github.io/tags/拓扑排序/"},{"name":"最小生成树","slug":"最小生成树","permalink":"https://beefyheisenberg.github.io/tags/最小生成树/"}]},{"title":"Alg.20.算法概述","slug":"19.Algorithm/Alg.20.算法概述","date":"2024-01-24T01:27:52.361Z","updated":"2024-01-24T01:27:52.362Z","comments":true,"path":"19.Algorithm/Alg.20.算法概述/","link":"","permalink":"https://beefyheisenberg.github.io/19.Algorithm/Alg.20.算法概述/","excerpt":"@todo: 算法设计: 排序, 贪心, 分治, 动态规划, 回溯, 随机化 数学基础: 二分查找, 欧几里得算法, 快速幂算法 字符串匹配算法: KMP 图论算法: 拓扑顺序 最短路径: Dijkstra算法, Floyd-Warshall算法 最小生成树: Prim, Kruskal 搜索算法: BFS, DFS, A*搜索 几何算法: 向量, 凸包 快速傅里叶变换(FFT): 离散傅里叶变换 复杂度分析几何级数 &amp; 算数级数 几何级数: $$ 1 + 2^1 + 2^2 + … + 2^N = 2^(N+1) -1 ≈ 2^N $$ 算术级数: $$ 1 + 2 + 3 + … + N = N(N+1)/2 ≈ N^2/2 $$","text":"@todo: 算法设计: 排序, 贪心, 分治, 动态规划, 回溯, 随机化 数学基础: 二分查找, 欧几里得算法, 快速幂算法 字符串匹配算法: KMP 图论算法: 拓扑顺序 最短路径: Dijkstra算法, Floyd-Warshall算法 最小生成树: Prim, Kruskal 搜索算法: BFS, DFS, A*搜索 几何算法: 向量, 凸包 快速傅里叶变换(FFT): 离散傅里叶变换 复杂度分析几何级数 &amp; 算数级数 几何级数: $$ 1 + 2^1 + 2^2 + … + 2^N = 2^(N+1) -1 ≈ 2^N $$ 算术级数: $$ 1 + 2 + 3 + … + N = N(N+1)/2 ≈ N^2/2 $$ 复杂度表示法▶ 大O符号（英语：Big O notation） 用另一个（通常更简单的）函数来描述一个函数数量级的渐近上界。设函数 $f(n)$ 代表某一算法在输入大小为n的情况下的工作量（效率），我们将 $f(n)$ 与另一行为已知的函数 $g(n)$ 进行比较，如果存在正数 C 和 n0，使得对于一切 $ n &gt;= n0 $ 有： $ 0 &lt;= f(n) &lt;= C g(n) $，则可以称 $f(n)$ 的渐进上界是 $g(n)$，记做 $ f(n) = O(g(n)) $， ▶ 小O符号： 类似大O，也用来表示「渐近上界」，对于任意正数 C 和 n0，使得对于一切 $ n &gt;= n0 $ 有： $ 0 &lt;= f(n) &lt; C g(n) $，则可以称 $f(n)$ 的渐进下界是 $g(n)$，记做 $ f(n) = o(g(n)) $。注意与大O定义的不同： 大O:「只要存在一个正数C」以及 $ f(n) &lt;= C g(n) $。 小O:「任意正数C」以及 $ f(n) &lt; C g(n) $。 两者都描述上限，但小O是更强有力的陈述，如果f∈o(g)，则f和g的增长率之间的差距比f∈O(g)时大得多。 例如, $ f(n) = n^2 + n $，则 $ f(n) $ 的复杂度可以记为 $ o(n^3) $ ▶ 大Ω符号，读音：big omega，用另一个（通常更简单的）函数来描述一个函数数量级的「渐进下界」。如果存在正数 C 和 n0，使得对于一切 $ n &gt;= n0 $ 有： $ 0 &lt;= C g(n) &lt;= f(n) $，则可以称 $f(n)$ 的渐进下界是 $g(n)$，记做 $ f(n) = Ω(g(n)) $ @ref: 007函数的渐近的界 - 算法基础 | Coursera 常用算法复杂度分析算法中 $log$ 级别的时间复杂度都是由于使用了分治思想, 这个底数直接由分治的复杂度决定: 如果采用二分法, 那么就是 $log_2n$, 三分法就是 $log_3n$, 其他亦然; 不过无论底数是什么, 对数函数的渐进趋势是一样的, 所以通常忽略底数只用 $logn$ 表示; 场景复杂度的增长趋势如下图: $O(1) &lt; O(logn) &lt; O(n) &lt; O(nlogn) &lt; O(n^2) &lt; O(n^3) &lt; O(2^n) &lt; O(n!) &lt; O(n^n)$ 排序算法复杂度 数据结构复杂度 Big-O Cheat @ref： Big-O Algorithm Complexity Cheat Sheet (Know Thy Complexities!) @ericdrowell 算法设计贪婪 贪心算法详解 分治 分治算法详解 map-reduce中的分治思想 回溯@todo 动态规划 动态规划详解 图论算法深度优先 &amp; 广度优先@todo 拓扑排序@todo 最短路径算法@todo 无权最短路径@todo Dijkstra算法@todo 网络流问题@todo 最小生成树@todo","categories":[{"name":"19.Algorithm","slug":"19-Algorithm","permalink":"https://beefyheisenberg.github.io/categories/19-Algorithm/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://beefyheisenberg.github.io/tags/数据结构与算法/"},{"name":"排序","slug":"排序","permalink":"https://beefyheisenberg.github.io/tags/排序/"},{"name":"贪心","slug":"贪心","permalink":"https://beefyheisenberg.github.io/tags/贪心/"},{"name":"分治","slug":"分治","permalink":"https://beefyheisenberg.github.io/tags/分治/"},{"name":"动态规划","slug":"动态规划","permalink":"https://beefyheisenberg.github.io/tags/动态规划/"},{"name":"回溯","slug":"回溯","permalink":"https://beefyheisenberg.github.io/tags/回溯/"},{"name":"二分查找","slug":"二分查找","permalink":"https://beefyheisenberg.github.io/tags/二分查找/"},{"name":"KMP","slug":"KMP","permalink":"https://beefyheisenberg.github.io/tags/KMP/"}]},{"title":"Alg.15.数据结构-堆","slug":"19.Algorithm/Alg.15.数据结构-堆","date":"2024-01-24T01:27:52.357Z","updated":"2024-01-24T01:27:52.358Z","comments":true,"path":"19.Algorithm/Alg.15.数据结构-堆/","link":"","permalink":"https://beefyheisenberg.github.io/19.Algorithm/Alg.15.数据结构-堆/","excerpt":"二叉堆 结构性：二叉堆是一个完全填满的二叉树（叶子节点都集中在左边）； 堆序性：父节点的键值总是大于或等于（小于或等于）任何一个子节点的键值：如果父节点的键值总是小于或等于子节点（根节点的值是最小的）, 那么称为小顶堆（min heap），反正择称为大顶堆（max heap） 二叉堆一般用数组来表示。如果根节点在数组中的位置是1，第_n_个位置的子节点分别在2_n_和 2_n_+1。因此，第1个位置的子节点在2和3，第2个位置的子节点在4和5。以此类推。这种基于1的数组存储方式便于寻找父节点和子节点。 如果存储数组的下标基于0，那么下标为 _i_ 的节点的子节点是 2i + 1 与 2i + 2 ；其父节点的下标是 floor((i − 1) ∕ 2)。函数 floor(x) 的功能是“向下取整”，或者说“向下舍入”，即取不大于 _x_ 的最大整数（与“四舍五入”不同，向下取整是直接取按照数轴上最接近要求值的左边值，即不大于要求值的最大的那个值）。比如 floor(1.1)、floor(1.9) 都返回1。 如下图的两个堆：","text":"二叉堆 结构性：二叉堆是一个完全填满的二叉树（叶子节点都集中在左边）； 堆序性：父节点的键值总是大于或等于（小于或等于）任何一个子节点的键值：如果父节点的键值总是小于或等于子节点（根节点的值是最小的）, 那么称为小顶堆（min heap），反正择称为大顶堆（max heap） 二叉堆一般用数组来表示。如果根节点在数组中的位置是1，第_n_个位置的子节点分别在2_n_和 2_n_+1。因此，第1个位置的子节点在2和3，第2个位置的子节点在4和5。以此类推。这种基于1的数组存储方式便于寻找父节点和子节点。 如果存储数组的下标基于0，那么下标为 _i_ 的节点的子节点是 2i + 1 与 2i + 2 ；其父节点的下标是 floor((i − 1) ∕ 2)。函数 floor(x) 的功能是“向下取整”，或者说“向下舍入”，即取不大于 _x_ 的最大整数（与“四舍五入”不同，向下取整是直接取按照数轴上最接近要求值的左边值，即不大于要求值的最大的那个值）。比如 floor(1.1)、floor(1.9) 都返回1。 如下图的两个堆： 将这两个堆保存在以1开始的数组中： 位置: 1 2 3 4 5 6 7 8 9 10 11左图: 1 2 3 4 5 6 7 8 9 10 11右图: 11 9 10 5 6 7 8 1 2 3 4 对于一个很大的堆，使用连续数组这种存储是低效的。因为节点的子节点很可能在另外一个内存页中。B-heap是一种效率更高的存储方式，把每个子树放到同一内存页。 如果用指针链表存储堆，那么需要能访问叶节点的方法。可以对二叉树“穿线”(threading)方式，来依序遍历这些节点。 @ref: 二叉堆 - 维基百科，自由的百科全书 插入操作 在数组的最末尾插入新节点。然后自下而上调整子节点与父节点（称作 up-heap 或 bubble-up, percolate-up, sift-up, trickle up, heapify-up, cascade-up 操作）：比较当前节点与父节点，不满足”堆性质”则交换。从而使得当前子树满足二叉堆的性质。复杂度 = O(logn) 插入操作需要维持堆序性，下图是向堆插入 14 的过程： 为将一个元素 X 插入到堆中，我们在下一个可用位置创建一个空穴，否则该堆将不是完全树。 如果 X 可以放在该空穴中而不破坏堆的序，那么插入完成。否则，我们把空穴的父节点上的元素移入该空穴中，这样，空穴就朝着根的方向上冒一步。继续改过程直到 X 能被放入空穴中为止。 这种实现过程称之为上滤：新元素在堆中上滤直到找出正确的插入位置。 删除操作 对于最大堆，删除根节点就是删除最大值；对于最小堆，是删除最小值。然后，把堆存储的最后那个节点移到填在根节点处。再从上而下调整父节点与它的子节点：对于最大堆，父节点如果小于具有最大值的子节点，则交换二者。这一操作称作down-heap或bubble-down, percolate-down, sift-down, trickle down, heapify-down, cascade-down,extract-min/max等。直至当前节点与它的子节点满足“堆性质”为止。 删除操作以小顶堆为例，找到的最小元素非常容易，但删除堆顶后还需要维持完全树，下图是删除堆顶 13 元素的过程： 首先我们删除根元素13,建立一个空穴,之后判断元素31是否可以放入这个空穴中, 也即先判断最右叶子，如果能直接移动最好，无需再维护完全树 无法直接移动，所以空穴下滑（向左儿子方向），再判断 31 能否插入空穴，不能，继续下滑： 最后 26 置入空穴中，同时空穴下滑到叶子层，31 可以置入空穴，结束： 这一种操作过程称之为下滤:空穴一步步下滑. PriorityQueue 源码分析PriorityQueue 是 JDK 中自带的优先级队列，使用小顶堆实现，有如下方法： 入队：add、offer 方法，如果失败，add 抛异常，offer 返回 false 获取队头：element、peek 返回堆顶最小的元素，但不删除队头（堆顶） 出队：remove、poll 返回并删除队头（堆顶）最小的元素 offer()offer()方法：插入元素到合适的位置 //offer(E e)public boolean offer(E e) &#123; if (e == null)//不允许放入null元素 throw new NullPointerException(); modCount++; int i = size; if (i &gt;= queue.length) grow(i + 1);//自动扩容 size = i + 1; if (i == 0)//队列原来为空，这是插入的第一个元素 queue[0] = e; else siftUp(i, e);//调整 return true;&#125; 上述代码中，扩容函数 grow() 类似于 ArrayList 里的 grow() 函数，就是再申请一个更大的数组，并将原数组的元素复制过去; 需要注意的是 siftUp(int k, E x) 方法，该方法用于插入元素 x 并维持堆的特性（上滤）。 //siftUp()private void siftUp(int k, E x) &#123; while (k &gt; 0) &#123; int parent = (k - 1) &gt;&gt;&gt; 1;//parentNo = (nodeNo-1)/2 Object e = queue[parent]; if (comparator.compare(x, (E) e) &gt;= 0)//调用比较器的比较方法 break; queue[k] = e; k = parent; &#125; queue[k] = x;&#125; 新加入的元素 x 可能会破坏小顶堆的性质，因此需要进行调整。调整的过程为：从 k 指定的位置开始，将 x 逐层与当前点的 parent 进行比较并交换，直到满足 x &gt;= queue[parent] 为止。 poll()poll 方法：删除堆顶，并维护堆序性 public E poll() &#123; if (size == 0) return null; int s = --size; modCount++; E result = (E) queue[0];//0下标处的那个元素就是最小的那个 E x = (E) queue[s]; queue[s] = null; if (s != 0) siftDown(0, x);//调整 return result;&#125; 上述代码首先记录 0 下标处的元素，并用最后一个元素替换 0 下标位置的元素，之后调用 siftDown() 方法对堆进行调整，最后返回原来 0 下标处的那个元素（也就是最小的那个元素）。重点是 siftDown(int k, E x) 方法，该方法的作用是从 k 指定的位置开始，将 x 逐层向下与当前点的左右孩子中较小的那个交换，直到 x 小于或等于左右孩子中的任何一个为止。 //siftDown()private void siftDown(int k, E x) &#123; int half = size &gt;&gt;&gt; 1; while (k &lt; half) &#123; //首先找到左右孩子中较小的那个，记录到 c 里，并用 child 记录其下标 int child = (k &lt;&lt; 1) + 1;//leftNo = parentNo*2+1 Object c = queue[child]; int right = child + 1; if (right &lt; size &amp;&amp; comparator.compare((E) c, (E) queue[right]) &gt; 0) c = queue[child = right]; if (comparator.compare(x, (E) c) &lt;= 0) break; queue[k] = c;//然后用 c 取代原来的值 k = child; &#125; queue[k] = x;&#125; @ref: https://www.cnblogs.com/Elliott-Su-Faith-change-our-life/p/7472265.html","categories":[{"name":"19.Algorithm","slug":"19-Algorithm","permalink":"https://beefyheisenberg.github.io/categories/19-Algorithm/"}],"tags":[]},{"title":"Alg.14.数据结构-图","slug":"19.Algorithm/Alg.14.数据结构-图","date":"2024-01-24T01:27:52.353Z","updated":"2024-01-24T01:27:52.353Z","comments":true,"path":"19.Algorithm/Alg.14.数据结构-图/","link":"","permalink":"https://beefyheisenberg.github.io/19.Algorithm/Alg.14.数据结构-图/","excerpt":"图的概念在图中的数据元素通常称为结点，V 是所有顶点的集合，E 是所有边的集合。如果两个顶点 v, w，只能由 v 向 w，而不能由 w 向 v，那么我们就把这种情况叫做一个从 v 到 w 的有向边。v 也被称做初始点，w 也被称为终点。这种图就被称做有向图。 如果v和w是没有顺序的，从v到达w和从w到达v是完全相同的，这种图就被称为无向图。 假如，图中的结点个数为 n，那么在一个无向图，假设每对结点之间只能有一条边，那么这个无向图中的边数最多只有 $ 1/2 n (n-1) $。边数最多的无向图也叫完全图。 同样的，对于有向图，边数最多有 $ n(n-1) $ 个，边数最多的有向图叫有向完全图。","text":"图的概念在图中的数据元素通常称为结点，V 是所有顶点的集合，E 是所有边的集合。如果两个顶点 v, w，只能由 v 向 w，而不能由 w 向 v，那么我们就把这种情况叫做一个从 v 到 w 的有向边。v 也被称做初始点，w 也被称为终点。这种图就被称做有向图。 如果v和w是没有顺序的，从v到达w和从w到达v是完全相同的，这种图就被称为无向图。 假如，图中的结点个数为 n，那么在一个无向图，假设每对结点之间只能有一条边，那么这个无向图中的边数最多只有 $ 1/2 n (n-1) $。边数最多的无向图也叫完全图。 同样的，对于有向图，边数最多有 $ n(n-1) $ 个，边数最多的有向图叫有向完全图。 如果图中的边数很少，这种图也被叫稀疏图。稀疏图是一种大约的概念，并没有一定的数值，说边数低于这个数值的时候就是稀疏图，在不同的场景下，稀疏图的定义会不一样。反之，如果边数比较多，就称为稠密图。 有时图的边具有与它相关的数，这种与图的边相关的数就叫做权。例如，从A地到B地的车票是80块钱，那这个80就是这条路上的耗费，我们如果把这样的交通网做成一个图，就变成了一个带权有向图。这种图也被称为网络。 一个顶点如果有多个边与其相联，那么这些相联的边数就称为点的度。如果是有向图，那么初始点就有出度，而终点则有入度。 图的表达邻接矩阵使用二维数组来表示一个图： 对于图 G，假如其中有 n 个结点，我们可以定义一个二维数组 A[n][n]，如果顶点 Vi 和顶点 Vj 之间存在边 Eij，那么就将 A[i][j] 设为1，否则设为0。就称二维数组 A 是图 G 的邻接矩阵。 如果图 G 是无向图，那么，如果 A[i][j] 为1，可以推知 A[j][i] 也为1（对称）。如果 G 是有向图（见下图），则不存在这个规律。 如果 G 的边上有权重，图 G 是一个带权有向图，顶点顶点 Vi 和顶点 Vj 之间存在边 Eij，且 Eij 的权重为 Wij，就令 A[i][j] 的值为 Wij。如果两个顶点 Vi 和顶点 Vj 之间不存在边，那么就记 A[k][l]为无穷大。在实际的实现中可以使用整型的最大值代替。 ➤ 复杂度分析： 在邻接矩阵中查询两个顶点是否相连的复杂度是O(1)_. 空间复杂度如何呢? 将图保存为邻接矩阵的空间复杂度是 O(n^2)，其中 n 是顶点的数目。也可表示为 O(|V|2)。 添加一个顶点的运行时间如何呢？顶点被保存在 VxV 矩阵中。因此，每次添加顶点时，矩阵必须被重构为新的(V+1)x(V+1)，在邻接矩阵中添加顶点的复杂度是 O(|V|^2) 邻接表显然，用邻接矩阵并不适合表达一个稀疏图，不仅有空间上的浪费，另外二维数组的时间 &amp; 空间复杂度都是 N^2 另外一种比较直接的思路就是使用多向链表。用一个结构体表示图的一个节点，结构体中包含数据域和多个指针，其中数据域存储该顶点的信息，指针指向有连接的其他节点。 这样做的一个缺点是，由于图中各个节点的度数各不相同，最大度数和最小度数可能相差很多，因此，若按度数最大的顶点设计结点结构，则会浪费很多存储单元。而如果按照每个顶点自己的度数设计不同的结点结构，所带来的编程的复杂度得不偿失。 所以，我们就用一种改进的方案：使用链表代表一个结点，这种方案被称为邻接表。 在邻接表中，图中的每一个节点都用一个链表表示。设链表 i 对应节点 i，链表 i 中每个元素都表示节点 i 的一条边。链表中的每个结点都由 3 个域组成：链表中的每个结点都由3个域组成，其中邻接点域表示与vi 相邻的点，例如与vi相 邻的vj，这个结点就是vj；链(nextArc)代表顶点i与顶点j之间的边eij；数据域(info)存储和边 相关的信息，例如权重等。 例如下面一个图： 用邻接表表示则为： ➤ 复杂度分析： 给定邻接表中两个节点是否相连的复杂度是 O(n), 其中 n 代表顶点的数量. 也可以写为 O(|V|). 你可以想象, 如果你想知道一个节点与另一个节点是否相连, 你必须遍历这个列表. 那么空间复杂度又如何呢? 将图存储为邻接表的空间复杂度是 O(n), 其中 n 是顶点数与边数的和. 也可以表示为 O(|V| + |E|). 上面这种实现方法为图中的每一个顶点（左边部分）都建立了一个单链表（右边部分）。这样我们就可以通过遍历每个顶点的链表，从而得到该顶点所有的边了。 通过邻接表可以获得从某个顶点出发能够到达的顶点，从而省去了对不相连顶点的存储空间。然而上面的邻接表只能表示顶点的“出度”，但没有表示“入度”。 这个问题很好解决，那就是增加一个表用来存储能够到达某个顶点的相邻顶点。这个表称作逆邻接表。 ➤ 逆邻接表 逆邻接表与邻接表结构类似，只不过图的顶点链接着能够到达该顶点的相邻顶点。也就是说，邻接表时顺着图中的箭头寻找相邻顶点，而逆邻接表时逆着图中的箭头寻找相邻顶点。 邻接表和逆邻接表的共同使用下，就能够把一个完整的有向图结构进行表示。可以发现，邻接表和逆邻接表实际上有一部分数据时重合的，因此可以将两个表合二为一，从而得到了所谓的十字链表： 但这并不是最优的表示方式。虽然这样的方式共用了中间的顶点存储空间，但是邻接表和逆邻接表的链表节点中重复出现的顶点并没有得到重复利用，反而是进行了再次存储。因此，上图的表示方式还可以进行进一步优化。 十字链表优化后，可通过扩展的顶点结构和边结构来进行正逆邻接表的存储：（下面的弧头可看作是边的箭头那端，弧尾可看作是边的圆点那端） data：用于存储该顶点中的数据； firstin指针：用于连接以当前顶点为弧头的其他顶点构成的链表，即从别的顶点指进来的顶点； firstout指针：用于连接以当前顶点为弧尾的其他顶点构成的链表，即从该顶点指出去的顶点； 边结构通过存储两个顶点来确定一条边，同时通过分别代表这两个顶点的指针来与相邻顶点进行链接： tailvex：用于存储作为弧尾的顶点的编号； headvex：用于存储作为弧头的顶点的编号； headlink 指针：用于链接下一个存储作为弧头的顶点的节点； taillink 指针：用于链接下一个存储作为弧尾的顶点的节点； 以上图为例子，对于顶点 A 而言，其作为起点能够到达顶点 E。因此在邻接表中顶点 A 要通过边 AE（即边04）指向顶点 E，顶点 A 的 firstout 指针需要指向边04的 tailvex。同时，从 B 出发能够到达 A，所以在逆邻接表中顶点 A 要通过边 AB（即边10）指向 B，顶点 A 的 firstin 指针需要指向边10的弧头，即 headlink 指针。依次类推。 十字链表采用了一种看起来比较繁乱的方式对边的方向性进行了表示，能够在尽可能降低存储空间的情况下增加指针保留顶点之间的方向性。具体的操作可能一时间不好弄懂，建议多看几次上图，弄清指针指向的意义，明白正向和逆向邻接表的表示。 @ref: 图算法：图的表达 图的存储结构之邻接表(详解)-阿里云开发者社区 深度优先和广度优先 深度优先搜索 深度优先算法是一种优先遍历子节点而不是回溯的算法。 时间复杂度: O(|V| + |E|) 广度优先搜索 广度优先搜索是优先遍历邻居节点而不是子节点的图遍历算法。 时间复杂度: O(|V| + |E|) 图的深度优先搜索 图的广度优先搜索 拓扑排序 拓扑排序是对于有向图节点的线性排序，如果存在某条从 u 到 v 的边，则认为 u 的下标先于 v。 时间复杂度: O(|V| + |E|) Dijkstra 算法 Dijkstra 算法 用于计算有向图中单源最短路径问题。 时间复杂度: O(|V|^2) Bellman-Ford 算法 Bellman-Ford 算法是在带权图中计算从单一源点出发到其他节点的最短路径的算法。 尽管算法复杂度大于 Dijkstra 算法，但是它适用于包含了负值边的图。 时间复杂度: 最优时间: O(|E|) 最坏时间: O(|V||E|) Floyd-Warshall 算法 Floyd-Warshall 算法 能够用于在无环带权图中寻找任意节点的最短路径。 时间复杂度: 最优时间: O(|V|^3) 最坏时间: O(|V|^3) 平均时间: O(|V|^3) Prim 算法 Prim 算法是用于在带权无向图中计算最小生成树的贪婪算法。换言之，Prim 算法能够在图中抽取出连接所有节点的边的最小代价子集。 时间复杂度: O(|V|^2) Kruskal 算法 Kruskal 算法同样是计算图的最小生成树的算法，与 Prim 的区别在于并不需要图是连通的。 时间复杂度: O(|E|log|V|) 参考[[../_attachments/图数据结构入门 - 技术翻译 - OSCHINA 社区.pdf]]","categories":[{"name":"19.Algorithm","slug":"19-Algorithm","permalink":"https://beefyheisenberg.github.io/categories/19-Algorithm/"}],"tags":[]},{"title":"Alg.13a.数据结构-散列函数-MD5算法原理及实现","slug":"19.Algorithm/Alg.13a.数据结构-散列函数-MD5","date":"2024-01-24T01:27:52.347Z","updated":"2024-01-24T01:27:52.347Z","comments":true,"path":"19.Algorithm/Alg.13a.数据结构-散列函数-MD5/","link":"","permalink":"https://beefyheisenberg.github.io/19.Algorithm/Alg.13a.数据结构-散列函数-MD5/","excerpt":"散列函数散列函数，也称作哈希函数，消息摘要函数，单向函数或者杂凑函数。散列函数主要用于验证数据的完整性。通过散列函数，可以创建消息的“数字指纹”，消息接收方可以通过校验消息的哈希值来验证消息的完整性，防止消息被篡改。散列函数具有以下特性： 散列函数的运算过程是不可逆的，这个称为散列函数的单向性。 对于一个已知的消息及其散列值，要找到另外一个消息使其获得相同的散列值是不可能的，这个特性称为散列函数的弱碰撞性。这个特性可以用来防止消息伪造。 任意两个不同消息的散列值一定不同。 对原始消息长度没有限制。 任何消息经过散列函数处理后，都会产生一个唯一的散列值，这个散列值可以用来验证消息的完整性。计算消息散列值的过程被称为“消息摘要”，计算消息散列值的算法被称为消息摘要算法。常使用的消息摘要算法有：MD—消息摘要算法，SHA—安全散列算法，MAC—消息认证码算法。本文主要来了解MD算法。 MD5算法原理","text":"散列函数散列函数，也称作哈希函数，消息摘要函数，单向函数或者杂凑函数。散列函数主要用于验证数据的完整性。通过散列函数，可以创建消息的“数字指纹”，消息接收方可以通过校验消息的哈希值来验证消息的完整性，防止消息被篡改。散列函数具有以下特性： 散列函数的运算过程是不可逆的，这个称为散列函数的单向性。 对于一个已知的消息及其散列值，要找到另外一个消息使其获得相同的散列值是不可能的，这个特性称为散列函数的弱碰撞性。这个特性可以用来防止消息伪造。 任意两个不同消息的散列值一定不同。 对原始消息长度没有限制。 任何消息经过散列函数处理后，都会产生一个唯一的散列值，这个散列值可以用来验证消息的完整性。计算消息散列值的过程被称为“消息摘要”，计算消息散列值的算法被称为消息摘要算法。常使用的消息摘要算法有：MD—消息摘要算法，SHA—安全散列算法，MAC—消息认证码算法。本文主要来了解MD算法。 MD5算法原理假设原始消息长度是b（以bit为单位），注意这里b可以是任意长度，并不一定要是8的整数倍。计算该消息MD5值的过程如下： 1.填充信息在计算消息的MD5值之前，首先对原始信息进行填充，这里的信息填充分为两步。第一步，对原始信息进行填充，填充之后，要求信息的长度对512取余等于448。填充的规则如下：假设原始信息长度为b bit，那么在信息的b+1 bit位填充1，剩余的位填充0，直到信息长度对512取余为448。这里有一点需要注意，如果原始信息长度对512取余正好等于448，这种情况仍然要进行填充，很明显，在这时我们要填充的信息长度是512位，直到信息长度对512取余再次等于448。所以，填充的位数最少为1，最大为512。第二步，填充信息长度，我们需要把原始信息长度转换成以bit为单位，然后在第一步操作的结果后面填充64bit的数据表示原始信息长度。第一步对原始信息进行填充之后，信息长度对512取余结果为448，这里再填充64bit的长度信息，整个信息恰好可以被512整除。其实从后续过程可以看到，计算MD5时，是将信息分为若干个分组进行处理的，每个信息分组的长度是512bit。 2.分组处理在进行MD5值计算之前，我们先来做一些定义。 信息分组定义原始信息经过填充之后，最终得到的信息长度（bit）是512的整数倍，我们先对信息进行分组，每512bit为一个分组，然后再将每个信息分组（512bit）再细分为16个小的分组，每个小分组的长度为32bit。规定如下$M_p$ 代表经过填充之后的信息$L_M$ 表示 $M_p$ 的长度（以 bit 为单位）N 表示分组个数，$N = L_M/512$$M[i]$ 表示将原始信息进行分组后的第 i 个信息分组，其中 i=1…N$X[i]$ 表示将 $M[i]$ 进行分组后的第 i 个小分组，其中 i=1…16 标准幻数定义现定义四个标准幻数如下，A = 01 23 45 67B = 89 ab cd efC = fe dc ba 98D = 76 54 32 10在计算机中存储时，采用小端存储方式，以A为例，A在Java中初始化的代码为为A=0x67452301 常量表TT 是一个常量表，$T[i] = 4294967296 * abs(sin(i))$ 的运算结果取整，其中 i=1…64 辅助方法我们定义四个辅助方法。F(x,y,z) = (x &amp; y) | ((~x) &amp; z)G(x,y,z) = (x &amp; z) | (y &amp; (~z))H(x,y,z) = x ^ y ^ zI(x,y,z) = y ^ (x | (~z))其中，x，y，z长度为32bit 下面就是最核心的信息处理过程，计算MD5的过程实际上就是轮流处理每个信息分组的过程。 A=0x67452301B=0xefcdab89C=0x98badcfeD=0x10325476for( j=1;j&lt;=N;j++)&#123; //依次处理每个分组，其中N代表分组个数 AA = A BB = B CC = C DD = D //开始处理分组，每个信息分组要经过4轮处理 /*第一轮 假设 [abcd k s i] 表示执行的运算是 a = b + ((a + F(b,c,d) + X[k] + T[i]) &lt;&lt;&lt; s)，其中&lt;&lt;&lt;表示循环移位。第一轮运算就是对分组执行以下所示的16次运算，运算的顺序从左到右。*/ [ABCD 0 7 1] [DABC 1 12 2] [CDAB 2 17 3] [BCDA 3 22 4] [ABCD 4 7 5] [DABC 5 12 6] [CDAB 6 17 7] [BCDA 7 22 8] [ABCD 8 7 9] [DABC 9 12 10] [CDAB 10 17 11] [BCDA 11 22 12] [ABCD 12 7 13] [DABC 13 12 14] [CDAB 14 17 15] [BCDA 15 22 16] /*第二轮 假设 [abcd k s i] 表示执行的运算是 a = b + ((a + G(b,c,d) + X[k] + T[i]) &lt;&lt;&lt; s)，其中 &lt;&lt;&lt;表示循环移位。第一轮运算就是对分组执行以下所示的16次运算，运算的顺 序从左到右。*/ [ABCD 1 5 17] [DABC 6 9 18] [CDAB 11 14 19] [BCDA 0 20 20] [ABCD 5 5 21] [DABC 10 9 22] [CDAB 15 14 23] [BCDA 4 20 24] [ABCD 9 5 25] [DABC 14 9 26] [CDAB 3 14 27] [BCDA 8 20 28] [ABCD 13 5 29] [DABC 2 9 30] [CDAB 7 14 31] [BCDA 12 20 32] /*第三轮 假设 [abcd k s i] 表示执行的运算是 a = b + ((a + H(b,c,d) + X[k] + T[i]) &lt;&lt;&lt; s)，其中&lt;&lt;&lt;表示循环移位。第一轮运算就是对分组执行以下所示的16次运算，运算的顺 序从左到右。*/ [ABCD 5 4 33] [DABC 8 11 34] [CDAB 11 16 35] [BCDA 14 23 36] [ABCD 1 4 37] [DABC 4 11 38] [CDAB 7 16 39] [BCDA 10 23 40] [ABCD 13 4 41] [DABC 0 11 42] [CDAB 3 16 43] [BCDA 6 23 44] [ABCD 9 4 45] [DABC 12 11 46] [CDAB 15 16 47] [BCDA 2 23 48] /*第四轮 假设 [abcd k s i] 表示执行的运算是 a = b + ((a + I(b,c,d) + X[k] + T[i]) &lt;&lt;&lt; s)，其中&lt;&lt;&lt;表示循环移位。第一轮运算就是对分组执行以下所示的16次运算，运算的顺序从左到右。*/ [ABCD 0 6 49] [DABC 7 10 50] [CDAB 14 15 51] [BCDA 5 21 52] [ABCD 12 6 53] [DABC 3 10 54] [CDAB 10 15 55] [BCDA 1 21 56] [ABCD 8 6 57] [DABC 15 10 58] [CDAB 6 15 59] [BCDA 13 21 60] [ABCD 4 6 61] [DABC 11 10 62] [CDAB 2 15 63] [BCDA 9 21 64] //将当前消息分组的运算结果和上一次的结果进行累加 A = A + AA B = B + BB C = C + CC D = D + DD&#125;//最终我们按照低字节在前的顺序依次将A,B,C,D拼接起来，就是计算得到的MD5值，因此，MD5值的长度是固定的，为128bit。 JDK 中的 MD5实现Java提供的标准MD5算法实现如下所示 import java.security.MessageDigest;import java.util.Arrays;public class MD5Test&#123; //标准的幻数 private static final int A=0x67452301; private static final int B=0xefcdab89; private static final int C=0x98badcfe; private static final int D=0x10325476; private static final int S11 = 7; private static final int S12 = 12; private static final int S13 = 17; private static final int S14 = 22; private static final int S21 = 5; private static final int S22 = 9; private static final int S23 = 14; private static final int S24 = 20; private static final int S31 = 4; private static final int S32 = 11; private static final int S33 = 16; private static final int S34 = 23; private static final int S41 = 6; private static final int S42 = 10; private static final int S43 = 15; private static final int S44 = 21; private static final int GROUP_LEN = 64; public byte[] digest(byte[] input)&#123; byte [] paddingData = getPaddingData(input); //对原始数据进行补位 return process(paddingData);//处理分组，核心算法 &#125; private int[] getGroupData(byte[] data,int index)&#123; int [] groupData=new int[16]; for(int i=0;i&lt;16;i++)&#123; groupData[i] = (data[4*i+index]&amp;0xFF)| //这里注意，在byte转int时一定要进行&amp;0xff操作 (data[4*i+1+index]&amp;0xFF)&lt;&lt;8| (data[4*i+2+index]&amp;0xFF)&lt;&lt;16| (data[4*i+3+index]&amp;0xFF)&lt;&lt;24; &#125; return groupData; &#125; private int[] getConstTable() &#123; int[] T = new int[64]; for(int i=1;i&lt;65;i++) &#123; T[i-1] = (int)((long)(Math.abs(Math.sin(i))*4294967296l)); &#125; return T; &#125; private byte[] getPaddingData(byte[] input) &#123; int length = input.length; long bitLength = length &lt;&lt; 3; int rest = length % 64; int paddingLength = 0; if(rest &lt; 56) &#123; paddingLength = 64-rest; &#125;else &#123; paddingLength = 128 - rest; &#125; byte[] paddingData = new byte[length+paddingLength]; for(int i=0;i&lt;length;i++) &#123; paddingData[i] = input[i]; &#125; paddingData[length] = (byte)(1&lt;&lt;7); for(int i=1;i&lt;paddingLength-8;i++) &#123; paddingData[length+i] = 0; &#125; for(int i=0;i&lt;8;i++)&#123; paddingData[length+paddingLength-8+i]=(byte)(bitLength&amp;0xFF); bitLength = bitLength &gt;&gt;&gt; 8; &#125; return paddingData; &#125; private byte[] process(byte[] data) &#123; int [] result = &#123;A,B,C,D&#125;; int length = data.length; int groupCount = length/64; //计算分组数量,每组512位（64字节） int[] T = getConstTable(); for(int groupIndex=0;groupIndex&lt;groupCount;groupIndex++)&#123; int[] x=getGroupData(data,groupIndex*GROUP_LEN);//获取分组数据 int a = result[0]; int b = result[1]; int c = result[2]; int d = result[3]; /*第一轮*/ a = FF(a, b, c, d, x[0], S11, T[0]); //a = b + ((a + F(b,c,d) + X[0] + T[0]) &lt;&lt;&lt; 7) d = FF(d, a, b, c, x[1], S12, T[1]); //d = a + ((d + F(a,b,c) + X[1] + T[1]) &lt;&lt;&lt; 12) c = FF(c, d, a, b, x[2], S13, T[2]); //c = d + ((c + F(d,a,b) + X[2] + T[2]) &lt;&lt;&lt; 17) b = FF(b, c, d, a, x[3], S14, T[3]); //b = c + ((b + F(c,d,a) + X[3] + T[3]) &lt;&lt;&lt; 22) a = FF(a, b, c, d, x[4], S11, T[4]); //a = b + ((a + F(b,c,d) + X[4] + T[4]) &lt;&lt;&lt; 7) d = FF(d, a, b, c, x[5], S12, T[5]); //d = a + ((d + F(a,b,c) + X[5] + T[5]) &lt;&lt;&lt; 12) c = FF(c, d, a, b, x[6], S13, T[6]); //c = d + ((c + F(d,a,b) + X[6] + T[6]) &lt;&lt;&lt; 17) b = FF(b, c, d, a, x[7], S14, T[7]); //b = c + ((b + F(c,d,a) + X[7] + T[7]) &lt;&lt;&lt; 22) a = FF(a, b, c, d, x[8], S11, T[8]); //a = b + ((a + F(b,c,d) + X[8] + T[8]) &lt;&lt;&lt; 7) d = FF(d, a, b, c, x[9], S12, T[9]); //d = a + ((d + F(a,b,c) + X[9] + T[9]) &lt;&lt;&lt; 12) c = FF(c, d, a, b, x[10], S13, T[10]); //c = d + ((c + F(d,a,b) + X[10] + T[10]) &lt;&lt;&lt; 17) b = FF(b, c, d, a, x[11], S14, T[11]); //b = c + ((b + F(c,d,a) + X[11] + T[12]) &lt;&lt;&lt; 22) a = FF(a, b, c, d, x[12], S11, T[12]); //a = b + ((a + F(b,c,d) + X[12] + T[12]) &lt;&lt;&lt; 7) d = FF(d, a, b, c, x[13], S12, T[13]); //d = a + ((d + F(a,b,c) + X[13] + T[13]) &lt;&lt;&lt; 12) c = FF(c, d, a, b, x[14], S13, T[14]); //c = d + ((c + F(d,a,b) + X[14] + T[14]) &lt;&lt;&lt; 17) b = FF(b, c, d, a, x[15], S14, T[15]); //b = c + ((b + F(c,d,a) + X[15] + T[15]) &lt;&lt;&lt; 22) /*第二轮*/ a = GG(a, b, c, d, x[1], S21, T[16]); //a = b + ((a + G(b,c,d) + X[1] + T[16]) &lt;&lt;&lt; 5) d = GG(d, a, b, c, x[6], S22, T[17]); //d = a + ((d + G(a,b,c) + X[6] + T[17]) &lt;&lt;&lt; 9) c = GG(c, d, a, b, x[11], S23, T[18]); //c = d + ((c + G(d,a,b) + X[11] + T[18]) &lt;&lt;&lt; 14) b = GG(b, c, d, a, x[0], S24, T[19]); //b = c + ((b + G(c,d,a) + X[0] + T[19]) &lt;&lt;&lt; 20) a = GG(a, b, c, d, x[5], S21, T[20]); //a = b + ((a + G(b,c,d) + X[5] + T[20]) &lt;&lt;&lt; 5) d = GG(d, a, b, c, x[10], S22, T[21]); ///d = a + ((d + G(a,b,c) + X[10] + T[21]) &lt;&lt;&lt; 9) c = GG(c, d, a, b, x[15], S23, T[22]); ///c = d + ((c + G(d,a,b) + X[15] + T[22]) &lt;&lt;&lt; 14) b = GG(b, c, d, a, x[4], S24, T[23]); //b = c + ((b + G(c,d,a) + X[4] + T[23]) &lt;&lt;&lt; 20) a = GG(a, b, c, d, x[9], S21, T[24]); ///a = b + ((a + G(b,c,d) + X[9] + T[24]) &lt;&lt;&lt; 5) d = GG(d, a, b, c, x[14], S22, T[25]); //d = a + ((d + G(a,b,c) + X[14] + T[25]) &lt;&lt;&lt; 9) c = GG(c, d, a, b, x[3], S23, T[26]); //c = d + ((c + G(d,a,b) + X[3] + T[26]) &lt;&lt;&lt; 14) b = GG(b, c, d, a, x[8], S24, T[27]); //b = c + ((b + G(c,d,a) + X[8] + T[27]) &lt;&lt;&lt; 20) a = GG(a, b, c, d, x[13], S21, T[28]); //a = b + ((a + G(b,c,d) + X[13] + T[28]) &lt;&lt;&lt; 5) d = GG(d, a, b, c, x[2], S22, T[29]); //d = a + ((d + G(a,b,c) + X[2] + T[29]) &lt;&lt;&lt; 9) c = GG(c, d, a, b, x[7], S23, T[30]); //c = d + ((c + G(d,a,b) + X[7] + T[30]) &lt;&lt;&lt; 14) b = GG(b, c, d, a, x[12], S24, T[31]); //b = c + ((b + G(c,d,a) + X[12] + T[31]) &lt;&lt;&lt; 20) /*第三轮*/ a = HH(a, b, c, d, x[5], S31, T[32]); //a = b + ((a + H(b,c,d) + X[5] + T[32])&lt;&lt;&lt; 4) d = HH(d, a, b, c, x[8], S32, T[33]); //d = a + ((d + H(a,b,c) + X[8] + T[33])&lt;&lt;&lt; 11) c = HH(c, d, a, b, x[11], S33, T[34]); //c = d + ((c + H(d,a,b) + X[11] + T[34])&lt;&lt;&lt; 16) b = HH(b, c, d, a, x[14], S34, T[35]); //b = c + ((b + H(c,d,a) + X[14] + T[35])&lt;&lt;&lt; 23) a = HH(a, b, c, d, x[1], S31, T[36]); //a = b + ((a + H(b,c,d) + X[1] + T[36])&lt;&lt;&lt; 4) d = HH(d, a, b, c, x[4], S32, T[37]); //d = a + ((d + H(a,b,c) + X[4] + T[37])&lt;&lt;&lt; 11) c = HH(c, d, a, b, x[7], S33, T[38]); //c = d + ((c + H(d,a,b) + X[7] + T[38])&lt;&lt;&lt; 16) b = HH(b, c, d, a, x[10], S34, T[39]); //b = c + ((b + H(c,d,a) + X[10] + T[39])&lt;&lt;&lt; 23) a = HH(a, b, c, d, x[13], S31, T[40]); //a = b + ((a + H(b,c,d) + X[13] + T[40])&lt;&lt;&lt; 4) d = HH(d, a, b, c, x[0], S32, T[41]); //d = a + ((d + H(a,b,c) + X[0] + T[41])&lt;&lt;&lt; 11) c = HH(c, d, a, b, x[3], S33, T[42]); //c = d + ((c + H(d,a,b) + X[3] + T[42])&lt;&lt;&lt; 16) b = HH(b, c, d, a, x[6], S34, T[43]); //b = c + ((b + H(c,d,a) + X[6] + T[43])&lt;&lt;&lt; 23) a = HH(a, b, c, d, x[9], S31, T[44]); //a = b + ((a + H(b,c,d) + X[9] + T[44])&lt;&lt;&lt; 4) d = HH(d, a, b, c, x[12], S32, T[45]); //d = a + ((d + H(a,b,c) + X[12] + T[45])&lt;&lt;&lt; 11) c = HH(c, d, a, b, x[15], S33, T[46]); //c = d + ((c + H(d,a,b) + X[15] + T[46])&lt;&lt;&lt; 16) b = HH(b, c, d, a, x[2], S34, T[47]); //b = c + ((b + H(c,d,a) + X[2] + T[47])&lt;&lt;&lt; 23) /*第四轮*/ a = II(a, b, c, d, x[0], S41, T[48]); //a = b + ((a + I(b,c,d) + X[0] + T[48]) &lt;&lt;&lt; 6) d = II(d, a, b, c, x[7], S42, T[49]); //d = a + ((d + I(a,b,c) + X[7] + T[49]) &lt;&lt;&lt; 10) c = II(c, d, a, b, x[14], S43, T[50]); //c = d + ((c + I(d,a,b) + X[14] + T[50]) &lt;&lt;&lt; 15) b = II(b, c, d, a, x[5], S44, T[51]); //b = c + ((b + I(c,d,a) + X[5] + T[51]) &lt;&lt;&lt; 21) a = II(a, b, c, d, x[12], S41, T[52]); //a = b + ((a + I(b,c,d) + X[12] + T[52]) &lt;&lt;&lt; 6) d = II(d, a, b, c, x[3], S42, T[53]); //d = a + ((d + I(a,b,c) + X[3] + T[53]) &lt;&lt;&lt; 10) c = II(c, d, a, b, x[10], S43, T[54]); //c = d + ((c + I(d,a,b) + X[10] + T[54]) &lt;&lt;&lt; 15) b = II(b, c, d, a, x[1], S44, T[55]); //b = c + ((b + I(c,d,a) + X[1] + T[55]) &lt;&lt;&lt; 21) a = II(a, b, c, d, x[8], S41, T[56]); //a = b + ((a + I(b,c,d) + X[8] + T[56]) &lt;&lt;&lt; 6) d = II(d, a, b, c, x[15], S42, T[57]); //d = a + ((d + I(a,b,c) + X[15] + T[57]) &lt;&lt;&lt; 10) c = II(c, d, a, b, x[6], S43, T[58]); //c = d + ((c + I(d,a,b) + X[6] + T[58]) &lt;&lt;&lt; 15) b = II(b, c, d, a, x[13], S44, T[59]); //b = c + ((b + I(c,d,a) + X[13] + T[59]) &lt;&lt;&lt; 21) a = II(a, b, c, d, x[4], S41, T[60]); //a = b + ((a + I(b,c,d) + X[4] + T[60]) &lt;&lt;&lt; 6) d = II(d, a, b, c, x[11], S42, T[61]); //d = a + ((d + I(a,b,c) + X[11] + T[61]) &lt;&lt;&lt; 10) c = II(c, d, a, b, x[2], S43, T[62]); //c = d + ((c + I(d,a,b) + X[2] + T[62]) &lt;&lt;&lt; 15) b = II(b, c, d, a, x[9], S44, T[63]); //b = c + ((b + I(c,d,a) + X[9] + T[63]) &lt;&lt;&lt; 21) result[0] += a; result[1] += b; result[2] += c; result[3] += d; &#125; byte[] resultByte = new byte[16]; for(int i = 0;i&lt;4;i++) &#123; for(int j = 0; j &lt; 4; j++) &#123; resultByte[i*4+j] = (byte) (result[i] &amp; 0xff); result[i]=result[i]&gt;&gt;8; &#125; &#125; return resultByte; &#125; private static int F(int x, int y, int z) &#123; return (x &amp; y) | ((~x) &amp; z); &#125; private static int G(int x, int y, int z) &#123; return (x &amp; z) | (y &amp; (~z)); &#125; private static int H(int x, int y, int z) &#123; return x ^ y ^ z; &#125; private static int I(int x, int y, int z) &#123; return y ^ (x | (~z)); &#125; private static int FF(int a, int b, int c, int d, int x, int s, int t) &#123; a += (F(b, c, d)&amp;0xFFFFFFFF) + x + t; a = ((a&amp;0xFFFFFFFF)&lt;&lt; s) | ((a&amp;0xFFFFFFFF) &gt;&gt;&gt; (32 - s)); //循环位移 a += b; return (a&amp;0xFFFFFFFF); &#125; private static int GG(int a, int b, int c, int d, int x, int s, int t) &#123; a += (G(b, c, d)&amp;0xFFFFFFFF) + x + t; a = ((a&amp;0xFFFFFFFF) &lt;&lt; s) | ((a&amp;0xFFFFFFFF) &gt;&gt;&gt; (32 - s)); a += b; return (a&amp;0xFFFFFFFF); &#125; private static int HH(int a, int b, int c, int d, int x, int s, int t) &#123; a += (H(b, c, d)&amp;0xFFFFFFFF) + x + t; a = ((a&amp;0xFFFFFFFF) &lt;&lt; s) | ((a&amp;0xFFFFFFFF) &gt;&gt;&gt; (32 - s)); a += b; return (a&amp;0xFFFFFFFF); &#125; private static int II(int a, int b, int c, int d, int x, int s,int t) &#123; a += (I(b, c, d)&amp;0xFFFFFFFF) + x + t; a = ((a&amp;0xFFFFFFFF) &lt;&lt; s) | ((a&amp;0xFFFFFFFF) &gt;&gt;&gt; (32 - s)); a += b; return (a&amp;0xFFFFFFFF); &#125; public static void main(String []args)&#123; MD5Test myMd5=new MD5Test(); String testData = \"hello,world\"; System.out.println(\"--------My MD5--------\"); byte[] myResult = myMd5.digest(testData.getBytes()); System.out.println(Arrays.toString(myResult)); System.out.println(\"--------Java MD5--------\"); try &#123; MessageDigest javaMd5 = MessageDigest.getInstance(\"MD5\"); byte[] javaResult = javaMd5.digest(testData.getBytes()); System.out.println(Arrays.toString(javaResult)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;","categories":[{"name":"19.Algorithm","slug":"19-Algorithm","permalink":"https://beefyheisenberg.github.io/categories/19-Algorithm/"}],"tags":[]},{"title":"Alg.13.数据结构-散列表","slug":"19.Algorithm/Alg.13.数据结构-散列表","date":"2024-01-24T01:27:52.342Z","updated":"2024-01-24T01:27:52.343Z","comments":true,"path":"19.Algorithm/Alg.13.数据结构-散列表/","link":"","permalink":"https://beefyheisenberg.github.io/19.Algorithm/Alg.13.数据结构-散列表/","excerpt":"散列表（Hash table，也叫哈希表），是根据 键（Key） 而直接访问在内存储存位置的数据结构。 散列表通过某一函数将键（Key） 转换为数组的下标，这个映射函数称做散列函数，存放记录的数组称做散列表。 散列函数的作用是将键（Key）映射到一个有限的整数空间上。 散列函数@todo","text":"散列表（Hash table，也叫哈希表），是根据 键（Key） 而直接访问在内存储存位置的数据结构。 散列表通过某一函数将键（Key） 转换为数组的下标，这个映射函数称做散列函数，存放记录的数组称做散列表。 散列函数的作用是将键（Key）映射到一个有限的整数空间上。 散列函数@todo 冲突解决如果对于不同的 K1、K2，经过散列函数计算出的散列值一样，就发生了散列冲突（碰撞）。 散列表解决冲突的方法主要有： 开放定址法 线性探测 平方探测 伪随机探测 再哈希法 链表法 建立公共溢出区 开放定址法：$$ H_i = ( hash(key) + d_i ) mod M , i = 1,2..k(k &lt;= M-1)$$ 其中 hash 是散列函数，m 是散列表数组大小。根据 di 的取值不同，开放定制又分为： 线性探测法：di = 1,2 … 平方探测法：di = 1^2, 2^2 … 伪随机探测法：需要一个初始随机种子 seed，和一个随机数产生器，例如 di=random(seed)，产生一个随机数序列, 伪随机函数 random() 的特点是，如果种子相同，那么 random() 产生的随机数序列是一样的； 再散列法：建立多个不同的散列函数 $$ H_i = hash_i(key), i=1,2…k(k &lt;= m-1) $$，若 Hash1 函数计算的散列值发生冲突, 再用 hash2 计算，直到没有冲突； 链表法：冲突的元素放入链表，将链表放入 table[i]（设 i= h(key) mod m）的位置； 建立公共溢出区：需要创建一个溢出区, 所有产生冲突的元素放入此溢出区； ➤ 几种冲突处理的比较： 开放定址法的缺点： 当冲突多的时候数据容易出现堆积（聚集），这时候对查找效率低，因为要多次处理冲突；（聚集：因为表项的空闲地址既向它的同义词表项开放，又向它的非同义词表项开放，所以不可避免会造成聚集现象） 删除结点的时候不能简单将结点的空间置空，否则将截断在它填入散列表之后的同义词（散列值相等）结点查找路径。因此如果要删除结点，只能在被删结点上添加删除标记，而不能真正删除结点； 相比链表法的优点： 链表法处理冲突简单，且无堆积现象，即非同义词决不会发生冲突，因此平均查找长度较短（但如果冲突产生，则需要查找链表）； 开放定址法为减少冲突，要求装填因子α较小，故当结点规模较大时会浪费很多 table 数组的空间。 在用拉链法构造的散列表中，删除结点的操作易于实现。只要简单地删去链表上相应的结点即可。而对开放地址法构造的散列表，删除结点较麻烦，参上 @ref： https://github.com/chefyuan/algorithm-base/blob/main/animation-simulation/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/Hash%E8%A1%A8%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B.md","categories":[{"name":"19.Algorithm","slug":"19-Algorithm","permalink":"https://beefyheisenberg.github.io/categories/19-Algorithm/"}],"tags":[]},{"title":"Alg.12.数据结构-树","slug":"19.Algorithm/Alg.12.数据结构-树","date":"2024-01-24T01:27:52.338Z","updated":"2024-01-24T01:27:52.338Z","comments":true,"path":"19.Algorithm/Alg.12.数据结构-树/","link":"","permalink":"https://beefyheisenberg.github.io/19.Algorithm/Alg.12.数据结构-树/","excerpt":"简单二叉树二叉树遍历 先序(preOrder): 中-左-右 中序(inOrder): 左-中-右 后序(postOrder): 左-右-中 图来自 http://www.crystaltenn.com/2020/04/binary-trees-traversal-recursive-vs.html ➤ 先序遍历(递归):","text":"简单二叉树二叉树遍历 先序(preOrder): 中-左-右 中序(inOrder): 左-中-右 后序(postOrder): 左-右-中 图来自 http://www.crystaltenn.com/2020/04/binary-trees-traversal-recursive-vs.html ➤ 先序遍历(递归): public void preOrder(Node&lt;T&gt; n) &#123; System.out.println(n.data); // 先序 if (n.left != null) preOrder(n.left); // System.out.println(n.data); // 中序 if (n.right != null) preOrder(n.right); // System.out.println(n.data); // 后序&#125; ➤ 先序-非递归, 最简单的一种: public void preOrder(Node root) &#123; Stack s = new Stack(); s.push(root); while(!s.isEmpty()) &#123; Node n = s.pop(); // 刚开始就pop了, 这种只能用来做先序 System.out.println(n.data); // 先序 if(n.right != null) &#123; s.push(n.right); &#125; if(n.left != null) &#123; s.push(n.left); &#125; &#125;&#125; ➤ 先序-非递归(方法 2), 使用栈模拟递归: public void preOrder(Node root) &#123; Stack s = new Stack(); while(!s.isEmpty() || root != null) &#123; if(root != null) &#123; System.out.println(root.data); // 先序 s.push(root); root = root.left; &#125; else &#123; root = s.pop(); // System.out.println(root.data); // 中序 root = root.right; &#125; &#125;&#125; ➤ 中序-非递归与上面类似 ➤ 后序-非递归(需要辅助栈): Push 根结点到第一个栈 s1中。 从第一个栈 s1 中 Pop 出一个结点，并将其 Push 到第二个栈 output 中。 然后 Push 该结点的左孩子和右孩子到第一个栈 s 中。 重复过程 2 和 3 直到栈 s 为空。 完成后，所有结点已经 Push 到栈 output 中，且按照后序遍历的顺序存放，直接全部 Pop 出来即是二叉树后序遍历结果。 public void postOrder(Node root) &#123; Stack s1 = new Stack(); Stack s2 = new Stack(); s1.push(root); while(!s1.isEmpty) &#123; Node curr = s1.pop(); s2.push(curr); if(curr.left !=null) &#123; s1.push(curr.left); &#125; if(curr.right !=null) &#123; s1.push(curr.right); &#125; &#125; while(!s2.isEmpty()) &#123; Node curr = s2.pop(); System.out.println(cur.data); &#125;&#125; ➤ 层序遍历（非递归算法）:第一个队列 currentLevel 用于存储当前层的结点，第二个队列 nextLevel 用于存储下一层的结点。当前层 currentLevel 为空时，表示这一层已经遍历完成，可以打印换行符了。然后将第一个空的队列 currentLevel 与队列 nextLevel 交换，然后重复该过程直到结束。如果不需要打印\\n区分层，那么只用一个队列即可实现 public void levelOrder(Node root) &#123; Queue&lt;Node&gt; currentLevel = new Queue(); Queue&lt;Node&gt; nextLevel = new Queue(); currentLevel.offer(root); while(!currentLevel.isEmpty()) &#123; currNode = currentLevel.poll(); if(currNode) &#123; print(currNode); nextLevel.offer(currNode.left); nextLevel.offer(currNode.right); &#125; if(currentLevel.isEmpty()) &#123; print(\"/n\"); swap(currentLevel, nextLevel); &#125; &#125;&#125; https://blog.csdn.net/sgbfblog/article/details/7773103 节点删除/插入 数据结构（七）：二叉树的删除和应用举例 AVL 树@ref: 平衡二叉树 代码实现平衡二叉树 AVL 树（Adelson-Velsky and Landis Tree，发明者名字）的产生是为了解决二叉排序树在插入时发生线性排列的现象。由于二叉排序树本身为有序，当插入一个有序程度十分高的序列时，生成的二叉排序树会持续在某个方向的字数上插入数据，导致最终的二叉排序树会退化为链表，从而使得二叉树的查询和插入效率恶化。 AVL 树的出现能够解决上述问题，但是在构造平衡二叉树时，却需要采用不同的调整方式，使得二叉树在插入数据后保持平衡。主要的四种调整方式有 LL（左旋）、RR（右旋）、LR（先左旋再右旋）、RL（先右旋再左旋）。 在插入一个结点后应该沿搜索路径将路径上的结点平衡因子进行修改，当平衡因子大于 1 时，就需要进行平衡化处理。从发生不平衡的结点起，沿刚才回溯的路径取直接下两层的结点，如果这三个结点在一条直线上，则采用单旋转进行平衡化，如果这三个结点位于一条折线上，则采用双旋转进行平衡化 旋转AVL 树在插入/删除节点后, 需要用旋转的操作重新平衡; 概念: 「节点的平衡因子」 每个结点的平衡因子就是该结点的左子树的高度减去右子树的高度，平衡二叉树的每个结点的平衡因子的绝对值不会超过 2 左旋：将当前结点 S 的左孩子旋转为当前结点父结点 E 的右孩子，同时将父结点 E 旋转为当前结点 S 的左孩子。可用动画表示： 右旋：将当前结点 S 的左孩子 E 的右孩子旋转为当前结点 S 的左孩子，同时将当前结点 S 旋转为左孩子 E 的右孩子。可用动画表示： 以下图表以 4 列表示 4 种需要重新做平衡的情况, Root 是失去平衡树的根节点(左右子树高度差大于 1) 左左（LL）: 失衡节点 root 的左子树更高, root 左子树的左子树更高 右右（RR）: 左右（LR）: 失衡节点 root 的左子树更高, root 左子树的右子树更高 右左（RL）: 图: 四种情况的旋转(Root 是失去平衡树的根节点，Pivot 是旋转后重新平衡树的根节点),可以看到需要1~2 次旋转即可使不平衡节点重新平衡: 删除的情况AVL 树删除一个节点，最坏情况下需要 logN 次旋转 才能恢复平衡性质（需要回溯到根节点）。插入节点是子树高度加1，旋转会将子树高度减1，因此一次旋转即可恢复平衡；删除节点是子树高度减1，旋转可能会将高度再次减1，这可能会触发再次旋转。 删除节点 X 之后，R4的平衡因子变为 -2，R4 左旋；R3 的平衡因子变为 2，R3 右旋；R2 的平衡因子变为 -2， R2左旋；R1的平衡因子变为2，R1 右旋……当从根节点至待删除节点的父节点平衡因子交替为 -1 和 +1，删除该节点一旦触发旋转就需要 logn 次旋转 （回溯至根节点）。 @ref: 二叉树04.深度分析AVL树的实现与优化 - 极客志 - OSCHINA - 中文开源技术交流社区 复杂度分析 查找: 可以像普通二叉查找树一样的进行，所以耗费 O(log n)时间，因为 AVL 树总是保持平衡的 插入: 向 AVL 树插入，可以透过如同它是未平衡的二叉查找树一样，把给定的值插入树中，接着自底往上向根节点折回，于在插入期间成为不平衡的所有节点(平衡因子&gt;1, 即左右子树高度差)上进行旋转来完成。上面分析了四种情况, 旋转1~2次即可完成, 所以也是 O(log n) 删除: 先看二叉查找树(BST)的删除操作: 当删除一个结点 P，首先需要定位到这个结点 P，这个过程需要一个查找的代价。然后稍微改变一下树的形态。如果被删除结点的左、右子树只有一个存在，则改变形态的代价仅为 O(1)。如果被删除结点的左、右子树均存在，只需要将当 P 的左孩子的右孩子的右孩子的…的右叶子结点与 P 互换(左的右右右, 也即比 P 小但是 P 最大的孩子 )，再改变一些左右子树即可。因此删除操作的时间复杂度最大不会超过 O(logN)。 如果从 AVL 树中删除，AVL 删除结点的算法可以参见上面 BST 的删除结点，但是删除之后必须检查从删除结点开始到根结点路径上的所有结点的平衡因子。因此删除的代价稍微要大一些。每一次删除操作最多需要 O(logN)次旋转。因此，删除操作的时间复杂度最大为 O(2logN) 红黑树红黑树的 5 个性质: 每个结点要么是红的要么是黑的。 根结点是黑的。 每个叶结点（叶结点即指树尾端 NIL 指针或 NULL 结点）都是黑的。 如果一个结点是红的，那么它的两个儿子都是黑的。 对于任意结点而言，其到叶结点树尾端 NIL 指针的每条路径都包含相同数目的黑结点。 正是红黑树的这 5 条性质，使一棵 n 个结点的红黑树始终保持了 logn 的高度，从而也就解释了上面所说的“红黑树的查找、插入、删除的时间复杂度最坏为 O(log n)”这一结论成立的原因。 红黑树通过将结点进行红黑着色，使得原本高度平衡的树结构被稍微打乱，平衡程度降低。红黑树不追求完全平衡，只要求达到部分平衡。这是一种折中的方案，大大提高了结点删除和插入的效率。C++中的 STL 就常用到红黑树作为底层的数据结构。 下图中，”叶结点” 或着叫”NULL 结点”，它不包含数据而只充当树在此结束的指示，这些节点在绘图中经常被省略 插入和删除@ref: https://github.com/julycoding/The-Art-Of-Programming-By-July-2nd/blob/master/ebook/zh/03.01.md 复杂度分析正是红黑树的这5条性质，使得一棵 n 个结点是红黑树始终保持了logn 的高度，从而也就解释了上面我们所说的“红黑树的查找、插入、删除的时间复杂度最坏为 O(log n)”这一结论的原因 B 树 &amp; B+树[[../32.Database/MySQL-02b-BTree索引原理]] 比较几种二叉树的复杂度➤ 二叉查找树 (Binary Search Tree) 的操作代价分析： (1) 查找代价： 任何一个数据的查找过程都需要从根结点出发，沿某一个路径朝叶子结点前进。因此查找中数据比较次数与树的形态密切相关。 当树中每个结点左右子树高度大致相同时，树高为 logN。则平均查找长度与 logN 成正比，查找的平均时间复杂度在 O(logN)数量级上。 当先后插入的关键字有序时，BST 退化成单支树结构。此时树高 n。平均查找长度为(n+1)/2，查找的平均时间复杂度在 O(N)数量级上。 (2) 插入代价： 新结点插入到树的叶子上，完全不需要改变树中原有结点的组织结构。插入一个结点的代价与查找一个不存在的数据的代价完全相同。 (3) 删除代价： 当删除一个结点 P，首先需要定位到这个结点 P，这个过程需要一个查找的代价。然后稍微改变一下树的形态：如果被删除结点的左、右子树只有一个存在，则改变形态的代价仅为 O(1)。如果被删除结点的左、右子树均存在，只需要将当 P 的左孩子的右孩子的右孩子的…的右叶子结点与 P 互换，在改变一些左右子树即可。因此删除操作的时间复杂度最大不会超过 O(logN)。 BST 效率总结 : 查找最好时间复杂度 O(logN)，最坏时间复杂度 O(N)。 插入删除操作算法简单，时间复杂度与查找差不多 ➤ AVL（带平衡条件的 BST） 的操作代价分析： (1) 查找代价： AVL 是严格平衡的 BST（平衡因子不超过 1）。那么查找过程与 BST 一样，只是 AVL 不会出现最差情况的 BST(单支树)。因此查找效率最好、最坏情况都是 O(logN)数量级的。 (2) 插入代价： AVL 必须要保证严格平衡(|bf|&lt;=1)，那么每一次插入数据使得 AVL 中某些结点的平衡因子超过 1 就必须进行旋转操作。事实上，AVL 的每一次插入结点操作最多只需要旋转 1 次(单旋转或双旋转)。因此，总体上插入操作的代价仍然在 O(logN)级别上(插入结点需要首先查找插入的位置)。 (3) 删除代价：AVL 删除结点的算法可以参见 BST 的删除结点，但是删除之后必须检查从删除结点开始到根结点路径上的所有结点的平衡因子。因此删除的代价稍微要大一些。每一次删除操作最多需要 O(logN)次旋转。因此，删除操作的时间复杂度为 O(logN)+O(logN)=O(2logN) AVL 效率总结 : 查找的时间复杂度维持在 O(logN)，不会出现最差情况 AVL 树在执行每个插入操作时最多需要 1 次旋转，其时间复杂度在 O(logN)左右。 AVL 树在执行删除时代价稍大，执行每个删除操作的时间复杂度需要 O(2logN)。 ➤ 红黑树 (Red-Black Tree)： 二叉平衡树的严格平衡策略，以牺牲插入、删除操作的代价，换来了稳定的 O(logN) 的查找时间复杂度。但是这样做是否值得呢？ 能不能找一种折中策略，即不牺牲太大的建立查找结构的代价，也能保证稳定高效的查找效率呢？ 答案就是：红黑树。 RBT 的操作代价分析： (1) 查找代价：由于红黑树的性质(最长路径长度不超过最短路径长度的 2 倍)，可以说明红黑树虽然不像 AVL 一样是严格平衡的，但平衡性能还是要比 BST 要好。其查找代价基本维持在 O(logN)左右，但在最差情况下(最长路径是最短路径的 2 倍少 1)，比 AVL 要略逊色一点。 (2) 插入代价：RBT 插入结点时，需要旋转操作和变色操作。但由于只需要保证 RBT 基本平衡就可以了。因此插入结点最多只需要 2 次旋转，这一点和 AVL 的插入操作一样。虽然变色操作需要 O(logN)，但是变色操作十分简单，代价很小。 (3) 删除代价：RBT 的删除操作代价要比 AVL 要好的多，删除一个结点最多只需要 3 次旋转操作。 RBT 效率总结 : 查找效率最好情况下时间复杂度为 O(logN)，但在最坏情况下比 AVL 要差一些，但也远远好于 BST。 插入和删除操作改变树的平衡性的概率要远远小于 AVL（RBT 不是严格高度平衡的）。因此需要的旋转操作的可能性要小，而且一旦需要旋转，插入一个结点最多只需要旋转 2 次，删除最多只需要旋转 3 次(小于 AVL 的删除操作所需要的旋转次数)。虽然变色操作的时间复杂度在 O(logN)，但是实际上这种操作由于简单所需要的代价很小。 ➤ B 树/B+树 (B-Tree) ： 对于在内存中的查找结构而言，红黑树的效率已经非常好了(实际上很多实际应用还对 RBT 进行了优化)。但是如果是数据量非常大的查找呢？将这些数据全部放入内存组织成 RBT 结构显然是不实际的。在磁盘中组织查找结构，从任何一个结点指向其他结点都有可能读取一次磁盘数据，再将数据写入内存进行比较。显而易见，所有的二叉树的查找结构在磁盘中都是低效的。因此， B-Tree 很好的解决了这一个问题。 B-Tree 的操作代价分析： B-Tree 查找代价 = $O\\log_M N$，M是度数 @link [[../32.Database/MySQL-02b-BTree索引原理.md]] (1) 查找代价： B-Tree 作为一个平衡多路查找树(m叉)。B 树的查找分成两种：一种是从一个结点查找另一结点的地址的时候，需要定位磁盘地址(查找地址)，查找代价极高。另一种是将结点中的有序关键字序列放入内存，进行优化查找(可以用折半)，相比查找代价极低。而 B 树的高度很小，因此在这一背景下，B 树比任何二叉结构查找树的效率都要高很多。 (2)插入代价： B-Tree 的插入会发生结点的分裂操作。当插入操作引起了 s 个节点的分裂时，磁盘访问的次数为 h(读取搜索路径上的节点)＋2s(回写两个分裂出的新节点)＋1（回写新的根节点或插入后没有导致分裂的节点）。因此，所需要的磁盘访问次数是 h+2s+1，最多可达到 3h+1。因此插入的代价是很大的。 (3)删除代价：B-Tree 的删除会发生结点合并操作。最坏情况下磁盘访问次数是 3h＝（找到包含被删除元素需要 h 次读访问）+（获取第 2 至 h 层的最相邻兄弟需要 h-1 次读访问）+（在第 3 至 h 层的合并需要 h-2次写访问）+（对修改过的根节点和第 2 层的两个节点进行 3 次写访问） B-Tree 效率总结： 由于考虑磁盘储存结构，B 树的查找、删除、插入的代价都远远要小于任何二叉结构树(读写磁盘次数的降低)。 @ref: https://blog.csdn.net/keda8997110/article/details/45057081 字典树（Trie）字典树的构建： 节点包含一个 size=26 的数组，下标对应 az，值是指向后续字符的指针，此外节点还有一个 flag 标识字符串是否结束（可选） 根节点不表示任何字符，但根节点的数组是指向子节点的； 每个子节点表示一个字符（有空间的浪费），改进方案是一个节点可以存储多个字符（压缩） 下图是一个字典树： 复杂度分析： 空间：O(n) 增/删/查：O(n) 使用场景： 一堆字符串的最长公共前缀（节点指向下层的指针=1，此节点即为公共前缀中的一个字母）； 统计词频：需要对 Node 的定义做一下修改，增加 freq 属性； typedef struct node&#123; int value;// ASCII码 int frequecy;//c出现的频率 struct node* child[R]; //有R个孩子，初始为NULL&#125;Node; 问题实例： 1、一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，给出时间复杂度分析 构建 Trie tree 用 Trie tree 统计每个词出现的次数，时间复杂度是 O(n*le)（le 表示单词的平均长度），然后是找出出现最频繁的前10个词。 2、寻找热门查询关键词： 搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。假设目前有一千万个记录，这些查询串的重复读比较高，虽然总数是1千万，但是如果去除重复和，不超过3百万个。一个查询串的重复度越高，说明查询它的用户越多，也就越热门。请你统计最热门的10个查询串，要求使用的内存不能超过1G。 提示：利用trie树，关键字域存该查询串出现的次数，没有出现为0。最后用10个元素的最小推来对出现频率进行排序。 @ref: 算法 - 用Trie树统计词频。 - hack - SegmentFault 思否 6.9 Trie树| 编程之法：面试和算法心得 线段树@todo： 数据结构：线段树 优先队列(堆)二叉堆就结构性质上来说就是一个完全填满的二叉树，满足树的结构性和堆序性。堆序性指的是：父节点的键值总是大于或等于（小于或等于）任何一个子节点的键值，且每个节点的左子树和右子树都是一个二叉堆（都是最大堆或最小堆）。 数据结构：堆 堆排序和PriorityQueue源码解析","categories":[{"name":"19.Algorithm","slug":"19-Algorithm","permalink":"https://beefyheisenberg.github.io/categories/19-Algorithm/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"https://beefyheisenberg.github.io/tags/二叉树/"},{"name":"BST","slug":"BST","permalink":"https://beefyheisenberg.github.io/tags/BST/"},{"name":"AVL","slug":"AVL","permalink":"https://beefyheisenberg.github.io/tags/AVL/"},{"name":"红黑树","slug":"红黑树","permalink":"https://beefyheisenberg.github.io/tags/红黑树/"},{"name":"B-Tree","slug":"B-Tree","permalink":"https://beefyheisenberg.github.io/tags/B-Tree/"}]},{"title":"Alg.11.数据结构-线性结构","slug":"19.Algorithm/Alg.11.数据结构-线性结构","date":"2024-01-24T01:27:52.334Z","updated":"2024-01-24T01:27:52.334Z","comments":true,"path":"19.Algorithm/Alg.11.数据结构-线性结构/","link":"","permalink":"https://beefyheisenberg.github.io/19.Algorithm/Alg.11.数据结构-线性结构/","excerpt":"@todo: 数组、链表、栈、队列、双向队列 栈栈的特点： 栈（stack）是插入和删除只能在一个位置上进行的线性表，该位置叫做栈顶（top），对栈的基本操作有 push(进栈)和 pop(出栈) 后进先出（LIFO） 栈的应用 ：中缀表达式转换为后缀表达式","text":"@todo: 数组、链表、栈、队列、双向队列 栈栈的特点： 栈（stack）是插入和删除只能在一个位置上进行的线性表，该位置叫做栈顶（top），对栈的基本操作有 push(进栈)和 pop(出栈) 后进先出（LIFO） 栈的应用 ：中缀表达式转换为后缀表达式中缀: 9 + ( 3 - 1 ) * 3 + 10 / 2 后缀: 9 3 1 - 3 * + 10 2 / + 规则 1.从左到右遍历中缀表达式的每个数字和符号，若是数字就输出（直接成为后缀表达式的一部分，不进入栈） 2.若是符号则判断其与栈顶符号的优先级，是右括号或低于栈顶元素，则栈顶元素依次出栈并输出，等出栈完毕，当前元素入栈。 3.遵循以上两条直到输出后缀表达式为止。 https://github.com/chefyuan/algorithm-base/blob/main/animation-simulation/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E5%85%B3%E4%BA%8E%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B.md 队列队列的特点： 队列也是线性表的一种 遵守先进先出的规则，FIFO 队列的基本操作： 入队（enqueue）:队尾(rear)插入一个元素 出队（dequeue）:队头(front)移出一个元素 使用数组实现循环队列数组实现：动图来自 https://github.com/chefyuan/algorithm-base/blob/main/animation-simulation/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/%E5%85%B3%E4%BA%8E%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B.md","categories":[{"name":"19.Algorithm","slug":"19-Algorithm","permalink":"https://beefyheisenberg.github.io/categories/19-Algorithm/"}],"tags":[]},{"title":"Alg.00.常用数据结构 Quick View","slug":"19.Algorithm/Alg.00.数据结构-Quick View","date":"2024-01-24T01:27:52.329Z","updated":"2024-01-24T01:27:52.330Z","comments":true,"path":"19.Algorithm/Alg.00.数据结构-Quick View/","link":"","permalink":"https://beefyheisenberg.github.io/19.Algorithm/Alg.00.数据结构-Quick View/","excerpt":"1.线性结构(Linear structures) Alg.11.数据结构-线性结构 「逻辑结构」揭示了数据元素之间的逻辑关系。在数组和链表中，数据按照顺序依次排列，体现了数据之间的线性关系；而在树中，数据从顶部向下按层次排列，表现出祖先与后代之间的派生关系；图则由节点和边构成，反映了复杂的网络关系。 逻辑结构通常分为「线性」和「非线性」两类。线性结构比较直观，指数据在逻辑关系上呈线性排列；非线性结构则相反，呈非线性排列，例如网状或树状结构。 线性数据结构：数组、链表、栈、队列； 非线性数据结构：树、图、堆、哈希表；","text":"1.线性结构(Linear structures) Alg.11.数据结构-线性结构 「逻辑结构」揭示了数据元素之间的逻辑关系。在数组和链表中，数据按照顺序依次排列，体现了数据之间的线性关系；而在树中，数据从顶部向下按层次排列，表现出祖先与后代之间的派生关系；图则由节点和边构成，反映了复杂的网络关系。 逻辑结构通常分为「线性」和「非线性」两类。线性结构比较直观，指数据在逻辑关系上呈线性排列；非线性结构则相反，呈非线性排列，例如网状或树状结构。 线性数据结构：数组、链表、栈、队列； 非线性数据结构：树、图、堆、哈希表； 2.树(Tree) Alg.12.数据结构-树 树相关概念 树的阶: 一个节点拥有的子节点最大值, 二叉树的阶是 2 树的度: 同阶的概念, 为什么 B-tree 在不同著作中度的定义有一定差别？ - 知乎 叶子节点: 没有子节点的节点,称为叶子节点 节点的高度: 到最深树叶的路径长度 节点的深度: 节点到根节点的距离(根节点深度为 0) 树的高度: 根节点的高度 常见树结构 二叉树二叉树: 每个节点的叶子不超过2 完全二叉树完全二叉树: 若设二叉树的深度为h，除第 h 层外，其它各层 (1～h-1) 的结点数都达到最大个数，第 h 层所有的结点都连续集中在最左边，这就是完全二叉树 二叉搜索树 BST二叉搜索树（BST / BinarySearchTree）特性: 对于树中某个节点X, 左子树中所有值都小于X, 右子树所有值都大于X; 不足: 但是当原序列有序时二叉搜索树为右斜树，同时二叉树退化成单链表，搜索效率降低为 O(n)。时间复杂度: 索引: O(log(n)) 搜索: O(log(n)) 插入: O(log(n)) 删除: O(log(n)) 平衡二叉树 AVL平衡二叉树（AVL）特性: 极端情况下的 BST 可能退化为链表，AVL 即一种为改进的二叉查找树。一般的二叉查找树的查询复杂度取决于目标结点到树根的距离（即深度），因此当结点的深度普遍较大时，查询的均摊复杂度会上升[1]。为了实现更高效的查询，产生了平衡树。 平衡二叉树的特点：任何节点的左右子树高度差不超过1; 在构造平衡二叉树时，需要采用不同的调整方式，使得二叉树在插入数据后保持平衡。主要的四种调整方式有LL（左旋）、RR（右旋）、LR（先左旋再右旋）、RL（先右旋再左旋） 红黑树 RB红黑树（Red Black Tree） 特性: 红黑树也是一种 AVL（带平衡条件的搜索树）。 红黑树在每个节点增加一个存储位表示节点的颜色，可以是红或黑（非红即黑）。 字典树 Tire字典树（Trie Tree）特性: 根节点不包含字符，除根节点外的每一个子节点都包含一个字符 从根节点到某一节点，路径上经过的字符连接起来，就是该节点对应的字符串 每个字符串的公共前缀作为一个字符节点保存 例：如果我们有 and,as,at,cn,com 这些关键词，那么构建的 trie 树如下 Trie 树就是利用字符串之间的公共前缀，将重复的前缀合并在一起。 线段树 Segment线段树（Segment Tree or Interval tree）特性： 线段树是用于存放间隔或者线段的树形数据结构，它允许快速的查找某一个节点在若干条线段中出现的次数. 时间复杂度: 区间查询: O(log(n)) 更新: O(log(n)) B 树 ~ B+树B-树: “Balance Tree”, 阶为 M 的B树满足如下特性: 树的 根节点 拥有的子节点数量子在 2- M 之间； 除根外，每个 非叶子节点 拥有的子节点数量在 M/2 - M 之间； 一个 非叶子节点 如果包含 k 个关键字，那么它有 k+1 个子节点； 所有叶子节点都在相同的深度，且叶子节点不包含关键字信息； B+树: 要存储的数据只在叶子节点中, 非叶子节点不存储数据, 只有关键字; 相邻的叶子节点之间都有一个链指针，不需要遍历整棵树就可以得到所存储的全部数据 @link: [[../32.Database/MySQL-02b-BTree索引原理]] 3.散列表(Hash Table) Alg.13.数据结构-散列表 散列（Hash，也译作哈希）能够将任意长度的数据映射到固定长度的数据。散列函数返回的即是哈希值，如果两个不同的键得到相同的哈希值，即将这种现象称为碰撞。 散列表（Hash table，也译作哈希表），它通过哈希函数把 Key 的值映射到表中一个位置，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。 https://zh.wikipedia.org/zh-hans/%E5%93%88%E5%B8%8C%E8%A1%A8 4.图(Graph) Alg.14.数据结构-图 图形结构是一种比树形结构更复杂的非线性结构。在树形结构中，结点间具有分支层次关系，每一层上的结点只能和上一层中的至多一个结点相关，但可能和下一层的多个结点相关。而在图形结构中，任意两个结点之间都可能相关，即结点之间的邻接关系可以是任意的。 无向图（Undirected Graph）: 无向图具有对称的邻接矩阵，因此如果存在某条从节点 u 到节点 v 的边，反之从 v 到 u 的边也存在。 有向图（Directed Graph）: 有向图的邻接矩阵是非对称的，即如果存在从 u 到 v 的边并不意味着一定存在从 v 到 u 的边。 https://zh.wikipedia.org/zh-hans/%E5%9B%BE_(%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84) 5.堆(Heap)堆（Heap）是一种特别的完全二叉树。若是满足以下特性，即可称为堆积：“给定堆积中任意节点 P 和 C，若 P 是 C 的父节点，那么 P 的值总是小于等于（或大于等于）C 的值”。 若父节点的值恒小于等于子节点的值，此堆积称为最小堆积（min heap）； 反之，若父节点的值恒大于等于子节点的值，此堆积称为最大堆积（max heap）； JDK 中的 PriorityQueue 通过二叉堆实现 @link: Alg.15.数据结构-堆 二叉堆二叉堆（Binary Heap）特性: 堆是一种特别的完全二叉树（除了最后一层，其他层的节点个数都是满的，最后一层的节点都靠左排列）； 如果父节点的键值总是小于或等于子节点（根节点的值是最小的）, 那么称为小顶堆（min heap），反正择称为大顶堆（max heap） 二叉堆是完全二叉树的特点，可以使用数组存储： 根节点在位置0 任意一个父节点设在位置 i，那么左子节点在位置 2i+1，右子节点在位置 2i+2 二叉堆一般用数组来表示。如果根节点在数组中的位置是1，第_n_个位置的子节点分别在2_n_和 2_n_+1。因此，第1个位置的子节点在2和3，第2个位置的子节点在4和5。以此类推。这种基于1的数组存储方式便于寻找父节点和子节点。 如果存储数组的下标基于0，那么下标为 i 的节点的子节点是2i + 1与 2i + 2；其父节点的下标是 $ floor((i − 1) ∕ 2) $。 floor(_x_)的功能是“向下取整”，或者说“向下舍入”，即取不大于_x_的最大整数（与“四舍五入”不同，向下取整是直接取按照数轴上最接近要求值的左边值，即不大于要求值的最大的那个值）。比如 floor(1.1)、floor(1.9)都返回1。 斐波那契堆➤ 常见的堆结构，除了上面提到的大小堆，还有斐波那契堆 (Fibonacci heap)： 裴波那契堆（Fibonacci Heap）是由 Michael L. Fredman 和 Robert E. Tarjan 在 1984 年发明的一种数据结构，它是一种可合并堆 （mergeable heap）。 裴波那契堆的特点是可以在 O(1)时间内插入单个元素，O(logn)时间内删除最小元素，O(1)时间内合并两个堆。同时，裴波那契堆的平均时间复杂度比二叉堆（Binary Heap）低，因此在某些应用中具有优势。 裴波那契堆的核心思想是利用裴波那契数列的特性来实现堆的操作。裴波那契数列是一个数列，其中每个数字都是前两个数字之和，数列的前几项为：0，1，1，2，3，5，8，13，21，34，…… 等。 裴波那契堆的节点中除了存储元素的值之外，还存储了节点的度数和父节点指针、左右子节点指针以及兄弟节点指针等信息。在堆的合并操作中，裴波那契堆采用了一种“合并根链”的方式，将两个堆中最小的根节点合并，并通过指针将两个堆的根链连接起来。 裴波那契堆的实现比较复杂，但是在某些应用场景下能够提供更好的效率。比如在 Prim 算法中，使用裴波那契堆可以将时间复杂度优化到 O(E+VlogV)。 算法 - 优先队列 - 斐波那契堆 | Earth Guardian 斐波那契堆(三)之 Java语言详解 | skywang","categories":[{"name":"19.Algorithm","slug":"19-Algorithm","permalink":"https://beefyheisenberg.github.io/categories/19-Algorithm/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://beefyheisenberg.github.io/tags/数据结构与算法/"}]},{"title":"软件架构模式","slug":"14.Coding-Pattern/软件架构模式","date":"2024-01-24T01:27:52.324Z","updated":"2024-01-24T01:27:52.325Z","comments":true,"path":"14.Coding-Pattern/软件架构模式/","link":"","permalink":"https://beefyheisenberg.github.io/14.Coding-Pattern/软件架构模式/","excerpt":"➤ 软件设计的”方法论” design patterns: 代码层面 architecture patterns: 架构层面 architecture patterns: 分层架构 管道.. CS.. MVC.. 事件驱动.. 微服务.. ➤ 分层架构: 表现层→业务层→数据层","text":"➤ 软件设计的”方法论” design patterns: 代码层面 architecture patterns: 架构层面 architecture patterns: 分层架构 管道.. CS.. MVC.. 事件驱动.. 微服务.. ➤ 分层架构: 表现层→业务层→数据层 特性: 用户请求不能跨层, 层和层之间暴露接口 优缺点: ➤ 管道-过滤器架构: source → filter1 → filterN → sink 例子: shell的| ➤ CS架构: Client → Server 特性: Server端有可共享的/丰富的资源 ➤ MVC架构: view → controller → model 特性: m的变化由controller通知view变更 view的操作由controller通知model 适用于用户界面的开发 ➤ 事件驱动架构: 事件产生 → 事件队列 → dispatch → handler ➤ 微服务架构: @ref: Fundamentals of Software Architecture 从分层架构到微服务架构（一） - 知乎 程序员必知的几种软件架构模式-InfoQ","categories":[{"name":"14.Coding-Pattern","slug":"14-Coding-Pattern","permalink":"https://beefyheisenberg.github.io/categories/14-Coding-Pattern/"}],"tags":[]},{"title":"设计模式","slug":"14.Coding-Pattern/设计模式","date":"2024-01-24T01:27:52.315Z","updated":"2024-01-24T01:27:52.316Z","comments":true,"path":"14.Coding-Pattern/设计模式/","link":"","permalink":"https://beefyheisenberg.github.io/14.Coding-Pattern/设计模式/","excerpt":"索引: 设计模式：可复用面向对象软件的基础 《设计模式：可复用面向对象软件的基础》（Design Patterns: Elements of Reusable Object-Oriented Software）是软件工程领域有关设计模式的一本书，提出和总结了对于一些常见软件设计问题的标准解决方案，称为软件设计模式。该书作者是埃里希·伽玛（Erich Gamma）、Richard Helm、Ralph Johnson和John Vlissides，后以“四人帮”（Gang of Four，GoF）[1]著称，书中的设计模式也被成为“四人帮设计模式”（Gang of Four design patterns） 创建型模式简单工厂","text":"索引: 设计模式：可复用面向对象软件的基础 《设计模式：可复用面向对象软件的基础》（Design Patterns: Elements of Reusable Object-Oriented Software）是软件工程领域有关设计模式的一本书，提出和总结了对于一些常见软件设计问题的标准解决方案，称为软件设计模式。该书作者是埃里希·伽玛（Erich Gamma）、Richard Helm、Ralph Johnson和John Vlissides，后以“四人帮”（Gang of Four，GoF）[1]著称，书中的设计模式也被成为“四人帮设计模式”（Gang of Four design patterns） 创建型模式简单工厂 工厂类实现工厂方法, 根据传入参数的不同, 返回不同的产品实例(可以返回产品的抽象类) 简单工厂类的工厂方法是静态方法, 又称为静态工厂模式 问题: 增加一种产品需要修改工厂方法, 增加工厂方法的复杂性 由于使用了静态方法, 简单工厂无法形成基于继承的层级结构 抽象工厂 抽象工厂类提供抽象工厂方法(可以有多种方法), 此类方法返回产品的抽象类； 实现抽象工厂类, 实现类需要实现不同的工厂方法, 此外还需要实现 FactoryProducer 来获取不同的工厂实例； 相比简单工厂: 简单工厂在一个工厂方法里生产所有产品, 如果需要新增产品…需要更改具体的工厂方法； 抽象工厂包含多个“工厂实现”, 每个工厂实现类只生产一类产品, 如果需要新增产品, 只需要增加新工厂类和方法； 问题是, 用户代码又引入了”FactoryProducer”, 如果要新增产品和工厂, 需要修改抽象工厂类 AbstractFactory factory1 = FactoryProducer.getFactory(type1)AbstractFactory factory2 = FactoryProducer.getFactory(type2)AbstractProduct product1 = factory1.get() 【图】抽象工厂示例，用户代码从main()函数开始，通过 FactoryProducer 获取抽象工厂（AbstractFactory） 建造者模式 建造者模式（Builder Pattern）使用多个简单的对象一步一步构建成一个复杂的对象。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。 抽象Builder, 提供为产品设定各个属性的的抽象方法, 以及创建产品的抽象方法 具体Builder, 实现… 调用者创建具体的Builder实例, 调用抽象Builder类的设定属性的方法, 最后创建产品.. 【图】建造者模式，从 main()函数开始，用户代码使用 MealBuilder 创建一个复杂的 Meal 对象 单例模式 单例模式的类, 会保证该类仅有一个实例, 并提供一个创建&amp;获取唯一实例的方法 为了保证只有一个实例, 单例类的构造函数是私有的, 不允许其他类调用其构造函数 基本样式: class Singleton &#123; private static Singleton INSTANCE; private Singleton(); public Singleton getInstance(); // 获取单例的具体实现&#125; 实现singleton的几种方式: Lazy式, getInstance()使用synchronized 加锁 Lazy式, getInstance()使用DLC(double lock check) 非Lazy式, 在static区进行实例化 // 不需要lazy loading时的首选 Lazy式, 嵌套类(Singleton类里加一个static类) // 需要lazy loading时的首选 枚举 // 原型模式原型模式（Prototype）是一种创建型设计模式，使你能够复制已有对象，而又无需使代码依赖它们所属的类。原型模式主要用于对象的复制，例如 clone() 如果业务对象需要“可 clone”，一般需继承一个表示是 “cloneable” 的 interface ； 业务对象实现 clone() 结构型模式适配器模式 适配器模式（Adapter Pattern） 用户代码里调用 methodA(), 但是实现类没有提供 methodA() 却提供了 methodB(), 这时候需要 adaptor 类对实现类进行包装, 并提供 methodA() 实现: adaptor类中, 持有一个实现类的引用 // 注意adaptor和实现类非继承关系, 而是关联关系 【图】用户代码（Client 类）通过 Adaptor 的实例，最终调用 methodB() 桥接模式桥接模式是软件设计模式中最复杂的模式之一，它把事物对象和其具体行为、具体特征分离开来，使它们可以各自独立的变化。事物对象仅是一个抽象的概念。如“圆形”、“三角形”归于抽象的“形状”之下，而“画圆”、“画三角”归于实现行为的“画图”类之下，然后由“形状”调用“画图”。 桥接（Bridge）模式把抽象事物/抽象行为分离开, 抽象事物调用抽象行为(的方法) 桥接是用于把抽象化与实现化解耦，使得二者可以独立变化。这种类型的设计模式属于结构型模式，它通过提供抽象化和实现化之间的桥接结构，来实现二者的解耦。 抽象事物(Abstraction)的继承类仍是抽象类(RedefinedAbstraction) 抽象行为(Implementor) 抽象事物(Abstraction)像桥一样把 RedefinedAbstraction 类和 Implementor 类连接在一起 实现: 抽象事物(Abstraction) 持有抽象行为(Implementor)的引用 RedefinedAbstraction extends Abstraction //实现具体事物 ConcreteImplementor extends Implementor //实现具体行为 【图】 装饰模式 装饰器模式（Decorator Pattern）允许向一个现有的对象添加新的功能，同时又不改变其结构。这种类型的设计模式属于结构型模式，它是作为现有的类的一个包装。 增加一个修饰类, 包裹原来的类, 包裹的方式一般是通过修饰类的构造函数传入, 修饰类实现新的功能 装饰模式可以避免向一个实现类添加新方法导致代码膨胀 下图中的 Decorator类即装饰类, 装饰类可以改写operation()方法也可以增加自己的方法 实现: 需要被装饰的类(ConcreteComponent), 和它的基类(Component) 装饰类(Decorator) 持有基类的一个引用. 事实上装饰类也继承上面的基类 代理模式 用户代码不调用具体的功能类, 而是通过调用代理类间接调用这些功能类 (用户代码往往调用的是代理类的抽象接口, 代理也不直接调用功能类, 而是调用功能类的接口) 代理类可以调用多种功能类, 并且可以在代理类中, 增加一些功能 @link [[../12.Java/Java-Tutorials.14.代理(Proxy)]] 实现: 被代理的类(RealSubject), 需要有一个接口(Subject) 创建Proxy类, Proxy类也实现该接口(Subject) 用户(client) 不直接调用 realSubject.DoAction(), 调用的是接口（Subject）的方法，然后是 Proxy的DoAction(), 最终调用 realSubject.DoAction() 可以在代理类 Proxy::DoAction()中做一些额外的操作: e.g. 实现引用计数 &amp; Java的AOP(面向切面编程) 享元模式 享元模式（Flyweight Pattern），创建大量对象时, 把这些对象共有的部分抽象出来单独存储, 这些对象共享共有部分, 而不是重复创建 享元模式通过共享数据减少内存使用量 例子: Java String Pool、Java Intger 行为模式责任链模式 实现责任链模式的抽象类, 通常具有一个next属性 实现类判断是否在自己这一层进行处理, 然后传递给next指向的对象 例如一条日志具有 debug/info/warning/error几个级别, 每个实现类判断自己是否需要处理(自己的优先级同这条日志的优先级比较), 然后传给下一个实现类 观察者模式 观察者 attach到被观察者, 被观察者发生改变时, 通知观察者 下图中, Observer是观察者, Subject作为被观察者的抽象类, 提供了attach和detach观察者的方法(add和delete) 实现: 被观察者( Subject) 持有观察者(Observer)的对象 注意二者关系是聚合关系(一种松散的关联关系, 二者不必有共同生命周期, Observer可以随时attach/detach到Subject) JDK里的设计模式(zz) 创建模式:- 抽象工厂模式：抽象工厂模式提供了一个协议来生成一系列的相关或者独立的对象，而不用指定具体对象的类型，如 `java.util.Calendar#getInstance()`。 - 建造模式(Builder)：定义了一个新的类来构建另一个类的实例，以简化复杂对象的创建，如：`java.lang.StringBuilder#append()`。 - 工厂方法：一个返回具体对象的方法，而不是多个，如 `java.lang.Object#toString()`、`java.lang.Class#newInstance()`。 - 原型模式：使得类的实例能够生成自身的拷贝、如：`java.lang.Object#clone()`。 - 单例模式：全局只有一个实例，如 `java.lang.Runtime#getRuntime()`。 结构型模式：- 适配器：用来把一个接口转化成另一个接口，如 `java.util.Arrays#asList()`。 - 桥接模式：这个模式将抽象和抽象操作的实现进行了解耦，这样使得抽象和实现可以独立地变化，如JDBC； - 组合模式：使得客户端看来单个对象和对象的组合是同等的。换句话说，某个类型的方法同时也接受自身类型作为参数，如 `Map.putAll`，`List.addAll`、`Set.addAll`。 - 装饰者模式：动态的给一个对象附加额外的功能，这也是子类的一种替代方式，如 `java.util.Collections#checkedList|Map|Set|SortedSet|SortedMap`。 - 享元模式：使用缓存来加速大量小对象的访问时间，如 valueOf(int)。 - 代理模式：代理模式是用一个简单的对象来代替一个复杂的或者创建耗时的对象，如 `java.lang.reflect.Proxy` 行为模式：- 命令模式：将操作封装到对象内，以便存储，传递和返回，如：`java.lang.Runnable`。 - 解释器模式：定义了一个语言的语法，然后解析相应语法的语句，如，`java.text.Format`，`java.text.Normalizer`。 - 迭代器模式：提供一个一致的方法来顺序访问集合中的对象，如 `java.util.Iterator`。 - 中介者模式：通过使用一个中间对象来进行消息分发以及减少类之间的直接依赖，`java.lang.reflect.Method#invoke()`。 - 观察者模式：它使得一个对象可以灵活的将消息发送给感兴趣的对象，如 `java.util.EventListener`。 - 责任链模式：通过把请求从一个对象传递到链条中下一个对象的方式，直到请求被处理完毕，以实现对象间的解耦。如 `javax.servlet.Filter#doFilter()`。 - 空对象模式：如 `java.util.Collections#emptyList()`。 - 模板方法模式：让子类可以重写方法的一部分，而不是整个重写，如 `java.util.Collections#sort()`。 @ref: Design Patterns in the JDK | Java Code Geeks - 2021 JDK里的设计模式 | 酷 壳 - CoolShell 关于UMLUML参考: 设计模式-UML类图","categories":[{"name":"14.Coding-Pattern","slug":"14-Coding-Pattern","permalink":"https://beefyheisenberg.github.io/categories/14-Coding-Pattern/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://beefyheisenberg.github.io/tags/设计模式/"},{"name":"Design Pattern","slug":"Design-Pattern","permalink":"https://beefyheisenberg.github.io/tags/Design-Pattern/"}]},{"title":"设计模式-UML类图","slug":"14.Coding-Pattern/设计模式-UML类图","date":"2024-01-24T01:27:52.311Z","updated":"2024-01-24T01:27:52.311Z","comments":true,"path":"14.Coding-Pattern/设计模式-UML类图/","link":"","permalink":"https://beefyheisenberg.github.io/14.Coding-Pattern/设计模式-UML类图/","excerpt":"类和接口➤ 具体类: 第一层类名, 第二层成员变量, 第三层方法 访问控制: +表示public, -表示private … ➤ 抽象类:","text":"类和接口➤ 具体类: 第一层类名, 第二层成员变量, 第三层方法 访问控制: +表示public, -表示private … ➤ 抽象类: 类名用斜体 ➤ 接口: 类名有Interface标识 ➤ 包: 关系 ➤ TOC 类-接口关系: 实现关系, implements, 实现类–▷接口 //虚线 类-类关系: 泛化关系: is-a, extends, 派生类——▷基类 //实线 关联关系: A持有B的引用, A——&gt;B 依赖关系: usa-a, A–&gt;B 聚合关系: has-a, A◇–&gt;B 组合关系: contains-a, A◆–&gt;B ➤ 实现关系: 例如java中的implements Interface ➤ 泛化关系: 例如java中的extends BaseClass ➤ 关联关系: A有B类型的成员变量 ➤ 依赖关系: use-a 可以看作是一种弱关联关系, 比上面的关联关系弱, 包括几种情况: A中定义了(B类型的)局部变量 A调用了B的静态方法 A的方法形参是B类型 A的方法返回B类型 ➤ 聚合关系: has-a, 特殊的关联关系 A关联B对象, 但A和B关系不紧密, 例如B可以属于多个A1,A2…类型 例如员工和部门, 员工可以属于多个部门, 部门裁撤, 员工可以转移到其他部门 ➤ 组合关系: contain-a, 特殊的关联关系 A关联对象B, A和B关系紧密, A和B同一个生命周期(一般由A管理B的生成和释放) 相比依赖/聚合关系, 组合关系表示更强的紧密程度 参考30分钟学会UML类图 - 知乎","categories":[{"name":"14.Coding-Pattern","slug":"14-Coding-Pattern","permalink":"https://beefyheisenberg.github.io/categories/14-Coding-Pattern/"}],"tags":[]},{"title":"Spring 中都用到了那些设计模式?","slug":"14.Coding-Pattern/Pattern-in-Spring","date":"2024-01-24T01:27:52.307Z","updated":"2024-01-24T01:27:52.307Z","comments":true,"path":"14.Coding-Pattern/Pattern-in-Spring/","link":"","permalink":"https://beefyheisenberg.github.io/14.Coding-Pattern/Pattern-in-Spring/","excerpt":"工厂模式Spring 使用工厂模式可以通过 BeanFactory 或 ApplicationContext 创建 bean 对象。 两者对比： BeanFactory ：延迟注入(使用到某个 bean 的时候才会注入),相比于 BeanFactory 来说会占用更少的内存，程序启动速度更快。 ApplicationContext ：容器启动的时候，不管你用没用到，一次性创建所有 bean 。BeanFactory 仅提供了最基本的依赖注入支持，ApplicationContext 扩展了 BeanFactory ,除了有 BeanFactory 的功能还有额外更多功能，所以一般开发人员使用 ApplicationContext 会更多。 ApplicationContext 的三个实现类：","text":"工厂模式Spring 使用工厂模式可以通过 BeanFactory 或 ApplicationContext 创建 bean 对象。 两者对比： BeanFactory ：延迟注入(使用到某个 bean 的时候才会注入),相比于 BeanFactory 来说会占用更少的内存，程序启动速度更快。 ApplicationContext ：容器启动的时候，不管你用没用到，一次性创建所有 bean 。BeanFactory 仅提供了最基本的依赖注入支持，ApplicationContext 扩展了 BeanFactory ,除了有 BeanFactory 的功能还有额外更多功能，所以一般开发人员使用 ApplicationContext 会更多。 ApplicationContext 的三个实现类： ClassPathXmlApplication：把上下文文件当成类路径资源。 FileSystemXmlApplication：从文件系统中的 XML 文件载入上下文定义信息。 XmlWebApplicationContext：从 Web 系统中的 XML 文件载入上下文定义信息。 Example: import org.springframework.context.ApplicationContext;import org.springframework.context.support.FileSystemXmlApplicationContext;public class App &#123; public static void main(String[] args) &#123; ApplicationContext context = new FileSystemXmlApplicationContext( \"C:/work/IOC Containers/springframework.applicationcontext/src/main/resources/bean-factory-config.xml\"); HelloApplicationContext obj = (HelloApplicationContext) context.getBean(\"helloApplicationContext\"); obj.getMsg(); &#125;&#125; 单例模式在我们的系统中，有一些对象其实我们只需要一个，比如说：线程池、缓存、对话框、注册表、日志对象、充当打印机、显卡等设备驱动程序的对象。事实上，这一类对象只能有一个实例，如果制造出多个实例就可能会导致一些问题的产生，比如：程序的行为异常、资源使用过量、或者不一致性的结果。 使用单例模式的好处: 对于频繁使用的对象，可以省略创建对象所花费的时间，这对于那些重量级对象而言，是非常可观的一笔系统开销； 由于 new 操作的次数减少，因而对系统内存的使用频率也会降低，这将减轻 GC 压力，缩短 GC 停顿时间。 Spring 中 bean 的默认作用域就是 singleton(单例)的。 除了 singleton 作用域，Spring 中 bean 还有下面几种作用域： prototype : 每次请求都会创建一个新的 bean 实例。 request : 每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP request 内有效。 session : 每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP session 内有效。 Spring 实现单例的方式： xml: &lt;bean id=\"userService\" class=\"top.snailclimb.UserService\" scope=\"singleton\"/&gt; 注解：@Scope(value = &quot;singleton&quot;) 代理模式AOP(Aspect-Oriented Programming:面向切面编程)能够将那些与业务无关，却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可拓展性和可维护性。 Spring AOP 就是基于动态代理的，如果要代理的对象，实现了某个接口，那么 Spring AOP 会使用JDK Proxy，去创建代理对象，而对于没有实现接口的对象，就无法使用 JDK Proxy 去进行代理了，这时候 Spring AOP 会使用Cglib ，这时候 Spring AOP 会使用 Cglib 生成一个被代理对象的子类来作为代理。 模板方法模板方法模式是一种行为设计模式，它定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤的实现方式。 Spring 中 jdbcTemplate、hibernateTemplate 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。一般情况下，我们都是使用继承的方式来实现模板模式，但是 Spring 并没有使用这种方式，而是使用 Callback 模式与模板方法模式配合，既达到了代码复用的效果，同时增加了灵活性。 观察者模式观察者模式是一种对象行为型模式。它表示的是一种对象与对象之间具有依赖关系，当一个对象发生改变的时候，这个对象所依赖的对象也会做出反应。Spring 事件驱动模型就是观察者模式很经典的一个应用。Spring 事件驱动模型非常有用，在很多场景都可以解耦我们的代码。比如我们每次添加商品的时候都需要重新更新商品索引，这个时候就可以利用观察者模式来解决这个问题。 Spring 事件驱动模型中的三种角色事件角色ApplicationEvent (org.springframework.context 包下)充当事件的角色,这是一个抽象类，它继承了 java.util.EventObject 并实现了 java.io.Serializable 接口。 Spring 中默认存在以下事件，他们都是对 ApplicationContextEvent 的实现(继承自 ApplicationContextEvent)： ContextStartedEvent：ApplicationContext 启动后触发的事件; ContextStoppedEvent：ApplicationContext 停止后触发的事件; ContextRefreshedEvent：ApplicationContext 初始化或刷新完成后触发的事件; ContextClosedEvent：ApplicationContext 关闭后触发的事件。 事件监听者角色ApplicationListener 充当了事件监听者角色，它是一个接口，里面只定义了一个 onApplicationEvent（） 方法来处理 ApplicationEvent。ApplicationListener 接口类源码如下，可以看出接口定义看出接口中的事件只要实现了 ApplicationEvent 就可以了。所以，在 Spring 中我们只要实现 ApplicationListener 接口实现 onApplicationEvent() 方法即可完成监听事件 package org.springframework.context;import java.util.EventListener;@FunctionalInterfacepublic interface ApplicationListener&lt;E extends ApplicationEvent&gt; extends EventListener &#123; void onApplicationEvent(E var1);&#125; 事件发布者角色ApplicationEventPublisher 充当了事件的发布者，它也是一个接口。 @FunctionalInterfacepublic interface ApplicationEventPublisher &#123; default void publishEvent(ApplicationEvent event) &#123; this.publishEvent((Object)event); &#125; void publishEvent(Object var1);&#125; ApplicationEventPublisher 接口的 publishEvent（） 这个方法在 AbstractApplicationContext 类中被实现，阅读这个方法的实现，你会发现实际上事件真正是通过 ApplicationEventMulticaster 来广播出去的。具体内容过多，就不在这里分析了，后面可能会单独写一篇文章提到。 Spring 的事件流程总结 定义一个事件: 实现一个继承自 ApplicationEvent，并且写相应的构造函数； 定义一个事件监听者：实现 ApplicationListener 接口，重写 onApplicationEvent() 方法； 使用事件发布者发布消息: 可以通过 ApplicationEventPublisher 的 publishEvent() 方法发布消息。 Example: // 定义一个事件,继承自ApplicationEvent并且写相应的构造函数public class DemoEvent extends ApplicationEvent&#123; private static final long serialVersionUID = 1L; private String message; public DemoEvent(Object source,String message)&#123; super(source); this.message = message; &#125; public String getMessage() &#123; return message; &#125;// 定义一个事件监听者,实现ApplicationListener接口，重写 onApplicationEvent() 方法；@Componentpublic class DemoListener implements ApplicationListener&lt;DemoEvent&gt;&#123; //使用onApplicationEvent接收消息 @Override public void onApplicationEvent(DemoEvent event) &#123; String msg = event.getMessage(); System.out.println(\"接收到的信息是：\"+msg); &#125;&#125;// 发布事件，可以通过ApplicationEventPublisher 的 publishEvent() 方法发布消息。@Componentpublic class DemoPublisher &#123; @Autowired ApplicationContext applicationContext; public void publish(String message)&#123; //发布事件 applicationContext.publishEvent(new DemoEvent(this, message)); &#125;&#125; 当调用 DemoPublisher 的 publish() 方法的时候，比如 demoPublisher.publish(&quot;你好&quot;) ，控制台就会打印出: 接收到的信息是：你好 。 适配器模式适配器模式(Adapter Pattern) 将一个接口转换成客户希望的另一个接口，适配器模式使接口不兼容的那些类可以一起工作，其别名为包装器(Wrapper)。 spring AOP 中的适配器模式我们知道 Spring AOP 的实现是基于代理模式，但是 Spring AOP 的增强或通知(Advice)使用到了适配器模式，与之相关的接口是 AdvisorAdapter 。Advice 常用的类型有：BeforeAdvice（目标方法调用前,前置通知）、AfterAdvice（目标方法调用后,后置通知）、AfterReturningAdvice (目标方法执行结束后，return 之前)等等。每个类型 Advice（通知）都有对应的拦截器: MethodBeforeAdviceInterceptor、AfterReturningAdviceAdapter、AfterReturningAdviceInterceptor。Spring 预定义的通知要通过对应的适配器，适配成 MethodInterceptor 接口(方法拦截器)类型的对象（如：MethodBeforeAdviceInterceptor 负责适配 MethodBeforeAdvice）。 spring MVC 中的适配器模式在 Spring MVC 中，DispatcherServlet 根据请求信息调用 HandlerMapping，解析请求对应的 Handler。解析到对应的 Handler（也就是我们平常说的 Controller 控制器）后，开始由 HandlerAdapter 适配器处理。HandlerAdapter 作为期望接口，具体的适配器实现类用于对目标类进行适配，Controller 作为需要适配的类。 为什么要在 Spring MVC 中使用适配器模式？ Spring MVC 中的 Controller 种类众多，不同类型的 Controller 通过不同的方法来对请求进行处理。如果不利用适配器模式的话，DispatcherServlet 直接获取对应类型的 Controller，需要的自行来判断，像下面这段代码一样： if(mappedHandler.getHandler() instanceof MultiActionController)&#123; ((MultiActionController)mappedHandler.getHandler()).xxx &#125;else if(mappedHandler.getHandler() instanceof XXX)&#123; ... &#125;else if(...)&#123; ... &#125; 假如我们再增加一个 Controller 类型就要在上面代码中再加入一行判断语句，这种形式就使得程序难以维护，也违反了设计模式中的开闭原则 – 对扩展开放，对修改关闭。 装饰者模式装饰者模式可以动态地给对象添加一些额外的属性或行为。相比于使用继承，装饰者模式更加灵活。简单点儿说就是当我们需要修改原有的功能，但我们又不愿直接去修改原有的代码时，设计一个 Decorator 套在原有代码外面。其实在 JDK 中就有很多地方用到了装饰者模式，比如 InputStream 家族，InputStream 类下有 FileInputStream (读取文件)、BufferedInputStream (增加缓存,使读取文件速度大大提升)等子类都在不修改 InputStream 代码的情况下扩展了它的功能。 Spring 中配置 DataSource 的时候，DataSource 可能是不同的数据库和数据源。我们能否根据客户的需求在少修改原有类的代码下动态切换不同的数据源？这个时候就要用到装饰者模式(这一点我自己还没太理解具体原理)。Spring 中用到的包装器模式在类名上含有 Wrapper 或者 Decorator。这些类基本上都是动态地给一个对象添加一些额外的职责。 总结Spring 框架中用到了哪些设计模式： 工厂设计模式 : Spring 使用工厂模式通过 BeanFactory、ApplicationContext 创建 bean 对象。 代理设计模式 : Spring AOP 功能的实现。 单例设计模式 : Spring 中的 Bean 默认都是单例的。 模板方法模式 : Spring 中 jdbcTemplate、hibernateTemplate 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。 装饰器设计模式 : 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。 观察者模式: Spring 事件驱动模型就是观察者模式很经典的一个应用。 适配器模式 :Spring AOP 的增强或通知(Advice)使用到了适配器模式、spring MVC 中也是用到了适配器模式适配 Controller。","categories":[{"name":"14.Coding-Pattern","slug":"14-Coding-Pattern","permalink":"https://beefyheisenberg.github.io/categories/14-Coding-Pattern/"}],"tags":[]},{"title":"Java代码规范","slug":"14.Coding-Pattern/Java代码规范","date":"2024-01-24T01:27:52.302Z","updated":"2024-01-24T01:27:52.302Z","comments":true,"path":"14.Coding-Pattern/Java代码规范/","link":"","permalink":"https://beefyheisenberg.github.io/14.Coding-Pattern/Java代码规范/","excerpt":"","text":"变量命名 【强制】POJO类中的任何布尔类型的变量，都不要加is前缀，否则部分框架解析会引起序列 化错误。 BigDecimal 的等值比较应使用 compareTo()方法，而不是 equals()方法。 说明:equals()方法会比较值和精度(1.0 与 1.00 返回结果为 false)，而 compareTo()则会忽略精度。 @ref: [[../_attachments/阿里巴巴Java开发手册.pdf]]","categories":[{"name":"14.Coding-Pattern","slug":"14-Coding-Pattern","permalink":"https://beefyheisenberg.github.io/categories/14-Coding-Pattern/"}],"tags":[]},{"title":"Go 项目结构","slug":"14.Coding-Pattern/Golang项目结构","date":"2024-01-24T01:27:52.298Z","updated":"2024-01-24T01:27:52.298Z","comments":true,"path":"14.Coding-Pattern/Golang项目结构/","link":"","permalink":"https://beefyheisenberg.github.io/14.Coding-Pattern/Golang项目结构/","excerpt":"@ref: 该如何组织 Go 项目结构？ - 知乎 [[Go工程化.pdf]] 一个常见的 Go 应用项目布局，通常有如下结构： - my-go-project |- cmd/ |- pkg/ |- internal/ |-biz/ |-data/ |-service |- go.mod |- go.sum |- Makefile","text":"@ref: 该如何组织 Go 项目结构？ - 知乎 [[Go工程化.pdf]] 一个常见的 Go 应用项目布局，通常有如下结构： - my-go-project |- cmd/ |- pkg/ |- internal/ |-biz/ |-data/ |-service |- go.mod |- go.sum |- Makefile cmdcmd 包是项目的主干，是编译构建的入口，main 文件通常放置在此处。需要注意的是，cmd 中的代码应该尽量「保持简洁」，main 函数中可能仅仅是参数初始化、配置加载、服务启动、关闭操作。一个典型的 cmd 包的目录结构如下所示 - cmd - demo1 - main.go - demo2 - main.go pkgpkg 中存放的是可供项目内部/外部所使用的公共性代码，例如：用来连接第三方服务的 client 代码等。也有部分项目将该包命名为 lib - pkg - cache - redis - memcache - conf - dsn - paladin internalinternal 包主要用处在于提供一个项目级别的代码保护方式，存放在其中的代码仅供项目内部使用。具体使用的规则是：…/a/b/c/internal/d/e/f 仅仅可以被…/a/b/c下的目录导入，…/a/b/g则不允许。internal 是 Go 1.4 版本中引入的特性，更多信息可以参考https://go.dev/doc/go1.4#internalpackages - internal - demo1 - biz - data - service internal: 是为了避免有同业务下有人跨目录引用了内部的 biz、 data、service 等内部 struct。• biz:业务逻辑的组装层，类似DDD的domain层，data类似DDD 的 repo，repo 接口在这里定义，使用依赖倒置的原则。• data:业务数据访问，包含cache、db等封装，实现了biz的repo 接口。我们可能会把 data 与 dao 混淆在一起，data 偏重业务的含义， 它所要做的是将领域对象重新拿出来，我们去掉了 DDD 的 infra 层。• service:实现了api定义的服务层，类似DDD的application层，处理 DTO 到 biz 领域实体的转换(DTO -&gt; DO)，同时协同各类 biz 交互， 但是不应处理复杂逻辑。 go.modgo.mod 与 go.sum 是采用 go modules 进行依赖管理所生成的配置文件。go modules 是 Go 1.11 版本中引入的版本管理功能，目前已经是 go 依赖管理的主流方式，所以此处不再讨论 vendor，dep 等依赖管理方式所生成的目录。 MakefileMakefile 文件通常存放项目的编译部署脚本。Go 的编译命令虽然简单，但总是手写命令还是效率低下，因此使用 Makefile 写编译部署脚本是工程实践中常见的方式。 kit工具包项目通常也叫 kit 项目，包含公司的公共依赖库，在 https://github.com/ardanlabs/kit 中给出了一个 kit 项目布局示例： github.com/ardanlabs/kit├── CONTRIBUTORS├── LICENSE├── README.md├── cfg/ ├── examples/ ├── log/├── pool/├── tcp/├── timezone/├── udp/└── web/ kit 项目有以下几个特点： （1）建议公司只有「一个」 kit 项目，kit 包含的是供公司多个项目使用的基础库，提供非常具体但是基本的功能。 （2）建议 kit 项目不要依赖第三方库版本，即 kit 中不要包含 vendor, go modules 等版本管理信息。kit 本质是基础工具包，如果内部含有 vendor 等版本管理，那么就要随着第三方库的更新而不断更新，导致上层依赖 kit 的应用也得随之更新，变更代价很大。","categories":[{"name":"14.Coding-Pattern","slug":"14-Coding-Pattern","permalink":"https://beefyheisenberg.github.io/categories/14-Coding-Pattern/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://beefyheisenberg.github.io/tags/Golang/"}]},{"title":"Java测试框架 - JUnit","slug":"13.JavaEE-Framework/Tools-测试框架","date":"2024-01-24T01:27:52.294Z","updated":"2024-01-24T01:27:52.294Z","comments":true,"path":"13.JavaEE-Framework/Tools-测试框架/","link":"","permalink":"https://beefyheisenberg.github.io/13.JavaEE-Framework/Tools-测试框架/","excerpt":"JUnitHow to maven 顶层POM文件增加JUnit依赖, &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; IDEA, 右键项目, maven -&gt; reimport 在src下, 创建一个test目录, 与main同级 右键这个test目录, “Mark Directory as” -&gt; “Test Resources Root” 选中要测试的类, cmd+shift+T, 创建Test类 （Junit3是继承TestCase, Junit4是基于@Test注解） Junit提供的断言: assertEquals assertNull 用Junit4测试Spring项目同样创建测试类, 测试类要加上如下注解:","text":"JUnitHow to maven 顶层POM文件增加JUnit依赖, &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; IDEA, 右键项目, maven -&gt; reimport 在src下, 创建一个test目录, 与main同级 右键这个test目录, “Mark Directory as” -&gt; “Test Resources Root” 选中要测试的类, cmd+shift+T, 创建Test类 （Junit3是继承TestCase, Junit4是基于@Test注解） Junit提供的断言: assertEquals assertNull 用Junit4测试Spring项目同样创建测试类, 测试类要加上如下注解: @RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations=\"/META-INF/applicationContext.xml\")@Transactionalpublic class UserDAOImplTest &#123;&#125; @ref: 关于Java单元测试，你需要知道的一切 | Lam’s Blog","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"},{"name":"JUnit","slug":"JUnit","permalink":"https://beefyheisenberg.github.io/tags/JUnit/"},{"name":"单元测试","slug":"单元测试","permalink":"https://beefyheisenberg.github.io/tags/单元测试/"}]},{"title":"Java构建工具 - Maven and Gradle","slug":"13.JavaEE-Framework/Tools-构建工具","date":"2024-01-24T01:27:52.288Z","updated":"2024-01-24T01:27:52.289Z","comments":true,"path":"13.JavaEE-Framework/Tools-构建工具/","link":"","permalink":"https://beefyheisenberg.github.io/13.JavaEE-Framework/Tools-构建工具/","excerpt":"Mavensetting.xml@ref https://maven.apache.org/settings.html默认配置文件在~/.m2/settings.xml, 命令mvn -X可以查看正在使用哪个Setting.xml, 以及xml文件中的配置参数.国内的mirrors和repositories基本都不可用, 所以直接使用central repositories(http://repo1.maven.org/maven2)并且设置proxy. pom.xml@ref https://maven.apache.org/pom.html","text":"Mavensetting.xml@ref https://maven.apache.org/settings.html默认配置文件在~/.m2/settings.xml, 命令mvn -X可以查看正在使用哪个Setting.xml, 以及xml文件中的配置参数.国内的mirrors和repositories基本都不可用, 所以直接使用central repositories(http://repo1.maven.org/maven2)并且设置proxy. pom.xml@ref https://maven.apache.org/pom.html profilesCreate ypur maven projects 命令: mvn archetype:generate -DgroupId=org.kshan.toolbox -DartifactId=XXX -Dversion=1.0-SNAPSHOT -DarchetypeArtifactId=maven-archetype-quickstart, 如果创建web项目, 将最后一项参数修改为: -DarchetypeArtifactId=maven-archetype-webapp 命令 mvn lifecycle, 比如mvn compile, mvn package, mvn install, 如果插件的目标绑定到该生命周期, 则会执行这个插件的目标(goal). mvn goal, 目标一般是由插件定义的, 例如mvn archetype:generate 就表示调用maven-archetype-plugin插件的generate目标，这种带冒号的调用方式与生命周期无关 运行maven工程里的某个main方法: mvn exec:java -Dexec.mainClass=&quot;org.xx.className, 这里的goal是 maven-exec-plugin插件定义的. lifecycle mvn compile : compile the source code of the project mvn test : test the compiled source code using a suitable unit testing framework mvn package : take the compiled code and package it in its distributable format, such as a JAR. -Dmaven.test.skip=ture : -Dmaven.compile.fork=true : Runs the compiler in a separate process -o : Work offline mvn install : install the package into the local repository, for use as a dependency in other projects locally mvn deploy: copies the final package to the remote repository mvn clean : cleans up artifacts created by prior builds snapshot快照库和release发布库的区别maven中的仓库分为两种，snapshot快照仓库和release发布仓库。snapshot快照仓库用于保存开发过程中的不稳定版本，release正式仓库则是用来保存稳定的发行版本。定义一个组件/模块为快照版本，只需要在pom文件中在该模块的版本号后加上-SNAPSHOT即可(注意这里必须是大写)，如下： &lt;groupId&gt;com.abc&lt;/groupId&gt;&lt;artifactId&gt;myLib1&lt;/artifactId&gt;&lt;version&gt;0.1-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt; 插件的Goal mvn eclipse:eclipse : 生成eclipse项目文件, 用于导入eclipse mvn idea:idea : 同上 将没有在maven官方repository中的jar包加入到本地的maven repository中: mvn install:install-file -Dfile=path-to-your-artifact-jar -DgroupId=your.groupId -DartifactId=your-artifactId -Dversion=your-version -Dpackaging=jar 仅下载依赖: mvn dependency:resolve 下载source和doc : mvn dependency:sources -DdownloadSources=true -DdownloadJavadocs=true 运行指定Jar: mvn exec:java -Dexec.mainClass=&quot;com.vineetmanohar.module.Main&quot; -Dexec.args=&quot;arg0 arg1 arg2&quot; 插件(plugins)&lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.3&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/pluginManagement&gt; maven-release-pluginmvn cleanmvn release:prepare -Darguments=&quot;-DskipTests&quot;mvn release:perform maven-resources-plugin为了使项目结构更为清晰，Maven区别对待Java代码文件和资源文件，maven-compiler-plugin用来编译Java代码，maven-resources-plugin则用来处理资源文件。默认的主资源文件目录是src/main/resources，很多用户会需要添加额外的资源文件目录，这个时候就可以通过配置maven-resources-plugin来实现。此外，资源文件过滤也是Maven的一大特性，你可以在资源文件中使用${propertyName}形式的Maven属性，然后配置maven-resources-plugin开启对资源文件的过滤，之后就可以针对不同环境通过命令行或者Profile传入属性的值，以实现更为灵活的构建。 Jetty Plugin mvn jetty:run mvn -Djetty.port=8888 jetty:run Help Plugin 获取插件帮助: mvn help:describe -Dplugin=eclipse 获取goal帮助: mvn help:describe -Dplugin=archetype mvn help:active-profiles mvn help:effective-settings mvn help:system 依赖(dependencies)&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.thrift&lt;/groupId&gt; &lt;artifactId&gt;libthrift&lt;/artifactId&gt; &lt;version&gt;$&#123;org.apache.thrift.version&#125;&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 查看依赖查看各个子module和引入Jar的依赖关系: mvn dependency:list 可以看到当前项目已解析的依赖 mvn dependency:tree 看到依赖树 mvn dependency:analyse 查看依赖的工具 scopescope有5个缺省值: compile: 缺省值, 表示该maven项目在 编译 / 测试 / 运行 阶段都需要依赖这个jar包, compile方式依赖的库具有传递性: 如果项目依赖了A库, 同时A依赖B(scope=compile) , 那么该项目也会依赖B; compile方式依赖的库会被打包进项目Jar包的lib目录下; provided: 表示该maven项目在 编译 / 测试 阶段都需要依赖这个jar包, 但在运行阶段是可以由容器(Container)来提供的, 而不必由该项目提供此Jar包;provided相当于compile, 是在打包阶段做了exclude的动作; 例如一个Web应用, 在编译时可能需要 Servlet API来编译一个Servlet, 但是你不会想要在打包好的WAR中包含这个Servlet API, 这个Servlet API JAR 应该由应用服务器或者Servlet容器提供; provided方式依赖的库并不是传递性的; provided方式依赖的库也不会被打包进项目Jar包的lib目录下; runtime: 在编译时不需要依赖此Jar包, 但在 运行 / 测试 的时候需要.例如JDBC驱动可以使用runtime, 因为只有在真正运行的时候才会调用到JDBC驱动的代码; test: 表示该dependency的Jar包只在单元测试时会\b依赖到, 不会打包进项目, 不会在运行期被依赖到, 典型的比如junit; system: 类似provided, \b不会被打包进项目, 在编译时maven不会从默认的repository寻找Jar包, 而是从本地目录加载依赖的Jar包.使用system需要通过&lt;systemPath&gt;指定该依赖包在本地的路径; import: Maven 2.0.9 之后新增; FAQ Why maven is downloading metadata every time? Maven – Always download sources and javadocs what’s the difference between -DskipTests and -Dmaven.test.skip=true","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"},{"name":"Maven","slug":"Maven","permalink":"https://beefyheisenberg.github.io/tags/Maven/"},{"name":"Gradle","slug":"Gradle","permalink":"https://beefyheisenberg.github.io/tags/Gradle/"},{"name":"构建工具","slug":"构建工具","permalink":"https://beefyheisenberg.github.io/tags/构建工具/"}]},{"title":"Tomcat","slug":"13.JavaEE-Framework/JavaEE.Tomcat","date":"2024-01-24T01:27:52.282Z","updated":"2024-01-24T01:27:52.284Z","comments":true,"path":"13.JavaEE-Framework/JavaEE.Tomcat/","link":"","permalink":"https://beefyheisenberg.github.io/13.JavaEE-Framework/JavaEE.Tomcat/","excerpt":"为什么 Java Web 开发需要 TomcatJavaEE、Servlet、Java Web 的概念： Java EE（Java Platform Enterprise Edition，2018 年 3 月更名为Jakarta EE）是一些列（Java 企业级开发）标准集合； Servlet 是 Java EE 众多标准下的一个 （link JavaEE.Servlet），主要定义了进行 Java Web 开发的规范（Request、Response 对象、servlet 生命周期） 一个典型的 Servlet 工作模式：","text":"为什么 Java Web 开发需要 TomcatJavaEE、Servlet、Java Web 的概念： Java EE（Java Platform Enterprise Edition，2018 年 3 月更名为Jakarta EE）是一些列（Java 企业级开发）标准集合； Servlet 是 Java EE 众多标准下的一个 （link JavaEE.Servlet），主要定义了进行 Java Web 开发的规范（Request、Response 对象、servlet 生命周期） 一个典型的 Servlet 工作模式： 创建并填充 Request 对象，包括：URI、参数、method、请求头信息、请求体信息等 创建 Response 对象 执行业务逻辑，将结果通过 Response 的输出流输出到客户端 所以 Servlet 定义了众多规范：Request &amp; Response 对象、Servlet 生命周期（init &amp; service &amp; destory 方法）…但 Servlet 没有 main 方法，需要在一个 Servlet 容器里面才能执行，Servlet 容器按照上述规范调用 Servlet 的方法，Tomcat 即是一个 Servlet 容器，在下面 Tomcat 源码分析可以看到 Tomcat 是如何使用 Servlet 规范处理一个 Http 请求的： Tomcat 接到 Http 请求后，使用 Poller 线程来处理这个请求的 socket，在 Poller 线程没有太多的处理，只是确认收包完整，然后把请求丢给 executor（工作线程池）； 在工作线程，把 Socket 读取到的数据，按照 Http 协议进行解析，并生成 Request 对象（这里也是按照 Servlet Request 的标准），并最终调用了 Servlet.service() Tomcat 的一个 Context 对应一个 ServletContext，一个 Context 下有 1 个 or 多个 Servlet 实现 回答最开是问题，为什么 Java Web 开发需要 Tomcat？Java Web 一般要遵循 Servlet 规范，Tomcat 是一个 Servlet 容器的实现，所以~ Java Web 开发需要 Tomcat。那么开发 Java Web 可以摆脱 Servlet 吗？也可以不用，比如 Spring 5 支持的 WebFlux framework Is it possible to create a Java web application without servlets? - Quora Tomcat 整体架构 Tomcat 的架构如上图，主要的组件如下： Server: 表示服务器，它提供了一种优雅的方式来启动和停止整个系统，不必单独启停连接器和容器；它是 Tomcat 构成的顶级构成元素，所有一切均包含在 Server 中； Service: 表示服务，Server 可以运行多个服务。比如一个 Tomcat 里面可运行订单服务、支付服务、用户服务等等；Server 的实现类 StandardServer 可以包含一个到多个 Services, Service 的实现类为 StandardService 调用了容器(Container)接口，其实是调用了 Servlet Engine(引擎)，而且 StandardService 类中也指明了该 Service 归属的 Server; Container: 表示容器，可以看做 Servlet 容器；引擎(Engine)、主机(Host)、上下文(Context)和 Wraper 均继承自 Container 接口，所以它们都是容器。 Engine – 引擎 Host – 主机 Context – 上下文 Wrapper – 包装器 Connector: 表示连接器, 它将 Service 和 Container 连接起来，首先它需要注册到一个 Service，它的作用就是把来自客户端的请求转发到 Container(容器)，这就是它为什么称作连接器, 它支持的协议如下： 支持 AJP 协议 支持 Http 协议 支持 Https 协议 Service 内部还有各种支撑组件，下面简单罗列一下这些组件 Manager – 管理器，用于管理会话 Session Logger – 日志器，用于管理日志 Loader – 加载器，和类加载有关，只会开放给 Context 所使用 Pipeline – 管道组件，配合 Valve 实现过滤器功能 Valve – 阀门组件，配合 Pipeline 实现过滤器功能 Realm – 认证授权组件 在下面讲解配置文件的时候可以看到，server.xml 里的元素，与上面的组件一一对应。 本节参考 @ref： https://pdai.tech/md/framework/tomcat/tomcat-x-arch.html 配置文件 server.xml一个配置文件实例:&lt;Server port=\"8005\" shutdown=\"SHUTDOWN\"&gt; &lt;Listener className=\"org.apache.catalina.startup.VersionLoggerListener\" /&gt; &lt;Listener className=\"org.apache.catalina.core.AprLifecycleListener\" SSLEngine=\"on\" /&gt; &lt;Listener className=\"org.apache.catalina.core.JasperListener\" /&gt; &lt;Listener className=\"org.apache.catalina.core.JreMemoryLeakPreventionListener\" /&gt; &lt;Listener className=\"org.apache.catalina.mbeans.GlobalResourcesLifecycleListener\" /&gt; &lt;Listener className=\"org.apache.catalina.core.ThreadLocalLeakPreventionListener\" /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name=\"UserDatabase\" auth=\"Container\" type=\"org.apache.catalina.UserDatabase\" description=\"User database that can be updated and saved\" factory=\"org.apache.catalina.users.MemoryUserDatabaseFactory\" pathname=\"conf/tomcat-users.xml\" /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name=\"Catalina\"&gt; &lt;Connector port=\"8080\" protocol=\"HTTP/1.1\" connectionTimeout=\"20000\" redirectPort=\"8443\" /&gt; &lt;Connector port=\"8009\" protocol=\"AJP/1.3\" redirectPort=\"8443\" /&gt; &lt;Engine name=\"Catalina\" defaultHost=\"localhost\"&gt; &lt;Realm className=\"org.apache.catalina.realm.LockOutRealm\"&gt; &lt;Realm className=\"org.apache.catalina.realm.UserDatabaseRealm\" resourceName=\"UserDatabase\"/&gt; &lt;/Realm&gt; &lt;Host name=\"localhost\" appBase=\"webapps\" unpackWARs=\"true\" autoDeploy=\"true\"&gt; &lt;Valve className=\"org.apache.catalina.valves.AccessLogValve\" directory=\"logs\" prefix=\"localhost_access_log.\" suffix=\".txt\" pattern=\"%h %l %u %t &amp;quot;%r&amp;quot; %s %b\" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; server.xml 配置元素分类整体结构server.xml 的整体结构如下：&lt;Server&gt; &lt;Service&gt; &lt;Connector /&gt; &lt;Connector /&gt; &lt;Engine&gt; &lt;Host&gt; &lt;Context /&gt; &lt;Context /&gt; &lt;!-- 现在常常使用自动部署，不推荐配Context --&gt; &lt;!-- Context表示一个War应用 --&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; 该结构中只给出了 Tomcat 的核心组件，除了核心组件外，Tomcat 还有一些其他组件，下面介绍一下组件的分类。 元素分类server.xml 文件中的元素可以分为以下 4 类： （1）顶层元素：&lt;Server&gt; 和 &lt;Service&gt; &lt;Server&gt; 元素是整个配置文件的根元素，&lt;Service&gt; 元素则代表一个 Engine 元素以及一组与之相连的 Connector 元素。 （2）连接器：&lt;Connector&gt; &lt;Connector&gt; 代表了外部客户端发送请求到特定 Service 的接口；同时也是外部客户端从特定 Service 接收响应的接口。 （3）容器：&lt;Engine&gt; &lt;Host&gt; &lt;Context&gt; 容器的功能是处理 Connector 接收进来的请求，并产生相应的响应。Engine、Host 和 Context 都是容器，都实现了 Container 接口，但它们不是平行的关系，而是父子关系：Engine 包含 Host，Host 包含 Context。 Engine 表示一个 Servlet 引擎，它可以包含一个或多个子容器，比如 Host 或者 Context 容器； Host 表示一台虚拟的主机，它可以包含一系列 Context 容器； Context 表示一个唯一的 ServletContext，一个 Context 对应一个 Web 工程，它可以包含一个或多个 Wrapper 容器； Wrapper 表示一个独立的 Servlet 定义，即 Wrapper 本质就是对 Servlet 进行了一层包装。 一个 Engine 组件可以处理 Service 中的所有请求，一个 Host 组件可以处理发向一个特定虚拟主机的所有请求，一个 Context 组件可以处理一个特定 Web 应用的所有请求。 （4）内嵌组件： 可以内嵌到容器中的组件。实际上，Server、Service、Connector、Engine、Host 和 Context 是最重要的最核心的 Tomcat 组件，其他组件都可以归为内嵌组件。 下面将详细介绍 Tomcat 中各个核心组件的作用，以及相互之间的关系。 核心组件本部分将分别介绍各个核心组件的作用、特点以及配置方式等。 ServerServer 元素在最顶层，代表整个 Tomcat 容器，因此它必须是 server.xml 中唯一一个最外层的元素。一个 Server 元素中可以有一个或多个 Service 元素。 在第一部分的例子中，在最外层有一个 &lt;Server&gt; 元素，shutdown 属性表示关闭 Server 的指令；port 属性表示 Server 接收 shutdown 指令的端口号，设为-1可以禁掉该端口。 Server 的主要任务，就是提供一个接口让客户端能够访问到这个 Service 集合，同时维护它所包含的所有的 Service 的声明周期，包括如何初始化、如何结束服务、如何找到客户端要访问的 Service。 ServiceService 的作用，是在 Connector 和 Engine 外面包了一层，把它们组装在一起，对外提供服务。一个 Service 可以包含多个 Connector，但是只能包含一个 Engine；其中 Connector 的作用是从客户端接收请求，Engine 的作用是处理接收进来的请求。 在第一部分的例子中，Server 中包含一个名称为“Catalina”的 Service。实际上，Tomcat 可以提供多个 Service，不同的 Service 监听不同的端口，后文会有介绍。 ConnectorConnector 的主要功能，是接收连接请求，创建 Request 和 Response 对象用于和请求端交换数据；然后分配线程让 Engine 来处理这个请求，并把产生的 Request 和 Response 对象传给 Engine。 通过配置 Connector，可以控制请求 Service 的协议及端口号。在第一部分的例子中，Service 包含两个 Connector： &lt;Connector port=\"8080\" protocol=\"HTTP/1.1\" connectionTimeout=\"20000\" redirectPort=\"8443\" /&gt;&lt;Connector port=\"8009\" protocol=\"AJP/1.3\" redirectPort=\"8443\" /&gt; （1）通过配置第 1 个 Connector，客户端可以通过 8080 端口号使用 http 协议访问 Tomcat。其中，protocol 属性规定了请求的协议，port 规定了请求的端口号，redirectPort 表示当强制要求 https 而请求是 http 时，重定向至端口号为 8443 的 Connector，connectionTimeout 表示连接的超时时间。 （2）通过配置第 2 个 Connector，客户端可以通过 8009 端口号使用 AJP 协议访问 Tomcat。AJP 协议负责和其他的 HTTP 服务器(如 Apache)建立连接；在把 Tomcat 与其他 HTTP 服务器集成时，就需要用到这个连接器。之所以使用 Tomcat 和其他服务器集成，是因为 Tomcat 可以用作 Servlet/JSP 容器，但是对静态资源的处理速度较慢，不如 Apache 和 IIS 等 HTTP 服务器；因此常常将 Tomcat 与 Apache 等集成，前者作 Servlet 容器，后者处理静态资源，而 AJP 协议便负责 Tomcat 和 Apache 的连接。Tomcat 与 Apache 等集成的原理如下图(图片来源)： EngineEngine 组件在 Service 组件中有且只有一个；Engine 是 Service 组件中的请求处理组件。Engine 组件从一个或多个 Connector 中接收请求并处理，并将完成的响应返回给 Connector，最终传递给客户端。 在第一部分的例子中，Engine 的配置语句如下： &lt;Engine name=\"Catalina\" defaultHost=\"localhost\"&gt; 其中，name 属性用于日志和错误信息，在整个 Server 中应该唯一。defaultHost 属性指定了默认的 host 名称，当发往本机的请求指定的 host 名称不存在时，一律使用 defaultHost 指定的 host 进行处理；因此，defaultHost 的值，必须与 Engine 中的一个 Host 组件的 name 属性值匹配。 HostEngine 与 HostHost 是 Engine 的子容器。Engine 组件中可以内嵌 1 个或多个 Host 组件，每个 Host 组件代表 Engine 中的一个虚拟主机。Host 组件至少有一个，且其中一个的 name 必须与 Engine 组件的 defaultHost 属性相匹配。 Host 的作用Host 虚拟主机的作用，是运行多个 Web 应用（一个 Context 代表一个 Web 应用），并负责安装、展开、启动和结束每个 Web 应用。 Host 组件代表的虚拟主机，对应了服务器中一个网络名实体(如” www.test.com ”，或 IP 地址”116.25.25.25”)；为了使用户可以通过网络名连接 Tomcat 服务器，这个名字应该在 DNS 服务器上注册。 Host 的配置在第一部分的例子中，Host 的配置如下： &lt;Host name=\"localhost\" appBase=\"webapps\" unpackWARs=\"true\" autoDeploy=\"true\"&gt; 下面对其中配置的属性进行说明： name 属性指定虚拟主机的主机名，一个 Engine 中有且仅有一个 Host 组件的 name 属性与 Engine 组件的 defaultHost 属性相匹配；一般情况下，主机名需要是在 DNS 服务器中注册的网络名，但是 Engine 指定的 defaultHost 不需要，原因在前面已经说明。 unpackWARs 指定了是否将代表 Web 应用的 WAR 文件解压；如果为 true，通过解压后的文件结构运行该 Web 应用，如果为 false，直接使用 WAR 文件运行 Web 应用。 Host 的 autoDeploy 和 appBase 属性，与 Host 内 Web 应用的自动部署有关；此外，本例中没有出现的 xmlBase 和 deployOnStartup 属性，也与 Web 应用的自动部署有关；将在下一节(Context)中介绍。 ContextContext 的作用Context 元素代表在特定虚拟主机上运行的一个 Web 应用。每个 Web 应用基于 WAR 文件，或 WAR 文件解压后对应的目录（这里称为应用目录）。 Context 是 Host 的子容器，每个 Host 中可以定义任意多的 Context 元素。 在第一部分的例子中，可以看到 server.xml 配置文件中并没有出现 Context 元素的配置。这是因为，Tomcat 开启了自动部署，Web 应用没有在 server.xml 中配置静态部署，而是由 Tomcat 通过特定的规则自动部署。下面介绍一下 Tomcat 自动部署 Web 应用的机制。 Web 应用自动部署如何开启自动部署 War: &lt;Host name=\"localhost\" appBase=\"webapps\" unpackWARs=\"true\" autoDeploy=\"true\"&gt; 此外 Context 组件还有一个 reloadable 属性, &lt;Context docBase=&quot;xxx&quot; path=&quot;/xxx&quot; reloadable=&quot;true&quot;/&gt;替换 WEB-INF/lib 目录中的 jar 文件或 WEB-INF/classes 目录中的 class 文件时，reloadable=”true”会让修改生效（但代价不小），该选项适合调试。 autoDeploy 和 reloadable 的区别是, 前者是 Host 的属性后者是 Context 的属性,前者监控的是 webapps 目录下 War 包的改动, 后者监控的是 webapps 下面文件夹内 jar 或者 class 文件的变化; 一般线上环境会关闭这两个参数, 开发阶段可以通过这两个参数无需重启 tomcat 预览改变; 自动部署的实现 Tomcat 的 Engine 会启动一个线程，该线程每 10s 会发送一个发送一个事件，监听到该事件的部署配置类, 会自动去扫描 webapp 文件夹下的 war 包，将其加载成一个 Context，即启动一个 web 服务。 Tomcat 的 StandardEngine 会在 starInternal() 启动一个线程，该线程运行的是 ContainerBackgroundProcessor.run() 方法,这个 run 每隔10s 唤醒调用一次 processChildren(), 继续跟踪该方法，会看到调用其子容器 Engine、Host、Context、Wrapper 各容器组件及与它们相关的其它组件的 backgroundProcess 方法。backgroundProcess() 发送一个事件 Lifecycle.PERIODIC_EVENT,StandardHost 通 server.xml 配置了 HostConfig 监听器，对该事件的响应方法是 HostConfig.lifecycleEvent(),lifecycleEvent() 会检查 autoDeploy=&quot;true&quot; 的配置, 如果开启了, 则调用 deployApps() 扫描 webapp 文件夹下的 war 包，将其加载成一个 Context，即启动一个 web 服务。 核心组件的关联整体关系核心组件之间的整体关系，在上一部分有所介绍，这里总结一下： Server 元素在最顶层，代表整个 Tomcat 容器；一个 Server 元素中可以有一个或多个 Service 元素。Service 在 Connector 和 Engine 外面包了一层，把它们组装在一起，对外提供服务。一个 Service 可以包含多个 Connector，但是只能包含一个 Engine； Connector 接收请求，Engine 处理请求。Engine、Host 和 Context 都是容器，且 Engine 包含 Host，Host 包含 Context。每个 Host 组件代表 Engine 中的一个虚拟主机；每个 Context 组件代表在特定 Host 上运行的一个 Web 应用。 如何确定请求由谁处理？当请求被发送到 Tomcat 所在的主机时，如何确定最终哪个 Web 应用来处理该请求呢？ （1）根据协议和端口号选定 Service 和 Engine Service 中的 Connector 组件可以接收特定端口的请求，当请求进来时，Tomcat 便可以根据协议和端口号选定处理请求的 Service；Service 一旦选定，Engine 也就确定。 （2）根据域名或 IP 地址选定 Host Service 确定后，Tomcat 在 Service 中寻找名称与域名/IP 地址匹配的 Host 处理该请求。如果没有找到，则使用 Engine 中指定的 defaultHost 来处理该请求。 （3）根据 URI 选定 Context/Web 应用 这一点在 Context 一节有详细的说明：Tomcat 根据应用的 path 属性与 URI 的匹配程度来选择 Web 应用处理相应请求，这里不再赘述。 （4）举例 以请求 http://localhost:8080/app1/index.html为例 ，首先通过协议和端口号（http 和 8080）选定 Service；然后通过主机名（localhost）选定 Host；然后通过 uri（/app1/index.html）选定 Web 应用。 如何部署多个 war 包项目@todo 其他组件ListenerListener(即监听器)定义的组件，可以在特定事件发生时执行特定的操作；被监听的事件通常是 Tomcat 的启动和停止。监听器可以在 Server、Engine、Host 或 Context 中，本例中的监听器都是在 Server 中。实际上，本例中定义的 6 个监听器，都只能存在于 Server 组件中。监听器不允许内嵌其他组件。监听器需要配置的最重要的属性是 className，该属性规定了监听器的具体实现类，该类必须实现了 org.apache.catalina.LifecycleListener 接口。 GlobalNamingResources 与 Realm@todo Valve在第一部分的例子中，Host 元素内定义了 Valve 组件： &lt;Valve className=\"org.apache.catalina.valves.AccessLogValve\" directory=\"logs\" prefix=\"localhost_access_log.\" suffix=\".txt\" pattern=\"%h %l %u %t &amp;quot;%r&amp;quot; %s %b\" /&gt; 单词 Valve 的意思是“阀门”，在 Tomcat 中代表了请求处理流水线上的一个组件；Valve 可以与 Tomcat 的容器(Engine、Host 或 Context)关联。不同的 Valve 有不同的特性，下面介绍一下本例中出现的 AccessLogValve。AccessLogValve 的作用是通过日志记录其所在的容器中处理的所有请求，在本例中，Valve 放在 Host 下，便可以记录该 Host 处理的所有请求。AccessLogValve 记录的日志就是访问日志，每天的请求会写到一个日志文件里。AccessLogValve 可以与 Engine、Host 或 Context 关联；在本例中，只有一个 Engine，Engine 下只有一个 Host，Host 下只有一个 Context，因此 AccessLogValve 放在三个容器下的作用其实是类似的。 性能优化bin/catalina.sh这里主要是对 JVM 参数的设置，主要修改 Xms, Xmx, PermSize 几个参数： JAVA_OPTS=\"-Xms8g -Xmx8g -Xmn2g -server -DServer=mblog -XX:PermSize=128m -XX:MaxPermSize=128m -XX:MaxTenuringThreshold=4 -XX:+UseConcMarkSweepGC -XX:SurvivorRatio=8 -XX:CMSInitiatingOccupancyFraction=70 -XX:+ExplicitGCInvokesConcurrent -XX:+PrintFlagsFinal -XX:+PrintCommandLineFlags -XX:+PrintGCDateStamps -XX:+PrintTenuringDistribution -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintGCApplicationConcurrentTime -Xloggc:../gclogs/gc.log.$nowday\" conf/server.xml这里主要是对 Connector 和线程池的设置 主要优化点 @tldr： maxThreads = 业务线程池大小，一般几百~几 K，如果并发到来的请求数超过 maxThreads，再新来的请求不能被及时处理； maxConnections：意思是 Tomcat 维护的已建立连接数上限。当连接数达到 maxConnections，Tomcat 不会再 accept，而是直接 block 掉（这时候系统仍然能 accept，但 Tomcat 不会把新连接扔给 Poller 线程了，而是 block 掉新的连接），maxConnections 在 NIO 模式默认是 1W； acceptCount：如果所有的业务线程都在忙（ all possible request processing threads are in use），即并发处理中的请求数超过了 maxThreads。这时候新请会放入 accept 队列（区别 socket 的 accept），acceptCount 即是这个队列的长度，默认 100； 区分连接数 &amp; 请求数： 连接数：建立并监听读写事件的 Connection 数量，大部分 Connection 都是空闲的，少数有读写 请求数：指客户端发 Http Request 过来，Tomcat 会把 Request 放入业务线程池处理 maxConnections 决定连接数上限；acceptCount + maxThread 决定并发请求的上限； 用 ASCIIFlow 画图解释： 新连接到来：[Acceptor] ────────────► [Poller] ──线程池是否满？────NO─────► [业务线程池]&lt;maxThreads limits&gt; &lt;maxConnections limits&gt; │ ▲ Yes │ │ │ ┴───►[accept queue]──┴ &lt;acceptCount limits&gt;图示：[ ] 表示对象实体&lt; &gt; 表示限制 这几个参数容易混淆，如果搞清楚 Tomcat 的 NIO 线程模型，就不难理解了 Tomcat 采用 Request Per Thread 策略, 每个用户请求由一个线程处理, &lt;Executor&gt; 部分定义了该线程池, 该线程池被多个 &lt;Connector&gt; 共享, server.xml 里的优化主要在 &lt;Connector&gt;: &lt;Executor className=\"org.apache.catalina.core.StandardThreadExecutor\" name=\"tomcatThreadPool\" namePrefix=\"catalina-exec\" maxThreads=\"300\" minSpareThreads=\"50\"/&gt;&lt;!-- 指定使用上面的线程池 --&gt;&lt;Connector executor=\"tomcatThreadPool\" port=\"8080\" protocol=\"HTTP/1.1\" connectionTimeout=\"8000\" enableLookups=\"false\" acceptCount=\"300\" maxThreads=\"300\" acceptorThreadCount=\"1\" URIEncoding=\"utf-8\" redirectPort=\"443\" compression=\"on\" compressionMinSize=\"1024\" compressableMimeType=\"text/html,text/xml,text/javascript,text/css,text/plain,application/json,application/xml\" /&gt; 参数说明： Executor 参数 maxThreads: 线程池最大线程数 minSpareThreads: 线程池最小线程数(线程池初始化时), 默认 25 Connector 参数: executor: 指明使用哪一个 Executor, 如果指定了,那么 Connector 中所有关于线程的设定会被忽略, 如果没有指定一个线程池, Connector 将会创建一个私有的线程池. maxThreads: 用于处理客户端请求的最大线程数, 设置为多少视 CPU 处理能力而定, 一般单个应用不应该超过 300, 如果超过 300 应考虑多个 Tomcat 组成集群方式 enableLookups: 是否开启域名反查，一般设置为 false 来提高处理能力，它的取值还有 true，一般很少使用。若设为 true, 则支持域名解析，可把 ip 地址解析为主机名 connectionTimeout: 网络连接超时，单位：毫秒。设置为 0 表示永不超时 acceptorThreadCount: 默认为 1，表示用于 accept 新 socket 连接的线程个数。一般跟监听端口数匹配。 acceptCount: 当全部线程都在忙(意味着客户端并发数超过 maxThreads 个线程), 新的请求会放入 accept 队列, 该值是队列的 size, 默认 100 maxConnections: Tomcat 的最大连接数, 如果连接数超过 maxConnections, tomcat 将不再 accept 新的连接而是拒绝, For NIO and NIO2 the default is 10000. For APR/native, the default is 8192. compressionMinSize: 大于这个数值讲开启压缩, 默认为 2K compressableMimeType: 压缩哪些类型 protocol：协议类型，可选类型有四种，分别为 BIO（阻塞型 IO），NIO，NIO2 和 APR。 BIO：BIO(Blocking I/O)，顾名思义，即阻塞式 I/O 操作，表示 Tomcat 使用的是传统的 Java I/O 操作(即 java.io 包及其子包)。Tomcat 在默认情况下，是以 bio 模式运行的。遗憾的是，就一般而言，bio 模式是三种运行模式中性能最低的一种。BIO 配置采用默认即可。 NIO：NIO(New I/O)，是 Java SE 1.4及后续版本提供的一种新的 I/O 操作方式(即 java.nio 包及其子包)。Java nio 是一个基于缓冲区、并能提供非阻塞 I/O 操作的 Java API，因此 nio 也被看成是 non-blocking I/O 的缩写。它拥有比传统 I/O 操作(bio)更好的并发运行性能。要让 Tomcat 以 nio 模式来运行也比较简单，我们只需要 protocol 类型修改为：protocol=&quot;org.apache.coyote.http11.Http11NioProtocol&quot;对于互联网应用，我们应该在 NIO、NIO2 之间做选择，因为它能够有效的提升性能（主要是并发能力），其中 NIO2 即为 AIO，需要 JDK 1.7+、Linux 2.6+才能支持。 NIO：JDK 1.6+，tomcat 6.x+ NIO2：JDK 1.7+，tomcat 7.x+ APR: 通过 Native 实现的 I/O 库, Tomcat 通过 JNI 调用; // Tomcat 支持的几种protocol://NIOprotocol=&quot;org.apache.coyote.http11.Http11NioProtocol&quot;//NIO2protocol=&quot;org.apache.coyote.http11.Http11Nio2Protocol&quot;//ARPprotocol=&quot;org.apache.coyote.http11.Http11AprProtocol&quot; @ref: 聊下并发和Tomcat线程数（Updated） - zhanjindong - 博客园 tomcat 源码为啥不采用netty 处理并发？ - 知乎 附: Connector 和线程池参数解析 &lt;Executor&gt; 部分, 参数说明: https://tomcat.apache.org/tomcat-8.5-doc/config/executor.html namePrefix: The name prefix for each thread created by the executor maxThreads: The max number of active threads in this pool, default is 200 minSpareThreads: The minimum number of threads (idle and active) always kept alive, default is 25 maxIdleTime: The number of milliseconds before an idle thread shutsdown, unless the number of active threads are less or equal to minSpareThreads. Default value is 60000(1 minute) maxQueueSize: The maximum number of runnable tasks that can queue up awaiting execution before we reject them. Default value is Integer.MAX_VALUE &lt;Connector&gt; 部分, https://tomcat.apache.org/tomcat-8.5-doc/config/http.html executor: A reference to the name in an Executor element. If this attribute is set, and the named executor exists, the connector will use the executor, and all the other thread attributes will be ignored. Note that if a shared executor is not specified for a connector then the connector will use a private, internal executor to provide the thread pool. acceptCount: The maximum queue length for incoming connection requests when all possible request processing threads are in use. Any requests received when the queue is full will be refused. The default value is 100. connectionTimeout: The number of milliseconds this Connector will wait, after accepting a connection, for the request URI line to be presented. Use a value of -1 to indicate no (i.e. infinite) timeout. The default value is 60000 (i.e. 60 seconds) but note that the standard server.xml that ships with Tomcat sets this to 20000 (i.e. 20 seconds). Unless disableUploadTimeout is set to false, this timeout will also be used when reading the request body (if any). maxThreads: The maximum number of request processing threads to be created by this Connector, which therefore determines the maximum number of simultaneous requests that can be handled. If not specified, this attribute is set to 200. If an executor is associated with this connector, this attribute is ignored as the connector will execute tasks using the executor rather than an internal thread pool. Note that if an executor is configured any value set for this attribute will be recorded correctly but it will be reported (e.g. via JMX) as -1 to make clear that it is not used. acceptorThreadCount: The number of threads to be used to accept connections. Increase this value on a multi CPU machine, although you would never really need more than 2. Also, with a lot of non keep alive connections, you might want to increase this value as well. Default value is 1. maxConnections: The maximum number of connections that the server will accept and process at any given time. When this number has been reached, the server will accept, but not process, one further connection. This additional connection be blocked until the number of connections being processed falls below maxConnections at which point the server will start accepting and processing new connections again. Note that once the limit has been reached, the operating system may still accept connections based on the acceptCount setting. The default value varies by connector type. For NIO and NIO2 the default is 10000. For APR/native, the default is 8192.Note that for APR/native on Windows, the configured value will be reduced to the highest multiple of 1024 that is less than or equal to maxConnections. This is done for performance reasons. Tomcat 在 NIO 模式下的线程模型Tomcat 使用 Connector 完成整个 HTTP Request 的处理流程, 包括 accept socket → NIO Selector 处理 socket 读事件 → 把可读 Socket 分发给 Work 线程 → 从 socket 读取数据并解析为 Http 请求 → Http 请求交给 CoyoteAdaper 处理, CoyoteAdaper 通过 Mapper 找到对应的 Servlet. 在 NIO 实现的 Connector 中，处理请求的主要实体是 NIoEndpoint 对象。NIoEndpoint 中除了包含 Acceptor 和 Worker 外，还是用了 Poller，处理流程如下图所示: Acceptor accept 客户端请求, 这里虽然是基于 NIO 的 connector，但是在接收 socket 方面还是传统的 serverSocket.accept() 方式, Acceptor 获取到客户端请求的 socket, 封装进 tomcat 的实现类 org.apache.tomcat.util.net.NioChannel 对象中, 然后将 NioChannel 对象封装在一个 PollerEvent 对象中，并将 PollerEvent 对象压入 events queue Poller 读取 events queue 取出 PollerEvent, Poller 线程中维护了一个 Selector 对象, Poller 从 Event 中取出客户端请求的 socketChannel, 把这个 channel 的 READ 事件注册到 Selector 上. Poller 通过 Selector.select() 遍历可读的 socketChannel, 从 Worker 线程池中拿到可用的 Worker 线程,将 socket 传递给 Worker 处理 Worker 线程将 socket 封装在 SocketProcessor 对象中。然后从 Http11ConnectionHandler 中取出 Http11NioProcessor 对象，从 Http11NioProcessor 中调用 CoyoteAdapter 的逻辑 本节参考:https://my.oschina.net/weiweiblog/blog/1830173https://www.jianshu.com/p/f91f99610b9e APR 支持APR(Apache Portable Runtime)可移植运行库，它是 Apache HTTP Server 2.x 的核心。APR 有很多用途，包括访问高级 IO 功能(例如 sendfile,epoll 和 OpenSSL)，OS 级别功能(随机数生成，系统状态等等)，本地进程管理(共享内存，NT 管道和 UNIX sockets)。这些功能可以使 Tomcat 作为一个通常的前台 WEB 服务器（类似 Nginx，只转发请求，不做业务），能更好地和其它本地 web 技术集成，总体上让 Java 更有效率作为一个高性能 web 服务器平台而不是简单作为后台业务容器。 可以简单地理解为: Tomcat 将以 JNI 的形式调用 APR 库中的 Native Method 处理文件读取或网络传输操作，提升 Tomcat 对静态文件等等的处理性能，APR 模式下的 Tomcat 更像是 Nginx 的角色。 安装步骤: 下载 APR, 编译 make &amp;&amp; make install 安装 Tomcat Native 到 Tomcat 的安装目录下 修改 conf/server.xml, 修改 &lt;Connector&gt; 的 protocol 日志参考: 日志机制 - Tomcat 8 权威指南 - 极客学院Wiki 在 Apache Tomcat 上运行的 Web 应用可以使用以下日志： 任何自选的日志框架，如 log4j； 使用 JDK 提供的日志 java.util.logging； Java Servlets 规范所提供的日志 API，如 javax.servlet.ServletContext.log(...)； 当 tomcat 启动时会为每个 app 分配了一个 WebappClassLoader ，这样来避免多个 app 会加载相同 jar 包的问题，不同 Web 应用程序下使用的 Servlet 日志（或者日志框架提供的日志，如 log4j 等）是相互独立的（这与 Tomcat 的 class loader 有关，参考 Class Loader HOW-TO ）。如果 Web 应用程序使用的是 java.util.logging 日志，那么它们并不相互独立，这是因为 java.util.logging 是由 JAVA 系统中的 Bootstrap ClassLoader 来加载的，因此它在各 Web 应用程序之间是共享的。 JULI vs JULJUL API（java.util.logging，日志实现，非日志门面）的默认实现功能有限，因此 tomcat 的默认配置中，新增了另一种日志实现 JULI API（org.apache.juli）， 可以在 Tomcat 的 logging.properties 里看到定义了两种日志:java.util.logging 的 java.util.logging.ConsoleHandler ;JULI 的 org.apache.juli.FileHandler ; JULI 同样支持标准 JDK java.util.logging 的配置机制（都默认使用 logging.properties 作为配置文件），不同的是 JULI 的每一个类加载属性文件都可以被设置，并可以在其中定义处理器，这样就给了开发者更大的自由度。JULI 的日志配置分为全局配置和 WebApp 项目配置。全局配置位于 tomcat 的配置目录 ${catalina.base}/conf/logging.properties 文件,如果该文件未配置或不可读，那么 tomcat 将会使用 JRE 中的默认日志配置，可以在 ${java.home}/lib/logging.properties 查看配置文件的内容；项目配置则是针对不同的项目，配置文件位于 WEB-INFO/classes/logging.properties. JUL 和 JULI 使用相同的日志级别：SEVERE (最高级别) &gt; WARNING &gt; INFO &gt; CONFIG &gt; FINE &gt; FINER &gt; FINEST (所有内容,最低级别) JULI 所使用的配置与 java.util.logging 所支持的配置基本相同，只不过使用了一些扩展，以便更灵活地配置 logger 和 handler。主要的差别在于： JULI 的 handler 名称前可以加上前缀，所以同一类可以实例化出多个 handler。前缀是一个以数字开头的字符串，并以 . 结尾。比如 22foobar. 就是个有效的前缀。 JULI 的 handler 支持额外的属性, 比如 bufferSize Tomcat 日志配置解析以下是一个 $CATALINA_BASE/conf 中的默认 logging.properties 文件： ## 声明所有的handlershandlers = 1catalina.org.apache.juli.FileHandler, 2localhost.org.apache.juli.FileHandler, 3manager.org.apache.juli.FileHandler, 4host-manager.org.apache.juli.FileHandler, java.util.logging.ConsoleHandler## RootLogger使用的handlers.handlers = 1catalina.org.apache.juli.FileHandler, java.util.logging.ConsoleHandler## 定义了4个 org.apache.juli.FileHandler : 1catalina, 2localhost, 3manager, 4host-manager1catalina.org.apache.juli.FileHandler.level = FINE1catalina.org.apache.juli.FileHandler.directory = $&#123;catalina.base&#125;/logs1catalina.org.apache.juli.FileHandler.prefix = catalina.1catalina.org.apache.juli.AsyncFileHandler.encoding = UTF-82localhost.org.apache.juli.FileHandler.level = FINE2localhost.org.apache.juli.FileHandler.directory = $&#123;catalina.base&#125;/logs2localhost.org.apache.juli.FileHandler.prefix = localhost.2localhost.org.apache.juli.AsyncFileHandler.encoding = UTF-83manager.org.apache.juli.FileHandler.level = FINE3manager.org.apache.juli.FileHandler.directory = $&#123;catalina.base&#125;/logs3manager.org.apache.juli.FileHandler.prefix = manager.3manager.org.apache.juli.FileHandler.bufferSize = 163843manager.org.apache.juli.AsyncFileHandler.encoding = UTF-84host-manager.org.apache.juli.FileHandler.level = FINE4host-manager.org.apache.juli.FileHandler.directory = $&#123;catalina.base&#125;/logs4host-manager.org.apache.juli.FileHandler.prefix = host-manager.4host-manager.org.apache.juli.AsyncFileHandler.encoding = UTF-8## 定义 ava.util.logging.ConsoleHandler :java.util.logging.ConsoleHandler.level = FINEjava.util.logging.ConsoleHandler.formatter = java.util.logging.SimpleFormatterjava.util.logging.ConsoleHandler.encoding = UTF-8## 定义handlers, 使用上面定义的 FileHandlerorg.apache.catalina.core.ContainerBase.[Catalina].[localhost].level = INFOorg.apache.catalina.core.ContainerBase.[Catalina].[localhost].handlers = 2localhost.org.apache.juli.FileHandlerorg.apache.catalina.core.ContainerBase.[Catalina].[localhost].[/manager].level = INFOorg.apache.catalina.core.ContainerBase.[Catalina].[localhost].[/manager].handlers = 3manager.org.apache.juli.FileHandlerorg.apache.catalina.core.ContainerBase.[Catalina].[localhost].[/host-manager].level = INFOorg.apache.catalina.core.ContainerBase.[Catalina].[localhost].[/host-manager].handlers = 4host-manager.org.apache.juli.FileHandler# For example, set the org.apache.catalina.util.LifecycleBase logger to log# each component that extends LifecycleBase changing state:#org.apache.catalina.util.LifecycleBase.level = FINE# To see debug messages in TldLocationsCache, uncomment the following line:#org.apache.jasper.compiler.TldLocationsCache.level = FINE java.util.logging.ConsoleHandler:When running Tomcat on unixes, the console output is usually redirected to the file named catalina.out.The name is configurable using an environment variable. (See the startup scripts).Whatever is written to System.err/out will be caught into that file. That may include: Uncaught exceptions printed by java.lang.ThreadGroup.uncaughtException(..) Thread dumps, if you requested them via a system signal java.util.logging.ConsoleHandler 是 java 自带的日志处理系统（JUL）的控制台日志 Handler,Tomcat 通过 System.err.println() / System.out.println() 打出的日志会通过 java.util.logging.ConsoleHandler 写入 Tomcat 进程的 stdout/stderr,并最终输出到文件”catalina.out”中, 这个文件名是在 Tomcat 启动脚本里定义的: org.apache.juli.FileHandler:org.apache.juli.FileHandler supports buffering of the logs.The buffering is not enabled by default. To configure it, use the bufferSize property of a handler.The value of 0 uses system default buffering (typically an 8K buffer will be used).A value of &lt; 0 forces a writer flush upon each log write.A value &gt; 0 uses a BufferedOutputStream with the defined value but note that the system default buffering will also be applied. org.apache.支持日志缓存。日志缓存默认是没有启用的。使用 handler 的 bufferSize 属性可以配置它：属性值为 0 时，代表使用系统默认的缓存（通常使用 8k 缓存）；属性值小于 0 时，将在每个日志写入上强制使用 writer flush（将缓存区中的数据强制写出到系统输出）功能；属性值大于 0 时，则使用带有定义值的 BufferedOutputStream 类——但要注意的是，这也将应用于系统默认的缓存。 WebApp 的日志配置解析下例是一个用于 servlet-examples 应用的 WEB-INF/classes 中的 logging.properties 文件 handlers = org.apache.juli.FileHandler############################################################# Handler specific properties.# Describes specific configuration info for Handlers.############################################################org.apache.juli.FileHandler.level = FINEorg.apache.juli.FileHandler.directory = $&#123;catalina.base&#125;/logsorg.apache.juli.FileHandler.prefix = $&#123;classloader.webappName&#125;. Tomcat 启动时报错 “SEVERE: Error listenerStart” 或者 “SEVERE: Error filterStart” 等, 但没有具体的错误日志:这种一般是因为 Tomcat WebAppClassLoader 加载的org.springframework类的日志没有关联一个 Handler,可以修改 webapps/xxx/WEB-INF/classes/logging.properties, Tomcat 就会在打印 org.springframework 类的详细的报错信息了.注意, 老的应用可能还在使用 System.out 或 System.err，这种情况下还需要在 web 应用的 classes/logging.properties 里增加 java.util.logging.ConsoleHandler: handlers = org.apache.juli.FileHandler, java.util.logging.ConsoleHandler## JULI.FileHandler 的设置...## JUL.ConsoleHandler 的设置java.util.logging.ConsoleHandler.level = FINEjava.util.logging.ConsoleHandler.formatter = java.util.logging.SimpleFormatter 对于还在使用 System.out 或 System.err 的应用:可以通过在 Context 元素上设置 swallowOutput 属性来调整。如该属性设为 true，那么在请求阶段对 System.out/err 的调用就会被拦截，它们的输出也会通过 javax.servlet.ServletContext.log(...) 调用反馈给日志系统。 日志文件 catalina.2017-08-29.log //Cataline 引擎的日志文件 localhost.2017-08-29.log //Tomcat 下内部代码抛出的日志 jsp 页面内部错误的异常 manager.2017-08-29.log //Tomcat 下默认 manager 应用日志 host-manager.2017-08-29.log //Tomcat 下默认 manager 应用日志 localhost_access_log.2017-08-29.txt //访问日志记录 catalina.out //控制台输出的日志,Linux 下默认重定向到 catalina.out 查看 catalina.sh, 最终启动 tomcat 执行的命令行是 java ${JAVA_OPTS} org.apache.catalina.startup.Bootstrap start 生产环境中的日志可能需要注意以下方面： 将 ConsoleHandler 从配置中移除。默认（ .handlers 设置）日志会使用 FileHandler 和 ConsoleHandler。后者的输出经常会被捕获到一个文件中，比如 catalina.out。从而导致同一消息可能生成了两个副本。 对于不使用的应用(比如 host-manager)，可以考虑将 FileHandlers 移除。 handler 默认使用系统缺省编码来写入日志文件，通过 encoding 属性可以修改设置，详情查看相关的 javadoc 文档。 增加 Access 访问日志。 使用 log4j参考 使用 Log4j @ref 如果只是想在自己的 Web 应用上使用 log4j 时 只需将 log4j.jar 和 log4j.properties 放到 Web 应用的 WEB-INF/lib 和 WEB-INF/classes 中即可 如果想配置 Tomcat 以便利用 log4j 来进行自身日志记录时，下面的步骤都是必需的: 创建一个包含下列配置的 log4j.properties 文件，将其保存到 $CATALINA_BASE/lib。Important! 下载 log4j 下载或构建 tomcat-juli.jar 和 tomcat-juli-adapters.jar，以便作为 Tomcat 的额外组件使用。 将 log4j.jar 和 tomcat-juli-adapters.jar 从 extras 中放入 $CATALINA_HOME/lib 中。 用 extras 中的 tomcat-juli.jar 替换 $CATALINA_HOME/bin/tomcat-juli.jar。 删除 $CATALINA_BASE/conf/logging.properties，以防止 java.util.logging 生成零长度的日志文件。 高级 IO推送: Comet 支持施工中 发送大型静态文件: sendfile施工中 How to deploy war有 3 中方式部署 war 包: 在 server.xml 的&lt;Host&gt;标签中声明&lt;Context&gt;标签 在 server.xml 的&lt;Host&gt;标签中开启 autoDeploy, 将 war 包放入 webapps 中会自动部署 context.xml 配置方式 Using the UI managerTomcat 提供了一个网页版的 Manager App, 默认位置在 webapps/manager, 也是一个 web 项目, 使用方式参考: Apache Tomcat 6.0 (6.0.53) - Manager App HOW-TO @ref Go to [&lt;protocol&gt;://]localhost:&lt;port&gt;/manager/html/ (usually localhost:8080/manager/html/),If you get:403 Access Denied go to %CATALINA_HOME%\\conf\\tomcat-users.xml and check that you have enabled a line like this:&lt;user username=&quot;tomcat&quot; password=&quot;tomcat&quot; roles=&quot;tomcat,role1,manager-gui&quot;/&gt; Using maven待补充… ClassLoader为什么 Tomcat 的 Web App ClassLoader 没有遵循 「双亲委派」？[[../12.Java/Advanced-Java.04.ClassLoader#Tomcat]] 翻译自: Apache Tomcat 7 (7.0.93) - Class Loader HOW-TO 与很多服务器应用一样，Tomcat 也安装了各种类加载器。借助类加载器，容器的不同部分以及运行在容器里的 Web Apps 就可以访问不同的仓库（保存着可使用的类和资源）。// 这里英文原文是”different repositories of available classes and resources.” 不知道该怎么翻译这里的”repositories” ? 在 Java 环境中，类加载器的布局结构是一种父子树的形式。通常，类加载器被请求加载一个特定的类或资源时，它会先把这一请求委托给它的父类加载器，只有（一个或多个）父类加载器无法找到请求的类或资源时，它才开始查看自身的仓库。 注意，Web 应用的类加载器模式跟这个稍有不同，下文将详细介绍，但基本原理是一样。 当 Tomcat 启动后，它就会创建一组类加载器，这些类加载器被布局成如下图所示这种父子关系，父类加载器在子类加载器之上： Bootstrap | System | Common / \\WebApp1 WebApp2 .. 如上图所示，Tomcat 在初始化时会创建如下这些类加载器： Bootstrap 这种类加载器包含 JVM 所提供的基本的运行时类，以及来自系统扩展目录（$JAVA_HOME/jre/lib/ext）里 JAR 文件中的类。注意：在有些 JVM 的实现中，它的作用不仅仅是类加载器，或者它可能根本不可见（作为类加载器）。 System 这种类加载器通常是根据 CLASSPATH 环境变量内容进行初始化的（也称为 App ClassLoader）。所有的这些类对于 Tomcat 内部类以及 Web 应用来说都是可见的。不过，标准的 Tomcat 启动脚本（$CATALINA_HOME/bin/catalina.sh 或 %CATALINA_HOME%\\bin\\catalina.bat）完全忽略了 CLASSPATH 环境变量自身的内容，相反从下列仓库来构建系统类加载器： $CATALINA_HOME/bin/bootstrap.jar 包含用来初始化 Tomcat 服务器的 main() 方法，以及它所依赖的类加载器实现类。 $CATALINA_BASE/bin/tomcat-juli.jar 或 $CATALINA_HOME/bin/tomcat-juli.jar 日志实现类。其中包括了对 java.util.logging API 的功能增强类（Tomcat JULI），以及对 Tomcat 内部使用的 Apache Commons 日志库的包重命名副本。详情参看 Tomcat 日志文档。如果 *$CATALINA_BASE/bin* 中存在 tomcat-juli.jar，就不会使用 $CATALINA_HOME/bin 中的那一个。它有助于日志的特定配置。 $CATALINA_HOME/bin/commons-daemon.jar Apache Commons Daemon 项目的类。该 JAR 文件并不存在于由 catalina.bat 或 catalina.sh 脚本所创建的 CLASSPATH 中，而是引用自 bootstrap.jar 的清单文件。 Common 这种类加载器包含更多的额外类，它们对于 Tomcat 内部类以及所有 Web 应用都是可见的。通常，应用类不会放在这里。该类加载器所搜索的位置定义在 $CATALINA_BASE/conf/catalina.properties 的 common.loader 属性中。默认的设置会搜索下列位置（按照列表中的上下顺序）。 $CATALINA_BASE/lib 中的解包的类和资源。 $CATALINA_BASE/lib 中的 JAR 文件。 $CATALINA_HOME/lib 中的解包类和资源。 $CATALINA_HOME/lib 中的 JAR 文件。 默认，它包含以下这些内容： annotations-api.jar JavaEE 注释类。 catalina.jar Tomcat 的 Catalina servlet 容器部分的实现。 jsp-api.jar JSP 2.3 API servlet-api.jar Servlet 3.1 API tomcat-api.jar Tomcat 定义的一些接口 tomcat-dbcp.jar 数据库连接池实现，基于 Apache Commons Pool 的包重命名副本和 Apache Commons DBCP。 tomcat-jdbc.jar 一个数据库连接池替代实现，又被称作 Tomcat JDBC 池。详情参看 JDBC 连接池文档。 … WebappX 为每个部署在单个 Tomcat 实例中的 Web 应用创建的类加载器。你的 Web 应用的 /WEB-INF/classes 目录中所有的解包类及资源，以及 /WEB-INF/lib 目录下 JAR 文件中的所有类及资源，对于该应用而言都是可见的，但对于其他应用来说则不可见。 如上所述，Web 应用类加载器背离了默认的 Java 委托模式（根据 Servlet 规范 2.4 版的 9.7.2 Web Application Classloader 一节中提供的建议）。当某个请求想从 Web 应用的 WebappX 类加载器中加载类时，该类加载器会先查看自己的仓库，而不是预先进行委托处理。JRE 基类的部分类不能被重写。对于一些类（比如 J2SE 1.4+ 的 XML 解析器组件），可以使用 J2SE 1.4 支持的特性。最后，类加载器会显式地忽略所有包含 Servlet API 类的 JAR 文件，所以不要在 Web 应用包含任何这样的 JAR 文件。Tomcat 其他的类加载器则遵循常用的委托模式。 因此，从 Web 应用的角度来看，加载类或资源时，要查看的仓库及其顺序如下： JVM 的 Bootstrap 类 Web 应用的 /WEB-INF/classes 类 Web 应用的 /WEB-INF/lib/*.jar 类，其中2和3 都是 WebApp Classloader加载的 System 类加载器的类（加载 CLASSPATH 下的类） Common 类加载器的类（加载 CATALINA_BASE 和 CATALINA_HOME 的lib下的类) 如果 Web 应用类加载器配置有 &lt;Loader delegate=&quot;true&quot;/&gt; ，则顺序变为： JVM 的 Bootstrap 类 System 类加载器的类（如上所述） Common 类加载器的类（如上所述） Web 应用的 /WEB-INF/classes 类 Web 应用的 /WEB-INF/lib/*.jar 类 源码导读 (Tomcat 8.5)编译ant cleanant 启动java -cp ./output/classes -Dcatalina.home=./output/build org.apache.catalina.startup.Bootstrap 启动过程源码调用时序Bootstrap.main // 入口方法 Bootstrap.init() initClassLoaders() // 初始化 commonLoader, catalinaLoader, sharedLoader commonLoader = createClassLoader(\"common\", null); ClassLoaderFactory.createClassLoader(repositories, parent); // 该方法通过 AccessController.doPrivileged 创建了 URLClassLoader, 并返回 catalinaLoader.loadClass(\"org.apache.catalina.startup.Catalina\")` // 创建 Catalina 对象 Bootstrap.load(args) Catalina.load() Digester digester = createStartDigester() // 为 digester 添加 Rule Digester.parse(inputSource) // 解析 server.xml !! Digester.startElement() Rule.begin() ObjectCreateRule.begin() // 这里通过反射调用了 Server &amp; Connector &amp; Context 等类的构造方法 org.apache.catalina.core.StandardServer.StandardServer() // Server 构造 org.apache.catalina.core.StandardService.StandardService() // Service 构造 ConnectorCreateRule.begin org.apache.catalina.connector.Connector.Connector() // Connector 构造, 根据配置中的 \"protocol\" 设置创建不同的创建 ProtocolHandler: Http11NioProtocol() // 默认的 ProtocolHandler AbstractHttp11Protocol(new NioEndpoint()) NioEndpoint() AbstractEndpoint() // 创建 worker 线程池 Bootstrap.start() Catalina.start() StandardServer.start() =&gt; LifecycleBase.start() StandardServer.startInternal() StandardService.start() =&gt; LifecycleBase.start() StandardService.startInternal() Engine.start() =&gt; LifecycleBase.start() // 启动 Engine StandardEngine.startInternal() ContainerBase.startInternal() StartChild.call() // 多线程启动, 线程数=Host 数量 StandardHost.start() =&gt; LifecycleBase.start() StandardHost.startInternal() ContainerBase.startInternal() =&gt; LifecycleBase.setStateInternal() ContainerBase.setState(LifecycleState.STARTING) LifecycleBase.fireLifecycleEvent(lifecycleEvent, data) HostConfig.start() HostConfig.deployApps() HostConfig.deployWARs() // 解析 web.xml !! MapperListener.start() =&gt; LifecycleBase.start() // 启动 MapperListener MapperListener.startInternal() Connector.start() =&gt; LifecycleBase.start() // 启动(多个) Connector Connector.startInternal() Http11NioProtocol.start() =&gt; AbstractProtocol.start() AbstractEndpoint.start() =&gt; NioEndpoint.startInternal() // 创建三个 cache: processorCache, eventCache, nioChannels startAcceptorThreads() new AsyncTimeout(); // Start async timeout thread StandardServer.await() // 创建一个在 8005 监听的 ServerSocket, 用于监听关闭 ServerSocket.accept // 阻塞在这里 源码分析 参考 Tomcat实现：源码分析Tomcat实现细节 @Archived * Connect.start()—创建并发线程模型: Work 线程, Poller 线程, Acceptor 线程, AsyncTimeout 线程 * 请求处理: Acceptor 线程, Poller 线程, Selector 如何解析 server.xml 在 Catalina.load() 创建 digester: Digester digester = createStartDigester() createStartDigester方法创建了 digester 对象, 并给 digester 对象添加多种 Rule, 每种 Rule 都对应 server.xml 里的一个节点类型, 比如&lt;Server&gt;, &lt;Connector&gt;; digester 对 server.xml 设置的标签动作有 5 种调用： addObjectCreate：遇到起始标签的元素，初始化一个实例对象入栈 addSetProperties：遇到某个属性名，使用 setter 来赋值 addSetNext：遇到结束标签的元素，调用相应的方法 addRule：调用 rule 的 begin 、body、end、finish 方法来解析 xml，入栈和出栈给对象赋值 addRuleSet：调用 addRuleInstances 来解析 xml 标签 从这些规则和 xml 中可以看到，Calatina 的 Server 对象是 StandardServer。 StandardService 包含了多个 Connector（xml 中有 2 个 connector）和一个 StandardEngine Container。 StandardEngine 包含了一个 Host Container 初始化 Connector根据配置文件 protocol = “HTTP/1.1”,”AJP/1.3” 创建对应 protocol, 默认是 Http11NioProtocol,再由 Http11NioProtocol 创建 NioEndpoint: 代码流程 调用Connector(String protocol), 构造函数Connector中默认创建org.apache.coyote.http11.Http11NioProtocol 以Http11NioProtocol为例, Http11NioProtocol.init()最终调用到NioEndpoint.bind() =&gt; NioEndpoint.initServerSocket() =&gt; serverSock.socket().bind(addr,getAcceptCount()) 完成了对端口的绑定 bind()的最后调用了NioSelectorPool.open(), 这是一个存放 Selector 的池子, 启动 ConnectorConnector 主要功能实现都是在 NioEndpoint, NioEndpoint 包括 x 个 Acceptor 线程, x 个 Poller 线程;Acceptor 线程(默认一个)用于 accept 客户端请求, 并把客户端请求 socket 封装进 event, 放入 events queue;Poller 线程池用于消费 events queue, 每个 Poller 都有自己的 Selector 对象, 不断取出 event, 并从中解析出 sockt, 并把 socket 的 READ 事件注册到自己的 Selector. 代码调用流程: Connector 的启动会调用start方法, =&gt; Connector.startInternal方法 =&gt; Http11NioProtocol.start() =&gt; AbstractProtocol.start() =&gt; NioEndpoint.start() =&gt; NioEndpoint.startInternal() 在NioEndpoint.startInternal()中, 如果 Worker 线程池是空, 则自己创建: 调用了父类AbstractEndpoint #createExecutor (), 创建 work 线程池, 名称前缀 “-exec-“; 创建NioEndpoint$Poller[]数组, Poller 是 Runnable 的实现, 然后所有的 Poller 线程都 start 起来, 线程名前缀是 “-ClientPoller-“, 数组的大小也就是 Poller 的数量是Math.min(2,Runtime.getRuntime().availableProcessors()), 可见 Poller 数量是 min(2, cpu 的 process 数量) 调用startAcceptorThreads(), 创建 Acceptor线程, 默认一个(线程数是 server.xml 里的acceptCount), , 线程名前缀是”-Acceptor-“ accept 请求Acceptor 线程 accept , 并把客户端请求 socket 封装进 event, 放入 events queue, 调用流程: Acceptor.run(): while (endpoint.isRunning()) &#123; socket = endpoint.serverSocketAccept(); endpoint.setSocketOptions(socket) // 调用了 NioEndpoint.setSocketOptions()&#125; 再看 NioEndpoint.setSocketOptions()里做了什么: 把客户端请求的 socket 封装进 NioChannel,调用 Poller.register(NioChannel): 把 NioChannel 封装进 PollerEvent, 每个 Poller 都有一个 PollerEvent 队列(events queue), 把 PollerEvent 放入这个队列 // Poller 有多个, 这里会轮询的方式选择出其中一个, AtomicInteger.incrementAndGet()) % pollers.length 处理一次 Req 请求Poller 线程用于消费 events queue, 代码调用流程: Poller.run() while 循环从 event queue 取出 PollerEvent, 然后调用 PollerEvent.run() PollerEvent.run() // 主要是在 Poller 自己的 Selector 上注册 READ 事件 Poller.processKey(SelectionKey , NioSocketWrapper) 调用-&gt; Poller.processSocket // 处理 OPEN_READ/OPEN_WRITE 等事件 创建一个 SocketProcessorBase 的实例, 把 socket 和 Event 封装进去, SocketProcessorBase 继承自 Runnable executor.execute(SocketProcessorBase) // 用 Worker 线程池运行这个 SocketProcessorBase SocketProcessorBase.run() -&gt; SocketProcessor.doRun() 再看 SocketProcessor 调用流程: SocketProcessor.doRun() : // 调用 SocketChannel.keyFor() AbstractProtocol$ConnectionHandler.process() NioEndpoint$SocketProcessor.doRun() Http11Processor.service() : 处理 Socket IO 流, 解析为 Http Request ApplicationFilterChain.internalDoFilter(): 调用Filter.doFilter() ,以及Servlet.service(); 如何 SHUTDOWN StandardServer.await() 创建一个在 8005 监听的 ServerSocket, 是用来监听关闭 Tomcat 命令的, 当执行 shutdown.sh 关闭 tomcat 时就是连接 8005 端口执行“SHUTDOWN”命令; 关闭请求发给 Tomcat, 由 StandardServer.await 处理, await 方法验证关闭请求是否有效, 如果有效则退出 await 方法, 进入 Catalina.stop(), 调用StandardServer.stop, StandardServer.destroy, 然后关闭 Connector, Service 从日志可以看到: WebappLoader.stopInternal -&gt; WebappClassLoaderBase.stop -&gt; WebappClassLoaderBase.clearReferences WebappClassLoaderBase.clearReferencesJdbc WebappClassLoaderBase.clearReferencesThreads AbstractProtocol.pause Pausing ProtocolHandler [“http-nio-8080”] AbstractProtocol.pause Pausing ProtocolHandler [“ajp-nio-8009”] StandardService.stopInternal Useful Java API usage AsyncChannelWrapperSecure: Executors.newFixedThreadPool , shutdownNow AsynchronousSocketChannel ByteBuffer, flip, hasRemaining, AtomicBoolean WsWebSocketContainer AsynchronousSocketChannel 并发的处理代码 用线程池启动容器内组件 // Start our child containers, if anyContainer children[] = findChildren();List&lt;Future&lt;Void&gt;&gt; results = new ArrayList&lt;&gt;();for (int i = 0; i &lt; children.length; i++) &#123; results.add(startStopExecutor.submit(new StartChild(children[i])));&#125;boolean fail = false;for (Future&lt;Void&gt; result : results) &#123; try &#123; result.get(); &#125; catch (Exception e) &#123; &#125;&#125; 通过 Callable 封装带返回值的任务 private static class StartChild implements Callable&lt;Void&gt; &#123; private Container child; public StartChild(Container child) &#123; this.child = child; &#125; public Void call() throws LifecycleException &#123; child.start(); return null;&#125; &#125; 参考 Tomcat那些事儿的热门分享 - 开发者头条","categories":[{"name":"13.JavaEE","slug":"13-JavaEE","permalink":"https://beefyheisenberg.github.io/categories/13-JavaEE/"}],"tags":[{"name":"JavaEE","slug":"JavaEE","permalink":"https://beefyheisenberg.github.io/tags/JavaEE/"},{"name":"Tomcat","slug":"Tomcat","permalink":"https://beefyheisenberg.github.io/tags/Tomcat/"}]},{"title":"Spring MVC","slug":"13.JavaEE-Framework/JavaEE.SpringMVC","date":"2024-01-24T01:27:52.276Z","updated":"2024-01-24T01:27:52.278Z","comments":true,"path":"13.JavaEE-Framework/JavaEE.SpringMVC/","link":"","permalink":"https://beefyheisenberg.github.io/13.JavaEE-Framework/JavaEE.SpringMVC/","excerpt":"Spring Framework 框架图下图是 Spring 官网的一个架构图，介绍下其组成部分： 核心容器由spring-core、spring-beans、spring-context、spring-context-support和spring-expression模块组成：","text":"Spring Framework 框架图下图是 Spring 官网的一个架构图，介绍下其组成部分： 核心容器由spring-core、spring-beans、spring-context、spring-context-support和spring-expression模块组成： spring-core 和 spring-beans 提供框架的基础部分，包括 IOC 功能，BeanFactory 是一个复杂的工厂模式的实现，将配置和特定的依赖从实际程序逻辑中解耦。 context 模块建立在 core 和 beans 模块的基础上，增加了对国际化的支持、事件广播、资源加载和创建上下文，ApplicationContext 是 context 模块的重点。 spring-context-support 提供对常见第三个库的支持，集成到 spring 上下文中，比如缓存(ehcache,guava)、通信(javamail)、调度(commonj,quartz)、模板引擎等(freemarker,velocity)。 spring-expression 模块提供了一个强大的表达式语言用来在运行时查询和操作对象图，这种语言支持对属性值、属性参数、方法调用、数组内容存储、集合和索引、逻辑和算数操作及命名变量，并且通过名称从 spring 的控制反转容器中取回对象。 AOP 和服务器工具 spring-aop 模块提供面向切面编程实现 单独的 spring-aspects 模块提供了 aspectj 的集成和适用。 spring-instrument 提供一些类级的工具支持和 ClassLoader 级的实现，用于服务器。spring-instrument-tomcat 针对 tomcat 的 instrument 实现。 消息组件包含了spring-messaging模块，从spring集成项目中抽象出来，比如Messge、MessageChannel、MessageHandler及其他用来提供基于消息的基础服务。 数据访问/集成数据访问和集成层由 JDBC、ORM、OXM、JMS 和 Transaction 模块组成。 spring-jdbc 模块提供了不需要编写冗长的 JDBC 代码和解析数据库厂商特有的错误代码的 JDBC 抽象出。 spring-orm 模块提供了领先的对象关系映射 API 集成层，如 JPA、Hibernate 等。 spring-oxm 模块提供抽象层用于支持 Object/XML maping 的实现，如 JAXB、XStream 等。 spring-jms 模块包含生产和消费消息的功能，从 Spring4.1开始提供集成 spring-messaging 模块。 spring-tx 模块提供可编程和声明式事务管理。 WebWeb层包含spring-web、spirng-webmvc、spring-websocket和spring-webmvc-portlet模块组成。 spring-web 模块提供了基本的面向 web 开发的集成功能，例如多文件上传、使用 servert listeners 和 web 开发应用程序上下文初始化 IOC 容器。也包含 HTTP 客户端以及 spring 远程访问的支持的 web 相关部分。 spring-webmvc 包含 spring 的 model-view-controller 和 REST web services 实现的 Web 应用程序。 spring-webmvc-portlet 模块提供了 MVC 模式的 portlet 实现，protlet 与 Servlet 的最大区别是请求的处理分为 action 和 render 阶段，在一个请求中，action 阶段只执行一次，但 render 阶段可能由于用户的浏览器操作而被执行多次。 测试spring-test模块支持通过组合Junit或TestNG来进行单元测试和集成测试，提供了连续的加载ApplicationContext并且缓存这些上下文。 使用Spring Context使用ClassPathXmlApplicationContext: ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"META-INF/spring/spring-main.xml\");A a = context.getBean(A.class); 直接使用 DefaultListableBeanFactory: Resource resource = new ClassPathResource(\"spring-core.xml\");DefaultListableBeanFactory beanFactory = new DefaultListableBeanFactory();XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(beanFactory);reader.loadBeanDefinitions(resource);MyBean myBean = (MyBean) beanFactory.getBean(\"myBean\");myBean.sayHello(); 区分ApplicationContext and ServletContext java - ApplicationContext and ServletContext - Stack Overflow 使用BeanSpring 基于 Ioc 和 DI 的方式 创建 &amp; 装配 Bean : 控制反转(Inversion of Control): 使用者不自己创建依赖的对象, 而交由第三方(IoC容器)创建. 从IOC容器中获取（和自动注入）.而不必由用户调用 new 来创建 Bean 对象, 通过 IoC 则可以减少它们之间的耦合度. 依赖注入(Dependency Injection): 将依赖对象传递给使用者. 在 Spring 中, bean 的装配是依赖注入的具体行为，依赖注入的时候需要根据 bean 的名称或类型等进行装配。 创建Bean的几种方式基于注解① 基于 @Component 通过注解方式创建容器: @Configuration@ComponentScanpublic interface ThisIsConfig &#123;&#125; @Configuration 来标注该接口是用于定义配置的, Spring 会视为该java文件为一个xml配置 @ComponentScan Spring 将会扫描该类所在的包下的所有 bean注解(@Component, @Service等等), 等同于在 Spring的xml里写: &lt;context:component-scan base-package=&quot;com.bigdata&quot;&gt;&lt;/context:component-scan&gt; 如果要指定要扫描的包的路径(而不是 这个类所在的包) 可以用 @ComponentScan(value=&quot;包路径&quot;) 指定; 带有 @Component注解的类被Ioc方式创建: 通过 @Autowired 用 DI 方式进行装配: 关于@Component,@Service,@Controler,@Repository注解这几个注解都是同样的功能，被注解的类将会被 Spring 容器创建单例对象。@Component : 侧重于通用的Bean类@Service：标识该类用于业务逻辑@Controler：标识该类为Spring MVC的控制器类@Repository: 标识该类是一个实体类，只有属性和Setter,Getter ② 基于 @Bean@Configuration@ComponentScanpublic class SwaggerConfig &#123; @Bean public SwaggerSpringMvcPlugin customImplementation() &#123; ... &#125;&#125; @Bean 注解在这里的意思是 : 该方法会返回一个 SwaggerSpringMvcPlugin 类型的 bean 二者区别Component vs Bean 的区别，参考下面的 「 [[#注解(Annotation)]] 」一章 基于XML① 基于构造器: 下面的类JedisPortsFactory 具有一个构造器(该构造器 有两个参数: config 和 autoFlush)config 引用到了另一个bean, autoFlush 是个boolean型 &lt;bean id = \"jedisPortsFactory\" class=\"com.bigdata.console.tools.online.JedisPortsFactory\"&gt; &lt;constructor-arg name=\"config\" ref=\"jedisEvictionPoolConfig\"/&gt; &lt;constructor-arg name=\"autoFlush\" value=\"true\"/&gt;&lt;/bean&gt; ② 基于 setter: CommonsMultipartResolver 要有property对应的 Setter方法 &lt;bean id=\"multipartResolver\" class=\"org.springframework.web.multipart.commons.CommonsMultipartResolver\"&gt; &lt;property name=\"defaultEncoding\" value=\"UTF-8\" /&gt; &lt;property name=\"maxUploadSize\" value=\"-1\" /&gt;&lt;/bean&gt; ③ 基于静态工厂: 指定 工厂类的class, 适用于 静态工厂方法: &lt;bean id=\"jp_featurePv\" class=\"com.bigdata.consoleJedisPortsFactory\" factory-method=\"getJedisMSServers\"&gt; &lt;constructor-arg type=\"java.lang.String\" value=\"xxx\"/&gt;&lt;/bean&gt; ④ 基于动态工厂: 指定 动态工厂的bean 和方法, 下面的例子中工厂方法 getJedisMSServers 有一个字符串型的参数, 适用于动态工厂方法: &lt;bean id=\"jp_featurePv\" factory-bean=\"jedisPortsFactory\" factory-method=\"getJedisMSServers\"&gt; &lt;constructor-arg type=\"java.lang.String\" value=\"xxx\"/&gt;&lt;/bean&gt; Bean的属性无论是基于@Component 还是 Xml 创建的 Bean ，属性都是通用的： scope scope=”singleton”: 单例, Spring 在每次需要时都返回同一个bean实例 scope=”prototype”: Spring 在每次需要时都产生一个新的 bean 实例 scope=”request” scope=”session” 如果使用 @Service、@Controller … 等注解创建 Bean： @Component 注解默认实例化的对象是单例，如果想声明成多例对象可以使用@Scope(“prototype”) @Repository 默认单例 @Service 默认单例 @Controller 默认单例 autowire autowire=”byName”: 只能用于setter注入。比如我们有方法“setHelloApi”，则“byName”方式Spring容器将查找名字为helloApi的Bean并注入 autowire=”no”: 意思是 Spring 将不自动装配这个Bean，必须明确指定依赖 &lt;bean id=\"bean\" class=\"bean.HelloApiDecorator\" autowire=\"byName\"/&gt; depends-onSpring保证该Bean所依赖的其他bean已经初始化, 用&lt;ref&gt;元素建立对其他bean的依赖关系, Sprign 会确保创建 bean的顺序: &lt;bean id=\"helloApi\" class=\"helloworld.HelloImpl\"/&gt;&lt;bean id=\"decorator\" class=\"helloworld.HelloApiDecorator\" depends-on=\"helloApi\"&gt; &lt;property name=\"helloApi\"&gt;&lt;ref bean=\"helloApi\"/&gt;&lt;/property&gt;&lt;/bean&gt; lookup-method单例模式的beanA需要引用另外一个非单例模式的beanB，为了在我们每次引用的时候都能拿到最新的beanB &lt;bean id=\"prototypeBean\" class=\"bean.PrototypeBean\" scope=\"prototype\"/&gt;&lt;bean id=\"singletonBean\" class=\"bean.SingletonBean\"&gt; &lt;!-- SingletonBean.getBean()方法被代理 --&gt; &lt;lookup-method name=\"getBean\" bean=\"prototypeBean\"/&gt;&lt;/bean&gt; 下面是java代码 public abstract class SingletonBean&#123; // 抽象方法, 每次获取一个新的PrototypeBean实例 protected abstract PrototypeBean getBean();&#125;ApplicationContext app = new ClassPathXmlApplicationContext(\"classpath:resource/applicationContext.xml\");SingletonBean single= (SingletonBean)app.getBean(\"singletonBean\");single.getBean(); // 每次返回一个新的PrototypeBean Bean的初始化/销毁回调 基于代码InitializingBean接口为bean提供了属性初始化后的处理方法，它只包括afterPropertiesSet方法，凡是继承该接口的类，在bean的属性初始化后都会执行该方法: public class ExampleBean implements InitializingBean &#123; public void afterPropertiesSet() &#123; // do some initialization work &#125;&#125; DisposableBean接口为bean提供销毁方法public class ExampleBean implements DisposableBean &#123; public void destroy() &#123; // do some destruction work &#125;&#125; 基于XML配置&lt;bean id=\"helloWorld\" class=\"com.dropNotes.HelloWorld\" init-method=\"init\" destroy-method=\"destroy\"&gt; &lt;property name=\"message\" value=\"Hello World!\"/&gt;&lt;/bean&gt; 上面的init-method属性和 destroy-method属性, 指定了HelloWorld类的初始化/销毁回调方法名字, 接下来在HelloWorld类中定义无参的方法即可. 何时调用当ApplicationContext.registerShutdownHook()被调用时 IOC 和 DI上面提到了 Spring 基于 Ioc 和 DI 的方式创建 &amp; 装配 Bean，总结一下 IoC 和 DI 的常用注解 : IoC 创建 Bean：@Bean、@Component、@Service、@Controller、@Repository … DI 注入 Bean：@Autowired、@Resource … 上面注解具体的区别参考下面的 「 [[#注解(Annotation)]] 」一章 Spring 如何实现 IOC 和 DI创建 bean（IoC），以 XML 方式为例，伪码： //解析&lt;bean .../&gt;元素的 id 属性得到该字符串值为“courseDao” String idStr = &quot;courseDao&quot;; //解析&lt;bean .../&gt;元素的class属性得到该字符串“com.xx.Dao.impl.CourseDaoImpl” String classStr = &quot;com.xx.Dao.impl.CourseDaoImpl&quot;; //利用反射创建对象 Class&lt;?&gt; cls = Class.forName(classStr); Object obj = cls.newInstance(); //放入Spring容器保存container.put(idStr, obj); 构造器注入（DI）实现的伪码： // 通过反射获取当前类所有的构造方法信息（Constructor 对象）Constructor&lt;?&gt;[] candidates = beanClass.getDeclaredConstructors();// 设置构造方法参数实例Object[] argsToUse = new Object[parameterTypes.length];argsToUse[i] = getBean(beanNames.get(i));// 使用带有参数的 Constructor 对象实现实例化 Beanreturn constructorToUse.newInstance(argsToUse); Autowired 注入（DI）实现的伪码： // 通过反射得到当前类所有的字段信息（Field 对象）Field[] fields = bean.getClass().getDeclaredFields();// 判断字段是否有 @Autowired 注解Annotation ann = field.getAnnotation(Autowired.class);// 设置字段可连接，相当于将非 public（private、default、protect）更改为 public field.setAccessible(true);// 通过反射设置字段的值field.set(bean, getBean(field.getName())); @ref: Spring 中的反射与反射的原理 - 掘金 使用AOPAOP(Aspect Oriented Program) ，面向切面编程:主要实现的目的是针对业务处理过程中的切面进行提取，它所面对的是处理过程中的某个步骤或阶段，以获得逻辑过程中各部分之间低耦合性的隔离效果。 AOP的一些概念 连接点（Jointpoint）连接点是能够插入切面的一个点，连接点可能是类初始化，可以是调某方法时，抛出异常时，修改某字段时 切入点（Pointcut）：一组连接点集合 通知（Advice）：定义在连接点上“要做什么”，以及“何时去做”，包括前置通知（before advice）、后置通知(after advice)、环绕通知（around advice） 切面（Aspect）：可以认为是”通知”和”切入点”的集合 目标对象（Target Object）：需要被织入横切关注点的对象，即该对象是切入点选择的对象，需要被通知的对象，从而也可称为“被通知对象”；由于Spring AOP 通过代理模式实现，从而这个对象永远是被代理对象，在AOP中表示为“对谁做”； AOP代理（AOP Proxy）：AOP框架使用代理模式创建的对象，从而实现在连接点处插入通知（即应用切面），就是通过代理来对目标对象应用切面。在Spring中，AOP代理可以用JDK动态代理或CGLIB代理实现，而通过拦截器模型应用切面。 织入（Weaving）：织入是一个过程，是将切面应用到目标对象从而创建出AOP代理对象的过程，织入可以在编译期、类装载期、运行期进行。 引入（inter-type declaration）：为已有的类添加额外新的字段或方法，Spring 允许引入新的接口（必须对应一个实现）到所有被代理对象（目标对象）, 在 AOP 中表示为“做什么”； 基于XML配置aspect&lt;bean id=\"aspect\" class=\"cn.javass.spring.chapter6.aop.HelloWorldAspect\"/&gt;&lt;aop:config&gt; &lt;!-- 定义了一个id=\"pointcut\"的切点, 范围是com.javass包下的所有类 --&gt; &lt;aop:pointcut id=\"pointcut\" expression=\"execution(* cn.javass..*.*(..))\"/&gt; &lt;!-- 定义切面的集合, ref=\"aspect\"表示要引入\"aspect\"这个bean --&gt; &lt;aop:aspect ref=\"aspect\"&gt; &lt;!-- 定义一个切点, 包括用哪些切点, 以及在切点处要插入aspect.beforeAdvice()方法 --&gt; &lt;aop:before pointcut-ref=\"pointcut\" method=\"beforeAdvice\"/&gt; &lt;!-- 定义另一个切点, 在切点处要插入aspect.afterFinallyAdvice()方法 --&gt; &lt;aop:after pointcut=\"execution(* cn.javass..*.*(..))\" method=\"afterFinallyAdvice\"/&gt; &lt;/aop:aspect&gt;&lt;/aop:config&gt; 基于注解配置aspect下面的代码定义一个切面(@Aspect): 哪里切入(@Pointcut), 切入的行为(@Advice) @Aspectpublic class ControllerLogAspect &#123; //定义了一个切面 // 定义切点\"logPointCut\", 在哪些类里切入 @Pointcut(\"execution(public * com.xxx.*.controller..*.*(..)) &amp;&amp; \" + \"!execution(public * com.xxx.*.controller..CheckController.*(..))\") public void logPointCut() &#123; &#125; // 环绕通知 @Around(\"logPointCut()\") public void advice(ProceedingJoinPoint joinPoint)&#123; &#125; // 前置通知, 在切点\"logPointCut\"之前 @Before(\"logPointCut()\") public void doBefore(JoinPoint joinPoint) &#123; &#125; // 后置通知 @AfterReturning(returning = \"ret\", pointcut = \"logPointCut()\") public void doAfter(Object ret) throws Throwable &#123; &#125;&#125; Spring 如何实现 AOPSpring 通过 jdk 动态代理和 cglib 动态代理实现 AOP. Spring 的 AOP 是通过 Java 语言提供的 代理(Proxy)模式 实现的, Java 语言的代理包括如下 2种方式: JDK 动态代理, Cglib 动态代理. 实现过程参考 @link [[../12.Java/Java-Tutorials.14.代理(Proxy)]] Spring AOP 就是基于动态代理的，如果要代理的对象，实现了某个接口，那么 Spring AOP 会使用 JDK Proxy，去创建代理对象，而对于没有实现接口的对象，就无法使用 JDK Proxy 去进行代理了，这时候 Spring AOP 会使用 Cglib ，这时候 Spring AOP 会使用 Cglib 生成一个被代理对象的子类来作为代理，如下图所示： Spring AOP vs AspectJSpring AOP 属于运行时增强，而 AspectJ 是编译时增强。 Spring AOP 基于代理(Proxying)，而 AspectJ 基于字节码操作(Bytecode Manipulation)。 Spring AOP 已经集成了 AspectJ ，AspectJ 应该算的上是 Java 生态系统中最完整的 AOP 框架了。AspectJ 相比于 Spring AOP 功能更加强大，但是 Spring AOP 相对来说更简单， 如果我们的切面比较少，那么两者性能差异不大。但是，当切面太多的话，最好选择 AspectJ ，它比Spring AOP 快很多。 DispatcherServlet Servlet 规范、Servlet 容器、Spring 实现的 DispatcherServlet 关系，参考 JavaEE.Tomcat 第一节 要使用Spring MVC只需要在web.xml(Java Servlet 规范里Java Web项目的部署描述符文件)里增加一个Servlet: &lt;servlet&gt; &lt;servlet-name&gt;comment&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:appcontext-core-web.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;comment&lt;/servlet-name&gt; &lt;url-pattern&gt;/api/*&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; DispatcherServlet 工作流程DispatcherServlet处理一次 Req 的流程，伪码：（1）Request → DispatcherServlet（2）DispatcherServlet 从 HandleMapping[] 查找匹配, 返回 HandlerExecutionChain &#123; HandlerInterceptor1,HandleInterceptor2..&#125;（3）HandleInterceptor → HandleAdaptor → Controller（4）Controller 返回 ModelAndView → ViewResolver（5）View 对于 Spring MVC 程序来说, 首先调用的是 DispatcherServlet.service(ServletRequest, ServletResponse), 实现是在 HttpServlet.service(ServletRequest req, ServletResponse resp), 这个方法里把 ServletRequest 对象转换为 HttpServletRequest, 在这个方法里又调用进了 FrameworkServlet.service(HttpServletRequest req, HttpServletResponse resp), 在这个方法里如果 method!=PATCH 则调用进 super.service(HttpServletRequest, HttpServletResponse), 也就是 HttpServletservice(HttpServletRequest, HttpServletResponse), 这里根据不同的 method 调用不同的 doX() 方法 以 GET 方法为例，调用 this.doGet(), 因为在 FrameworkServlet 重写了 doGet(), 所以这里调用的代码是 FrameworkServlet.doGet(), 在这个方法里调用了FrameworkServlet.processRequest(), 然后又调用了this.doService(), DispatcherServlet 重写了 doService(), 所以最终调用到 DispatcherServlet.doService(), 该方法逻辑大致如下: void doDispatch(HttpServletRequest request, HttpServletResponse response) &#123; HandlerExecutionChain mappedHandler = getHandler(processedRequest); HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); mv = ha.handle(processedRequest, response, mappedHandler.getHandler());&#125; getHandler()主要就是通过this.handlerMappings中的HandlerMapping实例来对具体request映射一个handler（Spring MVC中的Controller类） ; 如果看过this.handlerMappings的初始化，便知道HandlerMapping的具体实现有3个： RequestMappingHandlerMapping : 用来映射Controller和URL BeanNameUrlHandlerMapping SimpleUrlHandlerMapping …… …… 上图中组件处理顺序分别是: Dispatcher Servlet分发器 Handler Mapping 处理器映射 Controller 控制器 ModelAndView 模型和视图对象 ViewResolver 视图解析器 @ref SpringMVC 工作原理详解 拦截器(Interceptor)处理器映射处理过程配置的拦截器，必须实现 org.springframework.web.servlet包下的 HandlerInterceptor接口。这个接口定义了三个方法：preHandle(..)，它在处理器实际执行 之前 会被执行；postHandle(..)，它在处理器执行 完毕 以后被执行；afterCompletion(..)，它在 整个请求处理完成 之后被执行。 通过xml定义拦截器&lt;beans&gt; &lt;bean id=\"handlerMapping\" class=\"org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping\"&gt; &lt;property name=\"interceptors\"&gt; &lt;list&gt; &lt;ref bean=\"officeHoursInterceptor\"/&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id=\"officeHoursInterceptor\" class=\"samples.TimeBasedAccessInterceptor\"&gt; &lt;property name=\"openingTime\" value=\"9\"/&gt; &lt;property name=\"closingTime\" value=\"18\"/&gt; &lt;/bean&gt;&lt;beans&gt; 通过注解定义拦截器@Configuration@EnableWebMvcpublic class WebConfig extends WebMvcConfigurerAdapter &#123; @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new LocaleInterceptor()); registry.addInterceptor(new ThemeInterceptor()).addPathPatterns(\"/**\").excludePathPatterns(\"/admin/**\"); registry.addInterceptor(new SecurityInterceptor()).addPathPatterns(\"/secure/*\"); &#125;&#125; 控制器(Controller)传入类型 @RequestParam注解: @RequestParam(value = &quot;client_id&quot;) String appId Model类型: 这种通常返回String类型的view路径 HttpServletResponse: HttpServletRequest: 返回类型 返回ModelAndView: 返回视图return new ModelView(&quot;/view/111&quot;, map) 通过ModelAndView也可以重定向: return new ModelAndView(&quot;redirect:/controller2&quot;); 如果modelView是以参数传入的: model.setViewName(&quot;forward:index.jsp&quot;); return model; 返回RedirectView: 专门用来处理转发的视图, 见后面的代码. 返回String: 返回字符串可以指定逻辑视图名, 通过视图解析器解析为物理视图地址 通过String也可以重定向: return &quot;redirect:/resource/page2.jsp&quot;; 如果Controller带有@ResponseBody注解, 可以直接返回String字面值; 以json返回对象: 借助@ResponseBody注解, 项目导入Jackson.jar, 并且在Spring配置文件启用了&lt;mvc:annotation-driven /&gt; 1 返回Map: 借助@ResponseBody注解, return new HashMap&lt;&gt;();会返回一个json 没有@ResponseBody注解, map.put(&quot;key1&quot;, &quot;value-1&quot;); return map;, 在jsp页面中可直通过${key1}获得到值 返回void: 需要通过形参传入request和response 使用request转向页面: request.getRequestDispatcher(&quot;index.html&quot;).forward(request, response); 通过response页面重定向: response.sendRedirect(&quot;http://www.xxx.com&quot;); forward和Redirect的区别: forward是由Servlet直接转给另一个Controller处理, Redirect相当于302, 返回给浏览器, 然后浏览器再发一次新的请求到Controller2 通过response指定响应结果: 返回json: response.setContentType(&quot;application/json;charset=utf-8&quot;); response.getWriter().write(&quot;this_is_json&quot;); 返回Html: response.getWriter().println(&quot;&lt;title&gt;HelloWorld&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&quot;); 用RedirectAttributes带参跳转:@RequestMapping(\"/\")public RedirectView hello(RedirectAttributes attrs) &#123; attrs.addAttribute(\"message\", \"hello\"); attrs.addFlashAttribute(\"username\", \"sudoz\"); return new RedirectView(\"hello\");&#125;@RequestMapping(\"hello\") Map&lt;String, String&gt; hello(@ModelAttribute(\"username\") String username, @ModelAttribute(\"message\") String message) &#123; Map&lt;String, String&gt; map = Maps.newHashMap(); map.put(\"username\", username); map.put(\"message\", message); return map;&#125; 1 mvc:annotation-driven是一种简写形式，完全可以手动配置替代这种简写形式，&lt;mvc:annotation-driven /&gt;会自动注册DefaultAnnotationHandlerMapping与AnnotationMethodHandlerAdapter 两个bean,是Spring MVC为@Controllers分发请求所必须的。并提供了：数据绑定支持，@NumberFormatannotation支持，@DateTimeFormat支持，@Valid支持，读写XML的支持（JAXB），读写JSON的支持（Jackson）。 Spring是如何处理返回类型的?DispatchServlet.viewResolvers的类型是List&lt;ViewResolver&gt;, Controller返回的类型转给DispatchServlet, 最终交给不同的ViewResolver处理的 视图(View)所有web应用的MVC框架都提供了视图相关的支持。Spring提供了一些视图解析器，它们让你能够在浏览器中渲染模型，并支持你自由选用适合的视图技术而不必与框架绑定到一起。Spring原生支持JSP视图技术、Velocity模板技术和XSLT视图等。 有两个接口在Spring处理视图相关事宜时至关重要，分别是视图解析器接口ViewResolver和视图接口本身View。视图解析器ViewResolver负责处理视图名与实际视图之间的映射关系。视图接口View负责准备请求，并将请求的渲染交给某种具体的视图技术实现。 使用ViewResolver接口解析视图Spring MVC中所有控制器的处理器方法都必须返回一个逻辑视图的名字，无论是显式返回（比如返回一个String、View或者ModelAndView）还是隐式返回（比如基于约定的返回）。Spring中的视图由一个视图名标识，并由视图解析器来渲染。Spring有非常多内置的视图解析器。 资源(Resource)Resource接口Resource接口提供了足够的抽象，足够满足我们日常使用。而且提供了很多内置Resource实现：ByteArrayResource、InputStreamResource 、FileSystemResource 、UrlResource 、ClassPathResource、ServletContextResource、VfsResource等。 路径通配符 ?匹配一个字符，如config?.xml将匹配config1.xml *匹配零个或多个字符串，如cn/*/config.xml将匹配cn/javass/config.xml，但不匹配匹配cn/config.xml **匹配路径中的零个或多个目录，如cn/**/config.xml // 加载Resource例子1:ResourcePatternResolver resolver = new PathMatchingResourcePatternResolver();//只加载一个绝对匹配Resource，且通过ResourceLoader.getResource进行加载Resource[] resources=resolver.getResources(\"classpath:META-INF/INDEX.LIST\");// 加载Resource例子2:ResourcePatternResolver resolver = new PathMatchingResourcePatternResolver();//将加载多个绝对匹配的所有Resource//将首先通过ClassLoader.getResources(\"META-INF\")加载非模式路径部分//然后进行遍历模式匹配// classpath*： 用于加载类路径（包括jar包）中的所有匹配的资源Resource[] resources=resolver.getResources(\"classpath*:META-INF/INDEX.LIST\"); 静态资源静态资源包括：HTML、CSS、JS、图像、视频、PDF/Office等不需要服务器端处理的文件。 静态资源文件的位置: Java Web默认的静态资源文件夹是 src/main/webapp/ Spring Boot自动将src/main/resource/下的「/static」「/public」「/resources」「/META-INF/resources」识别为资源文件夹。 下面的css可以通过访问http://localhost:8080/css/a.css获取Project Root└─src └─ main └─ resources ├─ static | └─ css | └─ a.css ├─ public | └─ css | └─ b.css ├─ resources | └─ css | └─ b.css └─ META-INF └─ resources └─ css └─ d.css 异常处理(Exception) Controller的匹配. 除了value指定url, 还可以通过product指定MIME-TYPE(参考网络协议HTTP) 调试的时候需要注意, cURL实际是使用了Accept: */*, 浏览器发出的请求是Accept:text/html @RequestMapping(value = \"/return-text-plain\", produces = MimeTypeUtils.TEXT_PLAIN_VALUE)@ResponseBodypublic String returnPlainText() throws SomeException &#123; throw new SomeException();&#125; How to自定义Error页面:@Configurationpublic class CustomDefaultErrorViewConfiguration &#123; @Autowired private ThymeleafViewResolver thymeleafViewResolver; @Bean public View error() throws Exception &#123; return thymeleafViewResolver.resolveViewName(\"custom-error-page/error\", Locale.CHINA); &#125;&#125; 注解(Annotation)Spring注解IOC 注解: @Service, @Controller, @Repository, @Component, @Bean @Service: 用于注解Service层, 默认是单例的 @Controller: 定义控制器类一般这个注解在类中，通常方法需要配合注解 @RequestMapping @RestController相当于@ResponseBody和@Controller的合集, 默认是单例的 @Repository用于注解DAO，这个注解修饰的DAO类会被ComponetScan发现并配置，同时也不需要为它们提供xml配置项 如果一个类不好归类, 则使用 @Component 注解 The default scope for the bean is a singleton @Bean: 区别与上面的注解，@Component 注解作用于类，而 @Bean 注解作用于方法, 该方法必须返回一个类型对象, 该对象被注册为 Spring 上下文中的 bean, 注意方法名字将会作为 bean 的 ID, 相当于在 xml 中定义 &lt;bean&gt; @Bean(initMethod=”aa”,destroyMethod=”bb”): 指定 aa 和 bb 方法分别在在构造之后/销毁之前执行 Spring 会自动扫描 base-package 指定的包下面用 @Service 注解的所有类, 并注册到 beans 容器里.需要在 Spring 配置文件里增加: &lt;context:component-scan base-package=&quot;com.xxx.product.core.service&quot;/&gt; 来说明启用自动扫描 DI 注解: @Autowired, @Resource, @Inject, @Primary @Autowired: 可以写在属性上, 和 setter 方法上, 或者构造函数上, 默认按照类型进行装配 @Autowired 和 @Inject: 通过 AutowiredAnnotationBeanPostProcessor 来实现依赖注入, 顺序: 按照类型匹配 使用限定符进行类型限定 按照名称匹配 @Resource: 使用 CommonAnnotationBeanPostProcessor 来实现注入, 顺序: 按照名称匹配 按照类型匹配 使用限定符进行类型限定 ➤ 区别二者： @Resource 并不是 Spring 的注解，它的包是 javax.annotation.Resource， Spring 也支持该注解的注入； 两者都可以写在字段和 setter 方法上。两者如果都写在字段上，那么就不需要再写 setter 方法； @ComponentScan &amp; @Component @Component: 使用在类上, 表示可以被 @ComponentScan 标注的类扫描到 @ComponentScan: 使用在类上, 可以扫描到 @Component 注解的类 比较: @Configuration + @Bean 的方式需要在@Configuration 的类里定义”返回每种 Bean 类型的方法”, @ComponentScan + @Component 的方式省去了定义方法返回 Bean 的类型@Configuration, @ComponentScan, @Component 注解通常联合起来使用, 免去了在 xml 里定义 bean, 也不必写 @Bean @Componentpublic class CompactDisc &#123;&#125;@Componentpublic class MediaPlayer &#123; private CompactDisc cd; @Autowired public CDPlayer(CompactDisc cd) &#123; this.cd = cd; &#125;&#125;@Configuration@ComponentScanpublic class CDPlayerConfig &#123;&#125;// 使用扫描到的Bean:@ContextConfiguration(classes=CDPlayerConfig.class)public class Test &#123; @Autowired private MediaPlayer player; @Autowired private CompactDisc cd;&#125; @ContextConfiguration &amp; @Configuration @Configuration: 用于类上, 说明这个类可以使用 Spring IoC 容器作为 bean 定义的来源, 相当于在 xml 中定义 &lt;beans&gt; @ContextConfiguration(classes=KnightConfig.class) 使用在类上, 表示使用 @Configuration 标注的类当作 bean 的定义来源 @Configurationpublic class TextEditorConfig &#123; @Bean public TextEditor textEditor()&#123; return new TextEditor( spellChecker() ); &#125; @Bean public SpellChecker spellChecker()&#123; return new SpellChecker( ); &#125;&#125;// 上面的等同于在xml里定义了两个&lt;bean&gt;// 使用从@Configuration标注类里注入的bean@ContextConfiguration(classes=KnightConfig.class,loader=AnnotationConfigContextLoader.class)public class Test &#123; @Autowired TextEditor textEditor; @Autowired SpellChecker spellChecker;&#125; @Transcational, @Cacheable @Transcational : 事务处理 @Cacheable : 数据缓存 @Scope默认是@Scope(&quot;singleton&quot;)单例的, 此外还有: singleton 单例的 prototype 表示每次获得bean都会生成一个新的对象 request 表示在一次http请求内有效 session 表示在一个用户会话内有效 @Qualifierpublic class CarFactory&#123; @Autowired @Qualifier(\"ImplementedClass\") private AbstractClass a;&#125; 当抽象类AbstractClass的实现类有多个时, 如果没有Qualifier注解则会报错, 因为Spring不知道应该注入哪个类型, 注意@Qualifier()括号里是类的名字 @Aspect @After @Before. @Around 定义切面,可以直接将拦截规则(切入点 PointCut)作为参数 @PointCut : 专门定义拦截规则 然后在 @After @Before. @Around 中调用 @EnableAaspectJAutoProxy : 开启Spring 对 这个切面(Aspect )的支持 JDK注解 @Resource: 可以写在属性上, 和setter方法上, 默认按照名称进行装配 Spring中的线程安全性 本节参考： 聊一聊Spring中的线程安全性 | SylvanasSun’s Blog Spring 作为一个 IOC/DI 容器，帮助我们管理了许许多多的“bean”。但其实，Spring 并没有保证这些对象的线程安全，需要由开发者自己编写解决线程安全问题的代码。 Spring对每个bean提供了一个scope属性来表示该bean的作用域。它是bean的生命周期。例如，一个scope为singleton的bean，在第一次被注入时，会创建为一个单例对象，该对象会一直被复用到应用结束。 singleton：默认的scope，每个scope为singleton的bean都会被定义为一个单例对象，该对象的生命周期是与Spring IOC容器一致的（但在第一次被注入时才会创建）。prototype：bean被定义为在每次注入时都会创建一个新的对象。request：bean被定义为在每个HTTP请求中创建一个单例对象，也就是说在单个请求中都会复用这一个单例对象。session：bean被定义为在一个session的生命周期内创建一个单例对象。application：bean被定义为在ServletContext的生命周期中复用一个单例对象。websocket：bean被定义为在websocket的生命周期中复用一个单例对象。 我们交由Spring管理的大多数对象其实都是一些无状态的对象，这种不会因为多线程而导致状态被破坏的对象很适合Spring的默认scope，每个单例的无状态对象都是线程安全的（也可以说只要是无状态的对象，不管单例多例都是线程安全的，不过单例毕竟节省了不断创建对象与GC的开销）。 无状态的对象即是自身没有状态的对象，自然也就不会因为多个线程的交替调度而破坏自身状态导致线程安全问题。无状态对象包括我们经常使用的DO、DTO、VO这些只作为数据的实体模型的贫血对象，还有Service、DAO和Controller，这些对象并没有自己的状态，它们只是用来执行某些操作的。例如，每个DAO提供的函数都只是对数据库的CRUD，而且每个数据库Connection都作为函数的局部变量（局部变量是在用户栈中的，而且用户栈本身就是线程私有的内存区域，所以不存在线程安全问题），用完即关（或交还给连接池）。 有人可能会认为，我使用 scope=request 作用域不就可以避免每个请求之间的安全问题了吗？这是完全错误的，因为 Controller 默认是单例的，一个 HTTP 请求是会被多个线程执行的，这就又回到了线程的安全问题。当然，你也可以把 Controller 的 scope 改成 prototype，实际上 Struts2就是这么做的，但有一点要注意，Spring MVC 对请求的拦截粒度是基于每个方法的，而 Struts2是基于每个类的，所以把 Controller 设为多例将会频繁的创建与回收对象，严重影响到了性能。 通过阅读上文其实已经说的很清楚了，Spring 根本就没有对 bean 的多线程安全问题做出任何保证与措施。对于每个 bean 的线程安全问题，根本原因是每个 bean 自身的设计。不要在 bean 中声明任何有状态的实例变量或类变量，如果必须如此，那么就使用 ThreadLocal 把变量变为线程私有的，如果 bean 的实例变量或类变量需要在多个线程之间共享，那么就只能使用 synchronized、lock、CAS 等这些实现线程同步的方法了。ThreadLocal @link [[../12.Java/Java-并发.02.ThreadLocal]] &amp; Servlet 规范的线程安全 @link JavaEE.Servlet 本文作者为 SylvanasSun(sylvanas.sun@gmail.com)，首发于 SylvanasSun’s Blog。原文链接：https://sylvanassun.github.io/2017/11/06/2017-11-06-spring_and_thread-safe/（转载请务必保留本段声明，并且保留超链接。） @Async注解实现异步方法• 定义线程池：@Configurationpublic class ExecutorConfig &#123; @Bean(&quot;customExecutor-1&quot;)// 自定义线程池1 public Executor customExecutor1() &#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(3);//核心池大小 executor.setMaxPoolSize(6);//最大线程数 executor.setKeepAliveSeconds(60);//线程空闲时间 executor.setQueueCapacity(10);//队列程度 executor.setThreadNamePrefix(&quot;customExecutor-1-&quot;);//线程前缀名称 executor.setRejectedExecutionHandler(new ThreadPoolExecutor.AbortPolicy());//配置拒绝策略 executor.setAllowCoreThreadTimeOut(true);// 允许销毁核心线程 executor.initialize(); return executor; &#125;&#125; • @Async定义异步的service方法：@Servicepublic class AsyncService &#123; // 例：无返回值的异步方法 // 使用上面定义的线程池 @Async(&quot;customExecutor-1&quot;) public void noReturnMethod() &#123; String tName = Thread.currentThread().getName(); System.out.println(&quot;current thread name : &quot; + tName); System.out.println(&quot;noReturnMethod end&quot;); &#125; // 例：有返回值的异步方法 // 使用默认 SimpleAsyncTaskExecutor @Async public Future&lt;String&gt; withReturnMethod() &#123; String tName = Thread.currentThread().getName(); System.out.println(&quot;current thread name : &quot; + tName); return new AsyncResult&lt;&gt;(&quot;aaa&quot;); &#125;&#125; • 使用异步service@RestController@RequestMapping(&quot;/api/async/test/&quot;)public class AsyncController &#123; @Autowired AsyncService asyncService; // 无返回值 @GetMapping(&quot;/noReturn&quot;) public String noReturn() &#123; asyncService.noReturnMethod(); return &quot;success&quot;; &#125; // 有返回值 @GetMapping(&quot;/withReturn&quot;) public String withReturn() &#123; Future&lt;String&gt; future = asyncService.withReturnMethod(); try &#123; String res = future.get();// 阻塞获取返回值 System.out.println(&quot;res = &quot; + res); &#125; catch (InterruptedException | ExecutionException e) &#123; e.printStackTrace(); &#125; return &quot;success&quot;; &#125;&#125; 对“约定优于配置”的支持 约定优于配置（convention over configuration)，也称作按约定编程，是一种软件设计范式，旨在减少软件开发人员需做决定的数量，获得简单的好处，而又不失灵活性。本质是说，开发人员仅需规定应用中不符约定的部分。例如，如果模型中有个名为Sale的类，那么数据库中对应的表就会默认命名为sales。只有在偏离这一约定时，例如将该表命名为”products_sold”，才需写有关这个名字的配置。许多新的框架使用了约定优于配置的方法，包括：Spring，Ruby on Rails，Kohana PHP，Grails，Grok，Zend Framework，CakePHP，symfony，Maven，ASP.NET MVC，Web2py（MVC），Apache Wicket。比如Maven对目录做了”约定优于配置”的设定: src/main/resources: 资源文件目录; src/main/java: Java源码目录; src/main/webapp: web应用文件目录（当打包为war时），如WEB-INF/web.xml 对JDBC的支持Spring主要提供JDBC模板方式、关系数据库对象化方式和SimpleJdbc方式三种方式来简化JDBC编程，这三种方式就是Spring JDBC的工作模式： JDBC模板方式：Spring JDBC框架提供以下几种模板类来简化JDBC编程，实现GoF模板设计模式，将可变部分和非可变部分分离，可变部分采用回调接口方式由用户来实现：如JdbcTemplate、NamedParameterJdbcTemplate、SimpleJdbcTemplate。 关系数据库操作对象化方式：Spring JDBC框架提供了将关系数据库操作对象化的表示形式，从而使用户可以采用面向对象编程来完成对数据库的访问；如MappingSqlQuery、SqlUpdate、SqlCall、SqlFunction、StoredProcedure等类。这些类的实现一旦建立即可重用并且是线程安全的。 JDBC模板&lt;!--数据源的配置 --&gt;&lt;bean id=\"dataSource\" class=\"org.springframework.jdbc.datasource.DriverManagerDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"&gt;&lt;/property&gt; &lt;property name=\"url\" value=\"jdbc:mysql:///spring\"&gt;&lt;/property&gt; &lt;property name=\"username\" value=\"root\"&gt;&lt;/property&gt; &lt;property name=\"password\" value=\"\"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id=\"jdbcTemplate\" class=\"org.springframework.jdbc.core.JdbcTemplate\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"&gt;&lt;/property&gt;&lt;/bean&gt; public class JdbcTemplateTest &#123; private static JdbcTemplate jdbcTemplate; @Test public void testQuery() &#123; String sql = \"select * from INFORMATION_SCHEMA.SYSTEM_TABLES\"; jdbcTemplate.query(sql, new RowCallbackHandler() &#123; @Override public void processRow(ResultSet rs) throws SQLException &#123; String value = rs.getString(\"TABLE_NAME\"); System.out.println(\"Column TABLENAME:\" + value); &#125; &#125;); &#125; @Test public void testUpdate() &#123; jdbcTemplate.update(\"insert into test(name) values('name1')\"); jdbcTemplate.update(\"delete from test where name=?\", new Object[]&#123;\"name2\"&#125;); jdbcTemplate.update(\"update test set name='name3' where name=?\", new Object[]&#123;\"name1\"&#125;); &#125;&#125; 关系数据库对象化对MyBatis的支持参考mybatis-spring – MyBatis-Spring | 第二章 入门 @ref 1. 引入mybatis-spring依赖如果使用 Maven 作为构建工具，仅需要在 pom.xml 中加入以下代码即可： &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt;&lt;/dependency&gt; 2. SqlSessionFactoryBean &amp; Mapper要和 Spring 一起使用 MyBatis，需要在 Spring 应用上下文中定义至少两样东西：一个 SqlSessionFactory 和至少一个数据映射器。 增加 sqlSessionFactory 的 bean，注意 sqlSessionFactory 还需要一个数据源（DataSource），下面的例子用了 DruidDataSource 这里使用了 MapperScannerConfigurer, 它将会查找类路径下的映射器并自动将它们创建成 MapperFactoryBean （可选）增加 transactionManager 的 bean, 开启 Spring 事务 &lt;bean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\" destroy-method=\"close\"&gt; &lt;property name=\"url\" value=\"$&#123;jdbc.url&#125;\"/&gt; &lt;property name=\"username\" value=\"$&#123;jdbc.username&#125;\"/&gt; &lt;property name=\"password\" value=\"$&#123;jdbc.password&#125;\"/&gt; &lt;property name=\"driverClassName\" value=\"$&#123;jdbc.driver&#125;\"/&gt; &lt;property name=\"maxActive\" value=\"10\"/&gt; &lt;property name=\"minIdle\" value=\"5\"/&gt;&lt;/bean&gt;&lt;!-- 要注意 SqlSessionFactory 需要一个 dataSource --&gt;&lt;bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;property name=\"configLocation\" value=\"classpath:mybatis/mybatis-config.xml\"/&gt; &lt;property name=\"mapperLocations\" value=\"classpath:mapper/**/*.xml\"/&gt;&lt;/bean&gt;&lt;!--事务管理器--&gt;&lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\" /&gt;&lt;/bean&gt;&lt;!--定义注解驱动事务--&gt;&lt;tx:annotation-driven transaction-manager=\"transactionManager\"/&gt;&lt;!-- 配置扫描包，加载mapper代理对象 --&gt;&lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"basePackage\" value=\"com.kuaizhan.kzweixin.dao.mapper\"/&gt;&lt;/bean&gt; 对Transaction的支持 @Transactional(value=&quot;transactionManagerPrimary&quot;, isolation = Isolation.DEFAULT, propagation = Propagation.REQUIRED) value: 事务管理器 隔离级别（isolation）: DEFAULT：这是默认值，表示使用底层数据库的默认隔离级别。对大部分数据库而言，通常这值就是：READ_COMMITTED。 READ_UNCOMMITTED：该隔离级别表示一个事务可以读取另一个事务修改但还没有提交的数据。该级别不能防止脏读和不可重复读，因此很少使用该隔离级别。 READ_COMMITTED：该隔离级别表示一个事务只能读取另一个事务已经提交的数据。该级别可以防止脏读，这也是大多数情况下的推荐值。 REPEATABLE_READ：该隔离级别表示一个事务在整个过程中可以多次重复执行某个查询，并且每次返回的记录都相同。即使在多次查询之间有新增的数据满足该查询，这些新增的记录也会被忽略。该级别可以防止脏读和不可重复读。 SERIALIZABLE：提供严格的事务隔离。它要求事务序列化执行，事务只能一个接着一个地执行，不能并发执行。仅仅通过“行级锁”是无法实现事务序列化的，必须通过其他机制保证新插入的数据不会被刚执行查询操作的事务访问到。也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。 传播行为（Propagation）:所谓事务的传播行为是指，如果在开始当前事务之前，一个事务上下文已经存在，此时有若干选项可以指定一个事务性方法的执行行为。 REQUIRED：如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。这是最常见的选择。 SUPPORTS：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。 MANDATORY：如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。 REQUIRES_NEW：创建一个新的事务，如果当前存在事务，则把当前事务挂起。 NOT_SUPPORTED：以非事务方式运行，如果当前存在事务，则把当前事务挂起。 NEVER：以非事务方式运行，如果当前存在事务，则抛出异常。 NESTED：如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于REQUIRED。 Spring MVC Step by Step @Deprecated Pom.xml build - resources # 定义资源文件? webapp/WEB-INF/web.xml context-param: contextConfigLocation=classpath:spring/appcontext-.xml # 指定Spring配置路径 listener: # listen优先级&gt;Servlet ContextLoaderListener=org.springframework.web.context.ContextLoaderListener RequestContextListener=org.springframework.web.context.request.RequestContextListener servlet: org.springframework.web.servlet.DispatcherServlet init-param: contextConfigLocation=classpath:appcontext-core-web.xml # 指定Servlet配置路径 Spring配置xml: 默认去找classpath下的application-Context.xml,这是一种约定优于配置的概念 context:property-placeholder: 指定*.properties位置 mvc:interceptors // 定义拦截器 mvc:annotation-driven // 注册DefaultAnnotationHandlerMapping/AnnotationMethodHandlerAdapter, 用于支持@Controller等注解风格 mvc:resources # css/js/htm等静态资源映射 增加View解析器: bean id=”velocityConfigurer” class=”org.springframework.web.servlet.view.velocity.VelocityConfigurer” bean id=”viewResolver” class=”org.springframework.web.servlet.view.velocity.VelocityViewResolver” 增加多数据源 bean id=”parentDataSource” class=”org.springframework.jdbc.datasource.DriverManagerDataSource” bean id=”adminDataSource” parent=”parentDataSource” # 数据源1 bean id=”userDataSource” parent=”parentDataSource” # 数据源2 bean id=”dataSource” class=”com.frogking.datasource.DynamicDataSource” # 多数源映射关系, property增加上面两个bean bean id=”sessionFactory” class=”org.springframework.orm.hibernate3.LocalSessionFactoryBean” 附: Configuration XML说明&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath*:spring/appcontext-*.xml&lt;/param-value&gt;&lt;/context-param&gt;&lt;listener id=\"ContextLoaderListener\"&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt;&lt;listener id=\"RequestContextListener\"&gt; &lt;listener-class&gt;org.springframework.web.context.request.RequestContextListener&lt;/listener-class&gt;&lt;/listener&gt;&lt;filter&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/api/2/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;&lt;servlet&gt; &lt;servlet-name&gt;comment&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:appcontext-core-web.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;comment&lt;/servlet-name&gt; &lt;url-pattern&gt;/api/*&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;&lt;error-page&gt; &lt;error-code&gt;400&lt;/error-code&gt; &lt;location&gt;/error.jsp&lt;/location&gt;&lt;/error-page&gt;","categories":[{"name":"13.JavaEE","slug":"13-JavaEE","permalink":"https://beefyheisenberg.github.io/categories/13-JavaEE/"}],"tags":[{"name":"JavaEE","slug":"JavaEE","permalink":"https://beefyheisenberg.github.io/tags/JavaEE/"},{"name":"Spring MVC","slug":"Spring-MVC","permalink":"https://beefyheisenberg.github.io/tags/Spring-MVC/"}]},{"title":"Spring Boot","slug":"13.JavaEE-Framework/JavaEE.SpringBoot","date":"2024-01-24T01:27:52.272Z","updated":"2024-01-24T01:27:52.273Z","comments":true,"path":"13.JavaEE-Framework/JavaEE.SpringBoot/","link":"","permalink":"https://beefyheisenberg.github.io/13.JavaEE-Framework/JavaEE.SpringBoot/","excerpt":"Spring Boot vs Spring 内置了嵌入式的Tomcat、Jetty等Servlet容器，应用可以不用打包成War格式，而是可以直接以Jar格式运行 Spring Boot提倡无XML配置文件的理念，使用Spring Boot生成的应用完全不会生成任何配置代码与XML配置文件。 提供了多个可选择的「starter」: spring-boot-starter-data-redis: spring-boot-starter-activemq: spring-boot-starter-jdbc: spring-boot-starter-web: spring-boot-starter-actuator: Spring Boot 全家桶","text":"Spring Boot vs Spring 内置了嵌入式的Tomcat、Jetty等Servlet容器，应用可以不用打包成War格式，而是可以直接以Jar格式运行 Spring Boot提倡无XML配置文件的理念，使用Spring Boot生成的应用完全不会生成任何配置代码与XML配置文件。 提供了多个可选择的「starter」: spring-boot-starter-data-redis: spring-boot-starter-activemq: spring-boot-starter-jdbc: spring-boot-starter-web: spring-boot-starter-actuator: Spring Boot 全家桶 @ref: https://gitee.com/yidao620/springboot-bucket Spring Boot 的新注解 @SpringBootApplication: 相当于 @Configuration + @EnableAutoConfiguration + @ComponentScan @Configuration : 指明是IOC容器的配置类, 被标注的类等于在spring的XML配置文件中(applicationContext.xml)，装配所有bean事务，提供了一个spring的上下文环境。 @EnableAutoConfiguration : SpringBoot根据应用所声明的依赖来对Spring框架进行自动配置。 @ComponentScan : 组件扫描，可自动发现和装配Bean，默认扫描SpringApplication的run方法里的Booter.class所在的包路径下文件，所以最好将该启动类放到根包路径下。 @RestController: 作用是将controller的方法返回的对象通过适当的转换器转换为指定的格式之后，写入到response对象的body区，通常用来返回JSON或者是XML。使用此注解之后不会再走视图处理器，而是直接将数据写入到输入流中，效果等同于通过向response.getOutputStream()写入数据 @ImportResource(locations = &#123;\"classpath:spring/spring-main.xml\"&#125;)@SpringBootApplicationpublic class MyApiApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(MyApiApplication.class, args); &#125;&#125; Spring CloudSpring Cloud 主要组件： Spring Cloud Config：配置管理工具包，让你可以把配置放到远程服务器，集中化管理集群配置，目前支持本地存储、Git 以及 Subversion。 Spring Cloud Bus：事件、消息总线，用于在集群（例如，配置变化事件）中传播状态变化，可与 Spring Cloud Config 联合实现热部署。 Zuul：Zuul 是在云平台上提供动态路由,监控,弹性,安全等边缘服务的框架。Zuul 相当于是设备和 Netflix 流应用的 Web 网站后端所有请求的前门。 Ribbon：提供云端负载均衡，有多种负载均衡策略可供选择，可配合服务发现和断路器使用。 Hystrix：熔断器，容错管理工具，旨在通过熔断机制控制服务和第三方库的节点,从而对延迟和故障提供更强大的容错能力。 Consul：封装了 Consul 操作，consul 是一个服务发现与配置工具，与 Docker 容器可以无缝集成。 Eureka：云端服务发现，一个基于 REST 的服务，用于定位服务，以实现云端中间层服务发现和故障转移。 Spring Cloud Cluster：提供 Leadership 选举，如：Zookeeper, Redis, Hazelcast, Consul 等常见状态模式的抽象和实现。 Spring Cloud Zookeeper：操作 Zookeeper 的工具包，用于使用 zookeeper 方式的服务发现和配置管理。 Spring Cloud Task：提供云端计划任务管理、任务调度。 Spring Cloud Data Flow：大数据操作工具，作为 Spring XD 的替代产品，它是一个混合计算模型，结合了流数据与批量数据的处理方式。 Spring Cloud Stream：数据流操作开发包，封装了与 Redis,Rabbit、Kafka 等发送接收消息。 @ref: Spring boot与Spring cloud 是什么关系？ - 知乎 https://www.springcloud.cc/","categories":[{"name":"13.JavaEE","slug":"13-JavaEE","permalink":"https://beefyheisenberg.github.io/categories/13-JavaEE/"}],"tags":[{"name":"JavaEE","slug":"JavaEE","permalink":"https://beefyheisenberg.github.io/tags/JavaEE/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://beefyheisenberg.github.io/tags/Spring-Boot/"}]},{"title":"Servelt and JSP","slug":"13.JavaEE-Framework/JavaEE.Servlet","date":"2024-01-24T01:27:52.267Z","updated":"2024-01-24T01:27:52.268Z","comments":true,"path":"13.JavaEE-Framework/JavaEE.Servlet/","link":"","permalink":"https://beefyheisenberg.github.io/13.JavaEE-Framework/JavaEE.Servlet/","excerpt":"Java Web应用Java Web 应用是一个 servlets, HTML 页面,类,和其他资源的集合，用于一个在 Web 服务器的完成的应用。Web 应用可以捆绑和运行来自多个供应商的在多个容器。servlet 容器必须强制 Web 应用程序和 ServletContext 之间一对一对应的关系。ServletContext 对象提供了一个 servlet 和它的应用程序视图。 目录结构可以使用标准的 Java 归档工具把 Web 应用程序打包并签名到一个 Web 存档格式（WAR）文件中。例如，一个关于“issue tracking”的应用程序可以分布在一个称为 issuetrack.war 的归档文件中。 当打包成这种形式时，将生成一个 META-INF 目录，其中包含了对 java归档工具有用的信息。尽管这个目录的内容可以通过 servlet 代码调用ServletContext 的 getResource 和 getResourceAsStream 方法来访问，容器也不能把这个目录当作内容来响应客户端请求。此外，任何请求访问 META-INF 目录中的资源必须返回一个 SC_NOT_FOUND（404）的响应。常见的归档格式war 和 ear格式对比：","text":"Java Web应用Java Web 应用是一个 servlets, HTML 页面,类,和其他资源的集合，用于一个在 Web 服务器的完成的应用。Web 应用可以捆绑和运行来自多个供应商的在多个容器。servlet 容器必须强制 Web 应用程序和 ServletContext 之间一对一对应的关系。ServletContext 对象提供了一个 servlet 和它的应用程序视图。 目录结构可以使用标准的 Java 归档工具把 Web 应用程序打包并签名到一个 Web 存档格式（WAR）文件中。例如，一个关于“issue tracking”的应用程序可以分布在一个称为 issuetrack.war 的归档文件中。 当打包成这种形式时，将生成一个 META-INF 目录，其中包含了对 java归档工具有用的信息。尽管这个目录的内容可以通过 servlet 代码调用ServletContext 的 getResource 和 getResourceAsStream 方法来访问，容器也不能把这个目录当作内容来响应客户端请求。此外，任何请求访问 META-INF 目录中的资源必须返回一个 SC_NOT_FOUND（404）的响应。常见的归档格式war 和 ear格式对比： war: Web Archive file, 结构如下: webapp.war |-index.jsp |— META-INF |-Manifest.mf |— WEB-INF |- web.xml |— classes |— lib // 依赖的jar包 ear: Enterprise ARchieve, 用于在Java EE中将一个或者多个模块封装到一个文件中, 这样, 多个不同模块在应用服务器上的部署就可以同时并持续的进行. 结构如下: app.ear |- ejb.jar // ejb-jar包 |- other.jar // 普通jar包 |- webapp.war // war包 |—META-INF application.xml // EAR描述文件 Web.xml中的元素 servlet3.*的规范已经支持不使用 web.xml了 &lt;?xml version=\"1.0\" encoding=\"ISO-8859-1\" ?&gt;&lt;web-app xmlns=\"http://java.sun.com/xml/ns/j2ee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/j2ee http://java.sun.com/xml/ns/j2ee/web-app_2_4.xsd\" version=\"2.4\"&gt; &lt;display-name&gt;HelloWorld Application&lt;/display-name&gt; &lt;description&gt; This is a simple web application with a source code organization based on the recommendations of the Application Developer's Guide. &lt;/description&gt; &lt;listener&gt; &lt;listener-class&gt;org.web.listener.MyServletRequestListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;listener&gt; &lt;listener-class&gt;org.web.listener.MyServletContextListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;filter&gt; &lt;filter-name&gt;ResponseFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.web.filter.ResponseFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;ResponseFilter&lt;/filter-name&gt; &lt;servlet-name&gt;HelloServlet&lt;/servlet-name&gt; &lt;/filter-mapping&gt; &lt;servlet&gt; &lt;servlet-name&gt;HelloServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.web.Servlet.Hello&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;HelloServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/hello&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; Servlet（Server Applet）本节参考自: Java Servlet 3.1 Specification《Java Servlet 3.1 规范》中文翻译及示例 @ref 什么是 Servletservlet 是基于 Java 的 Web 组件，由容器进行管理，来生成动态内容。像其他基于 Java 的组件技术一样，servlet 也是基于平台无关的 Java 类格式，被编译为平台无关的字节码，可以被基于 Java 技术的 Web 服务器动态加载并运行。容器（Container），有时候也叫做 servlet 引擎，是 Web 服务器为支持 servlet 功能扩展的部分。客户端通过 servlet 容器实现的 request/response paradigm（请求/应答模式） 与 Servlet 进行交互。 什么是 Servlet 容器Servlet Container（Servlet 容器） 是 Web 服务器或者应用服务器的一部分，用于提供基于请求/响应发送模式的网络服务，解码基于 MIME 的请求，并且格式化基于 MIME 的响应。Servlet 容器同时也包含和管理他们的生命周期里 Servlet。JavaEE.Tomcat Servlet 容器可以嵌入到宿主的 Web 服务器中，或者通过 Web 服务器的本地扩展 API 单独作为附加组件安装。Servelt 容器也可能内嵌或安装到启用 Web 功能的应用服务器中。 所有的 Servlet 容器必须支持 HTTP 协议用于请求和响应，但额外的基于请求/响应的协议，如 HTTPS (HTTP over SSL)的支持是可选的。对于 HTTP 规范需要版本，容器必须支持 HTTP/1.0 和 HTTP/1.1。因为容器或许支持 RFC2616 (HTTP/1.1)描述的缓存机制，缓存机制可能在将客户端请求交给 Servlet 处理之前修改它们，也可能在将 Servlet 生成的响应发送给客户端之前修改它们，或者可能根据 RFC2616 规范直接对请求作出响应而不交给 Servlet 进行处理。 Servlet 容器应该使 Servlet 执行在一个安全限制的环境中。在 Java 平台标准版（J2SE, v.1.3 或更高） 或者 Java 平台企业版(Java EE, v.1.3 或更高) 的环境下，这些限制应该被放置在 Java 平台定义的安全许可架构中。比如，高端的应用服务器为了保证容器的其他组件不受到负面影响可能会限制 Thread 对象的创建。 Servlet 与其他技术的对比从功能上看，servlet 位于 Common Gateway Interface（公共网关接口，简称 CGI）程序和私有的服务器扩展如 Netscape Server API（NSAPI）或 Apache Modules 这两者之间。相对于其他服务器扩展机制 Servlet 有如下优势： 它们通常比 CGI 脚本更快，因为采用不同的处理模型。 它们采用标准的 API 从而支持更多的Web 服务器。 它们拥有 Java 编程语言的所有优势，包括容易开发和平台无关。 它们可以访问 Java 平台提供的大量的 API。 与 Java EE 的关系Java Servlet API 3.1 版本是 Java 平台企业版 7 版本必须的 API。Servlet 容器和 servlet 被部署到平台中时，为了能在 Java EE 环境中执行，必须满足 JavaEE 规范中描述的额外的一些要求。 与 Servlet 2.5 规范的兼容性在 Servlet 2.5 中, metadata-complete 只影响在部署时的注释扫描。 web-fragments 的概念在 servlet 2.5 并不存在。然而在 servlet 3.0 和之后,metadata-complete 影响扫描所有的在部署时指定部署信息和 web-fragments 注释。注释的版本的描述符必须不影响你扫描在一个web应用程序。除非 metadata-complete 指定，规范的一个特定版本的实现必须扫描所有配置的支持的注解。 定义 Servletweb.xml (1)、为Servlet命名：&lt;servlet&gt; &lt;servlet-name&gt;servlet1&lt;/servlet-name&gt; &lt;servlet-class&gt;org.whatisjava.TestServlet&lt;/servlet-class&gt;&lt;/servlet&gt;(2)、为Servlet定制URL：&lt;servlet-mapping&gt; &lt;servlet-name&gt;servlet1&lt;/servlet-name&gt; &lt;url-pattern&gt;*.do&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; -》 Spring Framework定义的 DispatcherServlet @ref: [[JavaEE.SpringMVC.md]] HttpServletRequest – 请求本节参考 请求 · Java Servlet 3.1 Specification《Java Servlet 3.1 规范》中文翻译及示例 @ref 生命周期每个请求对象只在一个 servlet 的 service 方法的作用域内，或过滤器的 doFilter 方法的作用域内有效，除非该组件启用了异步处理并且调用了请求对象的 startAsync 方法。在发生异步处理的情况下，请求对象一直有效，直到调用 AsyncContext 的 complete 方法。容器通常会重复利用请求对象，以避免创建请求对象而产生的性能开销。开发人员必须注意的是，不建议在上述范围之外保持 startAsync 方法还没有被调用的请求对象的引用，因为这样可能产生不确定的结果。 APIServletRequest 接口提供方法: getParameter getParameterNames getParameterValues getParts getPart getAttribute getHeader/getHeaders getContextPath … 文件上传当数据以multipart/form-data的格式发送时，servlet 容器支持文件上传。 头 getAttribute getAttributeNames setAttribute 属性 getAttribute getAttributeNames setAttribute 请求路径 getContextPath getServletPath getPathInfo requestURI = contextPath + servletPath + pathInfo 非阻塞 IO非阻塞 IO · Java Servlet 3.1 Specification《Java Servlet 3.1 规范》中文翻译及示例 ServletResponse – 响应响应 · Java Servlet 3.1 Specification《Java Servlet 3.1 规范》中文翻译及示例 ServletContext – 上下文ServletContext 接口定义了 servlet 运行在的 Web 应用的视图。容器供应商负责提供 servlet 容器的 ServletContext 接口的实现。servlet 可以使用 ServletContext 对象记录事件，获取 URL 引用的资源，存取当前上下文的其他 servlet 可以访问的属性。ServletContext 是 Web 服务器中已知路径的根。例如，servlet 上下文可以从 http://www.mycorp.com/catalog 找出，/catalog 请求路径称为上下文路径，所有以它开头的请求都会被路由到与 ServletContext 相关联的 Web 应用。 Filter – 过滤器过滤器是一种代码重用的技术，它可以转换 HTTP 请求的内容，响应，及头信息。过滤器通常不产生响应或像 servlet 那样对请求作出响应，而是修改或调整到资源的请求，修改或调整来自资源的响应。 在web.xml中声明的每个&lt;filter&gt;在每个 JVM 的容器中仅实例化一个实例。容器提供了声明在过滤器的部署描述符的过滤器config（译者注：FilterConfig），对 Web 应用的 ServletContext 的引用，和一组初始化参数。当容器接收到传入的请求时，它将获取列表中的第一个过滤器并调用doFilter 方法，传入 ServletRequest 和 ServletResponse，和一个它将使用的 FilterChain 对象的引用。 过滤器组件示例 Authentication filters //用户身份验证过滤器 Logging and auditing filters //日志记录与审计过滤器 Image conversion filters //图片转换过滤器 Data compression filters //数据压缩过滤器 Encryption filters //加密过滤器 Tokenizing filters //分词过滤 Filters that trigger resource access events //触发资源访问事件过滤 XSL/T filters that transform XML content MIME-type chain filters //MIME-TYPE 链过滤器 Caching filters //缓存过滤器 Listener – 监听器Listener 用于监听 java web程序中的事件，例如创建、修改、删除Session、request、context等，并触发响应的事件。Listener 对应观察者模式，事件发生的时候会自动触发该事件对应的Listeer。 Listener 主要用于对 Session、Request、Context 进行监控。servlet2.5 规范中共有 8 种Listener 。 不同功能的Listener 需要实现不同的 Listener 接口，一个Listener也可以实现多个接口，这样就可以多种功能的监听器一起工作。监听器接口可以分为三类： 1）监听 Session、Request、Context 的创建于销毁，分别为 HttpSessionLister、ServletContextListener、ServletRequestListener 2）监听对象属性变化，分别为：HttpSessionAttributeLister、ServletContextAttributeListener、ServletRequestAttributeListener 3）监听Session 内的对象，分别为HttpSessionBindingListener 和 HttpSessionActivationListener。与上面六类不同，这两类 Listener 监听的是Session 内的对象，而非 Session 本身，不需要在 web.xml中配置。 实现一个Listenerweb.xml的Listener配置： &lt;listener&gt;标签与 &lt;listener-class&gt; &lt;listener&gt; &lt;listener-class&gt;servlet.listener.MyListener&lt;/listener-class&gt;&lt;/listener&gt; 创建 MyListener, 实现监听对Session, Context, Request对象的创建与销毁: public class MyListener implements HttpSessionListener, ServletContextListener, ServletRequestListener &#123; Log log = LogFactory.getLog(getClass()); // 创建 session @Override public void sessionCreated(HttpSessionEvent se) &#123; HttpSession session = se.getSession(); log.info(\"新创建一个session, ID为: \" + session.getId()); &#125; // 销毁 session @Override public void sessionDestroyed(HttpSessionEvent se) &#123; HttpSession session = se.getSession(); log.info(\"销毁一个session, ID为: \" + session.getId()); &#125; // 加载 context @Override public void contextInitialized(ServletContextEvent sce) &#123; ServletContext servletContext = sce.getServletContext(); log.info(\"即将启动\" + servletContext.getContextPath()); &#125; // 卸载 context @Override public void contextDestroyed(ServletContextEvent sce) &#123; ServletContext servletContext = sce.getServletContext(); log.info(\"即将关闭\" + servletContext.getContextPath()); &#125;&#125; HttpSession – 会话会话跟踪机制: Cookie: 通过 HTTP cookie 的会话跟踪是最常用的会话跟踪机制，且所有 servlet 容器都应该支持。所有 servlet 容器必须提供能够配置容器是否标记会话跟踪 cookie 为HttpOnly的能力。 SSL会话: 安全套接字层(Secure Sockets Layer)，在 HTTPS 使用的加密技术，有一种内置机制允许多个来自客户端的请求被明确识别为同一会话。Servlet容器可以很容易地使用该数据来定义会话。 URL 重写: URL 重写是会话跟踪的最低标准。当客户端不接受 cookie 时，服务器可使用 URL 重写作为会话跟踪的基础。URL 重写涉及添加数据、会话 ID、容器解析 URL 路径从而请求与会话相关联。 Dispatcher – 分发器RequestDispatcher 接口负责把请求转发给一个 servlet 处理；当请求启用异步处理时，AsyncContext 允许用户将这个请求转发到servlet 容器。 可以通过ServletContext.getRequestDispatcher()获取 RequestDispatcher. 使用请求调度器: include 方法: include 方法的目标 servlet 能够访问请求对象的各个方法（all aspects），但是使用响应对象的方法会受到更多限制。 forward 方法: RequestDispatcher 接口的 forward() 方法，只有在没有输出提交到向客户端时，通过正在被调用的 servlet 调用。如果响应缓冲区中存在尚未提交的输出数据，这些数据内容必须在目标 servlet 的 service() 方法调用前清除。如果响应已经提交，必须抛出一个 IllegalStateException 异常。 String path = “/raisins.jsp”;RequestDispatcher rd = context.getRequestDispatcher(path);rd.include(request, response); 生命周期Servlet 生命周期当容器启动后, 容器会判断内存中是否存在指定的 Servlet对象, 如果没有则创建它, 当容器停止或者重新启动, Servlet容器调用 Servlet对象的 destroy方法来释放资源;Servlet生命周期分几个步骤: Servlet类加载 -&gt; 实例化 -&gt; 服务 -&gt; 销毁: Servlet容器 负责加载 Servlet类 Servlet容器 使用开始实例化 Servlet, 创建对象并调用 init()方法 响应客户请求阶段调用 service()方法 销毁阶段调用 destroy()方法 Request 生命周期接收到HTTP请求后, 容器会创建 HttpServletRequest对象, 并传递给 Servlet, 在这次请求结束后, Request对象也被销毁;每个请求对象只在一个 servlet 的 service() 方法的作用域内, 或过滤器的 doFilter() 方法的作用域内有效,除非该组件启用了异步处理并且调用了请求对象的 startAsync() 方法. 在发生异步处理的情况下, 请求对象一直有效, 直到调用 AsyncContext 的 complete() 方法. 并发 &amp; 多线程问题因为 Servlet 规范的特点，Servlet 容器（如 Tomcat）一般采用多线程来处理多个请求同时访问，Servlet 容器维护了一个线程池来服务请求。线程池实际上是等待执行代码的一组线程叫做工作者线程(WorkerThread)，Servlet容器使用一个调度线程来管理工作者线程(DispatcherThread)。当容器收到一个访问Servlet的请求，调度者线程从线程池中选出一个工作者线程，将请求传递给该线程，然后由该线程来执行Servlet的service()方法。当这个线程正在执行的时候，容器收到另外一个请求，调度者线程将从池中选出另外一个工作者线程来服务新的请求，容器并不关心这个请求是否访问的是同一个Servlet还是另外一个Servlet。当容器同时收到对同一Servlet的多个请求，那这个Servlet的service()方法将在多线程中并发的执行。 同步service()的两种方式: Servlet实现SingleThreadModel接口: 开发人员实现 SingleThreadModel 接口，由容器保证一个 service() 方法在同一个时间点仅被一个请求线程调用，但是此方案是不推荐的。servlet 容器可以通过串行化访问 servlet的请求，或者维护一个 servlet 实例池完成该需求。如果 Web 应用中的 servlet 被标注为分布式的，容器应该为每一个分布式应用程序的 JVM 维护一个 servlet 实例池。 synchronized同步service()方法, 不建议使用: 对于那些没有实现 SingleThreadModel 接口的 servlet，但是它的service() 方法（或者是那些 HttpServlet 中通过 service 方法分派的doGet、doPost 等分派方法）是通过 synchronized 关键词定义的，servlet 容器不能使用实例池方案，并且只能使用序列化请求进行处理。强烈推荐开发人员不要去同步 service() 方法（或者那些由 service() 分派的方法），因为这将严重影响性能。 线程不安全这就导致了Servlet里的实例变量是线程不安全的,多个线程（多个客户端的请求）共享这些实例变量，一个线程对这些实例变量的改变会影响其它线程的取值，Servlet规范已经声明Servlet不是线程安全的,包括jsp,Servlet,javabean等。 ServletContext：（线程不安全） ServletContext是可以多线程同时读/写属性的，线程是不安全的。要对属性的读写进行同步处理或者进行深度Clon。所以在Servlet上下文中尽可能少量保存会被修改（写）的数据，可以采取其他方式在多个Servlet中共享，比方我们可以使用单例模式来处理共享数据。 HttpSession：（线程不安全） HttpSession对象在用户会话期间存在，只能在处理属于同一个Session的请求的线程中被访问，因此Session对象的属性访问理论上是线程安全的。当用户打开多个同属于一个进程的浏览器窗口，在这些窗口的访问属于同一个Session，会出现多次请求，需要多个工作线程来处理请求，可能造成同时多线程读写属性。这时我们需要对属性的读写进行同步处理：使用同步块Synchronized和使用读/写器来解决。 ServletRequest：（线程安全） 对于每一个请求，由一个工作线程来执行，都会创建有一个新的ServletRequest对象，所以ServletRequest对象只能在一个线程中被访问。ServletRequest是线程安全的。ServletRequest对 象在service方法的范围内是有效的，不要试图在service方法结束后仍然保存请求对象的引用。 http://wenboo.site/2016/11/14/Servlet-%E5%B9%B6%E5%8F%91%E5%B0%8F%E7%BB%93/ 异步 &amp; AsyncContext@ref Servlet 3.0/3.1 中的异步处理 在Servlet 3.0之前，Servlet采用Thread-Per-Request的方式处理请求，即每一次Http请求都由某一个线程从头到尾负责处理。如果一个请求需要进行IO操作，比如访问数据库、调用第三方服务接口等，那么其所对应的线程将同步地等待IO操作完成， 而IO操作是非常慢的，所以此时的线程并不能及时地释放回线程池以供后续使用，在并发量越来越大的情况下，这将带来严重的性能问题。为了解决这样的问题，Servlet 3.0引入了异步处理，然后在Servlet 3.1中又引入了非阻塞IO来进一步增强异步处理的性能。 在Servlet 3.0中，@WebServlet 和 @WebFilter 注解有一个属性——asyncSupported，boolean 类型默认值为 false。当 asyncSupported 设置为 true，我们可以从HttpServletRequest对象中通过startAsync()获得一个AsyncContext对象，AsyncContext对象构成了异步处理的上下文，Request和Response对象都可从中获取。AsyncContext 可以从当前线程传给另外的线程，并在新的线程中完成对请求的处理并返回结果给客户端，当前请求的线程便可以还回给容器线程池以处理更多的请求。 一个有较长耗时操作的Servlet可以这样写： @WebServlet(value = \"/simpleAsync\", asyncSupported = true)public class SimpleAsyncHelloServlet extends HttpServlet &#123; protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; AsyncContext asyncContext = request.startAsync(); asyncContext.start(() -&gt; &#123; new LongRunningProcess().run(); try &#123; asyncContext.getResponse().getWriter().write(\"Hello World!\"); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; asyncContext.complete(); &#125;); &#125;&#125; 先通过request.startAsync()获取到该请求对应的AsyncContext，然后调用AsyncContext的start()方法进行异步处理，处理完毕后需要调用AsyncContext.complete()方法告知Servlet容器。AsyncContext.start()方法会向Servlet容器另外申请一个新的线程（可以是从Servlet容器中已有的主线程池获取，也可以另外维护一个线程池，不同容器实现可能不一样），然后在这个新的线程中继续处理请求，而原先的线程将被回收到主线程池中。事实上，这种方式对性能的改进不大，因为如果新的线程和初始线程共享同一个线程池的话，相当于闲置下了一个线程，但同时又占用了另一个线程。 这里有一篇文章The Limited Usefulness of AsyncContext.start() - DZone Java,对该方法做了性能测试, 结论如下 : Tomcat 的 AsyncContext.start 实现是, 把处理 Request 的线程放入 Http work threadpool 线程池执行 在 Tomcat中使用 Servlet3.0 的 AsyncContext.start 不会带来任何 Tomcat并发性能改进 正确的办法是另外维护一个线程池，这个线程池不同于Servlet容器的主线程池（请求线程池），如下图： 在上图中，用户发起的请求首先交由Servlet容器主线程池（请求线程池）中的线程处理，在该线程中，我们获取到AsyncContext，然后将其交给异步处理线程池。请求线程可以被归还回主线程池，这样主线程池用来处理 Http请求的线程没有被长时间占用。但是需要注意的是，这种做法可以及时归还请求线程，但在仍旧占用另一个线程，所以 JVM 的线程总数没有减少，系统瓶颈仍旧在 JVM 进程的最大线程数上（单个线程的栈大小默认是 -Xss1M） 代码如下： @WebServlet(value = \"/threadPoolAsync\", asyncSupported = true)public class ThreadPoolAsyncHelloServlet extends HttpServlet &#123; private static ThreadPoolExecutor executor = new ThreadPoolExecutor(100, 200, 50000L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue&lt;&gt;(100)); protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; AsyncContext asyncContext = request.startAsync(); executor.execute(() -&gt; &#123; new LongRunningProcess().run(); try &#123; asyncContext.getResponse().getWriter().write(\"Hello World!\"); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; asyncContext.complete(); &#125;); &#125;&#125; Requet 和 Response的非阻塞IOServlet 3.0对请求的处理虽然是异步的，但是对InputStream和OutputStream的IO操作却依然是阻塞的，对于数据量大的请求体或者返回体，阻塞IO也将导致不必要的等待。因此在Servlet 3.1中引入了非阻塞IO（参考下图红框内容），通过在HttpServletRequest和HttpServletResponse中分别添加ReadListener和WriterListener方式，只有在IO数据满足一定条件时（比如数据准备好时），才进行后续的操作。 对应的代码示例子: @WebServlet(value = \"/nonBlockingThreadPoolAsync\", asyncSupported = true)public class NonBlockingAsyncHelloServlet extends HttpServlet &#123; private static ThreadPoolExecutor executor = new ThreadPoolExecutor(100, 200, 50000L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue&lt;&gt;(100)); protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; AsyncContext asyncContext = request.startAsync(); ServletInputStream inputStream = request.getInputStream(); inputStream.setReadListener(new ReadListener() &#123; @Override public void onDataAvailable() throws IOException &#123; &#125; @Override public void onAllDataRead() throws IOException &#123; executor.execute(() -&gt; &#123; new LongRunningProcess().run(); try &#123; asyncContext.getResponse().getWriter().write(\"Hello World!\"); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; asyncContext.complete(); &#125;); &#125; @Override public void onError(Throwable t) &#123; asyncContext.complete(); &#125; &#125;); &#125;&#125; 在上例中，我们为ServletInputStream添加了一个ReadListener，并在ReadListener的onAllDataRead()方法中完成了长时处理过程。 异常处理servlet 在处理一个请求时可能抛出 ServletException 或UnavailableException 异常。 ServletException 表示在处理请求时出现了一些错误，容器应该采取适当的措施清理掉这个请求。 UnavailableException 表示 servlet 目前无法处理请求，或者临时性的或者永久性的： 如果 UnavailableException 表示的是一个永久性的不可用，servlet 容器必须从服务中移除这个 servlet，调用它的 destroy 方法，并释放servlet 实例。所有被容器拒绝的请求，都会返回一个 SC_NOT_FOUND (404) 响应。 如果 UnavailableException 表示的是一个临时性的不可用，容器可以选择在临时不可用的这段时间内路由任何请求到 Servlet。所以在这段时间内被容器拒绝的请求，都会返回一个 SC_SERVICE_UNAVAILABLE (503) 响应状态码，且同时会返回一个 Retry-After 头指示此 servlet 什么时候可用。容器可以选择忽略永久性和临时性不可用的区别，并把UnavailableException 视为永久性的，从而 servlet 抛出UnavailableException 后需要把它从服务中移除。 Servlet API@ref: JavaTM Platform, Enterprise Edition 6 API Specificatio https://waylau.gitbooks.io/servlet-3-1-specification Servlet Servlet[I]: 属于javax.servlet包 init() destroy() service(ServletRequest, ServletResponse) HttpServlet: 属于javax.servlet.http包 service(): 根据method调用: doHead(), doGet(), doPost() … DispatcherServlet : 属于org.springframework.web.servlet包 doService() : 调用了doDispatch() doDispatch() : 从这里调用进@Controller中相关的方法 ServletConfig对应web.xml的&lt;servlet&gt;, ServletConfig对象中维护了ServletContext对象的引用，开发人员在编写servlet时，可以通过ServletConfig.getServletContext方法获得ServletContext对象常用方法: getServletName： getServletContext： ServletContext对应web.xml的&lt;context-param&gt;, 容器中部署的每一个web应用都有一个ServletContext接口的实例对象与之关联常用方法: getInitParameter / getInitParameterNames addFilter addListener addServlet 在任何Servlet实现类中可以使用this.getServletContext获取Context Filter init / destroy doFilter FilterChain Response: ServletResponse[I] getOutputStream() / getWriter() flushBuffer() HttpServletResponse[I] addCookie setHeader HttpServletResponseWrapper Request: ServletRequest[I] getInputStream() / getReader() getParameter / getAttribute startAsync() HttpServletRequest[I] getContextPath(), getServletPath(), getPathInfo() getRequestURI() / getRequestURL() HttpServletRequestWrapper IO Stream ServletInputStream: readLine ServletOutputStream: print / println RequestDispatcherRequestDispatcher对象由Servlet容器来创建, 封装一个由路径所标识的服务器资源.在Servlet实现类中获取dispatcher对象: this.getServletContext().getRequestDispatcher(&quot;/api/v2/topic/load&quot;) 获取RequestDispatcher对象 ServletRequest的getRequestDispatcher(String path)方法 ServletContext的getNamedDispatcher(String path)和getRequestDispatcher(String path)方法 RequestDispatcher.forward(ServletRequest, ServletResponse) : 类似php里的inclde, 在返回页面中包括其他资源 RequestDispatcher.include(ServletRequest, ServletResponse) : 转发 request.getRequestDispatcher(&quot;/2.html&quot;).include(request, response); // 在当前页面包含2.htmlrequset.getRequestDisPatcher(&quot;/servlet2&quot;).dispatcher.forward(request, response); // 转发到servlet2 JSP（JavaServer Pages）Servlet &amp; JSP 区别与联系 Servlet在Java代码中通过HttpServletResponse对象动态输出HTML内容 JSP在静态HTML内容中嵌入Java代码, Java代码被动态执行后生成HTML内容, JSP的本质仍是Servlet, JSP编译之后生成的*.java文件和*.class里有什么? Servlet是被Context的类加载器加载的, 所以重写Servlet需要重新部署Context, JSP有自己的加载器, JSP文件在修改之后不需要”重新加载” 语法 代码段 &lt;% ... %&gt; 声明: &lt;%! ... &gt; &lt;%! int i = 0; %&gt;&lt;%! int a, b, c; %&gt; 表达式: &lt;p&gt; 今天的日期是: &lt;%= (new java.util.Date()).toLocaleString()%&gt;&lt;/p&gt; 动作元素 jsp:include : 在页面被请求的时候引入一个文件。 jsp:useBean : 寻找或者实例化一个JavaBean。&lt;jsp:useBean id=\"myName\" ... &gt; &lt;jsp:setProperty name=\"myName\" property=\"someProperty\" .../&gt;&lt;/jsp:useBean&gt;","categories":[{"name":"13.JavaEE","slug":"13-JavaEE","permalink":"https://beefyheisenberg.github.io/categories/13-JavaEE/"}],"tags":[{"name":"JavaEE","slug":"JavaEE","permalink":"https://beefyheisenberg.github.io/tags/JavaEE/"},{"name":"Servlet","slug":"Servlet","permalink":"https://beefyheisenberg.github.io/tags/Servlet/"},{"name":"JSP","slug":"JSP","permalink":"https://beefyheisenberg.github.io/tags/JSP/"}]},{"title":"Java JPA & ORM框架","slug":"13.JavaEE-Framework/JavaEE.ORM&JPA","date":"2024-01-24T01:27:52.262Z","updated":"2024-01-24T01:27:52.263Z","comments":true,"path":"13.JavaEE-Framework/JavaEE.ORM&JPA/","link":"","permalink":"https://beefyheisenberg.github.io/13.JavaEE-Framework/JavaEE.ORM&JPA/","excerpt":"一些概念：JDBC &amp; PJA &amp; ORMJDBC (Java Database Connectivity) API，即Java数据库编程接口，是一组标准的Java语言中的接口和类，使用这些接口和类，Java客户端程序可以访问各种不同类型的数据库。 JPA 全称为Java Persistence API ，Java持久化API是Sun公司在Java EE 5规范中提出的Java持久化接口。JPA吸取了目前Java持久化技术的优点，旨在规范、简化Java对象的持久化工作。使用JPA持久化对象，并不是依赖于某一个ORM框架。JPA规范本质上就是一种ORM规范，注意不是ORM框架——因为JPA并未提供ORM实现，它只是制订了一些规范，提供了一些编程的API接口，但具体实现则由服务厂商来提供实现，JBoss应用服务器底层就以Hibernate作为JPA的实现。虽然 ORM 框架都实现了 JPA 规范，但是在不同 ORM 框架之间切换是需要编写的代码有一些差异，而通过使用 Spring Data Jpa 能够方便大家在不同的 ORM 框架中间进行切换而不要更改代码。并且 Spring Data Jpa 对 Repository 层封装的很好，可以省去不少的麻烦。","text":"一些概念：JDBC &amp; PJA &amp; ORMJDBC (Java Database Connectivity) API，即Java数据库编程接口，是一组标准的Java语言中的接口和类，使用这些接口和类，Java客户端程序可以访问各种不同类型的数据库。 JPA 全称为Java Persistence API ，Java持久化API是Sun公司在Java EE 5规范中提出的Java持久化接口。JPA吸取了目前Java持久化技术的优点，旨在规范、简化Java对象的持久化工作。使用JPA持久化对象，并不是依赖于某一个ORM框架。JPA规范本质上就是一种ORM规范，注意不是ORM框架——因为JPA并未提供ORM实现，它只是制订了一些规范，提供了一些编程的API接口，但具体实现则由服务厂商来提供实现，JBoss应用服务器底层就以Hibernate作为JPA的实现。虽然 ORM 框架都实现了 JPA 规范，但是在不同 ORM 框架之间切换是需要编写的代码有一些差异，而通过使用 Spring Data Jpa 能够方便大家在不同的 ORM 框架中间进行切换而不要更改代码。并且 Spring Data Jpa 对 Repository 层封装的很好，可以省去不少的麻烦。 ORM :对象关系映射（Object Relational Mapping，简称 ORM）是一种为了解决面向对象与关系数据库存在的互不匹配的现象的技术。简单的说，ORM 是通过使用描述对象和数据库之间映射的元数据，将 java 程序中的对象自动持久化到关系数据库中。 从 JDBC 到 ORMJDBC 规范对与数据库的交互做了如下抽象：用 Connection 代表和数据库的连接，用 Statement 执行 SQL，用 ResultSet 表示 SQL 返回的结果，提供了对数据的遍历。从 Connection 可以创建 Statement，Statement 执行查询得到 ResultSet。 Connection、Statement、ResultSet 都是接口，具体实现由各个数据库提供商提供。可以通过 JDBC统一的接口，访问多种类型的数据库，可随便切换数据库。 下面是一个例子： Connection conn = null;PreparedStatement ps = null;ResultSet rs = null;try &#123; //1. 加载驱动 Class.forName(\"com.mysql.jdbc.Driver\"); //2. 获取连接 conn = DriverManager.getConnection(\"jdbc:mysql://localhost:3306/dropnotes?serverTimezone=UTC\", \"user\", \"pwd\"); //3. 创建 PreparedStatement ps = conn.prepareStatement(\"select * from notes\"); //4. 执行sql rs = ps.executeQuery(); //5. 遍历结果集 while(rs.next()) &#123; System.out.println(rs.getString(2)); &#125;&#125; catch (ClassNotFoundException e) &#123; e.printStackTrace();&#125; catch (SQLException e) &#123; e.printStackTrace();&#125;finally &#123; try &#123; rs.close(); ps.close(); conn.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125;&#125; JDBC1 提供了 DriverManager 用于加载数据库驱动 &amp; 获取 connection ，但这种方式显然不方便，需要自己管理 connection ，频繁建立 &amp; 释放 connection 性能也不高。 DriverManager 中使用了 SPI 模式来加载数据库 Driver Jar 包 @ref：Java常用机制 - SPI机制详解 | Java 全栈知识体系 在 JDBC2 中支持了 DataSource 的方式，DataSource 包含连接池和连接池管理2个部分，习惯上称为 #数据库连接池 。在初始化的时候，建立一些 connection 对象并存储在缓存中，当需要访问数据库时，从连接池中取出一个已建立的空闲 connection 对象。 DataSource 也只是一个规范，具体的实现有 dbcp、c3p0、druid ，使用 c3p0 连接池的代码如下： public static ComboPooledDataSource dataSource = new ComboPooledDataSource();public static void dataSource()&#123; try &#123; dataSource.setDriverClass(\"com.mysql.jdbc.Driver\"); dataSource.setJdbcUrl(\"jdbc:mysql://localhost:3306/test?serverTimezone=UTC\"); dataSource.setUser(\"root\"); dataSource.setPassword(\"123456\"); dataSource.setInitialPoolSize(3); dataSource.setMaxPoolSize(10); dataSource.setMinPoolSize(3); dataSource.setAcquireIncrement(3); &#125; catch (PropertyVetoException e) &#123; e.printStackTrace(); &#125;&#125;public static Connection conn() &#123; Connection conn = null; dataSource(); try &#123; conn = dataSource.getConnection(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; return conn;&#125; 使用了连接池后，无需手动管理 connection 释放，方便了很多，但此时还是需要手动写 Statement 和 ResultSet 的代码。 这时候就需要使用 ORM（对象关系映射），主要解决数据库数据和 POJO 对象的相互映射，就不需要手动写 SQL 了 选型对比Spring JPA - MyBatisSpring Data JPA or Mybatis? Jpa（Java Persistence API）是 sun 官方提出的 java 持久化规范。它为 java 开发人员提供了一种对象/关联映射工具，来管理 java 应用中的关系数据。它的出现主要是为了简化现有的持久化开发工作和整合 ORM 技术，结束现在 hibernate、toplink、jdo 等 ORM 框架各自为营的局面。 值得注意的是，Jpa 是在充分吸收了现有 ORM 框架的基础上发展而来的，具有易于使用，伸缩性强等优点。从目前的开发社区的反应上看，Jpa 受到了极大的支持和赞扬，其中就包括了 spring 和 EJB 的开发团队。 Spring Data Jpa 是 Spring 基于 ORM 框架、JPA 规范的基础上封装的一套 Jpa 应用框架，可使开发者用极简的代码即可实现对数据库的访问和操作。它提供了包括增删改查等在内的常用功能，且易于扩展 MyBatis 本是 apache 的一个开源项目 iBatis, 2010年这个项目由 apache software foundation 迁移到了 google code，并且改名为 MyBatis 。Mybatis：着力于 POJO 与 SQL 之间的映射关系 Spring Data JPA 默认使用 hibernate 作为 ORM。我们再看看 hibernate 的官方概念，Hibernate 是一个开放源代码的对象关系映射框架，它对 JDBC 进行了非常轻量级的对象封装，它将 POJO 与数据库表建立映射关系，是一个全自动的 orm 框架，hibernate 可以自动生成 SQL 语句 @ref: SpringBoot开发使用Mybatis还是Spring Data JPA?? - 知乎 使用 Spring Data Jpa 仅需要定义接口，并继承 JpaRepository 接口，不需要编写实现类，也不需要编写 XML 映射文件。Spring Data Jpa 默认提供简单的 CRUD 方法，并支持自动根据方法名生成 SQL，提供注解方式动态生成 SQL，也支持分页、排序。 个人更喜欢在分布式微服务项目中使用 Spring Data Jpa，特别是使用领域驱动设计架构设计的项目，而在管理后台项目使用 Mybatis。 因为管理后台需要更灵活的查询支持，经常写些复杂的 SQL，在这方面 Jpa 显得较弱势，而分布式微服务项目实现业务的核心逻辑，只需要用到简单的数据查询、删增改，因此较适合使用 Jpa。 @ref: Mybatis与Spring Data Jpa怎么选？ - 掘金 Hibernate - MyBatisHibernate 和 Mybatis 都是 ORM 持久层框架， Hibernate 提供的是一种全表映射的模型，对 JDBC 的封装程度比较高。但 Hibernate 也有不少缺点： 全表映射带来的不便，比如更新时需要发送所有的字段； 无法根据不同的条件组装不同的SQL； 对多表关联和复杂SQL查询支持较差，需要自己写SQL，返回后，需要自己将数据组装为POJO； 不能有效支持存储过程； 虽然有HQL，但性能较差，大型互联网系统往往需要优化SQL，而Hibernate做不到。 大型互联网环境中，灵活、SQL 优化，减少数据的传递是最基本的优化方法，Hibernate 无法满足要求，而 MyBatis 是一个半自动映射的框架，提供了更灵活、方便的方式。 MyBatis需要手工匹配提供POJO、SQL和映射关系，而全表映射的Hibernate只需要提供POJO和映射关系。 Spring Data JPAMyBatis在 Spring 项目中引入 MyBatis 支持 @link JavaEE.SpringMVC主要是定义 SqlSessionFactory、DataSource 和 Mapper。 Mybatis 四大核心类： SqlSessionFactoryBuilder：会根据配置信息或代码来生成 SqlSessionFactory； SqlSessionFactory：依靠工厂来生成SqlSession； SqlSession：是一个既可以发送SQL去执行并返回结果，也可以获取Mapper的接口； SQL Mapper：是MyBatis新设计的组件，由一个Java接口和XML文件构成，需要给出对应的SQL和映射规则。它负责发送SQL去执行，并返回结果。 MyBatis 3 | 入门 通过源码深入理解 SQL 的执行过程 MyBatis的架构设计以及实例分析 Hibernate Hibernate 教程","categories":[{"name":"13.JavaEE","slug":"13-JavaEE","permalink":"https://beefyheisenberg.github.io/categories/13-JavaEE/"}],"tags":[{"name":"JavaEE","slug":"JavaEE","permalink":"https://beefyheisenberg.github.io/tags/JavaEE/"},{"name":"ORM","slug":"ORM","permalink":"https://beefyheisenberg.github.io/tags/ORM/"},{"name":"MyBatis","slug":"MyBatis","permalink":"https://beefyheisenberg.github.io/tags/MyBatis/"},{"name":"Hibernate","slug":"Hibernate","permalink":"https://beefyheisenberg.github.io/tags/Hibernate/"}]},{"title":"Java日志框架（JCL,SLF4J,Log4J,Logback）","slug":"13.JavaEE-Framework/JavaEE.Log","date":"2024-01-24T01:27:52.258Z","updated":"2024-01-24T01:27:52.259Z","comments":true,"path":"13.JavaEE-Framework/JavaEE.Log/","link":"","permalink":"https://beefyheisenberg.github.io/13.JavaEE-Framework/JavaEE.Log/","excerpt":"日志框架简介 Commons Logging和SLF4J是java中的 日志门面(Facade)，即它们提供了一套通用的接口，具体的实现可以由开发者自由选择。 Log4j（以及最新的log4j 2）和Logback则是具体的 日志实现 方案。它们可以理解为接口与实现类的关系 四个框架都可以在程序中使用，但是为了考虑扩展性，一般我们在程序开发的时候，会选择使用 Commons Logging 或者 SLF4J 这些日志门面，而不是直接使用 log4j 或者 Logback 这些实现。即我们写代码的时候导入的类一般都是来自门面框架中的类，然后将某个日志的实现框架加入到项目中，提供真正的日志输出功能。如果项目依赖多个库，这些库又使用了不同的日志门面，这种情况可以方便的通过 Adapter 转接到同一个日志实现上； 比较常用的搭配是: commons-logging + log4j，这是一种比较老但稳妥的组合, 缺点是commons-logging不支持占位符; slf4j + logback，slf4j支持占位符, logback性能优于log4j; 日志门面（SLF4J，Commons-Loggings）SLF4JSLF4J全称为Simple Logging Facade for JAVA，Java简单日志门面。类似于Commons Logging，是对不同日志框架提供的一个门面封装，可以在部署的时候不修改任何配置即可接入一种日志实现方案。","text":"日志框架简介 Commons Logging和SLF4J是java中的 日志门面(Facade)，即它们提供了一套通用的接口，具体的实现可以由开发者自由选择。 Log4j（以及最新的log4j 2）和Logback则是具体的 日志实现 方案。它们可以理解为接口与实现类的关系 四个框架都可以在程序中使用，但是为了考虑扩展性，一般我们在程序开发的时候，会选择使用 Commons Logging 或者 SLF4J 这些日志门面，而不是直接使用 log4j 或者 Logback 这些实现。即我们写代码的时候导入的类一般都是来自门面框架中的类，然后将某个日志的实现框架加入到项目中，提供真正的日志输出功能。如果项目依赖多个库，这些库又使用了不同的日志门面，这种情况可以方便的通过 Adapter 转接到同一个日志实现上； 比较常用的搭配是: commons-logging + log4j，这是一种比较老但稳妥的组合, 缺点是commons-logging不支持占位符; slf4j + logback，slf4j支持占位符, logback性能优于log4j; 日志门面（SLF4J，Commons-Loggings）SLF4JSLF4J全称为Simple Logging Facade for JAVA，Java简单日志门面。类似于Commons Logging，是对不同日志框架提供的一个门面封装，可以在部署的时候不修改任何配置即可接入一种日志实现方案。 Adapter &amp; BridgeSLF4J在编译时静态绑定真正的Log库。下图介绍了SLF4J如何绑定具体的日志实现的: 对于application层，具体的日志框架对我们都是透明的，我们只针对slf4j-api编程。应用程序调用slf4j-api，而日志的输出最终是由底层的日志实现（Log4j、Logback）来负责的。上图也说明了具体日志实现（Log4j、Logback）的不同： Logback是基于slf4j接口编写的，所以中间不需要适配：SLF4J -&gt; Logback SLF4J+Log4j的方式就需要适配层：SLF4J -&gt; slf4j-log4j12 -&gt; Log4j SLF4J是如何绑定具体日志实现，参考：slf4j初始化绑定源码分析 | Sky’s Blog @ref 混乱的开始： SLF4J的开发者提供了各种 Adapter 和 Bridge 来适配各种 Log Implementation 和 Log Facade，使用JCL作为日志门面的旧项目也可以接入SLF4J。甚至可以有: Facade1 -&gt; Implementation1 -&gt; Bridge -&gt; Facade2 -&gt; Implementation2这种复杂的桥接方式.比如程序中以前使用的日志门面是commong-logging，那么你可以通过引入jcl-over-slf4j包来讲日志重定向到slf4j。 上图中红色的是 Log Facade， 蓝色的是 Log Implementation ，所以有了以下几种可能的复杂桥接方案: JCL(Commons Logging) -&gt; jcl-over-slf4j -&gt; SLF4J -&gt; Logback Log4j -&gt; log4j-over-slf4j -&gt; SLF4J -&gt; Logback 从上面可以看出, SLF4J -&gt; Logback是最简单的方案, SLF4J想使用 Log4j就需要桥接包 日志占位符SLF4J提供了更好的日志记录方式，支持占位符的方式打印日志。比如：logger.debug(&quot;Processing trade with id: {} and symbol : {} &quot;, id, symbol); 而不是使用JCL的+的方式：logger.debug(&quot;start process request, url:&quot; + url);直接使用 + 拼接字符串有什么问题呢？一般生产环境 log 级别都会设到 info 或者以上，那这条 log 是不会被输出的。然而不管是否输出，上面的代码都会做一个字符串连接操作，然后生产一个新的字符串。如果这条语句在循环或者被调用很多次的函数中，就会多做很多无用的字符串连接，影响性能。 所以 JCL 的最佳实践推荐这么写： if (logger.isDebugEnabled()) &#123; logger.debug(&quot;start process request, url:&quot; + url);&#125; 然而开发者常常忽略这个问题或是觉得麻烦而不愿意这么写。所以SLF4J提供的占位符{}方式更加方便。 SLF4J + Logback（推荐）SLF4J是编译时绑定到具体的日志框架，性能优于采用运行时搜寻的方式的commons-loggingSLF4J提供了更好的日志记录方式，带来下这几方面的好处： 更好的可读性； 不需要使用logger.isDebugEnabled()来解决日志因为字符拼接产生的性能问题。比如：logger.debug(“Processing trade with id: {} and symbol : {} “, id, symbol);logback支持了更方便的自定义日志，便于后期的日志分析，可以将日志格式化保存到各种存储引擎中，请点击这里 可以将日志写入到HBase等。但是SLF4J不支持FATAL级别 使用slf4j + logback步骤: 添加slf4j + logback的Jar包依赖; 去掉commons-loggings和log4j的依赖, 用mvn dependency:tree查看依赖, 并用&lt;exclusions&gt;去掉Jar依赖; 去掉重复引入的logback相关Jar, 比如我们使用slf4j + logback的方案，只需要引入logback-classic即可，不必再显示添加slf4j-api和logback-core，因为logback-classic本身依赖它们。 slf4j 配置文件: 无 logback 配置文件: logback.xml Java代码: import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class A &#123; private static final Logger logger = LoggerFactory.getLogger(A.class); public static void main(String[] args) &#123; if(logger.isDebugEnabled())&#123; logger.debug(\"slf4j-logback debug message\"); &#125; if(logger.isInfoEnabled())&#123; logger.info(\"slf4j-logback info message\"); &#125; if(logger.isTraceEnabled())&#123; logger.trace(\"slf4j-logback trace message\"); &#125; &#125;&#125; @ref: slf4j+logback的配置及使用 - 简书 Commons Logging（JCL）Commons Logging是一个通用的日志接口。在有些地方会看到简写为JCL（Jakarta Commons Logging）。 commons-logging是Apache commons类库中的一员。Apache commons类库是一个通用的类库，提供了基础的功能，比如说commons-fileupload，commons-httpclient，commons-io，commons-codes等。 common-logging通过动态查找的机制，在程序运行时自动找出真正使用的日志库。用户可以自由选择第三方的日志组件作为具体实现，像log4j，或者jdk自带的logging， Commons Logging会通过动态查找的机制，在程序运行时自动找出真正使用的日志库。所以使用Commons Logging，通常都是配合着log4j来使用。使用它的好处就是，代码依赖是Commons Logging而非log4j， 避免了和具体的日志方案直接耦合，在有必要时，可以更改日志实现的第三方库。 工作原理： 查找名为org.apache.commons.logging.Log的factory属性配置（可以是java代码配置，也可以是commons-logging.properties配置）； 查找名为org.apache.commons.logging.Log的系统属性； 上述配置不存在则classpath下是否有Log4j日志系统，如有则使用相应的包装类； 如果系统运行在JDK 1.4系统上，则使用Jdk14Logger； 上述都没有则使用SimpleLog。 所以如果使用commons-logging＋log4j的组合只需要在classpath中加入log4j.xml配置即可。commons-logging的动态查找过程是在程序运行时自动完成的。他使用ClassLoader来寻找和载入底层日志库，所以像OSGI这样的框架无法正常工作，因为OSGI的不同插件使用自己的ClassLoader。 Commons-Logging + Log4j 日志门面为Commons-Logging（JCL），实现类为log4j。Commons-Logging会通过动态查找的机制，在程序运行时自动找出真正使用的日志库。只要应用系统引入了log4j.jar包 并在classpath 配置了log4j.xml ，则Commons-Logging 就会使log4j 使用正常，而代码里不需要依赖任何log4j 的代码。 使用commons-logging + log4j的步骤: 添加Jar包依赖; commons-logging 配置文件: 默认的，common-logging会自动检查是否使用log4j，也可以使用配置文件显示的启用log4j。配置文件为commons-logging.properties,放在classpath下; org.apache.commons.logging.Log=org.apache.commons.logging.impl.Log4J-Loggerorg.apache.commons.logging.LogFactory=org.apache.commons.logging.impl.LogFactoryImpl log4j 配置文件: log4j.properties: log4j.rootLogger=DEBUG,consolelog4j.appender.console=org.apache.log4j.ConsoleAppenderlog4j.appender.console.layout=org.apache.log4j.PatternLayoutlog4j.appender.console.layout.ConversionPattern=[%-d&#123;yyyy-MM-dd HH:mm:ss&#125;]-[%t-%5p]-[%C-%M(%L)]： %m%n Java代码: import org.apache.commons.logging.Log;import org.apache.commons.logging.LogFactory;public class A &#123; private static Log logger = LogFactory.getLog(this.getClass()); public static void main(String[] args) &#123; logger.debug(\"Debug info: \" + args.toString()); &#125;&#125; 参考: Jakarta Commons Logging Users Guide @ref 日志实现（Log4J，LogBack，JUL）主流的日志实现有 log4j（还有升级版log4j2）和logback, 实现了将日志输出到具体的介质, 比如文件/Tcp/Scribe等.此外还有java.util.logging（JUL） log4j的默认配置文件是 log4j.properties; logback的默认配置文件是 logback.xml; Log4jLog4j是Apache的一个开放源代码项目，经典的一种日志解决方案。内部把日志系统抽象封装成Logger 、appender 、pattern等实现。我们可以通过配置文件轻松的实现日志系统的管理和多样化配置。通过使用Log4j，我们可以控制日志信息输送的目的地是控制台、文件、GUI组件、甚至是套接口服务器、NT的事件记录器、UNIX Syslog守护进程等；用户也可以控制每一条日志的输出格式；通过定义每一条日志信息的级别，用户能够更加细致地控制日志的生成过程。这些可以通过一个 配置文件来灵活地进行配置，而不需要修改程序代码。 Quick Start配置文件加载顺序: log4j.xml log4j.properites 所以把log4j.xml或log4j.properties放在这些目录下，那么log4j会“自动去加载”到，不用程序里手工写加载代码了。这也就“约定大于配置的好处”。 配置文件 log4j.properties配置文件log4j.properties 结构&amp;层级如下: logger appender layout Loggers(记录器)：记录日志的工具，程序中就是用它来记录我们想要的日志信息。 Appenders (输出源)：日志输出到什么地方，可以是控制台、文件、流位置、数据库，等等。 Layouts(布局模式)：日志需要记录哪些基本信息，用什么样的格式去记录展示这些信息。 一个 Logger 最少要有一个 Appender，一个 Appender 有一个 Layout。 log4j.properties 示例: log4j.rootLogger=INFO,A1 // 定义logger方式1: 定义根logger名=rootLogger, level=INFO, 使用名为A1的appenderlog4j.logger.loggerName1=DEBUG,A2 // 定义logger方式2: logger名=loggerName1, 使用名为A2的appenderlog4j.logger.org.apache = DEBUG, A3 // 定义logger方式3: 对org.apache下的类有效, 使用名为A3的appender// 定义A1 appender的属性log4j.appender.A1=org.apache.log4j.DailyRollingFileAppender // 可选ConsoleAppender, RollingFileAppender ..log4j.appender.A1.BufferedIO=falselog4j.appender.A1.BufferSize=1024log4j.appender.A1.file=../logs/api.log // 日志文件位置log4j.appender.A1.DatePattern=&apos;.&apos;yyyyMMddHHlog4j.appender.A1.layout=org.apache.log4j.PatternLayoutlog4j.appender.A1.layout.ConversionPattern=%-d&#123;yyyy-MM-dd HH\\:mm\\:ss SSS&#125; [%p] %m%n // 日志格式 代码public class Test &#123; // 获取rootLogger方法: public static Logger rootLogger = Logger.getRootLogger(); // 从logger名字获取: private static Logger log = Logger.getLogger(\"loggerName1\"); // 从class获取 private static Logger log2 = Logger.getLogger(Test.class); public static void main(String[] args) &#123; log.info(\"......\"); &#125;&#125; 性能问题 设置日志缓存，以及缓存大小 log4j.appender.A3.BufferedIO=true#Buffer单位为字节，默认是8K，IO BLOCK大小默认也是8Klog4j.appender.A3.BufferSize=8192 设置日志输出为异步方式 (异步输出必须使用xml方式配置才能支持) &lt;appender name=&quot;DAILY_FILE&quot; class=&quot;org.apache.log4j.DailyRollingFileAppender&quot;&gt; &lt;layout class=&quot;org.apache.log4j.PatternLayout&quot;&gt; &lt;param name=&quot;ConversionPattern&quot; value=&quot;%d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; %5p %c %x - %m%n&quot;/&gt; &lt;/layout&gt; &lt;param name=&quot;File&quot; value=&quot;log/log4j.log&quot;/&gt; &lt;param name=&quot;DatePattern&quot; value=&quot;&apos;.&apos;yyyy-MM-dd&quot;/&gt;&lt;/appender&gt;&lt;appender name=&quot;ASYNC_FILE&quot; class=&quot;org.apache.log4j.AsyncAppender&quot;&gt; &lt;param name=&quot;BufferSize&quot; value=&quot;10000&quot;/&gt; &lt;param name=&quot;Blocking&quot; value=&quot;false&quot;/&gt; &lt;appender-ref ref=&quot;DAILY_FILE&quot;/&gt;&lt;/appender&gt; Log4j的AsyncAppender存在的问题: Log4j的异步appender也就是AsyncAppender存在性能问题（现在Log4j 2.0 RC提供了一种新的异步写log的机制(基于disruptor)来试图解决问题），异步写log有一个buffer的设置，也就是当队列中多少个日志的时候就flush到文件或数据库，当配置为blocking=true的时候，如果应用写日志很快，log4j的缓冲队列将很快被占满，写日志会被阻塞 LogbackLogback也是一种日志实现。Logback是由log4j创始人设计的又一个开源日记组件。Logback当前分成三个模块：Logback-core,Logback- classic和Logback-access。Logback-core是其它两个模块的基础模块。Logback-classic是log4j的一个 改良版本。此外Logback-classic完整实现SLF4J API使你可以很方便地更换成其它日记系统如log4j或JDK14 Logging。Logback-access访问模块与Servlet容器集成提供通过Http来访问日记的功能。 LogBack 作为一个通用可靠、快速灵活的日志框架，将作为Log4j 的替代和SLF4J 组成新的日志系统的完整实现。官网上称具有极佳的性能，在关键路径上执行速度是log4j 的10 倍，且内存消耗更少。比如判定是否记录一条日志语句的操作，其性能得到了显著的提高。这个操作在LogBack中需要3纳秒，而在Log4J中则需要30纳秒。 LogBack创建记录器（logger）的速度也更快：13微秒，而在Log4J中需要23微秒。更重要的是，它获取已存在的记录器只需94纳秒，而 Log4J需要2234纳秒，时间减少到了1/23。”。 官方文档对logback的描述 NATIVE IMPLEMENTATION There are also SLF4J bindings external to the SLF4J project, e.g. logback which implements SLF4J natively. Logback’s ch.qos.logback.classic.Logger class is a direct implementation of SLF4J’s org.slf4j.Logger interface. Thus, using SLF4J in conjunction with logback involves strictly zero memory and computational overhead. 可以看到logback是直接实现了slf4j的接口，是不消耗内存和计算开销的。而log4j不是对slf4j的原生实现，所以slf4j api在调用log4j时需要一个适配层。 Quick Start@todo 配置文件 logback.xmllogback在启动时，根据以下步骤寻找配置文件： ①在classpath中寻找logback-test.xml文件 ②如果找不到logback-test.xml，则在 classpath中寻找logback.groovy文件 ③如果找不到 logback.groovy，则在classpath中寻找logback.xml文件 如果上述的文件都找不到，则logback会使用JDK的SPI机制查找 META-INF/services/ch.qos.logback.classic.spi.Configurator中的 logback 配置实现类，这个实现类必须实现Configuration接口，使用它的实现来进行配置。如果上述操作都不成功，logback 就会使用它自带的 BasicConfigurator 来配置，并将日志输出到console。 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!--scan: 当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。scanPeriod: 设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。debug: 当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。configuration 子节点为 appender、logger、root --&gt;&lt;configuration scan=\"true\" scanPeriod=\"60 seconds\" debug=\"false\"&gt; &lt;!--用于区分不同应用程序的记录--&gt; &lt;contextName&gt;edu-cloud&lt;/contextName&gt; &lt;!--日志文件所在目录，如果是tomcat，如下写法日志文件会在则为$&#123;TOMCAT_HOME&#125;/bin/logs/目录下--&gt; &lt;property name=\"LOG_HOME\" value=\"logs\"/&gt; &lt;!--控制台--&gt; &lt;appender name=\"stdout\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;encoder&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度 %logger输出日志的logger名 %msg：日志消息，%n是换行符 --&gt; &lt;pattern&gt;[%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;] [%thread] %-5level %logger&#123;36&#125; : %msg%n&lt;/pattern&gt; &lt;!--解决乱码问题--&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!--滚动文件--&gt; &lt;appender name=\"infoFile\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- ThresholdFilter:临界值过滤器，过滤掉 TRACE 和 DEBUG 级别的日志 --&gt; &lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"&gt; &lt;level&gt;INFO&lt;/level&gt; &lt;/filter&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;fileNamePattern&gt;$&#123;LOG_HOME&#125;/log.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt;&lt;!--保存最近30天的日志--&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;pattern&gt;[%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;] [%thread] %-5level %logger&#123;36&#125; : %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt;&lt;!--这里如果是info，spring、mybatis等框架则不会输出：TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR--&gt; &lt;!--root是所有logger的祖先，均继承root，如果某一个自定义的logger没有指定level，就会寻找 父logger看有没有指定级别，直到找到root。--&gt; &lt;root level=\"debug\"&gt; &lt;appender-ref ref=\"stdout\"/&gt; &lt;appender-ref ref=\"infoFile\"/&gt; &lt;appender-ref ref=\"errorFile\"/&gt; &lt;appender-ref ref=\"logstash\"/&gt; &lt;/root&gt;&lt;/configuration&gt; JULjava.util.logging 是 java自带的日志处理系统, 配置文件一般是logging.properties, java.util.logging.LogManager 负责读取配置, LogManager 还可以根据两个系统属性来允许用户控制日志的配置： “-Djava.util.logging.config.class=YourClass” “-Djava.util.logging.config.file=logging.properties” logging.properties和Tomcat的配置格式类似: handlers=java.util.logging.FileHandler,java.util.logging.ConsoleHandler,java.util.logging.ConsoleHandler.level=WARNINGjava.util.logging.ConsoleHandler.formatter=java.util.logging.SimpleFormatterjava.util.logging.FileHandler.level=INFOjava.util.logging.FileHandler.formatter=java.util.logging.SimpleFormatterjava.util.logging.FileHandler.limit=1024000java.util.logging.FileHandler.count=10java.util.logging.FileHandler.pattern=/data1/logs/log.%d&#123;yyyyMMddHH&#125;java.util.logging.FileHandler.append=true 最佳实践如果你的项目是一个库，需要提供给给别的项目使用，那么建议使用 Log Facade，而不使用具体的 Log Implementation。如果一定要使用 Log Implementation，那么建议你的项目里对 Log Implementation 的依赖设置为&lt;scope&gt;runtime&lt;/scope&gt; 并且&lt;optional&gt;true&lt;/optional&gt;, 设为optional，依赖不会传递； &lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-core&lt;/artifactId&gt; &lt;version&gt;$&#123;log4j.version&#125;&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-slf4j-impl&lt;/artifactId&gt; &lt;version&gt;$&#123;log4j.version&#125;&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; 如果是一个独立的项目(比如Web项目)，那么不要单独使用 Log Impementation，而应该跟 Log Facade一起使用。 如果有必要, 排除依赖的第三方库中的 Log Impementation依赖 这是很常见的一个问题，第三方库的开发者未必会把具体的 Log Implementation 或者桥接器的依赖设置为optional，然后你的项目会继承这些 Log Implementation 的库，—— 但这未必是你想使用的，比如第三方库依赖了Log4j，但你自己的项目使用的是Logback。另外，如果不同的第三方依赖使用了不同的桥接器和 Log Implementation ，也极容易形成依赖环。项目里就需要针对每个 Log Implementation 库都都写一个配置文件。这种情况下推荐的处理方法，使用exclude来排除所有的这些 Log Implementation 和桥接器的依赖，只保留第三方库里面对 Log Facade 的依赖。 @ref: Java 日志框架解析(上) - 历史演进 - 知乎 Java 日志框架解析(下) - 最佳实践 - 知乎","categories":[{"name":"13.JavaEE","slug":"13-JavaEE","permalink":"https://beefyheisenberg.github.io/categories/13-JavaEE/"}],"tags":[{"name":"JavaEE","slug":"JavaEE","permalink":"https://beefyheisenberg.github.io/tags/JavaEE/"},{"name":"JCL","slug":"JCL","permalink":"https://beefyheisenberg.github.io/tags/JCL/"},{"name":"SLF4J","slug":"SLF4J","permalink":"https://beefyheisenberg.github.io/tags/SLF4J/"},{"name":"Log4J","slug":"Log4J","permalink":"https://beefyheisenberg.github.io/tags/Log4J/"},{"name":"Logback","slug":"Logback","permalink":"https://beefyheisenberg.github.io/tags/Logback/"},{"name":"日志","slug":"日志","permalink":"https://beefyheisenberg.github.io/tags/日志/"}]},{"title":"Java EE 技术标准（JTS,JMS,JMX,JTA,JPA,EJB,JNDI,JDBC）","slug":"13.JavaEE-Framework/JavaEE.01.技术标准","date":"2024-01-24T01:27:52.254Z","updated":"2024-01-24T01:27:52.254Z","comments":true,"path":"13.JavaEE-Framework/JavaEE.01.技术标准/","link":"","permalink":"https://beefyheisenberg.github.io/13.JavaEE-Framework/JavaEE.01.技术标准/","excerpt":"相关概念Java平台共分为三个主要版本：Java SE、Java EE 和 Java ME。 Java SE，Java Platform Standard Edition，Java平台标准版, 基本等同于 JDK； Java EE，Java Platform Enterprise Edition，也即Java平台企业版，JavaEE实际上是一系列技术标准的集合，并不提供具体实现； Java ME，Java Platform Micro Edition，用于嵌入式和移动设备的Java平台，已经式微。 Java EE 是一系列技术标准所组成的平台，最早由 Sun 发布，后来 Oracle 把 Java EE 交给 Eclipse 基金会管理，同时改名为 Jakarta EE。Java EE 的技术标准包括：","text":"相关概念Java平台共分为三个主要版本：Java SE、Java EE 和 Java ME。 Java SE，Java Platform Standard Edition，Java平台标准版, 基本等同于 JDK； Java EE，Java Platform Enterprise Edition，也即Java平台企业版，JavaEE实际上是一系列技术标准的集合，并不提供具体实现； Java ME，Java Platform Micro Edition，用于嵌入式和移动设备的Java平台，已经式微。 Java EE 是一系列技术标准所组成的平台，最早由 Sun 发布，后来 Oracle 把 Java EE 交给 Eclipse 基金会管理，同时改名为 Jakarta EE。Java EE 的技术标准包括： Servlet: Java Servlet API JNDI(Java Name and Directory Interface): Java 命名和目录接口，它提供一个目录系统，并将服务名称与对象关联起来，从而使得开发人员在开发过程中可以使用名称来访问对象。并提供了一致的模型来存取和操作企业级的资源如 DNS 和 LDAP、本地文件系统、或应用服务器中的对象。 JTA(Java Transaction API): Java 事务 API. JTS(Java Transaction Service): Java 事务服务. JPA(Java Persistence API): 通过注解或 XML 描述对象－关系表的映射关系, 并将对象持久化到数据库中, 实现有 Spring-data-jpa, Hibernate。 JMS(Java Message Service): Java 消息服务接口是一个 Java 平台中关于面向消息中间件（MOM）的 API，用于在两个应用程序之间，或分布式系统中发送消息，进行异步通信。Java 消息服务的规范包括两种消息模式，点对点和发布者／订阅者。 JMX(Java Management Extensions): Java 管理扩展，JMX 提供了一套接口，让开发者和管理者可以通过 MBean 获取程序运行的状态以及动态的修改程序的相关配置。JMX 可以跨越一系列异构操作系统平台、系统体系结构和网络传输协议，灵活的开发无缝集成的系统、网络和服务管理应用。Tomcat、Kafka 等都通过 JMX 实现了监控接口，Jconsole 和 VisualVM 可以通过 JMX 协议获取程序运行状态实现监控。 Java Bean: 一般情况下指的是实体类, 所有属性为 private, 提供默认构造方法和 getter, setter, 如果一个 JavaBean 需要在不同的 JVM 的进程中进行传递，还需要实现 Serializable 接口. MBean（Managed Bean）: 托管 Bean, 是一种通过依赖注入创建的 Java Bean。MBean 代表了运行在 Java 虚拟机上的资源，例如应用程序或 Java EE 服务（事务监控、JDBC 驱动程序等）。其可以用于收集如性能、资源使用率、问题信息等关键的统计信息（通过拉取），获取或设置应用程序的配置或属性（通过推送或拉取），以及对故障或状态变化等的通知事件（通过推送）。 EJB(Enterprise JavaBean): 企业级 JavaBean, 与普通 Java Bean 的区别: JavaBean 的使用可以不需要容器，EJB 的运行一般需要 EJB 容器(即应用服务器，如 JBoss/Weblogic/Websphere… POJO(Plain Ordinary Java Object): 简单的 Java 对象, 实际就是普通 Java Beans, 是为了避免和 EJB 混淆所创造的简称 JDBC(Java Database Connectivity): 是一个标准 SQL(Structured Query Language, 结构化查询语言)数据库访问接口 附：来自 Oracke的 Java EE 8 技术列表 J2EE里面的2是什么意思？ J2SE，J2SE，J2ME中2的含义要追溯要1998年。1998年Java 1.2版本发布，1999年发布Java 1.2的标准版，企业版，微型版三个版本，为了区分这三个版本，分别叫做Java2SE，Java2EE，Java2ME，简称J2SE，J2EE，J2ME。故，2的含义为1.2版本。但是，这种叫法已经在2005年Java 1.6发布后取消，J2EE更名为Java EE，J2SE更名为Java SE，J2ME更名为Java ME。所以，现在的J2EE等叫法是05年以前旧的叫法。 JavaEE的发展@ref: 从Java EE到Jakarta EE，企业版Java的发展历程-java ee企业级 版本 发布日期 焦点说明 J2EE 1.4 2003.12 对 Web 服务更好支持。启用 javax 命名空间。Servlet 2.4、JSP 2.0、EJB 2.1 等 Java EE 5 2006.05 以 Web 为着力点继续优化。Servlet 2.5、JSP 2.1、EJB 3.0、注解支持等 Java EE 6 2009.12 添加了大量新技术来简化开发，如：Servlet 3.0(异步处理)、Bean Validation、EJB 3.1、JSF 2.0、JPA 2.0、上下文和依赖注入(CDI) Java EE 7 2013.06 提高生产力满足企业需求和 HTML5。Servlet 3.1、WebSocket 1.0、JSON 1.0、JMX 2.0、Batch 1.0 Java EE 8 2017.08 增加了 JSON 绑定和安全相关。Servlet 4.0、Bean Validation 2.0、CDI 2.0、JPA 2.2 Jakarta EE 入局 2017.08 Oracle 将 Java EE 交给开源组织，Eclipse 基金会接手（Apache 基金会爆冷出局还是不想要？）。但 Oracle 不允许开源组织使用 Java 名号，所以 Jakarta EE 名称于 2018.02.26 应运而生 Jakarta EE 8 2019.09 规范与 Java EE 8完全相同。Maven 的 GAV 变了：javax.servlet:javax.servlet-api:4.0.1 -&gt; jakarta.servlet:jakarta.servlet-api:4.0.2，但命名空间没变依旧还是 javax.*，算是个小过度吧 Jakarta EE 9 2020.11 没有加入新功能，Eclipse 基金会的首个正式版本。命名空间从 javax.* 迁移到 jakarta.*，前者从此成为历史。所有模块大版本号+1，如 Servlet 4.0.2 → Servlet 5 以表示其断层式升级 Jakarta EE 9.1 2021.06 相较于 9 没有 加入新 API。主要提供对 Java SE 11 的运行支持 2021年9月 Spring Boot 3.0 M1发布, 基线从 Java8提升至 Java17, 所有 Java EE API 被迁移到 Jakarta EE(用户需要将 javax 替换为 jakarta. 例如，javax.servlet.Filter 将替换为 jakarta.servlet.Filter) 其他参考： 2017 年 3 月: InfoQ观点：Java EE的未来 2018 年 2 月: Java EE重命名为Jakarta EE：Java EE Guardians与Oracle的分歧 2019 年 5 月: 谈判失败，Oracle亲手把Java EE送上断头台 JTA (Java Transaction API)@ref: Java Transaction API (JTA) Guide to Jakarta EE JTA | Baeldung Understanding JTA - The Java Transaction API Configuring Spring and JTA without full Java EE JTS (Java Transaction Service):@ref: Chapter 3 Using the Transaction Service Learning more about Java Transaction Service (JTS) JMS (Java Message Service)@ref: Java Message Service (JMS) JMS Tutorial - javatpoint javax.jms (Java(TM) EE 7 Specification APIs) JMX (Java Management Extensions)@ref: JMX - 维基百科，自由的百科全书","categories":[{"name":"13.JavaEE","slug":"13-JavaEE","permalink":"https://beefyheisenberg.github.io/categories/13-JavaEE/"}],"tags":[{"name":"JavaEE","slug":"JavaEE","permalink":"https://beefyheisenberg.github.io/tags/JavaEE/"},{"name":"JTS","slug":"JTS","permalink":"https://beefyheisenberg.github.io/tags/JTS/"},{"name":"JMS","slug":"JMS","permalink":"https://beefyheisenberg.github.io/tags/JMS/"},{"name":"JMX","slug":"JMX","permalink":"https://beefyheisenberg.github.io/tags/JMX/"},{"name":"JTA","slug":"JTA","permalink":"https://beefyheisenberg.github.io/tags/JTA/"},{"name":"JPA","slug":"JPA","permalink":"https://beefyheisenberg.github.io/tags/JPA/"},{"name":"JNDI","slug":"JNDI","permalink":"https://beefyheisenberg.github.io/tags/JNDI/"},{"name":"EJB","slug":"EJB","permalink":"https://beefyheisenberg.github.io/tags/EJB/"},{"name":"JDBC","slug":"JDBC","permalink":"https://beefyheisenberg.github.io/tags/JDBC/"}]},{"title":"Java-并发.09.《深入理解Java内存模型》笔记","slug":"12.Java/Java-并发.09.深入理解JMM","date":"2024-01-24T01:27:52.246Z","updated":"2024-01-24T01:27:52.247Z","comments":true,"path":"12.Java/Java-并发.09.深入理解JMM/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-并发.09.深入理解JMM/","excerpt":"@ref: 《深入理解Java内存模型》 @tldr: 并发编程模型 并发编程模型要解决的两个问题: 通信和同步 两种并发编程模型的: 基于共享内存, 基于消息 Java内存模型的抽象 Java 内存模型（JMM）的抽象: 主内存和线程的”本地内存” happens-before规则 该规则是 JSR-133 内存模型(JDK 层面定义的)中提出的概念, happens-before 并不是指两个指令执行的先后顺序, 而是两个指令的 内存可见性. 如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在 happens-before 关系。 该规则还保证了, 哪些 java 代码能达到 happens-before 的效果: 单线程下顺序执行; 正确使用 volatile, Synchronize 的情况下, 多线程也能提供 happens-before 效果; 重排序 为什么会产生重排序，有哪几种重排序? 在 JMM 上, 重排序必须遵守 as-if-serial 语义: as if serial, 「就像是顺序执行」 在单线程环境下, 保证 a-i-s, 处理器和编译器的重排序优化,不能改变存在数据依赖关系的两个操作的执行顺序 在存在竞争的多线程下, 处理器和编译器不保证 a-i-s, 必须正确使用 lock，volatile 和 final 才可以. 内存屏障 内存屏障指令是 cpu 架构层面定义的, Java 编译器会在生成字节码中插入内存屏障指令来禁止某些重排序, 保证多核环境下代码执行的”一致性” JMM 提供了四种内存屏障, 其中最重要的是 StoreLoad 屏障指令, 它能保证… Java 如何实现多线程环境下的正确同步: Volatile 实现了怎样的内存语义, 是如何实现的? Synchronize 实现了怎样的内存语义, 是如何实现的? ReentrantLock 是如何实现的? CAS 具有跟 Volatile 读写一样的内存语义, 是如何实现的? concurrent包的实现 : 四种方式(CAS 和 volatile) 并发编程模型","text":"@ref: 《深入理解Java内存模型》 @tldr: 并发编程模型 并发编程模型要解决的两个问题: 通信和同步 两种并发编程模型的: 基于共享内存, 基于消息 Java内存模型的抽象 Java 内存模型（JMM）的抽象: 主内存和线程的”本地内存” happens-before规则 该规则是 JSR-133 内存模型(JDK 层面定义的)中提出的概念, happens-before 并不是指两个指令执行的先后顺序, 而是两个指令的 内存可见性. 如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在 happens-before 关系。 该规则还保证了, 哪些 java 代码能达到 happens-before 的效果: 单线程下顺序执行; 正确使用 volatile, Synchronize 的情况下, 多线程也能提供 happens-before 效果; 重排序 为什么会产生重排序，有哪几种重排序? 在 JMM 上, 重排序必须遵守 as-if-serial 语义: as if serial, 「就像是顺序执行」 在单线程环境下, 保证 a-i-s, 处理器和编译器的重排序优化,不能改变存在数据依赖关系的两个操作的执行顺序 在存在竞争的多线程下, 处理器和编译器不保证 a-i-s, 必须正确使用 lock，volatile 和 final 才可以. 内存屏障 内存屏障指令是 cpu 架构层面定义的, Java 编译器会在生成字节码中插入内存屏障指令来禁止某些重排序, 保证多核环境下代码执行的”一致性” JMM 提供了四种内存屏障, 其中最重要的是 StoreLoad 屏障指令, 它能保证… Java 如何实现多线程环境下的正确同步: Volatile 实现了怎样的内存语义, 是如何实现的? Synchronize 实现了怎样的内存语义, 是如何实现的? ReentrantLock 是如何实现的? CAS 具有跟 Volatile 读写一样的内存语义, 是如何实现的? concurrent包的实现 : 四种方式(CAS 和 volatile) 并发编程模型在并发编程中，我们需要处理两个关键问题：线程之间如何通信及线程之间如何同步。 通信 是指: 通信是指线程之间以何种机制来交换信息。在共享内存的并发模型里，对于线程之间共享程序的公共状态，线程之间通过写-读内存中的公共状态来隐式进行通信。在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显式进行通信。 同步 是指: 程序用于控制不同线程之间操作发生相对顺序的机制。在共享内存并发模型里，同步是显式进行的。程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行。在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的。 在共享内存的并发模型里，线程之间共享程序的公共状态，线程之间通过写 - 读内存中的公共状态来隐式进行通信。在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显式进行通信。 Java 并发模型中, 线程的同步采用的是 共享内存 的方式，Java 线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。如果编写多线程程序的 Java 程序员不理解隐式进行的线程之间通信的工作机制，很可能会遇到各种奇怪的内存可见性问题。 Java 内存模型的抽象Java 线程之间的通信由 Java 内存模型（本文简称为 JMM）控制，JMM 决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM 定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的 本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存 是 JMM 的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。Java 内存模型的抽象示意图如下： 在 java 中，所有实例域、静态域和数组元素存储在堆内存中，堆内存在线程之间共享（本文使用“共享变量”这个术语代指实例域，静态域和数组元素）。局部变量（Local variables），方法定义参数（java 语言规范称之为 formal method parameters）和异常处理器参数（exception handler parameters）不会在线程之间共享，它们不会有内存可见性问题，也不受内存模型的影响。 JMM 的 happens-before 规则从 JDK 5 开始，java 使用新的 JSR-133 内存模型，JSR-133 提出了 happens-before 的概念，通过这个概念来阐述操作之间的内存可见性。如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在 happens-before 关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。与程序员密切相关的 happens-before 规则如下： 顺序规则：一个线程中的每个操作，happens-before 于该线程中的任意后续操作。 监视器锁（Monitor）规则：对一个监视器锁的解锁，happens-before 于随后对这个监视器锁的加锁。 volatile 变量规则：对一个 volatile 域的写，happens-before 于任意后续对这个 volatile 域的读。 传递性：如果 A happens-before B，且 B happens-before C，那么 A happens-before C。 线程启动法则：在一个线程里，对 Thread.start 的调用会 happens-before 于每个启动线程的动作。 线程终结法则：线程中的任何动作都 happens-before 于其他线程检测到这个线程已经终结、或者从 Thread.join 调用中成功返回，或 Thread.isAlive 返回 false。 中断法则：一个线程调用另一个线程的 interrupt happens-before 于被中断的线程发现中断。 终结法则：一个对象的构造函数的结束 happens-before 于这个对象 finalizer 的开始。 如果一个操作 happens-before 另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。两个操作之间存在 happens-before 关系，并不意味着一定要按照 happens-before 原则制定的顺序来执行。如果重排序之后的执行结果与按照 happens-before 关系来执行的结果一致，那么这种重排序并不非法。 JMM 顺序一致性什么是“顺序一致性”内存模型： 顺序一致性模型(sequential consistency)是一个被计算机科学家理想化了的理论参考模型，顺序一致性内存模型有两大特性： 一个线程中的所有操作必须按照程序的顺序来执行。 （不管程序是否同步）所有线程都只能看到一个单一的操作执行顺序。 在顺序一致性内存模型中，每个操作都必须原子执行且立刻对所有线程可见。 JMM 的顺序一致性保证： JMM 提供的顺序一致性内存模型是一种”面向程序员的内存模型”（Programmer-centric model），JMM 对正确同步的多线程程序的内存一致性做了如下保证： 如果程序是正确同步的（正确使用了 lock，volatile 和 final），程序的执行将具有顺序一致性（sequentially consistent）– 即程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同（这对于程序员来说是一个极强的保证）。 这里的同步是指广义上的同步，包括对常用同步原语（lock，volatile 和 final）的正确使用。 synchronized 提供的顺序一致性效果： 在 JMM 中，临界区内的代码可以重排序（但 JMM 不允许临界区内的代码“逸出”到临界区之外）。JMM 会在退出监视器和进入监视器这两个关键时间点做一些特别处理，使得线程在这两个时间点具有与顺序一致性模型相同的内存视图（具体细节后文会说明）。 虽然线程 A 在临界区内做了重排序，但由于监视器的互斥执行的特性，这里的线程 B 根本无法“观察”到线程 A 在临界区内的重排序。 重排序什么是重排序在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。在计算机中，软件技术和硬件技术有一个共同的目标：在不改变程序执行结果的前提下，尽可能的开发并行度。重排序分三种类型： 编译器优化 的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 指令级并行 的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 内存系统 的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。 上述的 1 属于编译器重排序，2 和 3 属于处理器重排序。这些重排序都可能会导致多线程程序出现内存可见性问题。 写缓冲区可以保证指令流水线持续运行，它可以避免由于处理器停顿下来等待向内存写入数据而产生的延迟。同时，通过以批处理的方式刷新写缓冲区，以及合并写缓冲区中对同一内存地址的多次写，可以减少对内存总线的占用。虽然写缓冲区有这么多好处，但每个处理器上的写缓冲区，仅仅对它所在的处理器可见。这个特性会对内存操作的执行顺序产生重要的影响：处理器对内存的读/写操作的执行顺序，不一定与内存实际发生的读/写操作顺序一致！ 遵守 as-if-serial 语义as-if-serial: 翻译就是「就像是顺序执行」. 编译器和处理器对重排序准守 as-if-serial 语义，as-if-serial 的意思指：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器/runtime/处理器都必须遵守 as-if-serial 语义。 为了遵守 as-if-serial 语义，编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不能改变存在数据依赖关系的两个操作的执行顺序。比如 a=b; b=1; 以及 a=1; b=a;，这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑。 编译器和处理器仅指在单线程环境下遵守 as-if-serial，在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果。必须通过正确的同步实现. 注意：if 等控制语句没有 数据依赖性，比如代码：if(flag) int i = r * r; 其中 if 和 int i= r * r 是控制依赖关系，但没有数据依赖性。当代码中存在控制依赖性时，会影响指令序列执行的并行度。为此，编译器和处理器会采用猜测（Speculation）执行来克服控制相关性对并行度的影响，提高执行效率。下面的情形是有可能发生的：处理器可以提前读取并计算 r * r，然后把计算结果临时保存到一个名为 重排序缓冲（reorder buffer ROB） 的硬件缓存中。当接下来 if(flag) 的条件判断为真时，就把该计算结果写入变量 i 中。 通过内存屏障禁止重排序编译器和处理器必须同时遵守重排规则。由于单核处理器能确保与“顺序执行”相同的一致性，所以在单核处理器上并不需要专门做什么处理，就可以保证正确的执行顺序。但在多核处理器上通常需要使用内存屏障指令来确保这种一致性。在不同的 CPU 架构上内存屏障的实现非常不一样。相对来说 Intel CPU 的强内存模型比 DEC Alpha 的弱复杂内存模型（缓存不仅分层了，还分区了）更简单。 内存屏障提供了两个功能。首先，它们通过确保从另一个 CPU 来看屏障的两边的所有指令都是正确的程序顺序，而保持程序顺序的外部可见性；其次它们可以实现内存数据可见性，确保内存数据会同步到 CPU 缓存子系统。 Java 编译器在生成指令序列的适当位置会插入 内存屏障（Barriers） 指令来禁止特定类型的处理器重排序。以实现屏障前后指令的可见性。 JMM 把内存屏障指令分为下列四类： 屏障类型 example 实现效果 LoadLoad Load 1; LoadLoad; Load 2; 确保 Load 1 数据的装载，之前于 Load 2 及所有后续装载指令的装载。(禁止 Load 1,Load 2 重排序) StoreStore Store 1; StoreStore; Store 2; 确保 Store 1 数据对其他处理器可见（刷新到内存），之前于 Store 2 及所有后续存储指令的存储。(禁止 Store 1,Store 2 重排序) LoadStore Load 1; LoadStore; Store 2; 确保 Load 1 数据装载，之前于 Store 2 及所有后续的存储指令刷新到内存。(禁止 Load 1,Store 2 重排序) StoreLoad Store 1; StoreLoad; Load 2; 确保 Store 1 数据对其他处理器变得可见（刷新到内存），之前于 Load 2 及所有后续装载指令的装载。StoreLoad Barriers 会使该屏障之前的所有内存访问指令（存储和装载指令）完成之后，才执行该屏障之后的内存访问指令。(禁止 Store 1,Load 2 重排序) StoreLoad 是一个“全能型”的屏障，它可以保证“先刷新到主内存再访问”。现代的多处理器大都支持该屏障（其他类型的屏障不一定被所有处理器支持）。执行该屏障开销会很昂贵，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中（buffer fully flush）。 Volatilevolatile 变量的特性 可见性：对一个 volatile 变量的读，总是能看到（任意线程）对这个 volatile 变量最后的写入。可以认为对 volatile 的写是原子的； 原子性：对任意单个 volatile 变量的读/写具有原子性，但类似于 volatile++ 这种”依赖当前值”的复合操作不具有原子性，所以仅仅使用 volatile 变量当做同步手段(比如当做锁的计数器) 是不可以的。线程安全的计数器请使用 AtomicInteger 扩展阅读: long 和 double 读写的 #原子性 :JMM 不保证对 64 位的 long 型和 double 型变量的读/写操作具有原子性, 在一些 32 位的处理器上，如果要求对 64 位数据的读/写操作具有原子性，会有比较大的开销。为了照顾这种处理器，java 语言规范鼓励但不强求 JVM 对 64 位的 long 型变量和 double 型变量的读/写具有原子性。当 JVM 在这种处理器上运行时，会把一个 64 位 long/ double 型变量的读/写操作拆分为两个 32 位的读/写操作来执行。这两个 32 位的读/写操作可能会被分配到不同的总线事务中执行，此时对这个 64 位变量的读/写将不具有原子性。 JMM 可以保证 64位环境，volatile long 的原子性： volatile 读写建立的 happens before 关系从 JSR-133 开始，volatile 变量的写-读可以实现线程之间的通信。看代码： class VolatileExample &#123; int a = 0; volatile boolean flag = false; // 线程A执行writer(): public void writer() &#123; a = 1; //1 flag = true; //2 &#125; // 线程B执行read(): public void reader() &#123; if (flag) &#123; //3 int i = a; //4 &#125; &#125;&#125; 根据 happens-before①，1 happens-before 2，3 happens-before 4； 根据 volatile 语义，2 happens-before 3； 根据 happens-before④，1 happens-before 4； 上面写 1 happens-before 2，指的是 1 对于 2 可见，但不一定是执行顺序； volatile 读写的内存语义volatile 读写的内存语义如下： 当读一个 volatile 变量时，JMM 会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。 当写一个 volatile 变量时，JMM 会把该线程对应的本地内存中的共享变量刷新到主内存。 “内存语义”（没找到对应的英文原语）的概念： 可以理解为多核环境下, “同步”(在 Java 里指 Volatile，Synchronize 等)实现的原则, 或者是”能达到的效果”. volatile 内存语义的实现下面是 JMM 针对编译器制定的 volatile 重排序规则表： 为了实现 volatile 的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能，为此，JMM 采取保守策略。下面是基于保守策略的 JMM 内存屏障插入策略： 在每个 volatile 写 操作的 前面 插入一个 StoreStore 屏障。 在每个 volatile 写 操作的 后面 插入一个 StoreLoad 屏障。 在每个 volatile 读 操作的 后面 插入一个 LoadLoad 屏障。 在每个 volatile 读 操作的 后面 再插入一个 LoadStore 屏障。 ① volatile 写插入的内存屏障：普通读/写操作StoreStore屏障 //禁止上面的普通写和下面的 Volatile写 重排序volatile写 // 因为v的写一般作为change标志位，所以v写之前的写，不能排到v写之后StoreLoad屏障 //禁止上面的Volatile写和下面有可能的 Volatile读写 重排序 StoreStore 屏障可以保证在 volatile 写之前，其前面的所有普通写操作已经对任意处理器可见了。这是因为 StoreStore 屏障将保障上面所有的普通写在 volatile 写之前刷新到主内存。 这里比较有意思的是 volatile 写后面的 StoreLoad 屏障。为了保证能正确实现 volatile 的内存语义，在每个 volatile 写的后面或在每个 volatile 读的前面插入一个 StoreLoad 屏障。从整体执行效率的角度考虑，JMM 选择了在每个 volatile 写的后面插入一个 StoreLoad 屏障。因为 volatile 写 - 读内存语义的常见使用模式是：一个写线程写 volatile 变量，多个读线程读同一个 volatile 变量。当读线程的数量大大超过写线程时，选择在 volatile 写之后插入 StoreLoad 屏障将带来可观的执行效率的提升。 ② volatile 读插入的内存屏障：volatile读 // v读一般作为检测标志，也就要求后面的普通读，不能先于v读之前LoadLoad屏障 // 禁止下面的普通读和上面的 Volatile读 重排序LoadStore屏障 // 禁止下面的普通写和上面的 Volatile读 重排序普通读/写 Synchronized有关 Synchronized 的实现, 请参考👉 《Java Tutorials》 Synchronized 的释放-获取建立的 happens before 关系线程 A 在释放锁之前所有可见的共享变量，在线程 B 获取同一个锁之后，将立刻变得对 B 线程可见。 Synchronized 释放-获取的内存语义 当线程释放锁时，JMM 会把该线程对应的本地内存中的共享变量刷新到主内存中。 当线程获取锁时，JMM 会把该线程对应的本地内存置为无效。从而使得被 monitor 保护的临界区代码必须要从主内存中去读取共享变量。 对比锁释放-获取的内存语义与 volatile 写-读的内存语义，可以看出：锁释放与 volatile 写有相同的内存语义；锁获取与 volatile 读有相同的内存语义。 Synchronized 内存语义的实现Synchronized 提供的 Monitor 机制可以保证：临界区内的代码可以重排序，但不允许临界区内的代码“逸出”到临界区之外。JMM 会在退出 Monitor 和进入 Monitor 这两个关键时间点做一些特别处理，使得线程在这两个时间点具有与顺序一致性模型相同的内存视图。虽然线程在临界区内可以做重排序，但其他线程根本无法“观察”到该线程在临界区内的重排序。这种重排序既提高了执行效率，又没有改变程序的执行结果。 ReentrantLockReentrantLock 实现的 happens-before 关系和内存语义与 Synchronized 的一样。ReentrantLock 实现的基础是 Volatile 变量和 CAS, 上面提到了 Volatile 变量的读/写可以实现”禁止重排序”的效果, CAS 操作同时具有 Volatile 读和写的禁止重排序效果. 「CAS的原理和实现的内存语义」一节介绍了 CAS 是如何同时具有 Volatile 变量的读和写的内存语义的. ReentrantLock 内存语义的实现解析回顾 ReentrantLock 的实现，lock() 调用栈如下： ReentrantLock : lock() FairSync : lock() AbstractQueuedSynchronizer : acquire(int arg) ReentrantLock : tryAcquire(int acquires) 在第 4 步真正开始加锁，tryAcquire方法首先读 volatile 变量 state， 如果state==0, 说明还未加锁, 再尝试CAS(state, 0, 1), 如果 CAS 成功则成功获取到锁; 如果state!=0, 说明已经加锁, 再判断 ExclusiveOwnerThread 是否等于当前线程, 如果等于, 重入该锁(立刻获取到锁) 解锁方法unlock()的方法调用栈如下(公平锁为例)： ReentrantLock : unlock() AbstractQueuedSynchronizer : release(int arg) Sync : tryRelease(int releases) 在第 3 步真正开始释放锁，tryRelease方法首先读 volatile 变量 state， 读取到的值-1, 然后把这个减 1 后的值写入 state(这里并没用 CAS 更新), 如果这个减 1 后的值=0, 则把锁状态置为 free 由上可知, 公平锁在释放锁的时候写 Volatile 变量, 在获取锁的时候读取 Volatile 变量, 根据 volatile 的 happens-before 规则：释放锁的线程在写 volatile 变量之前可见的共享变量，在获取锁的线程读取同一个 volatile 变量后将立即变的对获取锁的线程可见。 CAS 的原理和实现的内存语义CAS 同时具有 volatile 读和 volatile 写的内存语义。下面我们来分析在常见的 intel x 86 处理器中，CAS 是如何同时具有 volatile 读和 volatile 写的内存语义的。 sun.misc.Unsafe 类的compareAndSwapInt()方法是个 Native 方法, 最终调用到了 JVM 的 C++代码Atomic::cmpxchg()（compare and change）, C++的Atomic::cmpxchg()最终调用的是”compare and change”的汇编代码cmpxchg , Atomic::cmpxchg()函数会根据当前处理器的类型来决定是否为 cmpxchg 指令添加 lock 前缀。如果程序是在多处理器上运行，就为 cmpxchg 指令加上 lock 前缀（汇编代码是这个样子 lock cmpxchg dword ptr[edx], ecx）。intel 的手册对lock前缀的说明如下： 确保对内存的读-改-写操作原子执行。 禁止该指令与之前和之后的读和写指令重排序。 把写缓冲区中的所有数据刷新到内存中。 上面的第 2 点和第 3 点所具有的内存屏障效果，足以同时实现 volatile 读和 volatile 写的内存语义。所以，现在我们终于能明白为什么 JDK 文档说 CAS 同时具有 volatile 读和 volatile 写的内存语义 了。 cmpxchg 和 lock 前缀的解析，详细见 -&gt; Java-并发.05a.JUC-Atomic&CAS Concurrent 包的实现总结: Volatile 和 CAS由于 java 的 CAS 同时具有 volatile 读和 volatile 写的内存语义，因此 Java 线程之间的通信现在有了下面四种方式： A 线程写 volatile 变量，随后 B 线程读这个 volatile 变量。 A 线程写 volatile 变量，随后 B 线程用 CAS 更新这个 volatile 变量。 A 线程用 CAS 更新一个 volatile 变量，随后 B 线程用 CAS 更新这个 volatile 变量。 A 线程用 CAS 更新一个 volatile 变量，随后 B 线程读这个 volatile 变量。 Java 的 CAS 会使用现代处理器上提供的高效机器级别原子指令，这些原子指令以原子方式对内存执行读-改-写操作，这是在多处理器中实现同步的关键。同时，volatile 变量的读/写和 CAS 可以实现线程之间的通信。把这些特性整合在一起，就形成了整个 concurrent 包得以实现的基石。如果我们仔细分析 concurrent 包的源代码实现，会发现一个通用化的实现模式： 首先，声明共享变量为 volatile； 然后，使用 CAS 的原子条件更新来实现线程之间的同步； 同时，配合以volatile 读/写的内存语义 和 CAS 的内存语义，来实现线程之间的通信。 下图是 Java concurrent 包的实现层次结构, 以 Volatile 和 CAS 为基础, JDK 实现了 AQS / Atomic 类 / 非阻塞队列等等基本类, 然后通过这些基本类实现了重入锁, 阻塞队列, 线程池等.. final对于 final 域，编译器和处理器要遵守两个重排序规则： 在构造函数内对一个 final 域的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。 初次读一个包含 final 域的对象的引用，与随后初次读这个 final 域，这两个操作之间不能重排序。 读写 FINAL 域的重排序规则① 写: 写 final 域的重排序规则禁止把 final 域的写重排序到构造函数之外。这个规则的实现包含下面 2 个方面： JMM 禁止编译器把 final 域的写重排序到构造函数之外。 编译器会在 final 域的写之后，构造函数 return 之前，插入一个 StoreStore 屏障。这个屏障禁止处理器把 final 域的写重排序到构造函数之外。 ② 读: 在一个线程中，初次读对象引用与初次读该对象包含的 final 域，JMM 禁止处理器重排序这两个操作（注意，这个规则仅仅针对处理器）。编译器会在读 final 域操作的前面插入一个 LoadLoad 屏障。 FINAL 域是引用类型对于引用类型，写 final 域的重排序规则对编译器和处理器增加了如下约束：在构造函数内对一个 final 引用的对象的成员域的写入，与随后在构造函数外把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。 回到错误的 DCL 单例代码常见的双重锁检查（Double Checked Locking）的单例代码如下： public class DoubleCheckedLocking &#123; //1 private static Instance instance; //2 public static Instance getInstance() &#123; //3 if (instance == null) &#123; //4:第一次检查 synchronized (DoubleCheckedLocking.class) &#123; //5:加锁 if (instance == null) //6:第二次检查 instance = new Instance(); //7:问题的根源出在这里 &#125; //8 &#125; //9 return instance; //10 &#125; //11&#125; 但是这样写是有问题的，在多线程并发的情况下，当有某个线程在步骤 4 进行检查的时候发现 instance 非 null，但 instance 却指向一块已经分配但是未初始化的内存。 为什么出现这种情况：示例代码的第 7 行instance = new Instance()创建一个对象。这一行代码可以分解为如下的三行伪代码： synchronized (DoubleCheckedLocking.class) &#123; if (instance == null) &#123; memory = allocate(); //1：分配对象的内存空间 ctorInstance(memory); //2：构造函数，初始化对象 instance = memory; //3：设置 instance 指向刚分配的内存地址 &#125;&#125; 由 JSR-133 的 happens-before 和as-if-serial语义，在单线程里 1 happens-before 3，但 2 不能保证 happens-before 3， 如果发生了 1-3-2 的重排序，调用构造方法初始化对象被重排序到了最后一步，当线程 A 执行完 3，但还没执行 2 的时候(instance 指向分配好的内存, 但这块内存还未由构造函数初始化)，此时线程 B 开始运行, 到第一次判断 instance==null，线程 B 可能看到 instance 的值，所以不用走下面的 sync, 线程 B 直接获得了这个 instance（一个还未初始化的) 引用。然后就出问题了 所以, 解决方法有两种思路: 不允许 2 和 3 重排序； 允许 2 和 3 重排序，但不允许其他线程“看到”这个重排序，也即 1-3-2 都执行完之后其他线程才可以”看到”改变（可见性）。 第一种解决方案是, 将 instance 变量声明成 volatile。当声明对象的引用为 volatile 后，“问题的根源”的三行伪代码中的 2 和 3 之间的重排序，在多线程环境中将会被禁止。 第二种方案, 基于类初始化锁, 代码示例: public class InstanceFactory &#123; // 单例放在内部类 private static class InstanceHolder &#123; public static Instance instance = new Instance(); &#125; public static Instance getInstance() &#123; return InstanceHolder.instance ; // 这里将导致 InstanceHolder 类被初始化 &#125;&#125; 回顾一下 Java 对初始化的规范: T 是一个类, 首次对 T 的 static 成员属性进行读写的时候, 会触发 T 的初始化 T 是一个外部类, T 被初始化的时候, 其静态内部类 Inner 不会被初始化, 作为内部类, InstanceHolder 不会在外部类初始化时被初始化(可以实现延后初始化),首次调用 InstanceFactory.getInstance()的时候, 相当于调用了 getstatic指令读取 InstanceHolder 的静态属性, 会导致 InstanceHolder 被初始化,初始化包括执行 static 代码块, 初始化 static 成员属性, 这些操作代码都被放在一个叫 &lt; clinit &gt;的方法中, 被 JVM 加锁执行.这个方案的实质是：允许“问题的根源”的三行伪代码中的 2 和 3 重排序，但不允许其他线程（这里指线程 B）“看到”这个重排序。 Java 语言规范规定，对于每一个类或接口 C，都有一个唯一的初始化锁 LC 与之对应。从 C 到 LC 的映射，由 JVM 的具体实现去自由实现。JVM 在类初始化期间会获取这个初始化锁，并且每个线程至少获取一次锁来确保这个类已经被初始化过了 Reference 深入理解Java内存模型（一）——基础 深入理解Java内存模型（二）——重排序 深入理解Java内存模型（三）——顺序一致性 深入理解Java内存模型（四）——volatile 深入理解Java内存模型（五）——锁 双重检查锁定与延迟初始化 PDF：[[../_attachments/深入理解Java内存模型.pdf]]","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"https://beefyheisenberg.github.io/tags/Java并发/"},{"name":"JMM","slug":"JMM","permalink":"https://beefyheisenberg.github.io/tags/JMM/"}]},{"title":"Java-并发.08.多线程设计模式","slug":"12.Java/Java-并发.08.多线程设计模式","date":"2024-01-24T01:27:52.242Z","updated":"2024-01-24T01:27:52.242Z","comments":true,"path":"12.Java/Java-并发.08.多线程设计模式/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-并发.08.多线程设计模式/","excerpt":"Guarded Suspension 模式Guarded Suspension 模式: guarded 是“被保护着的”、“被防卫着的”意思，suspension 则是“暂停”的意思。当现在并不适合马上执行某个操作时，让要执行该操作的线程等待。 public synchronized Request getRequest() &#123; while (queue.size() &lt;= 0) &#123; // _警戒条件（guard condition）_ try &#123; wait(); &#125; catch (InterruptedException e) &#123; &#125; &#125; return (Request)queue.removeFirst();&#125; @ref Java多线程基础（五）——Guarded Suspension模式 - 透彻理解Java并发编程 - SegmentFault 思否 Balking 模式","text":"Guarded Suspension 模式Guarded Suspension 模式: guarded 是“被保护着的”、“被防卫着的”意思，suspension 则是“暂停”的意思。当现在并不适合马上执行某个操作时，让要执行该操作的线程等待。 public synchronized Request getRequest() &#123; while (queue.size() &lt;= 0) &#123; // _警戒条件（guard condition）_ try &#123; wait(); &#125; catch (InterruptedException e) &#123; &#125; &#125; return (Request)queue.removeFirst();&#125; @ref Java多线程基础（五）——Guarded Suspension模式 - 透彻理解Java并发编程 - SegmentFault 思否 Balking 模式Balking是“退缩不前”的意思。Balking Pattern和Guarded Suspension Pattern 一样需要警戒条件。在Balking Pattern中，当警戒条件不成立时，会马上中断，而Guarded Suspension Pattern 则是等待到可以执行时再去执行。 @ref Java多线程基础（六）——Balking模式 - 透彻理解Java并发编程 - SegmentFault 思否 Two -phase Termination 模式两段式终止: 当某个工作收到 shutdown 之类的指令后，不是立刻停止，而是进入一个“已收到终止请求”的状态，可以进行一些资源回收，这一步完成后，再进入“终止处理中”的状态 // 若数据有修改，则保存，否则直接返回public synchronized void save() throws IOException &#123; if (!changed) &#123; System.out.println(Thread.currentThread().getName() + &quot; balks&quot;); return; &#125; doSave(); changed = false;&#125; @ref Java多线程基础（十二）——Two-phase Termination模式 - 透彻理解Java并发编程 - SegmentFault 思否","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"https://beefyheisenberg.github.io/tags/Java并发/"},{"name":"JUC","slug":"JUC","permalink":"https://beefyheisenberg.github.io/tags/JUC/"}]},{"title":"Java-并发.06c.JUC-执行器-Fork/Join框架","slug":"12.Java/Java-并发.06c.JUC-Fork&Join","date":"2024-01-24T01:27:52.238Z","updated":"2024-01-24T01:27:52.238Z","comments":true,"path":"12.Java/Java-并发.06c.JUC-Fork&Join/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-并发.06c.JUC-Fork&Join/","excerpt":"Fork/Join 框架Java 在 JDK 7 之后加入了并行计算的框架 Fork/Join，可以解决我们系统中大数据计算的性能问题。Fork/Join 采用的是分治法，Fork 是将一个大任务拆分成若干个子任务，子任务分别去计算，而 Join 是获取到子任务的计算结果，然后合并，这个是递归的过程。子任务被分配到不同的核上执行时，效率最高。 Fork/Join 框架的核心是 ForkJoinPool (类似 ExecuteService ) 会给线程池中的线程分发任务，不同之处在于，ForkJoinPool 将一个大任务拆分为若干互不依赖的子任务，把这些子任务分别放到不同的队列里，并为每个队列创建一个单独的线程来执行队列里的任务。 同时，为了最大限度地提高并行处理能力，采用了工作窃取算法来运行任务，也就是说当某个线程处理完自己工作队列中的任务后，尝试当其他线程的工作队列中窃取一个任务来执行，直到所有任务处理完毕。 ForkJoinTask 是一个抽象类，有两个实现子类，RecursiveTask（有返回值）和 RecursiveAction（无返回结果），我们自己定义任务时，只需选择这两个类继承即可。","text":"Fork/Join 框架Java 在 JDK 7 之后加入了并行计算的框架 Fork/Join，可以解决我们系统中大数据计算的性能问题。Fork/Join 采用的是分治法，Fork 是将一个大任务拆分成若干个子任务，子任务分别去计算，而 Join 是获取到子任务的计算结果，然后合并，这个是递归的过程。子任务被分配到不同的核上执行时，效率最高。 Fork/Join 框架的核心是 ForkJoinPool (类似 ExecuteService ) 会给线程池中的线程分发任务，不同之处在于，ForkJoinPool 将一个大任务拆分为若干互不依赖的子任务，把这些子任务分别放到不同的队列里，并为每个队列创建一个单独的线程来执行队列里的任务。 同时，为了最大限度地提高并行处理能力，采用了工作窃取算法来运行任务，也就是说当某个线程处理完自己工作队列中的任务后，尝试当其他线程的工作队列中窃取一个任务来执行，直到所有任务处理完毕。 ForkJoinTask 是一个抽象类，有两个实现子类，RecursiveTask（有返回值）和 RecursiveAction（无返回结果），我们自己定义任务时，只需选择这两个类继承即可。 java.lang.Object java.util.concurrent.ForkJoinTask&lt;V&gt; java.util.concurrent.RecursiveTask&lt;V&gt; 继承 RecursiveTask 和 RecursiveAction 类必须实现 compute() 方法，在这个方法里要实现递归控制条件。 compute() 的实现通常为: if (任务足够小)&#123; 直接执行该任务;&#125;else&#123; 将任务一分为二; Fork执行这两个任务; Join等待结果;&#125; 下面是一个计算数组之和的 Fork/Join 例子: public class CJForkJoinTask extends RecursiveTask&lt;Integer&gt;&#123; // 要计算和的数组 private long[] array; private int low; private int high; @Override protected Integer compute() &#123; int sum = 0; if (high - low &lt;= THRESHOLD) &#123; // 小于阈值则直接计算 &#125; else &#123; // 一个大任务分割成两个子任务 int mid = (low + high) &gt;&gt;&gt; 1; CJForkJoinTask left = new CJForkJoinTask(array, low, mid); CJForkJoinTask right = new CJForkJoinTask(array, mid + 1, high); left.fork(); right.fork(); sum = left.join() + right.join(); &#125; return sum; &#125; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; // 生成大数组: long[] array = genArray(1000000); // 创建Fork/Join任务: CJForkJoinTask CJForkJoinTask = new CJForkJoinTask(array, 0, array.length - 1); // 创建Fork/Join线程池: ForkJoinPool forkJoinPool = new ForkJoinPool(); // 提交任务到线程池: forkJoinPool.submit(CJForkJoinTask); // 获取结果: Integer result = CJForkJoinTask.get(); &#125;&#125;","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"https://beefyheisenberg.github.io/tags/Java并发/"},{"name":"JUC","slug":"JUC","permalink":"https://beefyheisenberg.github.io/tags/JUC/"}]},{"title":"Java-并发.06b.JUC-执行器-Future","slug":"12.Java/Java-并发.06b.JUC-Future","date":"2024-01-24T01:27:52.233Z","updated":"2024-01-24T01:27:52.234Z","comments":true,"path":"12.Java/Java-并发.06b.JUC-Future/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-并发.06b.JUC-Future/","excerpt":"FutureCallable 接口类似于 Runnable，但是 Runnable 不会返回结果，并且无法抛出返回结果的异常，Callable 功能更强大一些，被线程执行后，可以返回结果。 Callable 有些类似 Runnable, 它们都是接口, 前者需要实现 V call(), 后者需要实现 void run(); Callable 需要用 FutureTask 包装一下, FutureTask 提供了 get() 方法, 可以获取执行结果; FutureTask 需要通过 Thread 执行: 通过构造器 Thread(FutureTask) 创建 Thread 对象 结果通过 FutureTask.get 获取, FutureTask 实现了 Future 接口, 通过 FutureTask 和 Future 类型引用都可以调用 get() , cancel() , isDone() , isCancelled() 等方法; Callable 也可以放入线程池, ExecutorService.submit(Callable) 把 Callable 提交到线程池并返回 Future ;","text":"FutureCallable 接口类似于 Runnable，但是 Runnable 不会返回结果，并且无法抛出返回结果的异常，Callable 功能更强大一些，被线程执行后，可以返回结果。 Callable 有些类似 Runnable, 它们都是接口, 前者需要实现 V call(), 后者需要实现 void run(); Callable 需要用 FutureTask 包装一下, FutureTask 提供了 get() 方法, 可以获取执行结果; FutureTask 需要通过 Thread 执行: 通过构造器 Thread(FutureTask) 创建 Thread 对象 结果通过 FutureTask.get 获取, FutureTask 实现了 Future 接口, 通过 FutureTask 和 Future 类型引用都可以调用 get() , cancel() , isDone() , isCancelled() 等方法; Callable 也可以放入线程池, ExecutorService.submit(Callable) 把 Callable 提交到线程池并返回 Future ; public class FutureAndFutureTaskExample &#123; /* * FutureTask 示例1: * 由FutureTask直接创建线程,并执行 */ public static void futureTaskExample() &#123; // 创建Callable实现类 Callable callable = new Callable&lt;Integer&gt;() &#123; @Override public Integer call() throws Exception &#123; return new Random().nextInt(100); &#125; &#125;; // 创建FutureTask FutureTask futureTask = new FutureTask(callable); // 创建Thread 并开始执行 new Thread(futureTask).start(); // 阻塞在此, 直到任务完成: Integer result = futureTask.get(); &#125; /* * Future 示例2: * Callable 提交到线程池执行 */ public static void futureExample() &#123; // Lambda创建Callable实现类 Callable&lt;Integer&gt; callable = () -&gt; &#123; return new Random().nextInt(100); &#125; ; ExecutorService executorService = Executors.newCachedThreadPool(); Future&lt;Integer&gt; future = executorService.submit(callable); Integer result = future.get(); // 或取消线程 future.cancel(true); &#125;&#125; 问题: FutureTask.cancel() 和 Thread.interrupt() 有什么区别?通过查看 cancel() 的源码发现, 实际 cancel() 最终还是调用了 Thread.interrupt(),所以, 要通过 FutureTask.cancel() 停止异步任务, 那么还需要在 Runnable 或 Callable 的主循环里捕捉 InterruptException 异常. ListenableFuture(Guava)Guava 的 Listenable Future 对 Future 做了改进，支持注册一个任务执行结束后回调函数。 // 创建一个 ListenableFutureListenableFuture&lt;String&gt; listenableFuture =listeningExecutor.submit(new Callable&lt;String&gt;() &#123; @Override public String call() throws Exception &#123; return \"\"; &#125;&#125;);// 通过addCallback() 给 ListenableFuture增加回调Futures.addCallback(ListenableFuture, new FutureCallback&lt;Object&gt;() &#123; public void onSuccess(Object result) &#123; // do something on success &#125; public void onFailure(Throwable thrown) &#123; // do something on failure &#125;&#125;); CompletableFuture(Java8)Future 是 Java 5添加的类，用来描述一个异步计算的结果。你可以使用 isDone 方法检查计算是否完成，或者使用 get 阻塞住调用线程，直到计算完成返回结果，你也可以使用 cancel 方法停止任务的执行。 虽然Future以及相关使用方法提供了异步执行任务的能力，但是对于结果的获取却是很不方便，只能通过阻塞或者轮询的方式得到任务的结果。阻塞的方式显然和我们的异步编程的初衷相违背，轮询的方式又会耗费无谓的CPU资源，而且也不能及时地得到计算结果，为什么不能用观察者设计模式当计算结果完成及时通知监听者呢？ 在Java 8中, 新增加了一个包含50个方法左右的类: CompletableFuture，提供了非常强大的Future的扩展功能，可以帮助我们简化异步编程的复杂性，提供了函数式编程的能力，可以通过回调的方式处理计算结果，并且提供了转换和组合CompletableFuture的方法。 使用示例Java8 的 CompletableFuture 参考了 Guava 的 ListenableFuture 的思路，CompletableFuture 能够将回调放到与任务不同的线程中执行，也能将回调作为继续执行的同步函数，在与任务相同的线程中执行。 CompletableFuture 弥补了 Future 模式的缺点。在异步的任务完成后，需要用其结果继续操作时，无需等待。可以直接通过 thenAccept、thenApply、thenCompose 等方式将前面异步处理的结果交给另外一个异步事件处理线程来处理。 与 Guava ListenableFuture 相比，CompletableFuture 不仅可以在任务完成时注册回调通知，而且可以指定任意线程，实现了真正的异步非阻塞。 ▶ 创建一个 CompletableFuture:public static CompletableFuture&lt;Void&gt; runAsync(Runnable runnable)public static CompletableFuture&lt;Void&gt; runAsync(Runnable runnable, Executor executor)public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier)public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier, Executor executor) runAsync 方法不支持返回值/supplyAsync 可以支持返回值没有指定 Executor 的方法会使用 ForkJoinPool.commonPool() 作为它的线程池执行异步代码。如果指定线程池，则使用指定的线程池运行。以下所有的方法都类同。 ▶ 使用 thenApply 串行任务:public &lt;U&gt; CompletableFuture&lt;U&gt; thenApply(Function&lt;? super T, ? extends U&gt; fn)public &lt;U&gt; CompletableFuture&lt;U&gt; thenApplyAsync(Function&lt;? super T, ? extends U&gt; fn)public &lt;U&gt; CompletableFuture&lt;U&gt; thenApplyAsync(Function&lt;? super T, ? extends U&gt; fn, Executor executor) 当一个线程依赖另一个线程时，可以使用 thenApply 方法来把这两个线程串行化。T：上一个任务返回结果的类型U：当前任务的返回值类型 ▶使用 thenAccept 消费处理结果:public CompletionStage&lt;Void&gt; thenAccept(Consumer&lt;? super T&gt; action);public CompletionStage&lt;Void&gt; thenAcceptAsync(Consumer&lt;? super T&gt; action);public CompletionStage&lt;Void&gt; thenAcceptAsync(Consumer&lt;? super T&gt; action,Executor executor); ▶ 使用 thenCombine 合并任务:public &lt;U,V&gt; CompletionStage&lt;V&gt; thenCombine(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T, ? super U, ? extends V&gt; fn);public &lt;U,V&gt; CompletionStage&lt;V&gt; thenCombineAsync(CompletionStage&lt;? extends U&gt; other,BiFunction&lt;? super T,? super U,? extends V&gt; fn);public &lt;U,V&gt; CompletionStage&lt;V&gt; thenCombineAsync(CompletionStage&lt;? extends U&gt; other,BiFunction&lt;? super T,? super U,? extends V&gt; fn,Executor executor); thenCombine 会把两个 CompletionStage 的任务都执行完成后，把两个任务的结果一块交给 thenCombine 来处理。 ▶ 使用 thenCompose 流水化处理任务:public &lt;U&gt; CompletableFuture&lt;U&gt; thenCompose(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn);public &lt;U&gt; CompletableFuture&lt;U&gt; thenComposeAsync(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn) ;public &lt;U&gt; CompletableFuture&lt;U&gt; thenComposeAsync(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn, Executor executor) ; thenCompose 方法允许你对两个 CompletionStage 进行流水线操作，第一个操作完成时，将其结果作为参数传递给第二个操作。 ▶ 代码示例 1: thenApply/whenComplete/exceptionally public static void example() throws Exception &#123; CompletableFuture&lt;Long&gt; future = CompletableFuture.supplyAsync(new Supplier&lt;Long&gt;() &#123; @Override public Long get() &#123; long result = new Random().nextInt(100); return result; &#125; &#125;).thenApply(new Function&lt;Long, Long&gt;() &#123; @Override public Long apply(Long t) &#123; long result = t*5; System.out.println(\"result2=\"+result); return result; &#125; &#125;); future.whenComplete(new BiConsumer&lt;Void, Throwable&gt;() &#123; @Override public void accept(Void t, Throwable action) &#123; System.out.println(\"执行完成！\"); &#125; &#125;); future.exceptionally(new Function&lt;Throwable, Void&gt;() &#123; @Override public Void apply(Throwable t) &#123; System.out.println(\"执行失败！\"+t.getMessage()); return null; &#125; &#125;);&#125; ▶ anyOf / allOfpublic static CompletableFuture&lt;Object&gt; anyOf(CompletableFuture&lt;?&gt;... cfs);public static CompletableFuture&lt;Void&gt; allOf(CompletableFuture&lt;?&gt;... cfs); anyOf: 当任意一个 CompletableFuture 完成后，创建一个完成的 CompletableFutureallOf: 当所有的阶段完成后, 创建一个完成的 CompletableFuture public static CompletableFuture&lt;List&gt; example() &#123; CompletableFuture&lt;Double&gt; future1 = rpcService1.invoke(); CompletableFuture&lt;Double&gt; future2 = rpcService2.invoke(); return CompletableFuture .allOf(future1, future2) .thenApply(v -&gt; &#123; Double d1 = future1.get(); Double d2 = future2.get(); return Arrays.asList(d1, d2); &#125;);&#125; 本节参考: Java CompletableFuture 详解 | 鸟窝 [译]20个使用 Java CompletableFuture 的例子 | 鸟窝 Timeout @ref Java 8 CompletableFuture中的默认值超时 - Thinbug似乎是翻译的 Stack Overflow … @ref Asynchronous timeouts with CompletableFutures in Java 8 and Java 9超时 &amp; CompletableFutures如果直接对 CompletableFutures 使用 Future.get(1, TimeUnit.SECONDS) 作为超时, 这样做仍旧阻塞 main 线程;在 Java9 中的支持: completeOnTimeout 或者 orTimeout vs ParallelStream@ref: Java8的completablefuture和parallel stream比较 -解道Jdon 可以上面的代码, ParallelStream 使用的 forkJoinPool, 处理过程会回到主线程调用 task（因为 forkJoinPool 使用了分治+递归，要回到主线程） CompletableFuture 默认也是使用 forkJoinPool 的线程池, 但没有回到主线程 因为 CompletableFuture 默认使用 forkJoinPool 线程池，所以线程池大小有限制 = processor 的数量，当然 CompletableFuture 也可以自己指定线程池，如果不是 CPU 密集而是 IO 密集的任务，最好是指定自己的线程池（ CPU Processor 的 2~3 倍 ）","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"https://beefyheisenberg.github.io/tags/Java并发/"},{"name":"JUC","slug":"JUC","permalink":"https://beefyheisenberg.github.io/tags/JUC/"}]},{"title":"Java-并发.06a.JUC-执行器-线程池","slug":"12.Java/Java-并发.06a.JUC-线程池","date":"2024-01-24T01:27:52.229Z","updated":"2024-01-24T01:27:52.229Z","comments":true,"path":"12.Java/Java-并发.06a.JUC-线程池/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-并发.06a.JUC-线程池/","excerpt":"线程池相关类和方法 ExecutorService: Java线程池的接口, 提供了如下方法: void execute(Runnable command) 执行 Ruannable 类型的任务 Future&lt;?&gt; submit(Runnable task) 可用来提交 Callable 或 Runnable 任务，并返回代表此任务的 Future 对象 Future&lt;T&gt; submit(Callable&lt;T&gt; task): 同上 void shutdown() : 关闭线程池，不再接受新提交的任务，但却可以继续处理阻塞队列中已保存的任务。最终调用了每个线程的 interrupt() void shutdownNow() : 关闭线程池, 中断正在处理任务的线程，也不处理阻塞队列中已保存的任务。最终调用了每个线程的 interrupt() boolean isShutdown() 几种常见的线程池实现类： ThreadPoolExecutor: 实现了ExecutorService接口, 通用线程池 ScheduledExecutorService: 也实现了 ExecutorService 接口, 它的 schedule() 方法用来执行定时任务 Executors 是线程池的工厂类, 用于创建线程池:","text":"线程池相关类和方法 ExecutorService: Java线程池的接口, 提供了如下方法: void execute(Runnable command) 执行 Ruannable 类型的任务 Future&lt;?&gt; submit(Runnable task) 可用来提交 Callable 或 Runnable 任务，并返回代表此任务的 Future 对象 Future&lt;T&gt; submit(Callable&lt;T&gt; task): 同上 void shutdown() : 关闭线程池，不再接受新提交的任务，但却可以继续处理阻塞队列中已保存的任务。最终调用了每个线程的 interrupt() void shutdownNow() : 关闭线程池, 中断正在处理任务的线程，也不处理阻塞队列中已保存的任务。最终调用了每个线程的 interrupt() boolean isShutdown() 几种常见的线程池实现类： ThreadPoolExecutor: 实现了ExecutorService接口, 通用线程池 ScheduledExecutorService: 也实现了 ExecutorService 接口, 它的 schedule() 方法用来执行定时任务 Executors 是线程池的工厂类, 用于创建线程池: ExecutorService newCachedThreadPool(): 创建一个可缓存线程池，队列容量固定是1（可以认为没有队列），线程数会一直增长（如果没有空闲线程），如果线程空闲超过60s会被回收； ExecutorService newFixedThreadPool(int nThreads): 创建一个定长线程池，超出的线程会进入等待队列，队列是无限大的； ExecutorService newSingleThreadExecutor(): 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 ScheduledExecutorService newScheduledThreadPool(int corePoolSize): 创建一个定长线程池，支持定时及周期性任务执行。 示例代码: public static void tpoolTest() &#123; ExecutorService cachedPool = Executors.newCachedThreadPool(); ExecutorService fixedPool = Executors.newFixedThreadPool(5); ScheduledExecutorService schedulePool = Executors.newScheduledThreadPool(1); // execute()无返回值 cachedPool.execute(new Runnable() &#123; @Override public void run() &#123; /*doSomething*/ &#125; &#125;); cachedPool.shutdown(); // submit()有返回值 // labmda写法 Futrue&lt;String&gt; futrue = fixedPool.submit(() -&gt; &#123; return \"hello world\"; &#125;); String ret = futrue.get(); fixedPool.shutdownNow(); // schedule()增加定时任务 schedulePool.schedule(() -&gt; &#123; System.out.print(\"scheduled task\"); &#125;, 5, TimeUnit.SECONDS ); schedulePool.shutdown();&#125; 线程池的实现构造方法工厂类 Executors 包装了对 ThreadPoolExecutor 构造方法的调用, 隐藏了很多创建线程池的细节, 所以在并发严格的情况下, 最好的方式还是直接调用 ThreadPoolExecutor 构造方法创建线程池. ThreadPoolExecutor的构造函数: public class ThreadPoolExecutor extends AbstractExecutorService &#123; public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,RejectedExecutionHandler handler); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler);&#125; 构造器中各个参数的含义: corePoolSize: （线程池的基本大小）：当提交一个任务到线程池时，线程池会创建一个线程来执行任务，即使其他空闲的基本线程能够执行新任务也会创建线程，等到线程数大于 corePoolSize 时就不再创建。如果调用了线程池的 prestartAllCoreThreads() 方法，线程池会提前创建并启动所有基本线程。 workQueue: 一个阻塞队列，用来存储等待执行的任务。当线程数已经大于 corePoolSize 时, 再向线程池添加任务，会把任务放入该队列中。阻塞队列有以下几种选择： ArrayBlockingQueue：基于数组结构的 有界阻塞队列，此队列按 FIFO（先进先出）排序元素。因为入队/出队操作的同步都用同一个 lock 对象，所以生产者和消费者无法同时进行，所以吞吐量低； LinkedBlockingQueue：一个基于链表结构的 有界阻塞队列，如果队列不指定 size，默认长度是 Integer.MAX，此队列按 FIFO （先进先出）排序元素，吞吐量通常要高于 ArrayBlockingQueue（因为使用了两个 lock，读写不冲突）。 Executors.newFixedThreadPool() 使用了这个队列。 SynchronousQueue：一个不存储元素的 有界阻塞队列。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态（可以这样来理解：生产者和消费者互相等待对方，握手然后一起离开）。Executors.newCachedThreadPool() 使用了这个队列。 PriorityBlockingQueue：一个具有优先级的 无限阻塞队列，此队列按优先级排序元素。 maximumPoolSize: 线程池最大容量（池+队列里的线程数）。 如果是 LinkedBlockingQueue 这种 近似无界的队列，maximumPoolSize 没有效果； 如果是 ArrayBlockingQueue 这种 有界阻塞队列，如果队列满了，并且已创建的线程数小于 maximumPoolSize，则线程池会再创建新的线程执行任务，直到总线程数超过 maximumPoolSize。 keepAliveTime: 工作线程空闲后，保持存活的时间。线程池会一直终止空闲超过 keepAliveTime 的线程，直到线程池中的线程数不超过 corePoolSize。 unit: keepAliveTime 的单位 handler: 当队列和线程池都满了（maximumPoolSize），说明线程池处于饱和状态，那么必须采取一种策略处理提交的新任务。这个策略默认情况下是AbortPolicy，表示无法处理新任务时抛出异常。 AbortPolicy：直接抛出异常。 CallerRunsPolicy：只用调用者所在线程来运行任务。 DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。 DiscardPolicy：不处理，丢弃掉。 ➤ 再回过来看 Executors 提供的几种工厂方法: newCachedThreadPool(): corePoolSize 为0, maximumPoolSize 为 INT.Max, 队列使用 SynchronousQueue 不存储线程, 所以有新任务提交时, 如果没有空闲的线程, 则继续创建新的线程, 直到线程数达到 INT.Max. 空闲时间超过 60s 的线程会被回收； newFixedThreadPool(int nThreads): corePoolSize 和 maximumPoolSize 都是 nThreads, 意味着线程池大小从 0 会增长到 coreSize, 队列是近似无界队列 LinkedBlockingQueue, 可以一直接收新任务, keepAliveTime=0 意味着不会回收空闲线程 newSingleThreadExecutor(): 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 上面提到的几种线程池，都有不足： 使用 newCachedThreadPool() 的问题在于, 如果没有控制好任务大小(所有线程一直在忙) 线程数会一直增长（maxPoolSize 是 Integer.MAX_VALUE). 只有线程空闲的时候才有机会减少线程数. 使用 newFixedThreadPool() 的问题在于, 虽然工作线程数是固定的, 但是等待队列大小是 Integer.MAX_VALUE, 这两种线程池都有可能因为创建大量线程导致 OOM. 所以不建议使用 Executors 提供的方法直接创建线程池 提交任务当提交一个新任务到线程池时（execute or submit），线程池的处理流程如下： 首先线程池判断基本线程池（corePoolSize） 是否已满？没满，创建一个工作线程来执行任务。满了，则进入下个流程。 其次线程池判断工作队列（workQueue） 是否已满？这一步尝试队列能否 offer 进新任务，如果 offer 失败（队列满），则进入下个流程。 最后线程池判断整个线程池（maximumPoolSize） 是否已满？没满，则创建一个新的工作线程来执行任务，满了，则交给饱和策略来处理这个任务。 public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); // ctl 是 Atomic类型 // 32位，高3位=线程池状态 ,后29位=当前运行worker的数量 int c = ctl.get(); // (1) corePoolSize if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) // 创建新线程 return; c = ctl.get(); &#125; // (2) taskQueue.offer if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; // (3) 大于coresize 且 queue满，再尝试增加线程数量到maximumPoolSize else if (!addWorker(command, false)) reject(command); // 拒绝&#125; 提交任务时，使用的是 TaskQueue 的 offer() 方法，不会阻塞调用线程； submit 方法在 AbstractExecutorService 中的实现： public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); // 通过 submit 方法提交的 Callable 任务会被封装成了一个 FutureTask 对象 RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask; &#125; 工作线程流程： execute –&gt; addWorker() –&gt;runWorker() 向线程池提交 Runnable, 会调用到线程池的 addWorker()，这个方法里会将工作线程封装成 Worker 类，在 ReentrantLock 锁的保证下，把 Woker 实例插入到 HashSet 后，并启动 Woker 中的线程。从 Woker 类的构造方法实现可以发现: 线程工厂在创建线程 thread 时，将 Woker 实例本身 this 作为参数传入，当执行 start 方法启动线程 thread 时，本质是执行了 Worker 的 runWorker 方法。 Worker 在执行完任务(firstTask)后，还会通过 runWorker() 无限循环获取工作队列里的任务来执行: public void runWorker() &#123; try &#123; // 执行当前task或从队列里取出新的task while (task != null || (task = getTask()) != null) &#123; w.lock(); beforeExecute(wt, task); task.run(); // 执行Runnable.run() afterExecute(task, thrown); &#125; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125;&#125; 关闭线程池线程池的 shutdown 或者 shutdownNow 方法来关闭线程池。 shutdown 方法将执行平缓的关闭过程：线程池状态设置为 SHUTDOWN，不接收新的任务，同时等待已提交的任务执行完成，包括哪些在队列中的任务； shutdownNow 方法将执行粗暴的关闭过程：线程池状态设置为 STOP，不接收新的任务，它将尝试取消（Interrupt）所有运行中的任务，并且清空等待队列（未开始的任务也不会再执行）； 优化线程池线程池参数的解析和使用建议: 线程池大小: 如果是 计算密集 任务，一般设置为 cpu 核心数 （ForkJoin 的 common 线程池） 如果是 IO 密集 任务一般设置为核心数2~3倍（Tomcat 的 Poller 线程池 &amp; Netty 的 sub-Reactor 线程池） 业务线程池：视业务耗时和吞吐量而定（Tomcat 默认工作线程池 size = 200） 预热线程池：默认情况下，核心工作线程值在初始的时候被创建，当新任务来到的时候被启动，但是我们可以通过重写 prestartCoreThread 或 prestartCoreThreads 方法来改变这种行为。通常场景我们可以在应用启动的时候来 WarmUp 核心线程，从而达到任务过来能够立马执行的结果，使得初始任务处理的时间得到一定优化。 队列的选择： 无界队列：使用无界队列如LinkedBlockingQueue没有指定最大容量的时候，将会引起当核心线程都在忙的时候，新的任务被放在队列上。 因此，永远不会有大于 corePoolSize 的线程被创建，因此 maximumPoolSize 参数将失效。 这种策略比较适合所有的任务都不相互依赖，独立执行。如 Web 服务器中，每个线程独立处理请求。 但是当任务处理速度小于任务进入速度的时候会引起队列的无限膨胀。 先级不同的任务可以使用优先级队列 PriorityBlockingQueue 来处理。它可以让优先级高的任务先得到执行，需要注意的是如果一直有优先级高的任务提交到队列里，那么优先级低的任务可能永远不能执行。 有界队列：有界队列如 ArrayBlockingQueue 帮助限制资源的消耗，但是不容易控制。队列长度和 maximumPoolSize 这两个值会相互影响， 使用 大的队列 和小 maximumPoolSize 会降低 CPU 占用、操作系统资源、上下文切换的消耗，但是会降低吞吐量，如果任务被频繁的阻塞如 IO 线程，系统其实可以调度更多的线程。 使用 小的队列 通常需要大 maximumPoolSize，从而使得 CPU 更忙一些，但是又会增加线程调度的消耗。 总结一下：是IO密集型可以考虑 多些线程+小的队列 来平衡CPU的使用，CPU密集型可以考虑 少些线程+大的队列 减少线程调度的消耗。 合理的拒绝策略: @todo 监控线程池通过线程池提供的参数进行监控。线程池里有一些属性在监控线程池的时候可以使用 taskCount：线程池需要执行的任务数量。 completedTaskCount：线程池在运行过程中已完成的任务数量。小于或等于taskCount。 largestPoolSize：线程池曾经创建过的最大线程数量。通过这个数据可以知道线程池是否满过。如等于线程池的最大大小，则表示线程池曾经满了。 getPoolSize:线程池的线程数量。如果线程池不销毁的话，池里的线程不会自动销毁，所以这个大小只增不+ getActiveCount：获取活动的线程数。 通过扩展线程池进行监控。通过继承线程池并重写线程池的beforeExecute，afterExecute和terminated方法，我们可以在任务执行前，执行后和线程池关闭前干一些事情。如监控任务的平均执行时间，最大执行时间和最小执行时间等。这几个方法在线程池里是空方法。如： @ref: 聊聊并发（三）——JAVA线程池的分析和使用 如何合理地估算线程池大小？ | 并发编程网 – ifeve.com java线程池大小为何会大多被设置成CPU核心数+1？ - 知乎","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"https://beefyheisenberg.github.io/tags/Java并发/"},{"name":"JUC","slug":"JUC","permalink":"https://beefyheisenberg.github.io/tags/JUC/"}]},{"title":"Java-并发.05c.JUC-Collections（并发集合）","slug":"12.Java/Java-并发.05d.JUC-Collections","date":"2024-01-24T01:27:52.224Z","updated":"2024-01-24T01:27:52.225Z","comments":true,"path":"12.Java/Java-并发.05d.JUC-Collections/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-并发.05d.JUC-Collections/","excerpt":"旧的线程安全的集合: 任何集合类都可以通过使用同步包装器变成线程安全的： List&lt;E&gt; synchArrayList = Collections.synchronizedList(new ArrayList&lt;E&gt;());Map&lt;K,V&gt; synchMap = Collections.synchronizedList(new HasMap&lt;K,V&gt;()); java.util.concurrent包提供了线程安全的集合, 继承关系如下: 阻塞队列 |- BlockingQueue（单向队列） |- ArrayBlockingQueue: 一个由数组结构组成的有界阻塞队列 |- LinkedBlockingQueue: 一个由链表结构组成的有界阻塞队列 |- PriorityBlockingQueue: 一个支持优先级排序的无界阻塞队列 |- LinkedBlockingDeque: 一个由链表结构组成的双向阻塞队列 |- BlockingDeque（双向队列） |- LinkedBlockingDeque: 一个由链表结构组成的双向阻塞队列非阻塞队列 |- ConcurrentLinkedQueue |- ConcurrentLinkedDequeMap |- ConcurrentHashMap |- ConcurrentSkipListMapSet |- ConcurrentSkipListSet Queue &amp; Deque","text":"旧的线程安全的集合: 任何集合类都可以通过使用同步包装器变成线程安全的： List&lt;E&gt; synchArrayList = Collections.synchronizedList(new ArrayList&lt;E&gt;());Map&lt;K,V&gt; synchMap = Collections.synchronizedList(new HasMap&lt;K,V&gt;()); java.util.concurrent包提供了线程安全的集合, 继承关系如下: 阻塞队列 |- BlockingQueue（单向队列） |- ArrayBlockingQueue: 一个由数组结构组成的有界阻塞队列 |- LinkedBlockingQueue: 一个由链表结构组成的有界阻塞队列 |- PriorityBlockingQueue: 一个支持优先级排序的无界阻塞队列 |- LinkedBlockingDeque: 一个由链表结构组成的双向阻塞队列 |- BlockingDeque（双向队列） |- LinkedBlockingDeque: 一个由链表结构组成的双向阻塞队列非阻塞队列 |- ConcurrentLinkedQueue |- ConcurrentLinkedDequeMap |- ConcurrentHashMap |- ConcurrentSkipListMapSet |- ConcurrentSkipListSet Queue &amp; Deque Name 是否阻塞 是否有界 队列长度 内部实现 ArrayBlockingQueue 阻塞 有界 构造器指定 循环数组,FIFO LinkedBlockingQueue 阻塞 有界 构造器指定, 默认Int.Max 链表,FIFO LinkedBlockingDeque 阻塞 有界 构造器指定, 默认Int.Max 双向链表,FIFO SynchronousQueue 阻塞 有界 1 PriorityBlockingQueue 阻塞 无界 构造器指定, 默认11, 无限扩容 二叉堆 DelayQueue 阻塞 无界 初始empty, 无限扩容 ConcurrentLinkedQueue 非阻塞 无界 初始empty, 无限扩容 单向链表 ConcurrentLinkedDeque 非阻塞 无界 初始empty, 无限扩容 双向链表 线程安全的队列可以分为 阻塞队列 , 非阻塞队列, 按照是否可无限扩容分为 有界队列 , 无界队列 : 阻塞队列: 当队列是空的时，从队列中获取元素的操作将会被阻塞，或者当队列是满时，往队列里添加元素的操作会被阻塞。 阻塞队列一般是用锁(例如 BlockingQueue)来实现,阻塞队列继承自接口BlockingQueue, 常用的有: ArrayBlockingQueue, LinkedBlockingQueue, PriorityBlockingQueue, LinkedBlockingDeque; 非阻塞队列是指: 非阻塞队列一般是用 CAS 实现的”Lock-Free”方法, 非阻塞队列主要有: ConcurrentLinkedQueue, ConcurrentLinkedDeque; 有界/无界: 无界队列可以无限扩容，一般链表实现的队列属于无界 阻塞队列阻塞队列一般使用condition实现消费者和生产者的”通讯”。比如当生产者往满的队列里添加元素时会阻塞住，当消费者消费了队列中的元素后，会通过condition通知生产者当前队列可用。 BlockingQueue接口方法有put/take： 阻塞方法： put(E o)：将元素添加到此队列尾，如果队列满将一直阻塞，可以响应中断。 take()：检索并移除此队列的头部，如果队列为空则一直阻塞，可以响应中断。 不阻塞且抛异常的方法： add(E o)：将元素添加到此队列中，如果队列已满不会阻塞，直接抛出 IllegalStateException remove()： 移除队列头部的元素，如果队列为空不会阻塞，直接抛出 IllegalStateException 不阻塞且带返回值的方法： offer(E o)： 将元素添加到队列，不阻塞，成功返回true，失败返回false； offer(E o, long timeout, TimeUnit unit)： 带等待时间的offer方法，如果队列已满，将等待指定的时间； poll(long timeout, TimeUnit unit)： 返回队列的头部并移除，如果队列为空，则等待指定等待的时间。如果取不到返回null； 其他方法： drainTo(Collection&lt;? super E&gt; c)： 移除此队列中所有可用的元素，并将它们添加到给定 collection 中。 drainTo(Collection&lt;? super E&gt; c,int maxElements)： 最多从此队列中移除给定数量的可用元素，并将这些元素添加到给定 collection 中 remainingCapacity()： 返回在无阻塞的理想情况下（不存在内存或资源约束）此队列能接受的元素数量；如果没有内部限制，则返回 Integer.MAX_VALUE。 ArrayBlockingQueue ArrayBlockingQueue 是一个用数组实现的有界阻塞队列。此队列按照先进先出（FIFO）的原则对元素进行排序 构造器 ArrayBlockingQueue(int) 都要指定数组初始大小，并且大小不再扩展。 默认情况下 ArrayBlockingQueue 不保证访问者公平的访问队列，所谓“公平访问队列”是指：当队列可用时，可以按照阻塞的先后顺序访问队列。我们可以使用以下代码创建一个“公平的”阻塞队列：ArrayBlockingQueue fairQueue = new ArrayBlockingQueue(1000,true); 队列满时，调用特定的插入方法会阻塞； 队列空时，调用特定的删除方法会阻塞 ArrayBlockingQueue 内部实现： 一个 ReentrantLock，阻塞方法，无论读写都是用这个 lock； 两个 Condition(notFull、notEmpty) 管理队列满或空时的阻塞状态； 在「生产者」+「消费者」情景下，因为读写都是共用同一个锁对象，由此也意味着两者无法真正并行运行，ArrayBlockingQueue 的吞吐量不如 LinkedBlockingQueue @ref: Java多线程进阶（三二）—— J.U.C之collections框架：ArrayBlockingQueue - 透彻理解Java并发编程 - SegmentFault 思否 LinkedBlockingQueue LinkedBlockingQueue 是链表实现的“有界”的阻塞队列。构造函数可以指定最大长度，如果不指定则最大长度默认为 Integer.MAX_VALUE 插入方法 put(E e)、offer(e, time, unit)，如果队列满了，会阻塞调用者线程； 获取方法 take()、poll(time, unit)，如果队列为空，会阻塞调用者线程； 内部基于链表实现， 两个指针：head 和 last 指向链表头尾； 由两个锁（takeLock 与 putLock），出队和入队时加锁 两个 Condition(notFull、notEmpty) ，管理队列满或空时的阻塞状态。 由于生产者端和消费者端分别采用了独立的锁来控制数据同步，这也意味着在高并发的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列的并发性能。 入队代码： /** * 在队尾插入指定的元素. * 如果队列已满，则阻塞线程. */public void put(E e) throws InterruptedException &#123; if (e == null) throw new NullPointerException(); int c = -1; Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); // 获取“入队锁” try &#123; while (count.get() == capacity) &#123; // 队列已满, 则线程在notFull上等待 notFull.await(); &#125; enqueue(node); // 将新结点添加到到“链表尾” /** * count 表示的队列中元素个数. * getAndIncrement 返回旧值，并+1 */ c = count.getAndIncrement(); // c表示入队前，链表中元素个数 if (c + 1 &lt; capacity) notFull.signal(); // 入队后，链表队列未满, 则唤醒一个“入队线程” &#125; finally &#123; putLock.unlock(); &#125; if (c == 0) // c是添加该元素前，链表中元素的数量 signalNotEmpty(); // 如果之前c=0，有线程可能阻塞在get上，需要唤醒&#125; 以入队为例，新元素入队后， 如果链表还没满，需要唤醒 notFull 条件上的“入队线程”； 如果新元素入队前，链表中元素数量为 0，说明可能有读线程阻塞在 get 方法（也即 notEmpty 条件）； @ref: Java多线程进阶（三三）—— J.U.C之collections框架：LinkedBlockingQueue - 透彻理解Java并发编程 - SegmentFault 思否 LinkedBlockingDeque LinkedBlockingDeque 是一个由链表结构组成的双向阻塞队列。构造函数可以指定最大长度，如果不指定，队列的默认和最大长度为 Integer.MAX_VALUE 相比其他的阻塞单向队列，LinkedBlockingDeque多了addFirst，addLast，offerFirst，offerLast，peekFirst，peekLast等方法 SynchronousQueueSynchronousQueue 特性，在某次添加元素后必须等待其他线程取走后才能继续添加，可以认为 SynchronousQueue 是一个缓存值为1的阻塞队列（虽然是属于无界的）； 但是 isEmpty()方法永远返回是true，remainingCapacity() 方法永远返回是0，remove()和removeAll() 方法永远返回是false，iterator()方法永远返回空，peek()方法永远返回null。 SynchronousQueue 没有使用 lock，而是使用了 CAS（一种名为“Dual stack and Dual queue”的无锁算法实现。） SynchronousQueue 有两种不同的模式：公平模式 or 非公平模式（默认）， 如果采用公平模式：这种模式下 transferer 被初始化队列，如果队列为空，先发起 get 的线程可以先从阻塞中被通知； 如果是非公平模式：这种模式下 transferer 被初始化栈，如果队列为空，先发起 get 的线程后通知； @ref: Java多线程进阶（三五）—— J.U.C之collections框架：SynchronousQueue - 透彻理解Java并发编程 - SegmentFault 思否 PriorityBlockingQueuePriorityBlockingQueue 是一种无界阻塞队列，在构造的时候可以指定队列的初始容量。具有如下特点： PriorityBlockingQueue 与之前介绍的阻塞队列最大的不同之处就是：它是一种优先级队列，也就是说元素并不是以 FIFO 的方式出/入队，而是以按照权重大小的顺序出队，所以队列中的元素必须是可以比较的，元素必须实现 Comparable 接口； PriorityBlockingQueue 是真正的无界队列（仅受内存大小限制），它不像 ArrayBlockingQueue 那样构造时必须指定最大容量，也不像 LinkedBlockingQueue 默认最大容量为 Integer.MAX_VALUE，虽然 PriorityBlockingQueue 也支持构造函数指定大小，但因为自动扩容所以元素数量不会受限制； 由于 PriorityBlockingQueue 无界队列，所以插入元素永远不会阻塞线程；但是当队列为空时，取出操作（take）会阻塞线程； 内部实现： PriorityBlockingQueue 底层是一种基于数组实现的堆结构，排序等功能的实现与 PriorityQueue 类似； 一个 ReentrantLock 锁对象，一个 notEmpty 条件对象 @ref Java多线程进阶（三四）—— J.U.C之collections框架：PriorityBlockingQueue - SegmentFault 思否 DelayQueueDelayQueue 是 JDK1.5时，随着J.U.C 包一起引入的一种阻塞队列，它实现了 BlockingQueue 接口，底层基于已有的PriorityBlockingQueue实现： 队列中的元素必须实现 Delayed 接口，在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才能从队列中提取元素。 Delayed 接口继承了 Comparable 接口，必须实现 compareTo 来指定元素的顺序。 由于DelayQueue内部委托了PriorityBlockingQueue对象来实现所有方法，所以能以堆的结构维护元素顺序，这样剩余时间最小的元素就在堆顶，每次出队其实就是删除剩余时间≤0的最小元素。 我们可以将 DelayQueue 运用在以下应用场景： 定时任务调度。使用 DelayQueue 保存当天将会执行的任务和执行时间，一旦从 DelayQueue 中获取到任务就开始执行，从比如 TimerQueue 就是使用 DelayQueue 实现的。 实现： DelayQueue 的主要成员： ReentrantLock lock： 保证线程安全 Thread leader：最早调用 get 并阻塞的线程 Condition available：条件对象，get 并阻塞的线程在此等待 因为是最小堆，所以堆顶是剩余时间最小的元素，每次 take 时： 如果堆顶时间未到，调用 get 的线程阻塞在 available； 如果堆顶元素时间到了，则取出堆顶； 实际的 put / take 更复杂，因为涉及到 Leader-Follower 机制： leader 是最早调用 take 并阻塞的线程；loader 阻塞在 available（条件对象），调用的是带超时时间的 awaitNanos(delay) 其他后续来 take 的线程也在 available 阻塞，用的是无限阻塞； loader 醒来后，先检测队头的节点是否到期，如果是则取走队头，并唤醒其他在 available 上的第一个线程，线程醒来（是在 take 函数的 await()）， /** * 队首出队元素. * 如果队首元素（堆顶）未到期或队列为空, 则阻塞线程. */public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; for (; ; ) &#123; E first = q.peek(); // 读取队首元素 if (first == null) // CASE1: 队列为空, 直接阻塞 available.await(); else &#123; // CASE2: 队列非空 long delay = first.getDelay(NANOSECONDS); if (delay &lt;= 0) // CASE2.0: 队首元素已过期 return q.poll(); // 取走队头元素，还要进入第2个finally // 执行到此处说明队列非空, 且队首元素未过期 first = null; if (leader != null) // CASE2.1: 已存在leader线程 available.await(); // 非 leader线程，无限期 await else &#123; // CASE2.2: 不存在leader线程 Thread thisThread = Thread.currentThread(); leader = thisThread; // 将当前线程置为leader线程 try &#123; available.awaitNanos(delay); // leader使用带时间的 await &#125; finally &#123; // 第 1 个 finally if (leader == thisThread) leader = null; &#125; &#125; &#125; &#125; &#125; finally &#123; // 第 2 个 finally if (leader == null &amp;&amp; q.peek() != null) // 不存在leader线程, 则唤醒一个其它出队线程 available.signal(); lock.unlock(); &#125;&#125; @ref: Java多线程进阶（三六）—— J.U.C之collections框架：DelayQueue - 透彻理解Java并发编程 - SegmentFault 思否 非阻塞队列ConcurrentLinkedQueue ConcurrentLinkedQueue是一个基于链接节点的无边界的线程安全队列，它采用FIFO原则对元素进行排序。采用“wait-free”算法（即CAS）来实现的。 ConcurrentLinkedQueue的结构是单向链表和head/tail两个指针，因为入队时需要修改队尾元素的next指针，以及修改tail指向新入队的元素两个CAS动作无法原子，所以需要的特殊的算法，见：Java 理论与实践： 非阻塞算法简介 ConcurrentLinkedDeque ConcurrentLinkedDeque是一种基于双向链表的无界链表。 与大多数集合类型不同，其size方法不是一个常量操作。因为链表的异步性质，确定当前元素的数量需要遍历所有的元素，所以如果在遍历期间有其他线程修改了这个集合，size方法就可能会报告不准确的结果。 批量的操作：包括添加、删除或检查多个元素，比如addAll()、removeIf()或者removeIf() 或forEach()方法，这个类型并不保证以原子方式执行。由此可见如果想保证原子访问，不得使用批量操作的方法。 ListCopyOnWriteArrayListArrayList 底层使用数组，实现了 List 接口，并且提供了 get(i) set(i)这种随机访问的方法，线程安全的版本是 Vector，通过 Synchronized 整个方法实现了线程安全，但是性能太差，CopyOnWriteArrayList 是一种线程安全的 ArrayList，更适合读多写少的场景 实现： 主要成员：Object 数组、ReentrantLock 锁 get：不加锁 add/remove：这些会更改数组的方法，都是用 ReentrantLock 加锁，使用 Arrays.copyOf 将旧内容拷贝入新数组，然后替换掉旧数组 public boolean add(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); // 旧数组 int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); // 复制并创建新数组 newElements[len] = e; // 将元素插入到新数组末尾 setArray(newElements); // 内部array引用指向新数组 return true; &#125; finally &#123; lock.unlock(); &#125;&#125; 写操作因为要 copy 整个旧数组，代价还是较高，适用于写非常少的场景 @ref: 并发容器之CopyOnWriteArrayList - 掘金 实现一个简单的阻塞队列_Java_h525483481的专栏-CSDN博客 SetConcurrentSkipListSetConcurrentSkipListSet的实现非常简单，其内部引用了一个ConcurrentSkipListMap对象，所有API方法都是调用了ConcurrentSkipListMap。ConcurrentSkipListSet和TreeSet，它们虽然都是有序的集。但是：第一，它们的线程安全机制不同，TreeSet是非线程安全的，而ConcurrentSkipListSet是线程安全的；第二，ConcurrentSkipListSet是通过ConcurrentSkipListMap实现的，而TreeSet是通过TreeMap实现的； MapConcurrentHashMap（JDK 1.8）在 JDK1.7之前，ConcurrentHashMap 是通过分段锁机制来实现的，所以其最大并发度受 Segment 的个数限制。因此，在 JDK1.8中，ConcurrentHashMap 的实现原理摒弃了这种设计，而是选择了与 HashMap 类似的数组+链表+红黑树的方式实现，而加锁则采用 CAS 和 synchronized 实现。 1.8 中 ConcurrentHashMap 使用了 CAS + Synchronized 两种方式，put 流程如下： 计算 index，方式同 HashMap： index = hash &amp; (n -1 ) 如果 table[i] = null, CAS 插入这个位置 如果 table[i] 是链表 or 红黑树，则 synchronized 锁住 table[i]，也即此处的 Node 对象 如果 table[i].hash = MOVED, 即“ForwardingNode 节点”，说明此时 HashMap 正在扩容，则调用 transfer 协助迁移 /** * 实际的插入操作 * * @param onlyIfAbsent true:仅当key不存在时,才插入 */final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); // 再次计算hash值 /** * 使用链表保存时，binCount记录table[i]这个桶中所保存的结点数； * 使用红黑树保存时，binCount==2，保证put后更改计数值时能够进行扩容检查，同时不触发红黑树化操作 */ int binCount = 0; for (Node&lt;K, V&gt;[] tab = table; ; ) &#123; // 自旋插入结点，直到成功 Node&lt;K, V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0) // CASE1: 首次初始化table —— 懒加载 tab = initTable(); else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; // CASE2:table[i]无数据 // 注意下上面table[i]的索引i的计算方式：key的hash值 &amp; (table.length-1) if (casTabAt(tab, i, null, new Node&lt;K, V&gt;(hash, key, value, null))) break; &#125; else if ((fh = f.hash) == MOVED) // CASE3: 发现ForwardingNode结点，说明此时table正在扩容，则尝试协助数据迁移 tab = helpTransfer(tab, f); else &#123; // CASE4: 出现hash冲突,也就是table[i]桶中已经有了结点 V oldVal = null; synchronized (f) &#123; // 锁住table[i]结点 if (tabAt(tab, i) == f) &#123; // 再判断一下table[i]是不是第一个结点, 防止其它线程的写修改 if (fh &gt;= 0) &#123; // CASE4.1: table[i]是链表结点 binCount = 1; for (Node&lt;K, V&gt; e = f; ; ++binCount) &#123; K ek; // 找到“相等”的结点，判断是否需要更新value值 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K, V&gt; pred = e; if ((e = e.next) == null) &#123; // “尾插法”插入新结点 pred.next = new Node&lt;K, V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123; // CASE4.2: table[i]是红黑树结点 Node&lt;K, V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K, V&gt;) f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) // 链表长度 &gt; 8 treeifyBin(tab, i); // 链表 -&gt; 红黑树 转换 if (oldVal != null) // 表明本次put操作只是替换了旧值，不用更改计数值 return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); // 计数值加1 return null;&#125; ➤ 扩容 tryPresize() 实现： 通过 CAS 保证只能由一个线程进行桶数组的扩容； 对链表进行红黑树转换的时候（触发阈值 8 ）, 如果桶数组小于 64，则不进行红黑树转换，而是进行扩容，把数组长度扩大到原来的两倍； 然后把旧数组中的所有元素，迁移到新数组中去； ➤ 迁移 transfer() 的实现： 如果 table[i]处节点的类型是 ForwardingNode，则说明这个节点已经迁移完成了； transfer 可以多个线程并发执行； 因为桶数组和计算 index（参考 hashMap ）的特性，扩容前和扩容后的位置只有 2 种可能，在原位置 or 原位置+oldCap，这种处理方式非常利于扩容时多个线程同时进行的数据迁移操作，因为旧 table 的各个桶中的结点迁移不会互相影响，所以就可以用分治的方式，将整个 table 数组划分为很多部分，每一部分包含一定区间的桶，每个数据迁移线程处理各自区间中的结点； 此处的 forwarding 节点的作用，与 copying GC 时用到的对象 forwarding ptr 作用非常类似 ➤ 计算元素个数 sum() 的实现： ConcurrentHashMap 的键值对计数逻辑与 LongAdder 的实现类似：一个 long 型的 base，另外是 cell[] 数组； 如果 CAS base 成功，直接在 base 上累加，如果 CAS 失败了，也即发生冲突，线程会根据自己的 hash，找到 cell[i]，然后对该 cell 进行 CAS+1； 计算 sum 时，和 LongAdder 一样，也是一个瞬时值 final long sumCount() &#123; CounterCell[] as = counterCells; CounterCell a; long sum = baseCount; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum;&#125; @ref： Java多线程进阶（二三）—— J.U.C之collections框架：ConcurrentHashMap(1) 原理 - 透彻理解Java并发编程 - SegmentFault 思否 Java多线程进阶（二四）—— J.U.C之collections框架：ConcurrentHashMap(2) 扩容 - 透彻理解Java并发编程 - SegmentFault 思否 ConcurrentHashMap（JDK 1.7） 数据分段存储，每个段有一个写锁（分段锁），当一个线程占用某个段的锁时，其他段也可以正常访问，有效分散了阻塞的概率，而且没有读锁； 没有读锁是因为put/remove动作是个原子动作(比如put是一个对数组元素/Entry 指针的赋值操作)，读操作不会看到一个更新动作的中间状态； 每次扩容为原来容量的2倍，ConcurrentHashMap不会对整个容器进行扩容，而只对某个segment进行扩容； 在获取size操作的时候，不是直接把所有segment的count相加就可以可到整个ConcurrentHashMap大小，也不是在统计size的时候把所有的segment的put、remove、clean方法全部锁住，这种方法太低效。在累加count操作过程中，之前累加过的count发生变化的几率非常小，所有ConcurrentHashMap的做法是先尝试2（RETRIES_BEFORE_LOCK）次通过不锁住Segment的方式统计各个Segment大小，如果统计的过程中，容器的count发生了变化，再采用加锁的方式来统计所有的Segment的大小。 putIfAbsent(k,v)：当k已经存在时返回已存在的v。 ➤ 内部实现: concurrencyLevel: 并行级别、也是Segment 数，默认是 16，也就是说 ConcurrentHashMap 有 16 个 Segments，所以理论上，最多可以同时支持 16 个线程并发写，只要它们的操作分别分布在不同的 Segment 上。这个值可以在初始化的时候设置为其他值，但是一旦初始化以后，它是不可以扩容的。 实例化ConcurrentHashMap时带参数时，会根据参数调整table的大小，假设参数为100，最终会调整成256，确保table的大小总是2的幂次方, 为什么? put操作: 计算桶位置: i = (table.size-1) &amp; hash 如果 table[i] == null : 用自旋+CAS 改变 table[i] 的值 如果 f = table[i] != null : Synchronized(f)锁住f节点 size的实现: 类似 LongAdder ConcurrentSkipListMap JDK6新增的并发优化的SortedMap，以SkipList实现。SkipList是红黑树的一种简化替代方案，是个流行的有序集合算法。Concurrent包选用它是因为它支持基于CAS的无锁算法，而红黑树则没有好的无锁算法。 ConcurrentSkipListMap 的key是有序的； 与ConcurrentHashMap相比，ConcurrentSkipListMap 支持更高的并发。ConcurrentSkipListMap 的存取时间是log(n)，和线程数几乎无关。也就是说在数据量一定的情况下，并发的线程越多，ConcurrentSkipListMap越能体现出优势。 它的size()比较特殊，需要遍历所有元素； Deprecated: Vector &amp; HashTableVector和HashTable已经被弃用，取而代之的是ArrayList和HashMap，如果要使用线程安全的容器，可以用Collections转换： List&lt;E&gt; syncList = Collections.synchronzedList(new ArrayList&lt;E&gt;());Map&lt;K,V&gt; syncMap = Collections.synchronizedMap(new HashMap&lt;K,V&gt;());","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"},{"name":"集合","slug":"集合","permalink":"https://beefyheisenberg.github.io/tags/集合/"},{"name":"Java并发","slug":"Java并发","permalink":"https://beefyheisenberg.github.io/tags/Java并发/"},{"name":"JUC","slug":"JUC","permalink":"https://beefyheisenberg.github.io/tags/JUC/"}]},{"title":"Java-并发.05d.JUC-Sync（同步器）","slug":"12.Java/Java-并发.05c.JUC-Sync","date":"2024-01-24T01:27:52.219Z","updated":"2024-01-24T01:27:52.220Z","comments":true,"path":"12.Java/Java-并发.05c.JUC-Sync/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-并发.05c.JUC-Sync/","excerpt":"CountDownLatch、CyclicBarrier、Semaphore 在 java1.5 被引入，它们也都是基于 AQS 实现的， ReentrantLock 是基于 Exclusive（独占），只有一个线程可以执行； CountDownLatch、CyclicBarrier、Semaphore 基于 Share(共享)，多个线程可同时执行； 计数器 CountDownLatchCountDownLatch.await 能够使一个线程等待, 直到计数器归于 0 后再继续执行。例如，应用程序的主线程希望在负责启动框架服务的线程已经启动所有的框架服务之后再执行。 CountDownLatch 提供了类似计数器的同步手段, 构造器和主要方法:","text":"CountDownLatch、CyclicBarrier、Semaphore 在 java1.5 被引入，它们也都是基于 AQS 实现的， ReentrantLock 是基于 Exclusive（独占），只有一个线程可以执行； CountDownLatch、CyclicBarrier、Semaphore 基于 Share(共享)，多个线程可同时执行； 计数器 CountDownLatchCountDownLatch.await 能够使一个线程等待, 直到计数器归于 0 后再继续执行。例如，应用程序的主线程希望在负责启动框架服务的线程已经启动所有的框架服务之后再执行。 CountDownLatch 提供了类似计数器的同步手段, 构造器和主要方法: // 构造初值=count 的计数器public CountDownLatch(int count) &#123; &#125;; //将count值减1public void countDown() &#123; &#125;;//调用await()方法的线程会被挂起，它会等待直到count值为0才继续执行public void await() throws InterruptedException &#123; &#125;;//和await()类似，只不过等待一定的时间后count值还没变为0的话就会继续执行public boolean await(long timeout, TimeUnit unit) throws InterruptedException &#123; &#125;; Example: public class Test &#123; public static void main(String[] args) &#123; final CountDownLatch latch = new CountDownLatch(2); new Thread(() -&gt; &#123; Thread.sleep(3000); latch.countDown(); &#125;).start(); new Thread(() -&gt; &#123; Thread.sleep(6000); latch.countDown(); &#125;).start(); latch.await(); // 在这里阻塞直到latch执行过两次countDown() &#125;&#125; CountDownLatch 也是基于 AQS 实现，但是对于 AQS.state 计数器的使用有区别： 在 CountDownLatch 中，同步状态 State 表示 CountDownLatch 的计数器的初始值，当 State==0 时，表示无锁状态，且一旦 State 变为 0，就永远处于无锁状态了，此时所有线程在 await 上等待的线程都可以继续执行。 而在 ReentrantLock 中，State==0 时，虽然也表示无锁状态，但是只有一个线程可以重置 State 的值。这就是共享锁的含义。 信号量 SemaphoreSemaphore 翻译成字面意思为 “信号量”，Semaphore 可以控同时访问的任务个数，通过 acquire(int) 获取n个许可，如果没有就等待； release(int) 释放n个许可。 如果线程 acquire 不到指定资源数（资源=0 或 acquire 的大于剩余资源），线程阻塞 release 释放许可，并唤醒队列中一个节点（线程） Example: class Pool &#123; private static final int MAX_AVAILABLE = 100; // 可同时访问资源的最大线程数 private final Semaphore available = new Semaphore(MAX_AVAILABLE, true); protected Object[] items = new Object[MAX_AVAILABLE]; //共享资源 protected boolean[] used = new boolean[MAX_AVAILABLE]; public Object getItem() throws InterruptedException &#123; available.acquire(); return getNextAvailableItem(); &#125; public void putItem(Object x) &#123; if (markAsUnused(x)) available.release(); &#125; private synchronized Object getNextAvailableItem() &#123; for (int i = 0; i &lt; MAX_AVAILABLE; ++i) &#123; if (!used[i]) &#123; used[i] = true; return items[i]; &#125; &#125; return null; &#125; private synchronized boolean markAsUnused(Object item) &#123; for (int i = 0; i &lt; MAX_AVAILABLE; ++i) &#123; if (item == items[i]) &#123; if (used[i]) &#123; used[i] = false; return true; &#125; else return false; &#125; &#125; return false; &#125;&#125; ➤ 构造器和主要方法： //参数permits表示许可数目，即同时可以允许多少线程进行访问public Semaphore(int permits) &#123; sync = new NonfairSync(permits);&#125;//多了一个fair表示是否是公平的，即等待时间越久的越先获取许可public Semaphore(int permits, boolean fair) &#123; sync = (fair)? new FairSync(permits) : new NonfairSync(permits);&#125;//获取一个许可public void acquire() throws InterruptedException &#123; &#125; //获取permits个许可public void acquire(int permits) throws InterruptedException &#123; &#125; //释放一个许可public void release() &#123; &#125; //释放permits个许可public void release(int permits) &#123; &#125; ➤ acquire 代码： //Semaphore方法public void acquire() throws InterruptedException &#123; //传递参数为1,说明要获取1个信号量资源 sync.acquireSharedInterruptibly(1);&#125;//AQS的方法public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; //(1)如果线程被中断,则抛出中断异常 if (Thread.interrupted()) throw new InterruptedException(); //(2)否则调用Sync子类方法尝试获取,分为公平和非公平策略 if (tryAcquireShared(arg) &lt; 0) //(3)如果获取失败则放入阻塞队列.然后再次尝试,如果使用则调用park方法挂起当前线程 doAcquireSharedInterruptibly(arg);&#125; tryAcquireShared: 由 Sync 子类实现 公平策略：若队列非空，先入队 非公平策略：先尝试 CAS state tryAcquireShared （公平策略）代码： protected int tryAcquireShared(int acquires) &#123; for (;;) &#123; //查询是否当前线程节点的前驱节点也在等待获取该资源,有的话直接返回 if (hasQueuedPredecessors()) return -1; int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125;&#125; 上面提到 ReentrantLock 对 state 的操作是基于独占模式，Semaphore 是基于共享模式，二者区别： 独占模式的 acquire： 如果 state = 0 则尝试 CAS(state, 0, 1) 如果 state &gt; 0 则需要测试 exclusiveThread 是否等于当前线程，是则 state+=1 共享模式的 acquire： CAS(state, available, available-1)，available 是当前的 state 值，表示“available”的许可数量 ➤ release： public void release() &#123; //(1)arg=1 sync.releaseShared(1);&#125;public final boolean releaseShared(int arg) &#123; //(2)尝试释放资源 if (tryReleaseShared(arg)) &#123; //(3)资源释放成功则调用park方法唤醒AQS队列里面最先挂起的线程 doReleaseShared(); return true; &#125; return false;&#125;protected final boolean tryReleaseShared(int releases) &#123; for (;;) &#123; //获取当前信号量值 int current = getState(); //将当前信号量值增加releases,这里为增加1 int next = current + releases; //移除处理 if (next &lt; current) // overflow throw new Error(\"Maximum permit count exceeded\"); //使用CAS保证更新信号量值的原子性 if (compareAndSetState(current, next)) return true; &#125;&#125; 循环栅栏 CyclicBarrierCyclicBarrier 是一个辅助同步器类，在 JDK1.5时随着J.U.C 一起引入。 CyclicBarrier 功能类似 CountDownLatch 区别是： CountDownLatch 计数器变为 0 之前，所有调用 await 的线程都需等待，计数器变为 0 后这些线程可以继续执行，但一旦计数器变为 0 就不可重置了； CyclicBarrier 构造时同样需要指定计数器 N，工作线程调用 CyclicBarrier.await 后会阻塞，直到 N 个工作线程都调用了 await，这些阻塞的线程才可以继续执行； 两种 await 的方式： CyclicBarrier.await(), CyclicBarrier.await(timeout,TimeUnit) ，后一种可以设置等待的超时； CyclicBarrier.await 可以响应 InterruptedException，和 BrokenBarrierException 如果正在 await 的线程 1 被打断，那么线程 1 的 await 抛出 InterruptedException，其他正在 await 的线程抛出 BrokenBarrierException 如果线程 1 使用带超时的 await，并且超时了，线程 1 的 await 抛出 TimeoutException，其他正在 await 的线程抛出 BrokenBarrierException 如果有线程调用了 CyclicBarrier.reset，其他正在 await 的线程抛出 BrokenBarrierException 调用了 CyclicBarrier.await 的线程退出等待状态的条件有：1 产生上面几种异常，2 或者达到了 await 的数量 如图，ABCD 四个线程都到达 Barrier 后，才可以同时“穿过”栅栏![[../_images/Java-并发.05c.JUC-Sync-2023-05-21-1.png]] Example: public class CyclicBarrierTest &#123; public static void main(String[] args) throws Exception&#123; ExecutorService service = Executors.newFixedThreadPool(3) ; // CyclicBarrier 可以指定一个最后执行的任务 CyclicBarrier cyclicBarrier = new CyclicBarrier(3,()-&gt;&#123; System.out.println(\"全部线程都调用了await，则执行这里\"); &#125;) ; for(int i = 0 ; i &lt; 3 ; i++) &#123; final int number = i ; service.execute(()-&gt;&#123; try &#123; System.out.println(\"线程 Num\" + number + \" start\"); cyclicBarrier.await(); // 线程在此wait，直到达成条件 &#125; catch (Exception e) &#123; // 这里应该分别处理 InterruptedException &amp; BrokenBarrierException // 如果使用了带超时的 await，这里还需要捕获 TimeoutException e.printStackTrace(); &#125; &#125;); &#125; service.shutdown(); &#125;&#125; 使用 CyclicBarrier 时，对异常的处理一定要小心，比如线程在到达栅栏前就抛出异常，其它已经到达栅栏的线程会一直等待（因为没有还没有满足总数），最终导致程序无法继续向下执行。 线程可以通过以下几种机制避免上述情况： 1 使用带超时的 await 2 捕获到异常，尝试再次 await 流程（重试） 3 重试失败调用 reset CyclicBarrier reset 相关的源码： //将屏障重置为其初始状态。public void reset() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; //唤醒所有等待的线程继续执行，并设置屏障中断状态为true breakBarrier(); // break the current generation //唤醒所有等待的线程继续执行，并设置屏障中断状态为false nextGeneration(); // start a new generation &#125; finally &#123; lock.unlock(); &#125;&#125;private void breakBarrier() &#123; generation.broken = true;//表示当代因为线程被中断，已经发成损坏了 count = parties;//重置count值 trip.signalAll();//调用Condition的signalAll方法，唤醒所有await的线程&#125;private void nextGeneration() &#123; // signal completion of last generation trip.signalAll();//调用Condition的signalAll方法，唤醒所有await的线程 count = parties;//重置count值 //生成新的Generation，表示上一代的所有线程已经唤醒，进行更新换代 generation = new Generation(); &#125; reset 方法会调用 breakBarrier（该方法意为栅栏损坏），该方法设置 broken 标志、重置 count、唤醒所有 await 线程； await 方法中也会调用 breakBarrier：当收到 InterruptedException，或者超时，都会调用 breakBarrier; 参考： Java多线程10 同步工具类CyclicBarrier - 简书 Java多线程进阶（十九）—— J.U.C之synchronizer框架：CyclicBarrier - 透彻理解Java并发编程 - SegmentFault 思否 PhaserPhaser 是JDK1.7开始引入的一个同步工具类，适用于一些需要分阶段的任务的处理。它的功能与 CyclicBarrier和CountDownLatch有些类似，类似于一个多阶段的栅栏，比较三者： 同步器 作用 CountDownLatch 倒数计数器，初始时设定计数器值，线程可以在计数器上等待，当计数器值归 0 后，所有等待的线程继续执行 CyclicBarrier 循环栅栏，初始时设定参与线程数，当线程到达栅栏后，会等待其它线程的到达，当到达栅栏的总数满足指定数后，所有等待的线程继续执行 Phaser 多阶段栅栏，可以在初始时设定参与线程数，也可以中途注册/注销参与者，当到达的参与者数量满足栅栏设定的数量后，会进行阶段升级（advance） Phaser 中几个重要的概念： （1）phase(阶段) 在CyclicBarrier中，只有一个栅栏，线程在到达栅栏后会等待其它线程的到达。 Phaser 也有栅栏，在 Phaser 中，栅栏的名称叫做phase(阶段)，在任意时间点，Phaser 只处于某一个phase(阶段)，初始阶段为0，最大达到 Integerr.MAX_VALUE，然后再次归零。当所有parties参与者都到达后，phase值会递增。 如果看过之前关于 CyclicBarrier 的文章，就会知道，Phaser 中的 phase(阶段)这个概念其实和CyclicBarrier中的Generation很相似，只不过Generation没有计数。 （2）parties(参与者) parties(参与者) 其实就是 CyclicBarrier中的参与线程的概念。 CyclicBarrier 中的参与者在初始构造指定后就不能变更，而 Phaser 既可以在初始构造时指定参与者的数量，也可以中途通过 register、bulkRegister、arriveAndDeregister 等方法注册/注销参与者。 （3）arrive(到达) / advance(进阶) Phaser 注册完 parties（参与者） 之后，参与者的初始状态是 unarrived 的，当参与者 到达（arrive） 当前阶段（phase）后，状态就会变成 arrived。当阶段的到达参与者数满足条件后（注册的数量等于到达的数量），阶段就会发生 进阶（advance） ——也就是 phase 值+1。 （4）Termination（终止） 代表当前Phaser对象达到终止状态，有点类似于CyclicBarrier中的栅栏被破坏的概念。 （5）Tiering（分层） Phaser 支持分层（Tiering） —— 一种树形结构，通过构造函数可以指定当前待构造的 Phaser 对象的父结点。之所以引入Tiering，是因为当一个 Phaser 有大量 参与者（parties） 的时候，内部的同步操作会使性能急剧下降，而分层可以降低竞争，从而减小因同步导致的额外开销。 在一个分层 Phasers 的树结构中，注册和撤销子 Phaser 或父 Phaser 是自动被管理的。当一个 Phaser 的参与者（parties） 数量变成0时，如果有该 Phaser 有父结点，就会将它从父结点中溢移除。 示例（1）通过 Phaser 控制多个线程的执行时机：有时候我们希望所有线程到达指定点后再同时开始执行，我们可以利用CyclicBarrier或CountDownLatch来实现，这里给出使用 Phaser 的版本。 public class PhaserTest1 &#123; public static void main(String[] args) &#123; Phaser phaser = new Phaser(); for (int i = 0; i &lt; 10; i++) &#123; phaser.register(); // 注册各个参与者线程 new Thread(new Task(phaser), \"Thread-\" + i).start(); &#125; &#125;&#125;class Task implements Runnable &#123; private final Phaser phaser; Task(Phaser phaser) &#123; this.phaser = phaser; &#125; @Override public void run() &#123; int i = phaser.arriveAndAwaitAdvance(); // 等待其它参与者线程到达 // do something System.out.println(Thread.currentThread().getName() + \": 执行完任务，当前phase =\" + i + \"\"); &#125;&#125; (2) 通过 Phaser 实现开关。在以前讲CountDownLatch时，我们给出过以CountDownLatch实现开关的示例，也就是说，我们希望一些外部条件得到满足后，然后打开开关，线程才能继续执行，我们看下如何用Phaser来实现此功能。 public class PhaserTest2 &#123; public static void main(String[] args) throws IOException &#123; Phaser phaser = new Phaser(1); // 注册主线程,当外部条件满足时,由主线程打开开关 for (int i = 0; i &lt; 10; i++) &#123; phaser.register(); // 注册各个参与者线程 new Thread(new Task2(phaser), \"Thread-\" + i).start(); &#125; // 外部条件:等待用户输入命令 System.out.println(\"Press ENTER to continue\"); BufferedReader reader = new BufferedReader(new InputStreamReader(System.in)); reader.readLine(); // 打开开关 phaser.arriveAndDeregister(); System.out.println(\"主线程打开了开关\"); &#125;&#125;class Task2 implements Runnable &#123; private final Phaser phaser; Task2(Phaser phaser) &#123; this.phaser = phaser; &#125; @Override public void run() &#123; int i = phaser.arriveAndAwaitAdvance(); // 等待其它参与者线程到达 // do something System.out.println(Thread.currentThread().getName() + \": 执行完任务，当前phase =\" + i + \"\"); &#125;&#125; (3) 通过Phaser控制任务的执行轮数 public class PhaserTest3 &#123; public static void main(String[] args) throws IOException &#123; int repeats = 3; // 指定任务最多执行的次数 Phaser phaser = new Phaser() &#123; @Override protected boolean onAdvance(int phase, int registeredParties) &#123; System.out.println(\"---------------PHASE[\" + phase + \"],Parties[\" + registeredParties + \"] ---------------\"); return phase + 1 &gt;= repeats || registeredParties == 0; &#125; &#125;; for (int i = 0; i &lt; 10; i++) &#123; phaser.register(); // 注册各个参与者线程 new Thread(new Task3(phaser), \"Thread-\" + i).start(); &#125; &#125;&#125;class Task3 implements Runnable &#123; private final Phaser phaser; Task3(Phaser phaser) &#123; this.phaser = phaser; &#125; @Override public void run() &#123; while (!phaser.isTerminated()) &#123; //只要Phaser没有终止, 各个线程的任务就会一直执行 int i = phaser.arriveAndAwaitAdvance(); // 等待其它参与者线程到达 // do something System.out.println(Thread.currentThread().getName() + \": 执行完任务\"); &#125; &#125;&#125; (4) Phaser 支持分层功能，我们先来考虑下如何用利用 Phaser 的分层来实现高并发时的优化，在示例三中，我们其实创建了10个任务，然后10个线程共用一个 Phaser 对象，如下图： 如果任务数继续增大，那么同步产生的开销会非常大，利用 Phaser 分层的功能，我们可以限定每个 Phaser 对象的最大使用线程（任务数），如下图： 可以看到，上述 Phasers 其实构成了一颗多叉树，如果任务数继续增多，还可以将 Phaser 的叶子结点继续分裂，然后将分裂出的子结点供工作线程使用。 public class PhaserTest4 &#123; private static final int TASKS_PER_PHASER = 4; // 每个Phaser对象对应的工作线程（任务）数 public static void main(String[] args) throws IOException &#123; int repeats = 3; // 指定任务最多执行的次数 Phaser phaser = new Phaser() &#123; @Override protected boolean onAdvance(int phase, int registeredParties) &#123; System.out.println(\"---------------PHASE[\" + phase + \"],Parties[\" + registeredParties + \"] ---------------\"); return phase + 1 &gt;= repeats || registeredParties == 0; &#125; &#125;; Tasker[] taskers = new Tasker[10]; build(taskers, 0, taskers.length, phaser); // 根据任务数,为每个任务分配Phaser对象 for (int i = 0; i &lt; taskers.length; i++) &#123; // 执行任务 Thread thread = new Thread(taskers[i]); thread.start(); &#125; &#125; private static void build(Tasker[] taskers, int lo, int hi, Phaser phaser) &#123; if (hi - lo &gt; TASKS_PER_PHASER) &#123; for (int i = lo; i &lt; hi; i += TASKS_PER_PHASER) &#123; int j = Math.min(i + TASKS_PER_PHASER, hi); build(taskers, i, j, new Phaser(phaser)); &#125; &#125; else &#123; for (int i = lo; i &lt; hi; ++i) taskers[i] = new Tasker(i, phaser); &#125; &#125;&#125;class Task4 implements Runnable &#123; private final Phaser phaser; Task4(Phaser phaser) &#123; this.phaser = phaser; this.phaser.register(); &#125; @Override public void run() &#123; while (!phaser.isTerminated()) &#123; //只要Phaser没有终止, 各个线程的任务就会一直执行 int i = phaser.arriveAndAwaitAdvance(); // 等待其它参与者线程到达 // do something System.out.println(Thread.currentThread().getName() + \": 执行完任务\"); &#125; &#125;&#125; @ref： Java多线程进阶（二二）—— J.U.C之synchronizer框架：Phaser - 透彻理解Java并发编程 - SegmentFault 思否 JUC工具类: Phaser详解 | Java 全栈知识体系","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"https://beefyheisenberg.github.io/tags/Java并发/"},{"name":"JUC","slug":"JUC","permalink":"https://beefyheisenberg.github.io/tags/JUC/"}]},{"title":"Java-并发.05b.JUC-Lock（锁）","slug":"12.Java/Java-并发.05b.JUC-Lock","date":"2024-01-24T01:27:52.213Z","updated":"2024-01-24T01:27:52.213Z","comments":true,"path":"12.Java/Java-并发.05b.JUC-Lock/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-并发.05b.JUC-Lock/","excerpt":"可重入锁: ReentrantLockReentrantLock 是”可重入锁”: 一个线程已经持有锁的情况下, 重复对该锁进行 lock() 操作, 能立刻获得锁且不会被阻塞. ReentrantLock reentrantLock = new ReentrantLock();reentrantLock.lock();try&#123; ... &#125; catch &#123; ... &#125;finally&#123; reentrantLock.unlock(); // 在finally里释放锁&#125; ReentrantLock 的构造函数 ReentrantLock(boolean fair) 可以返回公平锁(true)和非公平锁(false). 公平锁（Fair）：加锁时先检查是否有排队等待的线程，如果队列非空，当前线程先进入队列尾，尝试唤醒队列中第一个节点的线程，即获取锁的顺序同调用 lock 的顺序一致; 非公平锁（Nonfair）：加锁时不考虑排队等待问题，当前线程直接尝试获取锁，获取不到则将当前线程包装为节点并插入队尾;","text":"可重入锁: ReentrantLockReentrantLock 是”可重入锁”: 一个线程已经持有锁的情况下, 重复对该锁进行 lock() 操作, 能立刻获得锁且不会被阻塞. ReentrantLock reentrantLock = new ReentrantLock();reentrantLock.lock();try&#123; ... &#125; catch &#123; ... &#125;finally&#123; reentrantLock.unlock(); // 在finally里释放锁&#125; ReentrantLock 的构造函数 ReentrantLock(boolean fair) 可以返回公平锁(true)和非公平锁(false). 公平锁（Fair）：加锁时先检查是否有排队等待的线程，如果队列非空，当前线程先进入队列尾，尝试唤醒队列中第一个节点的线程，即获取锁的顺序同调用 lock 的顺序一致; 非公平锁（Nonfair）：加锁时不考虑排队等待问题，当前线程直接尝试获取锁，获取不到则将当前线程包装为节点并插入队尾; ReentrantLock()默认构造是 非公平锁 锁的实现AQS 概述ReentrantLock 的实现基于 AQS（AbstractQueuedSynchronizer），继承了 AQS 的计数器 state、双向同步队列，ReentrantLock 的条件对象 Condition 是 AQS 的内部类。 -&gt; Java-并发.05b.JUC-AQS Lock.lock() 实现ReentrantLock.lock()调用栈如下(以 NonFairSync 为例): ReentrantLock.lock() NonFairSync.acquire(1) AbstractQueuedSynchronizer.acquire(1) NonFairSync.tryAcquire(1) // ReentrantLock实现的，此处以非公平锁为例 AbstractQueuedSynchronizer.addWaiter(Node) // 当前线程入对尾 AbstractQueuedSynchronizer.acquireQueued(Node) // 如果队列中只有当前线程,尝试唤醒 过程大致如下: AbstractQueuedSynchronizer.acquire() 的分析见 Java-并发.05b.JUC-AQS NonFairSync.tryAcquire(): 如果 state = 0 ，尝试对 state CAS(0,1) 操作, （CAS(0,1) 意即为如果 state 等于期望值0则设置为1），CAS 成功, 成功获取到该锁, 并把 exclusiveOwnerThread 置为当前线程的引用, lock() 成功返回; 如果 state != 0，则检查 exclusiveOwnerThread 是否等于线程自己，如果是，则对 state+1，lock() 成功返回; AQS.addWaiter() &amp; AQS.acquireQueued(): CAS 不成功, 表明已经有线程持有该锁, 且 exclusiveOwnerThread 不等于当前线程, 创建当前线程的 AQS.Node 对象, 并插入 AQS 的队尾, 并调用 LockSupport.park() 使当前 Thread 进入 Blocked LockSupport.park() 最终调用了 unsafe.park（Native 方法）, 作用是 block 当前线程, 具体参考 LockSupport中的park与unpark原理-CSDN博客Java 线程的阻塞以及唤醒，都是依靠操作系统来完成的。举例来说，对于符合 posix 接口的操作系统（如 macOS 和绝大部分的 Linux），上述操作是通过 pthread 的互斥锁（mutex）来实现的。此外，这些操作将涉及系统调用，需要从操作系统的用户态切换至内核态，其开销非常之大。 用线程 A/B 抢锁的场景说明 ReentrantLock 工作流程: 线程 A 获取到锁: A 是首个获取锁的线程, CAS 成功, 获取到锁后, 设置 exclusiveOwnerThread 为 A 的线程 ID 线程 B 获取锁: A 已经持有锁, 所以 B 在这里 CAS 失败, 线程 B 的 Node 被放入队尾, 然后 B 线程 park; 线程 A 释放锁: CAS 状态值-1, 然后取队列的首节点( 注意队列的 head 节点不存储信息, 这里取的是 head 后面的节点), 然后 LockSupport.unpark(B) 唤醒线程 B, 此时 B 仍在队列; 线程 B 唤醒执行: B 唤醒后自旋调用 tryAcquire() 再次尝试获取锁, 若成功则把自己从队列删除（AQS.head 设置为 B 节点, 并清除 B 节点信息） Lock.unlock() 实现ReentrantLock.unlock() 调用栈如下: ReentrantLock.unlock() NonFairSync.release(1) AbstractQueuedSynchronizer.release(1) Sync.tryRelease(1) // 具体实现类，释放state AbstractQueuedSynchronizer.unparkSuccessor // 取出队列第一个节点线程，unpark唤醒 只允许已经持有锁的线程调用 unlock(), 否则 unlock() 会抛出 IllegalMonitorStateException 异常 已经持有锁的线程, 每次调用 unlock() 计数器都会-1, 直到计数器等于 0, 这时候表示锁全部被解开了, 再从 AQS 的队列取出第一个节点进行唤醒； 测锁与超时ReentrantLock lock = new ReentrantLock();if(lock.tryLock(1000, TimeUnit.MILLISECOND)) &#123; // 超时时间内尝试获取锁失败立刻返回&#125;if(lock.tryLock()) &#123; // 尝试获取锁失败立刻返回&#125; 读写锁 如果一个数据结构只有很少线程修改其值, 但是有很多线程读取, 这种数据结构非常适合用读写锁 ReentrantReadWriteLock writeLock 一旦被持有, 排除其他的写锁和读锁; readLock 一旦被持有, 排斥写锁, 但不排斥其他的读锁; ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();Lock wl = rwl.writeLock(); // 获取写锁Lock rl = rwl.readLock(); // 获取读锁wl.lock();// 写操作, 这里排斥其他的读写锁wl.unlock();rl.lock();// 读操作, 其他读锁仍可以进入, 写锁则不能rl.unlock(); RW Lock 其他特点: 支持 Fair 和 NoFair 两种模式 支持 Condition: 只有写锁支持 newCondition(), 读锁不支持这个方法, 为什么这样设计? // 当持有写锁时, 读锁是可以任意访问的, 即使拿到了读锁的 Condition 也没有意义, 因为读线程之前不需要协调 可以降级: 写锁可以降级为读锁, 当线程先拿到读锁, 接着拿到写锁, 此时写锁是被降级为读锁的 @ref: JUC锁: ReentrantReadWriteLock详解 | Java 全栈知识体系 条件对象: Condition一个锁可以创建多个 ConditionObject 对象，ReentrantLock.newCondition() 返回一个 ConditionObject, 它是 AbstractQueuedSynchronizer 的一个内部类; 使用示例: ReentrantLock reentrantLock = new ReentrantLock();Condition condition = reentrantLock.newCondition();reentrantLock.lock();try &#123; while(!resource_is_available) &#123; condition.await(); //1 失去锁 &amp; waiting状态 &amp; 进入condition的等待集 &#125; // here acquired lock, doSomething... condition.signalAll(); //2 把condition等待集里的所有线程移除&#125; catch() &#123;...&#125;finally &#123; reentrantLock.unlock(); //3 永远在finally里释放锁&#125; 条件对象的实现 区分 AQS 的队列和 Condition 的队列：“同步队列”也即 AQS 的队列，通过 Node.prev 属性和 Node.next 属性来维护的队列；“条件队列”是 ConditionObject 的队列，通过 Node.nextWaiter 属性来维护队列（也看出条件队列是单向队列）；另外，有些书将 prev 属性和 next 属性维护的队列称为“同步队列”，将 nextWaiter 维护的队列称为“等待队列”；根据源码的注释，其实两个队列都可以称为“等待队列”，因此特以“同步队列”和“条件队列”来区分 ➤ await 的实现解析： public final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); // 1. 将当前线程包装成Node，尾插入到「等待队列」中 Node node = addConditionWaiter(); // 2. 释放当前线程所占用的lock，并唤醒「同步队列」中的下一个节点 int savedState = fullyRelease(node); int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; // 3. 调用park，当前线程在此 wait 并让出CPU LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; /* 如果线程恢复运行，退出这个 while 循环的条件可能是： 情况1是线程被interrupt，走到break； 情况2是线程被放入了「同步队列」，即其他线程调用signal or signalAll */ // 4. 从上面的while中醒来，不断自旋尝试获取到lock if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); // 5. 处理被中断的情况 if (interruptMode != 0) reportInterruptAfterWait(interruptMode);&#125; ➤ signal 的实现解析： public final void signal() &#123; //1. 先检测当前线程是否已经获取lock,持有lock的线程才可以signal if (!isHeldExclusively()) throw new IllegalMonitorStateException(); //2. 获取等待队列中第一个节点（头节点） Node first = firstWaiter; if (first != null) //3. 将刚获取的节点，状态变更为CONDITION，并插入到「同步队列」 doSignal(first);&#125; ➤ signalAll 的实现解析： private void doSignalAll(Node first) &#123; // 清空 condition 的 lastWaiter &amp; firstWaiter lastWaiter = firstWaiter = null; do &#123; // 从头遍历「等待队列」所有节点 Node next = first.nextWaiter; first.nextWaiter = null; transferForSignal(first); // 节点放入「同步队列」 first = next; &#125; while (first != null);&#125; 线程调用完 signal()/signalAll() 后，一般都会再调用 unlock()，释放 state 计数器，并从「同步队列」唤醒一个线程； @ref: 深入理解Java并发线程协作类Condition | Java程序员进阶之路 比较 ReentrantLock 和 synchronized ReentrantLock 可以”可中断的”获取锁 void lockInterruptibly() throws InterruptedException ReentrantLock 可以尝试非阻塞地获取锁 boolean tryLock() ReentrantLock 可以超时获取锁，通过 tryLock(timeout, unit) ReentrantLock 可以实现公平锁，通过 new ReentrantLock(true) 实现 ReentrantLock 对象可以同时绑定多个 Condition 对象，只需要多次调用 newCondition() 方法即可。而在 synchronized 中只能使用一个对象的 wait(), notify(), notifyAll() Condition 对应的方法是 await(), signal(), signalAll(), Object 对应的方法 wait(), notify(), notifyAll() ReentrantLock 的实现是 AQS, synchronized 实现模型是 Monitor 注: ReentrantLock.lockInterruptibly() : 当调用 lockInterruptibly 时如果线程有中断标志, 则抛出 InterruptedException, 如果调用 InterruptedException 没有拿到锁, 线程进入 Blocked 状态, 是可以被 Interrupt 的@ref Java多线程进阶（二）—— J.U.C之locks框架：接口 - 透彻理解Java并发编程 - SegmentFault 思否","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"https://beefyheisenberg.github.io/tags/Java并发/"},{"name":"JUC","slug":"JUC","permalink":"https://beefyheisenberg.github.io/tags/JUC/"}]},{"title":"Java-并发.05b.JUC-AQS（）","slug":"12.Java/Java-并发.05b.JUC-AQS","date":"2024-01-24T01:27:52.208Z","updated":"2024-01-24T01:27:52.209Z","comments":true,"path":"12.Java/Java-并发.05b.JUC-AQS/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-并发.05b.JUC-AQS/","excerpt":"AQS 简介ReentrantLock 中有一个 Sync 类型的成员, 根据调用不同的构造方法, sync 被初始化为 NonFairSync (非公平锁, 默认) 或者 FairSync (公平锁), 这两种 Sync 都继承自 AbstractQueuedSynchronizer, 简称 AQS. AQS 是 java.util.concurrent 的核心, CountDownLatch, Semaphore, ReentrantLock 等都有一个内部类是 AQS 类的子类. 图-ReentrantLock-AQS UML: AbstractQueuedSynchronizer 有几个重要的成员变量:","text":"AQS 简介ReentrantLock 中有一个 Sync 类型的成员, 根据调用不同的构造方法, sync 被初始化为 NonFairSync (非公平锁, 默认) 或者 FairSync (公平锁), 这两种 Sync 都继承自 AbstractQueuedSynchronizer, 简称 AQS. AQS 是 java.util.concurrent 的核心, CountDownLatch, Semaphore, ReentrantLock 等都有一个内部类是 AQS 类的子类. 图-ReentrantLock-AQS UML: AbstractQueuedSynchronizer 有几个重要的成员变量: 1 计数器 private volatile int state ; 2 等待线程的队列：双向队列，由 head 和 tail 两个 Node 类型的引用，表示头尾; 3 从 AbstractOwnableSynchronizer 继承来的 exclusiveOwnerThread (Thread 类型); 计数器 state 是volatile修饰的, 作用是记录资源： 如果是 ReentrantLock，state 作用是记录锁被重入的次数, 初值是 0, 重入一次+1, 释放一次-1, 计数器为 0 表示没有线程持有该锁, 是 free 的; 如果是 Semaphore，state记录的是可用资源的数量，acquire(int) 可以尝试获取指定个数的资源； 尝试 CAS 修改计数器失败的线程, 会被放入队列尾部; exclusiveOwnerThread 用来记录当前该锁被哪个线程占用(但不是 volatile 的, 此处有疑问) ➤ AbstractQueuedSynchronizer 抽象类提供的主要的属性和方法: public abstract class AbstractQueuedSynchronizer &#123; private transient volatile Node head; // 双向队列头 private transient volatile Node tail; // 双向队列尾 private volatile int state; // 重入计数器 // Lock.lock() 调用了 sync.acquire(1) 方法, 最终调用到 AQS.acquire(1): public final void acquire(int arg) &#123; // tryAcquire 由具体类实现,获取state // FairSync 和 NonFairSync 分别实现了 tryAcquire if (!tryAcquire(arg) &amp;&amp; // addWaiter: 当前线程放入等待队列 // acquireQueued: 如果队列中只有刚放入的线程，则尝试唤醒 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) // selfInterrupt：中断当前线程，让出CPU selfInterrupt(); &#125; // Lock.unlock() 调用了 sync.release(1) 方法, 最终调用到 AQS.acquire(1): public final boolean release(int arg) &#123; // tryRelease 由具体类实现,释放state if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) // 从队列中取出第一个可释放的节点, unpark之 unparkSuccessor(h); return true; &#125; return false; &#125;&#125;static final class Node &#123; // CANCELLED，值为1，表示当前的线程被取消 // SIGNAL，值为-1，表示当前节点的后继节点包含的线程需要运行，也就是unpark // CONDITION，值为-2，表示当前节点在等待condition，也就是在condition队列中 // PROPAGATE，值为-3，表示当前场景下后续的acquireShared能够得以执行 // 值为0，表示当前节点在sync队列中，等待着获取锁 /** waitStatus value to indicate thread has cancelled. */ static final int CANCELLED = 1; /** waitStatus value to indicate successor's thread needs unparking. */ static final int SIGNAL = -1; /** waitStatus value to indicate thread is waiting on condition. */ static final int CONDITION = -2; /** waitStatus value to indicate the next acquireShared should * unconditionally propagate. */ static final int PROPAGATE = -3; volatile int waitStatus; volatile Thread thread; volatile Node prev; volatile Node next;&#125; acquire➤ AQS.acquire(int)解析： public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; // 参数 node 即刚添加到队尾的节点 final boolean acquireQueued(final Node node, int arg) &#123; boolean interrupted = false; try &#123; for (;;) &#123; final Node p = node.predecessor(); // 返回node.pre if (p == head &amp;&amp; tryAcquire(arg)) &#123; // pre是head，即队列中只有 node 一个 // tryAcquire： 再尝试 CAS // 进了这个if 说明抢到锁了，返回false setHead(node); p.next = null; // help GC return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node)) // 根据pre.state判断当前线程能否park interrupted |= parkAndCheckInterrupt(); // park 当前线程 &#125; &#125; catch (Throwable t) &#123; cancelAcquire(node); if (interrupted) selfInterrupt(); throw t; &#125;&#125; tryAcquire(int)：参数是 int 类型，表示获取多少个资源，tryAcquire 由具体的类实现， ReentrantLock 的 NonfairSync 和 FairSync 都分别实现了 tryAcquire： ReentrantLock.FairSync.tryAcquire：公平方式，如果队列里还有其他线程，返回 false ReentrantLock.NonfairSync.tryAcquire：非公平方式，直接尝试对 state 进行CAS，返回CAS的结果 // 解析 -&gt; Java-并发.05b.JUC-Lock addWaiter: 向队列尾添加（当前线程的）Node acquireQueued：向队列添加完 Node 后，接下来 acquireQueued() 的参数即刚添加的 Node 先判断队列是否只有一个 Node（因头节点不存储信息，这里只需判断 Node 的 pre 是否是 head 引用），如果是队列唯一的线程，那么再尝试一下CAS，如果CAS成功即算抢锁成功，如果CAS不成功 shouldParkAfterFailedAcquire 检查一下当前线程是否可以 park，只有当该节点的前驱结点的状态为 SIGNAL 时，才可以对该结点所封装的线程进行 park 操作。否则，将不能进行 park 操作 parkAndCheckInterrupt：调用 LockSupport.park(this) 停止当前的线程，让出 CPU release➤ AQS.release()解析： public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false; &#125; tryRelease(int)：参数是 int 类型，表示释放多少个资源，tryRelease 也需要具体类实现： unparkSuccessor(h)：唤醒 head 节点后面的节点，唤醒使用的是调 LockSupport.unpark() condition➤ 除了上述两个方法，AQS 还有一个重要的内部类 ConditionObject，这个内部类用于实现 ReentrantLock 等的 Condition 机制，一个 Lock 可以创建多个 ConditionObject 对象。Condition 工作机制参考 ReentrantLock Java-并发.05b.JUC-Lock","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[]},{"title":"Java-并发.05a.JUC-Atomic（原子操作）& CAS","slug":"12.Java/Java-并发.05a.JUC-Atomic&CAS","date":"2024-01-24T01:27:52.202Z","updated":"2024-01-24T01:27:52.203Z","comments":true,"path":"12.Java/Java-并发.05a.JUC-Atomic&CAS/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-并发.05a.JUC-Atomic&CAS/","excerpt":"一些概念（乐观锁、CAS）▷ 原子操作: 对int变量赋值的操作是原子的吗？ - 知乎 ▷ CAS: CAS(Compare And Swap)：比较并替换。CAS 需要有 3 个操作数：内存地址 V，旧的预期值 A，即将要更新的目标值 B。 CAS 指令执行时，当且仅当内存地址 V 的值与预期值 A 相等时，将内存地址 V 的值修改为 B 并返回 True，否则就什么都不做并返回 False。比较+替换是一个原子操作。","text":"一些概念（乐观锁、CAS）▷ 原子操作: 对int变量赋值的操作是原子的吗？ - 知乎 ▷ CAS: CAS(Compare And Swap)：比较并替换。CAS 需要有 3 个操作数：内存地址 V，旧的预期值 A，即将要更新的目标值 B。 CAS 指令执行时，当且仅当内存地址 V 的值与预期值 A 相等时，将内存地址 V 的值修改为 B 并返回 True，否则就什么都不做并返回 False。比较+替换是一个原子操作。 ▷ 乐观锁 &amp; 悲观锁: 悲观锁: 假定会出现冲突, 加锁前检查所有冲突的可能性，每次在拿数据的时候都会上锁，拿到锁之后才可以修改临界区数据； 乐观锁(Optimistic Locking): 假定不会出现冲突, 先尝试去修改数据的操作, 根据操作的返回值确定是否抢锁成功; Java 中乐观锁 &amp; 悲观锁的实现: CAS &amp; ReentrantLock Atomic在 JDK 5之前 Java 语言是靠 synchronized 关键字保证同步的, synchronized 的实现是 monitor 对象, 和 ReentantLock 类似也是一种重量级的锁, 获取锁失败会导致线程的上下文切换. Volatile 关键字能够在并发条件下，强制将修改后的值刷新到主内存中来保持内存的可见性。通过 CPU 内存屏障禁止编译器指令性重排来保证并发操作的有序性, 但 volatile 也有局限性, volatile++这种依赖当前值的操作并不能保证原子性. 在这种情况下, 不想使用重量级锁, Volatile 自增无法满足原子性, 这时候可以使用 java.util.concurrent.atomic ，支持了大部分 Java 包的原子操作: 原子更新基本类型：AtomicBoolean, AtomicInteger, AtomicLong. 原子更新数组：AtomicIntegerArray, AtomicLongArray, AtomicReferenceArray. 原子更新引用类型：AtomicReference, AtomicStampedReference, AtomicMarkableReference. 原子更新字段类型：AtomicReferenceFieldUpdater, AtomicIntegerFieldUpdater, AtomicLongFieldUpdater. 其他：LongAdder AtomicInteger atomicInteger = new AtomicInteger();// incrementAndGet提供了几个方法实现原子操作:int i = atomicInteger.get();atomicInteger.getAndSet(0); // 当前值设置为0, 并返回之前的值atomicInteger.compareAndSet(1,3); // 如果当前值等于1, 则更新为3atomicInteger.decrementAndGet(1); // 自减atomicInteger.incrementAndGet(1); // 自增 AtomicInteger 的 CAS 实现java.util.concurrent.atomic 包下的类, 大都是调用 sun.misc.Unsafe 里的方法实现的, sun.misc.Unsafe 主要的 CAS 方法： compareAndSetObject, compareAndSetInt 和 compareAndSetLong, 它们都是 native 方法, 最终实现在 Hotspot 的 unsafe.cpp, 最终调用了 C++ 的 Atomic::cmpxchg. public class AtomicInteger extends Number implements java.io.Serializable &#123; // 值的内存偏移量 private static final long VALUE = U.objectFieldOffset(AtomicInteger.class, \"value\"); // 值 private volatile int value; // 最终调用的是unsafe.compareAndSetInt, 传参是： // this：此 AtomicInteger对象 // VALUE: 值在AtomicInteger对象中的偏移量 // expectedValue：期望值 // newValue：新值 public final boolean compareAndSet(int expectedValue, int newValue) &#123; return U.compareAndSetInt(this, VALUE, expectedValue, newValue); &#125;&#125; unsafe.compareAndSetInt 是 native 函数： // unsafe.cpp// UNSAFE_ENTRY 和 UNSAFE_END 都是宏，在预编译期间会被替换成真正的代码// 下面的 jboolean、jlong 和 jint 等是一些类型定义（typedef）UNSAFE_ENTRY(jboolean, Unsafe_CompareAndSwapInt(JNIEnv *env, jobject unsafe, jobject obj, jlong offset, jint e, jint x)) UnsafeWrapper(\"Unsafe_CompareAndSwapInt\"); oop p = JNIHandles::resolve(obj); // 根据偏移量，计算 value 的地址。这里的 offset 就是 AtomaicInteger.value的Offset jint* addr = (jint *) index_oop_from_field_offset_long(p, offset); // 调用 Atomic 中的函数 cmpxchg，该函数声明于 Atomic.hpp 中 return (jint)(Atomic::cmpxchg(x, addr, e)) == e;UNSAFE_END // Atomic.hpp atomic.cppunsigned Atomic::cmpxchg(unsigned int exchange_value, volatile unsigned int* dest, unsigned int compare_value) &#123; assert(sizeof(unsigned int) == sizeof(jint), \"more work to do\"); /* * 根据操作系统类型调用不同平台下的重载函数，这个在预编译期间编译器会决定调用哪个平台下的重载 * 函数。相关的预编译逻辑如下： * * atomic.inline.hpp： * #include \"runtime/atomic.hpp\" * * // Linux * #ifdef TARGET_OS_ARCH_linux_x86 * # include \"atomic_linux_x86.inline.hpp\" * #endif * * // 省略部分代码 * * // Windows * #ifdef TARGET_OS_ARCH_windows_x86 * # include \"atomic_windows_x86.inline.hpp\" * #endif * * // BSD * #ifdef TARGET_OS_ARCH_bsd_x86 * # include \"atomic_bsd_x86.inline.hpp\" * #endif * * */ return (unsigned int)Atomic::cmpxchg((jint)exchange_value, (volatile jint*)dest, (jint)compare_value);&#125; C++ 的 Atomic::cmpxchg 在不同的平台有不同的实现, 以 Windows 为例： // atomic_windows_x86.inline.hpp#define LOCK_IF_MP(mp) __asm cmp mp, 0 \\ __asm je L0 \\ __asm _emit 0xF0 \\ __asm L0: inline jint Atomic::cmpxchg (jint exchange_value, volatile jint* dest, jint compare_value) &#123; // alternative for InterlockedCompareExchange int mp = os::is_MP(); __asm &#123; mov edx, dest mov ecx, exchange_value mov eax, compare_value LOCK_IF_MP(mp) cmpxchg dword ptr [edx], ecx &#125;&#125; 上面的代码由 LOCK_IF_MP 预编译标识符和 cmpxchg 函数组成。为了看到更清楚一些，我们将 cmpxchg 函数中的 LOCK_IF_MP 替换为实际内容。如下： inline jint Atomic::cmpxchg (jint exchange_value, volatile jint* dest, jint compare_value) &#123; // 判断是否是多核 CPU int mp = os::is_MP(); __asm &#123; // 将参数值放入寄存器中 mov edx, dest // 注意: dest 是指针类型，这里是把内存地址存入 edx 寄存器中 mov ecx, exchange_value mov eax, compare_value // LOCK_IF_MP cmp mp, 0 /* * 如果 mp = 0，表明是线程运行在单核 CPU 环境下。此时 je 会跳转到 L0 标记处， * 也就是越过 _emit 0xF0 指令，直接执行 cmpxchg 指令。也就是不在下面的 cmpxchg 指令 * 前加 lock 前缀。 */ je L0 /* * 0xF0 是 lock 前缀的机器码，这里没有使用 lock，而是直接使用了机器码的形式。至于这样做的 * 原因可以参考知乎的一个回答： * https://www.zhihu.com/question/50878124/answer/123099923 */ _emit 0xF0L0: /* * 比较并交换。简单解释一下下面这条指令，熟悉汇编的朋友可以略过下面的解释: * cmpxchg: 即“比较并交换”指令 * dword: 全称是 double word，在 x86/x64 体系中，一个 * word = 2 byte，dword = 4 byte = 32 bit * ptr: 全称是 pointer，与前面的 dword 连起来使用，表明访问的内存单元是一个双字单元 * [edx]: [...] 表示一个内存单元，edx 是寄存器，dest 指针值存放在 edx 中。 * 那么 [edx] 表示内存地址为 dest 的内存单元 * * 这一条指令的意思就是，将 eax 寄存器中的值（compare_value）与 [edx] 双字内存单元中的值 * 进行对比，如果相同，则将 ecx 寄存器中的值（exchange_value）存入 [edx] 内存单元中。 */ cmpxchg dword ptr [edx], ecx &#125;&#125; CAS 的实现离不开处理器的支持。如上面源代码所示，程序会根据当前处理器的类型来决定是否为 cmpxchg 指令添加 lock 前缀。如果程序是在多处理器上运行，就为 cmpxchg 指令加上 lock 前缀（lock cmpxchg）。反之，如果程序是在单处理器上运行，就省略 lock 前缀（单处理器自身会维护单处理器内的顺序一致性，不需要 lock 前缀提供的内存屏障效果）。 intel 的手册对 lock 前缀的说明如下： 确保对内存的读/改/写操作原子执行。在 Pentium 及 Pentium 之前的处理器中，带有 lock 前缀的指令在执行期间会锁住总线，使得其他处理器暂时无法通过总线访问内存。很显然，这会带来昂贵的开销。从 Pentium 4，Intel Xeon 及 P6 处理器开始，intel 在原有总线锁的基础上做了一个很有意义的优化：如果要访问的内存区域（area of memory）在 lock 前缀指令执行期间已经在处理器内部的缓存中被锁定（即包含该内存区域的缓存行当前处于独占或以修改状态），并且该内存区域被完全包含在单个 缓存行（cache line） 中，那么处理器将直接执行该指令。由于在指令执行期间该缓存行会一直被锁定，其它处理器无法读 / 写该指令要访问的内存区域，因此能保证指令执行的原子性。这个操作过程叫做 缓存锁定（cache locking），缓存锁定将大大降低 lock 前缀指令的执行开销，但是当多处理器之间的竞争程度很高或者指令访问的内存地址未对齐时，仍然会锁住总线。 禁止该指令与之前和之后的读和写指令重排序。 把写缓冲区中的所有数据刷新到内存中。 缓存行（cache line）和 MESI 协议参考： [[../21.Operating-System/01.CPU_Cache]] 上面的第 2 点和第 3 点所具有的内存屏障效果，JUC 的 Atomic.CAS 操作 足以同时实现 volatile 读和 volatile 写的内存语义。 @ref: https://www.cnblogs.com/huansky/p/15746624.html AtomicReferenceAtomicReference：原子性更新引用 实现： AtomicReference&lt;T&gt; 有一个 T 类型的 value 成员，使用这个成员来保存引用 在 static 代码块中，计算 value 在内存中的 offset compareAndSet 即对 value 进行CAS static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicReference.class.getDeclaredField(\"value\")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125;public final boolean compareAndSet(V expect, V update) &#123; return unsafe.compareAndSwapObject(this, valueOffset, expect, update); &#125; Atomic FieldUpdaterAtomicReferenceFieldUpdater, AtomicIntegerFieldUpdater, and AtomicLongFieldUpdater 原子性更新引用中的 field 使用 AtomicIntegerFieldUpdater 对类的 int 类型的 field 进行原子性更新： class Test &#123; volatile int count; public int getCount() &#123; return count; &#125;&#125;public static void main(String[] args) throws InterruptedException &#123; // 创建 FieldUpdater 对象， 并与Test.class 的filed 关联起来 AtomicIntegerFieldUpdater&lt;Test&gt; countFieldUpdater = AtomicIntegerFieldUpdater.newUpdater(Test.class, \"count\"); Test test = new Test(); ExecutorService es = Executors.newFixedThreadPool(5); for (int i = 0; i &lt; 5; i++) &#123; es.execute(() -&gt; &#123; for (int c = 0; c &lt; 100; c++) &#123; countFieldUpdater.incrementAndGet(test); &#125; &#125;); &#125; es.shutdown(); es.awaitTermination(10, TimeUnit.MINUTES); System.out.println(\"count: \" + test.getCount());&#125; 使用 AtomicReferenceFieldUpdater&lt;T, V&gt; 对类的引用类型 field 进行原子性更新： ： T - The type of the object holding the updatable field V - The type of the field @ref: Java - Atomic Field Updaters: AtomicReferenceFieldUpdater, AtomicIntegerFieldUpdater, and AtomicLongFieldUpdater AtomicStampedReference 解决 ABA 问题AtomicReference 的通用工作模式： AtomicReference&lt;Object&gt; ref = new AtomicReference&lt;&gt;(new Object());Object oldVal = ref.get();// 对旧对象做一些更新，得到新对象Object newVal = someFunctionOfOld(oldVal); // 如果期间没有其它线程改变了缓存值，则更新boolean success = ref.compareAndSet(oldVal , newVal); 但是上面的模式会有 ABA 问题： 线程 1 获取 Atomic 的 oldVal = A，但是因为某些原因让出了 CPU 线程 2 获取到 oldVal= A，并成功 CAS（A，B） 线程 2 继续 CAS（B，A）并且成功，Atomic 的最终值是A 线程 1 恢复，CAS（A，B）也成功了 Java 中的 AtomicStampedReference&lt;E&gt; 通过版本号避免了 ABA 问题，它通过包装 [E,Integer] 的 Pair 来对对象标记版本戳 stamp，从而避免 ABA 问题： AtomicStampedReference&lt;Object&gt; ref = new AtomicStampedReference&lt;&gt;(new Object(),0); // 创建AtomicStampedReference对象，持有Obj引用，版本为0int[] stamp = new int[1];Object oldVal = ref.get(stamp); // get 方法，一次调用获取 ref 和 stampint oldStamp=stamp[0]; // stamp[0] 保存的是上次的版本号ref.compareAndSet(oldVal, new Object(), oldStamp, oldStamp + 1) @ref： Java多线程进阶（十四）—— J.U.C之atomic框架：AtomicReference - 透彻理解Java并发编程 - SegmentFault 思否 LongAdder已经有 AtomicLong.addAndGet(l) 的情况下, 为什么还要设计 LongAdder? AtomicLong 是使用 “自旋+CAS”实现, 面对大量并发的情况下有性能瓶颈： public final long getAndAddLong(Object o, long offset, long delta) &#123; long v; do &#123; v = getLongVolatile(o, offset); &#125; while (!compareAndSwapLong(o, offset, v, v + delta)); return v;&#125; LongAdder 的使用： compareAndSet： addAndGet： decrementAndGet： 除了 CAS，LongAdder 还提供了很多 add 场景的操作，LongAdder 更适用于 add 并发多的场景。 LongAdder 的实现： 内部是 base + cell 数组，LongAdder 初始化时 cell = null 如果是写操作，尝试 CAS base， 如果 CAS base 成功，则只更新base 如果 CAS 失败说明有竞争，这时候开始初始化 cell 数组，并通过线程 hashCode 确认 cell 数组的位置（这里是用了 THREAD_PROBE.get(Thread.currentThread()), 是不是线程 hashCode 需要再确认，通过这个 hashCode 去确认数组位置，和 HashMap 的方法类似：index = (cell.length - 1) &amp; hash ） 以后线程进行写入操作时，如果 cell 非空，会尝试 CAS 属于自己的 cell cell 也会扩容（double cell 数组）需要注意 cell 数组大小超过 CPU 核数后则不再扩容 读操作（sum 方法）： base + ∑cell[] ，简单的累加操作，如果当前有线程正在改写 cell，这里得到的仍是一个近似值 @ref Java多线程进阶（十七）—— J.U.C之atomic框架：LongAdder - 透彻理解Java并发编程 - SegmentFault 思否","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"https://beefyheisenberg.github.io/tags/Java并发/"},{"name":"JUC","slug":"JUC","permalink":"https://beefyheisenberg.github.io/tags/JUC/"},{"name":"CAS","slug":"CAS","permalink":"https://beefyheisenberg.github.io/tags/CAS/"}]},{"title":"Java-并发.04.Volatile","slug":"12.Java/Java-并发.04.Volatile","date":"2024-01-24T01:27:52.196Z","updated":"2024-01-24T01:27:52.196Z","comments":true,"path":"12.Java/Java-并发.04.Volatile/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-并发.04.Volatile/","excerpt":"volatile关键字特性 多CPU环境的可见性: 多CPU的环境下, CPU有可能从寄存器或Cache里直接取值, 这种情况下运行在不同CPU上的线程获取的值可能不同, volitile变量可以保证每次更新都改变到主存, 每次读取都从主存中读取. volatile 可以作为一种开销较低的免锁机制(某些情况下). volatile 的 long, double 的读写不保证有原子性. volatile变量的”复合操作”(对变量的写操作依赖当前值)不具备原子性. volatile 的应用➤ 适用的情况： 作为简单的状态标志, vol_variable = 1 和 vol_variable = 0 这种操作是原子的, 对 volatile 变量的赋值也对其他线程立刻可见; 保证只有一个线程写, 其他线程只能读;","text":"volatile关键字特性 多CPU环境的可见性: 多CPU的环境下, CPU有可能从寄存器或Cache里直接取值, 这种情况下运行在不同CPU上的线程获取的值可能不同, volitile变量可以保证每次更新都改变到主存, 每次读取都从主存中读取. volatile 可以作为一种开销较低的免锁机制(某些情况下). volatile 的 long, double 的读写不保证有原子性. volatile变量的”复合操作”(对变量的写操作依赖当前值)不具备原子性. volatile 的应用➤ 适用的情况： 作为简单的状态标志, vol_variable = 1 和 vol_variable = 0 这种操作是原子的, 对 volatile 变量的赋值也对其他线程立刻可见; 保证只有一个线程写, 其他线程只能读; ➤ 不适用的情况： 用于计数器(请使用AomicInteger)， 虽然增量操作（x++）看上去类似一个单独操作，实际上它是一个由 “读取－修改－写入” 操作序列组成的组合操作，必须以原子方式执行，而 volatile 不能提供必须的原子特性。 “依赖当前值”的写操作, 比如i=i+1 非原子操作, i++, i=!i都不是原子操作 比如以下代码是有问题的: private volatile i = 0;protect void filp() &#123; i = !i;&#125; Volatile 的特性是如何实现的？ 第一：使用 volatile 关键字会强制将修改的值立即写入主存； 第二：使用 volatile 关键字的话，当线程 2 进行修改时，会导致线程1的工作内存中缓存变量的 缓存行 无效（缓存行，CPU 高速缓存中的 cache line） 第三：由于线程1的工作内存中缓存变量的 缓存行 无效，所以线程 1 再次读取变量的值时会去主存读取。 上面的特性，是通过 内存屏障 实现的，详见 Java-并发.09.深入理解JMM Volatile Double 是原子的吗？先看硬件的支持，如果要保证 double 写的原子性，那么要满足 64bit + 内存对齐 + 它没跨 cache line 如果是 64bit，且这个 double 是内存对齐的，那么对它的读写是原子的，但是很多情况下（C++ 和 Java 中）无法保证对齐，也就无法保证原子性 根据 IA64 手册，X86_64 架构下，不跨越 cacheline 的 8byte 读写是原子的 Double 是否是原子性，1 看硬件（64），2 看上层是否实现了对 double 的对齐 Java 语言规范文档：jls-17 Non-Atomic Treatment of double and long 对于 64 位的 long 和 double，如果没有被 volatile 修饰，那么对其操作可以不是原子的。在操作的时候，可以分成两步，每次对 32位操作。 如果使用 volatile 修饰 long 和 double，那么其读写都是原子操作 在实现 JVM 时，可以自由选择是否把读写 long 和 double 作为原子操作 作者测试了 32 Hotspot 和 64 下多线程写 volatile double 的表现： 32：无法保证原子性 64：看结果是可以保证 Java 中 long 和 double 的原子性？-腾讯云开发者社区-腾讯云 (2 封私信 / 62 条消息) 对int变量赋值的操作是原子的吗？ - 知乎","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"https://beefyheisenberg.github.io/tags/Java并发/"}]},{"title":"Java-并发.03.Synchronized","slug":"12.Java/Java-并发.03.Synchronized","date":"2024-01-24T01:27:52.192Z","updated":"2024-01-24T01:27:52.192Z","comments":true,"path":"12.Java/Java-并发.03.Synchronized/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-并发.03.Synchronized/","excerpt":"Synchronized使用(1) synchronized 方法: public class Bank &#123; public synchronized void transfer() &#123; while(!resource_is_available) // 进入代码块,此时持有对象锁 wait(); // 放弃锁，并在对象上等待 // 重新获得锁, doSomething... notifyAll(); // 通知其他等待该对象锁的线程 &#125;&#125; (2) synchronized 块:","text":"Synchronized使用(1) synchronized 方法: public class Bank &#123; public synchronized void transfer() &#123; while(!resource_is_available) // 进入代码块,此时持有对象锁 wait(); // 放弃锁，并在对象上等待 // 重新获得锁, doSomething... notifyAll(); // 通知其他等待该对象锁的线程 &#125;&#125; (2) synchronized 块: Object object = new Object();public void transfer(long userID, double amount) &#123; synchronized(object) &#123; // doSomething .. &#125;&#125; 每个类对象都有从 Object 继承的”对象锁”, synchronized 方法利用这个对象锁保护方法内的代码片段. 对于同步方法，锁是当前实例对象。 对于静态同步方法，锁是当前对象的 Class 对象。 对于同步方法块，锁是 Synchonized 括号里配置的对象。 实现 在 synchronized 代码块前后增加的 monitorenter 和 monitorexist 两个 JVM 字节码指令,指令的参数是 this 引用。 synchronized 关键字起到的作用是设置一个独占访问临界区，在进入这个临界区前要先获取对应的监视器锁，任何 Java 对象都可以成为监视器锁，声明在静态方法上时监视器锁是当前类的 Class 对象，实例方法上是当前实例。 synchronized 提供了原子性、可见性和防止重排序的保证。 JMM 中定义监视器锁的释放操作 happen-before 于后续的同一个监视器锁获取操作。再结合程序顺序规则就可以形成内存传递可见性保证。 下面以一段 Java 代码为例: public class TestSynchronize &#123; private int count; private void inc() &#123; synchronized (this) &#123; count++; &#125; &#125; public static void main(String[] args) &#123; new TestSynchronize().inc(); &#125;&#125; javap 查看 inc() 方法的实现: private void inc(); descriptor: ()V flags: ACC_PRIVATE Code: stack=3, locals=3, args_size=1 0: aload_0 1: dup 2: astore_1 3: monitorenter // monitor 1 4: aload_0 5: dup 6: getfield #2 // Field count:I 9: iconst_1 10: iadd 11: putfield #2 // Field count:I 14: aload_1 15: monitorexit // monitor 2 16: goto 24 19: astore_2 20: aload_1 21: monitorexit // monitor 3 22: aload_2 23: athrow 24: return Exception table: from to target type 4 16 19 any 19 22 19 any LineNumberTable: line 14: 0 line 15: 4 在 synchronized 代码块前后增加的 monitorenter 和 monitorexist 两个 JVM 字节码指令,指令的参数是 this 引用。 hotspot 中对于 monitor_enter 字节码指令的实现(注，不同 JDK 版本代码可能不同)： IRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorenter(JavaThread* thread, BasicObjectLock* elem))#ifdef ASSERT thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);#endif if (PrintBiasedLockingStatistics) &#123; Atomic::inc(BiasedLocking::slow_path_entry_count_addr()); &#125; Handle h_obj(thread, elem-&gt;obj()); assert(Universe::heap()-&gt;is_in_reserved_or_null(h_obj()), \"must be NULL or an object\"); // 是否使用偏向锁 JVM 启动时设置的偏向锁-XX:-UseBiasedLocking=false/true if (UseBiasedLocking) &#123; // Retry fast entry if bias is revoked to avoid unnecessary inflation ObjectSynchronizer::fast_enter(h_obj, elem-&gt;lock(), true, CHECK); &#125; else &#123; // 轻量级锁 ObjectSynchronizer::slow_enter(h_obj, elem-&gt;lock(), CHECK); &#125; assert(Universe::heap()-&gt;is_in_reserved_or_null(elem-&gt;obj()), \"must be NULL or an object\");#ifdef ASSERT thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);#endifIRT_END 从上面的 monitorenter 代码可以看到先尝试偏向锁（fast_enter），若失败则改为使用轻量级锁（slow_enter），在轻量级锁的代码中如果也失败，最后兜底方案是膨胀为重量级锁： // slow_enter()函数是轻量级锁的实现，函数最后的inflate()是重量级锁void ObjectSynchronizer::slow_enter(Handle obj, BasicLock* lock, TRAPS) &#123; //获取上锁对象头部标记信息 markOop mark = obj-&gt;mark(); assert(!mark-&gt;has_bias_pattern(), \"should not see bias pattern here\"); //如果对象处于无锁状态 if (mark-&gt;is_neutral()) &#123; //将对象头部保存在lock对象中 lock-&gt;set_displaced_header(mark); //通过cmpxchg进入自旋替换对象头为lock对象地址，如果替换成功则直接返回，表明获得了轻量级锁，不然继续自旋 if (mark == (markOop) Atomic::cmpxchg_ptr(lock, obj()-&gt;mark_addr(), mark)) &#123; TEVENT (slow_enter: release stacklock) ; return ; &#125; // 否则判断当前对象是否上锁，并且当前线程是否是锁的占有者，如果是markword的指针指向栈帧中的LR，则重入 &#125; else if (mark-&gt;has_locker() &amp;&amp; THREAD-&gt;is_lock_owned((address)mark-&gt;locker())) &#123; assert(lock != mark-&gt;locker(), \"must not re-lock the same lock\"); assert(lock != (BasicLock*)obj-&gt;mark(), \"don't relock with same BasicLock\"); lock-&gt;set_displaced_header(NULL); return; &#125;​#if 0 // The following optimization isn't particularly useful. if (mark-&gt;has_monitor() &amp;&amp; mark-&gt;monitor()-&gt;is_entered(THREAD)) &#123; lock-&gt;set_displaced_header (NULL) ; return ; &#125;#endif​ // 代码执行到这里，说明有多个线程竞争轻量级锁，轻量级锁通过`inflate`进行膨胀升级为重量级锁 lock-&gt;set_displaced_header(markOopDesc::unused_mark()); ObjectSynchronizer::inflate(THREAD, obj())-&gt;enter(THREAD);&#125; 对象锁的升级上面的代码看到了 monitor_enter 的大致流程：偏向锁（fast_enter）-》轻量级锁（slow_enter）-》重量级锁,前两者的实现都使用了 Java 对象的 Mark Word 来实现。 Java SE1.6 为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，所以在 Java SE1.6里 对象锁 一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态 和 重量级锁状态，它会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。 随着锁的升级， Java 对象头里的 Mark Word 存储的内容也会变化。 回顾 Java 对象的内存结构:在 64 位 JVM 环境, Java 对象对象头中，前 64bit 是”Mark Word”, 存储了 hashCode, 锁信息, 以及分代信息等, MarkWord 低 2 位是锁标记, 加上 1 位的偏向锁标记，一共对应 4 种锁: 图来自 https://juejin.cn/post/6844904114061590535#heading-5 无锁无锁状态下, 对象 Mark Word 锁标志也是 01(同偏向锁一样)； 偏向锁在无锁状态下，当有线程尝试获取对象锁（前提是 JVM 开启了支持偏向锁），那么会通过 CAS 操作，将对象头的 Mark Word 替换为自己的线程 ID，并把 Mark Word 锁标志置为101，这时候对象锁进入偏向锁； 偏向锁状态下，线程尝试进入同步块的过程如下： 检查 Mark Word 中的 ThreadID 是否等于自己的，如果是则直接进入同步块； 如果不等于自己的 ThreadID，获取偏向锁失败 所以，对于很少出现竞争的同步块，偏向锁的效率很高（只是简单检查） 偏向锁不会立刻撤销，而是等到下次全局安全点（safe point，当前 JVM 没有正在执行的字节码），JVM 会检查持有偏向锁的线程是否还活着， 如果否，会设置 Mark Word 为无锁状态，随后偏向新的线程； 如果是，已持有偏向锁的线程继续执行，竞争失败的线程开始自旋+CAS（轻量级锁） 可以看到偏向锁是一直等到有竞争才会释放，偏向锁的撤销需要等到下个 safe point。 是否要用偏向锁，取决于： 偏向锁在 JDK 6及以后的 JVM 里是默认启用的。可以通过 JVM 参数关闭偏向锁：-XX:-UseBiasedLocking=false； 如果对象已经调用过 hashCode 方法，Mark Word 中会存储 hashcode 的值，这种对象就无法转换为偏向锁了，而是直接从无锁转换为轻量级锁，但这对轻量锁和重量所没关系，因为这两种锁会各自保存 HashCode（前者会保存在栈帧中的 Lock Record，后者保存在 Monitor 对象中）@ref: Advanced-Java.05.对象内存结构 偏向锁中的 epoch 解析： 偏向锁里面的epoch作用_Java多线程-IT乾坤技术博客 轻量级锁上面提到，如果线程 A 已经持有了偏向锁，线程 B 尝试解锁的时候会使用 CAS，也即进入了轻量级锁，轻量级锁的实现是自旋+CAS， 竞争线程会在自己的栈帧中创建 Lock Record（锁记录），并将对象头中的 Mark Word 复制到 Lock Record 竞争线程使用 CAS，尝试将对象头的 Mark Word 替换为指向 Lock Record 的指针 CAS 失败则自旋获取锁，自旋超过一定次数，对象锁升级为重量级锁 上面的自旋次数默认是10次，可以使用-XX:PreBlockSpin 来更改，自旋锁在JDK1.4.2中引入，使用-XX:+UseSpinning来开启。JDK 6中变为默认开启，并且引入了自适应的自旋锁（适应性自旋锁）。 @doubt: 当是偏向锁时，另一个线程 B 尝试 CAS，CAS 的 exceptVal 是“无锁状态下的 MarkWord”？那么在 B 中如何获取“无锁状态下的 MarkWord”？ 重量级锁对象锁升级为重量级锁：Mark Word 的锁标记设置为 00，Mark Word 中指向 Lock Record 的指针被替换为指向重量级锁的指针， 图片来自 Synchronization - Synchronization - OpenJDK Wiki 重量级锁解析上面提到了轻量级锁在自旋失败后，会膨胀为重量级锁，重量级锁是由 ObjectMonitor 对象实现的，每个 Java 对象升级到重量级锁后，Mark Word 内会存储指向 ObjectMonitor 对象的指针。 先看 ObjectMonitor 的主要成员： ObjectMonitor() &#123; _recursions = 0; // 线程重入次数 _owner = NULL; // 指向拥有该 monitor 的线程 _WaitSet = NULL; // 等待线程 双向循环链表_WaitSet 指向第一个节点 _EntryList = NULL ; // _owner 从该双向循环链表中唤醒线程， &#125; _recursions：如果线程 a 已经持有 monitor 锁的情况下，再次加锁，recursions+1（类似 ReentrantLock 的 State 计数器） _owner：初始时为 NULL。当有线程占有该 monitor 时 owner 标记为该线程的 ID。当线程释放 monitor 时 owner 恢复为 NULL。_owner 是一个临界资源 JVM 是通过 CAS 操作来保证其线程安全的（类似 ReentrantLock 的 exclusiveOwnerThread） _EntryList： 竞争队列，因抢锁失败的线程会进入这个队列（类似 ReentratLock 的“同步队列”） _WaitSet: 等待队列，因调用 wait 方法而被阻塞的线程会被放在该队列中（ 类似 Condition 对象的“等待队列”） 【图】 Monitor 模型: 抢锁的线程先进入 EntrySet EntrySet 队列中的线程尝试 acquire() 锁，成功后改写 Owner 为线程自己， 持有锁的线程调用了 wait()，会释放锁并进入 WaitSet WaitSet 中的线程，被其他线程 notify()唤醒后，会尝试 acquire()锁 持有锁的线程释放锁 ↑ 只有 acquire 成功的线程是活动的（深色表示），其他的线程都是等待状态（浅色） ObjectMonitor 的 C++代码实现参考 @ref: synchronized 实现原理 | 小米信息部技术团队 ➤ 回到开头的例子： public class Bank &#123; public synchronized void transfer() &#123; // (1) while(!resource_is_available)&#123; wait(); // (2) &#125; notifyAll(); // (3) &#125;&#125; 执行到（1）进入 sync 代码块，当前线程 A 获得了对象锁； 执行（2）wait 后，线程会释放锁，进入 waitSet 队列，并调用 park 让出 CPU 另一个线程 B 再尝试获取锁，如果成功且调用了 （3）notifyAll，A 线程被唤醒，然后尝试抢锁； 假设有线程 C 尝试获取锁失败，C 线程会 park，然后进入 cxq 队列，当有线程释放锁时，会尝试从 cxq 中删除线程 C 的节点，然后把 C 加入 entrySet，C 再尝试抢锁 需要注意的： 调用 wait 后，线程会放弃锁，其他线程可以尝试抢锁； waitSet 是调用 wait 的线程的队列，cxq 是抢锁失败的线程的队列 notify：先 wait 的线程，先被唤醒； notifyAll：最后 wait 的线程，先被唤醒； wait 可以响应 InterruptedException 异常 @ref： http://lovestblog.cn/blog/2016/03/27/object-wait-notify/ 对象锁的优化-消除&amp;粗化锁粗化：如果在代码中，连续对同一个对象加锁，JIT（不确定）会把这块代码加入到一个同步块中； 锁消除：是虚拟机另外一种锁的优化，这种优化更彻底，Java 虚拟机在 JIT 编译时(可以简单理解为当某段代码即将第一次被执行时进行编译，又称即时编译)，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，通过这种方式消除没有必要的锁，可以节省毫无意义的请求锁时间，如下 StringBuffer 的 append 是一个同步方法，但是在 add 方法中的 StringBuffer 属于一个局部变量，并且不会被其他线程所使用，因此 StringBuffer 不可能存在共享资源竞争的情景，JVM 会自动将其锁消除。 // 参考自 https://blog.csdn.net/javazejian/article/details/72828483public class StringBufferRemoveSync &#123; public void add(String str1, String str2) &#123; //StringBuffer是线程安全,由于sb只会在append方法中使用,不可能被其他线程引用 //因此sb属于不可能共享的资源,JVM会自动消除内部的锁 StringBuffer sb = new StringBuffer(); sb.append(str1).append(str2); &#125; public static void main(String[] args) &#123; StringBufferRemoveSync rmsync = new StringBufferRemoveSync(); for (int i = 0; i &lt; 10000000; i++) &#123; rmsync.add(\"abc\", \"123\"); &#125; &#125;&#125; 需要注意的是，锁操作的 happens-before 规则的关键字是同一把锁。也就意味着，如果编译器能够（通过逃逸分析）证明某把锁仅被同一线程持有，那么它可以移除相应的加锁解锁操作。因此也就不再强制刷新缓存。举个例子，即时编译后的 synchronized (new Object()) {}，可能等同于空操作，而不会强制刷新缓存。","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"https://beefyheisenberg.github.io/tags/Java并发/"}]},{"title":"Java-并发.02.ThreadLocal","slug":"12.Java/Java-并发.02.ThreadLocal","date":"2024-01-24T01:27:52.186Z","updated":"2024-01-24T01:27:52.187Z","comments":true,"path":"12.Java/Java-并发.02.ThreadLocal/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-并发.02.ThreadLocal/","excerpt":"ThreadLocaljava.lang.ThreadLocal&lt;T&gt; 是一个为线程提供线程局部变量的工具类。为线程提供一个线程私有的变量副本，这样多个线程都可以随意更改自己线程局部的变量，不会影响到其他线程。 首次调用threadLocal.get()方法时会调用initialValue()赋一个初始值。 例子: 1.8之前提供的SimpleDateFormat不是线程安全的, 下面的代码用ThreadLocal 解决这个问题: private final static ThreadLocal&lt;DateFormat&gt; threadLocal = new ThreadLocal&lt;DateFormat&gt;() &#123; @Override protected DateFormat initialValue() &#123; return new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); &#125;&#125;;// or 设置当前线程的ThreadLocal 为新的对象// threadLocal.set(new SimpleDateFormat(\"yy-MM-dd\"));// 读取当前线程的ThreadLocal 内保存的对象DateFormat localFormatter = (DateFormat)threadLocal.get();","text":"ThreadLocaljava.lang.ThreadLocal&lt;T&gt; 是一个为线程提供线程局部变量的工具类。为线程提供一个线程私有的变量副本，这样多个线程都可以随意更改自己线程局部的变量，不会影响到其他线程。 首次调用threadLocal.get()方法时会调用initialValue()赋一个初始值。 例子: 1.8之前提供的SimpleDateFormat不是线程安全的, 下面的代码用ThreadLocal 解决这个问题: private final static ThreadLocal&lt;DateFormat&gt; threadLocal = new ThreadLocal&lt;DateFormat&gt;() &#123; @Override protected DateFormat initialValue() &#123; return new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); &#125;&#125;;// or 设置当前线程的ThreadLocal 为新的对象// threadLocal.set(new SimpleDateFormat(\"yy-MM-dd\"));// 读取当前线程的ThreadLocal 内保存的对象DateFormat localFormatter = (DateFormat)threadLocal.get(); 注： JDK1.8的 DateTimeFormatter是线程安全的. 实现我们需要知道 Thread 类中有一个 Map 类型的 threadLocals 成员: public class Thread &#123; ThreadLocal.ThreadLocalMap threadLocals = null;&#125; ThreadLocalMap 该类为一个采用线性探测法实现的 HashMap （区别于 HashMap 的拉链法），这个 HashMap 的 Entry 继承了 WeakReference&lt;ThreadLocal&lt;?&gt;&gt; （类似 WeakHashMap） 调用 threadLocal.set(Val) 设置新对象时。实际是向 thread.ThreadLocalMap 插入对象，创建新的 Entry(K,V)，K 即是 threadLocal 对象，并且从 Entry 的构造函数可以看到， K 是弱引用的，并且没有给弱引用设置一个回收用的 queue，这一点区别 WeakHashMap（Java-Tutorials.13.引用(Reference)），也就是说 threadLocal 并不会像 WeakHashMap 那样自动清理 Key 被回收掉的 Entry // Entry的构造Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); // 调用了WeakReference(k) value = v; &#125;// private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; // We don't use a fast path as with get() because it is at // least as common to use set() to create new entries as // it is to replace existing ones, in which case, a fast // path would fail more often than not. Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); // 开放定址法，i不断向后+1，尝试找到每个 entry for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; // entry继承自 WeakReference，这里调用了 Reference.get()，获取的是Key ThreadLocal&lt;?&gt; k = e.get(); // case1: key相同（即同一个 threadLocal对象 ），覆盖旧value if (k == key) &#123; e.value = value; return; &#125; // case2: 之前 threadLocal的Entry，key已经被GC回收 if (k == null) &#123; // 将新的entry放入 tab[i]， // 并将旧entry.value=null 帮助回收 replaceStaleEntry(key, value, i); // 内部调用了 expungeStaleEntry() return; &#125; &#125; // 在tab[i]没有找到过去的 threadLocal的Entry，新创建一个： tab[i] = new Entry(key, value); int sz = ++size; // 清理槽位失败且Entry数组长度超过阈值，重新rehash对Entry数组扩容 if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash(); &#125; 从 ThreadLocal 中 get 值的时候，首先通过 Thread.currentThread() 得到当前线程，然后拿到这个线程的 ThreadLocalMap，从 Map 取得 Entry，最后从 Entry 取得中的 value 值； ThreadLocal 的 set、get 、remove 方法最终都会调用 expungeStaleEntry()，找到已经被 GC 清理过的 Entry，将 value 置 null 帮助回收； ThreadLocalMap 与 WeakHashMap 的比较： 二者的 Entry 都继承自 WeakReference，对 Key 的处理也都是弱引用； ThreadLocalMap 是开放定址，WeakHashMap 使用了链表 ThreadLocalMap 没有为 Key 的弱引用指定 Queue，WeakHashMap 指定了 Queue，这也导致二者回收方式不同： WeakHashMap： get() put(), size() 时通过 queue 获取被清理的 entry，设置 entry.value = null 帮助回收，@ref Java-Tutorials.13.引用(Reference) ThreadLocalMap：见 expungeStaleEntry() @ref: 一文详解JDK中的ThreadLocal（全网最透彻易懂） - 掘金 应用场景 ThreadLocal 适用方法调用链上参数的透传，但要注意是同线程间，但不适合异步方法调用的场景。对于异步方法调用，想做参数的透传可以采用阿里开源的 TransmittableThreadLocal。权限、日志、事务等框架都可以利用 ThreadLocal 透传重要参数。 使用 ThreadLocal 保存 Connection： public class ConnectionManager &#123; private static final ThreadLocal&lt;Connection&gt; dbConnectionLocal = new ThreadLocal&lt;Connection&gt;() &#123; @Override protected Connection initialValue() &#123; try &#123; return DriverManager.getConnection(\"\", \"\", \"\"); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; return null; &#125; &#125;; public Connection getConnection() &#123; return dbConnectionLocal.get(); &#125;&#125; 需要注意，因为 thread.ThreadLocalMap 的 Entry(k,v)，其 K 是用 WeakReference 引用的，但是上面的代码中，K 是 static final 的强引用，所以每个线程 ThreadLocalMap 里的 Entry.value 都不会回收；上面的例子中 ThreadLocal 对象是 static 的，所以 key 也不会回收； InheritableThreadLocal如果在父线程中创建 ThreadLocal，会发现父线程设置的值在子线程中无法获取，JDK中有InheritableThreadLocal解决此问题。 public class SubThreadUsage &#123; private static ThreadLocal&lt;Integer&gt; threadLocal = new InheritableThreadLocal&lt;Integer&gt;(); public static void main(String[] args) &#123; threadLocal.set(1); // 新启一个线程 new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(\"threadLocal.get() -&gt; \" + threadLocal.get()); &#125; &#125;).start(); &#125;&#125; 实现InheritableThreadLocal 继承了 ThreadLocal，并且数据存放在Thread的 类变量的 inheritableThreadLocals中，变量类型是 ThreadLocal.ThreadLocalMap;在 Thread 构造方法调用的 init() 中，可看见如果 parent.inheritableThreadLocals不为空，则 ThreadLocal.createInheritedMap()拷贝 ThreadLocalMap，注意这里的拷贝是浅拷贝。子线程如果修改了继承自父线程的ThreadLocal，其他的子线程也可能会看到这个改变。 @ref: alibaba/TransmittableThreadLocal","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"https://beefyheisenberg.github.io/tags/Java并发/"}]},{"title":"Java-并发.01.线程基础 & API","slug":"12.Java/Java-并发.01.线程API","date":"2024-01-24T01:27:52.180Z","updated":"2024-01-24T01:27:52.181Z","comments":true,"path":"12.Java/Java-并发.01.线程API/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-并发.01.线程API/","excerpt":"线程6种状态 New, 创建 Thread 实例之后; Runnable, 执行 thread.start() 之后; Blocked, 线程试图获取 ReentrantLock 失败, 或进入 synchronize 代码块, 或调用 Block IO; Waiting, 调用 object.wait() 或 thread.join() 之后; 调用 object.wait(), condition.await() 方法都会产生 WAITING 状态; 调用 thread.join(long millis) 后, 调用者会 Waiting 一直到 thread 线程退出; Time-Waitting, 调用 thread.join(long millis)、thread.sleep(long millis)、或者 Object.wait(long)、lock.tryLock(long) 时; Terminated: 线程的 run() 方法正常退出或者 run() 方法抛出未捕获异常时; 上面的状态来自 Oracle JDK 8 java.lang.Thread.State, 并不等同于 unix 下的原生线程状态,Thread.State (Java Platform SE 8 ) 图-线程6种状态的转换: 线程控制 API","text":"线程6种状态 New, 创建 Thread 实例之后; Runnable, 执行 thread.start() 之后; Blocked, 线程试图获取 ReentrantLock 失败, 或进入 synchronize 代码块, 或调用 Block IO; Waiting, 调用 object.wait() 或 thread.join() 之后; 调用 object.wait(), condition.await() 方法都会产生 WAITING 状态; 调用 thread.join(long millis) 后, 调用者会 Waiting 一直到 thread 线程退出; Time-Waitting, 调用 thread.join(long millis)、thread.sleep(long millis)、或者 Object.wait(long)、lock.tryLock(long) 时; Terminated: 线程的 run() 方法正常退出或者 run() 方法抛出未捕获异常时; 上面的状态来自 Oracle JDK 8 java.lang.Thread.State, 并不等同于 unix 下的原生线程状态,Thread.State (Java Platform SE 8 ) 图-线程6种状态的转换: 线程控制 APIstart // 第一种Runnable接口Thread t = new Thread(new runnable() &#123; public void run() &#123; try&#123; while (true) &#123; Thread.sleep(1000); &#125; &#125; catch (InterruptedException e) &#123; &#125; finally &#123; &#125; &#125;&#125;);// new之后线程处于\"New\"状态t.start(); // start之后线程处于\"Runnable\"状态// 第二种Class MyThread extends Thread &#123; public void run()&#123; // doSomething &#125;&#125;new Mythread().start(); interrupt 调用 t.interrupt() 方法时, 线程 t 会收到中断信号, Java 并没有要求线程一定响应中断. 线程应该根据情况决定是否响应中断, 循环调用 t.isInterrupted() 可以检测线程的中断标志位. 如果线程内调用了 sleep() 或者 wait() 方法让线程进入等待状态, 当调用 t.interrupt(), 线程会抛出 InterruptException, 如果你的线程里调用了可能抛出该异常的阻塞方法, 那么就不必每次调用 isInterrupt() 检测中断状态了, 在 catch 里捕获该异常即可. 如果线程已经被中断的情况下再调用 sleep(), sleep() 方法会清除中断状态并且抛出上述异常, 并不会进入 sleep 状态, 所以线程循环中有 sleep() 的也不必用 isInterrupt 检查中断状态 可抛出中断异常的: 线程内调用 wait(), 或者调用 thread.join() 和 thread.sleep()Thread t = new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; while(!Thread.currentThread().isInterrupted() /* &amp;&amp; */) &#123; Thread.sleep(5000); // 如果有sleep, 上面的isInterrupted不必要 &#125; &#125; catch (InterruptedException e) &#123;&#125; &#125;&#125;);t.start(); // sub-thread now is \"runnnable\"t.interrupt(); // main thread interrupt sub-thread join执行 thread.join() 的线程会进入 waiting 状态, 直到 thread 线程终止或自然退出, 继续执行后面的代码 MyThread thread = new MyThread();thread.start();thread.join(); // 在这里waiting// 上面的thread退出后, 才会进行到这里 sleep执行 thread.sleep(m) 的线程会进入 timed_waitting 状态 m 毫秒(注意, 并没有 sleep 这种状态),Thread.sleep() 与线程调度器交互，它将当前线程设置为等待一段时间的状态。一旦等待时间结束，线程状态就会被改为可运行（runnable），并开始等待 CPU 来执行后续的任务。因此，当前线程的实际休眠时间取决于线程调度器，而线程调度器则是由操作系统来进行管理的。 sleep 和 wait 的区别?比较 thread.sleep(long millis) 和 object.wait(): Thread.sleep() 方法是一个静态方法，作用在当前线程上，线程进入 timed_waiting 状态； obj.wait() 方法是一个实例方法，调用 obj.wait() 的线程，会进入 waiting 状态； sleep() 方法导致了程序暂停执行指定的时间，让出 cpu 该其他线程，但是 cpu 对线程的监控状态依然保持者，当指定的时间到了又会自动恢复 runnable。 线程 A 里调用 obj.wait() 方法的时候，线程 A 进入等待此对象的等待队列，放弃对象锁并进入 waiting 状态，只有针对此对象调用 notify() 方法后, 线程 A 才会从对象锁的等待队列中被取出。 其他不同，主要是锁的状态： 调用 wait() 方法时，线程在等待的时候会释放掉它所获得的 monitor，但是调用 Thread.sleep() 方法时，线程在等待的时候仍然会持有 monitor 或者锁。 Java 中的 wait() 方法应在同步代码块中调用(已经获得了对象锁的情况下, 调用 obj.wait() 会放弃锁) 总结： 如果你需要暂定线程一段特定的时间就使用 sleep() 方法，如果你想要实现线程间通信就使用 wait() 方法。 如何终止线程?几个问题: 被调用了 sleep() 的线程(timed_waiting 状态)可以被 interrupt() 抛出异常吗? 调用了 thread.join() 的线程(waiting 状态)可以被 interrupt() 抛出异常吗? 调用了 object.wait() 的线程(waiting 状态)可以被 interrupt() 抛出异常吗? 调用阻塞 IO 方法被阻塞住的线程可以被 interrupt() 抛出异常吗? 试图抢占锁(synchronized 或 ReentrantLock)但失败的线程(blocked 状态)可以被 interrupt() 抛出异常吗? 答案: 可以, 可以, 可以, 否, 否 只有处于waiting 或 timed_waiting 状态的线程才可以抛出 InterruptException 异常被中断, block 状态的线程不可以; 1）如何终止 waiting 或 timed_waiting 状态的线程呢? 有两种方式: 用 volatile 的标志位控制线程的循环逻辑; thread.interrupt(): 中断当前线程, 线程的循环里应该 try-catch InterruptException 并处理 thread.stop(): 不推荐 2）但是对于进入 blocked 状态的线程, 是无法被 interrupt() 中断的, 所以可能的做法是: 关闭阻塞的资源 class IOBlocked implements Runnable &#123; private InputStream in; public IOBlocked(InputStream is) &#123; in = is; &#125; @Override public void run() &#123; try &#123; in.read(); &#125; catch (IOException e) &#123; &#125; catch (InterruptException e1) &#123; // 事实永远无法到达这, 因为read不抛InterruptException // InterruptException是受检异常 &#125; &#125;&#125;public class HowToInterruptIOBlockedThreads &#123; public static void main(String[] args) throws Exception &#123; // 创建线程池 ExecutorService service = Executors.newCachedThreadPool(); // 打开网络流 ServerSocket server = new ServerSocket(8080); InputStream stream = new Socket(\"localhost\", 8080).getInputStream(); // 执行会导致IO Blocked的线程 service.execute(new IOBlocked(stream)); // 主线程sleep TimeUnit.MILLISECONDS.sleep(100); //尝试停止所有正在执行的任务, shutdownNow会尝试调用所有线程的interrupt service.shutdownNow(); //通过关闭线程操作的资源来释放阻塞的线程 stream.close(); &#125;&#125; 唤醒线程如何唤醒 sleep / wait / blocked 的线程? 对于因调用 object.wait() 进入 waiting 状态的线程，调用 object.signal()； 对于因调用 t.sleep(), t.join() 而进入 timed_waiting 状态的线程, 调用 t.interrupt() 可以线程抛出 InterruptedException 来达到”唤醒”的效果; 对于因为 IO 阻塞而进入的 blocked 状态的线程, 没有办法唤醒; 被弃用的方法Thread 类不再推荐被使用的方法: ~yield,stop,suspend,resume~ yieldyield 方法会临时暂停当前正在执行的线程，来让有同样优先级的正在等待的线程有机会执行。如果没有正在等待的线程，或者所有正在等待的线程的优先级都比较低，那么该线程会继续运行。执行了 yield 方法的线程什么时候会继续运行由线程调度器来决定。yield 方法不保证当前的线程会暂停或者停止，但是可以保证当前线程在调用 yield 方法时会放弃 CPU。 yield()应该做的是让当前运行线程回到 可运行状态(Runnable)，以允许具有相同优先级的其他线程获得运行机会。因此，使用 yield()的目的是让相同优先级的线程之间能适当的轮转执行。但是，实际中无法保证 yield()达到让步目的，因为让步的线程还有可能被线程调度程序再次选中。 stop 该方法天生是不安全的。使用 thread.stop()停止一个线程，导致释放（解锁）所有该线程已经锁定的监视器（因沿堆栈向上传播的未检查 ERROR—— ThreadDeath 而解锁）。 // → 非受检异常如果之前受这些监视器保护的任何对象处于不一致状态，则不一致状态的对象（受损对象）将对其他线程可见，这可能导致任意的行为。ThreadDeath 是 java.lang.Error，不是 java.lang.Exception。不受检异常意味着我们不会有意识在代码里写 Try-Catch 去处理异常, 比如在 finally 里释放锁 上面的意思是:线程当前可能持有一个监视器(或锁)，执行 thread.stop() 将会产生一个 ThreadDeath 错误(是一种不受检 ERROR)，线程向上抛出错误，导致监视器被解锁。可能导致的问题: 以银行转账的例子, 如果在”减扣 A 余额, 增加 B 余额”的过程中, 线程被 stop, 将产生业务数据的不一致. 建议 用 interrupt 替代 stop, 在线程中循环检测 thread.isInterrupted() 或者捕获 InterruptException 然后由业务代码进行收尾处理. ThreadDeath 和 InterruptException 的区别是: 前者不受检, 意味着业务代码没有机会捕获并处理, 会向上层堆栈抛出错误, 线程状态变为 “Terminated”; 后者是受检异常, 可以被捕获并由业务代码处理; suspend &amp; resume 当某个线程的 suspend()方法被调用时，该线程会被挂起。如果该线程占有了锁，则它不会释放锁。线程在挂起的状态下还持有锁，这导致其他线程将不能访问该资源直到目标线程恢复工作。 线程的 resume()方法 会恢复因 suspend() 方法挂起的线程，使之重新能够获得 CPU 执行。 建议使用 object.wait 和 object.notify 方法代替 suspend &amp; resume 线程属性优先级 java 中线程优先级范围 MIN_PRIORITY~MAX_PRIORITY (其值1~10), NORMAL_PRIORITY (其值=5); 线程默认情况下继承父线程的优先级; daemonthread.setDaemon(true);thread.start(); 当 JVM 还存在一个非守护线程, JVM 就不会退出, 当存活的线程仅剩下守护线程时, JVM 才会退出.守护线程最典型的应用就是 GC 异常处理器thread.setUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() &#123; public void uncaughtException(Thread t, Throwable e) &#123; &#125; &#125;);thread.start();","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"https://beefyheisenberg.github.io/tags/Java并发/"}]},{"title":"Java-并发.00.索引","slug":"12.Java/Java-并发.00.Concurrent-Index","date":"2024-01-24T01:27:52.176Z","updated":"2024-01-24T01:27:52.176Z","comments":true,"path":"12.Java/Java-并发.00.Concurrent-Index/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-并发.00.Concurrent-Index/","excerpt":"Index of 「Java 并发 」 线程基础 API ThreadLocal Synchronized Volatile JUC What’s J.U.C ?Java 1.5. 提供了java.util.concurrent包, 该包参考自EDU.oswego.cs.dl.util.concurrent, 是JSR 166标准规范的一个实现.J.U.C 提供了 Java 并发编程的大部分功能，如下： juc-Atomic: 基于 CAS 的无锁原子操作, 包括基本类型/数组/引用/对象 field 四类原子操作 Java-并发.05a.JUC-Atomic&CAS juc-Locks: 可重入锁 ReentrantLock、读写锁 ReadWriteLock、条件对象 Condition 等.. Java-并发.05b.JUC-Lock juc-Collection: 并发容器（集合），包括 ArrayBlockingQueue、ConcurrentHashMap 等.. Java-并发.05d.JUC-Collections juc-Sync：同步器，基于 AQS 模式的 CountDownLatch、Semaphore、CyclicBarrier 等.. Java-并发.05c.JUC-Sync juc-执行器：线程池（ExecutorService）、Fork/Join 框架、Future Java-并发.06a.JUC-线程池","text":"Index of 「Java 并发 」 线程基础 API ThreadLocal Synchronized Volatile JUC What’s J.U.C ?Java 1.5. 提供了java.util.concurrent包, 该包参考自EDU.oswego.cs.dl.util.concurrent, 是JSR 166标准规范的一个实现.J.U.C 提供了 Java 并发编程的大部分功能，如下： juc-Atomic: 基于 CAS 的无锁原子操作, 包括基本类型/数组/引用/对象 field 四类原子操作 Java-并发.05a.JUC-Atomic&CAS juc-Locks: 可重入锁 ReentrantLock、读写锁 ReadWriteLock、条件对象 Condition 等.. Java-并发.05b.JUC-Lock juc-Collection: 并发容器（集合），包括 ArrayBlockingQueue、ConcurrentHashMap 等.. Java-并发.05d.JUC-Collections juc-Sync：同步器，基于 AQS 模式的 CountDownLatch、Semaphore、CyclicBarrier 等.. Java-并发.05c.JUC-Sync juc-执行器：线程池（ExecutorService）、Fork/Join 框架、Future Java-并发.06a.JUC-线程池","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"},{"name":"Java并发","slug":"Java并发","permalink":"https://beefyheisenberg.github.io/tags/Java并发/"}]},{"title":"Java Tutorials-14-代理","slug":"12.Java/Java-Tutorials.14.代理(Proxy)","date":"2024-01-24T01:27:52.172Z","updated":"2024-01-24T01:27:52.172Z","comments":true,"path":"12.Java/Java-Tutorials.14.代理(Proxy)/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-Tutorials.14.代理(Proxy)/","excerpt":"什么是代理模式:用户代码不直接调用某些功能类的方法, 而是通过代调类作为”中间层”去调用”被代理类”. 所有调用都会被代理类拦截, 我们可以利用代理类的这个特性, 在代理类里增加额外的执行代码. 使用代理可以给我们带来如下好处: 用户代码(调用者)和功能类(被调用者)解耦, 第二个好处是通过代理层可以加入一些通用的代码. Java 代理模式的实现主要有: 静态代理, JDK 动态代理, Cglib 动态代理. JDK 动态代理如何使用 JDK 的动态代理:","text":"什么是代理模式:用户代码不直接调用某些功能类的方法, 而是通过代调类作为”中间层”去调用”被代理类”. 所有调用都会被代理类拦截, 我们可以利用代理类的这个特性, 在代理类里增加额外的执行代码. 使用代理可以给我们带来如下好处: 用户代码(调用者)和功能类(被调用者)解耦, 第二个好处是通过代理层可以加入一些通用的代码. Java 代理模式的实现主要有: 静态代理, JDK 动态代理, Cglib 动态代理. JDK 动态代理如何使用 JDK 的动态代理: // 1 接口public interface YourInterface&#123; public void doSomething();&#125;// 2 实际类public class YourClass implements YourInterface&#123; public void doSomething() &#123; &#125;&#125;// 3 代理类:实现java.lang.reflect.InvocationHandler接口 &amp; 重写 invoke()public class YourHandler implements InvocationHandler &#123; private YourInterface target; // 被代理的实例 public YourHandler(YourInterface target)&#123; this.target = target; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; // 在这里可以放一些 @advice 操作 Object result = method.invoke(target, args); return result; &#125;&#125;// 4 创建代理YourInterface obj = new YourClass();InvocationHandler handler = new YourHandler(obj);// newProxyInstance 这一步是把 YourHandler 生成字节码, 并使用ClassLoader 创建YourInterface proxy = (YourInterface)Proxy.newProxyInstance( obj.getClass().getClassLoader(), obj.getClass().getInterfaces(), handler);// 5 通过代理调用proxy.doSomething(); 通过 proxy 调用 YourClass 实现自接口 YourInterface 的所有方法, 都会调用到 YourHandler 的 invoke 方法,在 invoke 方法里可以很方便的做一些前置和后置处理（访问控制、远程通信、日志、缓存等）, 在 invoke 里再通过反射调用实际类 YourClass 的方法. JDK动态代理的优点是, 当 YourInterface 的实现类有很多的时候, 比如有 YourClassA, YourClassB…通过代理调用这些实现类的方法(必须是实现 YourInterface 里的方法), 都会由代理调用到 InvocationHandler.invoke(), 如果用静态代理, 那么代理类(实现了 YourInterface 接口)必须为 YourInterface 的每一个方法都增加单独的代码. 参考: Java 动态代理作用是什么？ - 知乎 @ref 实现原理在调用 Proxy.newProxyInstance() 之后,又调用了 ProxyGenerator.generateProxyClass() 方法生成最终代理类的字节码, 并通过 ClassLoader 把字节码转化成对象.在最终代理类里实现了我们的 Interface 定义的所有方法, 在这些方法内部, 都通过反射调用了 InvocationHandler 接口实现类的 invoke() 方法 包 sun.misc.ProxyGenerator 提供了一个功能, 可以生成 YourInterface 的实现类的字节码:byte[] data = ProxyGenerator.generateProxyClass(name,new Class[]{YourInterface.class}); CGLIB 代理CGLIB 是一个功能强大&amp;高性能的字节码生成包。它为没有实现接口的类提供代理，为 JDK 的动态代理提供了很好的补充。通常可以使用 Java 的动态代理创建代理，但当要代理的类没有实现接口或者为了更好的性能，CGLIB 是一个好的选择。 CGLIB 与 JDK 动态代理不同的是, 使用 CGLIB 即使被代理类没有实现任何接口也可以实现动态代理功能。但是不能对 final 修饰的类进行代理。 JDK 动态代理通过反射类 Proxy 和 InvocationHandler 回调接口实现，要求委托类必须实现一个接口，只能对该类接口中定义的方法实现代理，这在实际编程中有一定的局限性。 CGLIB 包的底层是通过使用一个小而快的字节码处理框架 ASM，来转换字节码并生成新的类。ASM 是一个 Java 字节码操控框架。通过分析被代理类的 class 文件, 在内存中创建被代理类的增强子类, 它能被用来动态生成类或者增强既有类的功能。 ASM 可以直接产生二进制 class 文件，也可以在类被加载入 Java 虚拟机之前动态改变类行为。脚本语言例如 Groovy 和 BeanShell，也是使用 ASM 来生成 java 的字节码。当然不鼓励直接使用 ASM，因为它要求你必须对 JVM 内部结构包括 class 文件的格式和指令集都很熟悉。 下面通过一个例子看看使用 CGLib 如何实现动态代理: 定义业务逻辑: public class UserServiceImpl &#123; public void add() &#123; System.out.println(\"This is add service\"); &#125;&#125; 实现 MethodInterceptor 接口，定义方法的拦截器: public class YourMethodInterceptor implements MethodInterceptor &#123; public Object intercept(Object obj, Method method, Object[] arg, MethodProxy proxy) throws Throwable &#123; System.out.println(\"Before:\" + method); // 自定义前置代码 Object object = proxy.invokeSuper(obj, arg); System.out.println(\"After:\" + method); // 自定义后置代码 return object; &#125;&#125; 利用 Enhancer 类生成 UserServiceImpl 的代理类: Enhancer enhancer = new Enhancer();enhancer.setSuperclass(UserServiceImpl.class);enhancer.setCallback(new YourMethodInterceptor());UserServiceImpl userService = (UserServiceImpl)enhancer.create(); Enhancer 是 CGLib 的字节码增强类, 可以生成类的字节码( 上面的例子里, 生成的是 UserServiceImpl 的子类),其作用类似 sun.misc.ProxyGenerator, 区别是 Enhancer 不需要被代理类实现接口, 而 ProxyGenerator 要求被代理类必须实现接口 以上参考:@ref 说说 cglib 动态代理 Spring AOP 与代理 Spring AOP 中的一些注解 &amp; 概念: @Aspect: PointCut + Advice@PointCut: 切点, 在哪里切入@Advice: 切入的行为(在切点之前还是之后, 或者环绕切点), 以及做什么 Spring AOP 使用的动态代理，所谓的动态代理就是说 AOP 框架不会去修改字节码，而是在内存中临时为方法生成一个AOP 对象，这个 AOP 对象包含了目标对象的全部方法，并且在特定的切点做了增强处理，并回调原对象的方法。Spring AOP 中的动态代理主要有两种方式，JDK 动态代理 和 CGLIB 动态代理。 如果目标类(被切的类)有统一的实现接口，Spring AOP 使用 JDK 动态代理， 如果目标类没有实现接口，那么 Spring AOP 会选择使用 CGLIB 来动态代理目标类。 因此如果某个类被标记为 final，并且没有实现接口，那么它是无法被动态代理的，也就无法当做切点（CutPoint）","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"}]},{"title":"Java Tutorials-13-引用","slug":"12.Java/Java-Tutorials.13.引用(Reference)","date":"2024-01-24T01:27:52.167Z","updated":"2024-01-24T01:27:52.168Z","comments":true,"path":"12.Java/Java-Tutorials.13.引用(Reference)/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-Tutorials.13.引用(Reference)/","excerpt":"4种引用对比 强引用: 只要强引用还在就不会被 GC，JVM 宁愿抛出 OutOfMemoryError 错误也不会回收； 软引用(SoftReference): 用来描述非必需对象, GC 时发现内存不够时（Heap 内存超阈值）将会被回收。当垃圾回收器决定对其回收时，会先清空它的 SoftReference，也就是说 SoftReference 的 get() 方法将会返回 null，然后再调用对象的 finalize() 方法，并在下一轮 GC 中对其真正进行回收。 弱引用(WeakReference): 也是用来描述非需对象的, 无论内存够不够，下次 GC 时一定都被回收, 但对象同时也被强引用持有，则不会回收； 虚引用(PhantomReference): PhantomReference 无法用来获取对象，其 get 方法永远返回 null，为一个对象设置虚引用关联的唯一目的是跟踪对象被垃圾回收的状态，通过查看引用队列中是否包含对象所对应的虚引用来判断它是否即将被垃圾回收，当 PhantomReference 被放入队列时，说明 referent 的 finalize() 方法已经调用，并且垃圾收集器准备回收它的内存了。 FinalReference 以及 Finzlizer：@todo 相较于传统的引用计数算法，Java 使用可达性分析来判断一个对象是否存活。其基本思路是从 GC Root 开始向下搜索，如果对象与 GC Root 之间存在引用链，则对象是可达的。对象的可达性与引用类型密切相关。Java 有5中类型的可达性： 强可达(Strongly Reachable)：如果线程能通过强引用访问到对象，那么这个对象就是强可达的。 软可达(Soft Reachable)：如果一个对象不是强可达的，但是可以通过软引用访问到，那么这个对象就是软可达的 弱可达(Weak Reachable)：如果一个对象不是强可达或者软可达的，但是可以通过弱引用访问到，那么这个对象就是弱可达的。 虚可达(Phantom Reachable)：如果一个对象不是强可达，软可达或者弱可达，并且这个对象已经finalize过了，并且有虚引用指向该对象，那么这个对象就是虚可达的。 不可达(Unreachable)：如果对象不能通过上述的几种方式访问到，则对象是不可达的，可以被回收。 How to Use:","text":"4种引用对比 强引用: 只要强引用还在就不会被 GC，JVM 宁愿抛出 OutOfMemoryError 错误也不会回收； 软引用(SoftReference): 用来描述非必需对象, GC 时发现内存不够时（Heap 内存超阈值）将会被回收。当垃圾回收器决定对其回收时，会先清空它的 SoftReference，也就是说 SoftReference 的 get() 方法将会返回 null，然后再调用对象的 finalize() 方法，并在下一轮 GC 中对其真正进行回收。 弱引用(WeakReference): 也是用来描述非需对象的, 无论内存够不够，下次 GC 时一定都被回收, 但对象同时也被强引用持有，则不会回收； 虚引用(PhantomReference): PhantomReference 无法用来获取对象，其 get 方法永远返回 null，为一个对象设置虚引用关联的唯一目的是跟踪对象被垃圾回收的状态，通过查看引用队列中是否包含对象所对应的虚引用来判断它是否即将被垃圾回收，当 PhantomReference 被放入队列时，说明 referent 的 finalize() 方法已经调用，并且垃圾收集器准备回收它的内存了。 FinalReference 以及 Finzlizer：@todo 相较于传统的引用计数算法，Java 使用可达性分析来判断一个对象是否存活。其基本思路是从 GC Root 开始向下搜索，如果对象与 GC Root 之间存在引用链，则对象是可达的。对象的可达性与引用类型密切相关。Java 有5中类型的可达性： 强可达(Strongly Reachable)：如果线程能通过强引用访问到对象，那么这个对象就是强可达的。 软可达(Soft Reachable)：如果一个对象不是强可达的，但是可以通过软引用访问到，那么这个对象就是软可达的 弱可达(Weak Reachable)：如果一个对象不是强可达或者软可达的，但是可以通过弱引用访问到，那么这个对象就是弱可达的。 虚可达(Phantom Reachable)：如果一个对象不是强可达，软可达或者弱可达，并且这个对象已经finalize过了，并且有虚引用指向该对象，那么这个对象就是虚可达的。 不可达(Unreachable)：如果对象不能通过上述的几种方式访问到，则对象是不可达的，可以被回收。 How to Use: ReferenceQueue&lt;String&gt; queue = new ReferenceQueue&lt;&gt;(); // 对象被回收后, 被放入q里String str = new String(\"hello\");WeakReference&lt;String&gt; softRef = new WeakReference&lt;String&gt;(str, queue); // 这一步后, 有两个引用指向\"Hello\"str = null; // 当String对象只有一个软引用指向它时, 才有可能被回收System.out.print(softRef.get()); // 通过软引用调用对象用get方法// 假设这里因内存不足发生了GC，被回收的软引用会被放入队列queue// 从队列取出第一个:Reference&lt;? extends String&gt; ref = queue.poll();if(ref != null) &#123; // 从队列里取出的ref是个引用地址，非空 if(ref.get() != null) &#123; // 对ref再次get，肯定返回null &#125;&#125; 从 Soft、Weak、Phantom 三种引用的共同特点来看，都可以设置一个 ReferenceQueue，在 ref 关联的对象被回收时，ref 被放入 ReferenceQueue 中； 那么这个机制是如何实现的呢？ ReferenceQueue 的工作机制class Reference &#123; private T referent; // reference被回收后，当前 Reference实例会被添加到这个队列中 volatile ReferenceQueue&lt;? super T&gt; queue; // 全局唯一的 pending-Reference 列表 private static Reference&lt;Object&gt; pending = null; ReferenceHandler &#123; public void run() &#123; // 平时在 pending-Reference 上wait // CG收集器 把引用放入 pending-Reference后，此线程开始工作： &#125; &#125; static &#123; // Reference 的static 代码中，创建 ReferenceHandler 线程： Thread handler = new ReferenceHandler(); &#125;&#125; Reference 其引用的对象被回收后，垃圾回收器将其加入到 Reference.pending 链表（所有的 Reference 共享一个链表） Reference 类还包含一个 ReferenceHandler 线程（在 Reference 类的 static 代码中创建，同样是所有的 Reference 共享一个），此线程的从 pending-Reference 取出引用对象，将其加入它的 ReferenceQueue 用户的代码里读取 ReferenceQueue，自行处理 /* High-priority thread to enqueue pending References */ private static class ReferenceHandler extends Thread &#123; private static void ensureClassInitialized(Class&lt;?&gt; clazz) &#123; try &#123; Class.forName(clazz.getName(), true, clazz.getClassLoader()); &#125; catch (ClassNotFoundException e) &#123; throw (Error) new NoClassDefFoundError(e.getMessage()).initCause(e); &#125; &#125; static &#123; // pre-load and initialize InterruptedException and Cleaner classes // so that we don't get into trouble later in the run loop if there's // memory shortage while loading/initializing them lazily. ensureClassInitialized(InterruptedException.class); ensureClassInitialized(Cleaner.class); &#125; ReferenceHandler(ThreadGroup g, String name) &#123; super(g, name); &#125; public void run() &#123; while (true) &#123; tryHandlePending(true); &#125; &#125; &#125; /** * Try handle pending &#123;@link Reference&#125; if there is one.&lt;p&gt; * Return &#123;@code true&#125; as a hint that there might be another * &#123;@link Reference&#125; pending or &#123;@code false&#125; when there are no more pending * &#123;@link Reference&#125;s at the moment and the program can do some other * useful work instead of looping. * * @param waitForNotify if &#123;@code true&#125; and there was no pending * &#123;@link Reference&#125;, wait until notified from VM * or interrupted; if &#123;@code false&#125;, return immediately * when there is no pending &#123;@link Reference&#125;. * @return &#123;@code true&#125; if there was a &#123;@link Reference&#125; pending and it * was processed, or we waited for notification and either got it * or thread was interrupted before being notified; * &#123;@code false&#125; otherwise. */ static boolean tryHandlePending(boolean waitForNotify) &#123; Reference&lt;Object&gt; r; Cleaner c; try &#123; synchronized (lock) &#123; if (pending != null) &#123; r = pending; // 'instanceof' might throw OutOfMemoryError sometimes // so do this before un-linking 'r' from the 'pending' chain... c = r instanceof Cleaner ? (Cleaner) r : null; // unlink 'r' from 'pending' chain pending = r.discovered; r.discovered = null; &#125; else &#123; // The waiting on the lock may cause an OutOfMemoryError // because it may try to allocate exception objects. if (waitForNotify) &#123; lock.wait(); &#125; // retry if waited return waitForNotify; &#125; &#125; &#125; catch (OutOfMemoryError x) &#123; // Give other threads CPU time so they hopefully drop some live references // and GC reclaims some space. // Also prevent CPU intensive spinning in case 'r instanceof Cleaner' above // persistently throws OOME for some time... Thread.yield(); // retry return true; &#125; catch (InterruptedException x) &#123; // retry return true; &#125; // Fast path for cleaners if (c != null) &#123; c.clean(); return true; &#125; ReferenceQueue&lt;? super Object&gt; q = r.queue; if (q != ReferenceQueue.NULL) q.enqueue(r); return true; &#125; static &#123; ThreadGroup tg = Thread.currentThread().getThreadGroup(); for (ThreadGroup tgn = tg; tgn != null; tg = tgn, tgn = tg.getParent()); Thread handler = new ReferenceHandler(tg, \"Reference Handler\"); /* If there were a special system-only priority greater than * MAX_PRIORITY, it would be used here */ handler.setPriority(Thread.MAX_PRIORITY); handler.setDaemon(true); handler.start(); // provide access in SharedSecrets SharedSecrets.setJavaLangRefAccess(new JavaLangRefAccess() &#123; @Override public boolean tryHandlePendingReference() &#123; return tryHandlePending(false); &#125; &#125;); &#125; WeakHashMapWeakHashMap 的特点： WeakHashMap 会“被动的”清理放入 Map 的 Entry，适用于程序内缓存的场景； WeakHashMap.Entry ，出了继承 Map.Entry&lt;K,V&gt;，还继承了 WeakReference ； How to Use: protected static void weakHashMapTest() &#123; Map&lt;COREJBasicType, String&gt; map = new WeakHashMap&lt;&gt;(); COREJBasicType key1 = new COREJBasicType(); COREJBasicType key2 = new COREJBasicType(); map.put(key1, new String(\"hello\")); map.put(key2, new String(\"world\")); System.gc(); for (Map.Entry&lt;COREJBasicType, String&gt; entry : map.entrySet()) &#123; System.out.println(entry.getKey() + \" \" + entry.getValue()); &#125; key1 = null; // 帮助回收 System.gc(); for (Map.Entry&lt;COREJBasicType, String&gt; entry : map.entrySet()) &#123; System.out.println(entry.getKey() + \" \" + entry.getValue()); &#125;&#125; 第一次 gc 后，两个 Entry 都可以获取到，第二次 gc 后，遍历 WeakHashMap 只有 K2的 Entry 了； WeakHashMap 自动回收的特性可以作为缓存来用, 例如 tomcat 的 ConcurrentCache。 WeakHashMap 源码解析WeakHashMap 的主要属性: public class WeakHashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt; &#123; // 桶数组 Entry&lt;K,V&gt;[] table; // 回收队列 private final ReferenceQueue&lt;Object&gt; queue = new ReferenceQueue&lt;&gt;(); &#125; put（k，val）：过程与 HashMap 类似，但需要注意的是 WeakHashMap.Entry: WeakHashMap 的桶数组定义是： Entry&lt;K,V&gt;[] table WeakHashMap.Entry 继承自 WeakReference； WeakHashMap.Entry 的成员只有 value，没有 key（也就意味着 Entry 对象不会对 key 有强引用）； put 方法传入的 key，被转换为了一个弱引用，同时该弱引用关联 WeakHashMap.queue ： Entry(Object key, V value, ReferenceQueue&lt;Object&gt; queue, int hash, Entry&lt;K,V&gt; next) &#123; super(key, queue); // super() 即 WeakReference(req,queue) this.value = value; this.hash = hash; this.next = next;&#125; 当把一个 Entry put 后，再分析一下对象的可达性： 如果 weakHashMap 是强可达的，那么 entry 对象也是强可达； value 对象被 entry.value 引用，强可达； key 对象只有一个弱引用关联（弱可达），所以会被 GC 掉，同时 GC 线程把 Key 关联的弱引用，放入 WeakHashMap 对象的 queue； 那么WeakHashMap 是如何回收 value 的? 在 get() put(), size() 方法里都会先调用一个 expungeStaleEntries() 方法,此方法遍历 ReferenceQueue 取出每个弱引用（因为 Entry 继承自 WeakReference），把 Entry.val 设置为 null 帮助回收： private void expungeStaleEntries() &#123; for (Object x; (x = queue.poll()) != null; ) &#123; synchronized (queue) &#123; @SuppressWarnings(\"unchecked\") Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;) x; // （1）convert Key to Entry？ int i = indexFor(e.hash, table.length); Entry&lt;K,V&gt; prev = table[i]; Entry&lt;K,V&gt; p = prev; while (p != null) &#123; Entry&lt;K,V&gt; next = p.next; if (p == e) &#123; if (prev == e) table[i] = next; else prev.next = next; // Must not null out e.next; // stale entries may be in use by a HashIterator e.value = null; //（2） Help GC size--; break; &#125; prev = p; p = next; &#125; &#125; &#125; &#125; 代码（2）处把 Entry.value 设置为 null 帮助回收 @doubt: Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;) x ，x 是从 queue 里取出的，也即 Reference 类型，是如何转换为 Entry 类型的？ @ref: 浅谈WeakHashMap - CarpenterLee - 博客园 JDK 源码阅读 Reference WeakHashMap中关于queue的疑惑 ？ - 知乎","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"}]},{"title":"Java Tutorials-12-新特性（Java8~12）","slug":"12.Java/Java-Tutorials.12.新特性","date":"2024-01-24T01:27:52.162Z","updated":"2024-01-24T01:27:52.163Z","comments":true,"path":"12.Java/Java-Tutorials.12.新特性/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-Tutorials.12.新特性/","excerpt":"Java 8Lambda “Lambda 表达式”(lambda expression)是一个匿名函数，Lambda表达式基于数学中的λ演算得名，直接对应于其中的lambda抽象(lambda abstraction)，是一个匿名函数，即没有函数名的函数。Lambda表达式可以表示闭包（注意和数学传统意义上的不同）。闭包的概念: 可以把闭包简单理解成”定义在一个函数内部的函数体”，并且在内部函数体中能访问在外部函数中定义的变量 lambda的语法为: expression = (variable) -&gt; action, 例如 Runnable r = () -&gt; { log.info&quot;HelloWorld&quot;;} int sum = (x,y) -&gt; x+y; 等号的右边即是一个lambda表达式","text":"Java 8Lambda “Lambda 表达式”(lambda expression)是一个匿名函数，Lambda表达式基于数学中的λ演算得名，直接对应于其中的lambda抽象(lambda abstraction)，是一个匿名函数，即没有函数名的函数。Lambda表达式可以表示闭包（注意和数学传统意义上的不同）。闭包的概念: 可以把闭包简单理解成”定义在一个函数内部的函数体”，并且在内部函数体中能访问在外部函数中定义的变量 lambda的语法为: expression = (variable) -&gt; action, 例如 Runnable r = () -&gt; { log.info&quot;HelloWorld&quot;;} int sum = (x,y) -&gt; x+y; 等号的右边即是一个lambda表达式 Lambda表达式要点总结 lambda表达式可以用于以下几个情况: 有单个抽象方法的类, 比如一个方法接收Runnable、Comparable或者 Callable 接口，都有单个抽象方法，可以传入lambda表达式; 使用了 @FunctionalInterface 注释的函数式接口，比如java.util.function包下面的Predicate、Function、Consumer 或 Supplier, BinaryOperator 例如ArrayList的forEach(Consumer&lt;E&gt; action)方法的形参是Consumer类型, 可以接受一个lambda表达式做实参; 例如Collection的stream()返回一个Stream, Stream类的filter(), map() 的形参分别是Predicate和Function; lambda表达式内可以使用方法引用，仅当该方法不修改lambda表达式提供的参数。例如list.forEach(System.out::println) Lambda表达式在Java中又称为闭包或匿名函数 Lambda方法在编译器内部被翻译成私有方法，并派发 invokedynamic 字节码指令来进行调用。使用 javap -p 或 javap -c -v 命令来看一看lambda表达式生成的字节码。大致应该长这样： private static java.lang.Object lambda$0(java.lang.String); lambda内部可以使用静态、非静态和局部变量，这称为lambda内的变量捕获。 lambda表达式有个限制，那就是只能引用 final 或 final 局部变量，这就是说不能在lambda内部修改定义在域外的变量，\b读取是可以的但不能修改。int factor = 2;primes.forEach(element -&gt; &#123; System.out.println(factor*element); &#125;); 创建匿名类例1: new Thread(new Runnable() &#123; @Override public void run() &#123; ... &#125; &#125;).start();// Lambda写法:new Thread( () -&gt; System.out.println(\"Lambda thread\")).start(); 例2: 你们最讨厌的Comparator接口 Comparator&lt;Score&gt; byName = new Comparator&lt;Score&gt;() &#123; @Override public int compare(Score o1, Score o2) &#123; return o1.getName().compareTo(o2.getName()); &#125;&#125;;Collections.sort(list, byName);// Lambda写法:Comparator&lt;Score&gt; byName = (Score o1, Score o2) -&gt; o1.getName().compareTo(o2.getName()); 表达式迭代 forEachList list = Arrays.asList(\"Lambdas\", \"Default Method\", \"Stream API\", \"Date and Time API\");list.forEach((e) -&gt; System.out.println(e));// 或者使用Java 8的方法引用:list.forEach(System.out::println); map() &amp; reduce()// 为每个订单的价格加上12$的税, 并求和List costBeforeTax = Arrays.asList(100, 200, 300, 400, 500);double bill = costBeforeTax.stream().map((cost) -&gt; cost + 0.12*cost).reduce((sum, cost) -&gt; sum + cost).get();System.out.println(\"Total : \" + bill); 函数式接口什么是函数式接口？ 简单说就是只拥有一个抽象方法的接口，如Runnable Function功能型函数式接口类 java.util.function.Function&lt;T,R&gt; 相当于仅含有一个方法的接口类, 这个方法接收一个参数T, 返回类型R.在Java8中, 这种接口类可以用一个lambda表达式来表示.Function只有一个方法apply, 该方法接收一个参数并返回一个值: Function&lt;Integer, Integer&gt; func = x -&gt; x*2;Integer ii = func.apply(100); 除了👆上面这种形式, 在Java8中还增加了::, 称为”方法引用操作符”, 对象::方法将返回一个函数接口（function interface），我们可以使用它来引用类的方法. 例如: class MyMath&#123; public double square(double num)&#123; return Math.pow(num , 2); &#125;&#125;MyMath myMath = new MyMath();Function&lt;Double, Double&gt; square = myMath::square; // 声明一个函数式接口实例, 相当于把square方法抽取出来, 增加给这个实例double ans = square.apply(23.0); 注意被::引用的方法需要符合“函数式接口” （一个输入参数一个返回值） Predicate断言型函数式接口类 java.util.function.Predicate&lt;T&gt; 相当于一个”接收一个输入参数T, 返回boolean的lambda表达式”类型 : Predicate&lt;Integer&gt; pred = x -&gt; x&gt;5;boolean ret = pred.test(); 使用::方法引用操作符: Set&lt;String&gt; set = new HashSet&lt;&gt;();set.addAll(Arrays.asList(\"one\",\"two\",\"three\"));Predicate&lt;String&gt; pred = set::contains;boolean exists = pred.test(\"one\"); Predicate.test()的更多例子: List languages = Arrays.asList(\"Java\", \"Scala\", \"C++\", \"Haskell\", \"Lisp\");filter(languages, (str)-&gt;str.startsWith(\"J\"));filter(languages, (str)-&gt;str.endsWith(\"a\"));filter(languages, (str)-&gt;true);filter(languages, (str)-&gt;false);filter(languages, (str)-&gt;str.length() &gt; 4);public static void filter(List names, Predicate predicate) &#123; for(String name: names) &#123; if(predicate.test(name)) &#123; System.out.println(name + \" \"); &#125; &#125;&#125; Predicate.and(), or(), xor()的例子: List languages = Arrays.asList(\"Java\", \"Scala\", \"C++\", \"Haskell\", \"Lisp\");Predicate&lt;String&gt; startsWithJ = (n) -&gt; n.startsWith(\"J\");Predicate&lt;String&gt; fourLetterLong = (n) -&gt; n.length() == 4;languages.stream() .filter(startsWithJ.and(fourLetterLong)) .forEach((n) -&gt; System.out.print(\"nName, which starts with 'J' and four letter long is : \" + n)); Consumer消费型函数式接口@todo Supplier供给型函数式接口@todo Stream APIstream并不是某种数据结构，它只是数据源的一种视图。这里的数据源可以是一个数组，Java容器或I/O channel等。正因如此要得到一个stream通常不会手动创建，而是调用对应的工具方法，比如： 调用Collection.stream()或者Collection.parallelStream()方法 调用Arrays.stream(T[] array)方法 Map类容器无法直接用stream(), 但可以使用map.entrySet().stream()获得流 常见的stream接口继承关系如图： 流(Stream)的特性大部分情况下Stream是容器调用Collection.stream()方法得到的，但Stream和Collections有以下不同： 无存储。stream不是一种数据结构，它只是某种数据源的一个视图，数据源可以是一个数组，Java容器或I/O channel等。 为函数式编程而生。对stream的任何修改都不会修改背后的数据源，比如对stream执行过滤操作并不会删除被过滤的元素，而是会产生一个不包含被过滤元素的新stream。 惰式执行。stream上的操作并不会立即执行，只有等到用户真正需要结果的时候才会执行。 可消费性。stream只能被“消费”一次，一旦遍历过就会失效，就像容器的迭代器那样，想要再次遍历必须重新生成。 中间操作 &amp; 结束操作对stream的操作分为为两类，中间操作(intermediate operations)和结束操作(terminal operations)，二者特点是： 中间操作总是会惰式执行，调用中间操作只会生成一个标记了该操作的新stream，仅此而已。 结束操作会触发实际计算，计算发生时会把所有中间操作积攒的操作以pipeline的方式执行，这样可以减少迭代次数。计算完成之后stream就会失效。 下表汇总了Stream接口的部分常见方法: operator function 中间操作 concat() distinct() filter() flatMap() limit() map() peek() skip() sorted() parallel() sequential() unordered() 结束操作 allMatch() anyMatch() collect() count() findAny() findFirst() forEach() forEachOrdered() max() min() noneMatch() reduce() toArray() 中间操作filterfilter(): 函数原型为Stream&lt;T&gt; filter(Predicate&lt;? super T&gt; predicate)，作用是返回一个只包含满足predicate条件元素的Stream。 predicate 可以看成是返回boolean的lambda表达式 下面例子中, filter方法接收一个predicate类型的参数: // 保留长度等于3的字符串Stream&lt;String&gt; stream = Stream.of(\"Java\", \"Scala\", \"C++\", \"Haskell\", \"Lisp\");stream.filter(str -&gt; str.length()==3) .forEach(str -&gt; System.out.println(str)); 下面例子中, filter接收的参数是list2::contains， 被引用的方法（这里的contain方法）需符合“predicate”原型： // 求list1和list2的交集List&lt;T&gt; intersect = list1.stream() .filter(list2::contains) .collect(Collectors.toList()); distinctdistinct(): 函数原型为Stream&lt;T&gt; distinct()，作用是返回一个去除重复元素之后的Stream。 stream.distinct() .forEach(str -&gt; System.out.println(str)); limit &amp; skiplimit(n)/skip(n): limit 返回 Stream 的前面 n 个元素；skip 则是扔掉前 n 个元素 sortsorted(): 排序函数有两个，一个是用自然顺序排序，一个是使用自定义比较器排序，函数原型分别为Stream&lt;T&gt; sorted()和Stream&lt;T&gt; sorted(Comparator&lt;? super T&gt; comparator)。 stream().sorted((x, y) -&gt; x-y ).collect(Collectors.toList());// 使用 Map::Entry.comparingByValue和Comparator提供的方法:unsortedMap.entrySet().stream().sorted(Map.Entry.comparingByValue(Comparator.reverseOrder())) mapmap(): 对当前Stream所有元素执行mapper操作, 返回新的Stream stream.map(str -&gt; str.toUpperCase()) .forEach(str -&gt; System.out.println(str)); flatMapflatMap(): “摊平” // 把List&lt;Int&gt; 摊平成 IntStream&lt;List&lt;Integer&gt;&gt; stream = Stream.of(Arrays.asList(1,2), Arrays.asList(3, 4, 5));stream.flatMap(list -&gt; list.stream()) .forEach(i -&gt; System.out.println(i)); 结束操作结束操作包括collect, reduce, forEach等, 分别用于聚合和遍历. forEachforEach是结束操作, 会立刻执行, 执行结束后Stream失效.方法定义为void forEach(Consumer&lt;? super E&gt; action)，作用是对容器中的每个元素执行action指定的动作，也就是对元素进行遍历。通常我们在使用forEach时, 也会用来做合并操作。 使用Stream.forEach()迭代 Stream&lt;String&gt; stream = Stream.of(\"Java\", \"Scala\", \"C++\", \"Haskell\", \"Lisp\");stream.forEach(str -&gt; System.out.println(str)); 在forEach中进行合并: // Combine map1 and map2// Map.merge()用于相同k的合并Map&lt;String,Integer&gt; mergedMap = new HashMap(map1);map2.forEach((k,v) -&gt; mergedMap.merge(k,v, Integer::Sum)); reduce()规约操作（reduction operation）又被称作折叠操作（fold），是通过某个连接动作将所有元素汇总成一个汇总结果的过程。元素求和、求最大值或最小值、求出元素总个数、将所有元素转换成一个列表或集合，都属于规约操作。Stream类库有两个通用的规约操作reduce()和collect()，也有一些为简化书写而设计的专用规约操作，比如sum()、max()、min()、count()等。其原型为：Optional&lt;T&gt; reduce(BinaryOperator&lt;T&gt; accumulator) reduce()最常用的场景就是从一组值中生成一个值，reduce()的方法定义有三种重写形式： Optional&lt;T&gt; reduce(BinaryOperator&lt;T&gt; accumulator): 返回的类型Optional表示（一个）值的容器，使用它可以避免null值的麻烦。 // 找出最长的单词Optional&lt;String&gt; longest = stream.reduce((s1, s2) -&gt; s1.length()&gt;=s2.length() ? s1 : s2);System.out.println(longest.get()); T reduce(T identity, BinaryOperator&lt;T&gt; accumulator): int[] array = &#123;23,43,56,97,32&#125;;// 求所有元素的和:Integer sum = Arrays.stream(array).reduce(0, (a, b) -&gt; a+b);// 等价于:Integer sum = Arrays.stream(array).reduce(0, Integer::sum); &lt;U&gt; U reduce(U identity, BiFunction&lt;U,? super T,U&gt; accumulator, BinaryOperator&lt;U&gt; combiner):它提供一个起始值（种子），然后依照运算规则（BinaryOperator），和前面 Stream 的第一个、第二个、第 n 个元素组合。 // 求单词长度之和Stream&lt;String&gt; stream = Stream.of(\"Java\", \"Scala\", \"C++\", \"Haskell\", \"Lisp\");Integer lengthSum = stream.reduce(0, // 初始值 (sum, str) -&gt; sum+str.length(), // 累加器 (a, b) -&gt; a+b); // 部分和拼接器，并行执行时才会用到 更多reduce()的例子: // 求最小值， 有起始值double minValue = Stream.of(-1.5, 1.0, -3.0, -2.0).reduce(Double.MAX_VALUE, Double::min);// 求和，sumValue = 10, 有起始值int sumValue = Stream.of(1, 2, 3, 4).reduce(0, Integer::sum);// 求和，sumValue = 10, 无起始值int sumValue = Stream.of(1, 2, 3, 4).reduce(Integer::sum).get();// 字符串连接，有起始值, concat = \"ABCD\"String concat = Stream.of(\"A\", \"B\", \"C\", \"D\").reduce(\"\", String::concat);// 字符串连接，有起始值, 有filter操作, concat = \"ace\"String concat = Stream.of(\"a\", \"B\", \"c\", \"D\", \"e\", \"F\").filter(x -&gt; x.compareTo(\"Z\") &gt; 0).reduce(\"\", String::concat); collect()Stream.collect()方法和类Collectors一起使用, 常用于把一个Stream的结果收集进容器里,考虑一下将一个Stream转换成一个容器（或者Map）需要做哪些工作？我们至少需要两样东西： 目标容器是什么？是ArrayList还是HashSet，或者是个TreeMap。 新元素如何添加到容器中？是List.add()还是Map.put()。 如果并行的进行规约，还需要告诉collect() 多个部分结果如何合并成一个。 结合以上分析，collect()方法定义为 &lt;R&gt; R collect(Supplier&lt;R&gt; supplier, BiConsumer&lt;R, ? super T&gt; accumulator, BiConsumer&lt;R, R&gt; combiner); 三个参数依次对应上述三条分析。不过每次调用collect()都要传入这三个参数太麻烦，收集器Collectors就是对这三个参数的简单封装,所以collect()的另一定义为&lt;R,A&gt; R collect(Collector&lt;? super T,A,R&gt; collector)。 一些例子: 将Stream规约成List Stream&lt;String&gt; stream = Stream.of(\"Java\", \"Scala\", \"C++\", \"Haskell\", \"Lisp\");List&lt;String&gt; list = stream.collect(ArrayList::new, ArrayList::add, ArrayList::addAll);// 方式１List&lt;String&gt; list = stream.collect(Collectors.toList());// 方式2System.out.println(list); 将Stream转换成List 或Set Stream&lt;String&gt; stream = Stream.of(\"Java\", \"Scala\", \"C++\", \"Haskell\", \"Lisp\");List&lt;String&gt; list = stream.collect(Collectors.toList());Set&lt;String&gt; set = stream.collect(Collectors.toSet()); Stream转换成map &amp; map排序: // Stream转换成map:// Function.identity()返回一个输出跟输入一样的Lambda表达式对象，等价于形如t -&gt; t形式的Lambda表达式。Map&lt;Integer, String&gt; map = stream.collect(Collectors.toMap(Function.identity(), String::length));// map排序 &amp; 取TopN:// 对Entry的流进行排序, 然后生成有序的LinkedHashMap:Map&lt;String ,Long&gt; sortedMap = unsortedMap.entrySet().stream() .sorted(Map.Entry.comparingByValue(Comparator.reverseOrder())) .limit(topN) .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue, (oldValue, newValue) -&gt; oldValue, LinkedHashMap::new)); 合并Map1, Map2 Map&lt;String, Integer&gt; mx = Stream.of(m1, m2) .map(Map::entrySet) // converts each map into an entry set .flatMap(Collection::stream) // converts each set into an entry stream, then // \"concatenates\" it in place of the original set .collect( Collectors.toMap( // collects into a map Map.Entry::getKey, // where each entry is based Map.Entry::getValue, // on the entries in the stream Integer::max // such that if a value already exist for // a given key, the max of the old // and new value is taken ) ); 拼接字符串 Stream&lt;String&gt; stream = Stream.of(\"Java\", \"Scala\", \"C++\", \"Haskell\", \"Lisp\");String mergedString = stream.filter(string -&gt; !string.isEmpty()).collect(Collectors.joining(\", \")); 上述代码能够满足大部分需求，但由于返回结果是接口类型，我们并不知道类库实际选择的容器类型是什么，有时候我们可能会想要人为指定容器的实际类型，这个需求可通过Collectors.toCollection(Supplier&lt;C&gt; collectionFactory)方法完成。 // 使用toCollection()指定规约容器的类型ArrayList&lt;String&gt; arrayList = stream.collect(Collectors.toCollection(ArrayList::new));// (3)HashSet&lt;String&gt; hashSet = stream.collect(Collectors.toCollection(HashSet::new));// (4) Stream的底层实现 stream(): Stream只是一个接口，并没有操作的缺省实现。最主要的实现是ReferencePipeline,而它的一些具体实现又是由AbstractPipeline完成的 parrallelStream(): 底层使用的是ForkJoinPool, 比较适合使用计算密集型并且没有I/O的任务 新的Data &amp; Time@ref: Java 8 新特性概述 Java 9@ref: Java 9 新特性概述 Java 10@ref: Java 10 新特性介绍","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"}]},{"title":"Java Tutorials-11-安全和加密","slug":"12.Java/Java-Tutorials.11.安全和加密(security&crypto)","date":"2024-01-24T01:27:52.158Z","updated":"2024-01-24T01:27:52.158Z","comments":true,"path":"12.Java/Java-Tutorials.11.安全和加密(security&crypto)/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-Tutorials.11.安全和加密(security&crypto)/","excerpt":"java.security 包提供了消息摘要/消息签名等算法. 将长度不固定的消息（message)作为输入参数，运行特定的Hash函数，生成固定长度的输出，这个输出就是Hash，也称为这个消息的消息摘要（Message Digest）消息签名可以看成是在密钥加密的基础上的消息摘要, 消息摘要和消息签名的作用: 数据完整性检查 数据校验, 是否在传递过程中被篡改 消息摘要(Message Digest)有如下几种消息摘要:","text":"java.security 包提供了消息摘要/消息签名等算法. 将长度不固定的消息（message)作为输入参数，运行特定的Hash函数，生成固定长度的输出，这个输出就是Hash，也称为这个消息的消息摘要（Message Digest）消息签名可以看成是在密钥加密的基础上的消息摘要, 消息摘要和消息签名的作用: 数据完整性检查 数据校验, 是否在传递过程中被篡改 消息摘要(Message Digest)有如下几种消息摘要: MD5, 任何消息都压缩为16字节(128位)的摘要(指纹), @Quection: 不推荐使用 MD5的原因是? SHA1(属于SHA一代), 任何消息都压缩为20字节(160位)的摘要, 所以SHA-1共有最多2^120个摘要; SHA256(属于SHA二代), 32字节(256位); SHA512 MAC(或者HMAC算法), 在散列基础上增加了密钥; BCrypt: 根据Blowfish加密算法所设计的密码散列函数 // MD5 &amp; SHA// 位于 java.securityMessageDigest alg = MessageDigest.getInstance(\"SHA-1\"); // 也可以是MD5byte[] bytes = new byte[10]; // bytes存入要计算摘要的信息byte[] hash = alg.digest(bytes);// HMAC// 位于 javax.cypto.*KeyGenerator keyGenerator = KeyGenerator.getInstance(\"HmacMD5\"); //初始化密钥生成器SecretKey secretKey = keyGenerator.generateKey(); //产生密钥byte[] encoded = secretKey.getEncoded(); //获取密钥SecretKey restoreSecretKey = new SecretKeySpec(encoded, \"HmacMD5\"); //还原密钥Mac mac = Mac.getInstance(restoreSecretKey.getAlgorithm()); //实例化MACmac.init(restoreSecretKey); //初始化MACbyte[] hmacmd5Bytes = mac.doFinal(src.getBytes()); //执行摘要计算 消息签名(Message Signature) DSA(数字签名)/RSA(公钥/私钥), 例如DSA是利用了对数值巨大的数字进行因数分解的困难性. 对称加密 DES AES取代DES Blowfish: 对称密钥区块加密算法 /***** JDK提供的 DES, 位于 java.security *****/KeyGenerator keyGenerator = KeyGenerator.getInstance(\"DES\");keyGenerator.init(56);//设置长度SecretKey secretKey = keyGenerator.generateKey();byte[] keyBytes = secretKey.getEncoded();//key转换, javax.cypto.*DESKeySpec desKeySpec = new DESKeySpec(keyBytes);SecretKeyFactory secretKeyFactory = SecretKeyFactory.getInstance(\"DES\");SecretKey generateSecret = secretKeyFactory.generateSecret(desKeySpec);//加密, javax.cypto.*Cipher cipher = Cipher.getInstance(\"DES/ECB/PKCS5Padding\");cipher.init(Cipher.ENCRYPT_MODE, generateSecret);byte[] result = cipher.doFinal(src.getBytes());System.out.println(Hex.encodeHexString(result));//解密cipher.init(Cipher.DECRYPT_MODE,generateSecret);//使用同一个keyresult = cipher.doFinal(result);System.out.println(new String(result)); blowfish &amp; bcryptEncryption with BlowFish in Java - Stack Overflow // blowfishString Key = \"Something\";byte[] KeyData = Key.getBytes();SecretKeySpec KS = new SecretKeySpec(KeyData, \"Blowfish\");// 加密Cipher cipher = Cipher.getInstance(\"Blowfish\");cipher.init(Cipher.ENCRYPT_MODE, KS);byte[] encryptedData = cipher.doFinal(toEncryptString.getBytes());// 解密Cipher cipher2 = Cipher.getInstance(\"Blowfish\");cipher2.init(Cipher.DECRYPT_MODE, KS);byte[] decryptedData = cipher2.doFinal(encryptedData.getBytes()); BCrypt是基于Blowfish加密算法所设计的密码散列函数, 代码jBCrypt - strong password hashing for Java // bcryptString password = \"testpassword\";String hashed = BCrypt.hashpw(password, BCrypt.gensalt(12)); // 2的12次方// 返回的hashed 字符串包括盐// $2a$10$vI8aWBnW3fID.ZQ4/zo1G.q1lRps.9cGLcZEiGDMVr5yUP1KUOYTa// 2a identifies the bcrypt algorithm version that was used.// 10 is the cost factor; 2^10// 验证if (BCrypt.checkpw(candidate, hashed)) &#123;&#125; 非对称加密 RSA: @todo","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"}]},{"title":"Java Tutorials-10-注解","slug":"12.Java/Java-Tutorials.10.注解(Annotation)","date":"2024-01-24T01:27:52.154Z","updated":"2024-01-24T01:27:52.154Z","comments":true,"path":"12.Java/Java-Tutorials.10.注解(Annotation)/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-Tutorials.10.注解(Annotation)/","excerpt":"使用注解// Class annotation@Controller(\"topicControllerV2\")public class TopicController &#123; // Medhod annotation: @RequestMapping(value = \"/load\", method = RequestMethod.GET) public TopicLoadResponse topicLoad(@RequestParam(value = \"client_id\") String appId, @RequestParam(value = \"topic_url\") String topicUrl, @RequestParam(value = \"topic_source_id\", required = false) String topicSourceId) &#123; // ...method &#125;&#125; 定义一个注解所有注解都隐式的继承自java.lang.annotation.Annotation // Controller:@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME) // 使用元注解public @interface Controller &#123; // 注解的定义: modifier @interface Annotation String value() default \"\"; // 注解的方法都是这种格式: Type elementName() default defaultVal;&#125;// RequestMapping@Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Mappingpublic @interface RequestMapping &#123; String name() default \"\"; // String[] value() default &#123;&#125;; RequestMethod[] method() default &#123;&#125;; // RequestMethod是枚举类型GET/POST.. String[] headers() default &#123;&#125;;&#125;","text":"使用注解// Class annotation@Controller(\"topicControllerV2\")public class TopicController &#123; // Medhod annotation: @RequestMapping(value = \"/load\", method = RequestMethod.GET) public TopicLoadResponse topicLoad(@RequestParam(value = \"client_id\") String appId, @RequestParam(value = \"topic_url\") String topicUrl, @RequestParam(value = \"topic_source_id\", required = false) String topicSourceId) &#123; // ...method &#125;&#125; 定义一个注解所有注解都隐式的继承自java.lang.annotation.Annotation // Controller:@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME) // 使用元注解public @interface Controller &#123; // 注解的定义: modifier @interface Annotation String value() default \"\"; // 注解的方法都是这种格式: Type elementName() default defaultVal;&#125;// RequestMapping@Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Mappingpublic @interface RequestMapping &#123; String name() default \"\"; // String[] value() default &#123;&#125;; RequestMethod[] method() default &#123;&#125;; // RequestMethod是枚举类型GET/POST.. String[] headers() default &#123;&#125;;&#125; 如何获取带有特定注解(这里用@YourAnnotation注解为例)的类, 使用了org.reflections.Reflections工具类:Reflections reflections = new Reflections(\"org.test\");Set&lt;Class&lt;?&gt;&gt; classes = reflections.getTypesAnnotatedWith(YourAnnotation.class); 标准注解JavaSE在java.lang.annotation和javax.annotation包定义了大量注解, 其中4个是元注解, 用于定义一般注解 &amp;描述注解的行为属性. @Deprecated: 所有场合,包 &amp; 类 &amp; 方法 &amp; 属性 @SuppressWarnings: 类 &amp; 方法 &amp; 属性, 阻止某种警告信息, @SuppressWarnings(value={&quot;unchecked&quot;,&quot;deprecation&quot;}) @Override: 只有方法 @Resources: ? @Resource: 可以写在属性上, 和setter方法上, 默认按照名称进行装配 @PostConstruct 方法, 指明该方法在构造器之后立刻被调用 @PreDestory 方法, 指明该方法在类被销毁前调用 元注解 @Target: @Target(ElementType.TYPE) // 类, 接口, 枚举, 注解 @Target(ElementType.METHOD) //方法 @Target(ElementType.PARAMETER) //方法参数 @Target(ElementType.FIELD) //字段 @Retention: @Retention(RetentionPolicy.SOURCE) //注解仅存在于源码中, 在class字节码文件中不包含 @Retention(RetentionPolicy.CLASS) // 默认的保留策略, 注解会在class字节码文件中存在, 但运行时无法获得, @Retention(RetentionPolicy.RUNTIME) // 注解会在class字节码文件中存在, 在运行时可以通过反射获取到 @Document: 说明该注解将被包含在javadoc中 @Inherited: 一般在定义注解时使用, 说明这个子类可以继承父类中的这个注解","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"}]},{"title":"Java Tutorials-09-NIO & Netty","slug":"12.Java/Java-Tutorials.09.NIO&Netty","date":"2024-01-24T01:27:52.147Z","updated":"2024-01-24T01:27:52.148Z","comments":true,"path":"12.Java/Java-Tutorials.09.NIO&Netty/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-Tutorials.09.NIO&Netty/","excerpt":"@toc: NIO API（Channel/Buffer/Selector, 网络/文件/堆外内存） NIO 高性能的实现（异步非阻塞 I/O + 堆外内存） 网络编程中两种高性能 I/O 设计模式（多路复用）：Reactor 和 Proactor 从 BIO 到 NIO BIO 即阻塞 I/O，不管是磁盘 I/O 还是网络 I/O，数据在写入 OutputStream 或者从 InputStream 读取时都有可能会阻塞。一旦有线程阻塞将会失去 CPU 的使用权，这在当前的大规模访问量和有性能要求情况下是不能接受的。Java NIO 是 java 1.4 之后新出的一套 IO 接口，这里的的新是相对于原有标准的 Java IO 和 Java Networking 接口。NIO 提供了一种完全不同的操作方式。NIO（Non-blocking I/O）是一种同步非阻塞的 I/O 模型，也是 I/O 多路复用的基础，已经被越来越多地应用到大型应用服务器，成为解决高并发与大量连接、I/O 处理问题的有效方式。 NIO 包介绍","text":"@toc: NIO API（Channel/Buffer/Selector, 网络/文件/堆外内存） NIO 高性能的实现（异步非阻塞 I/O + 堆外内存） 网络编程中两种高性能 I/O 设计模式（多路复用）：Reactor 和 Proactor 从 BIO 到 NIO BIO 即阻塞 I/O，不管是磁盘 I/O 还是网络 I/O，数据在写入 OutputStream 或者从 InputStream 读取时都有可能会阻塞。一旦有线程阻塞将会失去 CPU 的使用权，这在当前的大规模访问量和有性能要求情况下是不能接受的。Java NIO 是 java 1.4 之后新出的一套 IO 接口，这里的的新是相对于原有标准的 Java IO 和 Java Networking 接口。NIO 提供了一种完全不同的操作方式。NIO（Non-blocking I/O）是一种同步非阻塞的 I/O 模型，也是 I/O 多路复用的基础，已经被越来越多地应用到大型应用服务器，成为解决高并发与大量连接、I/O 处理问题的有效方式。 NIO 包介绍Java Non-blocking I/O 主要有三大核心部分：Channel (通道)，Buffer (缓冲区), Selector；除此之外，Java NIO 还包括了新的文件/目录的操作: Path 和 Files。 java.nio.channels 包： java.nio.channels.ServerSocketChannel java.nio.channels.SocketChannel java.nio.channels.FileChannel java.nio.channels.SocketChannel.Selector 类 java.nio.Buff 接口： java.nio.ByteBuffer: 最基本的字符 buff, 从 Channel (ServerSocketChannel, FileChannel 等)读取出的内容放在 ByteBuffer 里, 或者通过 Channel.write 把 ByteBuffer 内容写入 Channel; DirectByteBuffer: JVM 堆外分配； java.nio.MappedByteBuffer: MappedBuffer 是通过内存文件映射将文件中的内容直接映射到堆外内存中，其本质也是一个 DirectBuffer； HeapByteBuffer: JVM 堆内分配； java.nio.file 包： java.nio.file.Path: Path 的实例指代一个目录或文件 java.nio.file.Paths: Path 的工厂类, 用于获取 Path 实例 java.nio.file.Files: 提供对 Path 的操作 ▶ BIO 和 NIO 的对比变化如下: (1) BIO 流 vs NIO 管道: Java BIO 的各种流的读写都是阻塞操作。这意味着一个线程一旦调用了 read(),write()方法但系统缓冲区没数据可读，那么该线程会进入阻塞状态（Blocked）。 NIO 读写都是非阻塞的, NIO 基于 Channel(管道)和 Buffer(缓冲区)进行操作：数据总是从通道读取到缓冲区中，或者从缓冲区写入到通道中。Channel 可以是文件也可以是 Socket； (2) NIO 里新增了 Selector，用于监听多个 Channel 的事件，当 Channel 产生可读写事件后, 用 ByteBuffer 读取数据。Selector 允许一个单一线程监听多个 Channel 输入。我们可以注册多个 Channel 到 Selector 上，然后然后用一个线程来挑出一个处于可读或者可写状态的 Channel。Selector 机制使得单线程管理过个 Channel 变得容易。 (3) NIO 的提供了 Path 和 Files 来取代 io 包中的 File, Path 的实例指代一个目录或文件，Files 则提供了对目录或文件的基本操作（exists, copy, move, delete） NIO ByteBufferByteBuffer (参考官方文档 Buffer (Java Platform SE 8 ) )的属性、方法: 使用Buffer读写数据一般遵循以下四个步骤：1. 写入数据到Buffer2. 调用flip()方法3. 从Buffer中读取数据4. 调用clear()方法或者compact()方法，准备再次写入 ByteBuffer.allocate(int): 创建 buff 并初始化大小 put(byte), put(byte[]): 向 buff 存储数据 get(), 返回 position 位置的一个 byte 属性 capacity &gt;= limit &gt;= position &gt;= mark capacity: 指定数组大小, Buffer 创建后就不可改变; position: 下一个要读或要写的位置, 初始值 0, 每次写入 or 读取一个字节 position++ limit: 缓冲区的终点, 不可操作 limit 后面的元素, buffer 刚创建还未写入数据时, limit 初始值等于 capacity, 开始写数据, position ++ 开始读数据, 调用 flip()方法后 limit=position, 然后 position=0, 意思是 buff 可读取的范围是 position~limit mark: 初始值-1, 备忘位置, 参见 mark()/reset()方法 flip(): 向 Buffer 写完数据, 开始读数据前要调用一次, 把 position 的值赋给 limit, 然后 position=0, 然后可以调用 get()从 position 读出字节, 读的上限是在 limit 处; clear(): limit 置为 capacity, position 置为 0, mark 置为-1, 这时可以写 buffer 了; compact(): 清除读过的数据, 将所有未读的数据拷贝到 buffer 起始处, position 指向未读的末尾, limit 置为 capacity, 又可以再次对 buffer 进行写入了; rewind(), position=0, mark=-1, 不改变 limit 的值, 可以再读一遍[0~limit]的字节 mark(): 调用后, 使 mark=position, 使用mark()来记录当前 position reset(): 调用后, 使 position=mark, 使用 reset()让 position 置为 mark 的值, 一次 reset()对应一次 mark() equals(): 比较两个 buff 剩余未读的字节数, 比较剩余的每一个字节 compareTo(): .. 图来自 https://www.baeldung.com/java-bytebuffer ByteBuffer 内部是由一个数组实现的, 所以 capacity 理论最大值受 MAX_Integer 和 -Xmx 限制 NIO Channel@todo NIO Selector@todo Files &amp; Path示例代码: public class NioPathAndFiles &#123; public static void apiTest() &#123; // 判断文件是否存在 Path path = Paths.get(\"data/logging.properties\"); boolean pathExists = Files.exists(path, new LinkOption[]&#123; LinkOption.NOFOLLOW_LINKS&#125;); // 创建目录 Path path2 = Paths.get(\"data/subdir\"); Files.createDirectory(path2); &#125; public static void readTest() &#123; Path path = Paths.get(\"~/text.txt\"); //通过bufferedReader读取 BufferedReader bufferedReader = Files.newBufferedReader(path, StandardCharsets.UTF_8);//文件编码 StringBuilder sb = new StringBuilder(); String tempString = null; while ((tempString = bufferedReader.readLine())!=null)&#123; sb = sb.append(tempString); &#125; System.out.println(sb); //通过Files方法readAllLines List&lt;String&gt; strings = Files.readAllLines(path); strings.forEach(s -&gt; System.out.print(s)); &#125; pulic static void writeTest() &#123; Path path = Paths.get(\"/text\"); // 写入 Files.write(path, \"Hello JDK7!\".getBytes(), StandardOpenOption.APPEND); &#125;&#125; NIO 网络读写API 说明: 服务端: ServerSocketChannel.open() : 创建一个 server socket channel 实例, 相当于传统 Socket 的 ServerSocket ServerSocketChannel.socket().bind(SocketAddress local) : 绑定端口 ServerSocketChannel.configureBlocking(false): 把 server socket channel 设置为 非阻塞 的情况下, accept()/read()/write() 会立刻返回; ServerSocketChannel.accept(): 阻塞, 并在有客户端成功连接时返回一个 SocketChannel 实例 ServerSocketChannel.register(Selector, EVENT): 为 server channel 注册监听的事件 Selector: Selector.open(): 创建一个 selector 实例 Selector.select(): 开始监听并阻塞 客户端: SocketChannel.configureBlocking(false): 把 socket channel 设置为非阻塞, 读写会立刻返回 SocketChannel.write(ByteBuffer): 写方法 SocketChannel.read(ByteBuffer): 读方法, 返回值是读取的字节数 用 NIO API 实现简单的 Socket Server（用 Selector 实现多路复用, 用 Channel.configureBlocking(false) 设置为非阻塞 I/O）: ByteBuffer echoBuffer = ByteBuffer.allocate(1024);// 创建ServerSocketChannel实例, 并绑定端口ServerSocketChannel channel = ServerSocketChannel.open();channel.socket().bind(new InetSocketAddress(8080));channel.configureBlocking(false);// Channel 绑定 Selector, 并注册 ReadSelector selector = Selector.open();SelectionKey regKey = channel.register(selector, SelectionKey.OP_READ);for (;;)&#123; // 在这里阻塞 int num = selector.select(); // 运行到这里表示有事件产生 Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; keyIterator = selectedKeys.iterator(); while(keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if ((selectionKey.readyOps() &amp; SelectionKey.OP_ACCEPT) == SelectionKey.OP_ACCEPT) &#123; // 取出服务端SocketChannel ServerSocketChannel serverSocketChannel = (ServerSocketChannel) selectionKey.channel(); // 接受请求, 返回客户端SocketChannel SocketChannel sc = serverSocketChannel.accept(); // 客户端SocketChannel设置NoneBlock sc.configureBlocking(false); // 客户端SocketChannel也添加进 SelectionKey newKey = sc.register(selector, SelectionKey.OP_READ); // 不要忘记删除 it.remove(); System.out.println(\"Got connection from \" + sc); &#125; else if ((selectionKey.readyOps() &amp; SelectionKey.OP_READ) == SelectionKey.OP_READ) &#123; // 取出可读的channel SocketChannel sc = (SocketChannel) selectionKey.channel(); // 处理数据 int bytesEchoed = 0; while (true) &#123; echoBuffer.clear(); int r = sc.read(echoBuffer); if (r &lt;= 0) break; echoBuffer.flip(); sc.write(echoBuffer); bytesEchoed += r; &#125; System.out.println(\"Echoed \" + bytesEchoed + \" from \" + sc); it.remove(); &#125; &#125;&#125; 总结: NIO 的 Socket 多路复用如下: 创建服务端 socketChannel 创建 Selector 服务端 socketChannel 在 Selector 上注册 ACCEPT 事件 While 循环 selector.select() 阻塞, 如果 Selector 上有事件发生, 退出阻塞 selector 取出所有事件集合, 并遍历 如果有 ACCEPT 事件, 服务端 socketChannel 去 accept 这个请求, 创建客户端 socketChannel, 并在 Selector 上注册该 channel 的 READ 事件 如果有 READ 事件, 读对应的客户端 socketChannel 与传统 Socket 比较从上面的代码可以看到, 传统的 Java Socket(BIO, 阻塞 IO), 等同于 java.net + java.io, 使用的”Socket 句柄”是 java.net.ServerSocket (服务端 socket)和 java.net.Socket (客户端 socket), 通过 Socket 获取 InputStream/OutpubtStream 进行读/写. NIO Socket 使用的”socket 句柄”是 java.nio.channels 包下面的 ServerSocketChannel 和 SocketChannel, SocketChannel 的读写是通过 java.nio.ByteBuffer 前者 IO 方法是阻塞的, 后者 IO 方法是非阻塞 // ? 多线程-BIO 缺陷 线程的创建和销毁成本很高 线程本身占用较大内存，像 Java 的线程栈，一般至少分配 512 K～1 M 的空间，如果系统中的线程数过千… 线程的切换成本是很高 容易造成锯齿状的系统负载。因为系统负载是用活动线程数或 CPU 核心数，高并发下会使系统负载压力过大 BIO(阻塞 IO)模型，之所以需要多线程，是因为在进行 I/O 操作的时候，一是没有办法知道到底能不能写、能不能读，只能阻塞等待。NIO 的读写函数可以立刻返回，这就给了我们不开线程利用 CPU 的最好机会：如果一个连接不能读写（socket.read()返回 0 或者 socket.write()返回 0），我们可以把这件事记下来，记录的方式通常是在 Selector 上注册标记位，然后切换到其它就绪的连接（channel）继续进行读写。NIO 由原来的阻塞读写（占用线程）变成了单线程轮询事件，找到可以进行读写的网络描述符进行读写。除了事件的轮询是阻塞的（没有可干的事情必须要阻塞），剩余的 I/O 操作都是纯 CPU 操作，没有必要开启多线程。单线程处理 I/O 的效率确实非常高，没有线程切换，只是拼命的读、写、选择事件。 以上参考: Java NIO浅析 - @ref NIO 大文件读写大文件读写几种方案: 传统 IO 读取方式: 字节方式读取: FileInputStream VS BufferedInputStream 字符方式读取: BufferedReader NIO 读取: FileChannel + ByteBuffer MappedByteBuffer(内存映射) 测试结论参考: JAVA NIO(六)：读取10G的文件其实很容易 - CSDN博客 @ref 传统 NIO 读取:java.io.RandomAccessFile 提供了文件随机读写,下面的代码是使用 nio 中的 FileChannel 和 ByteBuffer 从 RandomAccessFile 中读取: RandomAccessFile randomAccessFile = new RandomAccessFile(new File(filePath), \"r\");FileChannel fileChannel = randomAccessFile.getChannel(); // 1 获取channelByteBuffer buffer = ByteBuffer.allocate(BUF_SIZE);while ((read = fileChannel.read(buffer)) &gt; 0) &#123; // 2 读channel到ByteBuffer buffer.flip(); // 3 开始读之前flip // 从缓冲器读入数组, 省略处理过程... byte[] bytes = new byte[read]; buffer.get(bytes); // 4 buffer.clear(); // 5&#125;fileChannel.close();randomAccessFile.close(); 使用内存映射:nio.FileChannel 还提供了内存映射的方式读取文件: RandomAccessFile randomAccessFile = new RandomAccessFile(new File(filePath), \"r\");FileChannel fileChannel = randomAccessFile.getChannel();long length = randomAccessFile.length();// 整个文件映射到内存:MappedByteBuffer mappedByteBuffer = fileChannel.map(FileChannel.MapMode.READ_ONLY, 0, length);while (mappedByteBuffer.hasRemaining()) &#123; mappedByteBuffer.get(); //读取1字节 sum ++;&#125;// Close file &amp; channel 内存映射读取的优劣 内存映射方式的读取速度更快 read()是系统调用, 首先将文件从硬盘拷贝到内核空间的一个缓冲区, 再将这些数据拷贝到用户空间, 实际上进行了两次数据拷贝. map()也是系统调用, 但没有进行数据拷贝, 当缺页中断发生时, 直接将文件从硬盘拷贝到用户空间, 只进行了一次数据拷贝. MappedByteBuffer 使用虚拟内存, 因此分配(map)的内存大小不受 JVM 的-Xmx 参数限制, 但是也是有大小限制的; 如果当文件超出1.5G 限制时, 可以通过 position 参数重新 map(mode, position, size) 文件后面的内容; MappedByteBuffer 在处理大文件时的确性能很高, 但也存在一些问题, 如内存占用/文件关闭不确定, 被其打开的文件只有在垃圾回收的才会被关闭, 而且这个时间点是不确定的。javadoc 中也提到：”A mapped byte buffer and the file mapping that it represents remain* valid until the buffer itself is garbage-collected.” 参考: 深入浅出 MappedByteBuffer v 堆外内存堆外内存就是把内存对象分配在 Java 虚拟机的堆以外的内存，这些内存直接受操作系统管理（而不是虚拟机），这样做的结果就是能够在一定程度上减少垃圾回收对应用程序造成的影响。堆外内存默认是和 -Xmx 默认一样大，也可以使用 -XX:MaxDirectMemorySize 指定堆外内存大小 堆内 vs 堆外 堆外内存减少了堆内内存的垃圾回收, 减少 STW 停顿; 使用 Java 的 堆内内存 进行 IO 操作, 会比 C Native 的程序多一次内存拷贝。为什么呢？ Java 的 IO 底层也是调用了 C Native 的 read()/write() 函数, 这些函数需要传入 void * 类型的内存地址, 并且这个内存地址指向的内容不能被改变, 否则 read()/write() 操作的内存就错了;有些 GC 回收器会整理内存, Java 对象在内存的地址会被改变,所以使用堆内内存进行 IO 操作, 需要先把堆内内容 copy 到 JVM 堆外的连续内存, 然后传递给 C 的 read()/write(), 这就多了一次内存拷贝;JVM 规范没有要求 byte[] 一定是物理连续的, 但是 C 里用 malloc() 分配的内存是连续的; How to 创建堆外内存三种方式创建堆外内存： 使用 NIO 提供的分配方法 ByteBuffer buf = ByteBuffer.allocate(1024); // 返回的是堆内的 HeapByteBufferByteBuffer buf = ByteBuffer.allocateDirect(1024); // 返回的是直接堆外的 DirectByteBuffer 使用 NIO 提供的堆外内存相关的类：DirectByteBuffer，MappedByteBuffer // DirectByteBufferDirectByteBuffer dbf = new DirectByteBuffer(1024);// MappedByteBuffer可以通过FileChannel实例获取, 用于文件内存映射 直接使用 unsafe: Unsafe unsafe = GetUsafeInstance.getUnsafeInstance();long pointer = unsafe.allocateMemory(1024); DirectByteBuffer 该类本身还是位于 Java 内存模型的堆中。而 DirectByteBuffer 构造器中调用 unsafe.allocateMemory(size) 是个一个 native 方法，这个方法分配的是堆外内存，通过 C 的 malloc 来进行分配的。并不属于 JVM 内存。 堆外内存释放 通过堆内对象触发 GC, 堆内对象和指向的堆外内存一并被回收; 通过 Unsafe 回收; public class FreeDirectMemoryExample&#123; private long address = 0; private Unsafe unsafe = GetUsafeInstance.getUnsafeInstance(); public FreeDirectMemoryExample(int size) &#123; address = unsafe.allocateMemory(size); &#125; @Override protected void finalize() throws Throwable &#123; super.finalize(); unsafe.freeMemory(address); &#125;&#125; 堆外内存 GC如果堆外内存容量超过了 -XX:MaxDirectMemorySize 会发生 OutOfMemoryError: Direct buffer memory，如果 GC 回收了 DirectBuffer 对象，那么 DirectBuffer 对象指向的堆外内存，会在 GC 的后期被回收，如果 Java 程序使用的堆内内存（Heap）占用率不高但是却大量使用 DirectBuffer 分配堆外内存，这种情况下不会因为堆内内存触发 Full GC 也就无法自动释放堆外内存，所以通常需要调用 System.gc() 来强制回收堆外内存（但是线上环境不建议这样触发 Full GC），这种情况下一定确保不能启用了 -XX:+DisableExplicitGC 导致 System.gc() 被禁用。 System.gc() 会建议 JVM 进行 Full GC, 对新生代的老生代都会进行内存回收，这样会比较彻底地回收 DirectByteBuffer 对象以及他们关联的堆外内存.DirectByteBuffer 对象本身其实是很小的，但是它后面可能关联了一个非常大的堆外内存，因此我们通常称之为冰山对象.JVM 发生 YGC（Young gc 很频繁, 会 STW, 但是 Copy GC 算法的 STW 极短）的时候会将新生代里的不可达的 DirectByteBuffer 对象及其堆外内存回收了，但是无法对 Old Gen 里的 DirectByteBuffer 对象及其堆外内存进行回收，这也是我们通常碰到的最大的问题。( 并且堆外内存多用于生命期中等或较长的对象 )如果有大量的 DirectByteBuffer 对象移到了 Old Gen，但是又一直没有做 Old Gen 的 CMS GC 或者 Gull GC，那么物理内存可能被慢慢耗光，但是我们还不知道发生了什么，因为 heap 明明剩余的内存还很多。 本章参考 NIO 入门 Java NIO浅析 - 理解Java NIO-博客-云栖社区-阿里云 NIO 高性能是如何实现的（1）使用异步非阻塞实现高效的单线程轮询，避免阻塞式 IO 开多线程的方式。// NIO 由原来的阻塞读写（占用线程）变成了单线程轮询事件，找到可以进行读写的网络描述符进行读写。除了事件的轮询是阻塞的（Selector），剩余的 I/O 操作都是纯 CPU 操作，没有必要开启多线程。并且由于线程的节约，连接数大的时候因为线程切换带来的问题也随之解决，进而为处理海量连接提供了可能。 NIO 的读写函数可以立刻返回（用 Channel.configureBlocking(false) 设置该通道为非阻塞），如果一个连接不能读写（socket.read() 返回 0 或者 socket.write() 返回 0），我们可以把这件事记下来，记录的方式通常是在 Selector 上注册标记位，然后切换到其它就绪的连接（channel）继续进行读写。 Java 的 Selector ：同一个 channel 的 select 不能被并发的调用。因此，如果有多个 I/O 线程，必须保证：一个 socket 只能属于一个 IoThread，而一个 IoThread 可以管理多个 socket。 （2）使用 DirectBuffer 减少 IO 时数据拷贝次数： 使用堆内内存的时候，比如我们要完成一个从文件中读数据到堆内内存的操作，调用 FileChannelImpl.read(HeapByteBuffer) 实际上 File IO 会将数据读到堆外内存中，然后堆外内存再将这部分堆外数据拷贝到堆内内存。// 为什么 Java IO 会多一次内存拷贝? 因为系统调用 read &amp; write 函数的参数 buf 必须指向不变的内存地址，Java 的堆内内存在 GC 过程中（带有 compact 的 GC）地址会被改变； 如果直接使用堆外内存，如 DirectByteBuffer，这种方式是直接在堆外分配一个内存(即，native memory)来存储数据，程序通过 JNI, 直接将这部分的内存数据通过 read()/write() 到堆外内存中。 ➤ 比较传统 IO NIO 提供了直接内存的 ByteBuffer, 相比堆内内存, 在 read/write 时使用直接内存可以减少一次内存拷贝 // 但 DirectByteBuffer 创建和销毁的成本更高，更不宜维护，通常会用内存池来提高性能 NIO 多了非阻塞 IO + 多路复用 Selector（epoll 实现），Selector 可以使用一个线程即可管理大量 IO 连接的读写事件，对比 BIO （connection pre thread），节省了线程调度和切换的开销，更节省大量线程带来的内存消耗， Reactor 三种常见线程模型➤ 三种 Reactor 线程模型: 单 Reactor 单 Reactor + 多线程 主从 Reactor + 多线程 ➤ Reactor &amp; Proactor IO 模型中，涉及到的角色: Demultiplexer: 多路复用器, select or epoll 的抽象, 产生 IO 事件 Dispatcher: 分发器, 将多路复用器产生的事件进行分发 Acceptor: accept 事件处理器(函数) IOHandler: IO 事件处理器(函数) @ref: https://en.wikipedia.org/wiki/Reactor_pattern 单 Reactor 模型一个 Reactor Thread, 负责处理全部 I/O 事件(accept, read, send), 以及业务代码(decode, compute, encode) 在一个 Reactor Thread 里, select 监听 accept/read/write 事件, 事件由 Dispatcher 进行分发: 有 accept 事件, Dispatcher 分发给 Acceptor 进行握手/鉴权等处理; 有 read/write 事件, Dispatcher 分发给 IOHandler: 进行 read → decode → compute → encode → send ; 缺点: 当某个 Handler 阻塞时，会导致其他客户端的 handler 和 accpetor 都得不到执行，无法做到高性能，只适用于业务处理非常快速的场景 单 Reactor +多线程一个 Reactor Thread, 负责处理全部 I/O 事件(accept, read, send), 但业务代码交给线程池处理.. Reactor Thread 里, select 监听 accept/read/write 事件, 事件由 Dispatcher 进行分发: 有 accept 事件, 处理同单线程模型，Reactor 线程直接调用 acceptor 函数; 有 read 事件, Dispatcher 分发给 IOHandler 处理 (函数调用, 仍在 Reactor 线程里), 也就是在 Reactor 线程里进行非阻塞 read; 从 Worker Thread Pool 取出一个 Worker, 对读到的数据进行 decode → compute → encode 处理流程; Worker 的结果交还给 Reactor Thread, 由 Reactor Thread 进行 send; 比较单线程模型, 多线程 Reactor 模型仍在主线程里处理读/写操作, 不再处理业务代码, 业务代码交给线程池执行; 缺点: Reactor Thread 仍然负责全部的 accept/read/write 的处理, 如果在 Reactor Thread 进行有大量读写事件, 同时大量连接事件(在 accept 时进行鉴权等), 这时候仍会有单线程的瓶颈 主从 Reactor + 多线程不再是一个 Reactor Thread, 有 Main Reactor &amp; Sub Reactor 两个线程, 分别处理 accept 事件 &amp; IO 事件, 业务代码交给线程池处理 Main Reactor Thread 的 Selector 负责监听 accept 事件, 交给 Acceptor 处理; Acceptor 接受请求之后创建新的 SocketChannel, 并处理鉴权/握手等; 完成上一步处理的 socket, 从 Main Reactor Thread 的 Selector 移除, 并注册到 Sub Reactor Thread 的 Selector 上; Sub Reactor Thread 的 Selector 负责监听这些 socket 的 IO （read）事件, 并调用 IOHandler 进行非阻塞 read; 从 Worker Thread Pool 取出一个 Worker, 对读到的数据进行 decode → compute → encode 处理流程; Worker 的结果交还给 Reactor Thread, 由 Reactor Thread 进行 send; @ref: [[../_attachments/Scalable IO in Java - Doug Lea.pdf]] Netty 实现多线程 Reactor➤ Netty 中重要的 API 类: NioEventLoop: 是 Netty 的 Reactor 线程 继承自 SingleThreadEventExecutor, 只有一个线程的线程池 每个 NioEventLoop 都有一个 Selector(封装了 epoll), 可以用来监听 accept/r/w 事件 NioEventLoop 的职责： 1. 作为服务端 Acceptor 线程，负责处理客户端的请求接入； 2. 作为客户端 Connecor 线程，负责注册监听连接操作位，用于判断异步连接结果； 3. 作为 IO 线程，监听网络读操作位，负责从 SocketChannel 中读取报文； 4. 作为 IO 线程，负责向 SocketChannel 写入报文发送给对方，如果发生写半包，会自动注册监听写事件，用于后续继续发送半包数据，直到数据全部发送完成； 5. 作为定时任务线程，可以执行定时任务，例如链路空闲检测和发送心跳消息等； 6. 作为线程执行器可以执行普通的任务线程（Runnable）。 NioEventLoopGroup: 一个 NioEventLoopGroup 管理多个 NioEventLoop, 构造函数可以指定管理 NioEventLoop 的个数, 如果没有设置，默认取 -Dio.netty.eventLoopThreads，如果该系统参数也没有指定，则为可用的 CPU 内核数 × 2。 Channel（NioServerSocketChannel）：类似 NIO 中的 channel，对 socket 的封装，包括 connect、bind、read、write，此外 Nio 的 Channel 还包括一个 ChannelPipeline 成员； ChannelPipeline：该 Channel 上的读写操作，都会走到这个 ChannelPipeline 中，pipeline 上可以添加（事件，ChannelHandler），当 channel 上完成 register、active、read、readComplete 等事件时，会触发 pipeline 中的相应的 ChannelHandler；如同名字一样，pipeline 串行执行这些 Handler； EventLoop 串行执行 pipeline 上的 Handler： ➤ 用 Netty 实现多线程 Reactor(伪码)，这里使用的是主从 Reactor + 多线程模型: NioEventLoopGroup bossGroup = new NioEventLoopGroup(1); // 主Reactor线程NioEventLoopGroup workerGroup = new NioEventLoopGroup(); // 从Reactor线程ServerBootstrap bootstrap = new ServerBootstrap(); // 创建netty 服务器bootstrap.group(bossGroup,workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) // TCP参数 .option(ChannelOption.SO_BACKLOG, 1024) // TCP参数 .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ServerHandlerInitializer&lt;SocketChannel&gt;()&#123; @Override public void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline p = ch.pipeline(); if (sslCtx != null) p.addLast(sslCtx.newHandler(ch.alloc())); p.addLast(serverHandler); &#125; &#125;);// Start the server:ChannelFuture f = b.bind(PORT).sync(); Netty Server 创建两个 NioEventLoopGroup: bossGroup（main Reactor） 和 workerGroup（sub Reactor）; bossGroup 线程组通常只有一个 EventLoop 线程(Boss 线程), 这个线程作为 Main Reactor Thread, 负责 select 监听端口的 accept 事件并进行后续处理(创建 SocketChannel.. ); bossGroup 的 EventLoop 线程会把创建的 SocketChannel, 顺序分发给 workerGroup 线程组中的每一个 Worker 线程(类似轮询); workerGroup 线程组, 通常包含 cpu core 数量的 1-2倍个 EventLoop 线程(Worker 线程), 这些 Worker 线程作为 Sub Reactor Threads, Worker 线程内使用 Selector 监听 SocketChannel 的读写事件; childHandler 是传入了一个 ChannelInitializer，这是当有新的客户端连接到达时会回调的一个方法。我们给这个新的 channel 的 pipeline 上添加了一个处理器 serverHandler，当收到数据的时候会执行该 handler @ref: Netty系列之Netty线程模型 - InfoQ 聊聊Netty那些事儿之从内核角度看IO模型 剖析Netty内部网络实现原理 一文聊透 Netty 核心引擎 Reactor 的运转架构 - bin的技术小屋 - 博客园 Java 对 AIO 的支持AIO(asynchronous I/O): 异步 IO, java.nio.channels包做了支持, 包括: AsynchronousSocketChannel / AsynchronousServerSocketChannel / AsynchronousFileChannel","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"}]},{"title":"Java Tutorials-08-网络编程API","slug":"12.Java/Java-Tutorials.08.网络编程API","date":"2024-01-24T01:27:52.143Z","updated":"2024-01-24T01:27:52.143Z","comments":true,"path":"12.Java/Java-Tutorials.08.网络编程API/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-Tutorials.08.网络编程API/","excerpt":"Server/Client的Socket API介绍. ServerServerSocket server = new ServerSocket(9090);Socket client = server.accept(); // 阻塞InputStream input = client.getInputStream();OutputStream output = client.getOutputStream();double value = input.readDouble();output.writeDouble(value);inpput.close();output.close();server.close(); Client/* 方式1 */Socket socket = new Socket(host, port); // 阻塞OutputStream out = socket.getOutputStream();...out.close();socket.close();/* 方式2 */Socket socket = new Socket();socket.connect(new InetSocketAddress(host, port), timeout); // 阻塞","text":"Server/Client的Socket API介绍. ServerServerSocket server = new ServerSocket(9090);Socket client = server.accept(); // 阻塞InputStream input = client.getInputStream();OutputStream output = client.getOutputStream();double value = input.readDouble();output.writeDouble(value);inpput.close();output.close();server.close(); Client/* 方式1 */Socket socket = new Socket(host, port); // 阻塞OutputStream out = socket.getOutputStream();...out.close();socket.close();/* 方式2 */Socket socket = new Socket();socket.connect(new InetSocketAddress(host, port), timeout); // 阻塞 半关闭 Socket.shutdownOutput(): Socket.shutdownInput(): boolean isOutputShutdown(): boolean isInputShutdown(): Socket socket = new Socket(host, port);OutputStream out = socket.getOutputStream();InputStream in = socket.getInputStream();// 向out写入一些数据, 写入完毕, 半关闭socket的输出socket.shutdownOutput();// 此时socket仍可以从InputStream读取, 直到shutdown...socket.shutdown(); shutdownOutput 实际是发送了 FIN 报文给对方，意思是己方不再发送数据 [[../22.Network-Protocol/网络协议2-TCP#三次握手、四次挥手]] 可中断套接字当连接到一个套接字时，当前线程将会被阻塞直到建立连接或产生超时为止。java.nio包提供的一个特性——SocketChannel类，与上面的Socket不同，SocketChannel是可以中断的如果发生中断, 下面的操作不会阻塞, 而是抛出异常 SocketChannel channel = SocketChannel.open();channel.socket().connect(new InetSocketAddress(\"localhost\", 8080));Scanner in = new Scanner(channel);while (!Thread.currentThread().isInterrupted())&#123; if (in.hasNextLine()) String line = in.nextLine();&#125; KeepAlive参考： [[../22.Network-Protocol/网络协议2a-TCP的KeepAlive]]","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"}]},{"title":"Java Tutorials-06-序列化","slug":"12.Java/Java-Tutorials.06.序列化(Serialize)","date":"2024-01-24T01:27:52.138Z","updated":"2024-01-24T01:27:52.139Z","comments":true,"path":"12.Java/Java-Tutorials.06.序列化(Serialize)/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-Tutorials.06.序列化(Serialize)/","excerpt":"@toc: 序列化 Example Serializable 接口和 serialVersionUID 类的哪些字段不会被序列化 如何自定义序列化的策略？ArrayList 是如何序列化数组的？ JDK 序列化的实现 序列化 Exampleclass User implements java.io.Serializable &#123; private static final long serialVersionUID = 1L; transient Logger logger = LoggerFactory.getLogger(Config.class); long uid; String nick;&#125;// 写入ObjectOutputStream os = new ObjectOutputStream(new FileOutputStream(filePath));os.writeObject(user);os.close();// 读取ObjectInputStream is = new ObjectInputStream(new FileInputStream(filePath));User newUser = (User)is.readObject();is.close(); Serializable 接口和 serialVersionUID","text":"@toc: 序列化 Example Serializable 接口和 serialVersionUID 类的哪些字段不会被序列化 如何自定义序列化的策略？ArrayList 是如何序列化数组的？ JDK 序列化的实现 序列化 Exampleclass User implements java.io.Serializable &#123; private static final long serialVersionUID = 1L; transient Logger logger = LoggerFactory.getLogger(Config.class); long uid; String nick;&#125;// 写入ObjectOutputStream os = new ObjectOutputStream(new FileOutputStream(filePath));os.writeObject(user);os.close();// 读取ObjectInputStream is = new ObjectInputStream(new FileInputStream(filePath));User newUser = (User)is.readObject();is.close(); Serializable 接口和 serialVersionUID 类必须实现自 Serializable 接口，才可以被 ObjectOutputStream &amp; ObjectInputStream 序列化和反序列化，序列化时如果遇到未实现 Serializable 接口的类，会抛出 NotSerializableException 异常； 建议：可序列化的类定义自己的 serialVersionUID： private static final long serialVersionUID，在进行兼容升级时保持不变，也可以通过改变序列化 ID 限制某些用户使用； 在序列化时，VersionUID 被写入类对象的字节流，在反序列化时，ObjectInputStream 读取类对象字节流，并比较反序列化对象的 VersionUID 跟本地 class 的 VersionUID 作比较，如果不一致则抛出 InvalidClassException 异常； 如果没有定义 serialVersionUID，ObjectStreamClass（序列化 &amp; 反序列化操作的对象） 会自动生成一个，生成规则根据类名,接口名,属性名, 以及描述符等生成一个64位的哈希数字（见 ObjectStreamClass.getSerialVersionUID() 方法），每次改动类的代码都会导致自动生成的 serialVersionUID 发生变化； 类的哪些字段不会被序列化 static 成员 被声明为 transient 的成员 如果一个类有父类，那么父类中的成员如果也需要可序列化，那么父类也要实现 Serializable 接口 如何自定义序列化策略如何自定义序列化策略？ 在序列化的类中实现 writeObject(ObjectOutputStream) 和 readObject(ObjectInputStream) 方法即可 ArrayList 是如何序列化数组的？ ArrayList 内部是数组实现的，数据保存在 elementData[]，但实际使用中数组的大部分位置都是空值，为了让空元素不会被序列化，ArrayList 把 elementData[] 声明为 transient，并实现了 writeObject &amp; readObject 方法 JDK 序列化的实现如果一个类中包含 writeObject 和 readObject 方法，那么这两个方法是怎么被调用的?Serializable 只是一个空接口，它是如何保证只有实现类才可以被序列化呢？ 以 ObjectOutputStream 序列化为例，调用栈如下： ObjectOutputStream.writeObject writeObject0 // 判断 obj instanceof Serializable writeClassDesc -&gt; ... 通过 osc.getSerialVersionUID() 获取or生成 VersionUID writeOrdinaryObject writeSerialData invokeWriteObject // 通过反射调用类的 writeObject()，如果没定义则执行默认方法","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"}]},{"title":"Java Tutorials-05-IO","slug":"12.Java/Java-Tutorials.05.IO","date":"2024-01-24T01:27:52.134Z","updated":"2024-01-24T01:27:52.134Z","comments":true,"path":"12.Java/Java-Tutorials.05.IO/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-Tutorials.05.IO/","excerpt":"概述Java 的 I/O 操作类在包 java.io 下，大概有将近 80 个类，但是这些类大概可以分成四组，分别是： 基于字节操作的 I/O 流接口：InputStream 和 OutputStream 基于字符操作的 I/O 流接口： Writer 和 Reader 基于磁盘操作的 I/O 文件接口： File 参考: 深入分析 Java I/O 的工作机制 @ref 流","text":"概述Java 的 I/O 操作类在包 java.io 下，大概有将近 80 个类，但是这些类大概可以分成四组，分别是： 基于字节操作的 I/O 流接口：InputStream 和 OutputStream 基于字符操作的 I/O 流接口： Writer 和 Reader 基于磁盘操作的 I/O 文件接口： File 参考: 深入分析 Java I/O 的工作机制 @ref 流按照流操作对象的类型是字节还是字符, 分为字节流和字符流 字节流的父类是 InputStream/OutputStream, 读写单个字节/字节数组, 字符流的父类是 Reader/Writer 用于读写被编码(GBK/UTF8)的字符串, 读写Char/Char数组; 按照功能分为节点流(node stream)和过滤流(filter stream, 或者叫装饰流) 节点流用来处理从基本位置获取字节(文件, 内存, 管道), FileInputStream, ByteArrayInputStream, PipedInputStream, 这些类提供基本的读写方法; 过滤流用于包装节点流, 提供了新的方法, 可以更方便的读写高级类型的数据(类序列化, 压缩文件, Java基本类型) ObjectInputStream, ZipInputStream, DataInputStream. 节点流 &amp; 过滤流图-外层的DataInputStream（过滤流）提供了额外的方法： 字节流 &amp; 字符流字符流相关类以及继承关系: 字符流 |-InputStream | |-FileInputStream [node流] 文件流 | |-ByteArrayInputStream [node流] 内存字符流 | |-PipedInputStream [node流] 管道流 | |-ObjectInputStream | |-SequenceInputStream | |-FilterInputStream | |-DataInputStream | |-BufferedInputStream | |-OutputStream 字节流相关类以及继承关系: 字节流 |-Reader | |-InputStreamReader | |-FileReader | |-PipedReader | |-BufferedReader | |-CharArrayReader | |-StringReader | |-Writer |-PrintWriter 没有对应的Reader, 可以使用java.io.Scaner 字节流 常用类和方法 InputStream/OutputStream 提供基本的字符/字符数组读写 InputStream.available() : 返回可读的字节数 read(), read(byte[]): 阻塞的, read返回读取的一个字节(int) write(int b), write(byte[]): 阻塞的 close() FileInputStream/FileOutputStream ByteArrayInputStream/ByteArrayOutputStream: 包含一个内部缓冲区(字节数组), 该缓冲区包含从流中读取的字节 PipedInputStream/PipedOutputStream 同上 BufferedInputStream/BufferedOutputStream: 为另一个流提供缓冲 ObjectInputStream/ObjectOutputStream Object readObject() void writeObject(Object) 字符流 常用类和方法 Reader: 提供对char,char[],String类型数据的基本操作 read(): 返回字符的Unicode编码(0-65535,双字节范围), 到达流末尾返回-1; read(char[]): 读取字符到数组并返回已读取的字符个数; skip(long n): 跳过n个char mark(int limit): 为流的当前位置增加标记, 下次调用reset可以返回这个标记, 如果调用mark()后读取字符数超过limit, 下次调用reset会失败. reset(): close(): InputStreamReader getEncoding(): 获取输入流的编码 ready(): 如果有数据可读, 返回true FileReader: 继承自 InputStreamReader 构造器: FileReader(String), FileReader(java.io.File) BufferedReader: readLine() : 读取一行并返回字符串(不包括换行符), 如果流已经读尽则返回null Scanner: 不是继承自Reader Writer : 提供对char,char[],String类型数据的基本操作 write(char c), write(char[]), write(String) append(char), append(CharSequence) flush(): 让缓冲区的内容立刻写入 close() : PrintWriter: 文件本章主要介绍文件操作类: java.io.File 和 java.io.RandomAccessFile java.io.FileFile 是“文件”和“目录路径名”的抽象表示形式。File 直接继承于Object，实现了Serializable接口和Comparable接口。实现Serializable接口，意味着File对象支持序列化操作。实现Comparable接口，意味着File对象之间可以比较大小；File能直接被存储在有序集合(如TreeSet、TreeMap中)。 public class FileTest &#123; public static void testFileDirAPIS() &#123; // 新建目录 File dir = new File(\"dir\"); dir.mkdir(); // 新建文件 File file1 = new File(dir, \"file1.txt\"); file1.createNewFile(); // 列出目录下的文件 File[] fs = dir.listFiles(); &#125;&#125; java.io.RandomAccessFilejava.io.RandomAccessFile是随机访问文件(包括读/写)的类。它支持对文件随机访问的读取和写入，即我们可以从指定的位置读取/写入文件数据。需要注意的是，RandomAccessFile 虽然属于java.io包，但它不是InputStream或者OutputStream的子类；它也不同于FileInputStream和FileOutputStream。 FileInputStream 只能对文件进行读操作，而FileOutputStream 只能对文件进行写操作；RandomAccessFile 同时支持文件的读和写，并且它支持随机访问。 RandomAccessFile 大部分功能被JDK1.4中NIO的内存映射文件替代了 RandomAccessFile raf = new RandomAccessFile(args[0], \"r\");long position = raf.length();while (position &gt; 0) &#123; position -= 1; raf.seek(position); byte b = raf.readByte();&#125; try-with-resources旧风格的I/O操作的异常捕获: private static void printFile() throws IOException &#123; InputStream input = null; try &#123; input = new FileInputStream(\"file.txt\"); // 1 int data = input.read(); // 2 while(data != -1)&#123; System.out.print((char) data); data = input.read(); //3 &#125; &#125; finally &#123; if(input != null)&#123; input.close(); // 4 &#125; &#125;&#125; 上面代码中可能会抛出异常. try语句块中有3个地方能抛出异常, finally语句块中有一个地方会能出异常.不论try语句块中是否有异常抛出, finally语句块始终会被执行.这意味着, 不论try语句块中发生什么, InputStream 都会被关闭, 或者说都会试图被关闭.如果关闭失败, InputStream’s close()方法也可能会抛出异常.Q: 假设try语句块抛出一个异常, 然后finally语句块被执行.同样假设finally语句块也抛出了一个异常.那么哪个异常会根据调用栈往外传播？A: 即使try语句块中抛出的异常与异常传播更相关, 最终还是finally语句块中抛出的异常会根据调用栈向外传播. 在JDK7中, try-with-resources 风格的IO异常捕获:try-with-resources语句会确保在try语句结束时关闭所有资源. 实现了java.lang.AutoCloseable或java.io.Closeable的对象都可以做为在try()代码块内打开的资源, 并且可以在退出try()语句块时被自动关闭. // try()代码块内打开多个资源:try ( java.util.zip.ZipFile zf = new java.util.zip.ZipFile(zipFileName); InputStream ins = new FileInputStream(\"/a.txt\"); java.io.BufferedWriter writer = java.nio.file.Files.newBufferedWriter(outputFilePath, charset) // 这里没有分号)&#123; // Enumerate each entry for (java.util.Enumeration entries = zf.entries(); entries.hasMoreElements();) &#123; // Get the entry name and write it to the output file String newLine = System.getProperty(\"line.separator\"); String zipEntryName = ((java.util.zip.ZipEntry) entries.nextElement()).getName() + newLine; writer.write(zipEntryName, 0, zipEntryName.length()); &#125;&#125; catch(Exception1 | Exception2 e) &#123; // 新风格的catch&#125; 当try-with-resources结构中抛出一个异常, 同时资源调用close方法时也抛出一个异常, try-with-resources结构中抛出的异常会向外传播, 而资源被关闭时抛出的异常被抑制了. 这与旧风格代码的例子相反. API Example字节流 API Example/* 基本字节流 InputStream/OutputStream 接口测试: */byte[] bytes = &#123;72, 101, 108, 108, 111&#125;;OutputStream os = new FileOutputStream(\"~/testFile\");os.write(bytes); // 1os.close();int size; byte[] readbuf;InputStream is = new FileInputStream(\"~/testFile\");if((size= is.available()) &gt; 0) &#123; // 2 is.read(readbuf= new byte[size]); // 3 System.out.println(new String(readbuf));&#125;in.close();/* Filter Streams Layered onto Node Stream */FileOutputStream fileOutputStream = new FileOutputStream(\"A.txt\"); // Node StreamBufferedOutputStream bufferedOutputStream = new BufferedOutputStream(fileOutputStream); // Filter StreamDataOutputStream out = new DataOutputStream(bufferedOutputStream);out.writeInt(3);out.writeBoolean(true);out.flush();out.close();DataInputStream in = new DataInputStream( new BufferedInputStream( new FileInputStream(\"A.txt\")));// DataInputStream Methods:in.readInt();in.readBoolean();in.close(); 字符流 API Example/* PrintWriter and Scanner */PrintWriter out = new PrintWriter(\"A.txt\", \"UTF-8\");out.println(\"Hello\");out.close();Scanner scanner = new Scanner(new FileInputStream(\"A.txt\"), \"UTF-8\");while (scanner.hasNextLine()) &#123; String line = scanner.nextLine();&#125;scanner.close();/* FileReader -&gt; BufferedReader */FileReader fr=new FileReader(\"~/testout.txt\");BufferedReader br=new BufferedReader(fr);int i;while((i=br.read())!=-1)&#123; System.out.print((char)i);&#125;br.close();fr.close();/* BufferedReader 逐行读取 */String line;InputStream fis = new FileInputStream(ReadFile);InputStreamReader isr = new InputStreamReader(fis, \"UTF-8\");BufferedReader br = new BufferedReader(isr);while((line = br.readLine()) != null) &#123; System.out.println(line);&#125;br.close();/* 文件字节流 -&gt; 文件字符流 */FileOutputStream os = new FileOutputStream(WriteFile);OutputStreamWriter writer = new OutputStreamWriter(os,\"UTF-8\");writer.append(\"Hello\\r\\n\");writer.close();/* 字符流处理Socket */Socket socket = new Socket(\"127.0.0.1\", 8080);Writer writer = new PrintWriter(socket.getOutputStream());write.write(\"Hello\");// close writer and socket","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"}]},{"title":"Java Tutorials-04-泛型","slug":"12.Java/Java-Tutorials.04.泛型(Generic)","date":"2024-01-24T01:27:52.129Z","updated":"2024-01-24T01:27:52.129Z","comments":true,"path":"12.Java/Java-Tutorials.04.泛型(Generic)/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-Tutorials.04.泛型(Generic)/","excerpt":"泛型类和泛型方法泛型类public class Pair&lt;T&gt; &#123; private T first; private T second; public T getFirst() &#123;...&#125; public T getSecond() &#123;...&#125; public setFirst(T) &#123;...&#125; public setSecond(T) &#123;...&#125;&#125; 泛型方法public Class ArrayAlg &#123; public static &lt;T&gt; T getMiddle (T t) &#123; return t[t.length / 2]; &#125;&#125;// 调用泛型方法ArrayAlg.&lt;String&gt;getMiddle(\"Hello\");// 或者不用指定泛型方法的T, 编译期自行推断也是可以的:ArrayAlg.getMiddle(\"Hello\");","text":"泛型类和泛型方法泛型类public class Pair&lt;T&gt; &#123; private T first; private T second; public T getFirst() &#123;...&#125; public T getSecond() &#123;...&#125; public setFirst(T) &#123;...&#125; public setSecond(T) &#123;...&#125;&#125; 泛型方法public Class ArrayAlg &#123; public static &lt;T&gt; T getMiddle (T t) &#123; return t[t.length / 2]; &#125;&#125;// 调用泛型方法ArrayAlg.&lt;String&gt;getMiddle(\"Hello\");// 或者不用指定泛型方法的T, 编译期自行推断也是可以的:ArrayAlg.getMiddle(\"Hello\"); 泛型的类型限定public static &lt;T extends Comparable&gt; T min(T[] a) &#123; T min = a[0]; for(int i=0; i &lt; a.length; i++) &#123; if(a[i] &lt; min) min = a[i]; &#125; return min;&#125; 如果T需要多个类型限定: &lt;T extends Comparable &amp; Serializable&gt; 类型擦除 JVM没有”泛型类”这种类型, java代码被编译后生成的字节代码, 这个过程中所有的泛型类型要被替换, 原则: 有类型限定的, 替换为第一个限定类型, T extends Comparable &amp; Serializable被替换为Comparable 无类型限定, 替换为Object, T被替换为Object 对类型查询的影响1. instanceofPair&lt;String&gt; s = new Pair&lt;String&gt;(); // 擦除后为 Pair&lt;Object&gt; sif(s instanceof Pair&lt;T&gt;) &#123; // Pair&lt;T&gt;擦除后为Pair&lt;Object&gt; // yes&#125;if(s instanceof Pair&lt;Double&gt;) &#123; // yes&#125; 2. getClass()Pair&lt;String&gt; s = new Pair&lt;String&gt;();Pair&lt;Double&gt; d = new Pair&lt;Double&gt;();if(s.getClass() == d.getCLass()) &#123; // getClass()总是返回Pair&lt;Object&gt; // yes&#125;// 打印 s.getClass().toString() ， 得到的类型是 ‘Pair’ 不能创建泛型类数组// 试图创建泛型类型的数组会在编译期报错:Pair&lt;String&gt;[] arr = new Pair&lt;String&gt;[1]; // error !Pair&lt;String&gt;[] arr = Array.newInstance(Pair&lt;String&gt;.getClass(),1); // error ! 原因是数组一旦创建会记住元素的类型, 当试图向数组中存储不同的类型时会报错, Pair&lt;String&gt;[]这样声明的泛型数组, 擦除后变为Pair&lt;Object&gt;[]. 不能实例化泛型不能使用像new T(), new T[N], T.class这样的表达式. 通配符&lt;?&gt;无限定通配符public static boolean Foo(List&lt;?&gt; list) &#123; return list.get(0) != null;&#125; List&lt;?&gt;表示持有某种特定类型的List，但是不知道具体是哪种类型。那么我们可以向其中添加对象吗？当然不可以，因为并不知道实际是哪种类型，所以不能添加任何类型，这是不安全的。 上界通配符? extends ClassType表示ClassType的任何子类 先看一段代码:List&lt;? extends Fruit&gt; list = new ArrayList&lt;Apple&gt;();// Compile Error: can’t add any type of object:// flist.add(new Apple());// flist.add(new Fruit());// flist.add(new Object());// 只能向list里添加nulllist.add(null);// get是可以编译通过的list.get(0); 做了泛型的向上转型 (List&lt;? extends Fruit&gt; flist = new ArrayList&lt;Apple&gt;())，那么我们也就失去了向这个List添加任何对象的能力，即使是Object也不行。那么上界通配符有什么用呢? public class GenericTest &#123; public static void func(List&lt;? extends Fruit&gt; list) &#123; for(i=0; i&lt;list.size(); i++) &#123; Fruit fruit = list.get(i); System.out.println(fruit.getName()); &#125; list.add(new Apple()); // Compile Error! list.add(new Object()); // Compile Error! &#125;&#125; List&lt;? extends Fruit&gt; list 表示一个List, 里面存储的类型是Fruit的派生类, 从list里get出来的类型至少是Fruit, 或者Fruit的派生类, 可以调用Fruit类的方法.传递给GenericTest.func()的参数可以是List&lt;Apple&gt;, 也可以是List&lt;Lemon&gt;,上界通配符&lt;? extends Base&gt;, 可以调用基类Base里定义的方法, 也可以get, 但是不可以set 下界通配符? super Integer表示Integer的超类, 只能用于setter. void setFirst(Pair&lt;? super Integer&gt;); 限定符和泛型的一些问题…泛型中无界通配符&lt;?&gt; 和&lt;T&gt;的区别? &lt;T&gt;用在类或方法的定义里: public class ArrayList&lt;T&gt; &lt;?&gt;通配符用在”调用”的地方, 通配符是拿来使用定义好的泛型的, 可以使用?的一般满足: 方法定义里只使用Object的方法，跟?类型无关; 使用中不依赖于泛型, 最典型的是Class&lt;?&gt; ... 无限定通配符表示匹配任意类。ArrayList&lt;?&gt; 和ArrayList&lt;Object&gt; 看上去有点类似，但实际却不一样。 ArrayList&lt;?&gt;是任意 ArrayList&lt;T&gt; 的超类; List&lt;Apple&gt;是List&lt;? extends Fruit&gt;的子类(假设Apple继承自Fruit) ArrayList&lt;Object&gt; 并不是ArrayList&lt;T&gt; 的超类;","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"}]},{"title":"Java Tutorials-03-反射","slug":"12.Java/Java-Tutorials.03.反射(Reflection)","date":"2024-01-24T01:27:52.124Z","updated":"2024-01-24T01:27:52.125Z","comments":true,"path":"12.Java/Java-Tutorials.03.反射(Reflection)/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-Tutorials.03.反射(Reflection)/","excerpt":"反射和RTTI RTTI: Run-Time Type Indentification, 运行时类型识别. 并非Java体系中的概念, 来自Thinking in C++ Reflection(反射): 允许在程序运行期间探知并分析类对象的结构. RTTI（Run-Time Type Identification）运行时类型识别。在《Thinking in Java》一书第十四章中有提到，其作用是在运行时识别一个对象的类型和类的信息。主要有两种方式：一种是“传统的”RTTI，它假定我们在编译时已经知道了所有的类型；另一种是“反射”机制，它允许我们在运行时发现和使用类的信息。 Class 类 &amp; Class 对象每个类实例都有一个相对应的”Class 对象”, 所以类实例在进行向上转型时不会丢失原有的类型信息, 这个 Class 对象的类型就是”Class 类”, 位于 java.lang.Class;","text":"反射和RTTI RTTI: Run-Time Type Indentification, 运行时类型识别. 并非Java体系中的概念, 来自Thinking in C++ Reflection(反射): 允许在程序运行期间探知并分析类对象的结构. RTTI（Run-Time Type Identification）运行时类型识别。在《Thinking in Java》一书第十四章中有提到，其作用是在运行时识别一个对象的类型和类的信息。主要有两种方式：一种是“传统的”RTTI，它假定我们在编译时已经知道了所有的类型；另一种是“反射”机制，它允许我们在运行时发现和使用类的信息。 Class 类 &amp; Class 对象每个类实例都有一个相对应的”Class 对象”, 所以类实例在进行向上转型时不会丢失原有的类型信息, 这个 Class 对象的类型就是”Class 类”, 位于 java.lang.Class; T.class: 获取类型 T 的 Class 对象, 基本类型 int 也可以通过 int.class 获取, 虽然 int 等基本类型不是类, 但是也可以 Class cl = int.class; t.getClass(): 返回的也是 Class 对象, getClass() 是 Object 类的方法; 可以用 == 判断两个obj的 class 是否来自同一个 class 对象: if(a.getClass() == A.class); JVM 通过 ClassLoader 从 .class 文件中加载并创建 class 对象 Advanced-Java.04.ClassLoader 用反射创建类// 方式1:Human human = new Human();Class c1 = human.class;Human human = (Human)c1.newInstance(); // Class.newInstance()返回的是Object类型// 方式2:Class c1 = Class.forName(\"org.xxx.Human\");Human human = (Human)c1.newInstance(); 使用反射API分析类Class, Constructor(构造方法), Field(属性), Method(方法), Modifier(作用域) Class cl = Class.forName(\"orj.xxx.ClassName\");// Class.newINstance创建类对象, 这调用类的默认构造器ClassName obj = cl.newInstance();// 获取类的public staticString modify = Modifier.toString(cl.getModifiers());// 获取构造器Constructor[] contructors = cl.getDeclaredConstructors();// 获取方法Method[] methods = cl.getDeclaredMethods();// Class Method.getReturnType(); // 获得方法返回类型// 获取类的限定String methodModiifier = Modifier.toString(method.getModifiers());// 调用任意方法Class clazz = ConcurrentHashMap.class;// 获取concurrentHashMap.containsKey()方法// 第二个参数是可变参数Class&lt;?&gt;... parameterTypesMethod method = clazz.getMethod(\"containsKey\", Object.class);// 第一参数是类实例, 如果调用static方法, 第一个参数穿null// 第二个参数是可变参数Object... argsmethod.invoke(new ConcurrentHashMap&lt;String,String&gt;(), \"ThisIsKey\"); 使用反射API调用方法Test test = (Test) clazz.newInstance();// 从class获取参数是(string)的 MethodMethod method = clazz.getDeclaredMethod(&quot;sayHello&quot;, String.class);// 这里调用的是实例方法，第一个参数是Test的实例method.invoke(test, 15, &quot;arg&quot;); Class类的方法列表 Class&lt;?&gt; forName(String className) Class&lt;?&gt; forName(String name, boolean initialize, ClassLoader loader) T newInstance(): boolean isInstance(Object) : Native方法, 注意区别instanceof二元操作符 boolean isArray(): 是否是数组, Native方法 Class&lt;?&gt; getComponentType(): 返回Class类型, 返回的Class是数组元素的类型, 示例代码: String[].class.getComponentType() Method getMethod(String name, Class&lt;?&gt;... parameterTypes): 返回指定方法名和形参的方法 以下用来获取构造器/方法/属性的列表: Constructor[] getDeclaredConstructors() Method[] getDeclaredMethods() Field[] getDeclaredFields() 数组和反射java.lang.reflect.Array类提供了数组的反射方法, 注意区分java.util.Arrays 用反射创建数组// Array.newInstance 创建数组int[] array1 = (int[])Array.newInstance(int.class, 10);/* Class.newInstance 创建数组, 这里会抛异常, 因为数组类型T[]没有默认构造函数 * 这也是Array.newInstence和Class.newInstance的区别 */Class intArrClass = array1.getClass();int[] array2 = (int[])intArrClass.newInstance(); // 异常 !! 用反射分析数组// Class.getComponentType 获取数组元素类型Class c = array.getClass().getComponentType();// Array.getLength获取长度int l = Array.getLength(array);// 非数组的类型调用getComponentType会发生什么? 返回NullClass c2 = Object.class.getComponentType(); reflect.Array类的方法列表 Object newInstance(Class&lt;?&gt; componentType, int length) reflect.Array并没有探测数组元素类型, 和数组长度的方法:(Class类提供了一个: array.getClass().getComponentType().toString()); int Array.getLength(Object arr) : 返回值是int, 数组大小最大只能是int ? … 反射的使用场景使用到 class.","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"}]},{"title":"Java Tutorials-02-集合","slug":"12.Java/Java-Tutorials.02.集合(Collection)","date":"2024-01-24T01:27:52.120Z","updated":"2024-01-24T01:27:52.121Z","comments":true,"path":"12.Java/Java-Tutorials.02.集合(Collection)/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-Tutorials.02.集合(Collection)/","excerpt":"集合类继承关系Java 核心类库提供了两大类容器, Collection(集合)和 Map, 其中 Collection 接口又派生出 List, Queue, Set 三种接口: 容器顶层接口 Collection/Map 以及主要实现类 &amp; 继承关系: java.util.Collection [I] java.util.List [I] ArrayList LinkedList* Vector Stack java.util.Queue [I] LinkedList* PriorityQueue java.util.Deque [I] LinkedList java.util.Set [I] TreeSet* HashSet* LinkedHashSetjava.util.Map [I] TreeMap* HashMap* LinkedHashMap","text":"集合类继承关系Java 核心类库提供了两大类容器, Collection(集合)和 Map, 其中 Collection 接口又派生出 List, Queue, Set 三种接口: 容器顶层接口 Collection/Map 以及主要实现类 &amp; 继承关系: java.util.Collection [I] java.util.List [I] ArrayList LinkedList* Vector Stack java.util.Queue [I] LinkedList* PriorityQueue java.util.Deque [I] LinkedList java.util.Set [I] TreeSet* HashSet* LinkedHashSetjava.util.Map [I] TreeMap* HashMap* LinkedHashMap Collection 接口Collection 接口方法: add(): ArrayList 和 LinkedList 都是 append to end remove(Object): 对于 List, remove(obj)是遍历全部元素，找到 obj.equals 的元素并删除，对于 HashSet，remove(obj) 直接调用了 hashmap.remove(obj) contains(Object): 对于 List, contains 需要 O(N)遍历, 对于 HashSet, contains 调用的是 hashmap.containsKey() containsAll(Collection&lt;?&gt; c): 不是测试是否包含连续的集合, 比如 String.indexOf 那样 size(): toArray(): 生成数组 iterator(): 返回迭代器 Iterator&lt;E&gt;, 它具有 next()方法, 用于每次返回一个元素, 直到循环器中元素穷尽: 从 Object 继承的equals(), hashCode()等… ListList 接口常用方法: add(int index, E element):Inserts the specified element at the specified position in this list (optional operation). addAll(Collection&lt;? extends E&gt; c):Appends all of the elements in the specified collection to the end of this list, in the order that they are returned by the specified collection’s iterator (optional operation). contains(Object o):Returns true if this list contains the specified element. containsAll(Collection&lt;?&gt; c):Returns true if this list contains all of the elements of the specified collection. retainAll(Collection&lt;?&gt; c):Retains only the elements in this list that are contained in the specified collection (optional operation). sort(Comparator&lt;? super E&gt; c):Sorts this list according to the order induced by the specified Comparator. subList(int fromIndex, int toIndex):Returns a view of the portion of this list between the specified fromIndex, inclusive, and toIndex, exclusive. ArrayListArrayList 内部是 Object[] 数组实现, 随机访问性能好, 插入/删除代价较大, iterator 是整数封装. ArrayList 实现了 List 接口: iterator(), listIterator(), listIterator(index) add(E), add(index,E), addAll(Collection) remove(E), remove(index), removeAll(Collection) set(index,E) sort(Comparator&lt;? super E&gt; c): 实际调用了Arrays.sort() subList(start,end): 返回的并不是 ArrayList ,而是 ArrayList 的一个视图, 对于 SubList 的所有操作最终会反映到原列表上。 retainAll(Collection) 保留 ArrayList 中和 Collection 中共有的元素(但会改变 ArrayList, 没有在 Collection 中的元素会从 ArrayList 里删除) Object[] toArray(): 对该方法返回的数组, 进行操作（增删改查）都不会影响原集合的数据（ArrayList 中 elementData） 使用工具类 Arrays 的 asList() 方法把数组转换成集合后, 不能使用该集合的 add / remove / clear 方法, 否则抛出 UnsupportedOperationException 异常。 说明: asList() 的返回对象是一个 Arrays 内部类,并没有实现集合的修改方法。Arrays.asList() 体现的是适配器模式,只是转换接口,后台的数据仍是数组。 ➤ add 方法和扩容: 如果使用默认构造 ArrayList(), 数组大小是 0, 第一次调用 add，进行第一次扩容，数组容量扩容到 DEFAULT_CAPACITY（10） add 方法的逻辑： 先判断 size + 1 （size 是当前 ArrayList 包含的元素个数）是否大于数组容量 如果大于，则先扩容数组，新的数组大小 = 原数组 1.5 倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); 新添加的元素放入数组 所以 ArrayList 的扩容机制是：当原数组满了, 下次再 add 时先扩容 如果用默认构造创建的 ArrayList, 每次扩容后的大小是: 10, 15, 22, 33, 49 … 如果在构造 ArrayList 时就指定了初始大小为 N, 每次扩容后大小都是 1.5 倍 @ref: notes/ArrayList源码分析.md at master · wardseptember/notes · GitHub LinkedList链表实现, 随机访问性能差, 插入/删除较快, iterator 是引用封装.LinkedList 同时实现了 List, Queue, Deque 接口: add(E), add(index,E), addAll(Collection) poll(), offer(E) … 所有 Queue 接口的方法 addFirst(E), addLast(E), offerFirst(E), offerLast(E) … 所有 Deque 接口的方法 VectorVector 类实现了一个动态数组。功能和 ArrayList 很相似，但是两者是不同的： Vector 是线程安全，其方法都是 synchronized 修饰 Vector 包含了许多传统的方法，这些方法不属于 Collection Vector 是 @Deprecated 的，如果不需要线程安全可以用 ArrayList 替代，如果读多写少可以用 CopyOnWriteArrayList 替代 StackStack 是栈结构，先入后出 主要方法： push() 入栈, pop() 弹出栈顶部元素, peek() 获取栈顶但不弹出顶部元素 Stack 实际就是对 Vector 包装了一层, 所以也是 synchronized 同步 Stack 同样也是弃用类，如果要使用栈功能，推荐使用 Deque（双端队列）代替 Queue &amp; Deque➤ Queue 接口： offer , add: 添加元素到队列尾部.当队列满时, offer 返回 false, add 抛出异常. poll , remove: 返回队列头部的元素, 并移除出这个元素.当队列为空时, poll 返回 false, remove 抛出异常. peek , element: 返回队列头部的元素但不移除它.当队列空时, peek 返回 false, element 抛出异常. ➤ Deque 接口： offerFirst, offerLast : 添加元素到队列, 失败返 false addFirst, addLast : 添加元素到队列, 失败抛异常 pollFirst, poolLast : 返回并移出元素, 失败返 false removeFirst, removeLast : 返回并移出元素, 失败抛异常 peekFirst, peekLast : 返回但不移出, 失败返 false elementFirst, elementLast : 返回但不移出, 失败抛异常 LinkedList &amp; ArrayDeque LinkedList: 内部是一个双向链表, 同时实现了 Deque 和 Queue 接口, 它是唯一一个允许放入 null 的 Queue； 因为是链表实现，所以没有大小限制； LinkedList 不是线程安全的，如果想使 LinkedList 变成线程安全的，可以调用静态类 Collections 类中的 synchronizedList 方法：List list=Collections.synchronizedList(new LinkedList(...)); ArrayDeque: 以循环数组实现的双向 Queue，使用默认构造函数初始大小是 16，如果构造时指定大小，会指定为大于此长度的最小 2 的幂倍数；注 1 ArrayDeque 有 head 和 tail 两个引用，分别用于在队列头 &amp; 队列尾的增/删； 如果队尾的下标追上队头，说明数组所有空间已用完，进行双倍的数组扩容。 旧版本的 ArrayDeque 在构造时，会根据用户的构造大小重新计算数组大小，但新版本 JDK12 中已经不这样做了： // 找到大于需要长度的最小的2的幂整数private void allocateElements(int numElements) &#123; // MIN_INITIAL_CAPACITY为8 int initialCapacity = MIN_INITIAL_CAPACITY; if (numElements &gt;= initialCapacity) &#123; initialCapacity = numElements; initialCapacity |= (initialCapacity &gt;&gt;&gt; 1); initialCapacity |= (initialCapacity &gt;&gt;&gt; 2); initialCapacity |= (initialCapacity &gt;&gt;&gt; 4); initialCapacity |= (initialCapacity &gt;&gt;&gt; 8); initialCapacity |= (initialCapacity &gt;&gt;&gt; 16); initialCapacity++; if (initialCapacity &lt; 0) // Too many elements, must back off initialCapacity &gt;&gt;&gt;= 1; // Good luck allocating 2^30 elements &#125; elements = new Object[initialCapacity];&#125; PriorityQueue PriorityQueue 是用二叉堆实现的优先级队列，出队列的顺序不是按照 FIFO , 而是最小的元素先出队（小顶堆）。插入的元素必须实现 Comparable, 或者在 PriorityQueue 构造器传入 Comparator； 因为需要对元素进行比较，所以 PriorityQueue 不允许 null 元素； PriorityQueue 的方法： 入队：add、offer 方法，如果失败，add 抛异常，offer 返回 false，复杂度 O(logN) 获取队头：element、peek 返回堆顶最小的元素，但不删除队头（堆顶），复杂度 O(1) 出队：remove、poll 返回并删除队头（堆顶）最小的元素，复杂度 O(logN) PriorityQueue 是通过数组实现二叉堆，数组可以自动扩容，可以认为是无界队列 PriorityQueue 的实现 @ref: Java中PriorityQueue详解 - geekerin - 博客园 线程安全的队列J.U.C 包提供了线程安全的队列，阻塞/非阻塞 两大类, 详见 Java-并发.05d.JUC-Collections: 阻塞：ArrayBlockingQueue, LinkedBlockingQueue, LinkedBlockingDeque； 非阻塞： ConcurrentLinkedQueue , ConcurrentLinkedDeque； SetSet 是不能包含重复的元素的集合, Set 接口常用方法: add(E e) addAll(Collection&lt;? extends E&gt; c) contains(Object o) containsAll(Collection&lt;?&gt; c) retainAll(Collection&lt;?&gt; c) toArray() HashSetHashSet 是一个没有重复元素的集合. 元素并没有以某种特定顺序来存放,HashSet 内部实现是使用了 HashMap 的transient HashMap&lt;E,Object&gt; map, add(E)方法实际调用的是hashMap.put(e,PRESENT) @ref: Java 集合系列16之 HashSet详细介绍(源码解析)和使用示例 LinkedHashSetLinkedHashSet 可以按照插入顺序对元素进行遍历.LinkedHashSet 继承了 HashSet, 内部是基于 LinkedHashMap 来实现的. 可以在 LinkedHashSet 构造器看出来： HashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;E,Object&gt;(initialCapacity, loadFactor);&#125; TreeSetTreeSet 是基于 TreeMap 实现的（TreeMap 基于红黑树 ）. TreeSet 中的元素支持 2 种排序方式：Item 实现 Comparable 接口, 或者根据创建 TreeSet 时提供的 Comparator 进行排序. 这取决于使用的构造方法. TreeSet 的 add、remove 和 contains 方法的时间复杂度是 O(logn). class Item implements Comparable&lt;Item&gt; &#123; int val; public int compareTo(Item t) &#123; /* return 0; 相等 return 1; this 大 return -1; 比较的更大 */ if(this.val &gt; t.val) return 1; else if(this.val &lt; t.val) return -1; else return 0; &#125;&#125;public class TreeSetTest &#123; public static void main(String[] args) &#123; Set&lt;Teacher&gt; treeSet = new TreeSet&lt;Item&gt;(); treeSet.add(new Item(3)); treeSet.add(new Item(1)); treeSet.add(new Item(2)); //遍历输出: Iterator itTSet = treeSet.iterator(); while(itTSet.hasNext()) System.out.print(itTSet.next() + \"\\t\"); &#125;&#125; @ref: Java 集合系列17之 TreeSet详细介绍(源码解析)和使用示例 Iterator: 迭代器 Iterator 接口的方法 hasNext: 返回 true 或 false next: 迭代器后移一次之后, 回迭代器前面的元素 remove: 删除上次 next()返回的, 所以新创建迭代器之后, 必须先 next 一次才能 remove. 一次 remove 之前必须有一次 next, 不能连续调用 remove; add: Iterator 接口没有 add, 但 ArrayList 和 LinkedList 的内部 Itr 都实现了 add. 在当前迭代器之前插入. 如果创建了迭代器后立刻 add, 则是插入到首位. ArrayList 的 Iterator: 属性int cursor和int lastRet分别用来记录”下次 next 方法要返回的元素位置” 和”上次 next 方法返回的”, 初始值分别是 0和-1; 创建迭代器: 方法 1: ArrayList.iterator() 方法 2: ArrayList.listIterator(), 返回的迭代器有add(Ele)方法用于插入新元素; How to iterate collection// 1for(Iterator&lt;String&gt; itr = collection.iterator(); i.hasNext();) &#123; System.out.print(itr.next());&#125;// 2for(int i = 0; i&lt;list.size(); i++)&#123;&#125; 集合泛型算法区别 Collection &amp; Collections &amp; Arrays 常用的几种 package： java.util.Collection&lt;E&gt; 是一个泛型接口; java.util.Collections 是一个集合工具类, 提供一些操作 Collection 集合的通用方法; java.utils.Arrays 也是一个集合工具类, 提供操作数组的通用方法, 例如 merge, sort 等; java.lang.reflect.Array 类提供了数组的反射方法; 图-Collection 类 vs Collections 类: 排序操作（主要针对 List 接口相关） reverse(List list)：反转指定 List 集合中元素的顺序 rotate(List list, int distance)：将所有元素向右移位指定长度, 如果 distance 等于 size 那么结果不变 shuffle(List list)：对 List 中的元素进行随机排序（洗牌）,实现很简单：遍历 list 每个元素，每次生成一个随机数，将当前元素换入随机数对应的下标，需要 list 继承自 RandomAccess 接口才可以 shuffle（ArrayList 可，LinkedList 不可） sort(List list)：对 List 里的元素根据自然升序排序，JDK 里没有使用快排，而是 merge sort 或 tim sort（稳定排序） sort(List list, Comparator c)：自定义比较器进行排序 swap(List list, int i, int j)：将指定 List 集合中 i 处元素和 j 出元素进行交换 如果要使用 Collections.sort, 则要求集合内存放的类型必须实现 Comparable 接口 查找和替换（主要针对 Collection 接口相关） binarySearch(List list, Object key)：使用二分搜索法, 以获得指定对象在 List 中的索引, 前提是集合已经排序 fill(List list, Object obj)：使用指定对象填充 frequency(Collection Object o)：返回指定集合中指定对象出现的次数 max(Collection coll)：返回最大元素 max(Collection coll, Comparator comp)：根据自定义比较器, 返回最大元素 min(Collection coll)：返回最小元素 min(Collection coll, Comparator comp)：根据自定义比较器, 返回最小元素 replaceAll(List list, Object old, Object new)：替换 Map 接口Map 不是继承 Collection 接口, 也没有继承 Iterable 接口, Map 接口提供的方法: put(k,v), get(k), containsKey(k), containsValue(v) remove(k), replace(k,v 1,v 2) HashMap HashMap 是一个散列表, 它存储的内容是键值对(key-value)映射. HashMap 继承于 AbstractMap, 实现了 Map、Cloneable、java.io.Serializable 接口. HashMap 的实现不是同步的, 这意味着它不是线程安全的. 它的 key、value 都可以为 null. 此外, HashMap 中的映射不是有序的. 初始化HashMap 几个重要成员: Node[] table; // 桶float loadFactor; // 负载因子int threshold; // 等于 table.length x loadFactor, 所能容纳的 key-value 对极限int modCount; // 记录 HashMap 内部结构发生变化的次数int size; // HashMap 当前容纳键值对的数量 length: 桶数组长度 (默认值是16) loadFactor：为负载因子(默认值是0.75)，所以默认构造创建的 HashMap threshold = 12，超过这个数就要扩容 初始化桶数组： static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; // 判断是否超过最大容量&#125; 入参cap即构造时指定的初始大小，cap-1之后使用了无符号右移，然后进行或运算，将n-1得到的值转成2进制之后，从1的最高位开始将低位全部转化为1，再加1之后就可以得到一个2^n的数（初始桶数组是2的N次幂） 以后每次需要扩容时，桶数组都 double（桶数组大小仍保证是2的N次幂） put &amp; get➤ put(Key, Val) 函数大致的实现为: 计算 Key 的 hashCode, 创建新的 Node 对象 new Node(hash, key, value, null) ， Node 是 HashMap 的一个内部类，实现了 Map.Entry 接口，Node 对象中存储存储了 hashCode, Key, Val 然后再计算 Node 在数组里的 index （index = table.length-1 &amp; Key.hash）; 如果没碰撞(table[index] == null), 把 node 直接放到 table 数组里: table[index]=node； 如果碰撞了(table[index] != null), 则判断\btable[i]的首个元素的 key 是否 hashCode 相同 &amp;&amp; key equals 为真; 如果二者的 Key 是 equals 的, 说明 Key 相等，需要覆盖掉旧的 value; 如果二者的 Key 不是 equals 的, 说明这里发生了冲突，Node 插入到 \btable[i] 的链表里, 所以链表里保存是 “Key 的 hashCode 相同, 但 Key 对象不 equals 的 Node”; 如果此处 table[i] 发生多次碰撞, 导致链表过长(大于等于 TREEIFY_THRESHOLD, 8), 就把这条链表转换成红黑树； 如果 map 内的元素总数超过 threshold( = table.length x loadFactor), 就要 resize（扩容） 上面提到了 table[index]在哈希冲突时候, 会把 table[index]处理成链表, 当链表过长的时候, 链表的遍历性能是 O(n), 很差, 所以当链表长度&gt;=8 时, 转成查找效率更高的红黑树; ➤ get(k) 函数的实现: 省略了从 k 计算出 index 的步骤 计算出 index 后，接下来是判断 \btable[index] 保存的是链表 or 红黑树，然后遍历链表 or 树, 判断 Node.key 是否 equal, 如果是, 则返回该节点; 扩容扩容后的 HashMap 容量是之前的两倍，扩容后，每个 Node 都要重新确认位置，原来在同一条链表（or 红黑树）上的 Node，可能会分配在 newTable[] 的不同位置上。 解决哈希冲突上面也提到了，JDK 中的 HashMap 对于冲突的 Node 使用了链表存储（1.8 新增红黑树）； 其他解决哈希表冲突的方式有：开放定址、再哈希、链表：@ref [[../19.Algorithm/Alg.13.数据结构-散列表]] Set 视图获取 HashMap 的 Set 视图: Set&lt;Map.Entry&lt;K, V&gt;&gt; entrySet(), 返回类型是 EntrySet extends AbstractSet&lt;Map.Entry&lt;K,V&gt;&gt;, EntrySet 的方法: size(): 直接返回 HashMap 的 size forEach: 原型为 forEach(Consumer&lt;? super Map.Entry&lt;K,V&gt;&gt; action) EntrySet 的用途之一是遍历： for (Map.Entry&lt;String, String&gt; entry : map.entrySet()) &#123; // entry.getKey() // entry.getValue()&#125; 其实现在于 nextNode，每个 JDK 版本方法名有变动，但 forEach 的实现都类似：遍历 table[] 数组找到！=null 的节点: final Node&lt;K,V&gt; nextNode() &#123; Node&lt;K,V&gt;[] t; Node&lt;K,V&gt; e = next; if (modCount != expectedModCount) throw new ConcurrentModificationException(); if (e == null) throw new NoSuchElementException(); if ((next = (current = e).next) == null &amp;&amp; (t = table) != null) &#123; do &#123;&#125; while (index &lt; t.length &amp;&amp; (next = t[index++]) == null); &#125; return e; &#125; 其他细节为什么桶数组大小是 2^N？➤ 为什么 table[] 大小是 2 的 N 次方（一定是合数）？ @ref: Java 8系列之重新认识HashMap - 美团技术团队在 HashMap 中，哈希桶数组 table 的长度 length 大小必须为2的 n 次方(一定是合数)，这是一种非常规的设计，常规的设计是把桶的大小设计为素数。相对来说素数导致冲突的概率要小于合数，具体证明可以参考这篇文章，Hashtable 初始化桶大小为 11，就是桶大小设计为素数的应用（Hashtable 扩容后不能保证还是素数）。HashMap 采用这种非常规设计（2 的 N 次方，扩容 double），主要是为了在定位哈希桶和扩容时做优化：哈希不再简单用 Obj.hash，而是让 hash 高位也尽量参与运算，定位哈希桶不再简单用 mod 而是位移，这种定位方式也给扩容是的 rehash 带来了更高的效率。 ConcurrentHashMap 在计算 table 长度（保证为 2 的 n 次方）、计算 Key 在的 index、扩容等等机制是完全一样的 两种 HashMap 的桶数组的 length 都是2 的 N 次方，通过以下函数保证： private static final int tableSizeFor(int c) &#123; int n = -1 &gt;&gt;&gt; Integer.numberOfLeadingZeros(c - 1); return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; &#125; 桶大小 length = 2 的 N 次方，转换为二进制，都是如 1000 0000 这种形式：高位是 1，其他位为0； 然后计算 key 在桶数组的位置，使用的是 hash &amp; length-1 ，length-1 后，意味着高位是 0，其他位都是 1， HashMap 的扩容采用 double 桶数组的方式，所以扩容前 vs 扩容后的 length-1，区别是增加了一个最高位的 1，对于同一个 hash 值，所以扩容前 vs 扩容后的 hash &amp; length-1 只有 2 种可能：元素的位置要么是在原位置，要么是在原位置再+ oldLength 的位置； 所以扩容后，对每个元素进行 rehash 可以减少很多工作量，只需要判断一下原 hash 对应的高位是 0 还是 1，是0的新位置不变，是1的话，新索引变成“原位置+oldLength”，下图为16扩充为32的 resize 示意图，可以看到原 index=15上所有的元素，在新数组的位置要么是 15，要么是 15+ 16： 所以这种设计让 rehash 变得更简单，也有利于 ConcurrentHashMap 并发的扩容； 为什么加载因子是 0.75？➤ 为什么是 loadFactor 是 0.75? 在理想情况下，使用随机哈希码，在扩容阈值（加载因子）为 0.75 的情况下，节点出现在频率在 Hash 桶（表）中遵循参数平均为 0.5 的泊松分布。 @ref 泊松分布和指数分布：10分钟教程 - 阮一峰的网络日志 LinkedHashMap LinkedHashMap 继承自 HashMap, 继承了 HashMap 大部分方法的实现，不同的是 LinkedHashMap 的节点（Entry），包含了 before、after 两个引用，以实现双向链表；在 LinkedHashMap 中也有 head 和 tail 两个成员表示双向链表的头和尾； LinkedHashMap 还包含一个重要的成员 accessOrder, 如果设置为 true 表示迭代顺序 = 访问顺序，如果设置为 false 表示迭代顺序 = 插入顺序； 访问顺序：get 和 put 操作后，都会把 Entry 插入到队尾 插入顺序：put 操作后，把会把 Entry 插入到队尾 LinkedHashMap 在保留 HashMap 的查找效率的同时, 保持元素输出的顺序和输入时的顺序相同, 并提供了元素的 LRU 访问（访问顺序）. 参考: LinkedHashMap内部实现 @ref TreeMapTreeMap 是一个有序的 key-value 集合, TreeMap 根据 Key 的自然顺序进行排序, 或者根据 TreeMap 构造器提供的 Comparator 进行排序.内部是基于红黑树（Red-Black tree）的实现.TreeMap 的基本操作 containsKey、get、put 和 remove 的时间复杂度是 log(n). 基本用法：public static void main(String[] args) &#123; Map&lt;Item, Integer&gt; map = new TreeMap&lt;&gt;(new Comparator&lt;Item&gt;() &#123; public int compare(Item i1, Item i2) &#123; if (i1.score == i2.score) return 0; return i1.score.compareTo(i2.score); &#125; &#125;); map.put(new Item(10), new Object()); map.put(new Item(12), new Object()); map.put(new Item(13), new Object()); for (Item key : map.keySet()) &#123; System.out.println(key); &#125; System.out.println(map.get(new Item(10)));&#125;class Item &#123; public int score;&#125; TreeMap 实现了 SortedMap 接口，意味着它可以对插入的元素进行排序public interface SortedMap&lt;K,V&gt; extends Map&lt;K,V&gt; &#123; //返回元素比较器。如果是自然顺序，则返回null； Comparator&lt;? super K&gt; comparator(); //返回从fromKey到toKey的集合：含头不含尾 java.util.SortedMap&lt;K,V&gt; subMap(K fromKey, K toKey); //返回从头到toKey的集合：不包含toKey java.util.SortedMap&lt;K,V&gt; headMap(K toKey); //返回从fromKey到结尾的集合：包含fromKey java.util.SortedMap&lt;K,V&gt; tailMap(K fromKey); //返回集合中的第一个元素： K firstKey(); //返回集合中的最后一个元素： K lastKey(); //返回集合中所有key的集合： Set&lt;K&gt; keySet(); //返回集合中所有value的集合： Collection&lt;V&gt; values(); //返回集合中的元素映射： Set&lt;Map.Entry&lt;K, V&gt;&gt; entrySet();&#125; TreeMap 实现了NavigableMap接口，意味着它支持一系列的导航方法。比如返回有序的key集合public interface NavigableMap&lt;K,V&gt; extends SortedMap&lt;K,V&gt; &#123; //返回小于key的第一个元素： Map.Entry&lt;K,V&gt; lowerEntry(K key); //返回小于key的第一个键： K lowerKey(K key); //返回小于等于key的第一个元素： Map.Entry&lt;K,V&gt; floorEntry(K key); //返回小于等于key的第一个键： K floorKey(K key); //返回大于或者等于key的第一个元素： Map.Entry&lt;K,V&gt; ceilingEntry(K key); //返回大于或者等于key的第一个键： K ceilingKey(K key); //返回大于key的第一个元素： Map.Entry&lt;K,V&gt; higherEntry(K key); //返回大于key的第一个键： K higherKey(K key); //返回集合中第一个元素： Map.Entry&lt;K,V&gt; firstEntry(); //返回集合中最后一个元素： Map.Entry&lt;K,V&gt; lastEntry(); //返回集合中第一个元素，并从集合中删除： Map.Entry&lt;K,V&gt; pollFirstEntry(); //返回集合中最后一个元素，并从集合中删除： Map.Entry&lt;K,V&gt; pollLastEntry(); //返回倒序的Map集合： java.util.NavigableMap&lt;K,V&gt; descendingMap(); NavigableSet&lt;K&gt; navigableKeySet(); //返回Map集合中倒序的Key组成的Set集合： NavigableSet&lt;K&gt; descendingKeySet(); java.util.NavigableMap&lt;K,V&gt; subMap(K fromKey, boolean fromInclusive, K toKey, boolean toInclusive); java.util.NavigableMap&lt;K,V&gt; headMap(K toKey, boolean inclusive); java.util.NavigableMap&lt;K,V&gt; tailMap(K fromKey, boolean inclusive); SortedMap&lt;K,V&gt; subMap(K fromKey, K toKey); SortedMap&lt;K,V&gt; headMap(K toKey); SortedMap&lt;K,V&gt; tailMap(K fromKey);&#125; 为什么采用红黑树[[../19.Algorithm/Alg.12.数据结构-树]] HashTable HashTable 的方法都是采用了synchronized同步. 高并发场景下不推荐使用 HashTable, 应该使用java.util.concurrent.ConcurrentHashMap替代. WeakHashMap这种 Map 通常用在数据缓存中.它将键存储在 WeakReference 中, 就是说, 如果没有强引用指向键对象的话, 这些键就可以被垃圾回收线程回收, 实现参考 @ref: Java-Tutorials.13.引用(Reference) How to iterate map// 1:for (Map.Entry&lt;String, String&gt; entry : map.entrySet()) &#123; // entry.getKey() // entry.getValue()&#125;// 2for (String key : map.keySet()) &#123; //map.get(key);&#125;// 3Iterator it = map.entrySet().iterator();while (it.hasNext()) &#123; Map.Entry entry = (Map.Entry)it.next(); // entry.getKey(), entry.getValue()&#125; fail-fast几乎所有的 Java 容器都有 modCount ，这是为了实现 iterator 的 fail-fast， 无论是 add()、remove()，还是 clear()，只要涉及到修改集合中的元素个数时，都会改变 modCount 的值。 线程 a”创建了 arrayList 的 Iterator，建立 expectedModCount = modCount（当时的 modCount值） 当线程 a 检测到 modCount 最新值不等于 expectedModCount，抛出 ConcurrentModificationException，产生fail-fast事件 @ref: http://wangkuiwu.github.io/2012/02/04/collection-04-fail-fast/","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"},{"name":"集合","slug":"集合","permalink":"https://beefyheisenberg.github.io/tags/集合/"}]},{"title":"Java Tutorials-01-基础","slug":"12.Java/Java-Tutorials.01.基础","date":"2024-01-24T01:27:52.114Z","updated":"2024-01-24T01:27:52.115Z","comments":true,"path":"12.Java/Java-Tutorials.01.基础/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Java-Tutorials.01.基础/","excerpt":"数据类型基本数据类型Java的基本类型有: char(2字节), byte(1字节), short(2字节), int(4字节), long(8字节), float(4字节), double(8字节), boolean(-),Java没有bit类型, 但可以使用BitSet类代替. byte: 1字节, 范围-128~127 short: 2字节, 范围-32768~32767, 为什么最小是-32768 ? int/long: 100L表示long类型, 0x/0/0b前缀分别表示16/8/2进制 如果long l = 3600 * 24 * 30 * 1000，1000后面不加L，右边会按int计算并产生溢出 float/double: 3.14F表示float类型, 3.14和3.14D都表示double char: 单引号, ‘\\u2122’或’A’ 浮点数的比较","text":"数据类型基本数据类型Java的基本类型有: char(2字节), byte(1字节), short(2字节), int(4字节), long(8字节), float(4字节), double(8字节), boolean(-),Java没有bit类型, 但可以使用BitSet类代替. byte: 1字节, 范围-128~127 short: 2字节, 范围-32768~32767, 为什么最小是-32768 ? int/long: 100L表示long类型, 0x/0/0b前缀分别表示16/8/2进制 如果long l = 3600 * 24 * 30 * 1000，1000后面不加L，右边会按int计算并产生溢出 float/double: 3.14F表示float类型, 3.14和3.14D都表示double char: 单引号, ‘\\u2122’或’A’ 浮点数的比较浮点数(基本类型)之间是否相等不能用==来比较，浮点数(包装数据类型)不能用 equals 来判断。 // 反例1:float a = 1.0F - 0.9F; float b = 0.9F - 0.8F;if (a == b) &#123; // 预期进入此代码块，执行其它业务逻辑 // 但事实上 a==b 的结果为 false&#125;// 反例2:Float x = Float.valueOf(a);Float y = Float.valueOf(b);if (x.equals(y)) &#123; // 预期进入此代码块，执行其它业务逻辑 // 但事实上 equals 的结果为 false&#125;// 正例:float b = 0.9F - 0.8F; float diff = 1e-6F;if (Math.abs(a - b) &lt; diff) &#123; System.out.println(\"true\");&#125; BitSetBitSet bits = new BitSet(16); // 初始大小对性能的影响bits.set(index, true);bits.get(index) 包装器包装器API基本类型对应包装器为 Character, Byte, Short, Integer, Long, Float, Double, 包装器与基本类型互转: Integer ii = Integer.valueOf(1);int i = ii.intValue();/* Integer 可以直接与int比较 */if(ii == i) &#123; // yes&#125;// String &lt;-&gt; intString s = String.valueOf(1);int i2 = Integer.parseInt(\"1011\");// 坑if(new Long(1).equals(1)) &#123; printf(\"true\");&#125;/*上面并没有打印出True, 因为`equals(obj)`方法自动把int的1装箱为\"Integer\"类型,在equals里第一步check类型就返回false了:(*/ Integer 的相等比较： 如果比较 2 个 Integer 的值，需要用 equals 而不是 == Float 的相等比较： 计算 abs(f1 - f2) ，然后与一个极小 diff 比较 Integer 和 Long 不同类型慎用 equals！详见 Long.equals 的解析 Double类的一些方法: Double.compareTo(Double) : 大于小于直接比较, =的判断是把double转成一个LongBit? Native方法, 需要看一下浮点数的内存 isNaN() 返回true表示不是正常数字, 比如除以0, 负数的平方根. 代码里如何得到一个NaN? 装箱拆箱的实现▶ 何时发生装箱/拆箱: 什么是自动装箱: int → Integer, 实际调用 Integer.valueOf(int) 什么时候发生自动装箱: 创建对象: Integer i = 3 方法参数传递: void method(Integer i) 什么是自动拆箱: Integer → int, 实际调用 integer.intValue() 什么时候发生自动拆箱: 加法: integer1 + integer2, 先拆箱转换为int … 需要注意的是if (integer3 == integer1 + integer2), 首先右边1和2拆箱为int, 变成if (integer3 == int), 这时不是发生(int→integer)装箱, 而是继续拆箱, 最终比较的是if (int == int) ▶ Integer/Long自动装箱 valueOf(x)的实现 Integer/Long 的 valueOf(i) 使用了享元模式, 在 static 代码块中预先创建了范围 -128~127 的对象, 缓存在数组型的 Cache（Integer[] cache）里; 当调用valueOf(i)的时候，先判断i的范围是否是-128~127，如果是则直接从cache里返回对象，减少类的创建; 下面创建Integer的效率, 前者可能更高: Integer i = 3 , Integer i = new Integer(3); 为什么? Float/Double的valueOf(f)没有使用享元模式; ▶ 代码example Long l1 = Long.valueOf(128);Long l2 = Long.valueOf(128);System.out.println(\"l1==l2 \" + (l1==l2));Long l3 = Long.valueOf(127);Long l4 = Long.valueOf(127);System.out.println(\"l3==l4 \" + (l3==l4));Integer i1 = new Integer(40);Integer i2 = new Integer(40);Integer i3 = 0;System.out.println(\"i1==i2 \" + (i1==i2));System.out.println(\"i1==i2+i3 \" + (i1==i2+i3)); 输出: false, true, false, true @ref Java 自动装箱与拆箱的实现原理 - 简书 慎用 Long.equals()以下代码会输出false: System.out.println(new Long(1).equals(1)); 原因是，Long.equals(Object)，进入equals是会对整形参数1进行一次装箱，i被包装成Integer(1)，和其他类的equals行为一样，Long.equals(Integer(1))会先判断输入参数的类型if (obj instanceof Long)，这里就返回false了。 所以用Long的正确条例是，Long的方法传参数都用明确的long型：new Long(1L), longObj.equals(1L)。 BigInteger, BigDecimalJava还提供了两个用于大数运算的类: BigInteger(任意大整数)和BigDecimal(任意大小的带小数点的数字). 常用方法: add(), subtract(), multiply(), divide() BigInteger big1 = new BigInteger(\"99\");BigInteger big2 = BigInteger.valueOf(99);BigInteger big3 = big1.add(big2).multiply(big2); BigDecimal 的等值比较应使用 compareTo()方法，而不是 equals()方法。 说明:equals()方法会比较值和精度(1.0 与 1.00 返回结果为 false)，而 compareTo()则会忽略精度。 数组 Java中数组本质上也是对象, 拥有所有Object的方法, 不同于int/double等基本类型. Java 对象在内存里前几个字节是”对象头”, 非数组对象的的对象头占用2字节, 数组对象的对象头占用3字节, 多的1字节用来存储对象长度 数组可以通过属性 length 获取长度, 遍历数组: for(int i = 0; i &lt; array.length; i++) 数组创建后会记住元素类型和大小, 所以: A[] 类型的数组可以强转换为 Object[], 但不能反过来执行; 用 new A[1] 方式创建的数组, 只能向内存储 A 类型或者 A的派生类 的对象, 试图存入其他类型对象会抛 ArrayStoreException; 数组创建后不再能改变长度; ▶ 数组如果作为形参 or 返回值, 可以使用Object, 而不是用Object[] : // 反射方式创建新数组public static Object copyOfGenericArray(Object src, int newLength) &#123; assert newLength&gt;0 : \"assert length failed\"; if(!src.getClass().isArray()) &#123; return null; &#125; Class clz = src.getClass().getComponentType(); Object newArray = Array.newInstance(clz, newLength); int length = Array.getLength(src); System.arraycopy(src, 0, newArray, 0, Math.min(length, newLength)); return newArray;&#125; ▶ 数组与list互转: //list -&gt; arrayList&lt;Object&gt; list = new ArrayList&lt;Object&gt;();Object[] objArray = list.toArray();// array -&gt; listList&lt;Object&gt; newList = Arrays.asList(objArray); ArraysJava核心类库有两个Arrays类: java.lang.reflect.Array: 提供了数组的反射相关方法; java.utils.Arrays: 类似Collections类, 提供了merge/sort等方法 示例代码: 用反射创建数组, 拷贝数组： // java.lang.reflect.Array创建数组int[] arr = (int[])Array.newInstance(int.class,length) // &lt;Core Java&gt; P207// 拷贝数组System.arraycopy(src[], srcPos, dest[], destPos, length);// 使用java.utils.Arrays拷贝:Object[] newArr = Arrays.copyOf(Obj[], length)// Arrays工具类还提供了sort, binarySearch, asList()Entry[] entries = new Entry[1];Object[] objs = (Object[])entries; // 向上转型数组ok java.util.Arraysjava.util.Arrays 包含了许多处理数组的实用方法： asList: 将一个数组(变长参数的语法糖实现就是数组)转变成一个List（确切的来说是 ArrayList），注意这个List是定长的，企图添加或者删除数据都会报错（java.lang.UnsupportedOperationException）. List&lt;Integer&gt; list = Arrays.asList(3,4,2,1,5,7,6);// 下面这种用法是错误的:int a[] = new int[]&#123;1,2,5,4,6,8,7,9&#125;;List list = Arrays.asList(a); sort: 对数组进行排序。适合byte,char,double,float,int,long,short等基本类型，还有Object类型（实现了Comparable接口），如果提供了比较器Comparator也可以适用于泛型。 void sort(Object[] a); // 需要类实现Comparable接口void sort(T[] a, Comparator&lt;? super T&gt; c); // 带比较器 binarySearch: 通过二分查找法对已排序（譬如经过Arrays.sort排序，且按照升序进行排序。如果数组没有经过排序，那么检索结果未知）的数组进行查找。适合byte,char,double,float,int,long,short等基本类型，还有Object类型和泛型 copyOf: 数组拷贝，并返回新数组，底层采用System.arrayCopy（native方法）实现。 copyOfRange: 数组拷贝，指定一定的范围，String str2[] = Arrays.copyOfRange(arr,1,3); equals和deepEquals: equals：判断两个数组的每一个对应的元素是否equals deepEquals：主要针对一个数组中的元素还是数组的情况 toString和deepToString : 参考equals和deepEquals hashCode和deepHashCode : hashCode：计算一个数组的hashCode. 每个元素的element.hashCode()都要参与计算 fill: 给数组赋值。填充数组。Arrays.fill(intArr, 1); Java.lang.reflect.Array施工中 枚举 Java在SE5中才添加了emum特性, 在定义一个enum时会自动创建toString()和value()方法(均是static方法), enum还支持类似Objec的私有属性,和构造; enum 类型不支持public和protected修饰符的构造方法, 因此构造函数一定要是private或 friendly的. 也正因为如此, 所以枚举对象是无法在程序中通过直接调用其构造方法来初始化的. 枚举可以出现在switch语句中, 若要判断两个枚举类型常量的值是否相等, 使用==, 或equals()都可以. 前者更好因为可以可以判断null的情况 比较两个枚举类型常量的值的大小要使用compareTo()方法. // 一个基本的枚举:public enum COLOR &#123; RED(1), GREEN(2) // GREEN后面没有分号哟...&#125;// 一个带属性和构造器的枚举:public emum ApiUrl &#123; REGIST(\"http://changyan.com/api/open/reg\",1), LOGIN(\"http://changyan.com/api/open/validate\",2), SSO(\"http://changyan.com/api/open/set-cookie\",3); // 分号 private String url; // 私有的属性 private int index; private ApiUrl(String url, int index) &#123; // 私有的构造器!!! this.url = url; this.index = index; &#125; public getUrl() &#123; ...&#125; // Getter @Override public String toString() &#123; // 重写 return this.index + \"_\" + this.name; &#125;&#125;ApiUrl apiUrl = ApiUrl.REGIST; // 初始化枚举变量System.out.print(ApiUrl.REGIST.toString()); 运算符 类实例的赋值操作 a=b 实际是把 b 这个”对象引用”指向了 a 的指向的对象, 如果 b 原来的对象的引用数为0, 在一定条件下会被 JVM 销毁. 对于基本数据类型, ==判断的是值, 而不是”是否指向同一个引用”; 用==比较Object, 如果a和b是否指向的是同一块内存则为true 判断两个字符串的内容是否相同不能用if(str1==str2), 要用str1.equals(str2)方法. 大部分jdk中的类实现了Object.equals(Object)这个方法(判断两值是否相等), 但是对于某些自定义的类要留意其equals方法, 因为Object.equals默认行为是比较引用的this==obj; hashCode和equals更多参考: (五)面向对象 左右结合Java中赋值=, 单目运算++等, 条件运算符?:是右结合, 其他都是左结合,比如x=y=z, 相当于x=(y=z) 位移运算 左移&lt;&lt; : 丢弃最高位(符号位同样丢弃), 0补最低位. 当byte和short左移时, 自动升级为int型. 数学意义: 左移n位相等于乘以2^n 右移&gt;&gt; : 高位补充符号位, 正数右移补充0, 负数右移补充1, 当byte和short右移时, 自动升级为int型. 数学意义: 右移n位相当于除以2^n 无符号右移&gt;&gt;&gt; : 无论正负, 高位补充0 无符号右移只是对32位和64位的值有意义 关于补码/反码参考脚注1 java.lang.Math abs: return v&gt;0?v:-v; sqrt: native pow: native 控制流程和语句 Java的if, for, while, do-while, if...else if和C++完全一样, 此外Java还多了foreach: for(int i : integerArray) {...} switch语句支持String类型和enum类型 方法Java 的参数传递为 值传递. 也就是说, 当我们传递一个参数时, 方法内将获得实参的一个拷贝. 基本类型(int/char 等)的参数传递, 方法内获得是一个拷贝. Java 方法对变量的修改不会影响到原变量. 对象变量在 java 中实际是一个引用（可以理解为 C++的内存地址）, 对象变量作为参数传递, 函数内获得一个引用地址的拷贝. 在函数内修改这个对象变量的值, 不会影响到函数外, 因为函数内修改的只是这个拷贝. 在函数内修改这个对象变量的成员, 会影响到函数外的对象 @ref： 这一次，彻底解决Java的值传递和引用传递 - 个人文章 - SegmentFault 思否 SwapJava对普通类型的变量 or 引用类型的变量, 都无法简单通过=赋值实现 Swap, 折中的做法有: 1)使用数组, 2)作为成员变量 public static void swap1(int[] data, int a, int b) &#123; int t = data[a]; data[a] = data[b]; data[b] = t; &#125; public static void swap2(int a, int b) &#123; this.a = b; this.b = a; &#125; 变参函数Java也支持变参函数: void foo(String[] args) &#123; //第一种形式 foreach(String arg : args) &#123;...&#125;&#125;void foo(int para, String... args) &#123; //第二种形式 // 遍历方法同上&#125; final 关键字Java 中的 final 关键字和 C++中的 const 关键字一样, 都表示不可改变. final 关键字可以修饰: 成员: 表示常量, 也可以在 final 成员定义时不给初值, 在构造方法里赋初值; 形参: 表示这个参数引用指向的内容不能被改变. 方法: 表示这个方法不能在派生类中被”覆写”(Override), 但可以被继承使用. 类中所有 private 方法都被隐式的声明为 final 的. 类: 表示这个类不能被继承, final 类中所有的方法也被隐式声明为 final 的, 设计类时候, 如果这个类不需要有子类, 类的实现细节不允许改变, 并且确信这个类不会载被扩展, 那么就设计为 final 类. final 和 abstract 这两个关键字是反相关的, final 类就不可能是 abstract 的 C++的 const 类成员和 Java 的 final 类属性: 在 C/Java 的类中, 都支持 public final int ee = 1 这样的声明+赋初值的方式, 也支持先声明再初值的方式(这种情况下, 都需要在构造函数里初值). 这样的设计的好处是可以做到一个类中 final 域在不同的对象有不同的值. private final List Loans = new ArrayList();list.add(\"home loan\"); //validlist.add(\"personal loan\"); //validloans = new Vector(); //not valid 下面总结了一些使用 final 关键字的好处: final 关键字提高了性能, JVM 和 Java 应用都会缓存 final 变量. @doubt final 变量可以安全的在多线程环境下进行共享, 而不需要额外的同步开销. 使用 final 关键字, JVM 会对方法/变量及类进行优化. 摘自《Java 编程思想》第四版第 143 页：“使用 final 方法的原因有两个。第一个原因是把方法锁定，以防任何继承类修改它的含义；第二个原因是效率。在早期的 Java 实现版本中，会将 final 方法转为内嵌调用。但是如果方法过于庞大，可能看不到内嵌调用带来的任何性能提升。在最近的 Java 版本中，不需要使用 final 方法进行这些优化了。“ static 关键字使用 static 块初始化 final 的 Map:public class Test &#123; private static final Map&lt;Integer, String&gt; myMap; static &#123; Map&lt;Integer, String&gt; aMap = ....; aMap.put(1, \"one\"); aMap.put(2, \"two\"); myMap = Collections.unmodifiableMap(aMap); &#125;&#125; 回顾 C++的 const: 可以修饰函数(修饰返回值 or 修饰形参 or 修饰类的函数成员), const int ptr; // ptr 指向的内容无法修改int const ptr; // 指针 ptr 本身的值无法被修改修饰形参: void func(const int *ptr);修饰返回值: const &amp;aaa func(void); //修饰类的函数成员: void func(int, int) const; // 函数内不能修改类成员的值 面向对象Object的一些默认方法Object obj = new Object();int hash = obj.hashCode(); // navive方法, 返回内存地址, 但String.hashCode不是这样boolean b = obj.equals(obj); // return obj==this;Class cl = obj.getClass(); // navive方法Class cl2 = Object.class; // 通过 类名.class获取class实例Object newObject = obj.clone(); // error ! clone是protected native方法 equals()Object的equals方法默认是比较引用地址. equals方法的特点: 自反性: a.eq(a)==true 对称性: if a.eq(b)==true, then b.eq(a)==true 传递性: a-&gt;b, b-&gt;c, a-&gt;c 所以伪码如下: if super.equals==false falseif this==obj trueif obj==null falseif class!=obj.class falseif [!obj instanceof this] false其他的属性比较... hashCode()hashCode()返回int类型, 返回值可以看成是对象的”消息摘要” Object 默认的 hasCode()返回的并不是内存地址, hasCode()内部调用了 native 方法, 不同的 JVM 实现可能不一样, OpenJDK 的实现如下: mark = monitor-&gt;header();hash = mark-&gt;hash();if (hash == 0) &#123; hash = get_next_hash(Self, obj);&#125; 如果第一次hashCode, 则通过get_next_hash 重新获取一个随机值, 并保存在对象头 生成 hash 的最终函数 get_next_hash，这个函数提供了 6 种生成 hash 值的方法。 0. A randomly generated number.1. A function of memory address of the object.2. A hardcoded 1 (used for sensitivity testing.)3. A sequence.4. The memory address of the object, cast to int.5. Thread state combined with xorshift (https://en.wikipedia.org/wiki/Xorshift) 那么默认用哪一个呢？根据 globals.hpp，OpenJDK8默认采用第五种方法。而 OpenJDK7 和 OpenJDK6 都是使用第一种方法，即 随机数生成器。 @ref: java默认的hashcode方法到底得到的是什么？ - 云+社区 - 腾讯云 equals() vs hashCode() 如果重新了equals方法, 就必须重写hashCode方法, 以便可以将对象插入到HashMap中(摘自Java核心技术卷1, 为什么?) 如果两个对象equals, 那么hashCode一定相同, 如果两个对象hashCode相同, 但不一定equals, 为什么? equals要依次比较每个属性的值, hashCode是对”需要比较的属性”求散列, 所以如果哈希方法不够好出现碰撞, hashCode相同但是每个属性不equals 因为HashMap插入时用Key的hashCode作为数组的下标, 所以hashCode返回必须是正int 好的hashCode方法应该对”需要比较的每个属性”充分散列 clone()Object.clone默认是浅拷贝; Cloneable接口Cloneable和Serializable 一样都是标记型接口，它们内部都没有方法和属性，implements Cloneable表示该对象能被克隆，能使用Object.clone()方法。如果没有implements Cloneable的类调用Object.clone()方法就会抛出 CloneNotSupportedException Example: public class Example implements Cloneable &#123; @Override protected Object clone() throws CloneNotSupportedException &#123; return super.clone(); &#125;&#125; Example类的 clone()默认调用了 Object.clone(), 这是一个Native方法, 默认是 浅克隆（shallow clone） 浅拷贝（浅克隆）复制出来的对象的所有变量都含有与原来的对象相同的值，而所有的对其他对象的引用仍然指向原来的对象。深拷贝（深克隆）复制出来的所有变量都含有与原来的对象相同的值，那些引用其他对象的变量将指向复制出来的新对象，而不再是原有的那些被引用的对象。换言之，深复制把要复制的对象所引用的对象都复制了一遍。 如何实现 deep clone:clone方法里要对每个引用类型的成员都调用一次 clone(), 例子: class Car implements Cloneable &#123; Wheel wheel; @Override protected Object clone() throws CloneNotSupportedException &#123; Car car = (Car)super.clone(); car.wheel = (Wheel)this.wheel.clone(); return car &#125;&#125; 使用Serializable实现深克隆（deep clone）: 略 安全的类型转换 向上转型: List&lt;Object&gt; list = new ArrayList&lt;Object&gt;(); 向下转型: ChildA child = (obj instanceof ChildA ? (ChildA)obj : null); instanceof关键字用于判断一个引用类型变量所指向的对象是否是一个类（或接口、抽象类、父类）的实例。 构造和销毁构造器(constructor):Java的构造器实际上是一个static函数, 因为在没有实例化之前就可以调用构造, 但是一般来说, static方法里不能使用this关键字, 因为this的含义是指向类实例本身的一个引用(C++的this是指向类实例自身的指针), 但是构造器这个特殊的static方法里却可以使用this关键字. 继承和构造顺序派生类被实例化时, 总是先调用super(), 即基类的默认构造方法. 在派生类的构造函数中, 也可以使用super(args...)调用指定的基类构造方法. Class A &#123; public A () &#123; super(\"parent\"); // 通过super调用基类的\"非默认构造器\" this(\"child\"); // 通过this调用Override的构造器 &#125;&#125; 默认构造方法如果一个类没有定义任何构造方法, 那么编译器会为这个类自动生成一个不带参数的默认构造方法, 销毁 Java允许在类中定义一个finalize()方法, 这个方法里可以做什么? JVM何时调用这个方法? Efftive Java中提到finalize()方法可用作”守卫方法”, 比如socket在这里做最后的关闭检查: protect void finalize() &#123; close(); super.finalize(); // 不要忘记&#125; this关键字 在调用Java的方法时, 会隐式的将”指向自身的引用”作为方法的第一个参数function(this, param), C++的this是”指向类实例自身”的指针; static方法的第一个参数则是null. 访问控制权限 没有任何权限修饰, 默认是包内可见, friendly的; 访问权限 public &gt; protected &gt; friendly &gt; private protected: 包可见, 子类可见; friendly: 包可见, 子类不可见 (没有这个关键字, 什么都不加默认是friendly); private: 只对该类型可见; 继承多重继承 Java不支持多重继承class, 但支持多重继承interface. 思考一个问题: “有两个类B1和B2继承自A. 假设B1和B2都继承了A的方法并各自进行了覆盖, 编写了自己的实现. 假设C通过多重继承继承了B1和B2, 那么C应该同时继承B1和B2的重载方法, 那么它应该继承哪个的呢？是B1的还是B2的呢？” C++中经常会掉入这个陷阱, 虽然它也提出了替代的方法来解决这个问题. 我们在Java中就不会出现这个问题. 就算两个接口拥有同样的方法, 实现的类只会有一个方法, 这个方法由实现的类编写. 动态的加载类会让多重继承的实现变得困难. 因为在C++没有Interface, 在C++中使用”虚拟继承”解决上面的问题: B1和B2去虚拟继承A: class B1 : public virtual A ,class B2 : public virtual A C多重继承B1和B2: class C : public B1, public B2 ; 抽象类和接口 含有抽象方法(abstract function)的类是抽象类(abstract class). 任何子类都必须实现抽象类的抽象方法, 或者自身也声明为抽象类; 抽象类public abstract class A, 和接口的异同: 抽象类和接口都能有自己的属性成员, 不同的是接口中的成员属性都是static和final的, 因此比较合适的做法是在interface里放置一些常量. 抽象类里还可以定义自己的方法实现, 并能被派生类继承, 但接口不能含有任何方法实现. 多态(polymorphism)多态的含义就是一个方法多种实现, 分静态和动态, 在同一个类中实现多态是通过函数重载 -Overload, 在继承中实现多态是通过运行时绑定. 在Java的继承中, 除了static和final方法(private也是final的)之外, 其他的方法都是运行时绑定的, 类的属性成员并不在多态的讨论范围内, “多态”仅仅指方法的多态. 比如基类和派生类都有field属性, 那么在派生类实例中, 将包含两个field, 通过基类.field也只能访问基类的field, 因为 属性没有多态. 类的构造方法不具备多态性, 因为类的构造器默认是static属性的, 对比C++的构造也不具备多态性(C++通过虚函数实现), 原因是构造期间尚未生成虚函数表. 在派生类中, 覆写(Override)基类的私有方法不会编译报错, 但不会照期望的执行, 结论就是: 只有非private方法才可以被派生类覆写(Override). Java 的运行时绑定，是通过 Klass 对象的 vtable 实现的 @ref: Advanced-Java.02b1.MetaSpace解析 Java 和 C++实现多态的对比 C++ Java virtual func 普通方法 virtual f()=0 abstract func() abstract class interface 接口@todo 内部类一般内部类 外部类不一定有内部类实例, 但内部类一定有对应的外部类, 内部类的成员不能是static, 也不能有static代码块(但内部类可以是static的, 嵌套类) 外部类和内部类可以 互相访问 所有成员(包括private); 外部类可以访问内部类的一切成员, 无论这个内部类是 public 还是 private 的, 无论内部类的成员是 public 还是 private 的, 外部类通过 内部类实例.成员名 访问内部类的成员; 内部类可以访问外部类的一切成员, 包括外部类的 private 成员, 访问方式是 外部类类名.this.func(), 或者也可以”直接调用”外部类的成员. 在编译成功后, 会出现这样两个class文件: Outer.class和Outer$Inner.class; 定义一个内部类: public class Outter &#123; private void show()&#123; &#125; /* * public可有可无, 默认public的内部类是包内可见, friendly * 内部类可以单独继承一个抽象类或实现一个接口 */ public class Inner implements interface &#123; public void innerShow() &#123; show(); // 可以这样调用外部类方法 &#125; &#125;&#125; 外部类如何访问内部类 内部类访问外部类属性: println(OutterClass.this.propertyName); 外部类访问内部类属性: println(inner.propertyName) // 必须先创建内部类实例inner 在拥有外部类对象之前, 是不可能创建内部类对象的, 换句话说, 其他人只能通过外部类对象才能访问内部类: Outter.Inner in = new Outter.Inner(); // ERROR! 要先创建外部类//正确的创建内部类对象:Outter out = new Outter();Outter.Inner in = out.getInner(); // 在getter里返回Inner对象// 第二种创建方式:Outter out = new Outter();Outter.Inner in = out.new Inner(); // obj.new语法 其他类如何访问内部类 public的内部类 的public成员是包可见; public的内部类 的private成员包不可见, 仅对外部类可见; 当Inner是private时, 其他类不能通过Outter.Inner in = out.getInner()或者Outter.Inner in = out.new Inner的方式创建Inner对象, 因为Inner类就是private的;但是, 如果private的Inner继承自一个Base类, 这个Base类又是包可见（Public）的, 那么可以通过Base base = out.getInner()的方式创建内部类对象, 换句话说, 这个Base是内部类的一个对外接口, 只能通过这个对外接口访问private的内部类; 以上参考: 探讨Java内部类的可见性; @ref 内部类的必要性? Java不允许多重继承, 使用内部类可以”继承”外部类的方法, 并且内部类可以独立的继承自另一个抽象类或者接口. 把实现细节放在内部类, 相当于是对外隐藏细节, 封装. 使用内部类最吸引人的原因是：每个内部类都能独立地继承一个（接口的）实现, 所以无论外围类是否已经继承了某个（接口的）实现, 对于内部类都没有影响[Think in Java] 局部内部类 &amp; 匿名类 匿名类首先要有一个Interface or 基类; 匿名类没有名字, 也没有构造方法, 没有访问修饰符; 匿名类可以访问外部的变量, 但是创建匿名类的方法参数是final的; 定义一个匿名类: /* 匿名类要有一个接口或基类 */interface Pool &#123; int getNumber();&#125;public Pool getInnerClass(final int num) &#123; /* 传入匿名类的参数要声明为final的 */ return new Pool() &#123; int number = num++; public int getNumber()&#123; return number; &#125; &#125;; /* 注意：分号不能省 */&#125; UI中大量使用的事件callback: button.setOnClickListener(new OnClickListener() &#123; @Override public void onClick(View v) &#123; &#125; &#125;); 嵌套内部类 static的内部类被称为嵌套类, 嵌套内部类不需要由外部类创建, 也就没有隐藏的外部类引用 不能调用非 static 的外部类成员, 即不能访问 Outter.this.property; 外部类初始化的时候, 不会触发嵌套内部类的初始化. 静态内部类的初始化的时机：初始化时会初始化 static 成员变量, 执行 static 代码块, JVM 会把这些操作放在一个叫 clint 的方法中执行 字符串 String是一个特殊的类, 不需要构造函数就可以创建实例String s = &quot;hello world&quot;; String的char[]是final static的, 只有一份拷贝.一旦String被创建, 字符串的内容就不可改变了 // Question: 当new一个String时, 是如何判断字符串池里是否已经有相同字符串的? 字符串的比较不能使用==: ==仍然比较的是引用, 而应该使用String.equals() String一些方法和实现 bool contains(String str) : 判断参数s是否被包含在字符串中，并返回一个布尔类型的值 int indexOf(String str, int fromIndex) : String substring(int beginIndex, int endIndex) : 该方法从beginIndex位置起，从当前字符串中取出到endIndex-1位置的字符作为一个新的字符串返回。 int compareTo(String anotherString) : 该方法是对字符串内容按字典顺序进行大小比较，通过返回的整数值指明当前字符串与参数字符串的大小关系。若当前对象比参数大则返回正整数，反之返回负整数，相等返回0。 boolean equals(Object anotherObject) : 比较当前字符串和参数字符串，在两个字符串相等的时候返回true，否则返回false。 比较引用是否相等 要比较的对象是否 instanceof String 比较数组的长度 &amp; 依次比较每个char String concat(String str) : 将参数中的字符串str连接到当前字符串的后面, 生成一个新字符串返回 String replace(char oldChar, char newChar) : 用字符newChar替换当前字符串中所有的oldChar字符，并返回一个新的字符串。 String replaceAll(String regex, String replacement) : 该方法用字符replacement的内容替换当前字符串中遇到的所有和字符串regex相匹配的子串，应将新的字符串返回。 String 不可被继承public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence 比较StringBuffer StringBuffer 和 StringBuilder 类的对象能够被多次的修改，并且不产生新的未使用对象。两者的char [] 不是final的, 可以修改; StringBuffer线程安全, 所有方法都是synchronized的; /* 比较 `String concat(String)`, `+`, 以及 StringBuffer 效率*/// 默认StringBuilder的char[]初始长度是16StringBuilder sb = new StringBuilder(1024);for (int i = 0; i &lt; 1000; i++) &#123; sb.append(\" \"); // 可以看到sb.append的实现, 每次拷贝要扩容char[], 所以StringBuilder(len)设置好初始值 // 拼接字符串使用sb.append()的代价最小, 因为不用频繁创建Object&#125;String str = new String();// concat的实现&gt;/* 计算拼接后的长度len, 创建一个char[len] * 拷贝str2的cha[] 到上面创建的数组 * 调用String(char[]) 生成了新的String对象 * 所以, 每次对String改变都会导致创建新的对象, 性能差异在这里 * */str.concat(\" \").concat(\" \");// 编译器会把下面的string + 的操作转为StringBuild, 但生成1000次StringBuilder实例, 操作符+效率差在这里String str2;for (int i = 0; i &lt; 1000; i++) &#123; str2 = str2 + \" \";&#125; String,char,byte的互转 String是由char[]存储数据, char是unicode, 用16bit(2字节)的数值表示一个char: char c = &#39;\\u554a&#39;; String和char都可以用\\u0000这种方式初始化. byte是字节, String/char转为byte[]时, 不能确定byte[]的长度, 视转换用哪种编码(GBK/UTF-8)而定. String string = \"\\u0048\\u0069\"; // Unicode对应的字符串是\"Hi\"char[] chars = string.toCharArray();System.out.printf(\"str_len= %d, arr_len= %d\", string.length(), chars.length); // 输出2 2// 获取字符串指定位置的Unicode值:int index = s.offsetByCodePoints(0, 0);System.out.println(index + \":\" + s.codePointAt(index)); // 输出72 String str = \"嘿H1\";byte[] b1 = str.getBytes(\"GBK\");byte[] b2 = str.getBytes(\"UTF-8\");char[] c = str.toCharArray();// str, b1, b2, c的length分别是? unicode编码只指定了编码值, gbk和utf8定义了如何存储编码值. 一个char存储的是16位的unicode, 范围0~0xFFFF(65535), 超过这个范围的汉字, 比如”𩄀”, 要用两个char也就是4字节表示. 如果unicode用gbk编码, 一个中文3字节, 一个英文1字节; 如果unicode用utf-8编码, 中文2字节, 英文一字节; 所以上面的输出分别是3, 5, 6, 3; 常用类String &amp; StringBuffer见 字符串 包装类见 数据类型 Math类@todo 日期类 SimpleDateFormat 不是线程安全的 JDK8 的 DateTimeFormatter 线程安全 使用 DateTimeFormatter 替换 SimpleDateFormat: 你真的会使用SimpleDateFormat吗？ - 知乎 异常处理图-Java异常类的层次结构: Error &amp; Exception在 Java 语言规范中，所有异常都是 Throwable 类或者其子类的实例。Throwable 有两大直接子类。第一个是 Error，涵盖程序不应捕获的异常。当程序触发 Error 时，它的执行状态已经无法恢复，需要中止线程甚至是中止虚拟机。第二子类则是 Exception，涵盖程序可能需要捕获并且处理的异常。 Error 是程序无法处理的, 内存不足或JVM的错误, 比如 OutOfMemoryError, ThreadDeath Exception 可由程序处理, 又分为”CheckedException”(受捡异常, 上图粉红色), 和”UncheckedException”(不受检异常, 上图蓝色) 前者是程序需要捕获并处理的异常(比如打开文件错误, 网络超时等待), 需要throws-try-catch语句显式的捕获; 后者是代码错误, 比如数组越界, 这种不需要明确throws, 如果throws了也不强制代码必须catch, 其实Error也能算是不受检异常; 继承关系Throwable Error: 也算是&quot;不受检&quot; OutOfMemoryError StackOverflowError ThreadDeath Exception: UserDefinedException: 用户自定义异常继承者Exception ClassNotFoundException: 调用Class.forName时 InstantiationException: 调用Class.NewInstance时 IOException: 有一大堆派生自IOException的异常... EOFException: 意外遇到文件或流的末尾，如果是网络IO，可能是另一端非正常关闭连接 ConnectException: connection refused connect. BindException: address already in use RuntimeException: (不受检异常) NullPointerException: 最著名的不受检异常 IndexOutOfBoundsException: 数组越界 IllegalArgumentException: 调用方法时参数异常 IllegalAccessException: 方法对类没有访问权限 ArithmeticException: 数学算数异常 ArrayStoreException: 试图向数组存入不支持的类型 ClassCastException: 调用Class.cast(Object)时 NotSerializableException: 尝试对没有声明 Serializable接口的类进行序列化 try-catch如果该异常被 catch 代码块捕获，finally 代码块则在 catch 代码块之后运行。在某些不幸的情况下，catch 代码块也触发了异常，那么 finally 代码块同样会运行，并会抛出 catch 代码块触发的异常。在某些极端不幸的情况下，finally 代码块也触发了异常，那么只好中断当前 finally 代码块的执行，并往外抛异常。 try-catch-finally中的 return// x返回多少? 会打印出什么?private static int testTryCatch() throws Exception &#123; int x = 1; try &#123; return ++x; &#125; catch (Exception e) &#123; &#125; finally &#123; ++x; &#125; return x;&#125; 结果：返回 2 如果在 try-catch-finally 3个位置分别插入 return ，代码会如何执行？需要先明白一些概念： 每个 java 方法执行时都会创建一个栈帧，栈帧中比较重要的数据结构有：操作数栈、局部变量表 局部变量表：可以认为是一个数组，里面存储了方法内出现的所有局部变量 操作数栈：存放的是运行时的指令，也是栈结构，运行的指令依次进栈，运行完后 pop 编译过程中，如果一个方法里有 finally，为了保证它一定被执行，会在任何可能的代码执行路径的出口处，增加一段 finally 代码块，例如 try 的出口处增加 finally 块，catch 的出口处增加 finally 块.. 如果不知道这一点，那么看字节码会有疑惑，为什么会出现很多重复的字节码？ 扩展阅读： 06 | JVM是如何处理异常的？ JVM 运行时数据区: 局部变量表 &amp; 操作数栈 https://developer.aliyun.com/article/825859 如果 try 语句里有 return，那么代码的行为如下（见《Java Virtual Machine Specification》的 Chapter 4. The class File Format 中，「 Exceptions and finally」）： If the try clause executes a return, the compiled code does the following: Saves the return value (if any) in a local variable. Executes a jsr to the code for the finally clause. Upon return from the finally clause, returns the value saved in the local variable. 意思是： 如果 try 语句里有 return，那么代码的行为如下：1.如果有返回值，就把返回值保存到局部变量中2.执行jsr指令跳到finally语句里执行3.执行完finally语句后，返回之前保存在局部变量表里的值 那么字节码是如何实现上面的标准描述呢？ 为了保证 finally 一定被执行，所以会在 try 块的出口处，也增加 finally 代码块字节码 字节码对于返回值的处理是这样的，如果要把 a 这个局部变量作为返回值，那么 return a 这个 java 代码，翻译为字节码是：iload_1 然后 ireturn, 解释，把局部变量 a 加载到操作数栈，然后调用 ireturn 返回之。这里的 iload_1是返回局部变量表中1的位置（假定变量 a 在局部变量表位置1） 明白了对于返回值的处理，再看字节码就会清楚一些： 0-2，是 try 中的++ 5-6是 finally 的++，注意这里++完，istore_2把 x 保存在了本地变量表2的位置 10-11 是 return 之前 iload_2 是将本地变量表位置2的数据，放入操作数栈，然后 ireturn 返回 转自: “你真的了解try{ return }finally{}中的return？ getMessage vs toString 如代码所示,e.toString() 获取的信息包括异常类型和异常详细消息，而e.getMessage()只是获取了异常的详细消息字符串,所以推荐在Catch中使用e.toString() 常见异常及解释 Java常见异常及解释 - ImportNew 断言 表达式assert 表达式:错误消息 比如assert x&gt;y : &quot;断言失败!&quot; 如何开启关闭断言? 单点为某个类开启断言? java -ea Xxx , java -ea:MyClass Xxx Native Method实现一个Native方法: 声明java native method: public class CJNativeInterfaceDemo &#123; public native String input(String prompt); static &#123; System.loadLibrary(\"./libJniTest.so\"); &#125; public static void main(String[] args) &#123; CJNativeInterfaceDemo jniDemo = new CJNativeInterfaceDemo(); jniDemo.input(\"JNI Test\"); &#125;&#125; 生成c++头文件 javac CJNativeInterfaceDemo.java 生成.class文件 javah -jni CJNativeInterfaceDemo 生成.h文件 实现C++函数并编译成动态库gcc -I/usr/lib/jvm/java-7-openjdk-i386/include/ CJNativeInterfaceDemo.c -shared -o libJniTest.so 附录:JDK常用类java.lang📦继承关系图 java.util📦继承关系图 附录:补码,反码 反码: 正数的反码是本身, 负数的反码=符号位不变, 其他位取反补码: 正数的补码是本身, 负数的补码=符号位不变, 其他位取反, 再加1看几组补码-真值: “1111 1111”=-1, “1000 0010”=-126, “1000 001”=-127, “1000 0000”=-128不要用计算补码的方式去”算”-128的补码, 1000 0000 是定义的. 参考: @ref 原码, 反码, 补码 详解 @ref 原码、反码和补码 取余 &amp; 取模 取余：x%y 取模：Math.floorMod(x, y) 取余和取模的区别 =》 [[../19.Algorithm/Alg.数学基础]] 的「取余 &amp; 取模」 位运算符 &amp; 符号位 | 符号位 ~ 符号位 ^ 符号位 &lt;&lt; 左移: 丢弃最高位(符号位同样丢弃), 0补最低位. 当byte和short左移时, 自动升级为int型. 数学意义: 左移n位相等于乘以2^n &gt;&gt; 右移: 高位补充符号位, 正数右移补充0, 负数右移补充1, 当byte和short右移时, 自动升级为int型. 数学意义: 右移n位相当于除以2^n &gt;&gt;&gt; 无符号右移: 无论正负, 高位补充0 无符号右移运算符&gt;&gt;&gt; 只是对32位和64位的值有意义","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"}]},{"title":"Advanced Java-08-编译","slug":"12.Java/Advanced-Java.08.编译","date":"2024-01-24T01:27:52.109Z","updated":"2024-01-24T01:27:52.109Z","comments":true,"path":"12.Java/Advanced-Java.08.编译/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Advanced-Java.08.编译/","excerpt":"语法糖Java 中最常用的语法糖主要有泛型、变长参数、条件编译、自动拆装箱、内部类等。虚拟机并不支持这些语法，它们在编译阶段就被还原回了简单的基础语法结构，这个过程成为解语法糖。 编译器介绍前端编译器源码-&gt;字节码, javac","text":"语法糖Java 中最常用的语法糖主要有泛型、变长参数、条件编译、自动拆装箱、内部类等。虚拟机并不支持这些语法，它们在编译阶段就被还原回了简单的基础语法结构，这个过程成为解语法糖。 编译器介绍前端编译器源码-&gt;字节码, javac 语法分析, 代码-&gt;Token, Token-&gt;语法树 填充符号表 语义分析, 保证逻辑性 字节码生成 后端编译器字节码-&gt;机器码, 比如HotSpot自带的JIT, 当虚拟机发现某个方法或代码块运行特别频繁时, 就会把这些代码认定为Hot Spot Code, 虚拟机将会把这些代码编译成与本地平台相关的机器码","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://beefyheisenberg.github.io/tags/JVM/"}]},{"title":"Advanced Java-07-字节码","slug":"12.Java/Advanced-Java.07.字节码","date":"2024-01-24T01:27:52.105Z","updated":"2024-01-24T01:27:52.105Z","comments":true,"path":"12.Java/Advanced-Java.07.字节码/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Advanced-Java.07.字节码/","excerpt":"一些有关Java字节码的文章: Java Zone: Introduction to Java Bytecode 这篇文章图文并茂地向你讲述了 Java 字节码的一些细节，是一篇很不错的入门文章。 IBM DeveloperWorks: Java bytecode 讲 Java 字节码。 字节码相关库可以操作字节码的库: JVM Tool Interface (JVMTI): Java Bytecode and JVMTI Example，这是一些使用 JVM Tool Interface 操作字节码的比较实用的例子。包括方法调用统计、静态字节码修改、Heap Taggin 和 Heap Walking。计、静态字节码修改、Heap Taggin 和 Heap Walking asm tools - 用于生产环境的 Java .class 文件开发工具。 Byte Buddy - 代码生成库：运行时创建 Class 文件而不需要编译器帮助。","text":"一些有关Java字节码的文章: Java Zone: Introduction to Java Bytecode 这篇文章图文并茂地向你讲述了 Java 字节码的一些细节，是一篇很不错的入门文章。 IBM DeveloperWorks: Java bytecode 讲 Java 字节码。 字节码相关库可以操作字节码的库: JVM Tool Interface (JVMTI): Java Bytecode and JVMTI Example，这是一些使用 JVM Tool Interface 操作字节码的比较实用的例子。包括方法调用统计、静态字节码修改、Heap Taggin 和 Heap Walking。计、静态字节码修改、Heap Taggin 和 Heap Walking asm tools - 用于生产环境的 Java .class 文件开发工具。 Byte Buddy - 代码生成库：运行时创建 Class 文件而不需要编译器帮助。 多态性实现机制方法绑定Class 文件的编译过程中不包含传统编译中的连接步骤，一切方法调用在 Class 文件里面存储的都只是符号引用，而不是方法在实际运行时内存布局中的入口地址。一部分方法的符号引用在类加载阶段或第一次使用时转化为直接引用，这种称为 静态绑定；另一部分方法在类运行期间才能确定某些目标方法的直接引用，称为 动态绑定； Java 字节码中与调用相关的指令共有五种（还有一种invokedynamic，比较复杂）： 静态绑定: 调用哪个方法在编译期就确定了, 在类的加载阶段, static/final/private方法的符号引用被替换为直接引用, 用invokestatic,invokespecial指令调用的方法都是在加载阶段被替换为直接引用: invokestatic指令: 用来调用static方法; invokespecial指令: 用于调用私有实例方法、构造器，以及使用 super 关键字调用父类的实例方法或构造器，和所实现接口的默认方法。 动态绑定: 在运行阶段(每次类被初始化的时候?)才能确定直接引用的方法. invokevirtual指令: 调用所有的虚方法（即非私有实例方法, 除了static/private/Constructor方法之外的都算作虚方法, 虽然final方法也是由invokevirtual调用但是final方法不属于虚方法） invokeinterface指令: 调用接口方法 单分派 &amp; 多分派 方法的调用者与方法的参数统称为方法的”宗量”, 单分派是根据一个宗量对目标方法进行选择, 多分派是根据多个宗量对目标方法进行选择 单分派是根据一个宗量对目标方法进行选择，多分派是根据多于一个宗量对目标方法进行选择。此外分派还可以根据”动态/静态解析”分为动态分派(运行期)和静态分派(编译期间).两类分派方式两两组合便构成了静态单分派、静态多分派、动态单分派、动态多分派四种分派情况。 在编译阶段编译器的选择过程，即静态分派过程。这时候选择目标方法的依据有两点：一是方法的接受者（即调用者）的静态类型(基类类型)，二是方法参数类型。因为是根据两个宗量进行选择，所以 Java 语言的静态分派属于多分派类型。 运行阶段虚拟机的选择过程，即动态分派过程。由于编译期已经了确定了目标方法的参数类型（编译期根据参数的静态类型进行静态分派），因此唯一可以影响到虚拟机选择的因素只有此方法的参数类型。因为只有一个宗量作为选择依据，所以 Java 语言的动态分派属于单分派类型。","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://beefyheisenberg.github.io/tags/JVM/"}]},{"title":"Advanced Java-05-对象内存结构","slug":"12.Java/Advanced-Java.05.对象内存结构","date":"2024-01-24T01:27:52.101Z","updated":"2024-01-24T01:27:52.101Z","comments":true,"path":"12.Java/Advanced-Java.05.对象内存结构/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Advanced-Java.05.对象内存结构/","excerpt":"HotSpot 虚拟机中，对象在 Heap 中存储的布局可以分为三块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。 对象头在HotSpot里对象头包括3部分(如果此对象不是数组，则只包括前2部分): Mark Word: 用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等，这部分数据的长度在32位和64位VM中分别为32bit和64bit; Class Metadata Address: klass类型指针, 用来指向对象对应的Class对象（其对应的元数据对象）的内存地址。这部分数据的长度在32位和64位VM中分别为32bit和64bit。64位开启指针压缩的情况下, 这部分占32bit; Array Length: 如果是数组对象，还需要有一个Array Length保存数组长度的空间，32bit","text":"HotSpot 虚拟机中，对象在 Heap 中存储的布局可以分为三块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。 对象头在HotSpot里对象头包括3部分(如果此对象不是数组，则只包括前2部分): Mark Word: 用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等，这部分数据的长度在32位和64位VM中分别为32bit和64bit; Class Metadata Address: klass类型指针, 用来指向对象对应的Class对象（其对应的元数据对象）的内存地址。这部分数据的长度在32位和64位VM中分别为32bit和64bit。64位开启指针压缩的情况下, 这部分占32bit; Array Length: 如果是数组对象，还需要有一个Array Length保存数组长度的空间，32bit 对象头中的 Mark Word 对于 64bit 的 JVM，Mark Word 的大小是 64bit（8 字节），根据对象的不同状态，对象的 Mark Word 存储的内容也不同： tag=01：无锁状态下，保存的是对象 hashCode 和 GC 的分代年龄 tag=01、00、10：如果使用了该对象的同步锁（对该对象使用了 Synchronized 代码块），对象的 Mark Word 会存储锁相关的信息，这部分参考 @ref Java-并发.03.Synchronized tag=11：GC 标记，例如 forwarding pointer 等 @ref Advanced-Java.03a.GC 如果对象调用过 hashCode 方法，计算出的 hash 值缓存在 Mark Word Java GC详解 - 最全面的理解Java对象结构 - 对象指针 OOPs | HeapDump性能社区: Hashcode 尽量只计算一次，计算出后，对于无锁对象，保存在对象标记字 Markword 中。 处于各种锁状态的话（除了偏向锁），都会修改并占用 Markword 导致需要其他地方缓存计算好的 hashcode，对于重量锁是对应的 Monitor 中保存，对于轻量锁是所指向的锁记录的指针中保存。 对于偏向锁，由于没法哈希值，所以只要计算过哈希值，就不会再进入偏向锁的状态，而是直接从轻量锁开始。 对于 JDK 15 之后引入的异步 Monitor 降级（Async Monitor Deflation），需要在这个过程完成或者未开始的时候读取 monitor 对象的 hashcode 缓存。对于这个特性的详细说明，可以参考：Async Monitor Deflation 分代年龄，是该对象经历的 Young GC 次数，超过 -XX:MaxTenuringThreshold=n 的对象会被晋升至老年代，因为这个分代年龄只有 4bit，所以最大值是 15，上面提到的 MaxTenuringThreshold 不能超过 15（默认也是 15）// 关于对象的动态年龄计算，参考 Advanced-Java.03b.GC案例分析 GC 标记：使用带有“整理”功能的 GC，即 GC 前后对象地址可能发生变化，就需要这部分存储 “forwarding pointer” 参考 Advanced-Java.03a.GC /Copying GC 和 Mark-Compact 对象头中的 Class Pointer指向对象实的 Class 的指针。Java 7 之前指向的区域位于持久代（Permanent Generation），Java 8 之后，持久代废弃，引入了元数据区的概念（Metaspace），所以 Java 8 之后指向的是这个元数据区。 这个指针可能是被压缩的，就是压缩指针（Compressed OOPs）。当开启对象压缩时占用4字节（JVM 默认开启），关闭时占用8字节。 如果字节对齐 -XX:ObjectAlignmentInBytes 设置为 8，那么堆超过 32G 时，压缩指针会失效； @ref: Java GC详解 - 最全面的理解Java对象结构 - 对象指针 OOPs | HeapDump性能社区 实例数据去掉对象头, 剩下的是实例数据（Instance Data）和对齐填充（Padding）:实例数据部分包括了对象的所有成员变量，其大小由各个成员变量的大小决定，比如：byte和boolean是1个字节，short和char是2个字节，int和float是4个字节，long和double是8个字节，reference是4个字节（64位系统中是8个字节）。非final非static成员属性才在这里, final的常量属性在方法区; static的属性在class对象里, class对象也在堆区. 对齐填充填充字节, 使得对象的大小是8的倍数","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://beefyheisenberg.github.io/tags/JVM/"}]},{"title":"Advanced Java-05-class文件结构","slug":"12.Java/Advanced-Java.05.class文件结构","date":"2024-01-24T01:27:52.096Z","updated":"2024-01-24T01:27:52.097Z","comments":true,"path":"12.Java/Advanced-Java.05.class文件结构/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Advanced-Java.05.class文件结构/","excerpt":"class文件结构概述class文件是一种8位字节的二进制流文件， 各个数据项按顺序紧密的从前向后排列， 相邻的项之间没有间隙， 这样可以使得class文件非常紧凑， 体积轻巧， 可以被JVM快速的加载至内存， 并且占据较少的内存空间。 我们的Java源文件， 在被编译之后， 每个类（或者接口）都单独占据一个class文件， 并且类中的所有信息都会在class文件中有相应的描述。class文件中的每个数据项都有它的固定长度， 数据项的不同长度分别用u1，u2，u4，u8表示，长度分别是byte、short、int、long。class文件中存在以下数据项(该图表参考自《深入Java虚拟机》)： 类型 名称 数量 u4 magic 1 u2 minor_version 1 u2 major_version 1 u2 constant_pool_count 1 cp_info constant_pool constant_pool_count - 1 u2 access_flags 1 u2 this_class 1 u2 super_class 1 u2 interfaces_count 1 u2 interfaces interfaces_count u2 fields_count 1 field_info fields fields_count u2 methods_count 1 method_info methods methods_count u2 attribute_count 1 attribute_info attributes attributes_count class文件每个区域的说明： magic 和 version: magic 也即魔数(固定值0xCAFEBABE)占用4字节, class 文件版本号占用4字节, 不同版本的 javac 编译器编译的 class 文件, 版本号可能不同; 常量池数量 constant_pool_count, 等于实际常量池中项目的数量+1，因为常量池计数器是从1开始计数的，将第0项常量空出来是有特殊考虑的，索引值为0代表“不引用任何一个常量池项”。 常量池(constant_pool)存储的内容主要包括 符号引用 和 字面量; access_flag, 在常量池之后的两个字节, 这个标志用于识别一些类或接口层次的访问信息 this_class/super_class/interfaces: 类索引（this_class）和父类索引（super_class）都是一个 u2 类型的数据,而接口索引集合（interfaces）则是一组 u2 类型的数据集合, Class 文件中由这三项数据来确定这个类的继承关系; field_info字段表 method_info方法表 attribute_info属性表 方法字节码…","text":"class文件结构概述class文件是一种8位字节的二进制流文件， 各个数据项按顺序紧密的从前向后排列， 相邻的项之间没有间隙， 这样可以使得class文件非常紧凑， 体积轻巧， 可以被JVM快速的加载至内存， 并且占据较少的内存空间。 我们的Java源文件， 在被编译之后， 每个类（或者接口）都单独占据一个class文件， 并且类中的所有信息都会在class文件中有相应的描述。class文件中的每个数据项都有它的固定长度， 数据项的不同长度分别用u1，u2，u4，u8表示，长度分别是byte、short、int、long。class文件中存在以下数据项(该图表参考自《深入Java虚拟机》)： 类型 名称 数量 u4 magic 1 u2 minor_version 1 u2 major_version 1 u2 constant_pool_count 1 cp_info constant_pool constant_pool_count - 1 u2 access_flags 1 u2 this_class 1 u2 super_class 1 u2 interfaces_count 1 u2 interfaces interfaces_count u2 fields_count 1 field_info fields fields_count u2 methods_count 1 method_info methods methods_count u2 attribute_count 1 attribute_info attributes attributes_count class文件每个区域的说明： magic 和 version: magic 也即魔数(固定值0xCAFEBABE)占用4字节, class 文件版本号占用4字节, 不同版本的 javac 编译器编译的 class 文件, 版本号可能不同; 常量池数量 constant_pool_count, 等于实际常量池中项目的数量+1，因为常量池计数器是从1开始计数的，将第0项常量空出来是有特殊考虑的，索引值为0代表“不引用任何一个常量池项”。 常量池(constant_pool)存储的内容主要包括 符号引用 和 字面量; access_flag, 在常量池之后的两个字节, 这个标志用于识别一些类或接口层次的访问信息 this_class/super_class/interfaces: 类索引（this_class）和父类索引（super_class）都是一个 u2 类型的数据,而接口索引集合（interfaces）则是一组 u2 类型的数据集合, Class 文件中由这三项数据来确定这个类的继承关系; field_info字段表 method_info方法表 attribute_info属性表 方法字节码… class文件常量池常量池(constant_pool)存储的内容主要包括 符号引用 和 字面量: 字面量: 主要包括字符串常量和 final 常量值; 符号引用: 包括类继承的超类, 接口的全限定名, 及描述符（包括 fields 的名称和描述符, methods 的名称及描述符） 类和接口的全限定名: 例如一个类的权限定名是 org/kshan/corej/TestClass; 字段的名称和描述符: 字段名称: 当类被加载后的链接阶段, 这些符号引用被替换为直接引用; 字段描述符: 用来描述字段的类型比如二维数组 int [][] 被记录为 [[I, String[] 被记录为 [Ljava/lang/String; 方法的名称和描述符: 方法名称: 当类被加载后的链接阶段, 这些符号引用被替换为直接引用; 方法描述符: 用来描述方法的形参/返回值, 例如方法int getIndex(String name,char[] tgc,int start,int end,char target)的描述符为(Ljava/lang/String[CIIC) I; class 文件中的很多其他部分都是对常量池中的数据项的引用，比如后面要讲到的 this_class, super_class, field_info, attribute_info 等，另外字节码指令中也存在对常量池的引用，这个对常量池的引用当做字节码指令的一个操作数。此外，常量池中各个项也会相互引用。 注意不要与JVM内存模型中的”运行时常量池”混淆, Class文件中常量池主要存储了字面量以及符号引用，其中字面量主要包括字符串，final 常量的值或者某个属性的初始值等等， 下图参考自: 《Java虚拟机原理图解》 Class文件中的常量池详解 @ref 实例分析 class 文件常量池Java测试类: public class CJEntry extends CJBaseClass implements Serializable &#123; public final static int thatIsConstVar = 5; // 整形常量 public static boolean thatIsStaticVar = true; // 静态 public int thatIsInstanceVar; // 实例变量 public int thatIsInstanceMethod(String input) &#123; // 实例方法 return Integer.parseInt(input); // 调用静态方法 &#125;&#125; 编译后使用 javap 分析 class 文件: javac org/mk/corej/CJBaseClass.java &amp;&amp; javap -v org.mk.corej.CJBaseClass, 只截取输出的”Constant pool” 部分: #1 = Methodref #5.#23 // org/kshan/corej/CJBaseClass.&quot;&lt;init&gt;&quot;:()V ## 构造方法的符号引用#2 = Methodref #24.#25 // java/lang/Integer.parseInt:(Ljava/lang/String;)I ## Integer.parseInt()的符号引用#3 = Fieldref #4.#26 // org/kshan/corej/CJEntry.thatIsStaticVar:Z ## 静态field的符号引用#4 = Class #27 // org/kshan/corej/CJEntry ## 父类符号引用#5 = Class #28 // org/kshan/corej/CJBaseClass ## 接口符号引用#7 = Utf8 thatIsConstVar ##static final常量名字#10 = Integer 5 ## static final常量值#11 = Utf8 thatIsStaticVar ## 变量名字#13 = Utf8 thatIsInstanceVar ## 变量名字#14 = Utf8 &lt;init&gt; ###15 = Utf8 ()V ###18 = Utf8 thatIsInstanceMethod#19 = Utf8 (Ljava/lang/String;)I#23 = NameAndType #14:#15 // &quot;&lt;init&gt;&quot;:()V ## 构造方法的NameAndType, &lt;init&gt;是构造方法的名字, ()V表示无参返回Void#24 = Class #30 // java/lang/Integer#25 = NameAndType #31:#19 // parseInt:(Ljava/lang/String;)I ## 静态方法名字:描述符`(形参列表)返回值`的格式#26 = NameAndType #11:#12 // thatIsStaticVar:Z#27 = Utf8 org/kshan/corej/CJEntry#28 = Utf8 org/kshan/corej/CJBaseClass#29 = Utf8 java/io/Serializable#30 = Utf8 java/lang/Integer#31 = Utf8 parseInt @ref: 实例分析Java Class的文件结构 | | 酷 壳 - CoolShell 局部变量表、操作数栈@todo","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://beefyheisenberg.github.io/tags/JVM/"}]},{"title":"Advanced Java-04-ClassLoader","slug":"12.Java/Advanced-Java.04.ClassLoader","date":"2024-01-24T01:27:52.091Z","updated":"2024-01-24T01:27:52.092Z","comments":true,"path":"12.Java/Advanced-Java.04.ClassLoader/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Advanced-Java.04.ClassLoader/","excerpt":"类的加载过程本节参考了 Oracle 的 jvms: Chapter 5. Loading, Linking, and Initializing： Java虚拟机动态加载、链接和初始化类和接口。加载是查找具有特定名称的类或接口类型的二进制表示并从该二进制表示创建类或接口的过程。链接是获取类或接口并将其组合到Java虚拟机的运行时状态以使其能够执行的过程。类或接口的初始化包括执行类或接口初始化方法&lt;clinit&gt;(§2.9)。在本章中，§5.1描述了Java虚拟机如何从类或接口的二进制表示中派生符号引用。§5.2说明Java虚拟机如何首先启动加载、链接和初始化过程。§5.3规定类加载器如何加载类和接口的二进制表示，以及类和接口是如何创建的。链接在§5.4中进行了描述。§5.5详细说明类和接口是如何初始化的。§5.6引入了绑定本机方法的概念。最后，§5.7描述了Java虚拟机何时退出。 一个 Java Class 对象被创建的完整过程：加载 – 链接 – 初始化, 在加载阶段, 创建的 class 对象存储在堆(Heap)、以及 Metaspace 的 Klass、Non-Klass 对象; 在链接阶段, final 常量和字符串在方法区分配空间(jdk 8 变成了元空间); 在初始化阶段, 初始化 static 成员, 也在堆;","text":"类的加载过程本节参考了 Oracle 的 jvms: Chapter 5. Loading, Linking, and Initializing： Java虚拟机动态加载、链接和初始化类和接口。加载是查找具有特定名称的类或接口类型的二进制表示并从该二进制表示创建类或接口的过程。链接是获取类或接口并将其组合到Java虚拟机的运行时状态以使其能够执行的过程。类或接口的初始化包括执行类或接口初始化方法&lt;clinit&gt;(§2.9)。在本章中，§5.1描述了Java虚拟机如何从类或接口的二进制表示中派生符号引用。§5.2说明Java虚拟机如何首先启动加载、链接和初始化过程。§5.3规定类加载器如何加载类和接口的二进制表示，以及类和接口是如何创建的。链接在§5.4中进行了描述。§5.5详细说明类和接口是如何初始化的。§5.6引入了绑定本机方法的概念。最后，§5.7描述了Java虚拟机何时退出。 一个 Java Class 对象被创建的完整过程：加载 – 链接 – 初始化, 在加载阶段, 创建的 class 对象存储在堆(Heap)、以及 Metaspace 的 Klass、Non-Klass 对象; 在链接阶段, final 常量和字符串在方法区分配空间(jdk 8 变成了元空间); 在初始化阶段, 初始化 static 成员, 也在堆; ①加载(Loading) 由对应的 ClassLoader 从磁盘读取.class 文件字节 // 这里的类加载器可以自定义 ClassLoader 的 loadClass 最终通过 ClassLoader.defineClass() 方法创建一个 java.lang.Class 的对象, 对象存储在堆(Heap), 这一步除了创建 Class 对象，还会在 Metaspace 创建 Klass 对象等… @ref: Advanced-Java.02b1.MetaSpace解析 ②链接(Linking)链接阶段还分 3 个步骤： 1 验证(Verification): 验证加载类的字节码, 验证成功则载入到方法区(Method Area), 验证项包括如下: 变量使用前要初始化 方法调用与对象引用之间类型要匹配 访问私有数据和方法的规则没有违反 运行时堆栈没有溢出 2 准备(Preparation): 为静态字段分配内存，这一步仅是分配内存但并未对其初始化； 除了分配内存外，部分 Java 虚拟机还会在此阶段构造其他跟类层次相关的数据结构，比如说用来实现虚方法的动态绑定的 方法表 /方法表分为 vtable 和 itable，前者是非私的“实例方法”，后者是接口方法/; JDK8 移除了方法区，类的元数据移到了 Native 内存的 Metaspace，类的 static 成员在堆区 jvm - Where are static methods and static variables stored in Java? - Stack Overflow 3 解析(Resolution): 把类中的 符号引用 转换为 直接引用: 对于一个方法调用，编译器会生成一个包含目标方法所在类的名字、目标方法的名字、接收参数类型以及返回值类型的符号引用，来指代所要调用的方法。解析阶段的目的，正是将这些符号引用解析成为实际引用。对于 Java 来说，大部分方法调用都是通过 invokevirtual 字节码调用的实例方法，这类方法调用被解析为在 vtable 位置的索引； 如果符号引用指向一个未被加载的类，或者未被加载类的字段或方法，那么解析将触发这个类的加载（但未必触发这个类的链接以及初始化） ③初始化(Initialization)类加载的最后一步是初始化，为标记为常量值的字段赋值，以及执行 &lt;clinit&gt; 方法的过程。 如果 filed 是在声明时被直接赋值的： 如果 field 是 static final 修饰，且是基本类型（例如final static int m = 1），那么此 filed 会被编译器标记成常量值（ConstantValue），其初始化直接由 Java 虚拟机完成； 除了上面的情况之外的所有直接赋值操作，连同static 代码块，一并被放入&lt;clint&gt;方法，该方法是由JVM加锁执行，保证该方法的线程安全。这个特性常被用来保证单例模式的线程安全，如果是在“static的内部类”中定义的static field，还可以利用内部类实现延后单例。 @ref: 03 | Java虚拟机是如何加载Java类的? JVM 规范枚举了下述多种 触发初始化 的情况(但不限于这几种): Java 虚拟机启动时, 被标明为启动类(有 main 方法)会被初始化 初始化一个类的时候如果发现其父类还没用初始化, 则先初始化其父类, 这种属于 被动初始化; 用 new 明确创建一个类实例, 这里用的是 new 字节码指令, 当且类还没有完成初始化; 首次对类的 static (同时必须满足非 final)的成员属性进行读写, 一般是调 getter/setter 方法的时候, 对应字节码指令: getstatic, putstatic 首次调用类的 static 方法, 对应字节码指令: invokestatic 调用 Class.forName(&quot;xxx&quot;); … ➤ 比较四种指令 new, getstatic, putstatic, invokestatic: 除了 new 是主动初始化, 后面三种都是被动初始化. ➤ 比较 Class.forName(&quot;xxx&quot;) 和 ClassLoader.loadClass(): 作用都是返回 Class 对象;Class.forName()只能通过应用加载器(AppClassLoader)创建 Class 对象, 还会调用类的 static 代码块;ClassLoader.loadClass()可以通过自定义 ClassLoader 创建 Class 对象, 内部类的初始化 对于非静态内部类, 不允许有 static 成员, 也不允许有 static 代码块; 静态内部类是可以有 static{} 代码块的, 我们在 new Outter() 的时候, 其内部类的 static 代码块并没有被调用到, 直到对内部类进行 getstatic, invokestatic 等操作的时候, 内部类的 static 代码块才会被调用, 才会初始化. 单例模式就用到了这个”延迟初始化”的特性. 通过内部类实现单例: public class Singleton &#123; private Singleton() &#123;&#125; static class SingletonHolder &#123; private static final Singleton instance = new Singleton(); &#125; public static Singleton getInstance() &#123; return SingletonHolder.instance; &#125;&#125; ClassLoader使用Classloader 创建 Class对象JVM 在加载(Loading)阶段依靠 ClassLoader 完成, ClassLoader 的加载类过程主要使用 ClassLoader.loadClass(String name) 方法： MyClassLoader cl = new MyClassLoader();Class&lt;?&gt; clazz = cl.loadClass(&quot;org.mk.corej.Test&quot;);Test test = (Test)clazz.newInstance(); loadClass()：它会先检查类是否被加载过，如果否则将请求转发给父类加载器。如果父类加载器也无法加载此类，再尝试使用自己的findClass 加载； findClass()：从文件or网络流..，加载字节码，并可能对字节码进行预处理（例如解密等），然后调用 defineClass()创建Class的对象； defineClass()：最终调用了defineClass1()，是一个native 方法，返回Class 类型的对象 获得 Class类型的对象后，就可以使用 newInstance()创建实例对象，以及通过反射中的方法获取class 的方法 Java-Tutorials.03.反射(Reflection) 加载完成后, 虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区之中, 在 JVM 堆中也创建一个 java.lang.Class 类的对象. 每个 Java 类都维护着一个指向定义它的类加载器的引用，通过 object.getClass().getClassLoader() 方法就可以获取到此引用。 ClassLoader 分类Java 中的类加载器大致可以分成3类： 启动类加载器(Bootstrap ClassLoader): 它负责加载存放在 JDK\\jre\\lib\\rt.jar 里 java.* 开头的类; 谁加载了java.lang.ClassLoader本身? 答案就是 Bootstrap ClassLoader How is the Java Bootstrap Classloader loaded? - Stack Overflow 扩展类加载器(Extension ClassLoader): 它负责加载 JDK\\jre\\lib\\ext 目录中所有类库(如 javax.* 开头的类); 应用程序类加载器(Application ClassLoader): 它负责加载 -classpath 或 -cp 路径下的类, 开发者可以直接使用该类加载器, 如果应用程序中没有自定义过自己的类加载器, 一般情况下用的都是 Application ClassLoader , ps 有些资料也把它翻译为系统类加载器“System ClassLoader” 用户定义类加载器（User Defined ClassLoader），需要继承 ClassLoader，它的 parent 是 Application ClassLoader public void printClassLoaders() throws ClassNotFoundException &#123; System.out.println(\"Classloader of this class:\" + MyClass.class.getClassLoader()); System.out.println(\"Classloader of DriverManager:\" + DriverManager.class.getClassLoader()); System.out.println(\"Classloader of ArrayList:\" + ArrayList.class.getClassLoader());&#125; 运行上面的代码，可以看到返回的3个 Cl 分别是： jdk.internal.loader.ClassLoaders$AppClassLoader jdk.internal.loader.ClassLoaders$PlatformClassLoader null 也即上面提到的 Application ClassLoader、Extension ClassLoader、Bootstrap ClassLoader，可是为什么最后一个是null ？ 因为 Bootstrap ClassLoader 是C++实现的而非Java，所以没有一个Java 的 “Class”。 另，在Java 9 之后，扩展类加载器变为了 PlatformClassLoader。 ClassLoader是否是继承关系？三种层次的 ClassLoader 并不是继承关系（Inheritance），子 ClassLoader 通过是 组合（Composite） 的方式复用父 ClassLoader 的代码： public abstract class ClassLoader &#123; // The parent class loader for delegation private final ClassLoader parent;&#125; User defined ClassLoader 的 parent 是 App ClassLoader； App ClassLoader 的 parent 是 Ext ClassLoader； Bootstrap ClassLoader 作为其他所有 ClassLoader 的 parent； 以上 4类加载器通过这种方式组织起来形成树状结构，如下图所示（图中的 System Class Loader 即 App ClassLoader），虚线上方是 JDK 提供的 Cl，下方是用户自定义的 Cl： 在Java 12上测试： 用户自定义的加载器，getParent()返回的是 AppClassLoader； AppClassLoader.getParent() 返回的是 PlatformClassLoader； PlatformClassLoader.getParent() 返回 Null，因为 Bootstrap Cl 并不是一个 Java 类，而是一个 Native 类； Bootstrap class loader serves as the parent of all the other ClassLoader instances https://www.baeldung.com/java-classloaders A ClassLoader with a null parent ClassLoader appears to only have visibility into the java.base module. In Java 8 and earlier, such a ClassLoader would have visibility to all of the classes comprising the Java platform. https://bugs.openjdk.org/browse/JDK-8161269 组合模式（Composite Pattern），又叫部分整体模式，是用于把一组相似的对象当作一个单一的对象。组合模式依据树形结构来组合对象，用来表示部分以及整体层次。 ClassLoader 如何工作？双亲委派机制使用自定 ClassLoader 加载 class，并创建实例对象： MyClassLoader cl = new MyClassLoader();Class&lt;?&gt; clazz = cl.loadClass(\"org.mk.corej.Test\");Test test = (Test)clazz.newInstance(); 在 ClassLoader.loadClass() 方法内实现了双亲委派： 先检查类是否被加载过 如果否则将请求转发给父类加载器 如果父类加载器也无法加载此类，再尝试使用自己的findClass 加载 概括双亲委派就是 总是向上委托、可见性原则（每个加载器总是负责加载自己可见的类） protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; 这样做的好处是可以保证类的唯一性，例如 可以确保 Java 核心类的唯一性，因为向上委托的模式下，核心类总是由 Bootstrap 加载的。 ps：外文资料里一般都写 “Parents delegate”，国内资料大都默认了翻译成“双亲”，这是一种词不达意的翻译，理解起来好像是要委托2个父 ClassLoader，其实本意是“委托给 parents 一级的 ClassLoader”。 再看 ClassLoader 的几个方法： Class&lt;?&gt; loadClass(String cn, boolean resolve)：如上分析，loadClass 里实现了 双亲委派，并最终调用了 findClass，抛出 ClassNotFoundException 异常； Class&lt;?&gt; findClass(String cn)：findClass 里一般是加载.class的字节流然后调用 defineClass，例如 URLClassLoader.findClass 里实现的是通过URI获取.class的字节流，抛出 NoClassDefFoundError 异常； Class&lt;?&gt; defineClass(String name, byte[] b, int off, int len)：defineClass 把字节码转化为Class对象； 实现自定义 ClassLoader从 ClassLoader 的层级关系可知，我们自定义的 ClassLoader 的 parent 是 App ClassLoader； 从上面 ClassLoader 方法的介绍可知，如果我们的自定义 Cl 需要改变双亲委派机制，那么重写 loadClass 方法，如果不想改变，则只需重写 findClass 即可： // 1继承CLassLoaderpublic class MyClassLoader extends ClassLoader &#123; // 2重写findClass protected Class&lt;?&gt; findClass(String classFullName) throws ClassNotFoundException &#123; String path = classFullName.repace(\".\", File.separatorChar) + \".class\"; // 装换为路径.class InputStream ins = new FileInputStream(path); ByteArrayOutputStream baos = new ByteArrayOutputStream(); byte[] buffer = new byte[4096]; int bytesNumRead = 0; while ((bytesNumRead = ins.read(buffer)) != -1) &#123; baos.write(buffer, 0, bytesNumRead); &#125; byte[] bytes = classBytes baos.toByteArray(); return defineClass(name, classData, 0, classData.length); // 3 defineClass抛出NoClassDefFoundError异常 &#125; // 测试classLoader public static void main(String[] args) &#123; MyClassLoader loader1 = new MyClassLoader(); // 自定义的加载器 MyClassLoader loader2 = Thread.currentThread().getContextClassLoader(); // `Launcher$AppClassLoader` Class&lt;?&gt; class1 = loader1.loadClass(\"com.example.Sample\"); // 4 loadClass抛出ClassNotFoundException异常 Class&lt;?&gt; class2 = loader2.loadClass(\"com.example.Sample\"); if(class1 == class2) &#123; // true, class1, class2指向同一个引用 System.out.println(\"class1 == class2\"); &#125; &#125;&#125; 可见性（Visibility）子类加载器对父类加载器加载的类是可见的。例如，System Cl 加载的类，对 Ext Cl 和 Bootstrap Cl 加载的类具有可见性，但反之则不然。 为了说明这一点，如果类A由 App Cl 加载，而类B由 Ext Cl 加载，则就由 App Cl 加载的其他类而言，A和B类都是可见的。然而，类B是唯一对 Ext Cl 加载的其他类可见的类。 原文： Visibility In addition, children class loaders are visible to classes loaded by their parent class loaders. For instance, classes loaded by the system class loader have visibility into classes loaded by the extension and bootstrap class loaders, but not vice-versa. To illustrate this, if Class A is loaded by the application class loader, and class B is loaded by the extensions class loader, then both A and B classes are visible as far as other classes loaded by the application class loader are concerned. Class B, however, is the only class visible to other classes loaded by the extension class loader. 可见性的另一个例子见下面的「ConextClassLoader」一节 上下文类加载器（ConextClassLoader）有时当JVM核心类需要动态加载应用程序开发人员提供的类或资源时，我们可能会遇到问题。例如在JNDI中，核心功能由rt.jar中的引导类实现。但这些JNDI类可能会加载由第三方厂商实现的 JNDI Provider 库(这些库放在应用的 classpath 中)。此场景要求 Bootstrap 加载器(父类加载器)加载“对应用程序加载器(子类加载器)可见”的类。 这些类对于 Bootstrap 来说，是不可见的，双亲委派机制在这里也不起作用（双亲委派是 ClassLoader.loadClass 实现的，在 Bootstrap 没有实现这个机制，且 Bootstrap 也没有 parent loader），要绕过这个问题，我们需要找到类加载的替代方法，这可以使用线程上下文加载器来实现。 Thread类有一个方法 getContextClassLoader()，该方法返回特定线程的 “ConextClassLoader”。 ConextClassLoader 由线程的创建者在加载资源和类时提供。如果未设置该值，则默认为父线程的类加载器上下文。「The ContextClassLoader is provided by the creator of the thread when loading resources and classes. If the value isn’t set, then it defaults to the class loader context of the parent thread.」 @ref: https://www.baeldung.com/java-classloaders#context-classloaders ConextClassLoader 在实际应用，以 JDBC.DriverManager 创建连接为例： String url = \"jdbc:mysql://xxxx:xxxx/xxxx\";Connection conn = DriverManager.getConnection(url,username,password); JDBC 定义了接口 java.sql.Driver，具体的实现都是由数据库厂商来提供的。 DriverManager 是由 PlatformClassLoader 加载，根据 Cl 的职责，它只能加载 JDK 扩展包，那数据库厂商提供的 Jar 是如何加载到的呢？ private static Connection getConnection( String url, java.util.Properties info, Class&lt;?&gt; caller) throws SQLException &#123; ... ensureDriversInitialized(); ...&#125;private static void ensureDriversInitialized() &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator(); /* Load these drivers, so that they can be instantiated. * It may be the case that the driver class may not be there * i.e. there may be a packaged driver with the service class * as implementation of java.sql.Driver but the actual class * may be missing. In that case a java.util.ServiceConfigurationError * will be thrown at runtime by the VM trying to locate * and load the service. * * Adding a try catch block to catch those runtime errors * if driver not available in classpath but it's * packaged as service and that service is there in classpath. */ try &#123; while (driversIterator.hasNext()) &#123; driversIterator.next(); &#125; &#125; catch (Throwable t) &#123; // Do nothing &#125; return null; &#125; &#125;); println(\"DriverManager.initialize: jdbc.drivers = \" + drivers);&#125; 上面的代码可以看到，getConnection 最后是由 ServiceLoader 来加载数据库的 Driver，其 load 方法如下： public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) &#123; ClassLoader cl = Thread.currentThread().getContextClassLoader(); return new ServiceLoader&lt;&gt;(Reflection.getCallerClass(), service, cl); &#125; 创建了一个 Thread.currentThread().getContextClassLoader()，然后这个 contextClassLoader 被赋值给了 ServiceLoader.load 成员变量 … 在 driversIterator.hasNext() 里，会搜索 classpath 下以及 jar 包中所有的 META-INF/services 目录下的 java.sql.Driver 文件，并找到文件中的实现类的名字，此时并没有实例化具体的实现类 接着在 driversIterator.next() 里，根据实现类的全名创建 Class 对象。这里是用了 Class.forName(cn, false, loader) 来创建，第三个参数 loader 即第一步创建的 contextClassLoader @ref: Java常用机制 - SPI机制详解 | Java 全栈知识体系 不适用双亲委派的场景TomcatTomcat 作为一个 Servlet 容器，一个 Tomcat 实例（一个 JVM 进程）可以同时运行多个 Java Web Application（WAR 包），不同的 WAR 可能会依赖同一个第三方类库的不同版本， JDK 的 App ClassLoader 无法实现这个机制，所以 Tomcat 使用自己的 WebApp ClassLoader。[[../13.JavaEE-Framework/JavaEE.Tomcat#ClassLoader]] WebApp ClassLoader 的加载顺序和双亲委派相反： 首先用 WebApp ClassLoader 加载应用自己 /WEB-INF下的 class文件 WebApp ClassLoader 无法加载的交给 App ClassLoader （CLASSPATH下的class） 再加载不到的，最后交给 Common ClassLoader（加载 CATALINA 下面的lib） 可以认为每个不同的 web 应用都有各自的 CLASS_PATH，如果默认使用 App ClassLoader 无法实现 CP 的隔离 SPISPI（Service Provider Interface），是 JDK 内置的一种服务提供发现机制，由此机制，JDK 的核心类可以加载并使用第三方厂商提供的类。 JNDI、 JDBC DriveManager 都使用了这种机制来加载三方厂商的类库，二者各自被 Bootstrap 和 Ext ClassLoader 加载，但这两种 ClassLoader 都无法加载三方厂商的类库——因为它们是属于 App ClassLoader 的管辖范围，对 Bootstrap &amp; Ext ClassLoader 来说不可见。 以 JDBC DriveManager 为例，它使用 java.util.ServiceLoader 完成 SPI 机制，ServiceLoader 实现的原理一个是延后加载，一个是使用 ConextClassLoader，具体见上面的「ConextClassLoader」一节。 OSGIOSGi(Open Service Gateway Initiative) OSGi 是 Java 技术栈下的动态模块系统。OSGi 中的每个模块（bundle）都包含 Java 包和类。模块可以声明它所依赖的需要导入的其它模块的 Java 包和类（通过 Import-Package），也可以声明导出自己的包和类，供其它模块使用（通过 Export-Package）。 这是通过 OSGi 特有的类加载器机制来实现的。OSGi 中的每个模块都有对应的一个类加载器。它负责加载模块自己包含的 Java 类。当它需要加载 Java 核心库的类时，它会代理给父类加载器（通常是启动类加载器）来完成。当它需要加载其他模块导入的 Java 类时，它会代理给「导出此 Java 类的模块」来完成加载。 假设有两个模块 bundleA 和 bundleB，它们都有自己对应的类加载器 classLoaderA 和 classLoaderB。 在 bundleA 中包含类 com.bundleA.Sample，并且该类被声明为导出的，也就是说可以被其它模块所使用的。 bundleB 声明了导入 bundleA 提供的类 com.bundleA.Sample，并包含一个类 com.bundleB.NewSample 继承自 com.bundleA.Sample。 在 bundleB 启动的时候，其类加载器 classLoaderB 需要加载类 com.bundleB.NewSample，进而需要加载类 com.bundleA.Sample。由于 bundleB 声明了类 com.bundleA.Sample 是导入的，classLoaderB 把加载类 com.bundleA.Sample 的工作代理给导出该类的 bundleA 的类加载器 classLoaderA。 classLoaderA 在其模块内部查找类 com.bundleA.Sample 并定义它，所得到的类 com.bundleA.Sample 实例就可以被所有声明导入了此类的模块使用。 OSGi 模块的这种类加载器结构，使得一个类的不同版本可以共存在 Java 虚拟机中，带来了很大的灵活性。 不过它的这种不同，也会给开发人员带来一些麻烦，尤其当模块需要使用第三方提供的库的时候。下面提供几条比较好的建议： 如果一个类库只有一个模块使用，把该类库的 jar 包放在模块中，在 Bundle-ClassPath 中指明即可。 如果一个类库被多个模块共用，可以为这个类库单独的创建一个模块，把其它模块需要用到的 Java 包声明为导出的。其它模块声明导入这些类。 如果类库提供了 SPI 接口，并且利用线程上下文类加载器来加载 SPI 实现的 Java 类，有可能会找不到 Java 类。如果出现了 NoClassDefFoundError 异常，首先检查当前线程的上下文类加载器是否正确。通过 Thread.currentThread().getContextClassLoader()就可以得到该类加载器。该类加载器应该是该模块对应的类加载器。如果不是的话，可以首先通过 class.getClassLoader()来得到模块对应的类加载器，再通过 Thread.currentThread().setContextClassLoader()来设置当前线程的上下文类加载器。 Java 9 引入模块化之后整个 JDK 都基于模块化进行构建，以前的 rt.jar, tool.jar 被拆分成数十个模块，编译的时候只编译实际用到的模块，所以 App ClassLoader 中调用的 loadClass 逻辑已经发生改变（见下面的代码） 先尝试通过模块的 ClassLoader 进行加载，找不到模块 ClassLoader 才进行双亲委派。loadClass的工作模式不再总是“向上委托”了 protected Class&lt;?&gt; loadClassOrNull(String cn, boolean resolve) &#123; synchronized (getClassLoadingLock(cn)) &#123; // check if already loaded Class&lt;?&gt; c = findLoadedClass(cn); if (c == null) &#123; // 找到当前类属于哪个模块 LoadedModule loadedModule = findLoadedModule(cn); if (loadedModule != null) &#123; //获取当前模块的类加载器 BuiltinClassLoader loader = loadedModule.loader(); //进行类加载 c = findClassInModuleOrNull(loadedModule, cn); &#125; else &#123; // 找不到模块信息才会进行双亲委派 if (parent != null) &#123; c = parent.loadClassOrNull(cn); &#125; &#125; &#125; &#125; &#125; JVM 如何判断两个类是否相同OBJ09-J. Compare classes and not class names - SEI CERT Oracle Coding Standard for Java - Confluence In a Java Virtual Machine (JVM), “Two classes are the same class (and consequently the same type) if they are loaded by the same class loader and they have the same fully qualified name” [JVMSpec 1999]. Two classes with the same name but different package names are distinct, as are two classes with the same fully qualified name loaded by different class loaders. 在 Java 虚拟机(JVM)中，“如果两个类由相同的类加载器加载，并且它们具有相同的完全限定名，则它们是相同的类(因此是相同的类型)”[JVMSpec 1999] It could be necessary to check whether a given object has a specific class type or whether two objects have the same class type associated with them, for example, when implementing the equals() method. If the comparison is performed incorrectly, the code could assume that the two objects are of the same class when they are not. As a result, class names must not be compared. 例如，在实现equals()方法时，可能需要检查给定对象是否具有特定的类类型，或者两个对象是否具有与其关联的相同类类型。如果比较执行得不正确，代码可能会假定这两个对象属于同一类，但实际上并不是。因此，不能比较类名 JVM 在判定两个 class 是否相同时，不仅要判断两个类名是否相同，而且要判断是否由同一个类加载器实例加载的。只有两者同时满足的情况下，JVM 才认为这两个 class 是相同的。就算两个 class 是同一份 class 字节码，如果被两个不同的 ClassLoader 实例所加载，JVM 也会认为它们是两个不同 class。 比如网络上的一个 Java 类 org.classloader.simple.NetClassLoaderSimple，javac 编译之后生成字节码文件 NetClassLoaderSimple.class，ClassLoaderA 和 ClassLoaderB 这两个类加载器并读取了 NetClassLoaderSimple.class 文件，并分别定义出了 java.lang.Class 实例来表示这个类，对于 JVM 来说，虽然都来自一份.class，但它们是两个不同的实例对象，如果试图将这个 Class 实例生成具体的对象进行转换时，就会抛运行时异常 java.lang.ClassCaseException public class NewworkClassLoaderTest &#123; public static void main(String[] args) &#123; try &#123; // 测试加载网络中的class文件 String rootUrl = \"http://localhost:8080/httpweb/classes\"; String className = \"org.classloader.simple.NetClassLoaderSimple\"; // 定义2个Loader，并分别创建两个 class对象 NetworkClassLoader ncl1 = new NetworkClassLoader(rootUrl); NetworkClassLoader ncl2 = new NetworkClassLoader(rootUrl); Class&lt;?&gt; clazz1 = ncl1.loadClass(className); Class&lt;?&gt; clazz2 = ncl2.loadClass(className); // 测试两个class 对象是否指向一个内存 System.out.println(clazz1.equals(clazz2)); // false // 用2个class 分别创建2个 obj Object obj1 = clazz1.newInstance(); Object obj2 = clazz2.newInstance(); // 测试 2个 obj 在反射机制内是否被认为是同一个类型 clazz1.getMethod(\"setNetClassLoaderSimple\", Object.class).invoke(obj1, obj2); // false，invoke 抛出 ClassCaseException &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; setNetClassLoaderSimple() 实现也很简单，只有一个强制转换+赋值： this.instance = (NetClassLoaderSimple)object; PS: 加载类（NetClassLoaderSimple）不要放在 IDE 的工程目录内，因为 IDE 在 run 的时候会先将工程中的所有.class 都用 AppClassLoader 加载，输出结果是 true 结论，ClassLoader 对判断类是否相同的影响： 使用不同的 ClassLoader， loadClass()创建出来的 class 对象不同（不 equals，说明不是一个 class对象） 使用不同的 class 对象， newInstance()创建出来的 obj 对象也不同，反射调用失败 @ref： awesome-it-blog/深入分析Java类加载器原理.md at master · Lord-X/awesome-it-blog · GitHub ClassLoader 面试八股文你确定你真的理解”双亲委派”了吗？！ - HollisChuang - 博客园 1、什么是双亲委派？ 2、为什么需要双亲委派，不委派有什么问题？ 3、”父加载器”和”子加载器”之间的关系是继承的吗？ 4、双亲委派是怎么实现的？ 5、我能不能主动破坏这种双亲委派机制？怎么破坏？ 6、为什么重写loadClass方法可以破坏双亲委派，这个方法和findClass（）、defineClass（）区别是什么？ 7、说一说你知道的双亲委派被破坏的例子吧 8、为什么JNDI、JDBC等需要破坏双亲委派？ 9、为什么TOMCAT要破坏双亲委派？ 10、谈谈你对模块化技术的理解吧！","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://beefyheisenberg.github.io/tags/JVM/"}]},{"title":"Advanced Java-03b-GC案例分析","slug":"12.Java/Advanced-Java.03b.GC案例分析","date":"2024-01-24T01:27:52.087Z","updated":"2024-01-24T01:27:52.088Z","comments":true,"path":"12.Java/Advanced-Java.03b.GC案例分析/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Advanced-Java.03b.GC案例分析/","excerpt":"➤ GC问题排查总结: GC常见问题: GC发生频繁, GC某个阶段耗时长 要定位问题, 首先看GC Log 和监控图, 确定如下: 现在用的是哪种GC收集器? ( 该收集器的GC的触发条件? 每个阶段做了什么? 哪个阶段有STW?) 如果是GC频繁, 是哪个分代的GC频繁? 如果是新生代GC: 新生对象太多, 新生代空间太小 如果是FGC: 有些FGC是因为新生代GC引起的 如果是GC某个阶段耗时过长, 需要确认: 这个阶段主要做了什么? 导致耗时变长的原因之一是扫描对象过多 ➤ 案例1: Minor 和Major GC 频繁, Major耗时较长, 且出现晋升的动态年龄阈值被降低的情况 观察: 新生代和老年代使用率, 确定是因为大量新生对象(导致新生代GC频繁), JVM动态调整了晋升年龄, 导致大量低龄对象进入老年代. 分析: 如果新生代容量扩容1倍, 可以推算, MinorGC发生频率降低1倍, Minor GC的”扫描阶段”耗时增加1倍, 但”拷贝阶段”的耗时不会显著增加, 虽然Minor GC间隔增加, 但… 解决: 增大新生代容量 动态年龄计算：Hotspot 遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了 survivor 区的一半时，取这个年龄和 MaxTenuringThreshold 中更小的一个值，作为新的晋升年龄阈值。在本案例中，调优前：Survivor 区 = 64 M，desired survivor = 32 M，此时 Survivor 区中 age&lt;=2 的对象累计大小为 41 M，41 M 大于 32 M，所以晋升年龄阈值被设置为 2，下次 Minor GC 时将年龄超过2的对象被晋升到老年代。 JVM 引入动态年龄计算，主要基于如下两点考虑： 如果固定按照 MaxTenuringThreshold 设定的阈值作为晋升条件： a）MaxTenuringThreshold 设置的过大，原本应该晋升的对象一直停留在 Survivor 区，直到 Survivor 区溢出，一旦溢出发生，Eden+Svuvivor 中对象将不再依据年龄全部提升到老年代，这样对象老化的机制就失效了。 b）MaxTenuringThreshold 设置的过小，“过早晋升”即对象不能在新生代充分被回收，大量短期对象被晋升到老年代，老年代空间迅速增长，引起频繁的 Major GC。分代回收失去了意义，严重影响 GC 性能。 相同应用在不同时间的表现不同：特殊任务的执行或者流量成分的变化，都会导致对象的生命周期分布发生波动，那么固定的阈值设定，因为无法动态适应变化，会造成和上面相同的问题。","text":"➤ GC问题排查总结: GC常见问题: GC发生频繁, GC某个阶段耗时长 要定位问题, 首先看GC Log 和监控图, 确定如下: 现在用的是哪种GC收集器? ( 该收集器的GC的触发条件? 每个阶段做了什么? 哪个阶段有STW?) 如果是GC频繁, 是哪个分代的GC频繁? 如果是新生代GC: 新生对象太多, 新生代空间太小 如果是FGC: 有些FGC是因为新生代GC引起的 如果是GC某个阶段耗时过长, 需要确认: 这个阶段主要做了什么? 导致耗时变长的原因之一是扫描对象过多 ➤ 案例1: Minor 和Major GC 频繁, Major耗时较长, 且出现晋升的动态年龄阈值被降低的情况 观察: 新生代和老年代使用率, 确定是因为大量新生对象(导致新生代GC频繁), JVM动态调整了晋升年龄, 导致大量低龄对象进入老年代. 分析: 如果新生代容量扩容1倍, 可以推算, MinorGC发生频率降低1倍, Minor GC的”扫描阶段”耗时增加1倍, 但”拷贝阶段”的耗时不会显著增加, 虽然Minor GC间隔增加, 但… 解决: 增大新生代容量 动态年龄计算：Hotspot 遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了 survivor 区的一半时，取这个年龄和 MaxTenuringThreshold 中更小的一个值，作为新的晋升年龄阈值。在本案例中，调优前：Survivor 区 = 64 M，desired survivor = 32 M，此时 Survivor 区中 age&lt;=2 的对象累计大小为 41 M，41 M 大于 32 M，所以晋升年龄阈值被设置为 2，下次 Minor GC 时将年龄超过2的对象被晋升到老年代。 JVM 引入动态年龄计算，主要基于如下两点考虑： 如果固定按照 MaxTenuringThreshold 设定的阈值作为晋升条件： a）MaxTenuringThreshold 设置的过大，原本应该晋升的对象一直停留在 Survivor 区，直到 Survivor 区溢出，一旦溢出发生，Eden+Svuvivor 中对象将不再依据年龄全部提升到老年代，这样对象老化的机制就失效了。 b）MaxTenuringThreshold 设置的过小，“过早晋升”即对象不能在新生代充分被回收，大量短期对象被晋升到老年代，老年代空间迅速增长，引起频繁的 Major GC。分代回收失去了意义，严重影响 GC 性能。 相同应用在不同时间的表现不同：特殊任务的执行或者流量成分的变化，都会导致对象的生命周期分布发生波动，那么固定的阈值设定，因为无法动态适应变化，会造成和上面相同的问题。 ➤ 案例2: 使用CMS, remark阶段STW超过1000ms 分析: remark是CMS进行老年代回收的第3个步骤, remark阶段需要以新生代对象为根进行扫描(防止跨代引用), 所以新生代对象数量直接影响remark阶段的扫描耗时 CMS为了解决这个问题, 在remark阶段加入了一个”可中断的并发预清理阶段”(CMS-concurrent-abortable-preclean), 在”并发标记”阶段结束后, 如果Eden大小超过2M, 将会进入此阶段. 如果此阶段能等到一次Minor GC, 那么remark阶段需要扫描的对象数量将大大减少. concurrent-abortable-preclean阶段是可中断的: 如果此阶段在超过CMSMaxAbortablePrecleanTime 秒后都没有等到一次Minor, 仍旧会进入remark; 案例中, 发现remark耗时过长的时候, 新生代使用率都很高, 所以可以判定remark耗时过长是因为新生代对象数量过多; 解决: CMS提供了CMSScavengeBeforeRemark参数, 强制在remark之前进行一次Minor GC; ➤ 案例3: 日志里Full GC耗时过长 分析: GC日志里的Full GC不代表全堆GC, 而是指有”STW的GC”类型, 引起STW 的GC可能原因: 1)新生代晋升时,发现老年代剩余空间不够; 2)老年代空间大于%; 3)Perm代发生GC; 案例: 排除1, 因为没有 promotion failed; 排除2, 因为发生Full GC时老年代使用率不高; 并且Full GC之后 Perm代变大, 确定是第3种情况, perm不够用; 解决: 增加 permSize @ref 从实际案例聊聊Java应用的GC优化 - 美团技术团队","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://beefyheisenberg.github.io/tags/JVM/"}]},{"title":"Advanced-Java.03a1.ZGC回收器详解","slug":"12.Java/Advanced-Java.03a1.ZGC回收器","date":"2024-01-24T01:27:52.080Z","updated":"2024-01-24T01:27:52.081Z","comments":true,"path":"12.Java/Advanced-Java.03a1.ZGC回收器/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Advanced-Java.03a1.ZGC回收器/","excerpt":"ZGC（The Z Garbage Collector）是 JDK 11中推出的一款低延迟垃圾回收器，它的设计目标包括： 停顿时间不超过10ms（低延迟，最大特点）； 停顿时间不会随着堆的大小，或者活跃对象的大小而增加； 支持8MB~4TB 级别的堆（未来支持16TB） STW 对吞吐量的影响 部分上游业务要求风控服务65ms 内返回结果，并且可用性要达到99.99%。但因为 GC 停顿，我们未能达到上述可用性目标。当时使用的是 CMS 垃圾回收器，单次 Young GC 40ms，一分钟10次，接口平均响应时间30ms。 受影响的请求分2部分：1是 GC 持续时间内的（30ms），2是 GC 发生前30ms 内到来的请求（40ms），所以一次 YGC 受影响的请求持续时间是70ms，一分钟10次 YGC，那么就是一分钟内，有700ms 的请求会受影响（这个比例按照持续时间计算，是70ms / 60000ms = 1.12%），这段时间内的请求，其耗时会增加0~40ms 不等，最差就是多等40ms，也就是 GC 发生前30ms ~ GC 刚开始的时候到来的请求（30ms），这些请求的耗时会多出整整40ms；","text":"ZGC（The Z Garbage Collector）是 JDK 11中推出的一款低延迟垃圾回收器，它的设计目标包括： 停顿时间不超过10ms（低延迟，最大特点）； 停顿时间不会随着堆的大小，或者活跃对象的大小而增加； 支持8MB~4TB 级别的堆（未来支持16TB） STW 对吞吐量的影响 部分上游业务要求风控服务65ms 内返回结果，并且可用性要达到99.99%。但因为 GC 停顿，我们未能达到上述可用性目标。当时使用的是 CMS 垃圾回收器，单次 Young GC 40ms，一分钟10次，接口平均响应时间30ms。 受影响的请求分2部分：1是 GC 持续时间内的（30ms），2是 GC 发生前30ms 内到来的请求（40ms），所以一次 YGC 受影响的请求持续时间是70ms，一分钟10次 YGC，那么就是一分钟内，有700ms 的请求会受影响（这个比例按照持续时间计算，是70ms / 60000ms = 1.12%），这段时间内的请求，其耗时会增加0~40ms 不等，最差就是多等40ms，也就是 GC 发生前30ms ~ GC 刚开始的时候到来的请求（30ms），这些请求的耗时会多出整整40ms； +40ms | +0~40ms | -无影响- | req | STW | req | req |--------► ---------► --------► --------►| 30ms | 40ms | 30ms | 30ms | G1停顿时间瓶颈G1的混合回收过程可以分为标记阶段、清理阶段和复制阶段。 初始标记(STW), 并发标记, 再标记(STW), 清理(STW), 初始转移(STW), 并发转移 标记阶段停顿分析 初始标记阶段：初始标记阶段是指从GC Roots出发标记全部直接子节点的过程，该阶段是STW的。由于GC Roots数量不多，通常该阶段耗时非常短。 并发标记阶段：并发标记阶段是指从GC Roots开始对堆中对象进行可达性分析，找出存活对象。该阶段是并发的，即应用线程和GC线程可以同时活动。并发标记耗时相对长很多，但因为不是STW，所以我们不太关心该阶段耗时的长短。 再标记阶段：重新标记那些在并发标记阶段发生变化的对象。该阶段是STW的。 清理阶段停顿分析 清理阶段清点出有存活对象的分区和没有存活对象的分区，该阶段不会清理垃圾对象，也不会执行存活对象的复制。该阶段是STW的。 复制阶段停顿分析 复制算法中的转移阶段需要分配新内存和复制对象的成员变量。转移阶段是STW的，其中内存分配通常耗时非常短，但对象成员变量的复制耗时有可能较长，这是因为复制耗时与存活对象数量与对象复杂度成正比。对象越复杂，复制耗时越长。 四个 STW 过程中，初始标记因为只标记 GC Roots，耗时较短。再标记因为对象数少，耗时也较短。清理阶段因为内存分区数量少，耗时也较短。转移阶段要处理所有存活的对象，耗时会较长。因此，G1停顿时间的瓶颈主要是标记-复制中的转移阶段 STW。为什么转移阶段不能和标记阶段一样并发执行呢？主要是 G1未能解决转移过程中准确定位对象地址的问题。 G1的 Young GC 和 CMS 的 Young GC，其标记-复制全过程 STW，这里不再详细阐述。 ZGC 细节动态 RegionZCG 不再有 CMS、G1的分代概念，同时采用基于 Region 的堆内存布局（与 Shenandoah 和 G1一样），但与它们不同的是， ZGC 的 Region 具有动态性 ： 动态创建 动态销毁 以及动态的区域容量大小 ZGC 的 Region 可以具有大、中、小三类容量: Small Region：2MB，主要用于放置小于 256 KB 的小对象。 Medium Region：32MB，主要用于放置大于等于 256 KB 小于 4 MB 的对象。 Large Region：N * 2MB,这个类型的 Region 是可以动态变化的，不过必须是 2MB 的整数倍，最小支持 4 MB。每个 Large Region 只放置一个大对象，并且是不会被重分配的。 ZGC阶段ZGC 的垃圾回收周期分为如下几个阶段： 初始标记：初始标记阶段是指从 GC Roots 出发标记全部直接子节点的过程，GC Roots 数量不多，通常该阶段耗时非常短，需要STW； 并发标记/对象重定位：从 GC Roots 开始对堆中对象进行可达性分析，并发标记耗时相对长很多，但该阶段是并发的，无需 STW； 再标记：重新标记那些在并发标记阶段发生变化的对象。再标记因为对象数少，耗时较短，需要 STW； 并发转移准备： 初始转移：只处理 GC Roots，耗时较短，需要 STW； 并发转移：GC 线程和应用线程一起工作； ZGC 只有三个 STW 阶段：初始标记，再标记，初始转移。 初始标记和初始转移分别都只需要扫描所有 GC Roots，其处理时间和 GC Roots 的数量成正比，一般情况耗时非常短；再标记阶段 STW 时间很短，最多1ms，超过1ms 则再次进入并发标记阶段。即 ZGC 几乎所有暂停都只依赖于 GC Roots 集合大小，停顿时间不会随着堆的大小或者活跃对象的大小而增加。 ZGC 转移阶段的优化： G1 和 ZCG 都基于 标记-复制算法，所以都会有转移阶段，即把存活对象转移到新的 Region 中； G1的 转移阶段完全 STW 的，且停顿时间随存活对象的大小增加而增加； ZGC 把转移阶段分为了初始/并发两个阶段，并发转移虽然耗时较长但不需要 STW； ZGC 低延迟的实现ZGC 在标记、转移和重定位阶段几乎都是并发的，这是 ZGC 实现停顿时间小于10ms 目标的最关键原因。 ZGC 是如何做到并发标记和转移呢？这就要提到 ZGC 背后的核心技术 —— 读屏障（ load barrier ）和染色指针（ colored pointer ） 并发转移 中“并发”意味着GC线程在转移对象的过程中，应用线程也在不停地访问对象。假设对象发生转移，但对象地址未及时更新，那么应用线程可能访问到旧地址，从而造成错误。而在ZGC中，应用线程访问对象将触发“读屏障”，如果发现对象被移动了，那么“读屏障”会把读出来的指针更新到对象的新地址上，这样应用线程始终访问的都是对象的新地址。那么，JVM是如何判断对象被移动过呢？就是利用对象引用的地址，即着色指针。下面介绍着色指针和读屏障技术细节。 ➤ ZGC 通过 指针着色 和 读屏障 来实现的并发标记和并发转移： （1）指针着色：ZGC 仅支持64位系统，对象指针占用空间=64bit，其中真正作为地址的是0-41位，42-45存储指针着色，高18位不使用（42+4+18）； 其中表示染色状态的4位： finalizable 位：该对象只能通过终结器（finalizer）访问 remap 位：引用是最新的，并指向对象的当前位置 marked0 和 marked1 位：标记可达对象 对比过去的 GC，对象的存活信息是放在对象头的 Mark Word 中，而 ZGC 将对象存活信息存储在对象指针的4bits 中，少了一次读内存的操作。 传统的垃圾回收器需要进行一次内存访问，并将对象存活信息放在对象头中；而在 ZGC 中，只需要设置对象指针的第42~45位即可，并且因为是寄存器访问，所以速度比访问内存更快。 （2）读屏障： 即在“读操作”之后加入一小段代码，这段代码会修改指针的着色，这里的读操作指仅“从堆中读取对象引用”，无论GC 标记线程 和 应用线程 对这些引用的读取，都会被加入读屏障。 读屏障示例：Object o = obj.FieldA // 从堆中读取引用，需要加入屏障&lt;Load barrier&gt;Object p = o // 无需加入屏障，因为不是从堆中读取引用o.dosomething() // 无需加入屏障，因为不是从堆中读取引用int i = obj.FieldB //无需加入屏障，因为不是对象引用 接下来详细介绍 ZGC 一次垃圾回收周期中地址视图的切换过程（这里的几种视图可以理解为几种不同的指针着色标记）： 初始化：ZGC 初始化之后，整个内存空间的地址视图被设置为Remapped。程序正常运行，在内存中分配对象，满足一定条件后垃圾回收启动，此时进入标记阶段。 并发标记阶段：第一次进入标记阶段时视图为 M0，如果对象被 GC 标记线程或者应用线程访问过，那么就将对象的地址视图从 Remapped 调整为 M0。所以，在标记阶段结束之后，对象的地址要么是 M0视图，要么是 Remapped。*如果对象的地址是 M0视图，那么说明对象是活跃的；如果对象的地址是 Remapped 视图，说明对象是不活跃的。 并发转移阶段：标记结束后就进入转移阶段，此时地址视图再次被设置为 Remapped。如果对象被 GC 转移线程或者应用线程访问过，那么就将对象的地址视图从 M0调整为 Remapped。 在标记阶段存在两个地址视图 M0和 M1，上面的过程显示只用了一个地址视图。之所以设计成两个，是为了区别前一次标记和当前标记。第一次进入并发标记，视图调整为 M0，第二次进入并发标记阶段后，地址视图调整为 M1； 如下图所示，有3个对象1、2、3，初始阶段都是 “Remapped”.. ZGC 线上效果美团的案例： （1）可显著降低 TP999 和 TP99耗时，ZGC 在低延迟（TP999 &lt; 200ms）场景中收益较大： TP999：下降12~142ms，下降幅度18%~74%。 TP99：下降5~28ms，下降幅度10%~47%。 但超低延迟（TP999 &lt; 20ms）和高延迟（TP999 &gt; 200ms）服务收益不大，原因是这些服务的响应时间瓶颈不是 GC，而是外部依赖的性能。 TP(Top Percentile)是一项衡量系统延迟的指标：TP999表示99.9%请求都能被响应的最小耗时；TP99表示99%请求都能被响应的最小耗时。 （2）低延迟的代价是吞吐下降： 对吞吐量优先的场景，ZGC 可能并不适合。例如，Zeus 某离线集群原先使用 CMS，升级 ZGC 后，系统吞吐量明显降低。究其原因有二： 第一，ZGC 是单代垃圾回收器，而 CMS 是分代垃圾回收器。单代垃圾回收器每次处理的对象更多，更耗费 CPU 资源； 第二，ZGC 使用读屏障，读屏障操作需耗费额外的计算资源。 吞吐量: 系统的生命周期内，应用程序所花费的时间和系统总运行时间的比值。系统总运行时间 = 应用程序耗时 + 总 GC 耗时。for example:如果系统运行了 100 分钟，全部 GC 耗时 1 分钟，则系统吞吐量=99% 注意区别系统设计中的“Thoughput” ZGC 调优实践 -Xms -Xmx：堆的最大内存和最小内存，这里都设置为10G，程序的堆内存将保持10G 不变。 -XX:+UnlockExperimentalVMOptions -XX:+UseZGC：启用 ZGC 的配置。 -XX:ConcGCThreads：并发回收垃圾的线程。默认是总核数的12.5%，8核 CPU 默认是1。调大后 GC 变快，但会占用程序运行时的 CPU 资源，吞吐会受到影响。 -XX:ParallelGCThreads：STW 阶段使用线程数，默认是总核数的60%。 -XX:ZCollectionInterval：ZGC 发生的最小时间间隔，单位秒。 -XX:ZAllocationSpikeTolerance：ZGC 触发自适应算法的修正系数，默认2，数值越大，越早的触发 ZGC。 -XX:+UnlockDiagnosticVMOptions -XX:-ZProactive：是否启用主动回收，默认开启，这里的配置表示关闭。 -Xlog：设置 GC 日志中的内容、格式、位置以及每个日志的大小。 ZGC 日志分析https://tech.meituan.com/2020/08/06/new-zgc-practice-in-meituan.html Reference 新一代垃圾回收器ZGC的探索与实践 - 美团技术团队 丝般顺滑！全新垃圾回收器 ZGC 原理与调优｜龙蜥技术-阿里云开发者社区 Java ZGC垃圾收集器(算法及回收原理详解) – mikechen ZGC 原理是什么，它为什么能做到低延时？ - 知乎","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[]},{"title":"Advanced-Java.03a1.G1回收器详解","slug":"12.Java/Advanced-Java.03a1.G1回收器","date":"2024-01-24T01:27:52.075Z","updated":"2024-01-24T01:27:52.075Z","comments":true,"path":"12.Java/Advanced-Java.03a1.G1回收器/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Advanced-Java.03a1.G1回收器/","excerpt":"G1概述G1（garbage first）垃圾回收器是在 Java7 update 4之后引入的一个新的垃圾回收器，Java9成为默认回收器。G1依旧是一个分代的 GC、但与 CMS 不同的是，G1是带 compacting（压缩）的、同时可以进行新生代和老年代的 GC（CMS 只能用于老年代）。 它的设计目标是为了适应现在不断扩大的内存和不断增加的处理器数量，进一步降低暂停时间（pause time），同时兼顾良好的吞吐量。 G1的内存划分CMS 时期，JVM 内存分代将连续的内存空间划分为新生代、老年代和永久代（JDK 8去除了永久代，引入了元空间 Metaspace），这种划分的特点是各代的存储地址（逻辑地址，下同）是连续的。如下图所示：","text":"G1概述G1（garbage first）垃圾回收器是在 Java7 update 4之后引入的一个新的垃圾回收器，Java9成为默认回收器。G1依旧是一个分代的 GC、但与 CMS 不同的是，G1是带 compacting（压缩）的、同时可以进行新生代和老年代的 GC（CMS 只能用于老年代）。 它的设计目标是为了适应现在不断扩大的内存和不断增加的处理器数量，进一步降低暂停时间（pause time），同时兼顾良好的吞吐量。 G1的内存划分CMS 时期，JVM 内存分代将连续的内存空间划分为新生代、老年代和永久代（JDK 8去除了永久代，引入了元空间 Metaspace），这种划分的特点是各代的存储地址（逻辑地址，下同）是连续的。如下图所示： G1对 JVM 内存的划分： G1依然有 Eden、Survivor、Tenured 的分代概念，但是各代存储地址是不连续的，每个分代由多个 Region 组成； 一个 Region 的大小可以通过参数-XX:G1HeapRegionSize 设定，取值范围从1M 到32M，且是2的指数。如果不设定，那么 G1会根据 Heap 大小自动决定（2048） 每个 Region 都可以作为 Eden、Survivor、Old 分代的一部分，此外还有 Humongous 类型的 Region，这些 Region 存储的是巨大对象（humongous object，H-obj），即大小大于等于 region 一半的对象。H-obj 有如下几个特征： H-obj 直接分配到了 old gen，防止了反复拷贝移动。 H-obj 在 global concurrent marking 阶段的 cleanup 和 full GC 阶段回收。 在分配 H-obj 之前先检查是否超过 initiating heap occupancy percent 和 the marking threshold, 如果超过的话，就启动 global concurrent marking，为的是提早回收，防止 evacuation failures 和 full GC。 为了减少连续 H-objs 分配对 GC 的影响，需要把大对象变为普通的对象，建议增大 Region size。 RSet：解决跨代引用全称是 Remembered Set（记忆集），作用类似 CMS 中的卡表，用来处理跨代引用的问题： G1中依然使用卡页（Card，大小512B），作为管理对象分配的最小单元； 每个 Region 都有一个 RSet，记录了“谁引用了本 Region 中的对象”，这个 RSet 其实是一个 Hash Table，Key 是别的 Region 的起始地址，Value 是一个集合，里面的元素是“引用了它的对象”所在的 Card Table 的 Index。 比较 RSet 与 “卡表”： RSet 记录了其他 Region 中的对象引用本 Region 中对象的关系，属于 points-into 结构（谁引用了我的对象）。而 Card Table 则是一种 points-out（我引用了谁的对象）的结构； 下图表示了 RSet、Card 和 Region 的关系（出处）： 上图中有三个 Region，每个 Region 被分成了多个 Card，在不同 Region 中的 Card 会相互引用，Region1中的 Card 中的对象引用了 Region2中的 Card 中的对象，蓝色实线表示的就是 points-out 的关系，而在 Region2的 RSet 中，记录了 Region1的 Card，即红色虚线表示的关系，这就是 points-into。而维系 RSet 中的引用关系靠 write barrier 和 Concurrent refinement threads 来维护： 这里的 write barrier 和 CMS 中的卡表标记置脏类似，通过在“更新引用”的字节码后加一个记录，这些记录被写入缓冲区 /注意区分这个 write barrier 和 Volatile 屏障是完全不同的概念/； 当缓冲区满了，write barrier 就停止服务了，会由 Concurrent refinement threads 处理这些缓冲区日志 在做YGC的时候，只需要选定 young generation region 的 RSet作为根集，这些RSet记录了old-&gt;young的跨代引用，避免了扫描整个old generation。而mixed gc的时候（清理全部的 young generation + 部分选定的 old generation），old generation中记录了old-&gt;old的RSet，young-&gt;old的引用由扫描全部 young generation region得到，这样也不用扫描全部 Old Region。所以RSet的引入大大减少了GC的工作量。 CSet：收集集合Collection Set（CSet），它记录了下次 GC 要收集哪些 Region，被选入 CSet 的 Region 将会被 GC 回收，Region 能否进入 CSet的条件，见「Mixed GC」一节。 G1的日志中也有关于 CSet 的记录：2014-11-14T17:57:23.654+0800: 27.884: [GC pause (G1 Evacuation Pause) (young)Desired survivor size 11534336 bytes, new threshold 15 (max 15)- age 1: 5011600 bytes, 5011600 total# _pending_cards是关于RSet的Card Table。predicted base time是预测的扫描card table时间 27.884: [G1Ergonomics (CSet Construction) start choosing CSet, _pending_cards: 1461, predicted base time: 35.25 ms, remaining time: 64.75 ms, target pause time: 100.00 ms]# 添加Region到CSet，新生代一共159个Region，13个幸存区Region 27.884: [G1Ergonomics (CSet Construction) add young regions to CSet, eden: 159 regions, survivors: 13 regions, predicted young region time: 44.09 ms]# 完成CSet的选择，统计数据 27.884: [G1Ergonomics (CSet Construction) finish choosing CSet, eden: 159 regions, survivors: 13 regions, old: 0 regions, predicted pause time: 79.34 ms, target pause time: 100.00 ms] GC 流程G1提供了两种 GC 模式，Minor GC 和 Mixed GC，两种都是有 Stop The World 的。 Minor GC：选定所有年轻代里的 Region。通过控制年轻代的 Region 个数，即年轻代内存大小，来控制 Minor GC 的时间开销。 Mixed GC：选定所有年轻代里的 Region，另外增加根据 global concurrent marking 统计得出收集收益高的若干老年代 Region。在用户指定的开销目标范围内尽可能选择收益高的老年代 Region。 Minor GC、Concurrent marking、Mixed GC 的执行流程也不是固定的。比如，可能 1 次 Minor GC 后，发生了一次 Concurrent marking，接着发生了 9 次 Mixed GC。 图片来自https://c-guntur.github.io/java-gc/#/ ① Minor GCMinor GC 是全过程 STW 的，它的跨代引用使用 RSet 数据结构来追溯，会一次性回收掉年轻代的所有 Region。 触发条件：和过去的 Minor GC 一样，“当所有的 Eden Region 都无法再分配对象时”。 包括下面的回收阶段： （1）从 GC Roots 开始扫描，加上 RSet 记录的其他 Region 的外部引用； （2）更新 RSet：处理 dirty card queue 中的卡页，加入到 Region的 RSet； （3）从 RSet 开始扫描：对于从 Old Region → Eden 的跨代引用，作为存活的对象； （4）复制对象：收集算法依然使用的是 Copy 算法。Eden 区内存段中存活的对象会被复制到 Survivor Region，如果需要晋升，则复制到 Old Region。 （5）处理引用，处理 Soft、Weak、Phantom、Final、JNI Weak 等引用队列。 ② Concurrent Marking Cycle并发标记周期（Concurrent Marking Cycle）触发条件： 当整个堆内存使用达到一定比例（默认是 45%），并发标记阶段就会被启动。这个比例也是可以调整的，通过参数 -XX:InitiatingHeapOccupancyPercent 进行配置。 Concurrent Marking 是为 Mixed GC 提供标记服务的，并不是一次 GC 过程的一个必须环节。这个过程和 CMS 垃圾回收器的回收过程非常类似，你可以类比 CMS 的回收过程看一下。具体标记过程如下： （1）初始标记（Initial Mark）：这个过程共用了 Minor GC 的暂停，这是因为它们可以复用 root scan 操作。虽然是 STW 的，但是时间通常非常短。 （2）并发标记（ Concurrent Mark）：这个阶段从 GC Roots 开始对 heap 中的对象标记，标记线程与应用程序线程并行执行，并且收集各个 Region 的存活对象信息。 （3）重新标记（Remaking）：和 CMS 类似也是 STW 的，标记那些在并发标记阶段发生变化的对象。 （5）清理阶段（Cleanup）：这个过程不需要 STW，这一阶段只会清理全都是垃圾的Region，不全是垃圾的 Region并不会被立马处理，它会在 Mixed GC 阶段进行收集。 保证并发标记的正确性无论 CMS 还是 G1都存在并发标记阶段，这一阶段 Mutator 线程 和 Garbage Collector 线程 同时对对象进行修改，那么并发阶段是如何保证标记的正确性呢？ 主要需要解决2个问题： 漏标（存活的对象没有被标记，导致被回收） 多标（垃圾对象被标记为存活，导致不能在下次 GC 被回收） 三色标记法我们把遍历对象图过程中遇到的对象，按“是否访问过”这个条件标记成以下三种颜色： 白色：尚未访问过。 黑色：本对象已访问过，而且本对象 引用到 的其他对象 也全部访问过了。 灰色：本对象已访问过，但是本对象 引用到 的其他对象 尚未全部访问完。全部访问后，会转换为黑色。 三色标记遍历过程： 初始时，所有对象都在 【白色集合】中； 将GC Roots 直接引用到的对象 挪到 【灰色集合】中； 从灰色集合中获取对象： 3.1. 本对象 引用到的 其他对象 全部挪到 【灰色集合】中； 3.2. 本对象 挪到 【黑色集合】里面。 重复步骤3，直至【灰色集合】为空时结束。 结束后，仍在【白色集合】的对象即为 GC Roots 不可达，可以进行回收。 SATB了解了三色标记法，然后继续看 G1如何解决并发标记的问题： ➤ G1使用了 “原始快照”（Snapshot-At-The-Beginning，SATB） 来处理漏标，由字面理解，是GC开始时活着的对象的一个快照。它是通过 Root Tracing得到的，作用是维持并发GC的正确性。 当赋值语句发生时，快照发生改变，JVM 会将这次改变记录到 SATB日志 中，每个线程都会独占一个SATB缓冲区，初始有256条记录空间。当空间用尽时，线程会分配新的SATB缓冲区继续使用，而原有的缓冲去则加入全局列表中。最终在并发标记阶段，并发标记线程(Concurrent Marking Threads)在标记的同时，还会定期检查和处理全局缓冲区列表的记录，然后根据标记位图分片的标记位，扫描引用字段来 更新RSet。 下面看 SATB机制如何解决漏标的问题：漏标可以理解为并发标记过程中，一个白对象被重新引用了，变成了存活对象，这时要防止该白对象被漏标导致错误的回收。 对于并发标记期间 new 出来的白对象：Region 中有两个 top-at-mark-start（TAMS）指针，分别为 prevTAMS 和 nextTAMS。在 TAMS 以上的对象是新分配的，这是一种隐式的标记，这样就解决了此类对象被漏标的情况； 对于标记期已经存在的白对象，假如出现了漏标，只能是下面2个条件同时发生时： （1）断开了灰对象 -&gt; 白对象的引用 （2）增加了黑对象 -&gt; 白对象的引用 只有这2条同时发生，此白对象才是“漏标”对象，如果破坏上面任一条件，都可以防止漏标 G1的做法是，在（1）发生时，即 灰→白的引用消失，通过写屏障记录下这次改动（SATB），并发标记完成后，对该记录进行重新扫描； CMS 的做法是在（2）发生时，即新增了黑 -&gt; 白的引用，记录这次改动（incremental update），把黑色重新标记为灰色，下次会重新扫描灰色对象； 通过写屏障，将引用的变化记录下来，并发优化线程(Concurrence Refinement Threads)将这些记录更新到 RSet 中； 此外， Write Barrier （写屏障）有很多应用场景：除了上面的 STAB，还有 CMS 时期的卡表（Card_Table）。 ➤ 对于多标（浮动垃圾），产生的条件是： 并发标记期间， new 出来的对象 对“灰色对象”的引用被断开 对于情况1，并发期间新建对象，通常的做法是直接全部当成黑色，本轮不会进行清除。这部分对象期间可能会变为垃圾，这也算是浮动垃圾的一部分。 对于情况2，G1似乎没有特殊处理， ③ Mixed GCMixed GC 触发条件：通过 Concurrent Marking 阶段，我们已经统计了老年代的垃圾占比。在 Minor GC 之后，如果判断这个占比达到了某个阈值，下次就会触发 Mixed GC。这个阈值，由 -XX:G1HeapWastePercent 参数进行设置（默认是堆大小的 5%）。 虽然触发条件是老年代的垃圾占比，但 Mixed GC 同名字一样，会回收全部的 Young Region 外加一部分 Old Region，通过上一阶段 concurrent marking 的统计结果，选出收益高的 Old Region 进入 CSet，从而实现对 GC 暂停时间的控制； Mixed GC 不是full GC，它只能回收部分老年代的Region，如果mixed GC实在无法跟上程序分配内存的速度，导致老年代填满无法继续进行Mixed GC，就会使用serial old GC（full GC）来收集整个GC heap； 其他 Mixed GC 相关的参数： -xx:G1MixedGCLiveThresholdPercent：Old Region 中的存活对象的占比，低于这个值的 Region，才会被选入 CSet。 -xx:G1MixedGCCountTarget：一次 global concurrent marking 之后，最多执行 Mixed GC 的次数。 -xx:G1OldCSetRegionThresholdPercent：一次Mixed GC中能被选入CSet的最多Old Region数量。 停顿预测Pause Prediction Model 即停顿预测模型。它在G1中的作用是： G1 uses a pause prediction model to meet a user-defined pause time target and selects the number of regions to collect based on the specified pause time target. G1 GC是一个响应时间优先的GC算法，它与CMS最大的不同是，用户可以设定整个GC过程的期望停顿时间，参数-XX:MaxGCPauseMillis指定一个G1收集过程目标停顿时间，默认值200ms，不过它不是硬性条件，只是期望值。那么G1怎么满足用户的期望呢？就需要这个停顿预测模型了。G1根据这个模型统计计算出来的历史数据来预测本次收集需要选择的Region数量，从而尽量满足用户设定的目标停顿时间。 停顿预测模型是以衰减标准偏差为理论基础实现的： // share/vm/gc_implementation/g1/g1CollectorPolicy.hppdouble get_new_prediction(TruncatedSeq* seq) &#123; return MAX2(seq-&gt;davg() + sigma() * seq-&gt;dsd(), seq-&gt;davg() * confidence_factor(seq-&gt;num()));&#125; 在这个预测计算公式中：davg表示衰减均值，sigma()返回一个系数，表示信赖度，dsd表示衰减标准偏差，confidence_factor表示可信度相关系数。而方法的参数TruncateSeq，顾名思义，是一个截断的序列，它只跟踪了序列中的最新的n个元素。 在G1 GC过程中，每个可测量的步骤花费的时间都会记录到 TruncateSeq（继承了AbsSeq）中，用来计算衰减均值、衰减变量，衰减标准偏差等： // src/share/vm/utilities/numberSeq.cppvoid AbsSeq::add(double val) &#123; if (_num == 0) &#123; // if the sequence is empty, the davg is the same as the value _davg = val; // and the variance is 0 _dvariance = 0.0; &#125; else &#123; // otherwise, calculate both _davg = (1.0 - _alpha) * val + _alpha * _davg; double diff = val - _davg; _dvariance = (1.0 - _alpha) * diff * diff + _alpha * _dvariance; &#125;&#125; 比如要预测一次GC过程中，RSet的更新时间，这个操作主要是将Dirty Card加入到RSet中，具体原理参考前面的RSet。每个Dirty Card的时间花费通过_cost_per_card_ms_seq来记录，具体预测代码如下： // share/vm/gc_implementation/g1/g1CollectorPolicy.hpp double predict_rs_update_time_ms(size_t pending_cards) &#123; return (double) pending_cards * predict_cost_per_card_ms(); &#125; double predict_cost_per_card_ms() &#123; return get_new_prediction(_cost_per_card_ms_seq); &#125; 参数汇总@ref: Garbage-First Garbage Collector Tuning -XX:G1HeapRegionSize=n 设置Region大小，并非最终值 -XX:MaxGCPauseMillis 设置停顿的目标时间，默认值200ms -XX:G1NewSizePercent 新生代最小值，默认值5% -XX:G1MaxNewSizePercent 新生代最大值，默认值60% -XX:ParallelGCThreads STW期间，并行GC线程数 -XX:ConcGCThreads=n 并发标记阶段，并行执行的线程数 -XX:InitiatingHeapOccupancyPercent 设置触发标记周期的 Java 堆占用率阈值。默认值是45% 日志解析@ref: https://tech.meituan.com/2016/09/23/g1.html Reference G1垃圾收集器深入剖析(图文超详解) – mikechen Java Hotspot G1 GC的一些关键技术 - 美团技术团队 JVM 三色标记 增量更新 原始快照 - hongdada - 博客园 GC - Java 垃圾回收器之G1详解 | Java 全栈知识体系","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[]},{"title":"Advanced Java-03a-GC","slug":"12.Java/Advanced-Java.03a.GC","date":"2024-01-24T01:27:52.069Z","updated":"2024-01-24T01:27:52.070Z","comments":true,"path":"12.Java/Advanced-Java.03a.GC/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Advanced-Java.03a.GC/","excerpt":"Minor/Major/Full GC① Minor GC: 在年轻代 Young space(包括 Eden 区和 Survivor 区)中的垃圾回收称之为 Minor GC，或 Young GC 触发条件: 各种 GC 收集器的触发 Minor GC 的条件都是 Eden 区满了 STW: Minor GC 会 Stop the World，如果 Eden 区大部分对象都要被 GC（这也是正常情形）Minor GC 耗时可以基本不记，但是如果 Eden 区大部分对象都不符合 GC 条件，暂停时间将会长很多。 GC 过程: 一般使用 Copy GC, 具体步骤如下 用 new 或者 newInstance 等方式创建的对象默认都是存放在 Eden 区，Eden 满了触发 Minor GC，把存活的对象放入 S 0，并清空 Eden； 第二次 Eden 满了，会把 Eden 和 S 0 的存活对象放入 S 1，并清空 Eden 和 S0区； 在几次 Minor GC 后, 有些对象在 S 0/S 1 之间来回拷贝几次, 将会进入老年代(Tenured), 所以 young GC 后 OldGen 的占用量通常会有所升高； ↑ Minor GC 图例: 左边是 Minor GC 前(黄色是垃圾对象, 红色是存活对象), 右边是 Minor GC 后","text":"Minor/Major/Full GC① Minor GC: 在年轻代 Young space(包括 Eden 区和 Survivor 区)中的垃圾回收称之为 Minor GC，或 Young GC 触发条件: 各种 GC 收集器的触发 Minor GC 的条件都是 Eden 区满了 STW: Minor GC 会 Stop the World，如果 Eden 区大部分对象都要被 GC（这也是正常情形）Minor GC 耗时可以基本不记，但是如果 Eden 区大部分对象都不符合 GC 条件，暂停时间将会长很多。 GC 过程: 一般使用 Copy GC, 具体步骤如下 用 new 或者 newInstance 等方式创建的对象默认都是存放在 Eden 区，Eden 满了触发 Minor GC，把存活的对象放入 S 0，并清空 Eden； 第二次 Eden 满了，会把 Eden 和 S 0 的存活对象放入 S 1，并清空 Eden 和 S0区； 在几次 Minor GC 后, 有些对象在 S 0/S 1 之间来回拷贝几次, 将会进入老年代(Tenured), 所以 young GC 后 OldGen 的占用量通常会有所升高； ↑ Minor GC 图例: 左边是 Minor GC 前(黄色是垃圾对象, 红色是存活对象), 右边是 Minor GC 后 ② Major GC: 清理老年代（Tenured space） 触发条件: CMS：老年代使用率超过某个阈值,默认大约 90% 通过 -XX:CMSInitiatingOccupancyFraction 设置； G1：Heap 使用比例超过某个阈值； STW: 一般 Tracing GC 在标记和清理阶段都会有 STW, 具体 STW 耗时根据使用哪种 GC 收集器而定； GC 过程: 使用 Mark-Sweep 或 Mark-Compact 算法； ③ Full GC: 清理整个堆，包括 YoungGen / OldGen / PermGen（1.8 之前） / Matespace(1.8+)等所有部分的全局范围的 GC。 触发条件： 在将要进行(Young GC)时, 如果发现要晋升至 OldGen 的对象大小比 OldGen 剩余大小更大, 则不会触发 young GC 而是转为触发 full GC; // 如果是用的 CMS 收集器可以在日志中看到 “promotion failed” 和 “concurrent mode failure” 方法区满了触发(在 Java 8 之前)，或者 Metaspace 使用量达到 MaxMetaspace 阈值(Java 8+)； 调用 System.gc(): 此方法的调用是建议 JVM 进行 Full GC,虽然只是建议而非一定,但很多情况下它会触发 Full GC,从而增加 Full GC 的频率,也即增加了间歇性停顿的次数 当执行 jmap -histo:live 或者 jmap -dump:live，可能也会 STW: 视不同的 GC 收集器而定 GC 过程: 同上 需要明白的一点，我们在 jstat 或 GC 日志中看不到 Minor GC/ Major GC / Full GC 这些名词, 这些术语无论是在 JVM 规范还是在垃圾收集研究论文中都没有正式的定义.需要注意的是，无论是 jstat 返回还是 GC 日志，其中的 “Full GC” 并不是真正的 Full GC 发生次数, CMS GC 两个阶段(初始标记和 Remark)都会 Stop the World, 这两次 STW 在 jstat 里被视作了两次 Full GC，所以 jstat 的 FGC 更接近于统计 cms “Stop the World”的次数；如果要判断是否真的发生 Full GC，还要看 GC 发生时，是不是三个分代使用率都发生了下降； @ref: Major GC和Full GC的区别是什么？触发条件呢？ - 知乎 GC 算法对象存活判断判断对象存活的两种方法: ① 引用计数法：每个对象有一个引用计数属性，新增一个引用时计数加 1，引用释放时计数减 1，计数为 0 时可以回收。此方法简单，无法解决对象相互循环引用的问题：比如对象 a 和 b 互相有一个对方的引用，虽然两个对象都没用了但是计数却不为0。 现在主流的 JVM 无一使用引用计数方式来实现 Java 对象的自动内存管理，但 Py 和 PHP 似乎是用的这种方法； ② 可达性分析法（Reachability Analysis）：它的处理方式就是，设立若干种 roots 对象，roots 对象作为起点在图中进行深度优先遍历，每访问到一个对象，则该对象称为“可达对象”，也就是还活着的对象。否则就是不可达对象，可以被回收。 JVM 里适用于老年代的 GC 收集器都使用了”可达性分析”来判断对象是否存活，即从“GC Roots”对象出发，对堆内的对象进行 DFS 遍历。 什么是 GC Roots：对于一个正在回收的空间，所有不在这个空间里又指向本空间中的对象的引用的集合就是“GC roots”。一般而言，GC Roots 包括（但不限于）如下几种： 运行状态的线程的栈帧中，本地变量表中的对象引用 方法区中类静态属性实体引用的对象 方法区中常量引用的对象 Native 方法栈中的对象引用 由系统类加载器(system classloader)加载的对象，这些类是不能够被回收的 Copy GC 算法Copy GC 算法把空间分成两部分，一个叫分配空间(Allocation Space)，一个是幸存者空间(Survivor Space)。创建新的对象的时候都是在分配空间里创建。在 GC 的时候，把分配空间里的活动对象复制到 Survivor Space，把原来的 Allocation Space 全部清空。然后把这两个空间交换角色。 Copy GC 是从 GC roots 开始遍历对象，访问到一个对象则在 Survivor Space 分配一个与该对象大小相同的一块内存，然后把这个对象的所有数据都拷贝过去； Copying GC 是典型的采用空间换时间的方式来提升性能，因为 Survivor 空间无法直接分配对象。下面可以看到 SpotVM 的 YoungGen GC 回收器使用了1个 Allocation + 2个 Survivor，大小比例为8:1:1，这也是利用了 YoungGen 对象“朝生夕灭”的特点，大部分对象都会被回收，所以使用较小的 Survivor ； 如上所说，Copy GC 适合新生代； 在 HotsptVM 中，还会把 Allocation 称为 From space，Survivor 称为 To Space 具体的 Copy 实现可以参考 Copy GC(1) : 基本原理 - 知乎、 Copy GC(3) : JVM中的实现 - 知乎， 对象头的 Mark Word 中 forwarding 指针，在 GC 过程中的作用： 假设 A 和 B 都使用了 C 对象； 第一次遍历，通过 A 访问到 C，并 copy C 到 Survivor，假设对象新地址是 C1，还需要把旧对象 C 的 forwarding 指向 C1地址 通过 B 开始遍历，访问到 C 的时候，发现 C 的 forwarding != null，则 B 需要修改 C 的地址为 C1 每进行一次 copy gc，复制到 Survivor 的对象年龄都会+1 Tracing GC 算法Tracing GC 算法, 根据是否压缩内存又分两种 Mark-Sweep和 Mark-Compact在介绍 Tracing GC 之前, 需要先熟悉几个名词, 可达性分析和 GC Roots： Mark-Sweep标记-清除算法 (Mark-Sweep)如同它的名字一样，算法分为“标记”和“清除”两个阶段： 遍历+标记，从 roots 开始进行遍历，每个访问到的对象进行 mark 清理，扫描整个 Heap 区域，对于有 mark 的对象清除标记（为了下次 GC），没有 mark 的对象直接进行清理 标记-清除算法最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其不足进行改进而得到的。它的主要不足有两个： 效率问题，标记和清除两个过程的效率都不高, 回收时间与 heap 大小成正比； 空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 关于 mark-sweep 的一些细节，参考海纳的 Tracing GC(1) - 知乎 、Tracing GC(2) - 知乎： 如何对“可达的”对象进行 mark：“在 tracing gc 时，如果一个对象存活，就将其 mark word 的最低两位都置为1”；//低2位都为11 清理阶段，直接清理掉不可达的对象，这块内存变为空闲内存，空闲内存块使用一个 free-chunk 链表管理，当下次再创建一个新对象时，从链表里选择一个合适的 chunk（使用了 first-fit，而不是 best-fit）； 对于这个空闲内存块的列表，如何避免并发加锁带来的性能损失，HotSpot 使用了 #TLAB 机制； Mark-Compact标记-整理算法 (Mark-Compact): 因为多了 Compact 步骤：即可达对象复制到 Heap 的一端，这里也需要 forwarding 指针 mark: 从 roots 开始进行遍历，访问过一个可达的对象进行mark，计算它的新位置（从 Heap start 开始分配新位置），然后对象的 forwarding 改为新地址，完成这一步后，所有可达的对象的 forwarding 指针都指向新地址，但是新地址仍是空的； 更新引用关系：遍历 mark 过的对象，如果该对象引用了另一个对象，更新引用地址改为被引用对象的 forwarding 地址。执行完这一步以后，对象之间的引用其实是不对的。因为我们只是把对象间的相互引用更新为对象的新地址，但是新地址处还没有内容； 复制对象: 这一步需要遍历整个堆？有标注的对象，复制到 forwarding 指向的新地址，没有标注的对象回收掉。 标记-整理算法是在标记-清除算法的基础上，又进行了对象的移动，需要进行3次扫描，因此吞吐量差一些，但是却解决了内存碎片的问题。如果堆中存在某些对象，它们可以经过多次 GC 而存活下来，那么这些对象就会被整理到堆的开头。所以经过几轮 Compact 以后，堆的头部位置出现空洞的可能性就会很小，这个加速就会很明显 @ref: Tracing GC(3): mark &amp; compaction - 知乎 总结：比较三种 GC 算法 copy GC： ✔︎仅一次扫描即可完成 copy + 更新 forwarding ，吞吐量大，无碎片 ✘需要额外的 Survivor space，仅适合 YoungGen（因为每次 Young GC 后大部分对象都被销毁，只需要很小的 Survivor） tracing GC： mark and Sweep ✔︎不需要额外空间，需要2次扫描，第一次标记，第二次清理 ✘有内存碎片 mark and Compact ✔︎不需要额外空间，没有内存碎片 ✘因为需要内存Compact，需要3次扫描（1更新forwarding 2更新引用 3复制+清理），吞吐量最低 总结：如果 GC 中，对象的地址发生移动，才需要更新对象的 forwarding GC 收集器GC 收集器是上面提到的几种 GC 算法的具体实现, 有些 GC 收集器只能用于新生代(比如 ParNew), 有些只用于老年代(比如 CMS), 有些可以同时用于两个代(Serial);对于每种 GC 收集器, 都要注意以下几个问题: a. 这种 GC 收集器可以用于哪个区, 如何启用;b. 实现是什么样的, 分几个阶段, 哪些阶段有 STW;c. 并行(Parallel)还是并发(Concurrent)的, 注意“并发”和“并行”的不同： 并行（Parallel）：使用多个线程同时执行 GC 任务，但此时用户线程仍然处于等待状态。并行 GC 的两个例子，一个是 ParNew，一个是 parallel scavenge。这两种 GC 的特点都是启动了多个 GC 线程来做垃圾回收。 名字 Par(allel)开头的一般都是并行 GC, 多个线程同时进行 GC, 但仍会停顿; 并发（Concurrent）：指用户任务与 GC 任务同时执行（但不一定是并行的，可能会交替执行），用户任务不会停顿。并发 GC 的一个典型例子，是 CMS，看它的名字就知道了 Concurrent Mark Sweep。 名字 C(oncurrent)开头的是并发 GC, GC 线程和工作线程并发的执行; 下图是说明了不同分代可以使用的收集器，如果两个收集器之间存在连线，就说明它们可以搭配使用: ➤ 几种常见的 GC 收集器组合： 新生代 Parallel + 老年代 Parallel Old 新生代 ParNew + 老年代 CMS 新生代, 老年代都使用 G1 为什么不使用新生代 Parallel Scavenge + 老年代 CMS？因为二者 ➤ 下面介绍 7 种 GC 收集器 : Serial① 串行回收器（Serial Garbage Collector）, 可以用于新生代和老年代, 下面都使用 Serial New 和 Serial Old 表示两代的 GC 回收器 通过 JVM 参数 -XX:+UseSerialGC 可以使用串行垃圾回收器。 特性： 新生代、老年代都可以使用串行回收器, 新生代复制算法, 老年代标记-压缩算法. 串行垃圾回收器通过持有应用程序所有的线程进行工作。它为单线程环境设计，只使用一个单独的线程进行垃圾回收，可能会产生较长的停顿，所以可能不适合服务器环境。它依然是 HotSpot 虚拟机运行在 Client 模式下的默认的新生代收集器。 ParNew② ParNew 回收器：Serial 收集器新生代的多线程版本, 只适用于新生代. -XX:+UseParNewGC（new 代表新生代，所以适用于新生代），-XX:ParallelGCThreads 线程数量 特性: ParNew 收集器就是 Serial 收集器的多线程版本，它也是一个新生代收集器。除了使用多线程进行垃圾收集外，其余行为包括 Serial 收集器可用的所有控制参数、收集算法（复制算法）、Stop The World、对象分配规则、回收策略等与 Serial 收集器完全相同，两者共用了相当多的代码 ParNew 收集器是许多运行在 Server 模式下的虚拟机中首选的新生代收集器，原因是: 除了 Serial 收集器外，目前只有它能和 CMS 收集器（Concurrent Mark Sweep）配合工作 Parallel③ 并行回收器（Parallel Garbage Collector）: 可以用于新生代和老年代, 新生代是 Parallel Scavenge 收集器( 复制算法), 老年代是 Parallel Old( 标记整理算法). JVM 参数: -XX:+UseParallelGC：新生代使用 Parallel 收集器 + 老年代使用串行收集器 -XX:+UseParallelOldGC：新生代+老年都使用 Parallel 特性: 使用多线程进行扫描堆并标记对象, 缺点是在 minor 和 full GC 的时候都会 Stop the world CMS 等收集器的关注点是尽可能缩短垃圾收集时用户线程的停顿时间，而 Parallel Scavenge 收集器的目标是达到一个可控制的吞吐量（Throughput） CMS④ CMS(Concurrent Mark Sweep), 仅适用于老年代的回收器, 是一种以获取最短回收停顿时间为目标的收集器，它非常符合那些集中在互联网站或者 B/S 系统的服务端上的 Java 应用，这些应用都非常重视服务的响应速度。从名字上（“Mark Sweep”）就可以看出它是基于“标记-清除”算法实现的。 JVM 参数: 通过 JVM 参数 -XX:+UseConcMarkSweepGC 打开 -XX:+ExplicitGCInvokesConcurrent : 使 System.gc() 触发的 Full GC 改为 CMS，防止过长的 STW 时间 -XX:CMSInitiatingOccupancyFraction=70：老年代使用率超过70%，触发 CMS GC -XX:CMSFullGCsBeforeCompaction: 进行几次Full GC后，进行一次碎片整理: 特性: 只适用于老年代 GC, 新生代可以搭配 ParNew 收集器; “初始标记”和”重新标记”阶段仍然 Stop the World, 但耗时最长的”并发标记”和”并发清除”过程收集器线程都可以与用户线程一起”并发的”工作; 因为是 Mark-Sweep 的, GC 后有内存碎片, 所以很多情况下 Old Gen 有足够空间但是仍会由 Minor GC 触发 Major GC; 当 CMS 失败出现 Concurrent Mode Failure 会转换到 Serial Old, 将导致非常长时间的 Stop The World 触发 CMS GC 的条件可能有： OldGen 使用率大于阈值 -XX:CMSInitiatingOccupancyFraction，默认92； Young GC 有大量的对象晋升，但 OldGen 空间不够的时候（注1）； 大对象（需要大量连续内存空间）触发：此类对象会直接进入老年代，而老年代虽然有很大的剩余空间，但是无法找到足够大的连续空间来分配给当前对象，-XX:PretenureSizeThreshold 令大于这个设置值的对象直接在老年代分配，这样做的目的是避免在 Eden 区及两个 Survivor 区之间发生大量的内存复制； PermGen 和 Metaspace 超过初始的阈值扩容也会引起； Heap的使用量大于 -Xms引起扩容，也会触发CMS GC，建议 -Xms 和 -Xmx 设置为相同的值； Heap的剩余空间很多也会引起缩容操作，这时也会触发CMS GC； 调用 System.gc()； 注1：空间分配担保 （1）在发生 Minor GC 之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果条件成立的话，那么 Minor GC 可以确认是安全的；（2）如果不成立的话，虚拟机会查看 HandlePromotionFailure 设置值是否允许担保失败，如果允许那么就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次 Minor GC；如果小于，或者 HandlePromotionFailure 设置不允许冒险，那么就要进行一次 Full GC。 GC步骤: 初始标记（CMS initial mark）：仅仅只是标记一下 GC Roots 能直接关联到的对象（标记直接被 GC root 引用或者被年轻代存活对象所引用的所有对象），速度很快，需要“Stop The World”。 并发标记（CMS concurrent mark）: 由上一阶段标记过的”可达对象”出发进行标记（遍历老年代），用户任务不停顿; 重新标记（CMS remark）: 暂停用户任务，对 整个堆（新生代+老年代） 开始扫描并标记。因为并发标记阶段是和用户线程并发执行的过程，所以该过程中可能有对象从“不可达”变为“可达”，这个阶段需要重新标记出此类对象，防止在下一阶段被清理掉，该阶段会“Stop The World”；特别需要注意一点，这个阶段是 以新生代中对象为 GC Roots 来判断对象是否存活的（CMS 只做老年代的 Major GC，但很多 GC Roots 在新生代，又指向了老年代的的对象（这种情况叫跨代引用），所以需要以新生代对象为 GC Roots 进行扫描, CMS预清理可以减少这一阶段的耗时（见下面 “CMS-concurrent-preclean” ）。 并发清除（CMS concurrent sweep）：用户任务不停顿; 因为阶段3需要以新生代对象为 Roots 进行整堆扫描，但如果此时新生代对象非常多，会增加这一阶段的耗时（此阶段还有 STW），所以 CMS 提供了 CMSScavengeBeforeRemark 参数，在阶段3之前强制一次 Minor GC，减轻整堆扫描的负担，这一步 Minor GC 也叫预清理，在 CMS GC 日志中可以看到“CMS-concurrent-preclean” 就是这一阶段； 同样 Minor GC 的时候，也会遇到 “老年代 -&gt; 新生代” 的跨代引用，所以理论上也需要扫描整个堆，但是实际情况“老年代 -&gt; 新生代”的概率很小，经过统计信息显示，老年代持有新生代对象引用的情况不足1%，根据这一特性 JVM 引入了卡表（card table）来实现对这种情况的监控：将老年代的空间分成大小为512B 的若干张卡（card），用一个数组表示这些 card 的状态，如果发生 “老年代 -&gt; 新生代” 的跨代引用，这个 card 对应的数组元素会被置为脏（卡表还有另外的作用，标识并发标记阶段哪些块被修改过），之后 Minor GC 时通过扫描卡表就可以很快的识别哪些卡中存在老年代指向新生代的引用。这样虚拟机通过空间换时间的方式，避免了 Minor GC 的全堆扫描。 关于卡表（CARD Table）的设计，参考 「卡表」一节 网上搜索到的很多 GC 优化，都是针对 ParNew + CMS 的组合，正因为老年代+新生代分别使用两种不同的策略，导致二者不能非常好的配合，才不得不处理跨代引用的问题，所以针对 CMS 有非常多的优化案例，更多例子参考下面的「优化案例」一节。 这种情况在 G1 和 ZGC 出现后有了改观，程序员不再需要过多干预 GC 参数了。 @ref: 从实际案例聊聊Java应用的GC优化 - 美团技术团队 G1⑤ G1 回收器 : 在 JDK 7u4 版本被正式推出，JDK 9 成为 default GC，用于逐步替换掉 CMS 收集器, G1仍然是分代的（年轻代 &amp; 老年代），而 G1最大的优势就在于可预测的停顿时间模型，我们可以自己通过参数-XX:MaxGCPauseMillis 来设置允许的停顿时间(默认200ms) → G1回收器详解 ZGC⑥ ZCG: ZGC 是 JDK 11 引入的, 在 JDK 15成为 default GC，特点是极短的 STW 时间, 无论堆的大小(上 T 级的情况)能保证 10 ms 以下的 JVM 停顿。→ ZGC回收器详解 GC 优化GC 评价指标GC 策略的评价指标： 吞吐量: 系统的生命周期内，应用程序所花费的时间和系统总运行时间的比值。系统总运行时间 = 应用程序耗时 + 总 GC 耗时。for example:如果系统运行了 100 分钟，全部 GC 耗时 1 分钟，则系统吞吐量=99% 注意区别系统设计中的“Thoughput” STW时间： 是否需要 STW，以及 STW 耗时多少 垃圾回收频率: 一般而言，频率越低越好，通常增大堆空间可以有效降低垃圾回收发生的频率，但是会增加回收时产生的停顿时间。 反应时间: 当一个对象成为垃圾后，多长时间内，它所占用的内存空间会被释放掉。 优化的过程，确定需要优化的指标，确定优化方案，最后验收结果 GC 优化案例给出一些经验性的参考值: Young CG 发生频率很高, 频率秒~分钟之间, 每次 YGC 的 STW 耗时很短, 可能不超过10ms; Major GC 正常情况大约 1-2 次/天, 如果几小时就出现一次 Major GC 属于不正常; Full GC 尽量杜绝; ➤ 一些 GC 问题的参考案例，多为一些旧时代（JDK7 + CMS）的优化: Garbage Collection Optimization for High-Throughput and Low-Latency Java Applications Linked 的 Feed 后台 GC 优化（Java7u51，ParNew+CMS、32GB Heap、6 GB YoungGen） 因为有缓存长期存活的大对象，老年代 GC 触发阈值 CMSInitiatingOccupancyFraction=92，降低 Major GC 频率 因为新生代几乎都在 eden 被回收，晋升的数量很小，所以设置了更小的晋升年龄，MaxTenuringThreshold=2，缩短新生代的停顿时间（主要是 copy 这一步耗时） 开启 AlwaysPreTouch，commit 申请内存后立刻分配物理内存，而不是等发生缺页异常，也给出了这样做的原因：GC 发生 STW 时，user time 低、system time 高 从实际案例聊聊Java应用的GC优化 - 美团技术团队 案例 1: Minor GC 非常频繁（新生对象多，导致动态晋升年龄下降，更多的对象进入老年代）这里使用了扩容 eden 降低 Minor GC 频率 案例 2: CMS 的 remark 阶段耗费非常高（该阶段有 STW，导致接口的响应时间出现非常高的情况） 案例 3: PermGen 扩容导致出现 CMS GC（full gc） 探索StringTable提升YGC性能 - 简书 StringTable 过大导致的 YGC 时间过长 java - 由「Metaspace容量不足触发CMS GC」从而引发的思考 JDK8环境使用了 CMS，Metaspace 达到扩容阈值导致 CMS GC（full gc） GC 日志解读GC 日志相关参数:-XX:+PrintGC 输出 GC 日志-XX:+PrintGCDetails 输出 GC 的详细日志-XX:+PrintGCTimeStamps 输出 GC 的时间戳（以基准时间的形式）-XX:+PrintGCDateStamps 输出 GC 的时间戳（以日期的形式，如 2013-05-04T21:53:59.234+0800）-XX:+PrintHeapAtGC 在进行 GC 的前后打印出堆的信息-Xloggc:../logs/gc.log 日志文件的输出路径 一般 GC 日志格式图 1: Young GC 日志格式解释如下(ParallelGC): 图 2: Full GC 日志格式解释如下(ParallelGC): GC 日志实例分析Serial 收集器一次 YGC 和 Full GC: 33.125: [GC [DefNew: 3324 K-&gt;152 K(3712 K), 0.0025925 secs] 3324 K-&gt;152 K(11904 K), 0.0031680 secs]# 33.125 表示从 Java 虚拟机启动以来经过的秒数# DefNew 表示新生代用了 Serial 收集器, ParNew 表示 ParNew 收集器, PSYoungGen 表示 Parallel Scavenge 收集器# 3324 K-&gt;152 K(3712 K) 表示 GC 前新生代大小-&gt;GC 后新生代大小(新生代总大小)# 3324 K-&gt;152 K(11904 K) 表示 GC 前堆大小-&gt;GC 后堆大小(堆总大小)# 0.0025925 secs 表示此次新生代 GC 耗时 2ms100.667: [Full GC [Tenured: 0 K-&gt;210 K(10240 K), 0.0149142 secs] 4603 K-&gt;210 K(19456 K), [Perm : 2999 K-&gt;2999 K(21248 K)], 0.0150007 secs] [Times: user=0.01 sys=0.00, real=0.02 secs]# 100.667 表示从 Java 虚拟机启动以来经过的秒数# Full GC 表示这是一次 Full GC# [Tenured: 0 K-&gt;210 K(10240 K), 0.0149142 secs] 老年代 GC 前-&gt;后大小# 4603 K-&gt;210 K(19456 K) 表示堆 GC 前-&gt;后# [Times: user=0.01 sys=0.00, real=0.02 secs] 表示耗时 20 ms ParNew + CMS 收集器正常的 CMS GC 日志, 可以看到 CMS 标记的三个阶段: # 初始标记, STW15578.148: [GC [1 CMS-initial-mark: 6294851 K(20971520 K)] 6354687 K(24746432 K), 0.0466580 secs] [Times: user=0.04 sys=0.00, real=0.04 secs]# 并发标记, 从 CG Root 出发开始标记15578.195: [CMS-concurrent-mark-start]15578.333: [CMS-concurrent-mark: 0.138/0.138 secs] [Times: user=1.01 sys=0.21, real=0.14 secs]# 预清理15578.334: [CMS-concurrent-preclean-start]15578.391: [CMS-concurrent-preclean: 0.056/0.057 secs] [Times: user=0.20 sys=0.12, real=0.06 secs]# 可中断预清理15578.391: [CMS-concurrent-abortable-preclean-start]15581.905: [CMS-concurrent-abortable-preclean: 3.506/3.514 secs] [Times: user=11.93 sys=6.77, real=3.51 secs]# 重新标记, STW15582.032: [weak refs processing, 0.0027800 secs]15582.035: [class unloading, 0.0033120 secs]15582.038: [scrub symbol table, 0.0016780 secs]15582.040: [scrub string table, 0.0004780 secs] [1 CMS-remark: 6299829 K(20971520 K)] 6348225 K(24746432 K), 0.1365130 secs] [Times: user=1.24 sys=0.00, real=0.14 secs]# 并发清理15582.043: [CMS-concurrent-sweep-start]15590.327: [CMS-concurrent-sweep: 8.193/8.284 secs] [Times: user=30.34 sys=16.44, real=8.28 secs] 阶段 1：Initial Mark, 这个是 CMS 两次 stop-the-wolrd 事件的其中一次，这个阶段的目标是：标记那些直接被 GC root 引用或者被年轻代存活对象所引用的所有对象， 40.146: [GC [1 CMS-initial-mark: 26386 K(786432 K)] 26404 K(1048384 K), 0.0074495 secs] 阶段 2：并发标记, 在这个阶段 Garbage Collector 会根据上个阶段找到的 GC Roots 遍历查找，标记所有存活的对象。这一阶段，Garbage Collector 与用户的应用程序并发运行。 40.683: [CMS-concurrent-mark: 0.521/0.529 secs] 阶段 3：Concurrent Preclean, 这也是一个并发阶段，与应用的线程并发运行，不会 stop-the-wolrd 。这一阶段会查找前一阶段中从新生代晋升或者有更新的对象。这一阶段可以减少 stop-the-world 的 remark 阶段的工作量 40.701: [CMS-concurrent-preclean: 0.017/0.018 secs] 阶段 4：Concurrent Abortable Preclean (可中断的预清理) 这也是一个并发阶段，同样不会不会 stop-the-wolrd 。该阶段主要工作仍然是并发标记对象是否存活，只是这个过程可被中断。此阶段在 Eden 区使用超过 2 M 时启动，当然 2 M 是默认的阈值，可以通过参数修改。如果此阶段执行时等到了 Minor GC，或者等了超过CMSMaxAbortablePrecleanTime的时间(默认 5 s)都没有发生 Minor GC，则会进入下一阶段 – Remark。// 该阶段尽量等一次 Minor GC 来减少新生代对象数量，减少 remark 阶段需要扫描新生代对象的数量，减少 remark 阶段 STW 耗时。通过CMSScavengeBeforeRemark参数，可以在这一阶段强制进行一次 Minor GC。 15581.905: [CMS-concurrent-abortable-preclean: 3.506/3.514 secs] [Times: user=11.93 sys=6.77, real=3.51 secs] 阶段 5：Remark, 这是第二个 STW 阶段，暂停所有用户线程，从 GC Root 开始重新扫描整堆，标记存活的对象。需要注意的是，虽然 CMS 只回收老年代的垃圾对象，但是这个阶段依然需要扫描新生代，因为很多 GC Root 都在新生代，而这些 GC Root 指向的对象又在老年代，这称为“跨代引用”。 15582.032: [weak refs processing, 0.0027800 secs]15582.035: [class unloading, 0.0033120 secs]15582.038: [scrub symbol table, 0.0016780 secs]15582.040: [scrub string table, 0.0004780 secs] [1 CMS-remark: 6299829 K(20971520 K)] 6348225 K(24746432 K), 0.1365130 secs] [Times: user=1.24 sys=0.00, real=0.14 secs] 阶段 6：Concurrent Sweep，并发清理，不需要 STW，需要注意的： 因为 CMS 是 Mark-Sweep 算法, 仍会存在内存碎片。 15590.327: [CMS-concurrent-sweep: 8.193/8.284 secs] [Times: user=30.34 sys=16.44, real=8.28 secs] @ref 参考: JVM 之 ParNew 和 CMS 日志分析 有 GC 问题的日志例子: 106.641: [GC 106.641: [ParNew (promotion failed): 14784 K-&gt;14784 K(14784 K), 0.0370328 secs]106.678: [CMS 106.715: [CMS-concurrent-mark: 0.065/0.103 secs] [Times: user=0.17 sys=0.00, real=0.11 secs]# ParNew (promotion failed) 表示新生代 GC 过程中, 对象晋升到老年代失败, 因为需要晋升至老年代的对象超过了老年代的可用大小# 这种情况下会触发 Full GC, 见下0.195: [GC 0.195: [ParNew: 2986 K-&gt;2986 K(8128 K), 0.0000083 secs]0.195: [CMS 0.212: [CMS-concurrent-preclean: 0.011/0.031 secs] [Times: user=0.03 sys=0.02, real=0.03 secs](concurrent mode failure): 56046 K-&gt;138 K(57344 K), 0.0271519 secs] 59032 K-&gt;138 K(65472 K), [CMS Perm : 2079 K-&gt;2078 K(12288 K)], 0.0273119 secs] [Times: user=0.03 sys=0.00, real=0.03 secs]# 第二行表示在 cms-preclean 阶段发生了 concurrent mode failure,# CMS 失败往往意味着 JVM 会退回到 Serial Old 收集器进行回收, 造成较长的 STW 上面是因为执行 ParNew GC 的时候, 因为需要晋升至老年代的对象超过了老年代的可用大小, 所以 promotion failed, 而触发了 Full GC,还存在一种情况, 老年代大小足够的情况下仍然会触发 promotion failed, 可以通过 -XX:UseCMSCompactAtFullCollection -XX:CMSFullGCBeforeCompaction=5 参数, 在 5 次 Full GC 后进行一次 Compaction 操作避免内存碎片. GC 引起的 Error什么代码会导致 GC 引起的内存错误： OutOfMemoryError:Java Heap, OutOfMemoryError:PermGen, OutOfMemoryError:Matespace, OutOfMemoryError: Direct buffer memory ? (以及堆栈错误StackOverflowError) Java 虚拟机栈和本地方法栈: 在 JVM 规范中，对 Java 虚拟机栈规定了两种异常： 如果线程请求的栈大于所分配的栈大小，则抛出 StackOverFlowError 错误，比如进行了一个不会停止的递归调用； 如果虚拟机栈是可以动态拓展的，拓展时无法申请到足够的内存，则抛出 OutOfMemoryError 错误。 堆内存: OutOfMemoryError 直接内存: 在 JDK 1.4 中引入的 NIO 使用 Native 函数库在堆外内存上直接分配内存，但直接内存不足时，也会导致 OOM。 方法区: 随着 Metaspace 元数据区的引入，方法区的 OOM 错误信息也变成了 “java.lang.OutOfMemoryError:Metaspace”。对于旧版本的 Oracle JDK，由于永久代的大小有限，而 JVM 对永久代的垃圾回收并不积极，如果往永久代不断写入数据，例如 String.Intern()的调用，在永久代占用太多空间导致内存不足，也会出现 OOM 的问题，对应的错误信为 “java.lang.OutOfMemoryError:PermGen space” GC 内存设计卡表(Card_Table)Minor GC 是回收新生代，但是免不了老年代对象引用新生代，对于这个情况，Hotspot VM 使用了“卡表”的方案：该技术将整个堆划分为一个个大小为 512 字节的卡，并且维护一个 byte 型数组，用来存储每张卡的一个标识位。这个标识位代表对应的卡是否可能存有指向新生代对象的引用。如果可能存在这种引用，那么我们就认为这张卡是脏的。然后在进行 Minor GC 时，就可以把“脏卡”中的对象加入进 CG Roots 里； 用1 byte 表示一个 512B 的内存区，何时更新这个 1byte 的标志位呢？Hotspot 的做法是截获每一个更新引用的操作，这里采用了“宁可错杀，不可放过一个”，只要有“更新引用”的操作，不管更新后是不是指向新生代，都会把对应的卡表标志置为脏； 截获引用的写操作在解释执行中比较容易实现，但在机器码执行时就不太容易做到了，HotSpot 在这里使用了 写屏障 的技术（ 这里要区别 volatile 的写屏障，二者不是一回事），具体做法是，在“引用更新”的机器码后面，插入改写卡表标志的操作： CARD_TABLE [this address &gt;&gt; 9] = DIRTY; 右移9位 = 除以512，也正好是卡表的 size，上面的 address 就是“做了引用修改”的对象的地址，这种修改卡表项的操作，只需要2个机器码（一次位移+ 一次保存），效率尚可 但是在高并发环境下，对卡表标志的写操作，还会有“伪共享”的问题（有些地方也翻译为虚共享，英文 false sharing），在对卡表项状态进行写操作时，需要把卡表项数组加载进 CPU 缓存里，CPU 缓存的最小单元是 cache line（缓存行），大小=64byte，也就是说一个 cache line 里能存储 64个卡表项标志位，对应64x512= 32KB 的 JVM 内存； 假设出现了一个最坏情况，有2个线程 A 和 B，分别运行在2个 CPU1 和 2上，线程 A 需要修改 CARD_TABLE[0]，线程 B 修改 CARD_TABLE[6]，虽然看起来不冲突，但是实际上卡表项的0和6，会被加载进一个 cache line 里（一个 cache line 能容纳64个卡表项，卡表项0~64 都会在一个 cache line），这样 A 线程改完卡表项0，CPU1要向 CPU2 发送总线消息，告诉 CPU2这个 cache line 的数据被改了，需要 CPU2 同步 cache line 的状态（这一步骤是 #MESI 协议里规定的，详情参考 [[../21.Operating-System/01.CPU_Cache]] 看似2个线程的写操作互不干扰，但实际上因为这2个写都在操作一个 cache line，导致 CPU 做了很多同步工作，这也就是“伪共享” 为此，HotSpot 引入了一个新的参数 -XX:+UseCondCardMark，来尽量减少写卡表的操作。其伪代码如下所示： if (CARD_TABLE [this address &gt;&gt; 9] != DIRTY) CARD_TABLE [this address &gt;&gt; 9] = DIRTY; @ref： 12 | 垃圾回收（下） 与程序员相关的CPU缓存知识 | 酷 壳 - CoolShell） 记忆集(RSet)Remembered Set，与卡表类似，但 RSet 是一种 points-into 结构,见 G1回收器详解","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://beefyheisenberg.github.io/tags/JVM/"}]},{"title":"Advanced Java-02d-JVM分析工具","slug":"12.Java/Advanced-Java.02d.JVM分析工具","date":"2024-01-24T01:27:52.064Z","updated":"2024-01-24T01:27:52.065Z","comments":true,"path":"12.Java/Advanced-Java.02d.JVM分析工具/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Advanced-Java.02d.JVM分析工具/","excerpt":"JDK提供的命令行 以下每个工具都可以 cmd --help的方式查看说明 jps查看当前用户启动jvm进程 jps -m: 显示传递给Main方法的参数 jps -l: 显示Java进程的完整包名 jps -v: 显示JVM的参数 jps -lvm","text":"JDK提供的命令行 以下每个工具都可以 cmd --help的方式查看说明 jps查看当前用户启动jvm进程 jps -m: 显示传递给Main方法的参数 jps -l: 显示Java进程的完整包名 jps -v: 显示JVM的参数 jps -lvm jvm启动后会在/tmp/hsperfdata_&lt;username&gt;/目录下生成一个pid为名的文件, 这个目录由-Djava.io.tmpdir参数指定, 如果因为某些原因这个文件没有生成, jps也就不起作用文件内容:? jstat查看每个分代的使用率和GC次数，在没有GUI图形的服务器上是运行期定位虚拟机性能问题的首选。 注意jstat返回只有 YGC和 FGC，并不区分 Major GC和 Full GC；jstat和-XX:+PrintGCDetails提供的结果有不同，在于：jstat无法统计并行的任务，比如UseConcMarkSweepGC情况下，初始mark和remark阶段都会有 Stop the World的耗时，jstat的输出会把两个STW阶段视作两次 Full GC；而在GC日志里可以清楚的看到 UseConcMarkSweepGC情况下，每个阶段的耗时。 例如, 如果配置了CMS垃圾回收器，那么 jstat中的 FGC增加1并不表示就一定发生了 Full GC，很有可能是发生了老年代的 CMS GC，而且每发生一次老年代的 CMS GC，jstat中的 FGC就会+2 常用jstat命令： jstat -gc pid: 统计JVM内存（Young/Old/Method）的已使用/总空间大小，以及Young GC和Full GC发生次数和耗时； jstat -gcutil pid : 统计JVM内存（Young/Old/Method）的占用百分比，以及Young GC和Full GC发生次数和耗时； jstat -class pid : 类装载、卸载数量、总空间, 及类装载所耗费的时间 jstat -gccapacity pid : 查看三代（young,old,perm）对象的使用量大小(字节) jstat -gcnew pid: 年轻代的容量和GC情况 jstat -gcnewcapacity pid: jstat -gcold pid: 老年代的容量和GC情况 jstat -gcoldcapacity pid: 如果用jstat查看远程机器上的jvm, 需要在远程主机启动jstatd(详见 jstatd) jstat -gc pid@remote_IP # 用jstat连接远端的jstatd jstat -gc返回列解析示例1: attaches 到pid=14542的进程上, -h3表示每三行打印一次列名称, 采样间隔5sjstat -gc -h3 14542 5s S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT10240.0 10752.0 0.0 0.0 133120.0 10215.4 87552.0 9225.3 27904.0 26661.4 3328.0 3007.2 20 0.305 13 1.410 1.71510240.0 10752.0 0.0 0.0 133120.0 10659.2 87552.0 9225.3 27904.0 26661.4 3328.0 3007.2 20 0.305 13 1.410 1.71510240.0 10752.0 0.0 0.0 133120.0 10659.2 87552.0 9225.3 27904.0 26661.4 3328.0 3007.2 20 0.305 13 1.410 1.715 S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT10240.0 512.0 0.0 0.0 133120.0 79.2 87552.0 9224.0 27904.0 26662.1 3328.0 3007.2 21 0.318 14 1.522 1.84010240.0 512.0 0.0 0.0 133120.0 523.0 87552.0 9224.0 27904.0 26662.1 3328.0 3007.2 21 0.318 14 1.522 1.84010240.0 512.0 0.0 0.0 133120.0 523.0 87552.0 9224.0 27904.0 26662.1 3328.0 3007.2 21 0.318 14 1.522 1.840 每列说明如下: S0C: S0 Capacity(KB) S0U: S0 Utilization(KB) EC: Current eden space capacity (kB). EU: Eden space utilization (kB). MC: Metaspace capacity (kB). MU: Metacspace utilization (kB). YGC: 从JVM进程启动到当前采样，发生young gen GC总次数 YGCT: 从JVM进程启动到当前采样，young gen GC总消耗时间(秒)， 相邻两次相减就是该次耗时 FGC: 从JVM进程启动到当前采样，发生full GC总次数 FGCT: 从JVM进程启动到当前采样，full GC总消耗时间(秒)， 相邻两次相减就是该次耗时 注: 上面是java 1.8的jstat的返回值, 可以看到有Metaspace(元空间), 如果是java 1.7或更老版本, 则没有MC/MU, 而是PC/PU: PC：Perm Capacity(KB) PU: Perm Utilization(KB) jstat -gcutil返回列解析示例2: attaches 到pid=14542的进程上, -h3表示每三行打印一次列名称, 采样间隔250msjstat -gcutil -h3 14542 3s S0 S1 E O M CCS YGC YGCT FGC FGCT GCT 16.35 0.00 94.62 63.31 97.41 94.84 4522 83.661 32 0.931 84.592 16.35 0.00 95.52 63.31 97.41 94.84 4522 83.661 32 0.931 84.592 16.35 0.00 96.92 63.31 97.41 94.84 4522 83.661 32 0.931 84.592 S0 S1 E O M CCS YGC YGCT FGC FGCT GCT 0.00 14.90 1.43 63.31 97.41 94.84 4523 83.678 32 0.931 84.609 0.00 14.90 2.65 63.31 97.41 94.84 4523 83.678 32 0.931 84.609 0.00 14.90 3.68 63.31 97.41 94.84 4523 83.678 32 0.931 84.609 上面发生了一次Young GC, S0从16.35%降到0%, S1从0%增长到14.90%, Eden从96.92%降到1.43, 耗时0.017s 以上参考Oracle Java 8 jstat手册：jstat jstatdjstatd是一个 RMI的server，它可以监控 Hotspot的JVM的启动和结束，同时提供接口可以让远程机器连接到JVM。 比如 jstat / JVisualVM 都可以通过jstatd来远程观察JVM的运行情况。在远程服务器上启动jstatd: nohup jstatd -J-Djava.security.policy=/home/xxx/jstatd.all.policy -J-Djava.rmi.server.hostname=192.168.0.2 -p 1099 &amp; , 1099是jstatd的默认端口 jstatd.all.policy内容如下:grant codebase &quot;file:$&#123;java.home&#125;/../lib/tools.jar&quot; &#123; permission java.security.AllPermission;&#125;; jstack查看jvm进程的线程状态, 也可以做线程的dump,jstack pid : 查看当前所有线程的运行栈, 包括线程当前状态(blocked, waitting), 线程占用了哪个对象锁, 线程在等待哪个对象锁; $ jstack 18303 |morePicked up JAVA_TOOL_OPTIONS: -Duser.language=en2023-05-17 23:20:41Full thread dump OpenJDK 64-Bit Server VM (11.0.15+10-b2043.56 mixed mode):&quot;Finalizer&quot; #3 daemon prio=8 os_prio=31 cpu=385.10ms elapsed=657893.45s tid=0x00007feb5f0b2000 nid=0x4103 in Object.wait() [0x000070000d3db000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(java.base@11.0.15/Native Method) - waiting on &lt;no object reference available&gt; at java.lang.ref.ReferenceQueue.remove(java.base@11.0.15/ReferenceQueue.java:155) - waiting to re-lock in wait() &lt;0x00000007c047ac10&gt; (a java.lang.ref.ReferenceQueue$Lock) at java.lang.ref.ReferenceQueue.remove(java.base@11.0.15/ReferenceQueue.java:176) at java.lang.ref.Finalizer$FinalizerThread.run(java.base@11.0.15/Finalizer.java:170)&quot;Signal Dispatcher&quot; #4 daemon prio=9 os_prio=31 cpu=3.19ms elapsed=657893.40s tid=0x00007feb5e80d800 nid=0x5703 runnable [0x0000000000000000] java.lang.Thread.State: RUNNABLE&quot;Service Thread&quot; #5 daemon prio=9 os_prio=31 cpu=141.17ms elapsed=657893.39s tid=0x00007feb5f0c5800 nid=0x5803 runnable [0x0000000000000000] java.lang.Thread.State: RUNNABLE&quot;C2 CompilerThread0&quot; #6 daemon prio=9 os_prio=31 cpu=1165586.22ms elapsed=657893.39s tid=0x00007feb5f0cd000 nid=0x5b03 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE No compile task&quot;C1 CompilerThread0&quot; #7 daemon prio=9 os_prio=31 cpu=127074.31ms elapsed=657893.39s tid=0x00007feb6003b800 nid=0x5c03 waiting on condition [0x0000000000000000] java.lang.Thread.State: RUNNABLE No compile task jmap查看堆内存的情况, 也可以生成堆内存的dump信息,jmap dump会触发Full GC, 所以在生产环境要小心使用. jmap -heap pid: 打印Heap(新生代/老年代/永久代等等..)的size参数和实际占用 jmap -histo pid: 打印出每个类的对象数量, 以及占用内存。如果出现jvm堆占用率过高，可以用histo查看哪个类的对象最多，猜测出哪里的代码有问题 jmap -histo:live pid: 只打印存活的 jmap -dump:format=b,file=FileName 6900: 把内存详细使用情况dump到文件(小心, 这个命令可能会暂停当前应用) -dump:[live,]format=b,file=FileName: live指只有活动的对象被转储到dump文件 如果程序内存不足或者频繁GC，很有可能存在内存泄露情况： 可以先使用jmap -heap命令查看堆的使用情况，看一下各个堆空间的占用情况。 使用jmap -histo:[live]查看堆内存中的对象的情况。如果有大量对象在持续被引用，并没有被释放掉，那就产生了内存泄露，就要结合代码，为什么没有被释放 也可以使用 jmap -dump:format=b,file=&lt;fileName&gt;命令将堆信息保存到一个文件中，再借助jhat命令查看详细内容 在内存出现泄露、溢出或者其它前提条件下，建议多dump几次内存，把内存文件进行编号归档，便于后续内存整理分析。 图-使用jmap -histo pid 按类型统计存活类的个数: jhat查看jmap转储的二进制文件 jhat -port 5000 FileName : 在本地启动http服务显示jmap生成的dump文件信息, 在http://localhost:5000 查看 总结:对Jvm进程进行堆栈Dump的方法 jstack可以生成Jvm线程的堆栈dump文件, jmap可以生成堆栈的dump文件,让虚拟机在内存不足时自动生成dump文件: -XX:+HeapDumpOnOutOfMemoryError图形化的dump生成工具: Java VisualVM jcmd1.7之后新增, 有多种功能的命令集合, 命令格式: jcmd $PID $Command, 查看可用的Command: jcmd $PID help, “Oracle官方建议使用jcmd代替jmap” jcmd -l: 类似jps -m jcmd pid Thread.print : 打印当前堆栈 jcmd pid GC.heap_dump /tmp/dumpFile : 导出dump文件 jcmd pid VM.system_properties : 打印出该进程所有-D参数 jinfo jinfo pid, 获取jvm进程的所有参数, 后续版本可能会移除这个工具 jdb 被调试的java进程启动参数-Xdebug -Xrunjdwp:transport=dt_socket,address=8787 连接到上面的进程进行debug: jdb -attach 192.168.1.79:8787 -sourcepath . JConsoleJava 5提供的JConsole JProfilerJProfiler是由ej-technologies GmbH开发的商业授权的性能分析工具. 参考: 深入浅出JProfiler-博客-云栖社区-阿里云 @ref VisualVMVisualVM 是一个性能分析工具，自从 JDK 6 Update 7 以后已经作为 Oracle JDK 的一部分，位于 JDK 根目录的 bin 文件夹下。以下参考自: 使用 VisualVM 进行性能分析及调优 @ref 使用VisualVM需要远程服务器上运行一个jstatd守护进程, 或者远程服务器上运行的Java Application启用了JMX, 应用程序添加如下参数来启动JMX: -Dcom.sun.management.jmxremote=true-Dcom.sun.management.jmxremote.port=9090-Dcom.sun.management.jmxremote.ssl=false-Dcom.sun.management.jmxremote.authenticate=false JVisualVM连接到JVM线程使用了Attach API, 在本文档搜索Attach API.启动命令: jvisualvm Btrace BTrace是SUN Kenai云计算开发平台下的一个开源项目，旨在为java提供安全可靠的动态跟踪分析工具。 Btrace能用来做什么?举例, 如果要对线上运行的Java程序进行调试, 可以通过在代码里加入debug打印信息来实现, 但缺点也很明显, 需要不断地修改代码，加入System.out.println(), 还需要不断重启应用程序. 对于线上服务这是不可接受的. Btrace可以改变上面低效的调试方式, Btrace可以使用类似AOP式的代码植入, 在我们关心的代码位置插入自定义代码, 比如: 在每个方法结束都打印耗时, 统计最耗时的方法; 在ArrayList.add里加入代码, 如果size过大则打印log, 找出超大的ArrayList; 当System.gc()被调用时, 打印出调用堆栈, 找出是哪里在调用gc; 并且最重要的是, 使用Btrace不需要重新编译项目代码, 也不需要重启进程, 所以Btrace非常适合在线上发生异常的环境上进行调试埋点. Btrace的使用Btrece的使用: 启动Java程序 编写Btrace代码, 用注解指定要切入的类和方法 用btracec编译上面的代码 用btrace命令把 agent.jar attach到运行中的Java进程, agent.jar启动端口, Btrece Client 使用这个端口发送命令和.class字节码 更多BTrace使用例子: btrace/samples at master · btraceio/btrace Btrace用到的技术介绍Btrace 使用 Java Complier API 编译切入代码, 生成.class文件； 再使用 Attach API 把 agent.jar 附加到目标JVM上，agent 启动端口，接受来自 Client的指令和class字节码，当agent接收到监控命令后，主要有以下两部分工作： 重写类：遍历当前所有的class,根据正则找到匹配的类，使用asm重写被切入类的字节码（CGLIB代理也用到了asm） 替换类：使用替换掉原来的class，使用了 Instrumentation API ，instrumentation的retransformClasses方法将原始字节码替换掉 Attach API 和 Instrumentation API 都是JVM Tool Interface (JVMTI)里提供的工具类;有关JVMTI相关的链接: http://docs.oracle.com/javase/7/docs/platform/jvmti/jvmti.htmlhttps://github.com/jon-bell/bytecode-examples 参考: BTrace原理浅析-阿里云开发者社区 深入 Java 调试体系 第 1 部分，JPDA 体系概览 第 2 部分: JVMTI 和 Agent 实现 第 3 部分: JDWP 协议及实现 第 4 部分: Java 调试接口（JDI） HouseMD 比BTrace更轻量级的Java进程运行时的诊断调式命令行工具，可以用来跟踪跟踪方法的耗时。 UserGuideCN · CSUG/HouseMD Wiki Memory Analyzer (MAT) Java Heap Dump 文件(通过jmap -dump转储的文件)分析工具，可以分析堆内存中每种对象的数量，还可以跟踪对象的引用链，排查内存泄漏问题。 Eclipse Memory Analyzer Open Source Project | The Eclipse Foundation 使用 Eclipse Memory Analyzer 进行堆转储文件分析","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://beefyheisenberg.github.io/tags/JVM/"}]},{"title":"Advanced Java-02c-JVM参数和性能","slug":"12.Java/Advanced-Java.02c.JVM参数和性能","date":"2024-01-24T01:27:52.059Z","updated":"2024-01-24T01:27:52.060Z","comments":true,"path":"12.Java/Advanced-Java.02c.JVM参数和性能/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Advanced-Java.02c.JVM参数和性能/","excerpt":"JVM的模式关于JVM的类型和模式 - ImportNew 使用java -version命令查看出当前虚拟机处于哪种类型模式: Server or Client JVM启动时采用何种模式是在名为jvm.cfg的配置文件中配置的: 在32位JDK中，jvm.cfg位置为：JAVA_HOME/jre/lib/i386/jvm.cfg 在64位JDK中，jvm.cfg位置为：JAVA_HOME/jre/lib/amd64/jvm.cfg Server 和 Client 的区别: These two systems are different binaries. They are essentially two different compilers (JITs)interfacing to the same runtime system. The client system is optimal for applications which need fast startup times or small footprints, the server system is optimal for applications where the overall performance is most important. In general the client system is better suited for interactive applications such as GUIs. Some of the other differences include the compilation policy,heap defaults, and inlining policy.Client JVM适合需要快速启动和较小内存空间的应用，它适合交互性的应用，比如GUI；而Server JVM则是看重执行效率的应用的最佳选择。不同之处包括：编译策略、默认堆大小、内嵌策略。 使用java -X 可以看到Jvm工作模式 // JVM有以下几种模式：-Xint, -Xcomp, 和 -Xmixed -Xint代表解释模式(interpreted mode)，-Xint标记会强制JVM以解释方式执行所有的字节码 -Xcomp代表编译模式(compiled mode)，与它（-Xint）正好相反，JVM在第一次使用时会把所有的字节码编译成本地代码，从而带来最大程度的优化 -Xmixed代表混合模式(mixed mode)，前面也提到了，混合模式是JVM的默认工作模式。它会同时使用编译模式和解释模式。对于字节码中多次被调用的部分，JVM会将其编译成本地代码以提高执行效率；而被调用很少（甚至只有一次）的方法在解释模式下会继续执行，从而减少编译和优化成本 JVM相关日志 -XX:+HeapDumpOnOutOfMemoryError XX:HeapDumpPath=../ 开启jvm内存不足时生成dump文件, 指定位置 -XX:ErrorFile=/var/log/hs_err_pid.log jvm崩溃日志 -XX:+PrintGC -XX:+PrintGCDateStamps -Xloggc:../logs/gc.log 开启GC日志, 输出时间戳, 指定GC日志位置","text":"JVM的模式关于JVM的类型和模式 - ImportNew 使用java -version命令查看出当前虚拟机处于哪种类型模式: Server or Client JVM启动时采用何种模式是在名为jvm.cfg的配置文件中配置的: 在32位JDK中，jvm.cfg位置为：JAVA_HOME/jre/lib/i386/jvm.cfg 在64位JDK中，jvm.cfg位置为：JAVA_HOME/jre/lib/amd64/jvm.cfg Server 和 Client 的区别: These two systems are different binaries. They are essentially two different compilers (JITs)interfacing to the same runtime system. The client system is optimal for applications which need fast startup times or small footprints, the server system is optimal for applications where the overall performance is most important. In general the client system is better suited for interactive applications such as GUIs. Some of the other differences include the compilation policy,heap defaults, and inlining policy.Client JVM适合需要快速启动和较小内存空间的应用，它适合交互性的应用，比如GUI；而Server JVM则是看重执行效率的应用的最佳选择。不同之处包括：编译策略、默认堆大小、内嵌策略。 使用java -X 可以看到Jvm工作模式 // JVM有以下几种模式：-Xint, -Xcomp, 和 -Xmixed -Xint代表解释模式(interpreted mode)，-Xint标记会强制JVM以解释方式执行所有的字节码 -Xcomp代表编译模式(compiled mode)，与它（-Xint）正好相反，JVM在第一次使用时会把所有的字节码编译成本地代码，从而带来最大程度的优化 -Xmixed代表混合模式(mixed mode)，前面也提到了，混合模式是JVM的默认工作模式。它会同时使用编译模式和解释模式。对于字节码中多次被调用的部分，JVM会将其编译成本地代码以提高执行效率；而被调用很少（甚至只有一次）的方法在解释模式下会继续执行，从而减少编译和优化成本 JVM相关日志 -XX:+HeapDumpOnOutOfMemoryError XX:HeapDumpPath=../ 开启jvm内存不足时生成dump文件, 指定位置 -XX:ErrorFile=/var/log/hs_err_pid.log jvm崩溃日志 -XX:+PrintGC -XX:+PrintGCDateStamps -Xloggc:../logs/gc.log 开启GC日志, 输出时间戳, 指定GC日志位置 JVM参数: -D -X -XX查看当前JVM默认参数的命令: java -XX:+PrintFlagsFinal -version, 下面是需要注意的参数说明: -D参数： -D: JVM系统参数, 可以自定义, 在代码里通过System.getProperty(&quot;xxx&quot;)获取到 -Djava.ext.dirs=/path: -classpath参数只能指定jar包, 如果需要把某个目录的jar都包含进来, 可以使用-Djava.ext.dir= -Dfile.encoding=UTF-8: -Djava.io.tmpdir=/tmp: 在此路径下生成pid文件, jps命令读取此文件返回结果, 默认是/tmp/hsperfdata_&lt;username&gt;/目录下 -X参数： -X: 设置JVM扩展参数, 非标准的, 不保证任何JVM都实现 -Xms512m: 堆的初始化大小,默认物理内存的1/64(&lt;1GB), -Xmx512m: 最大堆大小,物理内存的1/4(&lt;1GB) -Xss1m: 线程栈大小, JDK5.0以后每个线程堆栈大小为1M -XX参数： -XX: 不稳定的参数, 不推荐在生产环境中使用: -XX:AutoBoxCacheMax : JAVA进程启动的时候,会加载rt.jar这个核心包的,rt.jar包里的Integer自然也是被加载到JVM中, VM在加载Integer这个类时,会优先加载静态的代码。当JVM进程启动完毕后, -128 ~ +127 范围的数字会被缓存起来,调用valueOf方法的时候,如果是这个范围内的数字,则直接从缓存取出。因此可以根据实际情况把AutoBoxCacheMax的值设置的更多一些: -XX:AutoBoxCacheMax=2000 -XX:+AlwaysPreTouch : JAVA进程启动的时候,虽然我们可以为JVM指定合适的内存大小,但是这些内存操作系统并没有真正的分配给JVM,而是等JVM访问这些内存的时候,才真正分配.这个参数可以让让操作系统在启动JVM时, 把内存真正的分配给JVM; -XX:CMSInitiatingOccupancyFraction : 当老年代堆空间的使用率达到75%的时候就开始执行垃圾回收, CMSInitiatingOccupancyFraction默认值是92%,这个就太大了如 -XX:CMSInitiatingOccupancyFraction=75, 注意 CMSInitiatingOccupancyFraction 参数必须跟下面两个参数一起使用才能生效: -XX:+UseConcMarkSweepGC-XX:+UseCMSInitiatingOccupancyOnly -XX:MaxTenuringThreshold 默认情况下, 这个值是15, 意思是 当新生代执行了15次 young gc后, 如果还有对象存活在Survivor区中,那么就可以直接将这些对象晋升到老年代.但是由于新生代使用copy算法,如果 Survivor区存活的对象太久的话, Survivor区存活的对象就越多, 这个就会影响copy算法的性能,使得 young gc停顿的时间加长,建议设置成6。有个例外的情况, 可能导致GC收集器 不按照MaxTenuringThreshold的值进行晋升,[动态年龄计算] :JVM遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了survivor区的一半时，取这个年龄和MaxTenuringThreshold中更小的一个值，作为新的晋升年龄阈值。例如age=2的所有对象占用了超过一半Survivor区大小, 那么晋升至老年代的age阈值会调整为2 -XX:ExplicitGCInvokesConcurrent 如果系统使用堆外内存,比如用到了Netty的DirectByteBuffer类,那么当想回收堆外内存的时候,需要调用System.gc(), 而这个方法将进行full gc,整个应用将会停顿,如果是使用CMS垃圾收集器,那么可以设置-XX:+ExplicitGCInvokesConcurrent, 来改变System.gc()的行为,让其从 full gc 变为 CMS GC,CMS GC 是并发收集的,且中间执行的过程中,只有部分阶段需要 STW; -XX:PermSize : 设置持久代(perm gen)初始值 物理内存的1/64, 例 XX:PermSize=512M -XX:MaxPermSize 设置持久代最大值 物理内存的1/4 -XX:SurvivorRatio: Eden和Survivor的大小比例, -XX:SurvivorRatio=8表示 Eden:Survivor=8:1，这是默认值 -XX:NewRatio: 老年代:年轻代 的比值, The default NewRatio for the Server JVM is 2: the old generation occupies 2/3 of the heap while the new generation occupies 1/3如果Young GC很频繁, 可以降低老年代的比例: -XX:NewRatio=1; 注意：-Xmn的优先级比-XX:NewRatio高，若-Xmn已指定，则无需再按NewRatio的比例计算。生产环境中一般只需指定-Xmn -XX:MaxTenuringThreshold: 控制进入老年前生存次数等, 如果设置为0的话,则年轻代对象不经过Survivor区,直接进入年老代. 对于年老代比较多的应用,可以提高效率.如果将此值设置为一个较大值,则年轻代对象会在Survivor区进行多次复制,这样可以增加对象再年轻代的存活 时间,增加在年轻代即被回收的概率, 该参数只有在串行GC时才有效. -XX:+DisableExplicitGC: 关闭System.gc() 这个参数需要严格的测试 -XX:+UseParallelGC: 选择垃圾收集器为并行收集器.此配置仅对年轻代有效 -XX:+UseParNewGC: 设置年轻代为并行收集 -XX:+UseParallelOldGC: 老年代垃圾收集方式为并行收集(Parallel Compacting) -XX:+UseConcMarkSweepGC: 使用CMS内存收集 -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGC:PrintGCTimeStamps -XX:+HeapDumpOnOutOfMemoryError: 当JVM因内存不足崩溃时产生dump文件 -XX:ErrorFile=/var/log/hs_err_pid.log: JVM崩溃, 产生的日志位置 JVM参数最佳实践 @ref: hashcon 我所使用的生产 Java 17 启动参数 - 掘金 @Deprecated: -Xmx4g -Xms4g -Xmn1G-XX:+UseParNewGC -XX:UseConcMarkSweepGC-XX:CMSInitiatingOccupancyFraction=70-verbose:gc -XX:+printGCDetails -XX:+PrintGCTimeStamps -Xloggc:$&#123;HBASE_HOME&#125;/logs/gc-$&#123;hostname&#125;-hbase.log","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://beefyheisenberg.github.io/tags/JVM/"}]},{"title":"Advanced-Java.02b1.MetaSpace解析","slug":"12.Java/Advanced-Java.02b1.MetaSpace解析","date":"2024-01-24T01:27:52.054Z","updated":"2024-01-24T01:27:52.055Z","comments":true,"path":"12.Java/Advanced-Java.02b1.MetaSpace解析/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Advanced-Java.02b1.MetaSpace解析/","excerpt":"Metaspace 中有什么？Metaspace 分为 Klass 和 Non-Klass 两个区域： Klass：每个 Java 类都对应一个 Klass（是一个 C++对象），Klass 里主要保存了类的 vtable 和 itable 和其他，这部分数据大都是指针类型，例如 vtable 保存了指向方法的指针； Non-Klass：这部分可以理解为 Klass 的数据区，存储了比较大的元数据，主要包括了常量池（constant pool）、字节码等等 @enhanced 在 Heap 中，每个 Java 类都有一个 Class 对象（区分上面的 Klass），这是一个 Java 对象，从.class 文件加载出的大多数数据都保存在 MetaSpace（如上所说），所以 Heap 中的 Class 对象可以认为是一个“与 Klass 交互的接口”； 此外，每次 new 都会在 Heap 创建类的对象（Object），每个对象在内存中都有一个“对象头”，包括 Mark Word 和指向 Klass 对象的指针，在 64 位机器上，指针默认大小是 64bit，所以会占用很大的内存，可以开启压缩指针减少内存消耗（开启后这个 Klass 指针就是 32bits），32 位指针最多能管理的 2^32 = 4G 内存，所以开启压缩指针的情况下，MetaSpace 中的 Klass 区也不能超过这个 4G 上限，否则 32 位指针无法管理这么大的内存区。","text":"Metaspace 中有什么？Metaspace 分为 Klass 和 Non-Klass 两个区域： Klass：每个 Java 类都对应一个 Klass（是一个 C++对象），Klass 里主要保存了类的 vtable 和 itable 和其他，这部分数据大都是指针类型，例如 vtable 保存了指向方法的指针； Non-Klass：这部分可以理解为 Klass 的数据区，存储了比较大的元数据，主要包括了常量池（constant pool）、字节码等等 @enhanced 在 Heap 中，每个 Java 类都有一个 Class 对象（区分上面的 Klass），这是一个 Java 对象，从.class 文件加载出的大多数数据都保存在 MetaSpace（如上所说），所以 Heap 中的 Class 对象可以认为是一个“与 Klass 交互的接口”； 此外，每次 new 都会在 Heap 创建类的对象（Object），每个对象在内存中都有一个“对象头”，包括 Mark Word 和指向 Klass 对象的指针，在 64 位机器上，指针默认大小是 64bit，所以会占用很大的内存，可以开启压缩指针减少内存消耗（开启后这个 Klass 指针就是 32bits），32 位指针最多能管理的 2^32 = 4G 内存，所以开启压缩指针的情况下，MetaSpace 中的 Klass 区也不能超过这个 4G 上限，否则 32 位指针无法管理这么大的内存区。 JVM 提供了 -XX:UseCompressedClassPointers 来指定是否开启压缩指针，只有在开启这个参数的情况下，Metaspace 才会有 Klass 区；默认情况下这个参数是打开的，如果我们把-Xmx 设置大于 32G 的话，因为内存很充足，所以就没必要开压缩指针，MetaSpace 中也就不再有Klass 区了； 下图是堆中的 Object 对象、Metaspace 中的 Klass 对象、Non-Klass 对象之间的关系：【图】来自 全网最硬核 JVM 内存解析 - 7.元空间存储的元数据 - 掘金 Klass：其实就是 Java 类的实例（每个 Java 的 class 有一个对应的对象实例，用来反射访问，这个就是那个对象实例），即 Java 对象头的类型指针指向的实例： InstanceKlass：普通对象类的 Klass： vtable：虚拟函数表，保存了该类的所有函数（static、final 除外） itable：接口函数表，保存了该类实现的接口的函数 InstanceRefKlass：java.lang.ref.Reference 类以及子类对应的 Klass InstanceClassLoaderKlass：Java 类加载器对应的 Klass InstanceMirrorKlass：java.lang.Class 对应的 Klass ArrayKlass：Java 数组对应的 Klass ObjArrayKlass：普通对象数组对应的 Klass TypeArrayKlass：原始类型数组对应的 Klass Non-Klass： Symbol：符号常量，即类中所有的符号字符串，例如类名称，方法名称，方法定义等等。 ConstantPool：运行时常量池，数据来自于类文件中的常量池。 ConstanPoolCache：运行时常量池缓存，用于加速常量池访问 ConstMethod：类文件中的方法解析后，静态信息放入 ConstMethod，这部分信息可以理解为是不变的，例如字节码，行号，方法异常表，本地变量表，参数表等等。 MethodCounters：方法的计数器相关数据。 MethodData：方法数据采集，动态编译相关数据。例如某个方法需要采集一些指标，决定是否采用 C1 C2 动态编译优化性能。 Method：Java 方法，包含以上 ConstMethod，MethodCounters，MethodData 的指针以及一些额外数据。 RecordComponent：对应 Java 14 新特性 Record，即从 Record 中解析出的关键信息。 注意，老版本中， UseCompressedClassPointers 取决于 UseCompressedOops，即压缩对象指针如果没开启，那么压缩类指针也无法开启。但是从 Java 15 Build 23 开始， UseCompressedClassPointers 已经不再依赖 UseCompressedOops 了，两者在大部分情况下已经独立开来。除非在 x86 的 CPU 上面启用 JVM Compiler Interface（例如使用 GraalVM）。 vtable &amp; itable➤ vtable 是 Java 虚拟函数表，Klass 通过虚函数表 vtable，来实现运行期的方法分派，也可以叫动态绑定；C++对象中的 vtable 只有虚函数，但 Java 中没有虚函数一说，所有函数都是动态绑定的，JVM 中的 Klass 的 vtable 包括所有函数（static、final 除外）；Java 的 vtable 与 C++的另一个区别：C++是每个对象都有 vtable，Java 只在 Klass 对象保存了 vtable； ➤ itable 是 Java 接口函数表，为了方便查找某个接口对应的方法实现。itable 的结构比 vtable 复杂，除了记录方法地址外还得记录该方法所属的接口类 klass。 more ref： 第6.3篇-klassVtable与klassItable类的介绍 - 鸠摩（马智） - 博客园 Metaspace 中类加载和卸载➤ Metaspace 中的元数据（Klass &amp; Non-Klass）何时被加载？在 ClassLoader 加载.class，在“准备”的阶段，类的元数据被载入 MetaSpace，这些元数据归加载它们的 ClassLoader 所有； ➤ Metaspace 中的元数据何时卸载？在 GC 时，当 ClassLoader 加载的全部对象都被标为“不活动”，那么接下来这个 ClassLoader 对象也会被释放，最后会卸载掉 MetaSpace 中的元数据（参见：jls12.7-类和接口的卸载） 【图】来自 https://javakk.com/391.html Metaspace 相关的 VM 参数MetaspaceSize默认 20.8M 左右(x86 下开启 c2 模式)，主要是控制 metaspaceGC 发生的初始阈值，也是最小阈值，但是触发 metaspaceGC 的阈值是不断变化的，与之对比的主要是指 Klass Metaspace 与 NoKlass Metaspace 两块 committed 的内存和。 MaxMetaspaceSize默认基本是无穷大，但是我还是建议大家设置这个参数，因为很可能会因为没有限制而导致 metaspace 被无止境使用(一般是内存泄漏)而被 OS Kill。这个参数会限制 metaspace(包括了 Klass Metaspace 以及 NoKlass Metaspace)被 committed 的内存大小，会保证 committed 的内存不会超过这个值，一旦超过就会触发 GC，这里要注意和 MaxPermSize 的区别，MaxMetaspaceSize 并不会在 jvm 启动的时候分配一块这么大的内存出来，而 MaxPermSize 是会分配一块这么大的内存的。 CompressedClassSpaceSize默认 1G，这个参数主要是设置 Klass Metaspace 的大小，不过这个参数设置了也不一定起作用，前提是能开启压缩指针，假如-Xmx 超过了 32G，压缩指针是开启不来的。如果有 Klass Metaspace，那这块内存是和 Heap 连着的。 jstat 中 Metaspace 字段 MC 表示 Klass Metaspace 以及 NoKlass Metaspace 两者总共 committed 的内存大小，单位是 KB，虽然从上面的定义里我们看到了是 capacity，但是实质上计算的时候并不是 capacity，而是 committed MU 表示是 Klass Metaspace 以及 NoKlass Metaspace 两者已经使用了的内存大小 CCSC 表示的是 Klass Metaspace 的已经被 commit 的内存大小，单位也是 KB CCSU 表示 Klass Metaspace 的已经被使用的内存大小 MCMX 表示 Klass Metaspace 以及 NoKlass Metaspace 两者总共的 reserved 的内存大小，比如默认情况下 Klass Metaspace 是通过 CompressedClassSpaceSize 这个参数来 reserved 1G 的内存，NoKlass Metaspace 默认 reserved 的内存大小是 2x InitialBootClassLoaderMetaspaceSize CCSMX 表示 Klass Metaspace reserved 的内存大小 区分内存分配的 reserve &amp; commit: reserve 动作：只是向 OS 申请内存，但 OS 并没有实际分配物理内存，对应 OpenJDK 的 os::reserve_memory 函数，reserve 最终是通过 mmap(2) 实现的； commit 动作：从已经 reserved 的内存区域中，commit 一部分出来，同时 commited 的内存也可以 uncommit 释放，对应 OpenJDK os::commit_memory 函数； commit 出来的内存也是没有分配物理内存的，真正的分配物理内存要等到向这块内存写入的时候； Reference JVM源码分析之Metaspace解密 - 你假笨 全网最硬核 JVM 内存解析 - 7.元空间存储的元数据 - 掘金 全网最硬核 JVM 内存解析 - 2.JVM 内存申请与使用流程 - 掘金","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://beefyheisenberg.github.io/tags/JVM/"},{"name":"MetaSpace","slug":"MetaSpace","permalink":"https://beefyheisenberg.github.io/tags/MetaSpace/"}]},{"title":"Advanced Java-02b-JVM运行时内存结构","slug":"12.Java/Advanced-Java.02b.JVM内存结构","date":"2024-01-24T01:27:52.050Z","updated":"2024-01-24T01:27:52.050Z","comments":true,"path":"12.Java/Advanced-Java.02b.JVM内存结构/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Advanced-Java.02b.JVM内存结构/","excerpt":"JDK6 时期 如上图, JDK6 时代的 JVM 内存分为下面几个部分: 堆区(Heap Space): 这部分被所有线程共享(除了 #TLAB ), 包括: 年轻代: eden:s0:s1 的默认比例是 8:1:1, 可见 eden 区大部分对象都是要被回收的; 老年代: 老年代:年轻代 的比例默认是 2:1 , 也就是说默认情况下堆区的 2/3 都属于老年代, 栈区(Stack Space): 每个线程独有, 包括: PC, Stack, Native Stack 方法区(Method Area) JVM 标准定义的内存区域为 Heap/Stack Space/Medhod Area; 分代的名称（年轻代/老年代/永久代）是 HotSpot 中定义的, 并不是 JVM 标准中定义的, 注意区分 @doubt","text":"JDK6 时期 如上图, JDK6 时代的 JVM 内存分为下面几个部分: 堆区(Heap Space): 这部分被所有线程共享(除了 #TLAB ), 包括: 年轻代: eden:s0:s1 的默认比例是 8:1:1, 可见 eden 区大部分对象都是要被回收的; 老年代: 老年代:年轻代 的比例默认是 2:1 , 也就是说默认情况下堆区的 2/3 都属于老年代, 栈区(Stack Space): 每个线程独有, 包括: PC, Stack, Native Stack 方法区(Method Area) JVM 标准定义的内存区域为 Heap/Stack Space/Medhod Area; 分代的名称（年轻代/老年代/永久代）是 HotSpot 中定义的, 并不是 JVM 标准中定义的, 注意区分 @doubt Heap 这块区域被同一 JVM 实例的所有线程共享(除了 TLAB), new 在堆创建对象. 堆的大小由 -Xms ~ -Xmx 指定: -Xmx2048m -Xms2048m -Xmx 堆的最大值默认是内存的 1/4; -Xms 堆的最小值; YoungGen(新生代)大小由参数 -XX:NewSize ~ -XX:MaxNewSize (jdk 1.3)指定, jdk1.4之后统一成一个参数 -Xmn512m 新生代又被分为三个区域: Eden: 新创建的对象被分配在这里; To Survivor、From Survivor: 发生 Young GC 时, 有用的对象从 Eden 区域和 From Survivor 区域移动到 → To Survivor , Eden 和 From 被清空, 同时 From 和 To 交换角色 ; 命令 jstat 的返回中, To/From Survivor 被标注为 S0/S1 Eden 区的 TLAB在Eden区，每个线程都有一块自己的TLAB（Thread Local Allocate Buffer），线程创建的对象优先在自己的TLAB中分配，其他的线程仍可以访问这些对象，但是无法在其他线程的TLAB中分配内存。 为什么需要为每个线程单独分配TLAB？ 内存分配要涉及到“空闲内存管理”，即把空闲的内存块管理起来，分配内存时从空闲块中取，一般的连续空闲内存管理使用：指针碰撞+空闲列表 bump-the-pointer：在连续的内存块上，指针之前表示已用区域，指针之后表示未用，分配内存时移动指针即可，但是对于前面已分配过的内存，可能因为释放导致空洞，指针碰撞法无法管理这部分空洞 free-list：对于指针碰撞法的补充，指针前面出现的空洞，用链表管理起来 实际分配时，在free-list 和 撞针寻找空闲的内存，这里通常使用 first-fit的方式寻找 多个进程都需要申请内存，就需要对 pointer &amp; free-list进行加锁，导致性能下降 【图】使用 list 管理不连续的空闲块： @link：pointer &amp; free-list 的空闲管理，比较物理内存的伙伴系统 &amp; Slab内存池 其实“bump-the-pointer”翻译为指针加法更合适，而不是“指针碰撞”我猜测会有留言问为什么不把 bump the pointer 翻译成指针碰撞。这里先解释一下，在英语中我们通常省略了 bump up the pointer 中的 up。在这个上下文中 bump 的含义应为“提高”。另外一个例子是当我们发布软件的新版本时，也会说 bump the version number。 线程向 TLAB 申请内存也是用““bump-the-pointer”：线程维护了两个指针（实际可能更多，但重要的就2个指针），end-ptr 指向 TLAB 末尾，free-ptr 指向“已分配”的后面，线程向 TLAB 申请内存只需向后移动 free-ptr TLAB的创建、释放： TLAB在 线程初始化时创建，在经历一次GC后会释放TLAB，在GC过程中TLAB中的可达对象被放入Survivor Space，TLAB的内存区域也被释放给Eden 管理； 在GC完之后，线程尝试分配对象时，再次创建新的TLAB； 如果一次 new 的内存块的大小，大于当前 TLAB 剩余空间，此时还需要判断剩余空间是否大于refill_waste（最大可浪费）： 如果TLAB的剩余容量，大于 refill_waste：在堆内存分配 如果TLAB的剩余容量，小于 refill_waste：TLAB 被退回给 Eden，线程不再使用这块 TLAB 分配，而是申请新的 TLAB 通过 refill_waste，减少重新申请 TLAB 的频次 TLAB参数： -XX:-ResizeTLAB: 关闭 TLAB的 resize，默认是开的，会根据线程分配历史动态调整TLAB的大小 -XX:TLABRefillWasteFraction=64 最大可浪费 TLAB的 1/64 @ref: 全网最硬核 JVM TLAB 分析 - 掘金 JVM源码分析之线程局部缓存TLAB - 简书 OldGen(老年代) 也叫 Tenured(晋升代), 在 GC 里被称为老年代(Old Generation) 没有参数可以指定大小, 但可以通过 Heap-新生代 计算出来 Stack当每个新线程出现时，都会获得自己的 PC Register、Java Stack、以及 Native Method Stack （1）Program Counter Register: 计数器, 记录当前线程执行 Java 字节码的行号; 这里是 JVM 中唯一没有规定任何 OutOfMemoryError 的区域; （2）Java Stack: 即每个线程执行时的 “Java 栈”，区别于 Native, 每个线程的栈由一个个栈帧（Frame）构成，线程中每次有方法调用时，会创建一个 Frame 并压入 Java Stack，方法调用结束时 Frame 被弹出，Java 的方法结束有两种方式： return 抛出异常 该区域存储线程的 Java 方法（再次强调不包括 Native method 的）调用的状态，包括其局部变量、调用它的参数、返回值和中间计算。 该区域会抛出 StackOverflowError 和 OutOfMemoryError （3）Native Method Stack: 除了上面的栈, 每个线程都有自己的 Native 方法执行栈， Java Stack 是线程执行字节码的栈, Native Stack 是线程执行 Native 代码的栈) ； 该区域会抛出 StackOverflowError 和 OutOfMemoryError； 上图显示了正在执行三个线程的虚拟机实例的快照：线程 1 和 2 正在执行 Java Method。线程三是执行 Native Method。 Stack 显示为向下增长。每个线程的 Java Stack 的“栈顶”显示在图的底部。对于当前正在执行 Java Method 的线程，pc 寄存器指示要执行的下一条指令。由于线程 3 当前正在执行 Native Method，因此其 pc 寄存器（以深灰色显示的内容）的内容未定义。 线程栈大小由参数 -Xss 指定, 默认 1m, 在 tomcat 这种多线程 web 服务器上, 保持 1m 或者更小可以处理更多的并发请求Stack 和 Native Stack 都会抛出 StackOverFlowError 和 OutOfMemoryError 两种错误, StackOverFlowError： 若 Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 异常。OutOfMemoryError： 若 Java 虚拟机栈的内存大小允许动态扩展，且当线程请求栈时内存用完了，无法再动态扩展了，此时抛出 OutOfMemoryError 异常。 Method Area 方法区与堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 Non-Heap（非堆），目的应该是与 Java 堆区分开来。 在 HotSpot 虚拟机中方法区也常被称为 “永久代”。也仅仅是 HotSpot VM 这么做，对于其他的虚拟机（如 Oracle JRockit、IBM J9 等）来说是不存在永久代的概念的。HotSpot 虚拟机设计团队用“永久代”来实现方法区而已，这样 HotSpot 虚拟机的垃圾收集器就可以像管理 Heap 一样管理这部分内存，能够省去专门为方法区编写内存管理代码的工作。 在 HotSpot VM, 永久代也是有 GC 的, 时机与老年代相同（再次提醒 永久代不属于堆） HotSpot VM 的永久代大小由 -XX:PermSize ~ -XX:MaxPermSize 指定, 一般服务器设置为: -XX:MaxPermSize=500m JDK 1.6 时期，HotSpot 的永久代包括: Runtime Constant Pool, 运行时常量池 String Pool: 字符串常量池, 以”Hello”字面量方式创建的字符串会存储在这里. 详见 「字符串在内存中的存储」 如果运行时有大量的类产生，可能会导致方法区被填满直至溢出。报出 java.lang.OutOfMemoryError: PermGen space，常见的应用场景如： Spring 和 ORM 框架使用 CGLib 操纵字节码对类进行增强，增强的类越多，就需要越大的方法区来保证动态生成的 Class 可以加载入内存。 大量 JSP 或动态产生 JSP 文件的应用（JSP 第一次运行时需要编译为 Java 类）。 基于 OSGi 的应用（即使是同一个类文件，被不同的类加载器加载也会视为不同的类）。 JDK7 时期String Pool （字符串常量池）被从 PermGen 里移除了, 这部分字符串对象放在了 Heap 里, 并且可以通过 -XX:StringTableSize 指定其大小，这部分的变化参考 [[#字符串在内存中的存储]] 此外 JDK7 的内存模型基本和 6 一样; •JDK6~7 的 VM 参数总结 &lt;JVM 6 &amp; 7 Memory options&gt;+-----------------+-----------------+--------------| PC | ||-----------------|-----------------+-------------| Stack &amp; | || Native Stack | | -Xss+-----------------+-----------------+---------------| Method Area | String Pool &amp; || (PermGen) | Runtime- | -XX:MaxPermSize| | Constant Pool | -XX:PermSize+-----------------+-----------------+-------+-------+---| OldGen | | | || (TenuredGen) | | | -Xmx |+-----------------+-----------------+-------+ || | To Survivor | | | Heap| YoungGen |-----------------| -Xmn | || | From Survivor | | -Xms || |-----------------| | || | Eden | | |+-----------------+-----------------+-------+-------+--- JDK8 时期(MetaSpace)在 HotSpot JDK7以及更早的版本里, 永久代最大大小由 -XX:MaxPermSize 指定, 一旦超过这个大小就不能再扩展, 假如加载的类过多会导致 Medhod Area 过大而导致 OOM, HotSpot JDK8 移除 了 JDK7 的 PermGen(永久代), 类的元信息被移到了 MetaSpace(元空间), 这块内存放在 Native memory 当中, 不再属于 JVM 线程内的内存区.interned 的 String、类的 static 成员在堆区 jvm - Where are static methods and static variables stored in Java? - Stack Overflow JDK7 移除了 PermGen 的「字符串常量池」;JDK8 移除了整个 PermGen, 类的元信息被放在 MateSpace; 更多关于 MetaSpace -&gt; Advanced-Java.02b1.MetaSpace解析 JVM 分代设置大小建议 堆区的默认值最大 size 是256MB, 永久代默认最大 size 是64MB, 堆:永久代 大约是是 4:1 （Test @ JDK6 + Windows 32 bit） 每个分代大小比例(经验值): Eden : Survivor0 : Survivor1 : OldGen : PermGen = 8 : 1 : 1 : 20 : 5 每个分代具体设置多大, 还可以根据 JVM 活跃数据 的大小进行估算: 活跃数据的大小是指，应用程序稳定运行时长期存活对象在堆中占用的空间大小，也就是 Full GC 后堆中老年代占用空间的大小。可以通过 GC 日志中 Full GC 之后老年代数据大小得出，比较准确的方法是在程序稳定后，多次获取 GC 数据，通过取平均值的方式计算活跃数据的大小。活跃数据和各分区之间的比例关系如下 例如，根据 GC 日志获得老年代的活跃数据大小为 300M，那么各分区大小可以设为： 总堆：1200MB = 300MB × 4新生代：450MB = 300MB × 1.5老年代： 750MB = 1200MB - 450MB 变量在JVM内存中的存储不同方式创建的变量 &amp; 常量，在 JVM 存储的位置： Stack（栈区）： 局部变量，保存在每个方法的栈帧中的“局部变量表”中 如果局部变量是类引用，引用本身也在局部变量表，引用指向的 object 在Heap Heap（堆区）: 每个 Object 对应的 Class Object Object 的普通成员变量（除 static、final 之外的） Object 的 static 成员：在堆 Object 的 final 成员： 基本类型的 final（int、double）：在 Metaspace 的常量池 引用类型的 final： 字符串常量(字面量): 字符串常量池在 JDK7 之后移到了堆区 JVM Storage for Static Members | Baeldung： Before Java 8, PermGen stores static members like static methods and static variables. Additionally, PermGen also stores interned strings.As we’ve already discussed, PermGen space is replaced with Metaspace in Java 8, resulting in a change for memory allocation of the static members.Since Java 8, Metaspace only stores the class metadata, and heap memory keeps the static members. Furthermore, the heap memory also provides storage for interned strings. MateSpace:这部分存储的内容参考 Advanced-Java.02b1.MetaSpace解析 对象在内存中的结构 @ref Advanced-Java.05.对象内存结构 字符串在JVM内存中的存储1.6之前的不管了，只看1.7及之后的： 双引号创建的 String s = &quot;hello&quot;，存储在堆中，但是”hello”会被放入 Sring Pool String s = new String(&quot;hello&quot;) 涉及到两个 string 对象：构造方法创建的存储在 Heap，另一个双引号创建的在 String Pool； String Pool 与 String.intern()Java 并不要求常量只在编译期产生, 并非只有 class 文件常量池的内容才能进入方法区的”运行时常量池”,运行期间可以添加常量进入常量池, 比如 String.intern() 方法; intern() 的作用是将该字符串驻留在 String Pool 中，如果 String Pool 中已存在当前字符串，就会直接返回当前字符串引用. 如果常量池中没有此字符串, 会将此字符串放入 Pool 中后再返回；但要注意： String Pool 中保存的是地址, 指向 Heap 中的 String 对象； String Pool 是 C++实现的 HashTable，也就是 HashTable 对象是在 vm 的 Native 内存，而不是在 Heap，但指向的 String 在 Heap； JDK7之后的 String Pool 是一个固定大小的 HashTable（通过 vm 参数 -XX:StringTableSize 指定大小，默认1009），因为 HashTable 大小固定，一旦 intern 的字符串数量过多，会导致链表过长，intern 性能下降， 这时 HashTable 也会 rehash，但不会扩容，而是重新生成 hash 的 seed 减少碰撞。但因为没有扩容，所以对于非常满的 HashTable，rehash 后效果不大； JDK7之后 String Pool 的实现在 \\openjdk7\\hotspot\\src\\share\\vm\\classfile\\symbolTable.cpp ： oop StringTable::intern(Handle string_or_null, jchar* name, int len, TRAPS) &#123; unsigned int hashValue = java_lang_String::hash_string(name, len); int index = the_table()-&gt;hash_to_index(hashValue); oop string = the_table()-&gt;lookup(index, name, len, hashValue); // Found if (string != NULL) return string; // Otherwise, add to symbol to table return the_table()-&gt;basic_add(index, string_or_null, name, len, hashValue, CHECK_NULL);&#125; 主要做的是 lookup 和 basic_add ，如果 hashTable 冲突严重导致链表过长，lookup 耗时也会增加； ➤ intern 使用场景： 如果产生很多相同的字符串，intern 可以减少 string 对象的内存占用，但响应的增加了 intern 的耗时——主要是在 HashTable 的查找上 对于大量但重复的字符串，可以使用 intern 放入 String pool，并使用 intern 获取 ： String symbol = new String(character).intern(); 除了 Java 代码中可以调用，VM 的 C++代码也可以调用 intern 向 String Pool 中插入数据，例如 Thread.currentThread().getStackTrace()，获取类名和方法名是通过 intern 获取： oop classname = StringTable::intern((char*) str, CHECK_0); oop methodname = StringTable::intern(method-&gt;name(), CHECK_0); oop filename = StringTable::intern(source, CHECK_0); ➤ intern 使用建议： 如果创建的重复字符串很多，intern 可以减少内存使用 String Pool 大小由 vm 参数指定，不可动态修改，也不会扩容，是根据自身需要调整 StringTableSize，代码中使用 intern 的要能确认所需 String pool 的容量范围 ➤ GC 和 intern 的问题： YGC 时需要扫描 String Pool，防止其中的在 YoungGen 分配的 string 对象被回收 @doubt：在 String Pool 中的 string 如果晋升 or 内存地址发生变化，需要同步修改 String Pool? @doubt: oldGC 是不是也需要扫描 String Pool？ 既然 YGC 是需要扫描 String Pool 的，那么过于庞大的 String Pool 也会影响 YGC 时间 @ref: 深入解析String#intern - 美团技术团队 JVM源码分析之String.intern()导致的YGC不断变长 - 你假笨 JDK6,7,8 的 String Pool JDK6: GermGen 的大小在64位机器上一般为96MB, 由 -XX:MaxPermSize 指定, String Pool(主要是个 C++描述的 StringTable)的大小默认是 1009(StringTable “桶”的大小), 且这个大小不能扩展, StringTable 的实现原理类似 HashMap, hash 值相同的会放进同一个桶的链表里. 如果太多调用了 String.intern(), 会导致这个 StringTable 性能下降. JDK7: String Pool 从 PermGen 移到 Heap, 并且增加了 -XX:StringTableSize 参数可以配置 String Pool 的大小, -XX:StringTableSize=1000003. JDK8: String Pool 与7相比没有太大变化, -XX:StringTableSize 默认是 60013, 可以用-XX:+PrintFlagsFinal 获取当前你使用的值是多少. 以上参考自：String.intern in Java 6, 7 and 8 - string pooling - Java Performance Tuning Guide @ref 下面代码运行结果是 ? String s = new String(\"1\"); // 两个对象, 字面量\"1\" &amp; new 创建的strs.intern();String s2 = \"1\";System.out.println(s == s2);String s3 = new String(\"1\") + new String(\"1\");s3.intern();String s4 = \"11\";//s3.intern();System.out.println(s3 == s4); 先说答案: 在 JDK6 下结果是 “false false”, 在 JDK8 下是 “false, true”. 没有在 JDK8 上验证, 但我觉得 7 和 8 在 String Pool 上改动不大, 8 仅仅是把 Method Area 移动到了 Native Memory 中 –被叫做 Metespace(元空间)的区域.因为看不到 HotSpot 的 native 层源码, 所以只能看 OpenJDK 的, 但是不保证 OpenJDK 与 HotSpot 实现一样 @todo 有时间一定要看了才能解惑. public String intern()Returns a canonical representation for the string object.A pool of strings, initially empty, is maintained privately by the class String.When the intern method is invoked, if the pool already contains a string equal to this String object as determined by the equals(Object) method, then the string from the pool is returned. Otherwise, this String object is added to the pool and a reference to this String object is returned. 从 JDK6 到 JDK7 的 String Pool 和 intern 方法的改变都比较大(String Pool 从 PermGen 移动到了 Heap, String.intern() 改变见下面的分析) in JDK6: String s = new String(&quot;Hello&quot;) 会创建两个字符串对象, 一个在 String Pool 里的字面值, 一个是 Heap 里的对象. intern() 方法首先在 String Pool 里查找是否有 equals 的字符串, 如果没有则在 String Pool 创建一个字面量字符串, 并返回其引用. 已经存在的话返回在 String Pool 里的引用. String s = new String(&quot;1&quot;), s 创建后, String Pool 和 Heap 各创建一个”1”, s 指向的是 Heap 里的对象; String s2 = &quot;1&quot;, s2 指向的是 String Pool 里的字面值; String s3 = new String(&quot;1&quot;) + new String(&quot;1&quot;) 这时”11”在内存里只有 Heap 里的一个, s3 指向这个 Heap 里的对象, s3.intern 之后 String Pool 里也创建一个”11”; String s4 = &quot;11&quot; s4 指向的是 String Pool 里的对象 in JDK7: String s = new String(&quot;Hello&quot;) 的行为跟 6 一样; str.intern() 执行后, 如果再 String Pool 里没有到 equals 的字符串, 就不再在 String Pool 里创建对象了, 而是直接把 Heap 里的对象引用放进来. // 这也是 6-&gt;7 的 String 的一个重要改变, 减少重复的字符串创建, 也更节省内存. String s = new String(&quot;1&quot;), s 创建后, String Pool 和 Heap 各创建一个”1”, s 指向的是 Heap 里的对象; s.intern() 检查 String Pool 里已经存在”1”的字面值了, 什么都不做; String s2 = &quot;1&quot;, s2 指向的是 String Pool 里的字面值, 故 s == s2 输出 false； String s3 = new String(&quot;1&quot;) + new String(&quot;1&quot;) 这时”11”在内存里只有 Heap 里的一个, s3 指向这个 Heap 里的对象, s3.intern() 在 String Pool 里找不到”11”, 但是不再创建新的, 而是直接把 s3 的引用复制进 String Pool, String s4 = &quot;11&quot; 这种方式创建是指明在 String Pool 里创建, 但是 String Pool 里已经存在一个”11”的引用了, 那么 s4 直接指向这个引用. 所以 s3 和 s4 指向的都是 Heap 里的”11”, 故 s3== s4 输出 true； •内存分区可能抛出的错误 Stack : StackOverflowError &amp; OutOfMemoryError Heap: OutOfMemoryError Method: OutOfMemoryError: PermGen space (1.8 之前) MetaSpace: OutOfMemoryError: Metaspace (1.8+): @ref： JVM相关 - StackOverflowError 与 OutOfMemoryError - 掘金","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://beefyheisenberg.github.io/tags/JVM/"}]},{"title":"Advanced Java-02a-JVM简介","slug":"12.Java/Advanced-Java.02a.JVM简介","date":"2024-01-24T01:27:52.045Z","updated":"2024-01-24T01:27:52.045Z","comments":true,"path":"12.Java/Advanced-Java.02a.JVM简介/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Advanced-Java.02a.JVM简介/","excerpt":"JVM Architecture Explained The JVM Architecture Explained - DZone Java JVM 分为三个子系统: Class Loader, Runtime Data Area, Execution Engine （1）ClassLoaderClassLoader：Java’s dynamic class loading functionality is handled by the ClassLoader subsystem. It loads, links. and initializes the class file when it refers to a class for the first time at runtime, not compile time.","text":"JVM Architecture Explained The JVM Architecture Explained - DZone Java JVM 分为三个子系统: Class Loader, Runtime Data Area, Execution Engine （1）ClassLoaderClassLoader：Java’s dynamic class loading functionality is handled by the ClassLoader subsystem. It loads, links. and initializes the class file when it refers to a class for the first time at runtime, not compile time. BootStrap ClassLoader – Responsible for loading classes from the bootstrap classpath, nothing but rt.jar. Highest priority will be given to this loader. Extension ClassLoader – Responsible for loading classes which are inside the ext folder (jre\\lib). Application ClassLoader –Responsible for loading Application Level Classpath, path mentioned Environment Variable, etc. The above ClassLoaders will follow Delegation Hierarchy Algorithm while loading the class files. （2）Runtime Data AreaRuntime Data Area：… Method Area Heap Area Stack Area Local Variable Array – Related to the method how many local variables are involved and the corresponding values will be stored here. Operand stack – If any intermediate operation is required to perform, operand stack acts as runtime workspace to perform the operation. Frame data – All symbols corresponding to the method is stored here. In the case of any exception, the catch block information will be maintained in the frame data. PC Registers Native Method stacks （3）Execution EngineExecution Engine: The bytecode, which is assigned to the Runtime Data Area, will be executed by the Execution Engine. The Execution Engine reads the bytecode and executes it piece by piece (// Execution Engine 又分为三个子系统: 解释器, JIT编译器, 垃圾收集器) : Interpreter: The interpreter interprets the bytecode faster but executes slowly. The disadvantage of the interpreter is that when one method is called multiple times, every time a new interpretation is required. // 解释器,每次执行同一段代码需要创建多个解释器? JIT Compiler: Execution Engine 使用 Interpreter解释代码并执行, 当 Execution Engine 检测到重复执行的代码时, JIT编译器将字节码便以为 native code Intermediate Code Generator: 中间代码生成器–产生中间代码 Code Optimizer: 代码优化器–负责优化上面生成的中间代码 Target Code Generator: 目标代码生成器–负责生成机器代码(或 native code) Profiler: 负责查找热点，即是否多次调用该方法。 Garbage Collector: 垃圾收集器 【图】JVM Architecture Diagram HotSpot vs OpenJ9 HotSpot VM: Oracle / Sun JDK、OpenJDK的各种变种（例如IcedTea、Zulu），用的都是相同核心的HotSpot VM。 OpenJ9 VM: OpenJ9 HotSpot VM 对比 Open J9: 原文: Part 1: OpenJ9 versus HotSpot 翻译: OpenJ9 和 HotSpot 的对比 Part 1 - OSCHINA stackOverflow 上的问题：jvm - OpenJDK vs Java HotspotVM - Stack OverflowOpenJDK VM 和 Oracle Hotspot 是不同的 VM 吗？Oracle HotSpot VM 基于 OpenJDK HotSpot 项目。因此，它们基本上是同一个 VM，除了 Oracle JVM 有一些额外的商业功能，主要是 Java Flight Recorder, Application Class Data Sharing and Cooperative Memory Management","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://beefyheisenberg.github.io/tags/JVM/"}]},{"title":"Advanced Java-01-JDK","slug":"12.Java/Advanced-Java.01.JDK","date":"2024-01-24T01:27:52.040Z","updated":"2024-01-24T01:27:52.041Z","comments":true,"path":"12.Java/Advanced-Java.01.JDK/","link":"","permalink":"https://beefyheisenberg.github.io/12.Java/Advanced-Java.01.JDK/","excerpt":"Java Development Kit（JDK），包括一个完整的Java运行环境（Java Runtime Environment，JRE），还包括一系列用于Java开发的组件和工具（javac、jar、javap、javadoc、jdb、jps、jhat、jstack ……） JDK 组件java, javac, jar 编译Java源码： javac -classpath PATH;PATH/xx.jar -sourcepath SOURCE_DIR -d OUTPUT_DIR 把.class文件打成Jar包： jar cvf JAR_FILE_NAME CLASS_FILE_NAMES 运行executable的Jar包（Jar包指定了Main-Class）： java -jar JAR_FILE_NAME 执行Jar包里的类（该类有main方法）： java -cp JAR_FILE_NAME CLASS_FULL_NAME 执行Jar包里的类的指定方法： java -cp JAR_FILE_NAME CLASS_FULL_NAME METHOD_NAME, 例如Tomcat 的启动脚本最终是执行了 Bootstrap这个主类中的start方法： java-Djava.util.logging.config.file=/data0/tomcat/tomcat_8080/conf/logging.properties-Xms2048m -Xmx2048m -XX:MaxPermSize=256m-classpath /data0/tomcat/tomcat_8080/bin/bootstrap.jar:/data0/tomcat/tomcat_8080/bin/tomcat-juli.jar -Dcatalina.base=/data0/tomcat/tomcat_8080 -Dcatalina.home=/data0/tomcat/tomcat_8080 -Djava.io.tmpdir=/data0/tomcat/tomcat_8080/temporg.apache.catalina.startup.Bootstrap start","text":"Java Development Kit（JDK），包括一个完整的Java运行环境（Java Runtime Environment，JRE），还包括一系列用于Java开发的组件和工具（javac、jar、javap、javadoc、jdb、jps、jhat、jstack ……） JDK 组件java, javac, jar 编译Java源码： javac -classpath PATH;PATH/xx.jar -sourcepath SOURCE_DIR -d OUTPUT_DIR 把.class文件打成Jar包： jar cvf JAR_FILE_NAME CLASS_FILE_NAMES 运行executable的Jar包（Jar包指定了Main-Class）： java -jar JAR_FILE_NAME 执行Jar包里的类（该类有main方法）： java -cp JAR_FILE_NAME CLASS_FULL_NAME 执行Jar包里的类的指定方法： java -cp JAR_FILE_NAME CLASS_FULL_NAME METHOD_NAME, 例如Tomcat 的启动脚本最终是执行了 Bootstrap这个主类中的start方法： java-Djava.util.logging.config.file=/data0/tomcat/tomcat_8080/conf/logging.properties-Xms2048m -Xmx2048m -XX:MaxPermSize=256m-classpath /data0/tomcat/tomcat_8080/bin/bootstrap.jar:/data0/tomcat/tomcat_8080/bin/tomcat-juli.jar -Dcatalina.base=/data0/tomcat/tomcat_8080 -Dcatalina.home=/data0/tomcat/tomcat_8080 -Djava.io.tmpdir=/data0/tomcat/tomcat_8080/temporg.apache.catalina.startup.Bootstrap start javap, javah javah：根据class文件生成h头文件javah -jni ClassFileName javap：反编译class文件成字节码javap -c ClassFileName jdb@todo javadoc@todo jps, jstack, jhat, jmap@link: Advanced-Java.02d.JVM分析工具 rt.jar, tools.jar, dt.jarrt.jar, tools.jar, dt.jar 都包含于JRE（除此之外还JRE包括Java虚拟机）： rt.jar: rt = runtime, 包括了Java核心类库, java.*包下的类； tools.jar: Jar包工具类, 我们执行的诸如javac等命令实际上是通过java命令调用了tools.jar, 比如 javac ClassName.java 相当于 java -cp tools.jar xx.Main ClassName.java； dt.jar: 主要是Swing类库； jar文件结构 jar包中的 META-INFO/MANIFEST.MF: Main-Class: com.xxx.Test // 指定该选项可以更简单执行jar: java -jar JAR_FILE_NAME Class-Path: libXX.jar // libXX.jar在相同目录下? Oracle JDK vs Open JDK区别与联系Oracle与OpenJDK之间的区别 - 掘金 免费 vs 付费 OpenJDK 每6个月发布一个新版本，不过每次新的版本发布后，旧的就不维护了，比如OpenJDK 12发布之后，11版本便停止更新，停留在11.0.2版本，没有LTS版本； Oracle JDK同样每6个月发布一个新版本，其中9、10、12是 non-LTS版本，Oracle提供的免费更新只有6个月； Oracle JDK 8、11是 LTS版本，提供6个月免费更新，但在这之后的更新不再免费（仅针对商业用户）。 Java 版本 发布日期 Oracle 提供的免费更新 Java 8(LTS) 2014.3 2019.1 Java 9 2017.9 2018.3 Java 10 2018.3 2018.9 Java 11(LTS) 2018.9 2019.3 Java 12 2019.3 2019.9 使用 Oracle JDK的解决方案： Oracle Java 8 （LTS）: 免费：用 8u192以及更早版本（有安全隐患） 交钱使用 Oracle提供的更新（8u211之后的更新） Oracle Java 11 （LTS）: 交钱 Oracle Java 10、12、13 non-LTS 每6个月都升级到下一个版本的JDK 使用其他 OpenJDK的方案： Alibaba JDK, 阿里开源自用OpenJDK版本，Java社区迎来中国力量-InfoQ Azul Systems发布的Zulu产品线中的Java SE产品, 链接, 下图是Azul JDK的 LTS维护周期: 关于 Oracle的许可协议： Oracle JDK 的许可协议有两种: BCL(Oracle Binary Code License Agreement): 个人/开发使用免费，商用免费（但商用免费仅限于”通用计算”设备, 移动设备/嵌入式设备不包括在免费领域）。JDK中的某些商业特性（使用-XX:+UnlockCommercialVMOptions打开的特性）仍是需要付费才可以使用的； OTN(Oracle Technology Network License Agreement): 个人/开发使用免费，商用收费； Oracle 9/10是 BCL, 11/12变成了OTN，Oracle Java SE 11开始，按照OTN（Oracle Technology Network License Agreement）协议规定，只有在开发、测试及原型证明的场景下提供有限的授权。关于授权政策的一些具体问题可以参考下面网页： https://www.java.com/zh_CN/download/faq/distribution.xml @ref Oracle JDK 8 在 8u211 和 8u212之后, 许可协议也变成了 OTN（因为 Oracle JDK 8 u192 是2019年1月前发布的最新版本，所以只要一直使用 JDK 8 u192 以及更早的版本，就不需付费） 本节参考: @ref Oracle如何对JDK收费 - 知乎 @ref Oracle 终于要向 Java 的非付费用户开枪了-怎么看？ - 知乎 JDK 版本历史→ Java version history - Wikipedia 几个重要的 JDK LTS 版本: Java SE8: 2014.3~2030.12 (Oracle于2019.1停止商用更新) Java SE11: 2018.9~2026.9 Java SE17: 2021.9~2029.9 本节参考 https://www.51cto.com/article/670298.html 诞生：1995 年 5 月，Oak 语言改名为 Java，标志着 Java 的诞生，并且提出了著名的 Write Once,Run Anywhere 口号。下面用表格形式记录其发版时间轴： 版本 发布日期 焦点说明 JDK 1.0 1996.01 Java 虚拟机、基础类库 JDK 1.1 1997.02 规定了 Jar 文件格式，JDBC、JavaBeans、RMI 等。开始支持内部类和反射 JDK 1.2 1998.12 引入集合框架 Collections、Map 等。从此版本开始，分为 3 个版本：J2SE/J2EE/J2ME（注：1999.04 著名的 HotSpot 虚拟机诞生，顺势推出了 Java EE 首个版本） JDK 1.3 2000.05 千禧年的第一个版本，对类库进行了优化 JDK 1.4 2002.02 支持正则 Pattern、NIO、JDBC 3.0、assert 断言 JDK 5 2004.09 JDK 命名方式变化、自动拆装箱、泛型、枚举、可变参数、增强 for 循环、JUC 并发包等等非常多新特性 JDK 6 2006.12 编译器注解处理器(lombok 的原理)、J2xx 改为 Java XX JDK 7 2009.02 try-with-resources、NIO2(也叫 AIO)、泛型推断 JDK 8 2014.03 Lambda 表达式、函数式编程、Stream 流式编程、方法引用、接口默认方法、彻底移除 HotSpot 的永久代 … … … JDK 11 2018.09 Jigsaw 模块化、增强类型推断、革命性的垃圾收集器 ZGC … … … JDK 17 2021.09 …敬请期待 Java 17（2021 年 9 月 14）新特性: Java 17 新特性概述 | Java 全栈知识体系 Java 17 新特性概览（重要） | JavaGuide(Java面试+学习指南) 期间，关于 Java/Sun 公司大事记： 日期 事件 1995.05 Java 语言诞生 1996.01 JDK 1.0 版本发布 1998.12 JAVA2 企业平台 J2EE 发布（和 JDK 1.2 一起） 2005.06 JavaOne 大会召开（Java 诞生 10 周年），J2EE 更名为 Java EE, J2SE 更名为 Java SE，J2ME 更名为 Java ME 2009.04 甲骨文 Oracle 以现金收购 Sun 微系统公司，交易价格 74 亿美元（Sun 公司市值顶峰时超 2000 亿美金。眼看他起高楼，眼看他宴宾客，眼看他楼塌了）。Sun 公司最大的资产，便是 Java。从此 Java 商标被 Oracle 收入囊中，才有了后来的 Oracle PK Google 大战 2017.08 Oracle 将Java EE（Java SE 还自己保留）交给开源组织，Eclipse 基金会接手。但 Oracle 不允许开源组织使用 Java 名号，所以 Jakarta EE 名称于 2018.02.26应运而生 JSR, JCP … JSR 是Java Specification Requests的缩写，意思是Java 规范提案。是指向JCP(Java Community Process)提出新增一个标准化技术规范的正式请求。任何人都可以提交JSR，以向Java平台增添新的API和服务。JSR已成为Java界的一个重要标准。 JCP, Java Community Process，Java 社区进程，JCP维护的规范包括J2ME、J2SE、J2EE，XML，OSS，JAIN等。组织成员可以提交JCR（Java Specification Requests），通过特定程序以后，进入到下一版本的规范里面。 Java EE跟JCP说再见-InfoQ","categories":[{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://beefyheisenberg.github.io/tags/JVM/"}]},{"title":"make and cmake","slug":"11.Programming-Language/make-and-cmake","date":"2024-01-24T01:27:52.036Z","updated":"2024-01-24T01:27:52.036Z","comments":true,"path":"11.Programming-Language/make-and-cmake/","link":"","permalink":"https://beefyheisenberg.github.io/11.Programming-Language/make-and-cmake/","excerpt":"make/cmake/qmake 区别GNU Make：Make - GNU Project - Free Software FoundationGNU Make is a tool which controls the generation of executables and other non-source files of a program from the program’s source files. Make gets its knowledge of how to build your program from a file called the makefile, which lists each of the non-source files and how to compute it from other files. When you write a program, you should write a makefile for it, so that it is possible to use Make to build and install the program. CMake：CMakeCMake is an open-source, cross-platform family of tools designed to build, test and package software. CMake is used to control the software compilation process using simple platform and compiler independent configuration files, and generate native makefiles.cmake是跨平台项目管理工具，它用比Makefile更友好的语法来组织项目，cmake 根据 CMakeLists.txt 来生成 makefile qmake：qmake ManualThe qmake tool helps simplify the build process for development projects across different platforms. It automates the generation of Makefiles so that only a few lines of information are needed to create each Makefile. You can use qmake for any software project, whether it is written with Qt or not.","text":"make/cmake/qmake 区别GNU Make：Make - GNU Project - Free Software FoundationGNU Make is a tool which controls the generation of executables and other non-source files of a program from the program’s source files. Make gets its knowledge of how to build your program from a file called the makefile, which lists each of the non-source files and how to compute it from other files. When you write a program, you should write a makefile for it, so that it is possible to use Make to build and install the program. CMake：CMakeCMake is an open-source, cross-platform family of tools designed to build, test and package software. CMake is used to control the software compilation process using simple platform and compiler independent configuration files, and generate native makefiles.cmake是跨平台项目管理工具，它用比Makefile更友好的语法来组织项目，cmake 根据 CMakeLists.txt 来生成 makefile qmake：qmake ManualThe qmake tool helps simplify the build process for development projects across different platforms. It automates the generation of Makefiles so that only a few lines of information are needed to create each Makefile. You can use qmake for any software project, whether it is written with Qt or not. @ref: make makefile cmake qmake都是什么，有什么区别？ - 知乎 make 命令常用参数格式：make [ -f makefile ] [ options ] ... [ targets ] ... -C DIR，--directory=DIR: 在读取 Makefile 之前，进入到目录 DIR，然后执行 make。当存在多个 “-C” 选项的时候，make 的最终工作目录是第一个目录的相对路径 -e，--enveronment-overrides: 使用环境变量定义覆盖 Makefile 中的同名变量定义。 -f=FILE，--file=FILE，-makefile=FILE: 指定文件 “FILE” 为 make 执行的 Makefile 文件 makefile文件解析@todo","categories":[{"name":"11.Programming-Language","slug":"11-Programming-Language","permalink":"https://beefyheisenberg.github.io/categories/11-Programming-Language/"}],"tags":[]},{"title":"Golang Tutorials-02并发","slug":"11.Programming-Language/Golang-Tutorials.02.并发","date":"2024-01-24T01:27:52.032Z","updated":"2024-01-24T01:27:52.032Z","comments":true,"path":"11.Programming-Language/Golang-Tutorials.02.并发/","link":"","permalink":"https://beefyheisenberg.github.io/11.Programming-Language/Golang-Tutorials.02.并发/","excerpt":"chan &amp; select chan 是并发安全的通信对象，读写使用示例: // 使用make 创建一个存储int 类型的chan:ch1 := make(chan int)// 向chan写入:ch1 &lt;- 1// 从chan读出:i := &lt;-ch1// 或者通过ok判断ch里是否有数据i, ok := &lt;-ch1// 不接受返回值的读:fmt.Println(&lt;-ch) 带缓冲区的 chan: ch := make(chan int, 100) 不带缓冲区的 channel, 如果 ch 已经有数据, 再向 ch 写数据会导致写入方阻塞, 如果 ch 空, 读取方会阻塞 带缓冲区的 channel, 如果 ch 没满, 写入方不会阻塞 channel 的关闭: close(channel)，： 只能由 sender 关闭； 调用 close 后，如果 sender 继续写入数据，会 panic； 调用 close 后，receiver 接收完最后一个元素，chan 为关闭状态，尝试从 chan 读取动作不会阻塞，而是立刻返回 success； 使用 select 监视一组 chan, 并从已经准备好的 chan 里随机选出一个, 用法类似 switch, 每个 case 后面是读取 chan 的操作: select &#123; case i := &lt;-ch1: fmt.Println(i) case j := &lt;-ch2: fmt.Println(j) default: fmt.Println(\"?\")&#125; chan 的内部实现，@ref: golang 系列：channel 全面解析 - 知乎 type hchan struct &#123; qcount uint // channel 里的元素计数 dataqsiz uint // 最大可以缓冲的数量 buf unsafe.Pointer // 该 buf 指向一个循环队列的数据结构 closed uint32 // 关闭状态 sendx uint // 当 channel 设置了缓冲数量时，数据区域即循环队列此时已发送数据的索引位置 recvx uint // 当 channel 设置了缓冲数量时，数据区域即循环队列此时已接收数据的索引位置 recvq waitq // 想读取数据但又被阻塞住的 goroutine 队列 sendq waitq // 想发送数据但又被阻塞住的 goroutine 队列 lock mutex&#125;","text":"chan &amp; select chan 是并发安全的通信对象，读写使用示例: // 使用make 创建一个存储int 类型的chan:ch1 := make(chan int)// 向chan写入:ch1 &lt;- 1// 从chan读出:i := &lt;-ch1// 或者通过ok判断ch里是否有数据i, ok := &lt;-ch1// 不接受返回值的读:fmt.Println(&lt;-ch) 带缓冲区的 chan: ch := make(chan int, 100) 不带缓冲区的 channel, 如果 ch 已经有数据, 再向 ch 写数据会导致写入方阻塞, 如果 ch 空, 读取方会阻塞 带缓冲区的 channel, 如果 ch 没满, 写入方不会阻塞 channel 的关闭: close(channel)，： 只能由 sender 关闭； 调用 close 后，如果 sender 继续写入数据，会 panic； 调用 close 后，receiver 接收完最后一个元素，chan 为关闭状态，尝试从 chan 读取动作不会阻塞，而是立刻返回 success； 使用 select 监视一组 chan, 并从已经准备好的 chan 里随机选出一个, 用法类似 switch, 每个 case 后面是读取 chan 的操作: select &#123; case i := &lt;-ch1: fmt.Println(i) case j := &lt;-ch2: fmt.Println(j) default: fmt.Println(\"?\")&#125; chan 的内部实现，@ref: golang 系列：channel 全面解析 - 知乎 type hchan struct &#123; qcount uint // channel 里的元素计数 dataqsiz uint // 最大可以缓冲的数量 buf unsafe.Pointer // 该 buf 指向一个循环队列的数据结构 closed uint32 // 关闭状态 sendx uint // 当 channel 设置了缓冲数量时，数据区域即循环队列此时已发送数据的索引位置 recvx uint // 当 channel 设置了缓冲数量时，数据区域即循环队列此时已接收数据的索引位置 recvq waitq // 想读取数据但又被阻塞住的 goroutine 队列 sendq waitq // 想发送数据但又被阻塞住的 goroutine 队列 lock mutex&#125; chan 使用范例：@ref : 深入golang之—goroutine并发控制与通信 - 知乎 CSP模型：Communicating Sequential Process，Go的Channel 和 Actor都算一种实现，二者的区别.. 代码demo功能：主进程和协程通信，主进程等待协程退出 共享变量实现：考虑这种做法的缺点是？ Channel + WaitGroup实现 Context + WaitGroup实现 syncGo 语言在 sync 包中提供了用于同步的一些基本原语，包括常见的 sync.Mutex、sync.RWMutex、sync.WaitGroup、sync.Once 和 sync.Cond @todo os/exec@Ref：go os/exec 简明教程 cmd基本函数： cmd.Start() 和 cmd.Wait(), 其他函数的实现可以看做是对Start和Wait的封装 cmd.Run() = Start() + Wait() cmd.CombinedOutput() = cmd. Stdout和cmd.Stderr关联同一个Buffer + Run()cmd属性: 标准输出/错误： cmd. Stdout 和 cmd. Stderr属性 cmd := exec.Command(\"ls\", \"-lah\")var stdout, stderr bytes.Buffercmd.Stdout = &amp;stdout // stdout关联Buffercmd.Stderr = &amp;stderrerr := cmd.Start() // 非阻塞if err != nil &#123; log.Fatalf(\"failed to call cmd.Start(): %v\", err)&#125;log.Printf(\"pid: %d\", cmd.Process.Pid)cmd.Process.Wait() // 阻塞直到退出log.Printf(\"exitcode: %d\", cmd.ProcessState.ExitCode())","categories":[{"name":"11.Programming-Language","slug":"11-Programming-Language","permalink":"https://beefyheisenberg.github.io/categories/11-Programming-Language/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://beefyheisenberg.github.io/tags/Golang/"}]},{"title":"Golang Tutorials-01基础","slug":"11.Programming-Language/Golang-Tutorials.01.基础","date":"2024-01-24T01:27:52.027Z","updated":"2024-01-24T01:27:52.028Z","comments":true,"path":"11.Programming-Language/Golang-Tutorials.01.基础/","link":"","permalink":"https://beefyheisenberg.github.io/11.Programming-Language/Golang-Tutorials.01.基础/","excerpt":"Golang中的约定大于配置Golang遵循”约定大于配置”(convention over configuratio)的理念: 小写开头的标识(变量/函数/结构体类型等等)是 package 内可见, 大写开头的标识包外可见(类似 public) 结构体中的”小写开头的成员”, 在用 json.Marshal 序列化时会被忽略 每个文件是一个 package，声明在源文件第一行，package main 是一个特殊的包 import as _ 和 . 的包: import . &quot;packageXXX&quot; : 调用包内的函数,不需要再加 packageXXX. import _ &quot;packageXXX&quot; : 匿名导入，并不使用包内导出的函数，而是仅仅让包的 init 得到调用 单元测试: 文件名: 源文件名_test.go 函数名: func Test源函数名() Package &amp; Import// A package clause starts every source file.// main is a special name declaring an executable rather than a library.package mainimport ( \"fmt\" // A package in the Go standard library. \"io/ioutil\" // Implements some I/O utility functions. \"math\" // Math library with local alias m. \"net/http\" // Yes, a web server! \"os\" // OS functions like working with the file system)func main() &#123;&#125;","text":"Golang中的约定大于配置Golang遵循”约定大于配置”(convention over configuratio)的理念: 小写开头的标识(变量/函数/结构体类型等等)是 package 内可见, 大写开头的标识包外可见(类似 public) 结构体中的”小写开头的成员”, 在用 json.Marshal 序列化时会被忽略 每个文件是一个 package，声明在源文件第一行，package main 是一个特殊的包 import as _ 和 . 的包: import . &quot;packageXXX&quot; : 调用包内的函数,不需要再加 packageXXX. import _ &quot;packageXXX&quot; : 匿名导入，并不使用包内导出的函数，而是仅仅让包的 init 得到调用 单元测试: 文件名: 源文件名_test.go 函数名: func Test源函数名() Package &amp; Import// A package clause starts every source file.// main is a special name declaring an executable rather than a library.package mainimport ( \"fmt\" // A package in the Go standard library. \"io/ioutil\" // Implements some I/O utility functions. \"math\" // Math library with local alias m. \"net/http\" // Yes, a web server! \"os\" // OS functions like working with the file system)func main() &#123;&#125; initinit()函数特性: 在 main 之前, 由 runtime 调用 同一个 go 文件下, 可以有多个 init 函数, 调用顺序同定义顺序 同一个 package 下, 可以有多个 init 函数, 调用顺序似乎是 go 文件字典顺序, 但不要依赖此顺序做初始化 对于 import 导入的包，这些导入的包的 init 的调用顺序同 import 的顺序 用户代码无法调用 init(), 会报错 undefined ➤ init 使用场景: 做初始化； 实现 sync.Once 功能； 无法用初始化表达式初始的变量； 变量 变量的声明 + 初始化： var i int = 1// 更方便的写法j := 1 全局变量Go 支持全局变量，首字母大写的变量名表示可被外界访问： package mypkgvar myVar = 100 // 未导出的本地变量const MyConst = \"hello\" // 导出的全局变量 基本数据类型整形： uint8/int8: 平台无关, 8位 uint16/int16: .. uint32/int32: .. uint64/int64: .. uint/int: 平台有关，可能是32 or 64 bits(视机器平台而定) 浮点数： float32：平台无关，4位 float64：… 复数： complex64: 复数, 由float32的实部 + float32的虚部构成 @ref: The Go Programming Language Specification - The Go Programming Language string 双引号和反引号： str1 := \"string example\"str2 := `another stringexample`str3 := `&#123;\"type\": \"json\"&#125;` 字符串是”只读的”, 意味着无法直接修改字符串的内存空间 字符串的实现，运行时使用 reflect.StringHeader 结构体表示字符串，与切片的结构体（SliceHeader）相比，字符串只少了一个表示容量的 Cap 字段: type StringHeader struct &#123; Data uintptr Len int&#125; 判断字符串 empty: len(str) == 0 类型转换 Golang的类型转换: T(var) 字符串 → any 都可以用strconv: i, err := strconv.ParseInt(\"1287089\", 10, 32)result := int(i) 函数Golang 函数声明的不同之处：形参列表后面才是返回值，返回值可以有多个，变量名在前类型在后 多个返回值: // 多个返回func foo1(x, y int) (sum, prod int) &#123; return x+y, x*y&#125; 可变参数: // 可变参数func foo1(params ...type) &#123; for _, param := range params &#123; ... &#125;&#125; Golang 是值传递还是引用传递? Golang 是值传递, 函数内得到一份形参的拷贝 对于 slice, map, chan, 因为其结构内包含指针, 所以仍可以在函数内改变其存储的值 数组也是值传递，因为数组的类型是 [N]Type，所以数组作为形参是有局限性的，大小 N 被固定，推荐用 slice 闭包（closure）例1: x := 1f := func() bool &#123; return x &gt; 100&#125;f() 例2: func foo2(x int) func() &#123; return func() &#123; x = x + 1 fmt.Printf(\"foo1 val = %d\\n\", x) &#125;&#125;f = foo2(133)f() 什么是闭包(closure)? a closure is a record storing a function together with an environment., 那么闭包的简化定义是: 函数+依赖的外部变量（不以参数传入的变量） 实际上, Golang 实现闭包, 实际是把 函数 和它依赖的外部变量 都放在了一个 struct 里, 用这个 struct 保存了函数地址，和它依赖的外部变量（的引用） 闭包的实现依赖 Golang 的逃逸分析, 在逃逸分析时，闭包依赖的外部环境变量，被判定为逃逸，则在堆上分配； 闭包另一个特性是延迟绑定, 意思是, 上面的闭包(也即 struct)里保存的环境变量的值, 不是在编译期确定的, 而是在闭包的运行时才确定, 在闭包的外部寻找依赖变量的最新值, 并赋值进去 // 闭包的运行时即 闭包() 时； 闭包 - 维基百科，自由的百科全书)在支持头等函数的语言中，如果函数f内定义了函数g，那么如果g存在自由变量，且这些自由变量没有在编译过程中被优化掉，那么将产生闭包。 再使用一个例子说明闭包的延迟绑定，下面输出什么? func foo(x int) []func() &#123; var fs []func() values := []int&#123;0, 1, 2, 3&#125; for _, val := range values &#123; fs = append(fs, func() &#123; fmt.Printf(\"in closure, x + val = %d\\n\", x+val) &#125;) &#125; return fs&#125;fs := foo(10)for _, f := range fs &#123; f() // 闭包运行时&#125; 这类问题的通解是： 找出闭包，找出闭包依赖的外部变量 在闭包运行时（调用 func() 时），找到外部变量当前值 分析: foo 返回了一个数组, 数组内是4个闭包函数, 闭包函数依赖2个外部变量: x 和 val foo 返回 fs 的时候, 仅仅是返回了一个闭包的定义, struct 定义中包含有“外部变量” x 和 val，但是 struct 中的 x 和 val 只是引用，并没有绑定值 第一次执行 f() 时, 寻找 x 和 val 的最新值并绑定到闭包, 也即10 和 3 所以输出的%d 是 13,13,13,13 Goroutine 的闭包： 没有自由变量，没有形成真正的闭包： func show(v interface&#123;&#125;) &#123; fmt.Printf(\"foo4 val = %v\\n\", v)&#125;func foo4() &#123; values := []int&#123;1, 2, 3, 5&#125; for _, val := range values &#123; go show(val) &#125;&#125;​foo4() // 打印 1,2,3,5 （不一定按顺序） go 后面的匿名函数内，使用了自由变量，形成了闭包，所以外部变量会在“运行时”绑定： func foo5() &#123; values := []int&#123;1, 2, 3, 5&#125; for _, val := range values &#123; go func() &#123; fmt.Printf(\"foo5 val = %v\\n\", val) &#125;() &#125;&#125;​foo5() // 打印 5,5,5,5 解析： go func() {... } () 的写法，虽然最后带 ()，但匿名函数并没有立刻执行，只是将它加入任务队列等待调度； 匿名函数使用了外部变量，也即形成了闭包，Go 对闭包的实现是定义一个 struct，该 struct 的成员包括函数返回地址和引用的环境中的变量地址； 匿名函数被 Goroution scheduler 调度到，以闭包的方式执行 @ref: 闭包的实现 · 深入解析Go：https://tiancaiamao.gitbooks.io/go-internals/content/zh/03.6.html Golang：“闭包（closure）”到底包了什么？ - 知乎：https://zhuanlan.zhihu.com/p/92634505 控制语句 if可以先赋值再判断 if x:=computerValue(); x&gt;y &#123;&#125; 按次数循环 // 循环1for x:=0; x&lt;10; x++ &#123; fmt.Println(x)&#125;// 一直循环for &#123;&#125; 遍历map/slice, 使用关键字range: index, elem : = range slice or k, v := range map // 循环遍历 mapfor k,v := range map[string]int &#123;\"one\":1, \"two\":2&#125; &#123; fmt.Println(\"%s %d\\n\", k,v)&#125;// 循环遍历 slicefor i,s := range []string &#123;\"one\",\"two\"&#125; &#123; fmt.Println(\"%d %s\\n\", i,s)&#125; switch switch x &#123;case 1: // 隐式break, 匹配到一个即停止default:&#125; type @ref: https://colobu.com/2017/06/26/learn-go-type-aliases/ golang中type的用法: 定义新类型: type newType oldType // C++中的typedef用法是typedef oldType newType … 定义结构体: type STypeName struct{} 类型别名: type rune = int32type byte = uint8type FloatType float32// 类型别名2:type S = stringvar str S = \"hello world\"// 函数别名:type F = func()var foo F = func() &#123;&#125; struct 定义： type YourFirstStruct struct &#123; member1 string member2 string // 每个成员没有分号&#125; 创建实例： s := YourFirstStruct &#123; member1: \"member1\", member2: \"member2\",&#125; golang 只有值传递, struct 在函数内/外传递 or 直接 = 赋值给另一 struct 变量, 都会有一次拷贝； s1 := YourFirstStruct &#123; member1: \"\" member2: \"\"&#125;s2 := s1 // 赋值导致一次拷贝// 避免拷贝的做法:ptr1 := &amp;YourFirstStruct &#123;&#125;ptr2 := ptr1 // 指针传递 因为函数传参是值传递，所以在函数内对 struct 类型的参数进行更改，所修改的只是副本，如果需要实现在函数内对 struct 的修改，应该使用 *T 类型作为形参； type T struct&#123; Value int&#125;func main()&#123; myT := T&#123;Value:666&#125; change(&amp;myT) println(myT.Value)&#125;func change(t *T)&#123; t.Value = 999&#125; 给Struct添加方法, 无需C++那样的头文件声明, 直接定义方法: // s被叫做“接收器”，第一种是“指针接收器”func (s *YourFirstStruct) foo(param int) (ret int) &#123;&#125;// “值接收器”func (s YourFirstStruct) foo2(param int) (ret int) &#123;&#125; 比较 struct 的“指针接收器” &amp; “值接收器” 如果 func 内改变结构体的内容，需要“指针接收器”； 从性能比较，“值接收器” 需要更多次拷贝； 如果使用“值接收器”，因为函数内使用的是拷贝，所以func线程安全 interface interface是一种类型, 包括0个或多个方法 type I interface &#123; Get() int Set(int)&#125; 空interface: interface{} 没有方法的interface, 可以认为任何类型都实现了该interface, func foo(any interface&#123;&#125;) &#123; // foo可以接受任何类型的参数&#125; Golang里没有extends这样的关键字来表名 某struct 实现了 某Interface, 只是在 赋值, 入参, 返回值 时被动检查 array 数组在编译期即指定大小 // 数组在用var声明时即分配了空间并给初始值var arr0 [4]string// 声明, 同时赋值arr1 := [3]string &#123;\"a\", \"b\", \"c\"&#125;arr2 := [...]string &#123;\"a\", \"b\", \"c\"&#125; golang在创建字面量数组时, 会根据数组长度进行不同的处理 数组len&lt;=4, 直接在栈上分配数组 数组len&gt;4, 会在静态区分配数组(编译期), 并在运行时取出来 上述没有考虑逃逸 数组的类型是: [N]ElemType, 长度也算类型的一部分, 例如 [10]int 和 [3]int 是不同的类型 在 golang 中，数组也是值传递，所以： 对于大型数组，应该使用 数组指针 or slice 的方式传递参数，避免拷贝； 如果要在函数内，修改函数外声明的数组，需要使用数组指针作为参数； slice slice: Golang 内置类型, 即”动态数组” // 区别：数组的长度固定，不可改变 比较 slice 和 array 的声明方式 s2 := []int{1,2,3} 字面量声明方式创建 slice 如果上面使用 [N] or [...] ，创建出来的就不是 slice 而是 array 了 // 数组: 声明即分配空间var arr0 [4]string// 切片: 声明时没有分配空间var slice0 []stringslice0[0] = 1 // panic: runtime error: index out of range// 创建切片1, 通过数组s1 := arr0[0:1]// 创建切片2, 创建时给初值s2 := []int&#123;1,2,3&#125;// 创建切片3, len=cap=0s3 := make([]int, 0) 切片的扩容: 向切片add元素, 如果 len 大于 cap, 将创建新数组, 大小为原切面cap的两倍, 然后所有元素复制到新数组中 切片底层实现，由两部分组成: Header + 数组实际存储空间, 其中 Header 的结构表述如下 type SliceHeader struct &#123;array unsafe.Pointer // 指针, 指向连续的内存len intcap int&#125; 从数组创建切片: slice := array[startIndex:endIndex] , 切片将包含 array[startIndex] ...array[endIdex-1], 这种方式创建的新数组, 只是新建了一个 slice 结构, data 指针指向的即是数组, 故修改 slice 的数据也会影响数组中的值: array := [5]int&#123;1, 2, 3, 4, 5&#125;slice := array3[1:3] // 此时slice包括 [2,3], len=2, 但slice指向的数组是[2,3,4,5], 故cap=4slice[0] = 7 // 对切片的修改也会影响数组, 但当切片发生一次扩容之后, 切片会指向一个新申请的数组空间 复制切片：slice3 := slice2[:] 可以快速复制切片，但缺陷是 slice3 和 slice2 是同一个切片，无论改动哪个，另一个都会产生变化。内建函数 copy 可以用于复制 slice，并且两个 slice 各自使用独立的数组，见「内置函数」 ➤ 比较数组和切片: 数组声明即分配空间, 且不可改变长度 切片声明不分配空间, 需要通过make() or arr[start:end] 切片的类型是 []type, 数组的类型是[N]type map 声明和初始化, 赋值, 访问： // 声明var mmap1 map[string]int// 初始化mmap1 = make(map[string]int)// 赋值mmap1[\"One\"] = 1// 访问if v, exist := mmap1[\"One\"]; exist &#123; delete(mmap1, \"One\")&#125;// 声明+定义mmap2 := map[string]string &#123;\"One\":1, \"Two\":2&#125; How to range map: for k,v = range myMap &#123; fmt.Printf(\"%s %s\", k, v)&#125; chan见第二部分 内置函数@ref: https://pkg.go.dev/builtin#pkg-functions len/cap len/cap: 返回数组, slice, map, string, chan ..的长度&amp;容量 append/copy append: 切片拼接，原型: func append(slice []Type, elems ...Type) []Type copy：切片复制，原型: func copy(dst, src []Type) int print/println print：输出到 std err，原型: func print(args ...Type) println：输出到 std err，arg 之间有空格，且有换行，原型: func println(args ...Type) 区分 fmt.Print()，输出到 standard output makefunc make(t Type, size ...IntegerType) Type slice: make([]T) make([]T, len) make([]T, len, cap) map: make(map[K]V) make(map[K]V, cap) chan: make(chan T, cap) new 原型: func new(Type) *Type 作用: 返回为指定类型分配的内存地址，分配的内存置零 example: type YourStruct struct &#123; member1 int&#125;// 创建struct方式1p1 := new(YourStruct)p1.member1 = 2// 创建struct方式2p2 := &amp;YourStruct&#123; ... &#125; Golang 中 new 和 var ，一个返回指针一个返回变量，二者的实现没有本质区别，都是要通过逃逸分析判断是在栈上/堆上分配变量（如果没有逃逸，new 创建的变量也可能在栈上创建） make vs new new(T)： 分配一块内存，内存置零，返回其指针（并未初始化） 根据new(T)的T创建内存，返回*T类型，p := new(Type) 等同于p := &amp; Type{} make(T)： 分配一块内存，并初始化，返回地址 make只能用于初始化slice/map/chan 比较： new([]int) 只分配了一片内存（指向 []int 类型，也就是 slice 的头）但是这块内存的 ptr 并未初始化； make([]int) 为 slice 的 prt 做了初始化； @ref: Go 语言中的 make 和 new | Go 语言设计与实现 delete delete: 用于删除 map 里的 key, 原型: func delete(m map[Type]Type1, key Type) close 关闭 chan，原型 func close(c chan&lt;- Type) close() 只能由 sender 调用，不可以由 receiver 调用，一旦对 chan 使用了 close，在接收完最后一个值后，该 chan 将被关闭，任何从该 chan 的 receive 都会返回 success 而不会阻塞； panic &amp; recoverypanic： panic 会停止当前 Goroutine 的正常执行，相当于其他编程语言的抛异常 原型：func panic(v any) 行为： 当函数 F 调用了 panic，F 的执行会被停止，在 F 中 panic 前面定义的 defer 操作都会被执行，然后 F 函数返回给调用者 G。 对于 G，调用 F 的行为类似于调用 panic，G 将调用 defer 函数，并返回给上一层调用者，直到程序非零值退出（除非调用了recover） recovery：让程序从 panic 中恢复，阻止 panic 继续向上层调用者传播。返回类型是 any，返回的值是传入 panic(v) 的参数，recovery 必须在 defer 块中调用 原型：func recover() any ➤ panic &amp; recovery 使用示例： func main() &#123; defer func() &#123; if r := recover(); r != nil &#123; fmt.Println(\"Recovered in main\", r) &#125; &#125;() fmt.Println(\"Returned normally from main.\") &#125; func f(i int) &#123; fmt.Println(\"Calling f.\") if i &gt; 0 &#123; fmt.Println(\"Panicking in f!\") panic(fmt.Sprintf(\"%v\", i)) &#125; fmt.Println(\"Returned normally from f.\")&#125; @ref: https://pkg.go.dev/builtin#panic ➤ defer 关键字 → [[#defer]] error error是一个Interface: type error interface &#123; // 接口只有一个函数,返回字符串 Error() string&#125; 使用errors创建一个错误: err := errors.New(&quot;Error occured!&quot;), 返回的是一个type errorString struct类型的错误 定义自己的 error 类型: 定义错误的 Struct 类型, 然后实现 Error() string 方法即可 defer 函数内定义的 defer 后的表达式，在函数退出前执行； 一个 func 可以有多个 defer 语句, defer 语句被压入栈中，所以函数退出时执行顺序与 defer 定义顺序相反； 如果 defer 之后是一个带参函数，例如 defer f(i)，运行至 defer 时会立刻保存 i 的值（类似于一次值拷贝）； 如果 defer 之后形成了闭包（匿名函数内使用了外部变量），那么对外部变量的处理与闭包类似，在闭包实际运行时读取外部变量的最新值 func DeferEtudes3() &#123; i := 1 // 以形参传入，不是闭包的自由变量 j := 9 // 形成闭包的自由变量 defer func(i int) &#123; fmt.Printf(\"in defer: i=%d, j=%d\\n\", i, j) // 1， 10 &#125;(i) i = i + 1 j = j + 1 fmt.Printf(\"in func: i=%d, j=%d\\n\", i, j) // 2， 10 // j是闭包的自由变量，符合“运行时”绑定值， // i以参数传入，不是闭包的自由变量，会在运行到defer时就保存当时的值&#125; @ref： Defer, Panic, and Recover - The Go Programming Language ➤ defer 的实现： 编译器将 defer 关键字转换为调用 runtime.deferproc() 函数，这个函数接收了参数的大小和闭包所在的地址两个参数。 在 runtime.deferproc() 中，创建一个 runtime._defer 结构体，并为它的成员赋值：函数指针 fn、程序计数器 pc 和栈指针 sp ，并将相关的参数拷贝到相邻的内存空间中，并将结构体加入 _defer 链表的开头； 在调用 defer 的函数末尾，插入 runtime.deferreturn() 函数的调用，该函数会从 Goroutine 的 _defer 链表中取出最前面的 runtime._defer 结构体 … 以上 @ref: 理解 Go 语言 defer 关键字的原理 | Go 语言设计与实现 序列化 小写开头的成员默认不被序列化 struct tag: json:&quot;var_name&quot; 指定序列化后的变量名 struct tag: json:&quot;var_name,omitempty&quot; 如果成员值为”zero-value”, 序列化将不包括此字段 struct tag: json:&quot;-&quot; 序列化时跳过此字段 type YourFirstStruct struct &#123; Mem1 string `json:\"variable1\"` Mem2 string `json:\"variable2,omitempty\"` Mem3 string `json:\"-\"` // 每个成员没有分号&#125; Type(struct/map 等) → byte[] slice_of_byte, err := json.Marshal(obj) byte[] → Type obj := interface&#123;&#125;json_str := `&#123;\"Name\":\"X\", \"Age\": 101&#125;`err := json.Unmarshal([]byte(json_str), &amp;obj) 时间 API 获取 int64时间戳: var timestampSec int32 = time.Now().Unix() 单元测试https://geektutu.com/post/quick-go-test.html 命令行 &amp; 环境Usage: go &lt;command&gt; [arguments]The commands are: bug start a bug report build compile packages and dependencies clean remove object files and cached files doc show documentation for package or symbol env print Go environment information fix update packages to use new APIs fmt gofmt (reformat) package sources generate generate Go files by processing source get add dependencies to current module and install them install compile and install packages and dependencies list list packages or modules mod module maintenance run compile and run Go program test test packages tool run specified go tool version print Go version vet report likely mistakes in packages ➤ 常用： 获取包并安装：go get golang.org/x/tools/gopls@latest （源码默认下载到 $GOPATH/src） 开启 Go module：go env -w GO111MODULE=on，从 v1.13 版本开始这个选项默认开启 Go 1.11 引入了 Go Modules，不再使用 GOPATH 存储每个依赖包的 git checkout，而是通过项目目录下的 go.mod 记录依赖包 ➤ Golang 的环境变量可以使用 go env 查看： $GOROOT 表示 Go SDK 的安装位置，它的值一般都是 $HOME/go $GOPATH 表示工作空间的路径，用来保存 Go 项目代码和第三方依赖包 $GOARCH 表示目标机器的处理器架构，它的值可以是 386、amd64 或 arm。 $GOOS 表示目标机器的操作系统，它的值可以是 darwin、freebsd、linux 或 windows。 $GOARM 专门针对基于 arm 架构的处理器，它的值可以是 5~7，默认为 6。 GOARM=5: 使用软件浮点（software floating point）；当 CPU 没有 VFP 协同处理器时 GOARM=6: 仅使用 VFPv1; 使用交叉编译时的默认使用此选项，通常在 ARM11 或更高版本的内核中使用（也支持 VFPv2 或更高版本） GOARM=7: 使用 VFPv3；通常在 Cortex-A 内核中使用","categories":[{"name":"11.Programming-Language","slug":"11-Programming-Language","permalink":"https://beefyheisenberg.github.io/categories/11-Programming-Language/"}],"tags":[{"name":"Golang","slug":"Golang","permalink":"https://beefyheisenberg.github.io/tags/Golang/"}]},{"title":"C语言 & C++ 标准","slug":"11.Programming-Language/C和CPP标准","date":"2024-01-24T01:27:52.022Z","updated":"2024-01-24T01:27:52.023Z","comments":true,"path":"11.Programming-Language/C和CPP标准/","link":"","permalink":"https://beefyheisenberg.github.io/11.Programming-Language/C和CPP标准/","excerpt":"C语言标准 C89: 1989 年，C语言由美国国家标准协会（ANSI）进行了标准化，这个版本的语言经常被称作”ANSI C”，或有时称为”C89” C99: 在2000年三月，ANSI采纳了ISO/IEC 9899:1999标准。这个标准通常指C99。新特性: 包括内联函数（inline functions）、可变长度的数组（variable-length array）、灵活的数组成员（即柔性数组）、复合字面量、指定成员的初始化器、对IEEE754浮点数的改进、支持不定参数个数的宏定义，在数据类型上还增加了 long long int 以及复数类型。 C11: 在2011年12月，ANSI采纳了ISO/IEC 9899:2011标准。这个标准通常即C11。新特性: 字节对齐说明符(alignas)、泛型机制（generic selection）、对多线程的支持、静态断言、原子操作以及对 Unicode 的支持 C18: 在2018年6月，ANSI采纳了ISO/IEC 9899:2018标准，这个标准通常即C18(有时被称为C17)，它是C语言的现行标准。 C++标准 C++98: C++98是第一个C++标准。它分为两个部分：核心语言和C++标准程序库；后者包含了大部分标准模板库和C标准程序库的稍加修改版本。存在许多不属于标准部分的C++程序库，且使用外部链接，程序库甚至可以用C撰写。 C++03: C++11: C++14 C++17: C 和 C++的异同","text":"C语言标准 C89: 1989 年，C语言由美国国家标准协会（ANSI）进行了标准化，这个版本的语言经常被称作”ANSI C”，或有时称为”C89” C99: 在2000年三月，ANSI采纳了ISO/IEC 9899:1999标准。这个标准通常指C99。新特性: 包括内联函数（inline functions）、可变长度的数组（variable-length array）、灵活的数组成员（即柔性数组）、复合字面量、指定成员的初始化器、对IEEE754浮点数的改进、支持不定参数个数的宏定义，在数据类型上还增加了 long long int 以及复数类型。 C11: 在2011年12月，ANSI采纳了ISO/IEC 9899:2011标准。这个标准通常即C11。新特性: 字节对齐说明符(alignas)、泛型机制（generic selection）、对多线程的支持、静态断言、原子操作以及对 Unicode 的支持 C18: 在2018年6月，ANSI采纳了ISO/IEC 9899:2018标准，这个标准通常即C18(有时被称为C17)，它是C语言的现行标准。 C++标准 C++98: C++98是第一个C++标准。它分为两个部分：核心语言和C++标准程序库；后者包含了大部分标准模板库和C标准程序库的稍加修改版本。存在许多不属于标准部分的C++程序库，且使用外部链接，程序库甚至可以用C撰写。 C++03: C++11: C++14 C++17: C 和 C++的异同 宏与模板: C++ 的模板在设计之初的一个用途就是用来替换宏定义。模板特性在 C++11 后支持了可变长度的模板参数表，可以用来替代 C 中的可变长度函数并保证类型安全； 泛型：C++使用模板，C语言在C11中也通过_Generic宏支持了泛型； 重载：C++支持重载； 指针与引用: C++ 中你仍然可以使用 C 风格的指针，但是对于变量传递而言，更推荐使用 C++ 的 引用 特性来实现类似的功能。由于引用指向的对象不能为空，因此可以避免一些空地址访问的问题； struct: 在 C 和 C++ 中都有 struct 的概念，C 中的 struct 用来描述一种固定的内存组织结构，而 C++ 中的 struct 就是一种类，它与类唯一的区别就是它的成员和继承行为默认是 public 的，而一般类的默认成员是 private 的； const: const 在 C 中只有限定变量不能修改的功能，而在 C++ 中，由于大量新特性的出现，const 也被赋予的更多用法。C 中的 const 在 C++ 中的继任者是 constexpr； 内存分配: C++ 中新增了 new 和 delete 关键字用来在“自由存储区”上分配空间，这个自由存储区可以是堆也可以是静态存储区，他们是为了配合“类”而出现的。其中 delete[] 还能够直接释放动态数组的内存，非常方便。new 和 delete 关键字会调用类型的构造函数和析构函数，相比 C 中的 malloc()、realloc()、free() 函数，他们对类型有更完善的支持，但是效率不如 C 中的这些函数。 参考@ref: C++ - 维基百科，自由的百科全书 C++标准演化简介 | Jack Huang’s Blog 现代 C99, C11 标准下的 C 语言编程","categories":[{"name":"11.Programming-Language","slug":"11-Programming-Language","permalink":"https://beefyheisenberg.github.io/categories/11-Programming-Language/"}],"tags":[]},{"title":"Cpp Tutorials-04-Debug and Perf","slug":"11.Programming-Language/Cpp-Tutorials.04.Debug-and-Perf","date":"2024-01-24T01:27:52.017Z","updated":"2024-01-24T01:27:52.017Z","comments":true,"path":"11.Programming-Language/Cpp-Tutorials.04.Debug-and-Perf/","link":"","permalink":"https://beefyheisenberg.github.io/11.Programming-Language/Cpp-Tutorials.04.Debug-and-Perf/","excerpt":"排查指针/内存问题 &amp; 解决方案指针引起的内存问题: 野指针读写: 野指针指的是未经初始化的指针（似乎int *p;定义的指针没有自动置为Null） 悬垂指针读写: 被free释放但是没有置为Null的指针 数组等类型读写越界 内存释放两次（DF，Double Free），第二次释放导致coredump 内存泄漏, 通常是不匹配地使用 malloc/new/new[] 和 free/delete/delete[] Core Down问题排查引起core down的原因可能有:","text":"排查指针/内存问题 &amp; 解决方案指针引起的内存问题: 野指针读写: 野指针指的是未经初始化的指针（似乎int *p;定义的指针没有自动置为Null） 悬垂指针读写: 被free释放但是没有置为Null的指针 数组等类型读写越界 内存释放两次（DF，Double Free），第二次释放导致coredump 内存泄漏, 通常是不匹配地使用 malloc/new/new[] 和 free/delete/delete[] Core Down问题排查引起core down的原因可能有: 数组访问越界, 读到错误的数据, 这种情况一般直接Core down? 数组/指针写越界, 破坏了其他的数据, 这种情况可能当时不引起Core down Double Free, 第二次free()直接Core down 不使用第三方工具重载new/ malloc, 申请的内存添加头部/尾部特殊字节(线程id), 并用magic number填充, core down时可以分析是被哪个线程写入了 使用第三方工具/库解决方案:一些满足特殊现象的分析方法: 对于固定会越界的代码位置来说，计算好数据位置，使得越界后第一个字节的内存起始的内存页mprotect写保护中就可以了。随后像man文档的例子一样注册SIGSEGV信号的处理函数即可，这里可以用backtrace(3)和backtrace_symbols(3)等函数来打出调用栈，轻松找过越界的罪魁祸首 gdb调试支持对内存位置设置修改断点，而且gdb的内存断点不像直接用mprotect()有那么多限制 静态分析工具代码静态分析工具, google有很多, 可以检查疑似写内存的问题 分析coredump文件一般方法仍然是分析coredump文件, coredump文件里有哪些有用的信息? glibc的MALLOC_CHECK环境变量, 适用于“double free”, “free(invalid )” 实现: 实际上malloc()分配的内存会比用户实际申请的长度大一点，在返回给用户代码的指针位置的前面有一个固定大小的结构，放置着该块内存的长度、属性和管理的数据结构。 每当在程序运行过程free内存给glibc时，glibc会检查其隐藏的元数据的完整性，如果发现错误就会立即abort。 electric-fence内存调试库: 适用于内存被写坏, 延后引发的core down。 原理是采用Linux的虚拟内存机制来保护动态分配的内存，在申请的内存的位置放置只读的哨兵页，在程序越界读写时直接coredump退出。 因为对内存做保护使用了mprotect(2)等API，这个API对内存设置只读等属性要求内存页必须是4K对齐的（本质上是Intel CPU的页属性设置的要求），所以内存使用率较低的程序可以用该库进行检查，但是内存使用率很高的程序在使用过程中会造成内存暴涨而不可用。 Valgrind仿真工具(最常用的是Memcheck) 可以检查: 使用未初始化的内存，使用已经释放了的内存，内存访问越界等。 以上两种工具都很明显影响性能, 新版本的gcc（gcc49）提供了很好的内存访问检查机制命令行参数 -fsanitize=address -fno-omit-frame-pointer 检查内存越界的实现是..? 另外, Google的 address sanitizer（简称asan）是一个用来检测c/c++程序的快速内存检测工具。相比valgrind的优点就是速度快，官方文档介绍对程序性能的降低只有2倍。 内存泄漏排查 代码静态检查工具 Valgrind仿真 重载全局的malloc / free函数，申请和释放内存的时候打印函数和返回地址（用异步日志库） C++考虑使用shared_ptr, RAII机制来避免内存泄漏 多线程 &amp; 高并发情况下在增加debug log/ efence动态库 / 都会严重影响qps导致Core down无法重现, 另外特殊网络环境(高延迟, 丢包)下才会重现的问题 弱网络环境模拟traffic control: 能够控制网络速率、丢包率、延时等网络环境，作为iproute工具集中的一个工具，由linux系统自带 Http压测工具wrk, 类似ab 手动异常测试请求: 异常的tcp连接。即在客户端 tcp connent系统调用时，10%概率直接close这个socket。 异常的ssl连接。考虑两种情况，full handshake第一阶段时，即发送 client hello时，客户端10%概率直接close连接。full handshake第二阶段时，即发送 clientKeyExchange时，客户端 10%概率直接直接关闭 TCP连接。 异常的HTTPS请求，客户端10%的请求使用错误的公钥加密数据，这样nginx解密时肯定会失败。 使用 tcpcopy等工具在线上引流到测试机器进行压测，如果常规流量达不到重现标准，可以对流量进行放大。若线上搭建环境测试有困难，可以对线上流量抓包，然后在线下重放（tcpdump、tcpreplay和tcprewrite等工具）。这一步之后，一般情况下都能增大重现的概率。如果还难以重现，往往都是一些代码本身的竞态条件（Race Condition）造成的，一般需要在引流测试的同时对CPU或者IO加压，以增大资源竞争的概率来增加问题复现的概率。甚至有些问题是出现网络抖动等情况下，需要模拟弱网络的环境（Linux 2.6内核以上有netem模块，可以模拟低带宽、传输延迟、丢包等情况，使用tc这个工具就可以设置netem的工作模式）。 参考 Linux环境下多线程C/C++程序的内存问题调试 | 浅墨的部落格 高并发性能调试经验分享 - 腾讯WeTest 定位多线程内存越界问题实践总结 - DJ IN MUSIC - 博客园 程序性能分析@ref： Perf – Linux下的系统性能调优工具，第 1 部分 perfperf应该是最全面最方便的一个性能检测工具。由 linux内核携带并且同步更新，基本能满足日常使用。 使用 perf，您可以分析程序运行期间发生的硬件事件，比如 instructions retired ，processor clock cycles 等；您也可以分析软件事件，比如 Page Fault 和进程切换。 使用 Perf 可以计算每个时钟周期内的指令数，称为 IPC，IPC 偏低表明代码没有很好地利用 CPU。 Perf 还可以对程序进行函数级别的采样，从而了解程序的性能瓶颈究竟在哪里等等。 通过perf top就能列举出当前系统或者进程的热点事件，函数的排序。 perf record能够纪录和保存系统或者进程的性能事件，用于后面的分析，比如火焰图。 oprofile基本被perf取代 @ref: linux性能分析工具oprofile的安装与使用 » reille blog gprofgprof主要是针对应用层程序的性能分析工具，缺点是需要重新编译程序，而且对程序性能有一些影响。不支持内核层面的一些统计，优点就是应用层的函数性能统计比较精细，接近我们对日常性能的理解，比如各个函数时间的运行时间，，函数的调用次数等，很人性易读。原理是 编译期前在每个函数增加一个mcount函数调用, 用来记录函数耗时和调用次数。 systemtapsystemtap 其实是一个运行时程序或者系统信息采集框架，主要用于动态追踪，当然也能用做性能分析，功能最强大，同时使用也相对复杂。不是一个简单的工具，可以说是一门动态追踪语言。如果程序出现非常麻烦的性能问题时，推荐使用 systemtap。","categories":[{"name":"11.Programming-Language","slug":"11-Programming-Language","permalink":"https://beefyheisenberg.github.io/categories/11-Programming-Language/"}],"tags":[{"name":"指针","slug":"指针","permalink":"https://beefyheisenberg.github.io/tags/指针/"},{"name":"内存泄漏","slug":"内存泄漏","permalink":"https://beefyheisenberg.github.io/tags/内存泄漏/"}]},{"title":"Cpp Tutorials-02b-智能指针","slug":"11.Programming-Language/Cpp-Tutorials.02b.智能指针","date":"2024-01-24T01:27:52.012Z","updated":"2024-01-24T01:27:52.012Z","comments":true,"path":"11.Programming-Language/Cpp-Tutorials.02b.智能指针/","link":"","permalink":"https://beefyheisenberg.github.io/11.Programming-Language/Cpp-Tutorials.02b.智能指针/","excerpt":"C++11 中推出了三种智能指针，unique_ptr、shared_ptr 和 weak_ptr，同时也将 auto_ptr 置为废弃 (deprecated)。 unique_ptr它是一个独占型的智能指针，不允许其他的智能指针共享其内部的指针，更像原生的指针（但更为安全，能够自己释放内存）。不允许赋值和拷贝操作，只能够移动。 std::unique_ptr&lt;int&gt; ptr1(new int(0)); std::unique_ptr&lt;int&gt; ptr2 = ptr1; // 错误，不能复制 std::unique_ptr&lt;int&gt; ptr3 = std::move(ptr1); // 可以移动 在 C++14 中，对于 std::unique_ptr 引入了 std::make_unique 方法进行初始化：","text":"C++11 中推出了三种智能指针，unique_ptr、shared_ptr 和 weak_ptr，同时也将 auto_ptr 置为废弃 (deprecated)。 unique_ptr它是一个独占型的智能指针，不允许其他的智能指针共享其内部的指针，更像原生的指针（但更为安全，能够自己释放内存）。不允许赋值和拷贝操作，只能够移动。 std::unique_ptr&lt;int&gt; ptr1(new int(0)); std::unique_ptr&lt;int&gt; ptr2 = ptr1; // 错误，不能复制 std::unique_ptr&lt;int&gt; ptr3 = std::move(ptr1); // 可以移动 在 C++14 中，对于 std::unique_ptr 引入了 std::make_unique 方法进行初始化： std::unique_ptr&lt;std::string&gt; ptr = std::make_unique&lt;std::string&gt;(&quot;make_unique init!&quot;); 智能指针 unique_ptr 的实现最简单，参考 「RAII（资源获取即初始化）」，因为 C++ 的 zero cost abstraction 的特点，unique_ptr 在默认情况下和裸指针的大小是一样的。所以内存上没有任何的额外消耗，性能也是最优的 shared_ptrshared_ptr 智能指针，一个对象可以被多个 shared_ptr 管理： shared_ptr&lt;A&gt; sp1(new A(2)); //A(2)由sp1托管，shared_ptr&lt;A&gt; sp2(sp1); //A(2)同时交由sp2托管shared_ptr&lt;A&gt; sp3;sp3 = sp2; //A(2)同时交由sp3托管A * p = sp3.get(); // get返回托管的指针，p 指向 A(2)sp1.reset(new A(3)); // reset导致托管新的指针, 此时sp1托管A(3) shared_ptr 的实现：shared_ptr 对所管理的对象进行了引用计数，当新增一个 shared_ptr 对该对象进行管理时，就将该对象的引用计数加一；减少一个 shared_ptr 对该对象进行管理时，就将该对象的引用计数减一，如果该对象的引用计数为0的时候，说明没有任何指针对其管理，才调用 delete 释放其所占的内存。","categories":[{"name":"11.Programming-Language","slug":"11-Programming-Language","permalink":"https://beefyheisenberg.github.io/categories/11-Programming-Language/"}],"tags":[]},{"title":"Cpp Tutorials-02a-内存管理（深入理解 new）","slug":"11.Programming-Language/Cpp-Tutorials.02a.内存管理-new","date":"2024-01-24T01:27:52.006Z","updated":"2024-01-24T01:27:52.006Z","comments":true,"path":"11.Programming-Language/Cpp-Tutorials.02a.内存管理-new/","link":"","permalink":"https://beefyheisenberg.github.io/11.Programming-Language/Cpp-Tutorials.02a.内存管理-new/","excerpt":"使用 new &amp; delete@tldr: C++中的new, operator new, placement new: cplusplus.com :operator new can be called explicitly as a regular function, but in C++, new is an operator with a very specific behavior: An expression with the new operator, first calls function operator new (i.e., this function) with the size of its type specifier as first argument, and if this is successful, it then automatically initializes or constructs the object (if needed). Finally, the expression evaluates as a pointer to the appropriate type. new(new operator) 作用是申请内存和执行构造函数 A *a = new A();，分两步： operator new 只负责申请内存 placement new 调用构造函数","text":"使用 new &amp; delete@tldr: C++中的new, operator new, placement new: cplusplus.com :operator new can be called explicitly as a regular function, but in C++, new is an operator with a very specific behavior: An expression with the new operator, first calls function operator new (i.e., this function) with the size of its type specifier as first argument, and if this is successful, it then automatically initializes or constructs the object (if needed). Finally, the expression evaluates as a pointer to the appropriate type. new(new operator) 作用是申请内存和执行构造函数 A *a = new A();，分两步： operator new 只负责申请内存 placement new 调用构造函数 区分 new、operator new、placement new： A* pA = new A(); void *p = ::operator new(100); T* pA = new(ptr) A(); new（new operator） new(new operator): 调用 operator new 分配内存，然后调用构造函数 new 对应的删除操作是 delete operator, 与new相反，delete 调用析构函数并调用 operator delete 来释放内存 A* a = new A();delete a; 通过反汇编可以看出A* = new A会被gcc解析成operator new(sizeof(A))和A()两个步骤, delete a被解析为~A()和operator delete(a)两个步骤。 ➤ 使用 new operator 分配数组，分两种情况： 对基本类型使用： char* buf = new char[N] 它将转换为对函数 operator new 的调用 对 class 类型使用：A* ptr = new A[N] 分两个步骤： 调用 operator new[] 函数完成内存分配 在申请的空间上执行 N 次构造函数 delete operator 与上面类似，delete 与 new 配合使用，delete[] 与 new[] 配合使用 operator new operator new指对new的重载形式，它是一个函数，并不是运算符。只负责分配内存而不会调用构造, 对于operator new来说，分为全局重载和类重载: 全局重载: void* ::operator new(size_t size) 类中重载: void* A::operator new(size_t size), 注意operator new的参数是size_t, 返回是void指针 operator new()完成的操作一般只是分配内存，事实上系统默认的全局::operator new(size_t size)也只是调用malloc分配内存，并且返回一个void*指针; 对应的删除operator delete: operator delete(buf); 只删除内存空间; ➤ 如何调用 operator new： void *p = ::operator new(100); // 指定调用全局的operator new , 而不是类自己重载的版本void *p = operator new(sizeof(int)); ➤ operator new 有三种形式的函数重载： (1)throwing： void* operator new (std::size_t size) throw (std::bad_alloc); (2)nothrow： void* operator new (std::size_t size, const std::nothrow_t&amp; nothrow_value) throw(); (3)placement： void* operator new (std::size_t size, void* ptr) throw(); A* a = new A;这句代码里的new（new operator），先是调用了throwing版本的 operator new 分配内存, 然后调用构造; A* a = new(std::nothrow) A;new operator 先调用 nothrow 版本的operator new, 然后调用构造; placement版本的operator new，它也是对operator new的一个重载，定义于&lt;new&gt;中, 它多接收一个ptr参数，但它只是简单地返回ptr, 内部什么都没有做, 当使用 placement new expression 的时候会调用这个版本的operator new 重载::operator newEffective C++ 第三版第 50 条列举了定制 new/delete 的几点理由 检测代码中的内存错误 优化性能 获得内存使用的统计数据 不改变operator new的默认参数重载: 用这种方式的重载，使用方不需要包含任何特殊的头文件，也就是说不需要看见这两个函数声明。“性能优化”通常用这种方式。 void* operator new(std::size_t sz) &#123; std::printf(\"global op new called, size = %zu\\n\",sz); return std::malloc(sz);&#125;void operator delete(void* ptr) noexcept &#123; std::puts(\"global op delete called\"); std::free(ptr);&#125;int main() &#123; // 以下调用自定义的operator new/delete: int* p1 = new int; delete p1; int* p2 = new int[10]; delete[] p2;&#125; 增加新的参数的operator new, 为了跟踪内存分配的错误 void* operator new(size_t size, const char* file, int line); // 其返回的指针必须能被普通的 ::operator delete(void*) 释放void operator delete(void* p, const char* file, int line); // 这个函数只在析构函数抛异常的情况下才会被调用// new (__FILE, __LINE__)会调用构造函数吗?Foo* p = new (__FILE, __LINE__) Foo; 重载class::operator newstruct X &#123; static void* operator new(std::size_t sz)&#123; std::cout &lt;&lt; \"custom new for size \" &lt;&lt; sz &lt;&lt; '\\n'; return ::operator new(sz); &#125; static void* operator new[](std::size_t sz)&#123; std::cout &lt;&lt; \"custom new for size \" &lt;&lt; sz &lt;&lt; '\\n'; return ::operator new(sz); &#125;&#125;;int main() &#123; // 以下会调用类成员的operator new/delete X* p1 = new X; delete p1; X* p2 = new X[10]; delete[] p2;&#125; 重载时的优先顺序在使用 new运算符分配类类型的对象时（如果该类重载了operator new），将调用该类的operator new。在使用 new运算符分配内置类型的对象、未重载operator new函数的类类型的对象、任何类型的数组时，将调用全局operator new 函数。 new_handleroperator new失败, 会调用new_handler, 如果new_handler不存在则抛出一个std::bad_alloc异常,std::set_new_handler可以为当前operator new指定一个new_handler typedef void (*p_new_handler)();std::set_new_handler(p_new_handler);int* pBigDataArray = new int[1000000000000L]; 如何设计一个良好的new_handler ? 《Effective C++》建议以下几种做法(选1即可): 让更多的内存可以被使用（也就是清理内存，让出更多的空间给这里的内存分配操作） 安装另一个new_handler（当这个new_handler无法处理当前分配失败的情况时，我们可以装在另外一个new_handler试图处理这种情况） 卸载new_handler（如果当前的new_handler确实无法处理当前错误，那么就将当前的new_handler卸载，例如nullptr，让new抛出bad::alloc的异常） 直接抛出bad::alloc的异常 调用abort()或exit()直接终止程序 placement new expressionchar* ptr = new char[sizeof(T)]; // 分配内存T* tptr = new(ptr) T(\"hello\"); // 在已分配内存进行构造tptr-&gt;~T(); // 析构delete[] ptr; 第二行的new(ptr) T(&quot;hello&quot;)会调用operator new的placement形式 参考 C++ 工程实践(2)：不要重载全局 ::operator new() - CSDN博客 new 表达式 - cppreference.com operator new, operator new[] - cppreference.com new 和 delete 的内部实现new 表达式源码位置 gcc/libstdc++-v3/libsupc++/new_op.cc _GLIBCXX_WEAK_DEFINITION void *operator new (std::size_t sz) _GLIBCXX_THROW (std::bad_alloc)&#123; void *p; /* malloc (0) is unpredictable; avoid it. */ if (sz == 0) sz = 1; while (__builtin_expect ((p = malloc (sz)) == 0, false)) &#123; new_handler handler = std::get_new_handler (); if (! handler) _GLIBCXX_THROW_OR_ABORT(bad_alloc()); handler (); &#125; return p;&#125; operator new➤ 全局 operator new 和 operator delete 源码: void *__CRTDECL operator new(size_t size) _THROW1(_STD bad_alloc)&#123; // try to allocate size bytes void *p; while ((p = malloc(size)) == 0) //申请空间 if (_callnewh(size) == 0) //若申请失败则调用处理函数 &#123; // report no memory static const std::bad_alloc nomem; _RAISE(nomem); // #define _RAISE(x) ::std:: _Throw(x) 抛出nomem的异常 &#125; return (p);&#125;void operator delete(void* pUserData)&#123; _CrtMemBlockHeader* pHead; RTCCALLBACK(_RTC_Free_hook, (pUserData, 0)); if (pUserData == NULL) return; _mlock(_HEAP_LOCK); /* block other threads */ __TRY /* get a pointer to memory block header */ pHead = pHdr(pUserData); /* verify block type */ _ASSERTE(_BLOCK_TYPE_IS_VALID(pHead-&gt;nBlockUse)); _free_dbg(pUserData, pHead-&gt;nBlockUse); __FINALLY _munlock(_HEAP_LOCK); /* release other threads */ __END_TRY_FINALLY return;&#125; 可以看出 operaotr new 和 malloc 的不同：如果分配失败，前者抛异常，后者返回null；","categories":[{"name":"11.Programming-Language","slug":"11-Programming-Language","permalink":"https://beefyheisenberg.github.io/categories/11-Programming-Language/"}],"tags":[]},{"title":"Cpp Tutorials-01-基础","slug":"11.Programming-Language/Cpp-Tutorials.01.基础","date":"2024-01-24T01:27:52.001Z","updated":"2024-01-24T01:27:52.002Z","comments":true,"path":"11.Programming-Language/Cpp-Tutorials.01.基础/","link":"","permalink":"https://beefyheisenberg.github.io/11.Programming-Language/Cpp-Tutorials.01.基础/","excerpt":"类型限定符 const：表示该变量的值不能被修改 volatile：修饰符 volatile 告诉该变量的值可能会被程序以外的因素改变，如硬件或其他线程 restrict：由 restrict 修饰的指针是唯一一种访问它所指向的对象的方式。 C99 增加了新的类型限定符 restrict mutable：表示类中的成员变量可以在 const 成员函数中被修改 register：提示编译器尽可能把变量存入到CPU内部寄存器中 static： 用于声明静态变量或类的静态函数。静态变量作用范围在一个文件内，程序开始时分配空间，结束时释放空间，默认初始化为 0，使用时可改变其值； C++ 类的成员变量被声明为 static（称为静态成员变量），意味着它被该类的所有实例所共享，也就是说当某个类的实例修改了该静态成员变量，其修改值为该类的其它所有实例所见；而类的静态成员函数也只能访问静态成员（变量或函数）； extern： 当出现 extern “C”时，表示 extern “C”之后的代码按照 C 语言的规则去编译； 当 extern 修饰变量或函数时，表示其具有外部链接属性，即其既可以在本模块中使用也可以在其他模块中使用； 类访问控制 private(默认访问权限)：只能由1.该类中的函数、2.其友元函数访问。不能被任何其他访问 protected：可以被1.该类中的函数、2.子类的函数、以及3.其友元函数访问 public：可以被1.该类中的函数、2.子类的函数、3.其友元函数访问","text":"类型限定符 const：表示该变量的值不能被修改 volatile：修饰符 volatile 告诉该变量的值可能会被程序以外的因素改变，如硬件或其他线程 restrict：由 restrict 修饰的指针是唯一一种访问它所指向的对象的方式。 C99 增加了新的类型限定符 restrict mutable：表示类中的成员变量可以在 const 成员函数中被修改 register：提示编译器尽可能把变量存入到CPU内部寄存器中 static： 用于声明静态变量或类的静态函数。静态变量作用范围在一个文件内，程序开始时分配空间，结束时释放空间，默认初始化为 0，使用时可改变其值； C++ 类的成员变量被声明为 static（称为静态成员变量），意味着它被该类的所有实例所共享，也就是说当某个类的实例修改了该静态成员变量，其修改值为该类的其它所有实例所见；而类的静态成员函数也只能访问静态成员（变量或函数）； extern： 当出现 extern “C”时，表示 extern “C”之后的代码按照 C 语言的规则去编译； 当 extern 修饰变量或函数时，表示其具有外部链接属性，即其既可以在本模块中使用也可以在其他模块中使用； 类访问控制 private(默认访问权限)：只能由1.该类中的函数、2.其友元函数访问。不能被任何其他访问 protected：可以被1.该类中的函数、2.子类的函数、以及3.其友元函数访问 public：可以被1.该类中的函数、2.子类的函数、3.其友元函数访问 注：友元函数包括3种：设为友元的普通的非成员函数；设为友元的其他类的成员函数；设为友元类中的所有成员函数。 static 成员区别与C，在C++中 static 的类成员表示：属于一个类而不是属于此类的任何特定对象的变量和函数. 对于类的static成员, 该类的所有实例都共用一个static成员.比如在对某一个类的对象进行计数时, 计数生成多少个类的实例, 就可以用到静态数据成员. 注意, static成员函数必须只能调用static成员. 类实例内存占用@todo 构造函数析构函数 析构函数是一个成员函数，在对象超出范围或通过调用 delete 显式销毁对象时，会自动调用析构函数。 只有当类存储了需要释放的系统资源的句柄，或拥有其指向的内存的指针时，你才需要定义自定义析构函数。 当下列事件之一发生时，将调用析构函数： 具有块范围的本地（自动）对象超出范围。 使用 delete 显式解除分配了使用 new 运算符分配的对象。 临时对象的生存期结束。 程序结束，并且存在全局或静态对象。 使用析构函数的完全限定名显式调用了析构函数。 析构函数可以随意调用类成员函数和访问类成员数据。 析构的顺序： 按照非静态成员对象的析构函数在类声明中的显示顺序的相反顺序调用这些函数。 这些成员的构造中使用的可选成员初始化列表不会影响构造或销毁顺序。 非虚拟基类的析构函数以声明的相反顺序被调用 虚拟基类的析构函数以声明的相反顺序被调用 很少需要显式(手动的)调用析构函数。但是，对置于绝对地址的对象进行清理会很有用（这些对象通常用 placement new 创建），可能会用到手动调用析构，但注意显式析构并不能释放”类自身”占用的内存，： char* p_space = (char*)malloc( sizeof(Thing) ); // 创建内存块Thing* p_thing = new (p_space) Thing(); // 在此内存块上new实例p_thing-&gt;~Thing(); // 调用析构, 但Thing实例的内存不释放delete p_space; // 销毁了存储区, 不会调用析构函数//delete p_thing; // 这样会连同存储区p_space一起销毁, 并调用析构~Thing() @ref: https://learn.microsoft.com/zh-cn/cpp/cpp/destructors-cpp?view=msvc-170 重载C++ 允许在同一作用域中的某个函数和运算符指定多个定义，分别称为函数重载和运算符重载。 重载函数在同一个作用域内(namespace or class)内可以声明几个同名的函数, 函数的参数列表(参数个数/类型/顺序)必须不同, 不能近通过返回值区分重载函数; 重载运算符头文件: class MyString&#123;public: MyString(const char *str=NULL);//构造函数 MyString(const Mystring&amp; obj); //拷贝构造函数 MyString&amp; operator=(const Mystring &amp;obj); MyString&amp; operator+(const Mystring &amp;obj); MyString&amp; operator+=(const Mystring &amp;obj); bool operator !=(const MyString &amp;obj); bool operator &gt;(const MyString &amp;obj); bool operator &lt;(const MyString &amp;obj); friend std::ostream &amp; operator&lt;&lt;(std::ostream &amp;out, const MyString &amp;obj); friend std::istream &amp; operator&gt;&gt;(std::istream &amp;in, MyString &amp;obj);&#125;; 源文件: #include \"MyString.h\"Mystring Mystring::operator=(const Mystring &amp;obj)&#123; //分配内存空间，记得+1，因为c风格的字符串以'\\n'结尾，需要多加一个字符 this-&gt;pstr=new char[strlen(obj.pstr)+1]; strcpy(this-&gt;pstr,obj.pstr); return *this;&#125; C++如何实现重载C++ 实现函数重载很大程度上依赖与编译器对函数名的 Mangling(损坏，破坏)，即 C++ 的源代码被编译后同名的重载函数名字会被破坏，一般是在原函数名前后加上特定的字符串（g++编译器中通过在函数名后面添加参数的后缀），以区分不同重载函数，然后在调用的时候根据参数的不同选择合适的函数，如下代码说明了编译器是如何处理普通函数重载的 对于函数定义 void foo(int x, int y);该函数被 C 编译器编译后在库中的名字为_foo,而 C++编译器则会产生像_foo_int_int之类的名字用来支持函数重载和类型安全连接。 这样一来就造成问题：C和C++中对函数的生成规则是不同的，C++程序不能直接调用 C 函数。例如在C++中，调用foo的代码编译为汇编是call _foo_int_int，如果这个foo是在C库中的，那么foo的符号是_foo，在链接过程中就造成找不到这个符号报错 extern “C”在C++项目中，调用C库函数，需要在头文件声明： #ifdef __cplusplusextern &quot;C&quot; &#123;#endifvoid foo(int x, int y);#ifdef __cplusplus&#125;#endif 这就告诉 C++编译译器,函数 foo 是个 C 库的函数，那么 C++编译器应该按照 C 编译器的编译和链接规则来进行链接，也就是说到库中找名字_foo 而不是找_foo_int_int（原因是 C++支持函数的重载） 继承类的继承后方法属性变化 private 属性不能够被继承。 使用private继承，父类的protected和public属性在子类中变为private，并且不能被这个派生类的子类所访问。 使用protected继承，父类的protected和public属性在子类中变为protected，并且只能被它的派生类成员函数或友元访问，基类的私有成员仍然是私有的。 使用public继承，父类中的protected和public属性不发生改变，父类中的private不变。 多重继承 class Divide: public Base1, protected Base2 { ... }; Base类的private成员，在Divide类中是否占用空间 // yes 继承了多个基类的派生类, 有多个虚函数表, 如果派生类没有重写任何基类的virtual函数, 派生类也有虚函数表(vtable), 里面是指向基类的函数 如果派生类没有重写任何基类的virtual函数, 且派生类新建了一个virtual函数, 派生类的虚函数表(vtable)里面依次基类虚函数指针, 派生类自己的虚函数指针 虚函数 &amp; 纯虚函数虚函数的定义格式: virtual void func(param); 虚函数作用是在程序的运行阶段动态地选择合适的成员函数，在定义了虚函数后，可以在基类的派生类中对虚函数重新定义，在派生类中重新定义的函数应与虚函数具有相同的形参个数和形参类型。 如果在派生类中没有对虚函数重新定义，则它继承其基类的虚函数。 设派生类有虚函数func，派生类中也声明了func 但是没有带virtual关键字，此时 Derive::func()仍然是虚函数。 如果类声明中有virtual函数, 但没有定义函数体, 则构造过程中出错, why?因为创建类的实例时, 会初始化vtable, 如果这个类有未定义的虚函数, 则初始化vtable失败. 析构函数virtual的必要性? 如果一个类是作为基类的,那么该类的析构应该写为virtual: 这样在 delete 基类指针 时, 会自动选择相应的析构函数. 纯虚函数的定义格式: virtual void func(param)=0; 含有纯虚函数的类被称为”抽象类”（abstract class）, 无法实例化. 如果派生类没有实现纯虚函数, 也仍是抽象类.如果一个类的全部函数都是纯虚函数, 那么这个类可以声明为abstract的. 一些C++的代码策略： private的纯虚函数: 可以作为一种策略, 比如我们要实现一个抽象类, 但是不想让其他人的代码继承这个抽象类, 就可以使用这种策略. private的构造函数 &amp; 析构函数： … 友元首先,友元关系不能被继承, 即Func()函数是Base类的友元, 但对于Base类的派生Derive, 不存在友元关系;class A&#123; friend void func(); friend class B; // B类 是 A类的友元&#125; 虚函数表（vtable）类实例的前4个字节, 是”数组的首地址”, 数组的元素是”虚函数地址”, 这个数组就是虚函数表. Derive1 d;cout &lt;&lt; &quot;vtable数组首地址&quot; &lt;&lt; *(int*)(&amp;d)&lt;&lt; endl;cout &lt;&lt; &quot;第一个虚函数地址vtable[0]&quot; &lt;&lt; *((int*)(*(int*)(&amp;d))+ 0) &lt;&lt; endl;cout &lt;&lt; &quot;第二个虚函数地址vtable[1]&quot; &lt;&lt; *((int*)(*(int*)(&amp;d))+ 1) &lt;&lt; endl;typedef void (*pFunc)(void);pFunc pf;pf = (pFunc)*((int*)(*(int*)(&amp;d))+ 0);pf(); // 执行第一个vFuncpf = (pFunc)*((int*)(*(int*)(&amp;d))+ 1);pf(); // 执行第一个vFuncpFunc* vtable = (pFunc*)*(int*)(&amp;d);(vtable[0])();(vtable[1])(); 虚继承@todo 类型转换C++中几种类型转换方式： 旧风格的类型转换: C 风格（C-style）强制转型: (T) exdivssion // cast exdivssion to be of type T 函数风格（Function-style）强制转型: T(exdivssion) // cast exdivssion to be of type T static_cast: 用法static_cast &lt; type-id &gt; ( expression ), 该运算符把exdivssion转换为type-id类型，但没有运行时类型检查来保证转换的安全性。它主要有如下几种用法： 上行转换（把子类的指针或引用转换成基类表示）是安全的； 进行下行转换（把基类指针或引用转换成子类指针或引用），由于没有动态类型检查，所以是不安全的，需要开发者自己保证 static_cast 转换的结果是否安全，static_cast转换失败会导致运行时错误； 用于基本数据类型之间的转换，如把int转换成char，把int转换成enum等。得到的 char 可能没有足够的位来保存整个 int 值，这种转换的安全性也要开发人员来保证； static_cast不能转换掉expression的const、volitale、或者__unaligned属性 通常使用 static_cast 转换数值数据类型，例如将枚举型转换为整型或将整型转换为浮点型，而且你能确定参与转换的数据类型。 // static_cast 示例Base *a = new Base;Derived *b = static_cast&lt;Derived *&gt;(a);double d = 3.14159265;int i = static_cast&lt;int&gt;(d); dynamic_cast: 主要用来在继承体系中的安全向下转型。它能安全地将指向基类的指针转型为指向子类的指针或引用 为什么需要 dynamic_cast 强制转换? 当无法使用 virtual 函数的时候 如果转型失败会返回null（转型对象为指针时）或抛出异常（转型对象为引用时） dynamic_cast 会动用运行时信息（RTTI）来进行类型安全检查，因此dynamic_cast存在一定的效率损失。 基类要有虚函数，否则会编译出错；static_cast则没有这个限制。 充满风险的隐式类型转换什么是“隐式类型转换”： // 1.赋值int a = 0;long b = a + 1;// 2.比较（==,&gt;,&lt;）和switchif (a == b) &#123; // 默认的operator==需要a的类型和b相同，因此也发生转换&#125;std::shared_ptr&lt;int&gt; ptr = func();if (ptr) &#123; // 这里会从shared_ptr转换成bool // 处理数据&#125;// 3.函数传参 引用与指针相似的是，引用将存储位于内存中其他位置的对象的地址。有两种引用： 引用命名变量的 lvalue 引用：&amp; 运算符表示 lvalue 引用 引用临时对象的 rvalue 引用：&amp;&amp; 运算符表示 rvalue 引用，或通用引用（rvalue 或 lvalue），具体取决于上下文 引用很容易与指针混淆，它们之间有三个主要的不同： 不存在空引用。引用必须连接到一块合法的内存。 一旦引用被初始化为一个对象，就不能被指向到另一个对象。指针可以在任何时候指向到另一个对象。 引用必须在创建时被初始化。指针可以在任何时间被初始化。 inline String&amp; String::operator=(const String&amp; other)&#123; if (this!=&amp;other) &#123; delete[] m_data; if(!other.m_data) m_data=0; else &#123; m_data = new char[strlen(other.m_data)+1]; strcpy(m_data,other.m_data); &#125; &#125; return *this; //返回this的解&#125; C++ 设计技巧RAII资源获取即初始化（ Resource Acquisition Is Initialization ），或称 RAII。它将必须在使用前请求的资源（被分配的堆内存、执行的线程、打开的接头、打开的文件、被锁的互斥、磁盘空间、数据库连接等——任何存在于受限供给中的事物）的生命周期绑定到一个对象的生存期。 RAII 可总结如下: 将资源的操作封装入一个RAII类里: 构造函数请求资源，并建立所有类不变量或在它无法完成时抛出异常， 析构函数释放资源并决不抛出异常； 始终经由RAII类的实例使用资源，在栈上创建RAII类型的函数内变量，当函数退出时依靠”Stack winding”来保证一定调用RAII类的析构函数完成资源释放 例子1template &lt;TYPENAME T&gt;class RAII &#123; T* p_;public: explicit RAII(T* p) : p_(p) &#123;&#125; ~RAII() &#123; delete p_; &#125; T&amp; operator*() const &#123; return *p_; &#125;private: RAII(const RAII&amp; other); RAII&amp; operator=(const RAII&amp; other);&#125;;///class Example &#123; RAII&lt;SOMERESOURCE&gt; p_; RAII&lt;SOMERESOURCE&gt; p2_;public: Example() : p_(new SomeResource()), p2_(new SomeResource()) &#123;&#125; ~Example() &#123; std::cout &lt;&lt; \"Deleting Example, freeing SomeResource!/n\"; &#125;&#125;; C++中的explicit关键字只能用于修饰只有一个参数的类构造函数，它的作用是表明该构造函数是显示的，而非隐式的， 跟它相对应的另一个关键字是implicit，意思是隐藏的，类构造函数默认情况下即声明为implicit(隐式)。 问题: new Example()生成的Example实例, 如果没有调用delete(), RAII类的析构函数会被调用到吗?会，C++ 编译器会在生成代码的合适位置，插入对构造和析构函数的调用，编译器会自动调用析构函数，包括在函数执行发生异常的情况。在发生异常时对析构函数的调用，还有一个专门的术语，叫栈展开（stack unwinding）。 CPP内存管理 | Little Web 例子2错误的加锁: void bad()&#123; mutex.lock(); // 请求互斥 f(); // 若 f() 抛异常，则互斥不被释放 mutex.unlock(); // 抵达此语句，互斥才被释放&#125; 正确的方法, 使用std::lock_guard: std::mutex mutex; // 定义全局的mutexvoid good()&#123; std::lock_guard&lt;std::mutex&gt; lock(mutex); f(); // f()抛出异常, 仍然会调用到~lock_guard() 释放锁 // 运行到这里自动执行~lock_guard()&#125; 注:lock_guard是互斥封装器, 构造/析构函数定义如下: explicit lock_guard(Mutex&amp; m_): m(m_)&#123; m.lock();&#125;~lock_guard() &#123; m.unlock(); &#125; @ref: RAII - cppreference.com 【C++设计技巧】C++中的RAII机制 Pimpl这个机制是”Private Implementation”的缩写: 也即 实现私有化，力图使得头文件对改变不透明。 “实现私有化”必要性在C++中, 头文件(类的声明)和源文件(类的实现)是分开的,举个例子, 头文件base.h里声明了一个基类Base, 如果改动Base的公有接口, 会导致所有包含base.h的类(调用Base类的代码, 以及Base的派生类)都有重新编译, 在一个大工程中，这样的修改可能导致重新编译时间的激增。你可以使用Doxygen或者SciTools看看头文件依赖。改动公有接口导致的编译时间激增是可以理解的, 但是如果我们改动了Base的私有接口或者成员, 也会导致上面编译时间激增的情况, 这就有些不可接受了. 如何PimplMyClass.h 文件内容如下: class MyClassImpl; // forward declarationclass MyClass &#123;public: MyClass(); ~MyClass(); int foo();private: MyClassImpl *m_pImpl;&#125;; MyClass.cpp 文件内容如下: // 定义MyClass的函数:MyClass::MyClass() : m_pImpl(new MyClassImpl) &#123;&#125;MyClass::~MyClass() &#123; try &#123; delete m_pImpl; &#125; catch (...) &#123;&#125;&#125;int MyClass::foo() &#123; return m_pImpl-&gt;foo();&#125;// 声明并定义MyClassImplclass MyClassImpl &#123;public:int foo() &#123; return bar();&#125;int bar() &#123; return var++; &#125; int var;&#125;; 总结 Pimpl要实现的是, 在对类的私有函数/成员做改动时, 不希望(所有包含该头文件的)源文件被重新编译. 如果一个类被设计为基类，应避免在头文件中出现private函数或成员， 如果该类有private的函数或成员，最好把它们放进“前置声明（forward declaration）”的类里面，以避免private的声明出现在头文件； Java需要这种机制吗 ? 不需要, java里有interface, interface里不包含私有数据的, 所以不会有“改动上层类的私有数据导致编译量增加”这种问题. 前置声明(forward declaration)如果类A中, 有C类型的成员, 则可以在A.h中声明该成员之前, 用class C;的方式来前置声明类型C, 而不再需要在A.h中包含C.h文件: A.h头文件: // #include \"C.h\" // 不再需要这一行了class A&#123; class C; // 前置声明C C* ptr; // 成员声明&#125;; 但是使用类型的前置声明是有条件的。假设有一个类C，那么如果你的类中如果有定义类型为C的非静态成员，抑或你的类继承了C的话，就不能使用类Test的前置声明，只能用include C.h的方式大概有三种情况可以使用前置声明： 参数或返回类型为C的函数声明； 类型为C的类静态成员； 类成员变量的类型是 C类型的指针或引用: C*或 C&amp;； @ref: 【C++程序设计技巧】Pimpl机制 NVINVI（Non-Virtual Interface ）机制：将虚函数声明为非公有，而将公有函数都声明为非虚 —— 虚拟和公有选其一。 如果在基类中作为”对外接口”(public)的函数, 一定设计成非virtual的 当且仅当子类需要调用基类的虚函数时才将虚函数设置为protected NVI机制不适用于析构函数，对于析构函数，如果是public的也应该是virtual的 如果一个类是作为基类的,那么该类的析构应该写为virtual; 这样在”delete 基类指针” 时, 会自动选择相应版本的析构函数. 为什么需要NVI在标准C++库中我们可以看到这样的一个现象：6个公有虚函数，并且都是std::exception::what()和其重载。142个非公有虚函数。这样设计的目的何在呢，为什么“多此一举”的把虚函数设置为非公有呢？ 先看示例代码: class Base &#123; public: void Foo()&#123; DoFoo1(); DoFoo2(); &#125; protected: virtual void DoFoo1()&#123; cout &lt;&lt; \"Base's DoFoo1\" &lt;&lt;endl; &#125; private: virtual void DoFoo2()&#123; cout &lt;&lt; \"Base's DoFoo2\" &lt;&lt;endl; &#125; &#125;;class Derived: public Base&#123; private: virtual void DoFoo2()&#123; cout &lt;&lt; \"Derived's DoFoo2\" &lt;&lt; endl; &#125;;&#125;; 因为C++没有Interface的概念, 我们把基类里定义的 public且非虚的函数 视作”接口”, 与java中的接口不同的是, 基类的”接口”函数有自己的函数体. 一般在基类的”接口”里定义更上层的代码(参件Foo()函数), 而把具体的实现放进private/protected的虚函数, 这样做的好处是实现了接口和实现的分离; 派生类可以从基类继承的函数声明为protected virtual的; 需要派生类自己实现的函数声明为private virtual的; Pimpl和NVI都实现了：接口和实现的分离，将不经常变动的控制代码放入public非虚函数，经常变更或者需要派生类重写的放进非public的虚函数。从设计模式上来看，Pimpl用的是委托，NVI用的继承. @ref: 【C++程序设计技巧】NVI（Non-Virtual Interface ）","categories":[{"name":"11.Programming-Language","slug":"11-Programming-Language","permalink":"https://beefyheisenberg.github.io/categories/11-Programming-Language/"}],"tags":[]},{"title":"C Tutorials-02-内存管理（深入理解 malloc）","slug":"11.Programming-Language/C-Tutorials.02.内存管理-malloc","date":"2024-01-24T01:27:51.995Z","updated":"2024-01-24T01:27:51.996Z","comments":true,"path":"11.Programming-Language/C-Tutorials.02.内存管理-malloc/","link":"","permalink":"https://beefyheisenberg.github.io/11.Programming-Language/C-Tutorials.02.内存管理-malloc/","excerpt":"@tldr： 如果申请空间&lt; 128K，则尝试上推 brk 指针，（这种管理空闲内存的方式是典型的“bump-point 和 free-list” 结合的方式，JVM管理 TLAB 的方式类似）当然也不一定每次都需要上推 brk 指针，还会在 free-list 里做 first-fit 查找空闲块 如果&gt; 128K, 则直接在 mmap区（内存映射区）分配 深入理解mallocvoid *ptr = malloc(N) 之后发生了什么? 从操作系统角度来看，进程分配内存有两种方式，分别由两个系统调用完成：brk 和 mmap（不考虑共享内存）。","text":"@tldr： 如果申请空间&lt; 128K，则尝试上推 brk 指针，（这种管理空闲内存的方式是典型的“bump-point 和 free-list” 结合的方式，JVM管理 TLAB 的方式类似）当然也不一定每次都需要上推 brk 指针，还会在 free-list 里做 first-fit 查找空闲块 如果&gt; 128K, 则直接在 mmap区（内存映射区）分配 深入理解mallocvoid *ptr = malloc(N) 之后发生了什么? 从操作系统角度来看，进程分配内存有两种方式，分别由两个系统调用完成：brk 和 mmap（不考虑共享内存）。 1、do_brk() 系统调用通过调整堆中的 brk 指针大小来增加或者回收堆内存2、mmap 是在进程的虚拟地址空间中（堆和栈中间，称为文件映射区域的地方）找一块空闲的虚拟内存。 内核中使用 start_brk 标识堆的起始位置，brk 标识堆当前的结束位置。当堆申请新的内存空间时，只需要将 brk 指针增加对应的大小，回收地址时减少对应的大小即可。 // 参考 struct mm_struct 结构体的解析 这两种方式分配的都是虚拟内存，没有分配物理内存。在第一次访问已分配的虚拟地址空间的时候，发生缺页中断，操作系统负责分配物理内存，然后建立虚拟内存和物理内存之间的映射关系。 ▷ 情况 1：malloc 小于128k 的内存，会调用 do_brk() 进行分配内存，将 brk 指针往高地址推，给进程分配了 N bytes 的线性地址区域(VM) ，此时系统并没有随即分配物理内存, 进程也没有占用 N bytes 的物理内存. // 这也表明了, 你时常在使用 top 的时候 VIRT 值增大, 而 RES 值却不变的原因. 但是 do_brk() 也不一定每次都上推 brk 指针，如果在 start_brk - brk 地址之间有未使用的内存块（这些内存块可能是被 free 过了，但是页框没有被回收，参考 free），会优先使用这部分内存块； 当第一次通过指针使用此内存页, 在 RAM 中找不到与之相对应的 页框（page frame，也即物理内存）. 发生 缺页异常, 系统灵敏地捕获这一异常, 进入缺页异常处理阶段：接下来, 系统会分配一个页框映射给它, 我们把这种情况(被访问的页还没有被放在任何一个页框中, 内核分配一新的页框并适当初始化来满足调用请求) 称为 Demand Paging. 页框：对应4K大小的物理页，详见 [[01.RAM.1.内存寻址.md]] 「页帧」 过了很长一段时间, 通过 *ptr 再次引用内存第一页. 若系统在 RAM 找不到它映射的页框(可能交换至磁盘了). 也会发生缺页异常, 进入缺页异常处理：系统会分配页框(page frame), 找到备份在磁盘的那“页”, 并将它换入内存(其实因为换入操作比较昂贵, 所以预换入多页. 这也表明某些文档说：”vmstat 某时出现不少 si 并不能意味着物理内存不足”). 通过指针使用到了 N bytes 的第二页. 参见第一次访问 N bytes 第一页, “Demand Paging” 凡是类似这种会迫使进程去睡眠(很可能是由于当前磁盘数据填充至页框所花的时间), 阻塞当前进程的缺页异常处理称为主缺页(major falut), 也称为 大缺页. 相反, 不会阻塞进程的缺页, 称为次缺页(minor fault). ▷ 情况 2：malloc 函数分配内存大于128K（可由 M_MMAP_THRESHOLD 选项调节），那就不是去推 brk 指针了，而是利用 mmap 系统调用，从堆和栈的中间分配一块虚拟内存（也即内存映射区）。内存映射区即 Mapping Area : [[../21.Operating-System/APUE.03b.进程的虚拟内存管理]] ▷ free 的过程： 如果是在内存映射区分配的内存（大于 128K），指针对应的虚拟内存和物理内存一起释放； 如果是在堆区分配的内存（小于 128K），这时情况会变得不同，如果用 malloc 依次申请了 a、b、c 三块内存（这时候 brk 指针指向的是 c 的末端），如果 free(b)，这时候 b 的虚拟内存和物理内存都没有被释放，因为 c 内存块还在使用中所以无法直接移动 brk 指针，这样就产生了内存碎片。 如果这时又新 malloc 了一块内存，b 还可以重复使用，如果 b 比这次 malloc 分配的区域小，那么原来 b 区域要分裂为两块，此时还是有碎片。 在 free 的时候，发现最大地址空闲内存超过128K（可由 M_TRIM_THRESHOLD 选项调节），执行内存紧缩操作（trim） 因为 Heap 区都是小于128k 的细碎内存块, 上面的链表可以防止反复申请/释放带来的内存碎片, 但 mmap 对应的区域都是大块(大于128K)的内存, 所以不用采用上面的机制. ▷ 主缺页异常处理过程示意图,参见 Handling Page Fault, 当系统进入缺页异常流程后（do_page_fault），最终会调用 alloc_pages 申请真正的物理内存页 @link 伙伴系统 @ref: CodingLabs - 如何实现一个malloc Linux内存分配的原理–malloc/brk/mmap | VZ’s Blog","categories":[{"name":"11.Programming-Language","slug":"11-Programming-Language","permalink":"https://beefyheisenberg.github.io/categories/11-Programming-Language/"}],"tags":[]},{"title":"C Tutorials-01-基础","slug":"11.Programming-Language/C-Tutorials.01.基础","date":"2024-01-24T01:27:51.990Z","updated":"2024-01-24T01:27:51.992Z","comments":true,"path":"11.Programming-Language/C-Tutorials.01.基础/","link":"","permalink":"https://beefyheisenberg.github.io/11.Programming-Language/C-Tutorials.01.基础/","excerpt":"基本数据类型 C/C++作为一种强类型语言, 一个变量被使用前必须被定义. 在32位系统中基本类型的长度(字节): char(1B), short(2B), int(4B), 指针(4B), long(4B), float(4B), double(8B), long long(8B); 在64位系统中基本类型的长度(字节): char(1B), short(2B), int(4B), 指针(8B) long(8B), float(4B), double(8B), long long(8B); long 和 int 范围是[-2^31,2^31), 即-2147483648~2147483647. 而unsigned范围是[0,2^32), 即0~4294967295. 也就是说, 常规的32位整数只能够处理40亿以下的数. 相比于C++98标准, C++11整型的最大改变就是多了long long long long整型有两种：long long和unsigned long long. 在C++11中, 标准要求long long整型可以在不同平台上有不同的长度, 但至少有64位. 我们在写常数字面量时, 可以使用LL后缀（或是ll）标识一个long long类型的字面量, 而ULL（或ull、Ull、uLL）表示一个unsigned long long类型的字面量. 比如：unsigned long long int ulli = -9000000000000000000ULL; 对于有符号的, 下面的类型是等价的：long long、signed long long、long long int、signed long long int; 对于无符号的：unsigned long long和unsigned long long int也是等价的. 同其他的整型一样, 要了解平台上long long大小的方法就是查看&lt;climits&gt;（或&lt;limits.h&gt;中的宏）. 与long long整型相关的一共有3个：LLONG_MIN、LLONG_MAX和ULLONG_MIN, 它们分别代表了平台上最小的long long值、最大的long long值, 以及最大的unsigned long long值. #include &lt;climits&gt;int main() &#123; long long ll_min = LLONG_MIN; long long ll_max = LLONG_MAX; unsigned long long ull_max = ULLONG_MAX; // 编译选项:g++ -std=c++11 2-2-1.cpp // 在代码清单中, 将以上3个宏打印了出来, 对于printf函数来说, // 输出有符号的long long类型变量可以用符号%lld, // 无符号的unsigned long long则可以采用%llu. printf(\"min of long long: %lld\\n\", ll_min); // min of long long: -9223372036854775808 printf(\"max of long long: %lld\\n\", ll_max); // max of long long: 9223372036854775807 printf(\"max of unsigned long long: %llu\\n\", ull_max); // max of unsigned long long: 18446744073709551615&#125; @ref: 结构体对齐, 位域, 柔性数组 - DOS5GW的专栏 - CSDN博客 大小端存储","text":"基本数据类型 C/C++作为一种强类型语言, 一个变量被使用前必须被定义. 在32位系统中基本类型的长度(字节): char(1B), short(2B), int(4B), 指针(4B), long(4B), float(4B), double(8B), long long(8B); 在64位系统中基本类型的长度(字节): char(1B), short(2B), int(4B), 指针(8B) long(8B), float(4B), double(8B), long long(8B); long 和 int 范围是[-2^31,2^31), 即-2147483648~2147483647. 而unsigned范围是[0,2^32), 即0~4294967295. 也就是说, 常规的32位整数只能够处理40亿以下的数. 相比于C++98标准, C++11整型的最大改变就是多了long long long long整型有两种：long long和unsigned long long. 在C++11中, 标准要求long long整型可以在不同平台上有不同的长度, 但至少有64位. 我们在写常数字面量时, 可以使用LL后缀（或是ll）标识一个long long类型的字面量, 而ULL（或ull、Ull、uLL）表示一个unsigned long long类型的字面量. 比如：unsigned long long int ulli = -9000000000000000000ULL; 对于有符号的, 下面的类型是等价的：long long、signed long long、long long int、signed long long int; 对于无符号的：unsigned long long和unsigned long long int也是等价的. 同其他的整型一样, 要了解平台上long long大小的方法就是查看&lt;climits&gt;（或&lt;limits.h&gt;中的宏）. 与long long整型相关的一共有3个：LLONG_MIN、LLONG_MAX和ULLONG_MIN, 它们分别代表了平台上最小的long long值、最大的long long值, 以及最大的unsigned long long值. #include &lt;climits&gt;int main() &#123; long long ll_min = LLONG_MIN; long long ll_max = LLONG_MAX; unsigned long long ull_max = ULLONG_MAX; // 编译选项:g++ -std=c++11 2-2-1.cpp // 在代码清单中, 将以上3个宏打印了出来, 对于printf函数来说, // 输出有符号的long long类型变量可以用符号%lld, // 无符号的unsigned long long则可以采用%llu. printf(\"min of long long: %lld\\n\", ll_min); // min of long long: -9223372036854775808 printf(\"max of long long: %lld\\n\", ll_max); // max of long long: 9223372036854775807 printf(\"max of unsigned long long: %llu\\n\", ull_max); // max of unsigned long long: 18446744073709551615&#125; @ref: 结构体对齐, 位域, 柔性数组 - DOS5GW的专栏 - CSDN博客 大小端存储大端/小端存储（big endian/little endian）: MSB＝高权位,LSB＝低权位,比如自然数字0x1A39,1A是MSB,39是LSB,判断大小端存储,可根据数据在内存中存储的地址是以MSB/LSB为地址, 大端: LSB在高地址,MSB在低地址; 小端: MSB在高地址,LSB在低地址; 比如一个int,其LSB作为此数据的首地址(内存中的低地址),则为小端存储; 比如书写顺序0x1122,11是高字节MSB,22是低字节LSB.如果用大端存储:高地址22,低地址11;如果用小端存储:高地址11,低地址22; @ref: 大端(Big Endian)与小端(Little Endian)详解 - DOS5GW的专栏 - CSDN博客 运算符 位与&amp;, 位或|, 异或^, 取反~, 位左移&lt;&lt; , 位右移&gt;&gt; sizeof是C语言的一种单目操作符, 如C语言的其他操作符++、–等. 它并不是函数. sizeof操作符以字节形式给出了其操作数的存储大小. 操作数可以是一个表达式或括在括号内的类型名. 操作数的存储大小由操作数的类型决定. 当操作数具有数组类型时, 其结果是数组的总字节数 联合类型操作数的sizeof是其最大字节成员的字节数 sizeof的优先级为2级, 比乘除等3级运算符优先级高 编程语言中, 取余和取模的区别到底是什么？ - 知乎当除数和被除数不同符号时: 取余向0方向舍弃小数位, 取模向负无穷方向舍弃小数位, 比如4/(-3)约等于-1.3 :取余: 4 rem 3 = -1;取模: 4 mod 3 = -2; 格式化输出格式化输出printf是一个变参函数, 原型为int printf(char *format,...) ,C语言用宏来处理这些可变参数, 根据参数入栈的特点从最靠近第一个可变参数的固定参数开始, 依次获取每个可变参数的地址. 例如printf (&quot;Decimals: %d %ld\\n&quot;, 1977, 650000L);需要注意的是格式要跟变量的长度对应, 比如long long要使用%ll, int类型不能使用%c格式. extern首先,声明与定义的区别: 定义：编译器会为变量或函数分配内存 //如：int a=1; 声明：只是表明其存在，但没有分配内存这个过程。//如：int a; 带或带extern extern的两个作用: (1) extern声明 &amp; 定义变量和函数. 例如 在aaa.cpp 定义函数: void func(); 在bbb.cpp 调用该函数前需要先extern声明: extern void func(); 或者在aaa.h头文件里extern声明, 所有包含此头文件的*.cpp都可以是使用func()函数. (2) C++项目中常见的 extern &quot;C&quot;: 这就告诉 C++编译译器,函数 foo 是个 C库的函数，那么C++编译器应该按照C编译器的编译和链接规则来进行链接，也就是说到库中找名字_foo 而不是找_foo_int_int（原因是C++支持函数的重载） static(1) 当我们同时编译多个文件时，所有未加 static 前缀的全局变量和函数都具有全局可见性。如果加了 static，就会对其它源文件隐藏(其他文件无法使用)。所以static 和 extern不能同时修饰一个变量 (2) 全局变量和 static 变量存储在 静态存储区，程序启动时被初始化为0 const(1) 修饰局部 &amp; 全局常量：const int num=5; (2) 常量指针：指针指向的内容是常量，两种定义皆可：const int * num; 和 int const * num; (3) 指针常量：指针本身是个常量，不能再指向其他的地址 int *const num; (4) 修饰函数的形参： 防止修改指针指向的内容 void FUN(char *destin, const char *source); 防止修改指针指向的地址 void FUN ( int * const p1 , int * const p2); (5) 修饰函数的返回值：const char * FUN(void);char *str = FUN(); // errconst char *str = FUN(); 数组什么是数组类型? 下面是C99中原话: An array type describes a contiguously allocated nonempty set of objects with a particular member object type, called the element type.36) Array types are characterized by their element type and by the number of elements in the array. An array type is said to be derived from its element type, and if its element type is T , the array type is sometimes called ‘‘array of T ’’. The construction of an array type from an element type is called ‘‘array type derivation’’. 很显然, 数组类型也是一种数据类型, 其本质功能和其他类型无异:定义该类型的数据所占内存空间的大小以及可以对该类型数据进行的操作(及如何操作). 数组退化数组类型也是一种数据类型, 其本质功能和其他类型无异:定义该类型的数据所占内存空间的大小以及可以对该类型数据进行的操作(及如何操作).数组在某些情况下, “数组类型的变量”会退化成指针类型,这时候无法再获取数组长度, 会影响sizeof操作符的结果, 数组什么时候会”退化”数组在除了3种情况外, 其他时候都要”退化”成指向首元素的指针. 这3中例外情况是:比如有数组 char s[10] = &quot;hello&quot;; sizeof(s) &amp;s 用char s[10]作为左值创建”字符串”, s仍然是数组类型 静态数组索引(C99)下面的代码向编译器保证, 你传递给f 的指针指向一个具有至少10个int 类型元素的数组的首个元素. 我猜这也是为了优化; 例如, 编译器将会假定a 非空. 编译器还会在你尝试要将一个可以被静态确定为null的指针传入或是一个数组太小的时候发出警告. void f(int a[static 10]) &#123; ...&#125; 声明一个不可修改的数组, 这和说明符int * const a.作用是一样的 void f(int a[const]) &#123; ...&#125; 指针指针的值就是一个内存地址, 或者说,指针指向的内存区的开始地址, 指针的长度为sizeof(int)=4 (32位机), restrict关键词是一个限定词, 可以被用在指针上. 它向编译器保证, 在这个指针的生命周期内, 任何通过该指针访问的内存, 都只能被这个指针改变. 比如, int f(const int* restrict x, int* y) &#123; (*y)++; int z = *x; (*y)--; return z;&#125; 指针的类型 &amp; 指针指向的类型: 例子,说明以下指针的类型/指向的类型： int* ptr; char* ptr; int** ptr; int (*ptr)[3]; int* (*ptr)[4]; 将*号去掉, 剩下的部分即是”指针的类型”; 将”指针名字”和”指针名字左边的指针声明符*“去掉, 剩下的部分即是”指向的类型”. 指针的加减运算加减运算包括: 自++,–, 指针±数值, 指针±指针, 这些运算时, 指针数值的变化, 指针指向的变化. 自++/–: 指针±1, 指针数值±sizeof(指针类型), 指针指向下一个元素的地址; 指针±N: 指针数值±sizeof(指针类型)*N, 指针移动到后面第N个元素; 指针-指针: 两个指针相隔的元素个数, 同类型的指针才可以相减; 指针+指针: 无意义. 阅读下面的代码, 打印结果?:int a[5]=&#123;1,2,3,4,5&#125;;int *ptr1=(int *)(&amp;a+1);int *ptr2=(int *)((int )a+1);printf(&quot;%x,%x&quot;,ptr1[-1],*ptr2); 第二行: &amp;a, 数组名取地址, 相当于一个”数组指针”, 该指针的类型是int (*)[5], 指向的类型是int [5], 所以这个指针+N, 指针实际移动的字节数 = N * sizeof(int [5]), ptr1[-1]会打印出: 5 数组 &amp; 指针的不同char s[] = \"hello\";char *p = \"hello\"; 初始化的不同在第一句中,以&amp;s[0]开始的连续6个字节内存分别被赋值为: ‘h’, ‘e’, ‘l’, ‘l’, ‘o’, ‘/0’第二句中,p被初始化为程序data段的某个地址,该地址是字符串”hello”的首地址 sizeof的不同: sizeof(s)应为6, 而sizeof(p)应为一个”指针”的大小. &amp;取地址操作符的不同:&amp;s的类型为pointer to array of 6 chars.&amp;p的类型为pointer to pointer to char. 结构体 在C99之前, 你只能按顺序初始化一个结构体. 在C99中你可以这样做 struct Foo &#123; int x; int y; int z;&#125;;Foo foo = &#123;.z = 3, .x = 5&#125;; 这段代码首先初始化了foo.z,然后初始化了foo.x. foo.y 没有被初始化, 所以被置为0. 这一语法同样可以被用在数组中. 以下三行代码是等价的： int a[5] = &#123;[1] = 2, [4] = 5&#125;;int a[] = &#123;[1] = 2, [4] = 5&#125;;int a[5] = &#123;0, 2, 0, 0, 5&#125;; Struct结构体字节对齐➤ 结构体的sizeof, gcc和cl编译器有所不同, 以cl为例: 结构体变量的首地址能够被其平台的对齐字节数所整除（4字节对齐 or 8字节对齐） 结构体每个成员相对结构体首地址的偏移都是该成员大小的整数倍, 例如int成员相对结构体首地址的偏移是sizeof(int), char成员相对结构体首地址的偏移是sizeof(char). 如不满足, 会在前一个成员之后增加填充字节以满足对齐. 如果结构体成员是数组TYPE arr[3], 成员arr的首地址以sizeof(TYPE)对齐而不是sizeof(TYPE[3]). sizeof(struct)等于struct内最大基本元素长度的整数倍, 如有需要编译器会在最末一个成员之后加上填充字节（trailing padding）. 考虑一下, 为什么有第3条对齐准则？如果声明一个结构体struct sArr[2];, 这样可保证sArr[1]的首地址也满足第1条 @ref: 字节对齐，看这篇就懂了 - 腾讯云开发者社区-腾讯云 ➤ 包含结构体成员的结构体： 在寻找最宽基本类型成员时, 应当包括“子结构体”的成员; “子结构体变量”的首地址能够被其最宽基本类型成员的大小所整除; struct S1 &#123; char c; int i;&#125;; //sizeof(S1) = 8struct S3 &#123; char c1; S1 s; //8 bytes char c2&#125;; S1或S3的最宽简单成员的类型都为int, 所以S3的最宽简单类型为int;S3::s的类型是struct S1, 其起始地址是sizeof(int)的整数倍（struct S1最宽的成员是int型）;S3占用内存如下：S3:c1占1字, 填充3字, S1:c占一字, 填充3字, S1:i占4字, S3:c2占1字, 填充3字, 故sizeof(struct S3) = 16; ➤ 改变缺省的对齐条件, 即“成员相对于结构体首地址的偏移量, 是成员大小的整数倍”, 变成了“成员相对于结构体首地址的偏移量, 是对齐字节的整数倍”. VC6中使用语法如下： #pragma pack(push) // 将当前pack设置压栈保存#pragma pack(2) //按照2字节对齐struct S1&#123; char c; int i;&#125;; // 6 bytesstruct S2&#123; char c1; struct S1 sss; char c2&#125;;#pragma pack(pop) #pragma pack(n), 如果n比结构体成员的sizeof值小, 那么该成员的偏移量应该以此值为准, 结构体成员的偏移量应该取二者的最小值.上面对定义中最宽的int, 和#pragma pack(2)比较, 所以对齐条件是2字节;char S1::c占1字, int S1::i宽度是4, 这里不以4而是以2对齐, 所以int S1::i的起始位置是2, sizeof(S1) == 6.注: 没有任何成员的“空结构体”占1byte; 含位域结构体的sizeof使用位域的主要目的是压缩存储, 其大致规则为： 1) 如果相邻位域字段的类型相同, 且其位宽之和小于类型的sizeof大小, 则后面的字段将紧邻前一个字段存储, 直到不能容纳为止; 2) 如果相邻位域字段的类型相同, 但其位宽之和大于类型的sizeof大小, 则后面的字段将从新的存储单元开始, 其偏移量为其类型大小的整数倍; 3) 如果相邻的位域字段的类型不同, 则各编译器的具体实现有差异, VC6采取不压缩方式, Dev-C++采取压缩方式; 4) 如果位域字段之间穿插着非位域字段, 则不进行压缩; 5) 整个结构体的总大小为最宽基本类型成员大小的整数倍. 柔性数组(flexible array) C99中, 结构中的最后一个元素允许是未知大小的数组, 这就叫做柔性数组成员, 但结构中的柔性数组成员前面必须至少一个其他成员. 柔性数组成员允许结构中包含一个大小可变的数组. sizeof返回的这种结构大小不包括柔性数组的内存. 包含柔性数组成员的结构用malloc函数进行内存的动态分配, 并且分配的内存应该大于结构的大小, 以适应柔性数组的预期大小. 柔性数组到底如何使用呢？看下面例子： typedef struct st_type&#123; int len; char data[0];&#125;type_a; 有些编译器会报错无法编译可以改成： typedef struct st_type&#123; int len; char data[];&#125;type_a; 通过如下表达式给结构体分配内存： type_a *p = (type_a*)malloc(sizeof(type_a) + 100*sizeof(char)); 这样我们为结构体指针 p 分配了一块内存(该内存块大小远大于结构的大小).但是这时候我们再用 sizeof（*p） 或 sizeof(type_a) 测试结构体的大小, 发现仍然为 4, sizeof返回值不包括柔性数组部分.前面说过，数组名就代表一个地址，是一个不变的地址常量。在柔性数组的结构体中，数组名仅仅是一个符号而已，只代表一个偏移量，不会占用具体的空间。 我们用 p-&gt;data[n]就能简单地访问可变长元素. 对于柔性数组的这个特点，很容易构造出变成结构体，如缓冲区等等， 其实柔性数组成员在实现跳跃表时有它特别的用法，在Redis的SDS数据结构中和跳跃表的实现上，也使用柔性数组成员。它的主要用途是为了 满足需要变长度的结构体，为了解决使用数组时内存的冗余和数组的越界问题。 当然, 上面既然用 malloc函数分配了内存, 肯定就需要用 free函数来释放内存：free(p) 需要说明的是：C89不支持这种东西, C99把它作为一种特例加入了标准. 但是, C99 所支持的是 incomplete type, 而不是 zero array, 形同 int item[0];这种形式是非法的, C99支持的形式是形同 int item[];只不过有些编译器把 int item[0];作为非标准扩展来支持, 而且在C99发布之前已经有了这种非标准扩展了, C99发布之后, 有些编译器把两者合而为一了. @ref: 结构体对齐 http://blog.csdn.net/yinkaizhong/archive/2009/12/06/4951288.aspx 柔性数组 http://blog.csdn.net/yiruirui0507/archive/2010/07/22/5756328.aspx typedef➤ 用法: typedef oldType newType: typedef unsigned char BYTE; // 新定义BYTE typedef struct Language { ... } LANG; // 新定义LANG typedef void (*pf)(int, int); // 函数指针 ➤ typedef vs #define typedef仅可用于类型, define宏还可以用于数值, 例如#define 1 ONE typedef由编译器进行解释, define宏是由预编译期解释的 @ref https://www.runoob.com/cprogramming/c-typedef.html 字符串在 C语言中，字符串实际上是使用 null 字符 \\0 终止的一维字符数组。 在 string.h中提供的字符串api: strcpy(s1, s2); strcat(s1, s2); strlen(s1); strcmp(s1, s2); strchr(s1, ch); strstr(s1, s2); 函数如果函数要使用参数，则必须声明接受参数值的变量。这些变量称为函数的形式参数。形式参数就像函数内的其他局部变量，在进入函数时被创建，退出函数时被销毁。 当调用函数时，有两种向函数传递参数的方式： 传值调用：该方法把参数的实际值复制给函数的形式参数。在这种情况下，修改函数内的形式参数不会影响实际参数。 引用调用：通过指针传递方式，形参为指向实参地址的指针，当对形参的指向操作时，就相当于对实参本身进行的操作。 默认情况下，C 使用传值调用来传递参数。这意味着函数内的代码不能改变用于调用函数的实际参数。 可变参函数声明方式为： int func_name(int arg1, ...); 其中，省略号 … 表示可变参数列表。 @ref: https://www.runoob.com/cprogramming/c-variable-arguments.html 内存管理常用函数： void *malloc(int num)：用于动态分配内存。它接受一个参数，即需要分配的内存大小（以字节为单位），并返回一个指向分配内存的指针。这块内存空间在函数执行完成后不会被初始化，它们的值是未知的。malloc的实现 =&gt; [[C-Tutorials.02.内存管理-malloc.md]] void free(void *address)：用于释放先前分配的内存。它接受一个指向要释放内存的指针作为参数，并将该内存标记为未使用状态。 void *calloc(int num, int size)：用于动态分配内存，并将其初始化为零。它接受两个参数，即需要分配的内存块数和每个内存块的大小（以字节为单位），并返回一个指向分配内存（num x size 字节）的指针。 void *realloc(void *address, int newsize)：用于重新分配内存。它接受两个参数，即一个先前分配的指针和一个新的内存大小，然后尝试重新调整先前分配的内存块的大小。如果调整成功，它将返回一个指向重新分配内存的指针，否则返回一个空指针。 宏(macro)C/C++的宏定义将一个标识符定义为一个字符串, 源程序中的该标识符均以指定的字符串来代替. 宏的替换是在程序源代码被编译之前, 由预处理器（Preprocessor）对程序源代码进行的处理. 宏主要用在宏定义和条件编译. 宏定义宏常量#define MAX 1000: 在《Effective C++》中, 这种做法却并不提倡, 书中更加推荐以const常量来代替宏常量. 因为在进行词法分析时, 宏的引用已经被其实际内容替换, 因此宏名不会出现在符号表中. 所以一旦出错, 看到的将是一个无意义的数字, 比如上文中的1000, 而不是一个有意义的名称, 如上文中的MAX. 而const在符号表中会有自己的位置, 因此出错时可以看到更加有意义的错误提示. 宏函数为什么使用宏函数？ 宏只是在预编译期做展开（简单替换宏代码），并不像真正的函数需要额外的一次函数调用，也就节省了函数用的开销（传参、寄存器… ） 与inline函数的区别？ @todo #define MAX(a,b) ((a)&lt;(b) ? (b) : (a)) 为什么大量的宏定义中用到了do-while: #define FOO(x) bar(x); baz(x)// 如果这样使用宏:if (condition) FOO(1);// 会被替换成:if (condition) bar(x); baz(x); // 第二句脱离了if控制// 改进一下, 加上大括号#define FOO(x) &#123; bar(x); baz(x); &#125;// 被替换成这样:if (condition) &#123; bar(x); baz(x); &#125;; // 多了个分号, 编译错误 所以正确的写法: #define FOO(x) do &#123; bar(x); baz(x); &#125; while (0)// 如果这样使用宏:if (condition) FOO(1);// 会被替换成:if (condition) do &#123; bar(x); baz(x); &#125; while (0); do{...} while(condition)语句最后可以有分号也可以没有, 这两种语法上都正确 宏定义中的”#”和”##”#的功能是将其后面的宏参数进行字符串化操作（Stringfication）： #define DEBUG_RUN(func)do &#123; printf(\"entry:\"#func\"\\n\"); func(); &#125; while(0) #func替换后, 作为字符串拼接, 相当于printf(&quot;entry:&quot; + funcName + &quot;\\n&quot;) ##被称为连接符（concatenator）, 用来将两个Token连接为一个Token. struct command&#123; char * name; void (*function) (void);&#125;;#define COMMAND(NAME) &#123; NAME, NAME ## _command &#125;// 然后你就用一些预先定义好的命令来方便的初始化一个command结构的数组了：struct command cmds[] = &#123;COMMAND(quit),COMMAND(help),&#125; 可变参数的宏@todo 预处理器 &amp; 条件编译C 预处理器不是编译器的组成部分，但是它是编译过程中一个单独的步骤。简言之，C 预处理器只不过是一个文本替换工具而已，它们会指示编译器在实际编译之前完成所需的预处理。我们将把 C 预处理器（C Preprocessor）简写为 CPP。 所有的预处理器命令都是以井号（#）开头。它必须是第一个非空字符，为了增强可读性，预处理器指令应从第一列开始。下面列出了所有重要的预处理器指令： #define 定义宏 #include 包含一个源代码文件 #ifdef 如果宏已经定义，则返回真 #ifndef 如果宏没有定义，则返回真 #error 当遇到标准错误时，输出错误消息 #pragma 使用标准化方法，向编译器发布特殊的命令到编译器中 … 条件编译 #define常与#ifdef, #ifndef, defined指令配合使用, 用于条件编译. #ifndef _HEADER_INC_#define _HEADER_INC_#endif 用宏控制debug日志: #ifdef DEBUGprintf(\"Debug information\\n\");#endif 通过DEBUG宏, 我们可以在代码调试的过程中输出辅助调试的信息. 当DEBUG宏被删除时, 这些输出的语句就不会被编译. 更重要的是, 这个宏可以通过编译参数来定义. 因此通过改变编译参数, 就可以方便的添加和取消这个宏的定义, 从而改变代码条件编译的结果. 预定义宏#include &lt;stdio.h&gt;main()&#123; printf(\"File :%s\\n\", __FILE__ ); printf(\"Date :%s\\n\", __DATE__ ); printf(\"Time :%s\\n\", __TIME__ ); printf(\"Line :%d\\n\", __LINE__ ); printf(\"ANSI :%d\\n\", __STDC__ );&#125; 博客旧文章 C语言里面的一些陷阱 | 扔掉笔记 ᐛ C语言的编译与链接 - gcc,ld,ar等工具的介绍 | 扔掉笔记 ᐛ GNU的obj分析工具的使用 - nm,objdump | 扔掉笔记 ᐛ","categories":[{"name":"11.Programming-Language","slug":"11-Programming-Language","permalink":"https://beefyheisenberg.github.io/categories/11-Programming-Language/"}],"tags":[]},{"title":"Objective-C Tutorials","slug":"11.Programming-Language/06.ObjectiveC-Tutorials","date":"2024-01-24T01:27:51.986Z","updated":"2024-01-24T01:27:51.987Z","comments":true,"path":"11.Programming-Language/06.ObjectiveC-Tutorials/","link":"","permalink":"https://beefyheisenberg.github.io/11.Programming-Language/06.ObjectiveC-Tutorials/","excerpt":"h文件#import \"AnyHeaderFile.h\"@interface ClassName : SuperClass&#123; @property int x; // @property属性成员, m文件不用自己写getter 和 setter @property (nonatomic, assign) int commentTimeFontSize;&#125;// 公有方法+ (void) getInstance; // 静态方法- (type)doItWithA:(type)a;- (type)doItWithA:(type)a ParamB:(type)b ParamC:(type)c;@end m文件#import \"YourClassName.h\"@interface ClassName () // m文件里也可以定义interface@end@implementation ClassName &#123; // define private instance variables&#125;// implement methods@end 对象","text":"h文件#import \"AnyHeaderFile.h\"@interface ClassName : SuperClass&#123; @property int x; // @property属性成员, m文件不用自己写getter 和 setter @property (nonatomic, assign) int commentTimeFontSize;&#125;// 公有方法+ (void) getInstance; // 静态方法- (type)doItWithA:(type)a;- (type)doItWithA:(type)a ParamB:(type)b ParamC:(type)c;@end m文件#import \"YourClassName.h\"@interface ClassName () // m文件里也可以定义interface@end@implementation ClassName &#123; // define private instance variables&#125;// implement methods@end 对象// 实例化ClassName * myObject =[[ClassName alloc] init]; // init可以认作是构造函数// 方法调用[myObject doIt];[myObject doItWithA:a];[myObject doItWithA:a ParamB:b];// 属性 @property[myObject setPropertyName:a];myObject.propertyName = a; // alta = [myObject propertyName];a = myObject.propertyName; // alt NSStringNSString *personOne = @\"Ray\";NSString *personTwo = @\"Shawn\";NSString *combinedString = [NSString stringWithFormat:@\"%@: Hello, %@!\", personOne, personTwo];NSLog(@\"%@\", combinedString);NSString *tipString = @\"24.99\";float tipFloat = [tipString floatValue]; NSArrayNSMutableArray *array = [@[person1, person2] mutableCopy];[array addObject:@\"Waldo\"];NSLog(@\"%d items!\", [array count]);for (NSString *person in array) &#123; NSLog(@\"Person: %@\", person);&#125;NSString *waldo = array[2]; Block语法// 定义一个代码块^&#123; NSLog(@\"This is a block\");&#125; 如何使用: void (^simpleBlock)(void); // 相当于函数指针simpleBlock = ^&#123; NSLog(@\"This is a block\");&#125;; 参考 Objective-C Cheat Sheet and Quick Reference","categories":[{"name":"11.Programming-Language","slug":"11-Programming-Language","permalink":"https://beefyheisenberg.github.io/categories/11-Programming-Language/"}],"tags":[{"name":"编程语言快速入门","slug":"编程语言快速入门","permalink":"https://beefyheisenberg.github.io/tags/编程语言快速入门/"},{"name":"Objective-C","slug":"Objective-C","permalink":"https://beefyheisenberg.github.io/tags/Objective-C/"}]},{"title":"响应式编程","slug":"11.Programming-Language/05.响应式编程","date":"2024-01-24T01:27:51.979Z","updated":"2024-01-24T01:27:51.980Z","comments":true,"path":"11.Programming-Language/05.响应式编程/","link":"","permalink":"https://beefyheisenberg.github.io/11.Programming-Language/05.响应式编程/","excerpt":"什么是响应式编程响应式编程或反应式编程（英语：Reactive programming）是一种面向数据流和变化传播的编程范式。这意味着可以在编程语言中很方便地表达静态或动态的数据流，而相关的计算模型会自动将变化的值通过数据流进行传播。例如，在命令式编程环境中， a:=b+c表示将表达式的结果赋给 a，而之后改变 b或 c的值不会影响 a。但在响应式编程中， a的值会随着 b或 c的更新而更新。 响应式编程最初是为了简化交互式用户界面的创建和实时系统动画的绘制而提出来的一种方法，但它本质上是一种通用的编程范式。例如，在MVC软件架构中，响应式编程允许将相关模型的变化自动反映到视图上，反之亦然。 响应式编程的三种模型: Actor模型, 实现类库: AKKA Actor: Actor模型为编写并发和分布式系统提供了一种更高的抽象级别。它将开发人员从显式地处理锁和线程管理的工作中解脱出来，使编写并发和并行系统更加容易。 响应式扩展(reactive extensions, Rx)模型, 实现类库: RxJava: Reactive Extensions for Java Reactor: Reactor是Pivotal发布的第四代响应式框架，跟RxJava 2有些相似。 Spring WebFlux 以Reactor为基础，实现Web领域的反应式编程框架。 函数响应式编程(functional reactive programming, FRP)模型","text":"什么是响应式编程响应式编程或反应式编程（英语：Reactive programming）是一种面向数据流和变化传播的编程范式。这意味着可以在编程语言中很方便地表达静态或动态的数据流，而相关的计算模型会自动将变化的值通过数据流进行传播。例如，在命令式编程环境中， a:=b+c表示将表达式的结果赋给 a，而之后改变 b或 c的值不会影响 a。但在响应式编程中， a的值会随着 b或 c的更新而更新。 响应式编程最初是为了简化交互式用户界面的创建和实时系统动画的绘制而提出来的一种方法，但它本质上是一种通用的编程范式。例如，在MVC软件架构中，响应式编程允许将相关模型的变化自动反映到视图上，反之亦然。 响应式编程的三种模型: Actor模型, 实现类库: AKKA Actor: Actor模型为编写并发和分布式系统提供了一种更高的抽象级别。它将开发人员从显式地处理锁和线程管理的工作中解脱出来，使编写并发和并行系统更加容易。 响应式扩展(reactive extensions, Rx)模型, 实现类库: RxJava: Reactive Extensions for Java Reactor: Reactor是Pivotal发布的第四代响应式框架，跟RxJava 2有些相似。 Spring WebFlux 以Reactor为基础，实现Web领域的反应式编程框架。 函数响应式编程(functional reactive programming, FRP)模型 @ref 响应式编程 - 维基百科 附: 常用编程范式 声明式: 响应式 函数式 命令式: 过程式 面向对象 元编程 响应式系统模型Actor模型Actor模型=数据+行为+消息。Actor模型内部的状态由自己的行为维护，外部线程不能直接调用对象的行为，必须通过消息才能激发行为，这样就保证Actor内部数据只有被自己修改。Actor是一个个独立的实体，他们之间是毫无关联的。但是，他们可以通过消息来通信。一个Actor收到其他Actor的信息后，它可以根据需要作出各种相应。Actor的常见应用模式是处理大规模并发输入流：将具体工作分类给异步的工作节点，之后返回工作节点计算的结果。Actor模型实际上并不是纯正的函数式编程模型。Receive方法返回Unit类型，这意味着在该方法中，所有事情都是通过副作用完成的。再者，只要需要，Actor模型便会允许使用可变状态，但这里要遵守一个规则，将状态封装在某个actor中，并确保所有状态的响应操作是线程安全的。综上，Actor模型是处理大规模、高度可用、事件驱动应用程序的更为通用的方法。 函数响应式编程（functional reactive programming，FRP）在函数响应式编程模型中，基于时间的状态需要通过某一系统传播到需要使用这些状态的代码中。当FRP模型中的某一状态发生变化时，你并不需要手动地对依赖这些变化的变量进行更新，与之相反，FRP会使用声明的方式描述数据元素之间的依赖关系，而FRP运行时则会负责状态的传播。因此，用户使用函数式声明语句和组合语法编写代码。 FRP基本上就是面向异步事件流的编程了，这个异步事件流（Stream）是一个按时间排序的事件序列。Stream是不可变的，任何操作都返回新的Stream，且它是一个Monad。 响应式扩展（reactive extensions，Rx）Reactive Extension 这个概念最早出现在.net社区的Rx.net，一个提供处理异步事件的程序库，其核心概念是Observable，表示有限或者无限多个现在或者将来到达的事件。Observable提供了onNext，onError，onCompleted供开发者定制新元素到达，出现错误，或者流结束时的程序的行为。并提供了List上类似的操作，如map，filter，reduce，大大降低了异步事件编程的复杂度。因为这些概念是如此的强大，以至于很多编程语言，如java，ruby，javascript很快就有了各自的reactvie extension。 Rx模型中的可观察序列代表事件流或其他数据源。通过将可观察序列与LINQ（language-integrated query，语言集成查询）库提供的查询操作符（组合器）拼接起来，Rx组成了异步程序。 RxJava ( Reactive Extension for Java ) ，Reactive可以翻译为响应式、反应式。ReactiveX是Reactive Extensions的缩写，一般简写为Rx，最初是LINQ的一个扩展，由微软的架构师Erik Meijer领导的团队开发，在2012年11月开源，Rx是一个编程模型，目标是提供一致的编程接口，帮助开发者更方便的处理异步数据流，Rx库支持.NET、JavaScript和C++，现在已经支持几乎全部的流行编程语言，Rx的大部分语言库由ReactiveX这个组织负责维护，比较流行的有RxJava/RxJS/Rx.NET，社区网站是reactivex.io。RxJava是由Netflix主导做出的提供在JVM上实现Reactive Programming 的一种方式。同类的库还有Project Reactor, Akka 和Google 的 Agera等等。 Reactive Streams Java 9 新特性：Reactive Streams（响应式流）是一个使用非阻塞back pressure（背压机制）的异步流处理标准。在java.util.concurrent包中提供 Java 9 揭秘（17. Reactive Streams） Reactor Reactor是Pivotal发布的第四代响应式框架，跟RxJava 2有些相似。 Spring WebFlux 以Reactor为基础，实现Web领域的反应式编程框架。 使用 Reactor 进行反应式编程 RxJava Reactive Extensions for Java RXJava实例解析 RxJava 2.0发布：支持响应式流规范 Akka Actor模型为编写并发和分布式系统提供了一种更高的抽象级别。它将开发人员从显式地处理锁和线程管理的工作中解脱出来，使编写并发和并行系统更加容易。 漫谈并发编程：Actor模型 - 简书 Actor模型原理 - MOBIN - 博客园 Vert.x Java 异步非阻塞编程框架，底层基于Netty异步通信。Vert.x本身是事件驱动、非阻塞纯异步IO模型，这意味着可以使用很少的线程处理大量并发请求。 Vert.x 线程模型揭秘 | 鸟窝","categories":[{"name":"11.Programming-Language","slug":"11-Programming-Language","permalink":"https://beefyheisenberg.github.io/categories/11-Programming-Language/"}],"tags":[{"name":"编程语言快速入门","slug":"编程语言快速入门","permalink":"https://beefyheisenberg.github.io/tags/编程语言快速入门/"},{"name":"响应式编程","slug":"响应式编程","permalink":"https://beefyheisenberg.github.io/tags/响应式编程/"},{"name":"Reactive","slug":"Reactive","permalink":"https://beefyheisenberg.github.io/tags/Reactive/"},{"name":"Actor","slug":"Actor","permalink":"https://beefyheisenberg.github.io/tags/Actor/"},{"name":"RxJava","slug":"RxJava","permalink":"https://beefyheisenberg.github.io/tags/RxJava/"},{"name":"Akka","slug":"Akka","permalink":"https://beefyheisenberg.github.io/tags/Akka/"}]},{"title":"Shell Script Tutorials","slug":"11.Programming-Language/04.Shell-Tutorials","date":"2024-01-24T01:27:51.973Z","updated":"2024-01-24T01:27:51.974Z","comments":true,"path":"11.Programming-Language/04.Shell-Tutorials/","link":"","permalink":"https://beefyheisenberg.github.io/11.Programming-Language/04.Shell-Tutorials/","excerpt":"Shell 简介Shell是用户和 Linux操作系统之间的接口, 也可以看作是命令行的解释器.常见的 Shell Script解释器有: sh: 即 Bourne shell，POSIX（Portable Operating System Interface）标准的shell解释器，它的二进制文件路径通常是/bin/sh，由Bell Labs开发。 bash: Bash是Bourne shell的替代品，属GNU Project，二进制文件路径通常是/bin/bash。 zsh: zsh是由Paul Falstad于1990年创建的，它是一个Bourne风格的shell，它包含了bash中的功能，甚至更多。 例如，zsh具有拼写检查功能，可以监视登录/注销，某些内置编程功能（如字节码），支持语法中的科学计数，允许浮点运算和更多功能。 Shell 脚本文件开头一般会声明用哪种脚本解释器: #!/bin/bash","text":"Shell 简介Shell是用户和 Linux操作系统之间的接口, 也可以看作是命令行的解释器.常见的 Shell Script解释器有: sh: 即 Bourne shell，POSIX（Portable Operating System Interface）标准的shell解释器，它的二进制文件路径通常是/bin/sh，由Bell Labs开发。 bash: Bash是Bourne shell的替代品，属GNU Project，二进制文件路径通常是/bin/bash。 zsh: zsh是由Paul Falstad于1990年创建的，它是一个Bourne风格的shell，它包含了bash中的功能，甚至更多。 例如，zsh具有拼写检查功能，可以监视登录/注销，某些内置编程功能（如字节码），支持语法中的科学计数，允许浮点运算和更多功能。 Shell 脚本文件开头一般会声明用哪种脚本解释器: #!/bin/bash 如何切换Shell切换到 zsh: chsh -s /bin/zsh 切换到 bash: chsh -s /bin/bash 变量, 数据类型 变量定义: var=value注意等号两边没有空格,推荐用双引号把右值引用起来 调用已经定义的变量$var或${var}; declare的使用点这里. Shell提供语法检测变量是否赋值: ${var:-value} : 如果var存在且非空, 整个表达式的值是var; 如果var为空或者未定义, 表达式的值是value; ${var:=value} : 如果var存在且非空, 整个表达式的值是var; 如果var为空或者未定义, 表达式的值是value, 并且给var赋值; ${var:+mesg} : 测试var, 如果var存在且非空，则${var:+mesg}的返回值为mesg;如果var为空或未定义，则返回null 如果是把一个命令的结果赋值给某变量: var=`date`#或者var=$(date) 内置变量 HOME, PS1, 等等 $0: 脚本自身的名称 $1 ~ $n : 每个参数, 例如$1是第一个参数 $＃: 所有参数的数量 $* : 所有参数的组成的字符串,比如命令test.sh param1 param2, 其$*的值是”param1 param2”; $@: 所有参数, 和上面不同的是: $@是由多个子字符串组成的, $@的内容是”param1”, “param2” 这两个字符串; $?: 上个命令退出状态码, 0表示成功 $$: 当前Shell进程的PID $!: Shell最后运行的后台Process的PID 数值计算var1=$((1 + 3))var2=$((var1 + 1)) ## 注意var1前没有var3=`expr $var2 + 1` 数组 @和*可以获取数组所有元素: ${my_array[*]} , ${my_array[@]} 数组长度: ${＃array[*]}, ＃号在shell里表示长度 arr1[0]=\"cy\"arr1[1]=\"kz\"arr1=(java,php,python) # 此时[0]和[1]都被覆盖了# 遍历数组echo $&#123;arr1[*]&#125; # 以一个字符串打印所有元素echo $&#123;arr1[@]&#125; # 每个元素作为一个字符串echo $&#123;＃arr1[*]&#125; # 数组元素个数, 卧槽,,, 这语法# 清空unset arr1[0] # 仅清空一个元素unset arr1[*] # 清空所有 字符串 定义: str=&quot;hello&quot; 拼接: str=$str&quot;world&quot; 字符串长度: ${＃str} 替换: ${源字符串/查找字串/替换字串} : 一个’/‘表示替换第一个’//‘表示替换所有，当查找出中出现了：”/“需要转义成”\\/“ 常用的字符串替换: arr=(${string//,/ }) 可以实现把逗号分隔的字符串转成数组 字符串续行shell字符串续行符 “\\”，来把一行长字符串分解成多行： # Example1: echo将输出一行 \"continuation lines\"echo \"continuation \\ lines\"# Example2: 把一条长命令写为多行commannd1 arg1 arg2 \\arg3 arg4# Example3: 定义一个字符串, 写为多行, 但字符串里不包括换行符var=\"this is \\continuation\" 常用类型比较包括文件/字符串/数字比较 文件比较 -e filename 如果 filename 存在，则为真 -d filename 如果 filename 为目录，则为真 -f filename 如果 filename 为常规文件，则为真 -L filename 如果 filename 为符号链接，则为真 Example: if [ ! -f /tmp/foo.txt ]; then echo \"File not found!\"fi 字符串比较 -z string 如果 string 长度为零，则为真 -n string 如果 string 长度非零，则为真 string1 = string2 如果 string1 与 string2 相同，则为真 string1 != string2 如果 string1 与 string2 不同，则为真 &quot;$str&quot; == &quot;This&#39;s String&quot; 变量比较字符串 &quot;$sub&quot; =~ &quot; $string &quot; 变量$sub是否包含在字符串$string里, 注意两个空格 判断字符串是空串: if [ \"$str\" == \"\" ];then echo NULLfi 数字比较 num1 -eq num2 数字比较, 等于则为真 num1 -ne num2 数字比较, 不等于则为真 num1 -lt num2 小于 num1 -gt num2 大于 num1 -ge num2 大于或等于 Shell Scripts中的符号总结井号#井号: 求长度 字符串的长度: ${＃string} 数组的长度: ${＃array[*]} 大中小括号 ()小括号, 三种用途 命令组: (cmd1; cmd2)括号中的命令将会新开一个子shell顺序执行，所以括号中的变量不能够被括号外的命令使用。括号中多个命令之间用分号隔开，最后一个命令可以没有分号，各命令和括号之间不必有空格。 命令替换: $(cmd) 等同于 `cmd`，原理是 shell先扫描一遍命令行，发现了该行里有$(cmd)结构，便将$(cmd)中的cmd执行一次，得到其标准输出，再将此输出放到原来命令。例如 airportd_pid=$(ps -ef | grep airportd | grep -v grep | awk &#39;{print $2}&#39;) 定义数组: array=(a b c d) $(())双小括号: 数值计算, 不支持浮点型。例如 $((exp))结构扩展并计算一个算术表达式的值，如果表达式的结果为0，那么返回的退出状态码为1（false），而一个非零值的表达式所返回的退出状态码将为0（true）。若是逻辑判断，表达式exp为真则为1,假则为0。 # 例1:echo $(( groupnum*100 ))# 例2: 数值与运算符可以没有空格,变量的使用时也可以不使用$numwhile ((num&lt;100))do echo \"$num\" ((num=num*2))done []中括号: 见”if-then-else” [[ ]]双中括号: 可以视作[]的升级版版, 对字符串提供了高级特性, 比如支持正则: if [[ $var != &quot;x*&quot; ]] {}花括号: 变量替换, 例如 ${var} 反引号反引号用于命令替换, 同上面的$(cmd), 例如: count=`echo $var | sed &#39;s/^-//&#39;` 这行命令截去var前置的负号 控制流程和语句顺序执行 cmd1 ; cmd2 : 命令顺序执行，命令之间不存在关系，互不影响 cmd1 &amp;&amp; cmd2 : cmd1返回0(成功)那么才执行cmd2 cmd1 || cmd2 : cmd1返回非0(不成功)那么才执行cmd2 grouping commands(cmd1; cmd2)(cmd1; cmd2)：注意cmd2后面没有分号，() 将command group置于sub-shell(子shell) 中去执行，也称 nested sub-shell。括号内对环境变量的修改，不会影响括号外面。 {cmd1; cmd2;}{cmd1; cmd2;}：注意最后一个语句后有分号，{} 则是在同一个shell内完成，也称 non-named command group。Shell的函数跟 non-named command group 是类似的，每个命令之间可以用分号或者换行符隔开。 if-then-else [ 和]前后都要有空格, if与[之间也需要有空格(好操蛋的语法): if [ -d /root/fff ]; then do_somethingelif [ $timeofday = \"no\" ]; then do_something2else do_something3fi if [ $a == &quot;true&quot; ]; then 中的then可以写在第二行, 下面的语法也是正确的: if [ status ]then do_somethingelse do_something2fi 多重条件if判断: if [ \"$bool1\" == true ] || [ \"$bool1\" == true ] &amp;&amp; [ \"$bool1\" != true ]; then echo 7; fi #1, no output, due to &amp;&amp; IS NOT higher precedence than ||if [ \"$bool1\" == true ] || &#123; [ \"$bool1\" == true ] &amp;&amp; [ \"$bool1\" != true ] ;&#125;; then echo 7; fi #not same like #1if &#123; [ \"$bool1\" == true ] || [ \"$bool1\" == true ] ;&#125; &amp;&amp; [ \"$bool1\" != true ]; then echo 7; fi #same like #1if [[ \"$bool1\" == true || \"$bool1\" == true &amp;&amp; \"$bool1\" != true ]]; then echo 7; fi #1 #print 7, due to &amp;&amp; higher precedence than ||if [[ \"$bool1\" == true ]] || &#123; \"$bool1\" == true &amp;&amp; \"$bool1\" != true ;&#125;; then echo 7; fi #same like #1if &#123; \"$bool1\" == true ]] || \"$bool1\" == true ;&#125; &amp;&amp; [[ \"$bool1\" != true ]] ; then echo 7; fi #not same like #1 if in one lineif [status]; then do_something; else do_something; fi for-do-donefor var in 1 2 3; do echo $vardone# 也可以写for var in 1 2 3do echo $vardone# 对ls返回的内容循环for f in $(ls); do echo \"$f\"done# 或for f in *; do echo \"$f\"done# 循环所有子目录for dir in */; do echo \"$dir\"done# 对一个文件每行循环cat file | while read line; do echo $line;done# 对一个数组循环array=(1 2 3)for var in $&#123;array[@]&#125;; do&#123; echo $var&#125; &amp; ## 并行执行done for in one line循环语句写为一行: for var in a b c; do echo $var; done while注意中括号[前后的空格: $i=0while [ $i -lt 5 ]do do_somethingdone switchcase $var instring1) # do_something ;;string2) # do_something ;;*) echo \"default\" exit 1 ;;esac 函数shell中的函数都不带参数, 在函数内用$1…$2作为参数 doSomething() &#123; echo \"hello\"&#125;# 调用doSomething param1 param2 # 没有分号! 重定向 详见: [[../21.Operating-System/Linux.01.常用命令行#命令重定向]] Example: command &gt; outfile 2&gt;&amp;1 &amp; command &lt; infile &gt; outfile Here document:wc -l &lt;&lt; EOF hello worldEOF Learn Shell in Y Minutes【Learn Shell in Y Minutes】 是一个很有意思的项目, 用一段简单的代码介绍 Shell中的各种语法,地址: Learn X in Y Minutes: Scenic Programming Language Tours # 定义数组# 变量定义,=号前后都不能有空格, 这奇葩语法规则...hosts=(10.10.2.58:8080 10.10.2.58:8090 10.10.50.71:8080)# 访问数组全部echo $&#123;hosts[@]&#125; &gt; testecho $&#123;hosts[*]&#125;&gt;&gt; test# 命令给变量赋值line=`cat test | sed \"s/ /\\n/g\" | wc -l`# 这是另一种:line=$(cat test | sed \"s/ /\\n/g\" | wc -l)# if, 中括号[]前后要有空格if [ $line -gt 0 ]then echo 'line='$linefi# whilei=0while [ $i -lt $line ]do echo $&#123;hosts[$i]&#125; i=$((i+1)) # i=`expr $i+1` # i=$(expr $i+1)donefor host in $&#123;hosts[@]&#125;do ip=`echo $host | cut -d : -f 1` port=`echo $host | cut -d : -f 2` echo $ip $portdone","categories":[{"name":"11.Programming-Language","slug":"11-Programming-Language","permalink":"https://beefyheisenberg.github.io/categories/11-Programming-Language/"}],"tags":[{"name":"编程语言快速入门","slug":"编程语言快速入门","permalink":"https://beefyheisenberg.github.io/tags/编程语言快速入门/"},{"name":"Linux","slug":"Linux","permalink":"https://beefyheisenberg.github.io/tags/Linux/"},{"name":"Bash","slug":"Bash","permalink":"https://beefyheisenberg.github.io/tags/Bash/"},{"name":"Shell","slug":"Shell","permalink":"https://beefyheisenberg.github.io/tags/Shell/"},{"name":"命令行","slug":"命令行","permalink":"https://beefyheisenberg.github.io/tags/命令行/"}]},{"title":"PHP Tutorials","slug":"11.Programming-Language/03.PHP-Tutorials","date":"2024-01-24T01:27:51.963Z","updated":"2024-01-24T01:27:51.965Z","comments":true,"path":"11.Programming-Language/03.PHP-Tutorials/","link":"","permalink":"https://beefyheisenberg.github.io/11.Programming-Language/03.PHP-Tutorials/","excerpt":"变量引用 $ref =&amp; $a : $ref是一个引用, ‘ref’会被增加到符号表, 但不会新建一个zval, 而是$ref和$a指向同一个zval, zval::is_ref变为1, zval::refcount变为2 在函数内引用全局变量: $var1 = \"hello world\";$var2 = \"\";function f()&#123; // 相当于$var1 =&amp; GLOBALS['var1'], 函数内新建一个本地的引用$var1指向全局变量 global $var1,$var2; $var2 =&amp; var1; // 本地的引用$var2重新被指向&#125;f();var_dump($var2); // var2仍然是空字串 下面的代码不会改变$bar的值: function f(&amp;ref) &#123; // 新建本地引用变量$ref, 指向$bar $ref =&amp; GLOBALS['xxx']; // $ref被重新指向&#125;f($bar);","text":"变量引用 $ref =&amp; $a : $ref是一个引用, ‘ref’会被增加到符号表, 但不会新建一个zval, 而是$ref和$a指向同一个zval, zval::is_ref变为1, zval::refcount变为2 在函数内引用全局变量: $var1 = \"hello world\";$var2 = \"\";function f()&#123; // 相当于$var1 =&amp; GLOBALS['var1'], 函数内新建一个本地的引用$var1指向全局变量 global $var1,$var2; $var2 =&amp; var1; // 本地的引用$var2重新被指向&#125;f();var_dump($var2); // var2仍然是空字串 下面的代码不会改变$bar的值: function f(&amp;ref) &#123; // 新建本地引用变量$ref, 指向$bar $ref =&amp; GLOBALS['xxx']; // $ref被重新指向&#125;f($bar); unset一个引用, 只是断开了引用和实际变量的连接(php manual原话, 实际做了两件事情: 1从符号表删除这个引用变量的名字,2引用指向的zval的引用计数-1,当引用计数变为0时, zbal::is_ref也变为0), 引用指向的实际变量并不被销毁: function f()&#123; global $var; // 相当于$var &amp; = $GLOBALS['var'] unset $var;&#125;// 这里的$var不受影响 引用计数: zval结构和引用计数 对一个变量$a使用unset, refcount会减1, $a = \"old string\"; // 符号表里新增一个'a', 内存新建一个zval结构, 此时zal::is_ref是0,引用计数是1$c = $b = $a; // 符号表新增b和c, 但为了效率没有给b和c新建zval, 而是指向同一个zvalxdebug_debug_zval( 'a' ); // a符号对应的zval的引用计数=3, is_ref变成1$c = \"new string\"; // 发生写时复制, 这时候才给c新建一个zvalxdebug_debug_zval( 'a' ); // a引用计数=2xdebug_debug_zval( 'c' ); // c是一个新的zval,c引用计数为1unset( $b, $c ); // 从符号表删除b和c, b和c指向的zval各自引用计数-1, 当引用计数减为1时is_ref变为0, 当引用计数减为0时被gcxdebug_debug_zval( 'a' ); // 计数=1xdebug_debug_zval( 'c' ); // 已从符号表删除 变量与常量 在函数内调用全局变量时需要用global关键字声明: global $x,$y; , 注意这里的global是声明而不是定义. 全局变量: 在函数内global $a 和$GLOBALS[&#39;a&#39;]的区别: global $var; 是 $var = $GLOBALS[&#39;var&#39;];的简写。所以unset($var)不会影响外面的global. 如果想要在函数中销毁全局变量可以用unset($GLABOL[&#39;var&#39;]) Wordpress的全局变量$wpdb的定义: require_wp_db() 常量定义: define(&quot;CONST_STRING1&quot;, &quot;Hello world.&quot;);const CONST_STRING2 = &apos;Hi world&apos;; // 在PHP5.3之后可以用这种方法. 如果常量名是动态的, 也可以用函数 constant(&quot;常量名&quot;)来获取常量的值. 用 get_defined_constants() 可以获得所有已定义的常量列表. empty, isset, is_null ,is_object, is_array, is_string, is_resource, 参考PHP type comparison tables empty() : 大致相当于!isset($var) || is_null($var) || !$var, 详见 empty函数说明和 (http://stackoverflow.com/questions/4559925/why-check-both-isset-and-empty) isset($a) : 当变量a被赋值, 并且不是null, 那么isset($a)为真. 如果在函数中unset一个全局变量, 那么仅仅在这个函数中全局变量被销毁了, 在此函数外面仍旧可以使用这个全局变量. 如果想要在函数中销毁全局变量, 需要用unset(GLOBALS[&#39;ha&#39;])来销毁; is_resource()可以判断fopen返回的文件句柄; 基本数据类型 PHP的基本类型有6种: boolean, integer, float, string, 复合类型: array, object; 在PHP中, 数组和字符串都属于”基本类型”, 基本类型的赋值/函数传递都是传值的; (1) boolean: 整数(0)/浮点数(0.0)/对象(NULL)都被视作false, 可以使用boolean is_bool($x)判断是否是boolean型; (2) integer: 类似C/C++, 0900, 0x900分别用来表示八进制, 十六进制. (3) float: PHP的浮点数和C/C++中的双精度浮点数范围一样, 都是8字节. (4) string: 可以使用==号比较两个字符串是否相同, 用boolean is_string($x)判断变量是否是字符串. PHP使用[ ] 或大括号访问字符串的单个字符, 例如$str{0}或$str{$i} 除了单引号和双引号的字符串, PHP还支持nowdoc和heredoc来支持长字符串, nowdoc类似单引号, heredoc类似双引号: $nowdoc = &lt;&lt;&lt; 'END' //结束符可以自定义...END; // 遇到结束符表示一段结束, 不要忘记分号$heredoc = &lt;&lt;&lt; END // 结束符不带单引号...END; // heredoc无法解析$ 字符串字符串处理函数 参考: (https://php.net/ref.strings) 字符串空格、大小写：trim, ltrim, rtrim, strtolower, strtoupper; 字符串截取: string substr($str,$start,$len), 查找字符串的首次出现: string strstr(string,search), 如果只是想测试a是b的子串，请使用速度更快耗费内存更少的 strpos() 函数。 字符串分解: list($a,$b,$c) = explode(&#39;,&#39;, $str); 字符串合并: $str_imp = implode(&#39;,&#39;, $array) 将数组的元素合并成一个字符串; Web相关字符串处理函数 HTML实体: htmlentities 区别htmlspecialchars, (http://www.w3school.com.cn/php/func_string_htmlentities.aspx) 去除html标签 string strip_tags($htmstr), 去除&lt;p&gt;,&lt;i&gt;等 获取HTML mate属性: $arr = get_meta_tags($htmstr) 获取HTTP头: array get_headers($url) 将当前的 QUERY_STRING解析到数组: void parse_str(string,array), 将url的get参数解析到array, 这个函数的输出受到magic_quotes_gpc的影响. 与上面的parse_str()相反, 将array组装为get查询字符串http_build_query($array) 解析URL的要素: array parse_url($url), 返回包含host,port,user 等 对URL进行编码: urlencode($url): 将非字母字符转换为”%数字”, 空格编码为”+”, 对应解码为urldecode($url) 对URL进行编码: rawurlencode($url): 与上面的区别是空格编码为”%20”, 对应解码是rawurldecode($url) 问题: 为什么要对URL进行编码? 哪些需要编码? (http://www.blogjava.net/donghang73/archive/2011/08/10/356208.html) 更多URL函数参考(http://php.net/manual/zh/book.url.php) [注1] addslashes() / stripslashes() : (http://php.net/manual/zh/function.addslashes.php) 比较字符串 在PHP中字符串是基本类型, 所以==是比较值, 而不是像Java比较字符串引用的指向, 另外int类型的1和”1”用==比较是相等的; 如果想严格比较字符串, 包括类型比较, 则使用===; strcmp($1,$2), strcasecmp($1,$2) Perl风格正则 boolean preg_match($pattern, $string, $array_match): 第三参数match也可以没有, match[0]存储完整的$string, match[1]存储…正则表达式快速参考(https://msdn.microsoft.com/zh-cn/library/az24scfc(v=vs.110).aspx) 格式化输出echo, print(), printf(), print_r(), var_dump(): echo和print都是语言结构, 有无括号均可使用, echo和print都不是函数所以没有返回值, 所以不要把echo当作if的判断条件; echo后面可以是一般的变量(包括类的成员), 但不能是array和object; printf是函数所以有返回值, 和C语言的printf基本一样. print_r()和var_dump()可以更详细的打印出类型和值; echo &quot;1&quot;, &quot;2&quot;, &quot;3&quot;; // echo可以一次输出多个字符echo (&quot;$var&quot;); // echo 也可以带括号echo (&quot;1&quot;, &quot;2&quot;, &quot;3&quot;); // error! echo不是函数echo &quot;$_GET[&apos;action&apos;]&quot;; // error!echo &quot;$&#123;_GET[&apos;action&apos;]&#125;&quot;; // $符号后加个大括号就正确了 PHP的数组 测试一个对象是否是数组: is_array($x) 获取数组大小: sizeof($arr)和 count($arr); 生成连续数组: range() 例如: $arr = range(1,100) 或者$arr = range(&#39;a&#39;, &#39;z&#39;); 为数组元素赋值: array_pad($arr,n,val), 注意array_pad()返回的是一个新数组, 在原数组$arr基础上,生成一个带有n个初值为val的数组; 从数组中析取多个值: $arr = array(1,2);list($a,$b,$c) = $arr; // 变量a,b,c的值分别为1,2,null 获取子数组: // array_slice()返回是一个新数组, 当然也可以可以用list析取值:list($a,$b) = array_slice($arr, 1, 3); //返回从$arr[1]开始, 包括arr[1]的3个元素 检查数组里是否存在Key: if(array_key_exists(&#39;name&#39;, $array)), 能否用if($array[&#39;name&#39;])判断? 检查数组里是否存在Value: if(in_array(&quot;abc&quot;,$array)), 第三个参数可选,true或false表示是否判断类型; 迭代器(iterator), PHP有一些函数来移动迭代器, 并返回元素: current(), reset(), next(), prev(), key(), 迭代器each()返回当前的k和v, 并指向下一个元素: while(list($k, $v) = each($array)); 数组排序: sort(), rsort(), 翻转数组: array_reverse($arr), 合并数组: array_merge($arr1,$arr2): 对于数字索引的数组, 如果第二个数组有 Key 重复的元素, 这个元素会被分配一个新的索引; 对于字符串索引的数组则覆盖前面的值; 思考: 如果两个数组一个是”数字索引”另一个是”字符串索引”, merge的结果是怎样的? 数组相加: $arr1 + $arr2: 相同索引的元素会合并, 和merge的区别是, 如果有索引相同的元素, 加号是保留第一个数组的元素; 比较数组: $arr_diff = array_diff($arr1,$arr2), 返回值是$arr1和$arr2的交集, 并且对于数组的value是用===比较的,所以$arr1和$arr2分别有int(1)和”1”也要被算作不同; 数组作为LIFO堆栈后进先出 : array_push($arr,$elem)和array_pop() 更多数组函数参考(http://php.net/manual/zh/ref.array.php) PHP数组的key可以为integer(甚至是负数)和string, value可以为任意类型; key有如下几个转换规则: 如果key是可以转换成integer的(例如字符型的”8”,布尔型的true), 那么key会被转换为integer; 当key是float型, 其小数部分会被舍去, 自动转换为integer; 定义数组时, 多个元素使用同一个key, 这些元素的值会被最后一个覆盖, 比如arr = array(3.1 =&gt; &#39;3.1&#39;, &#39;3&#39; =&gt; &#39;three&#39;);, 最终数组只有一个元素k,v = 3,&#39;three&#39;; 使用[]符号访问数组成员时, 也符合以上的转换规则, 例如arr[3.1]和arr[‘3’]都会被默认转换为arr[3]; 数组引用(references)$worker = array(\"Fred\",\"Willma\");$Clone = $worker; // worker的一份拷贝$Ref =&amp; $worker; // 不产生新的拷贝, 仅指向同一个对象$worker[1] = 37; // $Clone发生写时复制var_dump($Clone); // 值没有改变var_dump($Ref); // 值改变了 原数组赋值null: $worker = null;var_dump($Clone); // 正常访问var_dump($Ref); // NULL 删除原数组: unset($worker); // 删除原来的数组var_dump($Clone); // 正常访问var_dump($Ref); // 正常访问 结论 Obj无论用= 还是=&amp;, 修改其中一个都会影响另一个, 因为Obj的赋值是按引用传递的. 但是Array和String属于基本类型, 使用=的时候是值传递, 改变一个另一个不受影响, 只有=&amp;按引用传递时才会改变另一个. unset一个引用只会断开引用和实际变量的连接, 并不会影响实际变量 问题 使用unset和$a=null的区别是? (http://stackoverflow.com/questions/584960/whats-better-at-freeing-memory-with-php-unset-or-var-null) $a=null 立即释放内存, 但没有把$a从符号表里删除; unset($a) 不会立即释放而是在适当时候释放内存(类似Java), 但会立即把$a从符号表删除, 此时再用if($a==null) 会得到一个”未定义变量”的错误. array_key_exists(&#39;var_name&#39;, $var) 引用计数和写时复制 引用计数 : (http://php.net/manual/zh/features.gc.refcounting-basics.php) 写时复制 : (http://www.php-internals.com/book/?p=chapt06/06-06-copy-on-write) PHP的类型转换php中的强制转换和c的语法类似, 强转为string类型还可以使用strval()函数; $fst = (string) $foo; // c风格转换echo strval(pow(2,50)); // 利用函数转换 转换为对象 如果将一个对象转换成对象, 它将不会有任何变化. 数组转换成对象将使键名成为属性名并具有相对应的值. 如果基本类型的值被转换成对象, 将会创建一个内置类 stdClass 的实例. 如果该值为 NULL, 则新的实例为空. 名为 scalar 的成员变量将包含该值 基本类型转化为对象 $obj = (object) 'abc'; // 字符串转化为对象echo $obj-&gt;scalar; // outputs 'abc' 数组转换为对象: $arr = array(\"One\" =&gt; 1, \"Two\" =&gt; 2);$obj = (object)$arr;echo $obj-&gt;One;echo $obj-&gt;Two; 转换为数组对于任意 integer, float, string, boolean 和 resource 类型, 如果将一个值转换为数组, 将得到一个仅有一个元素的数组, 其下标为 0, 该元素即为此标量的值.如果一个 object 类型转换为 array, 结果为一个数组, 其单元为该对象的属性. 键名将为成员变量名, 不过有几点例外： 整数属性不可访问；私有变量前会加上类名作前缀； 保护变量前会加上一个 * 做前缀. 这些前缀的前后都各有一个 NULL 字符. 这会导致一些不可预知的行为： PHP各种类型的比较PHP里的比较运算符==,&gt;,&lt;不区分类型, 只比较”值”, 如果比较符号两边不是同一类型(但是能转换为同一类型)也可以比较. 比如(int)1和(string)”1”用==比较是相等的;如果要做严格的类型比较, 需要用全等于===, 当类型和值都相同时表达式才是true. PHP的== 和=== : 字符串: 作为PHP的基本类型, 字符串==是比较值而非引用, 所以==和===以及strcmp()都可以用来比较字符串; 数组==比较: 两个数组的key和value都相等则为true, 顺序可以不同, 类型不必严格相等; 数组===比较: 两个数组必须顺序一致, 并且key和value的类型也严格相等, 也可以使用array_diff()函数; 对象==比较: 成员的值相等, 并且两个对象是同一个class类型; 对象===比较: 必须指向同一个对象 不同类型间的比较 : 上面的情况1要注意: 当其中一个变量不确定类型时(来自用户的输入), 用==比较是危险的, 比如if(0==&#39;pwd123&#39;)是真, 所以strcmp和===才是妥当的字符串比较. int/string/array/obj 同boolean比较? # int(非0), 非空的string(‘false’和’true’), 非空array, 同true做==比较都是真 int/string/array/obj 同null比较? # int(0),空字符串string(‘’),空数组array() 与null做==比较都是真, if(‘’ == null)是真 空字符串$b=&#39;&#39;和null用==比较返回真, 用===比较返回假; 只有$b=null之后, if($b === null)才是真 流程控制 if-else嵌入到html: (http://stackoverflow.com/questions/722379/can-html-be-embedded-inside-php-if-statement) 函数(方法) 类对象作为参数/返回值: 都是按照引用的方式传递参数. 函数返回引用: function &amp;returns_reference() // 函数名前要带一个&amp;符号&#123; return $someref; // 没有&amp;&#125;$newref =&amp; returns_reference(); // 注意这里也需要&amp;符号 函数按引用传参: function foo(&amp;$var)&#123; $var++;&#125;$a=5;foo($a); // $a is 6 here 面向对象 “魔术方法” : __sleep(), __wakeup(), __invoke(), 这个函数实际是如何使用的? “后期静态绑定”: 在继承中使用self::或者__CLASS__, 取决于函数的定义是由基类or派生类, 如果用static::代替self:: C++具有abstract方法和类, 但没有interface; Java有abstract方法, 但没有抽象类, Java用interface替代抽象类; 但PHP同时具有以上; C++用const可以修饰方法和属性, Java没有const关键字而用final修饰常量, 同时final还可以修饰属性(常量),方法和类(不可继承), 形参(同C++的const); PHP同时拥有const和final关键字, const修饰常量和类成员常量, final和abstract都可以修饰抽象类和函数 上代码: 参考(http://learnxinyminutes.com/docs/zh-cn/php-cn/) class MyClass extends MyAbstractClass implements InterfaceTwo&#123; const MY_CONST = 'value'; // 常量 static $staticVar = 'static'; public $property = 'public'; // 在这里可以初始化 public $instanceProp; // 类成员要在构造函数里初始化 protected $prot = 'protected'; // 当前类和子类可访问 private $priv = 'private'; // 仅当前类可访问 // 构造可以有不同的参数列表, 类似于C++的构造函数重载 public function __construct($instanceProp) &#123; parent::__construct(); // 要手动调用父类的构造 $this-&gt;instanceProp = $instanceProp; &#125; // 不可被改写的方法 final function youCannotOverrideMe() &#123; &#125;&#125;// 命名空间:// 类会被默认的放在全局命名空间中，可以被一个\\来显式调用$cls = new \\MyClass();// 为一个文件设置一个命名空间namespace My\\Namespace;class MyClass&#123; ... &#125;// 你也可以为命名空间起一个别名namespace My\\Other\\Namespace;use My\\Namespace as SomeOtherNamespace;$cls = new SomeOtherNamespace\\MyClass(); 类自省 类检验: class_exists(&#39;className&#39;), get_class_methods(&#39;className&#39;), get_class_vars(&#39;className&#39;), get_parent_class(&#39;className&#39;), for example: $methods_arr = get_class_methods(&apos;ChangyanHandler&apos;); // 返回数组if(!count($methods_arr)) &#123; ... &#125;$vars_arr = get_class_vars(&apos;Class&apos;); // 注意只返回有默认值的属性, 数组// 用foreach(...)遍历类的属性 对象检验: is_object($obj), get_class($obj), bool method_exists(obj, method_name), get_object_vars($obj), for example: $class_name = get_class($obj); // 由类实例获取类名$vars_arr = get_object_vars($obj); // 只返回有默认值的属性, 数组 if($obj instanceof ChangyanHandler) 串行化$str = serialize($mixed)串行化对象或者数组, $mixed = unserialize($str)从字符串恢复对象或者数组, 在串行化和反串行化操作一个object时, 有两个钩子函数: __sleep() : 在serialize()之前调用, 在这个函数里你需要关闭已达开的资源, 并返回array, 包含需要串行化的成员名字; __wakeup() : 在unserialize()之后调用, 在这个函数里你需要重新打开资源; 模块化引用其他文件： include &#39;globals.php&#39; : require &#39;globals.php&#39; : 如果不能被导入时，会抛出错误 异常@todo MySQL [注1] 对输入进行安全处理: addslashes()函数对_COOKIE[], _GET[], _POST[]的输入进行去引号以及斜线进行转义处理, 注意, magic_quotes_gpc设置为On的时候默认对上面的输入自动进行addslashes(), 不要在该值为On的时候重复调用addslashes, 稳妥的做法是: if (get_magic_quotes_gpc()) &#123; $lastname = stripslashes($_POST[&apos;lastname&apos;]); //得到原始的输入&#125; 属性magic_quotes_gpc自从5.4起被移除, 不再推荐使用 对于5.4之前的版本也要注意, magic_quotes_gpc只对GET/SET/COOKIE有效, 但没有转义$_SERVER[] 建议使用 DBMS 指定的转义函数（比如 MySQLi 是 mysqli_real_escape_string(), 但是如果你使用的 DBMS 没有一个转义函数才选择使用使用addslashes(); Mysqli和PDO都提供了预处理语句prepare()和bind_param(), 使用预处理语句的优点? PDO参数化查询 对于非array或obj的输入, 可以用intval()转换. PDO vs. MySQLi 选择哪一个？ Web 全局数组: _COOKIE[], _GET[], _POST[], _FILES, _SERVER[], _ENV[]: 数组$_SERVER[]包括的全局变量有: REQUEST_METHOD: 访问页面时的请求方法.例如: “GET”. “HEAD”. “POST”. “PUT”. REQUEST_TIME: 请求开始时的时间戳. QUERY_STRING: 查询（query）的字符串（URL中第一个问号？之后的内容）. DOCUMENT_ROOT: 当前运行脚本所在的文档根目录.在服务器配置文件中定义. HTTP_ACCEPT: 当前请求的Accept头信息的内容. HTTP_ACCEPT_CHARSET: 当前请求的Accept-Charset头信息的内容. SERVER_PROTOCOL: 请求页面时通信协议的和版本, 例如:Http/1.0; REQUEST_METHOD: 访问页面时的请求方法.例如:”GET”. “HEAD”. “POST”. “PUT”. 获取SSL状态 if($_SERVER[&#39;HTTPS&#39;] != &#39;on&#39;) { .. } Http Header HTTP响应头的设置: 在用header()前不能有任何html输出header(&apos;Location: http://segmentfault.com/&apos;); // 重定向header(&quot;HTTP/1.0 404 Not Found&quot;); // 返回404header(&apos;Content-type: application/pdf&apos;); // 页面将输出pdfheader(&apos;Content-Type: text/html; charset=utf-8&apos;); // 设置输出html和编码 在任何输出之前, 应该使用header() Cookie:跨域种Cookie// 文件a.com/setcookie.phpheader(&apos;P3P: CP=&quot;CURa ADMa DEVa PSAo PSDo OUR BUS UNI PUR INT DEM STA PRE COM NAV OTC NOI DSP COR&quot;&apos;);setcookie(&quot;TestCookie&quot;, $value, time()+3600, &quot;/rasmus/&quot;, &quot;example.com&quot;, 1); // 1小时, &quot;example.com/rasmus&quot;及其子目录有效, Https Only// 文件b.com/b_setcookie.php&lt;script src=&quot;http://a.com/setcookie.php&quot;&gt;&lt;/script&gt;//访问b.com/b_setcookie.php 能设置a.com的cookie Session session的实现: 在当前域下种”PHPSESSIONID”的cookie, 这个cookie的值就是服务器端对应session的文件名, 可以使用session_save_path()获取设置session存储路径. session_start()都做了什么? session的同步: NFS, Memcached PHP Session可能会引起并发问题 发送Http请求 Wordpress 支持两种, stream和curl方式, 分别使用stream_context_create和curl_exec实现 具体参考代码WP_Http_Streams::request() 和WP_Http_Curl::request() 安全问题: fsockopen和pfsockopen, 后者是打开一个持续的连接, 在php.ini的选项disable_functions增加”fsockopen” 和allow_url_fopen=Off IDC为什么禁用fsockopen、pfsockopen函数 异步请求: curl_multi php.ini配置 获取php.ini的设置: $val = ini_get(&#39;magic_quotes_gpc&#39;); php.ini 配置选项列表: (http://php.net/manual/zh/ini.list.php) php.ini 安全最佳实践: expose_php, display_errors, log_errors/error_log (http://www.cyberciti.biz/tips/php-security-best-practices-tutorial.html) 错误捕获 error_reporting=E_ALL &amp; ~E_DEPRECATED &amp; ~E_STRICT : display_errors=On : 是否将错误信息作为输出的一部分显示到屏幕 error_log=&quot;D:\\xampp\\php\\logs\\php_error_log&quot; : 设置脚本错误将被记录到的文件 文件编码参考十步解决Php Utf-8编码: php文件本身必须是UTF-8编码. 不像Java会生成class文件, 避免这个问题 php要输出头：header(&quot;Content-Type: text/html; charset=UTF-8&quot;) meta标签无所谓, 有header所有浏览器就会按header来解析 所有外围都得用UTF8, 包括数据库. *.js, *.css(CSS影响倒不大) php本身不是Unicode的, 所有substr之类的函数需改为mb_substr（需要装mbstring扩展）；或者用 iconv functions转码 性能参考 (http://www.imooc.com/video/4169) apache benchmark php解析-&gt; 解释器 内置函数的性能, 实现 少用魔法函数 禁用@错误抑制, @是如何实现的? 及时unset()不使用的, Google: unset会有无法注销变量的情况 正则对性能的影响 数组的查找, map IO: 磁盘, 数据库, 内存, 网络 网络请求并行: curl_multi_*, 调试 使用echo,print,var_dump等在页面上显示错误, 需要修改php.ini的display_errors等选项, 参考, 额外的:debug_backtrace() 输出到文件: file_put_contents(&#39;debug.log&#39;,&quot;msg...&quot;,FILE_APPEND) , 或者error_log($str, 3, &#39;errors.log&#39;), 用法参考 线上环境调试: phpstrom+xdebug + chrome（debug helper） or firefox (easy xdebug) zend studio + zend debugger , 或者在 NetBeans IDE PHP 编辑器中调试 PHP 源代码 参考 PHP: PHP 手册 - Manual","categories":[{"name":"11.Programming-Language","slug":"11-Programming-Language","permalink":"https://beefyheisenberg.github.io/categories/11-Programming-Language/"}],"tags":[{"name":"编程语言快速入门","slug":"编程语言快速入门","permalink":"https://beefyheisenberg.github.io/tags/编程语言快速入门/"},{"name":"PHP","slug":"PHP","permalink":"https://beefyheisenberg.github.io/tags/PHP/"}]},{"title":"沉思录：公开的部分","slug":"99.Journal/沉思录-公开的部分","date":"2022-10-03T16:00:00.000Z","updated":"2024-01-24T01:27:54.334Z","comments":true,"path":"99.Journal/沉思录-公开的部分/","link":"","permalink":"https://beefyheisenberg.github.io/99.Journal/沉思录-公开的部分/","excerpt":"","text":"2022.10 如果你总用宇宙视角的无意义感逃避琐碎，那你也同样应该承认，现在诚惶诚恐的维护一个人设、在意他人眼光、以及道德的自我束缚、会让自己的体验受限，这些行为在被拉长的时空里进行考察，都是微不足道的事 2022.9 当沮丧和低落到来时，应该用更强硬的行动反击，而不是用颓靡的姿态附和它，这只会给它们更多的给养。—— “用愤怒面对你的懈怠” 2022.9 另一个建议，做任何事都纯粹一点，比如跑步途中不要思考人生，出去旅行就不要带一堆书，做饭的时候就不要刷手机，也不要试图在网吧里写代码，吃饭要像吃最后一顿。 2022.8 《存在主义心理治疗》: 「如果什么都不重要，那么“什么都不重要”这个结论本身也不重要 」—— 黑洞并非无法直视 「一个人了解自己是为了不要将全副心神贯注在自己身上」—— 自我探索、自我反省的目的都是为了更好的回归到外部生活中去 2022.6 里尔克：「几乎一切人都错用了、浪费了这种经验，把它放在生命疲倦的地方当作刺激，当作疏散，而不当作向着顶点的聚精会神」 2021.7 心生妒忌……或者用批判的态度对待他人的价值观、以及其他不端正的心态，今天它们是否又出现？这也是一种考察你内心是否平静的角度 2020.5 自控力像是一块肌肉，也会疲劳，也需要休息，也需要能量储备，长期松弛也会变弱 2019.9 不要总关注 内部价值 的实现而忽视了 外部价值 的实现，“取得内部价值的成功后，外部价值的成功是顺理成章的”这种想法非常想当然，从内部目标到外部目标这个路径非常长也非常不可控。 2019.7 人生每个阶段都会遇到『迷障』，是指让你在一段时间内耗尽精力但不会获得内在价值的事物（比如烧摄影设备、打游戏），保持批判式的判断力，可以有效避免沉迷于此。 2019.2 如果我们承认了人生的虚无和无意义，那也就没有理由感到恐惧，也没有理由感到失望。当我们否定了恐惧和失望，我们还需要害怕虚无吗？ 2019.2 盛夏季节也不要忘记：寒冬可能会来的很快（2018-2019） 2018.3 无节制的生活方式，和失控的offline ，让你断断续续的努力变成一堆无用的零件。 2017.12 当你戾气渐长的时候, 多想想有关人类历史或者仅仅其中一朵涟漪, 先人对浩瀚的星空从遐想到探索, 科学史上无数璀璨的姓名。 2017.11 断线式的内省很危险。内省走向了偏差 —— 一条阴暗的小路 2017 用愤怒面对你的懈怠。 2016 幻想由你人格最羸弱的部分构成 2016 扔掉欲望，扔掉低俗，你才变得有趣。 2015.11 你不能把世界让给你鄙视的人。 2015.11 想成为什么样的人, 和另一半是什么样的人并没有直接关系, 持续的自我认知, 自我反省, 自我改良的起因和动力, 都源于自身想要进化完整的渴望, 而非他人. 2015.6 「生活方式 总是自我实践为始 再蔓延成为他者认同的影响力 看似很多无用 却是创造的巨大养分」 2014.11 保持对知识的好奇心 2014.9「写下的，可能被忘记，只字不提的，却都铭记在心」","categories":[{"name":"99.Journal","slug":"99-Journal","permalink":"https://beefyheisenberg.github.io/categories/99-Journal/"}],"tags":[{"name":"存在主义","slug":"存在主义","permalink":"https://beefyheisenberg.github.io/tags/存在主义/"},{"name":"虚无主义","slug":"虚无主义","permalink":"https://beefyheisenberg.github.io/tags/虚无主义/"},{"name":"意义","slug":"意义","permalink":"https://beefyheisenberg.github.io/tags/意义/"},{"name":"沉思录","slug":"沉思录","permalink":"https://beefyheisenberg.github.io/tags/沉思录/"}]},{"title":"人生的意义II","slug":"99.Journal/2022.10人生的意义II","date":"2022-10-03T16:00:00.000Z","updated":"2024-01-24T01:27:54.329Z","comments":true,"path":"99.Journal/2022.10人生的意义II/","link":"","permalink":"https://beefyheisenberg.github.io/99.Journal/2022.10人生的意义II/","excerpt":"人生的意义是？ 不可否认，世间本就不存在为我们预设好的意义。甚至作为一个绝对的理性主义者，他还可能得出“生命没有意义” 这种接近虚无主义1的答案。但人仍有自由选择的权利，这种自由可以决定是否要为自己创造出一个意义。罗素在自传序言《What I Have Lived for》中写道他的人生三动力：对爱情的渴望、对知识的追寻、以及对尘世的怜悯之心。 如果让我回答这个问题，意义重要却不复杂，意义感源自那些 —— 最简单、最自然、带给自己正向感受的事物 它们看起来是正确的、美好的；它们提供内在的满足，而不需要别的动机来支持2 一. 对知识的追求。它们帮我找回我那属于理性的另一半灵魂、帮我消除偏见，解答我的疑惑，也给予我开放和容纳的心态… 它一直在帮助我去理解… 我所触碰到的世界。 缮写室、毕达哥拉斯的金诗、卡尔达诺书3……无论迷茫曾把我带向何处，当我翻开书时，我总能找到这片居心地","text":"人生的意义是？ 不可否认，世间本就不存在为我们预设好的意义。甚至作为一个绝对的理性主义者，他还可能得出“生命没有意义” 这种接近虚无主义1的答案。但人仍有自由选择的权利，这种自由可以决定是否要为自己创造出一个意义。罗素在自传序言《What I Have Lived for》中写道他的人生三动力：对爱情的渴望、对知识的追寻、以及对尘世的怜悯之心。 如果让我回答这个问题，意义重要却不复杂，意义感源自那些 —— 最简单、最自然、带给自己正向感受的事物 它们看起来是正确的、美好的；它们提供内在的满足，而不需要别的动机来支持2 一. 对知识的追求。它们帮我找回我那属于理性的另一半灵魂、帮我消除偏见，解答我的疑惑，也给予我开放和容纳的心态… 它一直在帮助我去理解… 我所触碰到的世界。 缮写室、毕达哥拉斯的金诗、卡尔达诺书3……无论迷茫曾把我带向何处，当我翻开书时，我总能找到这片居心地 二. 自身价值得到实现。因为利他性的内核，我是乐于助人的。相比直接的帮助，我更希望自己的建议和观点有助于人。对于亲密的人，除了陪伴，也希望自己对彼此内心成长性有所裨益。这些让我直观地感受到存在的价值。 知识和观点的最终用途应该是：“实践自我价值、有助益于人，而不是写入卷轴然后束之高阁” 三. 那些打动内心的体验。 在黎明时分，我路过那片海，望不到尽头的红树林中，千万只海鸟出巢前的鸣叫，千万双羽翼扑棱的声音，如此近距离地触摸到这鲜活又真实的生命力。我的视线开始模糊，只记得周身被一种明澈的希望托起… 没人比《我在荒岛迎接黎明》4里写得更好… “十万支金喇叭又一次齐鸣，我忽然泪下如雨，但是我心底在欢歌… 这是我一生最美好的时刻，我站在那一个门坎上，从此我将和永恒连结起” 还有，某个秋天独自去T城闲逛：“抛掉杂念，我们上路了，树荫下洗麻将的声音，那么好听”，就是那一刻，自由的味道、秋叶的飒响、平淡又真诚的生活，我从中走过，感受着它们流过指缝。像《黄昏到黎明》5的歌词：“缓 缓 说 起 以 后，在 什 么 城 市， 进 怎 样 的 门，People talk and talk，love is found and lost” 这些微小的体验都曾打动我（感谢里尔克） 四. 可能还有.. 对感情的渴望，无需用其他方式证明，只需当我心甘情愿地说出：“无论什么时候，我都愿意站在你这一边”。以及… 当我面对你时，终于可以把内心的柔软自然地表达。我并不害怕孤独，毕竟…有“一个人就是一场盛大的欢愉”这种想法的人怎么会害怕孤独？甚至我还称它为“亲切的”… 只是，孤独同时又是一个遗憾： 过去我有一瓶香水叫「无论如何」，意思是无论如何都要找到爱的人 五. 自我完善（Ego Integrity）的渴望： 一直以来心里是存在着另一个自己的，那个自己更优秀、更博学、更正直 —— 具备一切我尚未拥有的品质。追寻完整的自我，就如同宗教中的圣杯隐喻。虽然巴别塔一次次被倾覆、西西弗斯一次次滚落山下，但这个隐隐的信念从未变过。 马斯洛认为人有着向成长和人格整合的倾向：“人类的构造迫使他走向越来越完全的存在，也就是大多数人所说的美好价值，走向平静、仁慈、勇敢、诚实、爱、无私和善良” /Trotsky在自传中也提到：“自我完善对我而言与其说是思想流派，不如说是精神成长的有机需要” 六. 以及 那些热泪盈眶、不可言说的情节 …比如不适合这个时代的 英雄主义，殉道者们 etc. 以上几种，在我不同的时期可能有不同的次序和重要性，或者有些曾在我的生活里消失很久。但我知道它们无论何时出现，都会令我欣喜或触动。 我还是爱这个世界的。 @update: 人是种追求意义的动物，却出生在一个本没有预设意义的世界中，这么说是因为在宇宙中并没有宏大的设计，世界也不会告知你我意义的方向，它们同样冷漠且客观，对人类的追寻意义的期望无动于衷。 我曾经不喜欢身上感性的那部分，它太柔软，且容易产生情绪，所以我选择..疏远感性，倒向理性的那一面，因为棱角分明的理性天生坚固。 当时的我还为找到了正确的道路自喜：我的人格是理性的，并且不太需要感性的那部分 但当我面对虚无主义的时候，理性却无能为力，因为选择理性等同于承认客观世界的无意义，所以当时的我只好把“人生的意义是什么”看做一个黑洞问题 —— 就如同黑洞无法被直视，无尽的虚空正吞噬着掷向它的一切，这个问题也就等于无法被思考，除非你愿意体验被虚无吞噬的感受。 还有许人也同样饱受这种折磨…我相信罗素所描写的正是这种感受：“在世界的边缘，俯瞰那冰冷死寂、深不可测的深渊”。 我可以做的，只有尽快把自己投入进繁忙的工作，选择暂时远离和忘记。这很可笑，面对这个问题的方式与“生命的意义”这个问题的提出同样可笑 诚然理性可以对“世间无意义”进行理性的回应：如果什么事都不重要，那“什么事都不重要”这个命题也不重要。这种解释，在理性的层面上令内心不再恐惧于直视黑洞，但此时意义的废墟仍未重建。 世界本无意义，个体可以选择是否主动创造意义，但这种“决定去创造意义”的觉悟，是理性所无能为力的，理性只能承认着这个客观世界的无意义性，这正是理性的能力边界。 如果理性无法带来答案，那就低头去问自己的感受，让感性来做决定，问自己：那些正确的、美好的、自然的、打动我们内心的事物，究竟是什么？如果此时此刻，表征那些事物的词句，正在在你的胸口跳动，在唇边、它们想要生长出来 —— “那便是答案” 假如可以带粉笔进入迷宫，以纯蓝标记每一处通往灾祸的岔口：“我到过这儿必将永不再受诱”，它们将变得可以承受。…假如我尝过的每种汞与砷能使你免于读懂这首诗——它们将变得可以承受 1.虚无主义的英文“Nihilism” 最早来源于拉丁语中的“nihil”，意为“什么都没有” ↩2.欧文·亚隆 《存在主义心理治疗》 第四部分→ [[../62.Psychology/《存在主义心理治疗》读书笔记]] ↩3.关于 缮写室、金诗、卡尔达诺书 ↩4.《我在荒岛迎接黎明》收录于 《绿毛水怪》 ↩5.Romantic Fear - 《D 2 D | 黄 昏 到 黎 明》 ↩","categories":[{"name":"99.Journal","slug":"99-Journal","permalink":"https://beefyheisenberg.github.io/categories/99-Journal/"}],"tags":[{"name":"存在主义","slug":"存在主义","permalink":"https://beefyheisenberg.github.io/tags/存在主义/"},{"name":"虚无主义","slug":"虚无主义","permalink":"https://beefyheisenberg.github.io/tags/虚无主义/"},{"name":"意义","slug":"意义","permalink":"https://beefyheisenberg.github.io/tags/意义/"},{"name":"沉思录","slug":"沉思录","permalink":"https://beefyheisenberg.github.io/tags/沉思录/"}]},{"title":"数据可视化","slug":"51.Productivity/数据可视化","date":"2022-03-02T16:00:00.000Z","updated":"2024-01-24T01:27:53.223Z","comments":true,"path":"51.Productivity/数据可视化/","link":"","permalink":"https://beefyheisenberg.github.io/51.Productivity/数据可视化/","excerpt":"@todo 待整理 AntV 是蚂蚁金服全新一代数据可视化解决方案，致力于提供一套简单方便、专业可靠、无限可能的数据可视化最佳实践。 选择什么图表，需要回答的首要问题是『我有什么数据，需要用图表做什么』，而不是 『图表长成什么样』 。因此我们从数据出发，从功能角度对图表进行分类，如下所示：@ref: 图表用法 - AntV 比较类 柱状图 直方图 南丁格尔玫瑰图 … 分布类 热力图 散点图 …待整理 @todo","text":"@todo 待整理 AntV 是蚂蚁金服全新一代数据可视化解决方案，致力于提供一套简单方便、专业可靠、无限可能的数据可视化最佳实践。 选择什么图表，需要回答的首要问题是『我有什么数据，需要用图表做什么』，而不是 『图表长成什么样』 。因此我们从数据出发，从功能角度对图表进行分类，如下所示：@ref: 图表用法 - AntV 比较类 柱状图 直方图 南丁格尔玫瑰图 … 分布类 热力图 散点图 …待整理 @todo 比较类柱状图 直方图直方图 vs 柱状图 柱状图是以矩形的长度表示每一组的频数或数量，其宽度(表示类别)则是固定的，利于较小的数据集分析。 直方图是以矩形的长度表示每一组的频数或数量，宽度则表示各组的组距，因此其高度与宽度均有意义，利于展示大量数据集的统计结果。 由于分组数据具有连续性，直方图的各矩形通常是连续排列，而柱状图则是分开排列。 直方图的扩展: 通过变换坐标系，我们能获得极坐标下的直方图、圆环上的直方图、以及翻转的直方图 堆叠面积图堆叠面积图和基本面积图一样，唯一的区别就是图上每一个数据集的起点不同，起点是基于前一个数据集的，用于显示每个数值所占大小随时间或类别变化的趋势线，展示的是部分与整体的关系。 堆叠面积图上的最大的面积代表了所有的数据量的总和，是一个整体。各个叠起来的面积表示各个数据量的大小，这些堆叠起来的面积图在表现大数据的总量分量的变化情况时格外有用，所以堆叠面积图不适用于表示带有负值的数据集。非常适用于对比多变量随时间变化的情况。 矩形树图没有权重关系，且需要明显展示层级关系，用分叉树图更合适 南丁格尔玫瑰图","categories":[{"name":"51.Productivity","slug":"51-Productivity","permalink":"https://beefyheisenberg.github.io/categories/51-Productivity/"}],"tags":[{"name":"可视化","slug":"可视化","permalink":"https://beefyheisenberg.github.io/tags/可视化/"}]},{"title":"同步 VSCode 配置文件（macOS）","slug":"50.Farbox-Blog/【编辑器】同步VSCode配置文件","date":"2020-03-17T16:00:00.000Z","updated":"2024-01-24T01:27:53.132Z","comments":true,"path":"50.Farbox-Blog/【编辑器】同步VSCode配置文件/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【编辑器】同步VSCode配置文件/","excerpt":"方法1) 使用Dropbox同步cd ~/Library/Application\\ Support/Codemv -f User ~/Dropbox/VSCode/ln -s ~/Dropbox/VSCode/User User 方法2) 使用 Microsoft 账号同步Settings Sync in Visual Studio Code 方法3) 使用 Settings Sync 扩展","text":"方法1) 使用Dropbox同步cd ~/Library/Application\\ Support/Codemv -f User ~/Dropbox/VSCode/ln -s ~/Dropbox/VSCode/User User 方法2) 使用 Microsoft 账号同步Settings Sync in Visual Studio Code 方法3) 使用 Settings Sync 扩展Settings Sync - Visual Studio Marketplace","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://beefyheisenberg.github.io/tags/Windows/"},{"name":"OSX","slug":"OSX","permalink":"https://beefyheisenberg.github.io/tags/OSX/"},{"name":"macOS","slug":"macOS","permalink":"https://beefyheisenberg.github.io/tags/macOS/"},{"name":"VSCode","slug":"VSCode","permalink":"https://beefyheisenberg.github.io/tags/VSCode/"},{"name":"Dropbox","slug":"Dropbox","permalink":"https://beefyheisenberg.github.io/tags/Dropbox/"}]},{"title":"OKR是什么","slug":"51.Productivity/OKR是什么","date":"2019-10-07T16:00:00.000Z","updated":"2024-01-24T01:27:53.149Z","comments":true,"path":"51.Productivity/OKR是什么/","link":"","permalink":"https://beefyheisenberg.github.io/51.Productivity/OKR是什么/","excerpt":"OKR（Objective &amp; Key Results）：OKR是一个从个人愿景到设定个人目标的方法论，它能帮助组织成员/使用者聚焦最重要的事。OKR是确保将整个组织/个人的力量都聚焦于完成对所有人/个人都同样重要的事项的一套管理方法。正是多了Objectives，才能让参与者先思考最重要的事，然后再去拆解任务。而KPI却是直接确定任务。 制定 制定OKR的基本方法是：首先，要设定一个“目标”（Objective），这个目标不必是确切的、可衡量的，例如“我想让我的网站更好”；然后，设定若干可以量化的“关键结果”（Key Results），用来帮助自己实现目标，例如“让网站速度加快30%”或者“融入度提升15%”之类的具体目标。 目标（Objective）要是有野心的，有一些挑战的，有些让你不舒服的。一般来说，1为总分的评分，达到0.6-0.7是较好的了，这样你才会不断为你的目标而奋斗，而不会出现期限不到就完成目标的情况。 关键结果（Key Results）所谓的KR就是为了完成这个目标我们必须做什么，KR是必须具备以下特点的行动：","text":"OKR（Objective &amp; Key Results）：OKR是一个从个人愿景到设定个人目标的方法论，它能帮助组织成员/使用者聚焦最重要的事。OKR是确保将整个组织/个人的力量都聚焦于完成对所有人/个人都同样重要的事项的一套管理方法。正是多了Objectives，才能让参与者先思考最重要的事，然后再去拆解任务。而KPI却是直接确定任务。 制定 制定OKR的基本方法是：首先，要设定一个“目标”（Objective），这个目标不必是确切的、可衡量的，例如“我想让我的网站更好”；然后，设定若干可以量化的“关键结果”（Key Results），用来帮助自己实现目标，例如“让网站速度加快30%”或者“融入度提升15%”之类的具体目标。 目标（Objective）要是有野心的，有一些挑战的，有些让你不舒服的。一般来说，1为总分的评分，达到0.6-0.7是较好的了，这样你才会不断为你的目标而奋斗，而不会出现期限不到就完成目标的情况。 关键结果（Key Results）所谓的KR就是为了完成这个目标我们必须做什么，KR是必须具备以下特点的行动： 必须是能直接实现目标的； 必须具有进取心、敢创新的，可以不是常规的； 必须是以产出或者结果为基础的、可衡量的，设定评分标准； 不能太多，一般每个目标的KR不超过4个； 必须是和时间相联系的。 常见的KR分为三种类型：积极的、有效的、临界值, 举例: 积极的：6月底前完成40篇博客撰写。 消极的：40篇内容错别字不超过2处。 临界值：咨询转化率保证在60%以上。 建议你尽可能的设定积极的KR，我们应该试图去获得好的成绩，而不是避免不好的事情发生。 实施@TODO 例子Objective设定为：提升每位用户的平均观看时间 那么Key Results可以设定为： •提升每天XX分钟的观看时间•推出两个新的操作系统的YouTube客户端•降低X%的视频加载时间 vs KPI相比OKR，KPI只有任务和数据指标, 没有目标（Objective） KPI还有一个更严重的问题，那就是为了完成可测量的目标，有可能实际执行手段与该目标要达到的不可测量愿景正好相反。举个例子来说，我们希望用户更喜欢使用我们的产品，因为喜欢无法测量，所以把PV写进了KPI里面。但在实际执行过程中，我们可以把用户原本在一个页面上就能完成的事情分到几个页面上来完成，结果PV达到了KPI指定的目标，但用户其实更讨厌我们的产品了。 OKR解决了KPI的种种缺陷。首先它和绩效考核分离，把绩效考核交给peerreview（相当于中国公司的360度评价）来做。","categories":[{"name":"51.Productivity","slug":"51-Productivity","permalink":"https://beefyheisenberg.github.io/categories/51-Productivity/"}],"tags":[{"name":"项目管理","slug":"项目管理","permalink":"https://beefyheisenberg.github.io/tags/项目管理/"}]},{"title":"新裤子年鉴","slug":"63.Culture-and-Arts/新裤子年鉴","date":"2019-09-15T16:00:00.000Z","updated":"2024-01-24T01:27:53.965Z","comments":true,"path":"63.Culture-and-Arts/新裤子年鉴/","link":"","permalink":"https://beefyheisenberg.github.io/63.Culture-and-Arts/新裤子年鉴/","excerpt":"专辑list乐评from： 新裤子：北京旧浪潮-虎嗅网 1998年：同名专辑《新裤子》 #Punk 我们的时代 嘿！你 我不想失去你 猴子 过时","text":"专辑list乐评from： 新裤子：北京旧浪潮-虎嗅网 1998年：同名专辑《新裤子》 #Punk 我们的时代 嘿！你 我不想失去你 猴子 过时 2000年：《Disco Girl》 #Punk #Disco #新浪潮 流行一代 Disco Girl 我爱你 计算机 Modern Sky 我们明天就分手 2002年：《我们是自动的》 #new_wave 她是自动的 2002 年，新裤子朋克时期的最后一张专辑《我们是自动的》封面还是星球大战主题，乐队在《Fashion1983》中唱着“Western style minds feels so great／Everybody living in a fashion magazine”，仿佛那个美好的彼岸即将成为此岸。 2006年：《龙虎人丹》 #new_wave 你就是我的明星 Bye Bye Disco 两个男朋友 神秘的香波 龙虎人丹 爱瑞巴迪 我想她 庞宽刚写出《龙虎人丹》时，取名《法国夜生活》，中间取样阿兰·德龙；后来彭磊一听，觉得调子那么老和巴黎一点关系也没有，给安个中国名儿，把阿兰·德龙的采样换成了李小龙。唱片整体设计也因此走向复古，没想到大获成功。 2008年：《野人也有爱》； #土摇 02.金色偶像 03.两个女朋友 04.大熊猫 08.伤心招待所 11.我们可以在一起 2009年：《Go East》 Go East - 新裤子 野人也有爱 - 新裤子 我不想失去你 - 新裤子 到了 2009 年的《Go East》，彭磊和庞宽已经穿上了中山装：“I saw tears on your face／Western life is the dead／When we stand in Tian An Men Square／We can feel the happiness”。无论这是真心话还是政治波普，新裤子创作场域显然已经聚焦于中国。《我不想模仿你》中，他们又表现了一种自省而无奈的态度：“我们不是雷蒙斯，我们不是 Joy Division。” 2011年：《SEX DRUGS INTERNET》 #新浪潮 2.你還記得那個電影演員嗎？ 4.總有一天我會欺騙你 7.After party 10.別再問我什麽是迪斯科 2014年：《弹着吉他的少年》?? 再往后，乐队进入“土摇”时期，甚至连挣扎的迹象都不再表露于音乐中。直截了当的本土青年关怀替代了国际化前卫乐队之梦，而这些追随新裤子的本土青年又何尝不是世纪之交最先追随王小波的媒体精英的投射，只是这世界比二十年前又下沉了一点而已。 2016年：《生命因你而火热》#土摇 01 你要跳舞吗 02 我们最好的时光 就是现在 03 没有理想的人不伤心 04 每一次我们开始争吵 05 生活因你而火热 07 关于夜晚和失眠的世界 (album version) Ref 不止《流行一代》，这张专辑还有一首超级市场乐队成员 —— 羽伞制作的赛博浪漫曲目《计算机》，更与朋克少年无涉。在即将跨入新千年的时候，电脑代表着 “青年人、神秘的事物与打开的眼睛”，对新生活敏感的 “北京新声” 乐队对此多有涉及，连主打英式摇滚的麦田守望者乐队，当时也有描写电子邮件发来生日信的《电子祝福》，甚至连专辑都命名为《Save As…》。当《计算机》在 2009年的《Go East》中被 Sulumi 重新混音时，你更能看到那首歌的超前敏感度，当时被指为不知所云的它，直接指出了之后十几年年轻人们的情感寄托。《Disco Girl》的变化只是 “新裤子背叛史” 中具有代表性的一个小节，关于 “改变” 的争议贯穿了这个乐队成立以来的每个重要时点。当2006年的《龙虎人丹》彻底倒向 New Wave 与合成器流行后，连创始成员 —— 刘葆都觉得他们 “变成了一支娘娘腔的同性恋乐队”，于是加盟蜜三刀，玩回自己的 Oi Punk。新裤子则继续输出着青年人的慵懒的快乐、忧伤的嘶吼。到2013年的《没有理想的人不伤心》之后，彭磊甚至用 Shoegazing 风格的噪音音墙或 Sigur Ros 式的钢琴旋律来表达。 2006 年，加入 WTO 后中国的全球化之路已经走了5年，人们的生活被更多更便宜的国际品牌笼罩，人们用诺基亚和索尼爱立信的手机，用戴尔和 IBM 的笔记本电脑， 穿 Levi’s 和 G2000 的牛仔裤与都市休闲装。80年代的国货在并购潮下被冲击不小，当时网上最热的帖子是：《震惊！中华牙膏竟然不是中国货！》。 娃哈哈集团的董事长宗庆后，因为本土品牌的使用权和控股娃哈哈的达能集团打起了用民族主义当大棒的舆论战。新裤子当然对民族主义没兴趣，他们是被改革开放后、商品社会前的生活趣味浸淫的一代人。2006年初，《龙虎人丹》横空出世，彭磊、庞宽、刘葆三人穿着极其 80年代的彩色条纹运动裤与皮衣，站在与全球化丝毫无关的前门大栅栏古街上 “凹造型”，发廊、舞厅、彩色墨镜、迪斯科球、合成器、紧身裤与老运动服成了这张专辑的重要意象，封面的设计也完全仿制了古早中式产品的样子 —— “龙虎人丹” 本身就是一味古老的中成药。 @Ref 除了新裤子，中国从未有一支可以影响每一代年轻人的摇滚乐队 “想扭屁股”是张蔷启蒙了张晓舟那一代人的荷尔蒙的身体反应，在《别再问我什么是Disco》发布后，张晓舟在《大家》专栏上写道：“在我少时的想象中，张蔷是扭着屁股唱歌的，但现在才发现，即便是在唱迪斯科劲歌的时候，她的歌唱，也多少是与身体脱节的，她的下半身还是如此的温良恭俭让。八十年代对于五千年文明来说是石破天惊的，但对于虾米陌陌时代来说，却又老派得令人发指。是历史的一阵恼人的秋风，把张蔷忽然刮到时代的前列，而她还没有做好准备，就红遍天下了，同样还没做好准备，就又被九十年代淡忘了。就像驾着手扶拖拉机一下闯进了凯宾斯基——所谓的现代性，往往是在知识分子尚未意识到、更没来得及命名的时候，便悍然发生了。张蔷的回归不仅仅具有音乐的意义——音乐美学上的价值也确实有限——而且还提供一个机会，让不同年代的人们重新认识八十年代。八十年代的中国，就像是一块古老的沉重的石头在跳舞，而张蔷们，是在用口红胡涂乱抹在XXXX上。 @Ref DISCO is OUT , So TM What ?OPEN开腔新浪博客 作者：Rosasinespina博尔赫斯有一句诗叫，“我试图用困惑，危险，失败打动你”，我被危险打动过一次，被失败打动过一次，这次估计是新裤子独有的傻了吧唧朋克青年的困惑打动了我吧。不知为何，觉得这张专辑的好多歌词，都用一种极其无聊又刻骨的方式解构了失败与人生的困惑，比如不放开，比如总有一天我会欺骗你。要说是一种什么感觉呢，以前提过一个概念是“末日温情”，类似于杀猪之前要把猪喂饱这种心情，又或者，用一个很雷的比喻，就像是后会无期里马浩汉对江河说“我这个人朋友多，不像你”，结果最后连狗都没跟他。第一次听到“我相信明天会失败 不代表我心里没有爱”的时候简直觉得迷一样感动，当时我宿醉头晕了两天，躺在床上，正在权衡是把鞋盒里的打火机拿出来但是又担心被脚气熏死的利弊，突然就，那么一下，正中红心了，那种感觉就是，愿意用下半辈子的性生活换取此刻。（虽然下半辈子可能不会有性生活。总有一天我会欺骗你，我觉得这个根本就是我的爱情观。活这么大岁数虽然情商有点跟不上但好歹也经历过一点东西了，也大概在刚开始喜欢一个人的时候就知道自己距离把他的电话号码放进黑名单还剩多久了。在我看来爱就是一个装傻装久了慢慢变成真傻的过程，享受的就是当下被骗蒙圈的感觉，等到觉得没病可以站起来走两步了，也就是时候抛弃对方了，换句话说，抛弃也算爱的一种组成部分，这个部分时时刻刻提示着人们当下的感觉才是最重要的，反正大家都在说假话，只要说的那一刻心甘情愿上当就可以了，用冯金线的话说就是，它们都存在，那时那刻，此时此刻，实在，不空。 @Ref 新裤子乐队的彭磊是一个怎么样的人？ - Rosasinespina的回答- 知乎","categories":[{"name":"63.Culture-and-Arts","slug":"63-Culture-and-Arts","permalink":"https://beefyheisenberg.github.io/categories/63-Culture-and-Arts/"}],"tags":[{"name":"流行文化","slug":"流行文化","permalink":"https://beefyheisenberg.github.io/tags/流行文化/"},{"name":"新裤子","slug":"新裤子","permalink":"https://beefyheisenberg.github.io/tags/新裤子/"}]},{"title":"OSX（macOS）开发环境配置 and Tweaks","slug":"50.Farbox-Blog/【开发环境】MacOS开发环境配置","date":"2019-05-05T16:00:00.000Z","updated":"2024-01-24T01:27:53.101Z","comments":true,"path":"50.Farbox-Blog/【开发环境】MacOS开发环境配置/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【开发环境】MacOS开发环境配置/","excerpt":"安装OSX 从OSX制作启动U盘: http://www.iplaysoft.com/osx-yosemite-usb-install-drive.html 从WIN制作启动U盘: http://www.cnblogs.com/maybego/p/3266528.html 快捷键 Command + Option + Esc : 相当于Windows上的 Ctrl + Alt + Del，或者点击左上角图标-强制退出 参考 https://support.apple.com/zh-cn/HT201236","text":"安装OSX 从OSX制作启动U盘: http://www.iplaysoft.com/osx-yosemite-usb-install-drive.html 从WIN制作启动U盘: http://www.cnblogs.com/maybego/p/3266528.html 快捷键 Command + Option + Esc : 相当于Windows上的 Ctrl + Alt + Del，或者点击左上角图标-强制退出 参考 https://support.apple.com/zh-cn/HT201236 开发工具 &amp; 常用软件常用软件(DMG安装文件) Shadowsocks: https://github.com/shadowsocks/shadowsocks-iOS/wiki/Shadowsocks-for-OSX-Help Google Chrome: https://www.google.com/intl/zh-CN/chrome/ Dropbox: https://www.dropbox.com/zh_CN/install 1Password: https://1password.com/zh-cn/downloads/mac/ 英雄留步关于Xcode, 不做iOS开发也要安装, Xcode作用相当于Windows上的.NET Framework, 直接在App Store上安装即可, 下载时间很长, 可以先睡一会, 醒来就装好了. 安装完Xcode后, 命令行执行: xcode-select --install # 安装 Command Line Toolssudo xcodebuild -license accept # 同意协议, 不用再打开一次 Xcode了 Homebrew &amp; cask Homebrew 官网: http://brew.sh/ , 安装方式: /usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" Homebrew-cask 官网: https://caskroom.github.io/ , 安装方式: brew tap caskroom/cask brew 和 brew cask 的区别: brew 是从下载源码解压然后 ./configure &amp;&amp; make install, brew主要用来安装不带UI的命令行或者库, brew安装的程序包在/usr/local/Cellar/, 可执行文件链接到/usr/local/bin/ brew cask 是安装已经编译好了的应用包, brew cask主要用来下载一些带界面的应用软件, 安装目录默认在/usr/local/Caskroom/ 安装了 Homebrew 和 Homebrew-cask 之后就可以用brew install和brew cask install命令安装其他程序,brew 命令参考: https://docs.brew.sh/Manpage 替换为国内镜像 替换及重置Homebrew默认源 替换为 USTC 镜像： cd &quot;$(brew --repo)&quot;/Library/Taps/caskroom/homebrew-caskgit remote set-url origin https://mirrors.ustc.edu.cn/homebrew-cask.git 重置为官方地址： cd &quot;$(brew --repo)&quot;/Library/Taps/caskroom/homebrew-caskgit remote set-url origin https://github.com/caskroom/homebrew-cask Homebrew常用命令brew install xxx # 按名称安装brew uninstall xxx # 按名称卸载brew list # 列出已安装的包brew outdated # 列出可更新的包brew update # 更新Homebrew自身brew upgrade xxx # 升级某个软件包brew upgrade # 升级全部软件包brew pin/unpin xxx # 锁定或者解锁软件包版本，防止误升级brew search xxx # 按名称搜索brew info xxx # 查看包信息brew doctor # 诊断关于Homebrew的问题(Homebrew 有问题时请用它)brew cleanup # 清理老版本软件包或者无用的文件# 第三方Repositories相关:brew tap # 列出所有安装的第三方Repositoriesbrew tap &lt;user/repo&gt; # 安装第三方Repositories Homebrew-Cask常用命令注: 不再支持 brew cask xx命令, 改为: brew xx --caskbrew cask install xxx # 安装软件brew cask uninstall xxx # 卸载软件brew cask search xxx # 模糊搜索软件brew cask info xxx # 显示软件的详细信息brew cask list # 列出所有已安装的软件brew cask upgrade # 更新所有已安装的软件 安装统计在Homebrew Analytics Install Events — Homebrew可以看到被安装的app排名 使用命令brew analytics off来退出 Homebrew 的分析。 Zsh 和终端替代品iTerm2 Zsh: sh -c &quot;$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot; 终端替代品iTerm2: brew cask install iterm2 Zsh插件 brew install autojump zsh-syntax-highlighting zsh-autosuggestions并在~/.zshrc下增加: [ -f /usr/local/etc/profile.d/autojump.sh ] &amp;&amp; . /usr/local/etc/profile.d/autojump.sh` 补充, 如果使用了Oh-my-zsh就不用上面这么麻烦了, 直接在~/.zshrc里这样enable插件: plugins=(git autojump osx mvn gradle zsh-syntax-highlighting zsh-autosuggestions) 编辑器(Vim &amp; Sublime) MacVim: brew cask install macvim Sublime text: brew cask install sublime-text java环境brew tap caskroom/versionsbrew cask install java8 或者直接在Oracle官网下载, 并在.bashrc（如果你用的zsh，则是.zshrc）添加$JAVA_HOME环境变量： export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_101.jdk/Contents/Homeexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar Mac上Java的安装目录在终端输入which java, 返回的是: “/usr/bin/java” ,/usr/bin/java 是个链接, 指向: “/System/Library/Frameworks/JavaVM.framework/Versions/Current/Commands/java” ,但是我输入echo $JAVA_HOME, 返回： “/Library/Java/JavaVirtualMachines/jdk1.8.0_192.jdk/Contents/Home” ,那么 /System/Library/Frameworks/JavaVM.framework/ 和 /Library/Java/JavaVirtualMachines 哪个才是真正的Java安装目录? 答案是后者, 我发现 “/System/Library/Frameworks/JavaVM.framework/Versions/Current/Commands/“ 下所有的可执行文件大小都是完全相同的,该目录中的二进制文件是确定要使用哪个Java VM的存根应用程序, 可以使用dtrace查看java -version命令调用的全过程: sudo dtrace -n 'syscall::posix_spawn:entry &#123; trace(copyinstr(arg1)); &#125;' -c \"/usr/bin/java -version\"# 返回如下:dtrace: description 'syscall::posix_spawn:entry ' matched 1 probedtrace: pid 44727 has exitedCPU ID FUNCTION:NAME 8 619 posix_spawn:entry /System/Library/Java/JavaVirtualMachines/jdk1.8.0_192.jdk/Contents/Home/bin/java 多版本Java共存管理多版本Java的工具: jEnv 安装 &amp; 配置: # 安装 jenvbrew install jenvmkdir -p ~/.jenv# 添加到你的 shell profile文件:echo 'eval \"$(jenv init -)\"' &gt;&gt; ~/.zshrc 添加 jdk: # jenv add 会在 ~/.jenv/versions 下建立对应 jdk的软链jenv add /Library/Java/JavaVirtualMachines/jdk1.8.0_172.jdk/Contents/Homejenv add /Library/Java/JavaVirtualMachines/jdk-12.0.2.jdk/Contents/Home How to Use: # 列出所有的 jdk$ jenv versions system openjdk12.0.2 oraclejdk1.8.0_172# 使用jdk 12(全局生效)$ jenv global openjdk12.0.2# 使用jdk 12(当前shell生效)$ jenv shell openjdk12.0.2 jenv 在我的MBP上一直有问题, jenv global无效, 港真我还是觉得自己手动修改 $JAVA_HOME 的方式比较好 python环境brew install python ## will install python &amp; pip 由于 macOS 10.13已经预安装了Python 2.7.10, 上面的命令会安装Python3 到/usr/local/Cellar/python/Version并在/usr/local/bin/创建链接:python3, pip3, easy_install-3.6 对于用系统默认easy_install安装的包, 会放在/Library/Python/2.7/site-packages, 所以需要sudo:sudo easy_install tornado 如果不喜欢sudo, 则可以用pip仅在当前用户下安装, 尤其对于需要升级系统自带的package时:pip install --user --upgrade matplotlib easy_install和pip两者都是 setuptools 基础上的工具，pip 比 easy_install 提供更多高级选项, 比如uninstall, freeze golang环境@ref: https://github.com/astaxie/build-web-application-with-golang/blob/master/zh/preface.md php环境brew tap homebrew/phpbrew install php70brew install mcrypt php70-mcryptbrew install composer Add PATH: export PATH=&quot;$(brew --prefix homebrew/php/php70)/bin:$PATH&quot; node环境brew install node ## will install node &amp; npm NPM命令： [[../41.Uncategorized/NPM命令速查]] 下载工具Aira2安装aira2: brew install aria2touch ~/.aria2/aria2.conf 配置文件： 使用下面的token方式rpc-secret=thats_a_token#允许rpcenable-rpc=true#允许所有来源, web界面跨域权限需要rpc-allow-origin-all=true#RPC端口rpc-listen-port=6800 使用aira2: # 使用aria2下载单个文件:/usr/local/bin/aria2c -s10 -x10 &lt;下载url&gt;# 启动 aria2 demon:/usr/local/bin/aria2c --conf-path=/Users/heisenbug/.aria2/aria2.conf -D 使用UI：下载 AriaNg，浏览器打开index.htm（建议加进浏览器收藏夹），第一步先配置参数： RPC地址： http://localhost:6800/jsonrpc 密钥： 即 aria2.conf 中的 rpc-secret 字符串 其他工具 常用开发套件: brew install ctags cscope wget watch tmux cmake openssl geoip automake autoconf 虚拟机: brew cask install virtualbox 压缩工具: brew cask install the-unarchiver 生成SSH公钥 生成ssh key ssh-keygen -t rsa -C &quot;邮箱&quot; 添加到系统: ssh-add ~/.ssh/你的私钥 cURLmacOS 中 Curl 的版本针对 SSL/TLS 验证使用安全传输。如果你更愿意使用 OpenSSL，用 brew install curl --with-openssl 安装并通过 brew link --force curl 确保它是默认的。 Jupyter Notebook升级python3、pip3: pip3 install --upgrade pip 安装: pip install jupyterlabpip install notebook 修改默认目录: jupyter notebook --generate-config # 生成一个新配置文件gvim ~/.jupyter/jupyter_notebook_config.py# 找到c.NotebookApp.notebook_dir 并修改路径, 这里是相对路径(当前用户$HOME) 启动: jupyter notebook 入门: How to Use Jupyter Notebook in 2020: A Beginner’s Tutorial Plotting sine and cosine with Matplotlib and Python - Python for Undergraduate Engineers 系统设置Launchpad 重置 Launchpad 图标数据库：在 Terminal 中键入defaults write com.apple.dock ResetLaunchPad -bool true &amp;&amp; killall Dock 配置文件位置:~/Library/Application\\ Support/Dock/desktoppicture.db Menu Bar Vanilla，精简 Mac 菜单栏应用图标，小巧轻量还免费丨App+1 - 少数派 Dock 重置Dockdefaults delete com.apple.dock; killall Dock Notification Center@todo Finder@todo Spotlight@todo WIFI重启airportd: #/bin/bashairportd_pid=`ps -ef | grep airportd | grep -v grep | awk &apos;&#123;print $2&#125;&apos;`; echo $&#123;airportd_pid&#125;; sudo kill -9 $&#123;airportd_pid&#125;; DNS 缓存如何清理DNS缓存: 如果操作系统是Lion、Mountain Lion和Mavericks+：sudo killall -HUP mDNSResponder 如果操作系统是Leopard和Snow Leopard：sudo dscacheutil -flushcache 定时任务(launchd) launchctl 是一个统一的服务管理框架，可以启动、停止和管理进程、应用程序、脚本等。参考: Creating Launch Daemons and Agents 创建可执行脚本 task.sh 在 ~/Library/LaunchAgents 目录下创建 plist文件: touch ~/Library/LaunchAgents/com.myMac.cron.task.plist 编辑 plist 文件如下: &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE plist PUBLIC &quot;-//Apple//DTD PLIST 1.0//EN&quot; &quot;http://www.apple.com/DTDs/PropertyList-1.0.dtd&quot;&gt;&lt;plist version=&quot;1.0&quot;&gt; &lt;dict&gt; &lt;!-- 唯一plist名字 --&gt; &lt;key&gt;Label&lt;/key&gt; &lt;string&gt;com.myMac.cron.task&lt;/string&gt; &lt;!-- 可执行命令， 第一个为命令，其它为参数 --&gt; &lt;key&gt;ProgramArguments&lt;/key&gt; &lt;array&gt; &lt;string&gt;/Users/xxx/Scripts/task.sh&lt;/string&gt; &lt;/array&gt; &lt;!-- 定时执行 这里的例子每天22点 --&gt; &lt;key&gt;StartCalendarInterval&lt;/key&gt; &lt;dict&gt; &lt;key&gt;Minute&lt;/key&gt; &lt;integer&gt;0&lt;/integer&gt; &lt;key&gt;Hour&lt;/key&gt; &lt;integer&gt;22&lt;/integer&gt; &lt;key&gt;Weekday&lt;/key&gt; &lt;integer&gt;0&lt;/integer&gt; &lt;/dict&gt; &lt;!-- 标准输出和错误输出 --&gt; &lt;key&gt;StandardOutPath&lt;/key&gt; &lt;string&gt;/tmp/cron-task.log&lt;/string&gt; &lt;key&gt;StandardErrorPath&lt;/key&gt; &lt;string&gt;/tmp/cron-task.log&lt;/string&gt; &lt;/dict&gt;&lt;/plist&gt; 加载到系统: launchctl load com.myMac.cron.task.plist; 如果查看所有载入的: launchctl list; 如果需要移除: launchctl unload com.myMac.cron.task.plist, 注：已经载入的任务要先 unload 才可以 load StartCalendarInterval项的解释: &lt;key&gt;Hour&lt;/key&gt;: Hour of the day (0-24). &lt;key&gt;Weekday&lt;/key&gt;: Weekday is the day of the week (0 and 7 == Sunday). &lt;key&gt;Day&lt;/key&gt;: Day is the day of the month. 如果间隔 5 分钟执行：&lt;key&gt;StartInterval&lt;/key&gt;&lt;integer&gt;300&lt;/integer&gt; ➤ 升级后发现的，原本正常执行的 shell 脚本报错 operation not permitted，更改为 chmod 777也不行， ls -l@ script.sh # 查看隐藏的@属性# 或者xattr -l script.sh# 发现多了一行 com.apple.quarantine，删除：sudo xattr -d com.apple.quarantine script.sh 删除了多余属性还是不行… 参考 how to fix “Operation not permitted” when i use launchctl in macos catalina - Stack Overflow 的方案，是因为 Catalina 升级了权限管理，要给 /bin/bash 「full disk access」，想想还是算了吧 Safari推荐扩展\b: AdBlock: 拦截广告 webQR: 当前的地址转换为二维码 Tab Lister: Chrome上的 OneTab, 可以将打开的标签页收纳到一个标签页, 关闭所有标签页节省资源 sVim: 为Safari增加Vim的快捷键 链接 AutoPagerize: 自动再入”下一页” 链接 Reverse Image Search : 图片上右键搜索相似图 链接 WeChat清理微信的存储空间： cd ~/Library/Containers/com.tencent.xinWeChat/Data/Library/Application\\ Support/com.tencent.xinWeChat/2.0b4.0.9/du -d 1 -h | sort -hcd 3592d0142e681d9a9e3333959dae1bad/Messagedu -d 1 -h | sort -h macOS Mojave(10.14)开启子像素抗锯齿升级 macOS Mojave 新系统后，苹果默认关闭了子像素抗锯齿(也称为字体平滑)，导致字体变细锯齿增多。在连接到非Retina显示屏的MacBook Air或桌面Mac上，升级会使您的字体看起来更糟。如果您的Mac带有Retina显示屏，我们不建议启用亚像素抗锯齿功能。 即使没有亚像素抗锯齿，字体在Retina显示屏上看起来也应该看起来不错且可读。 但是，如果您有非Retina显示屏，我们建议您重新启用此功能。像素抗锯齿是一种技巧，旨在使字体在较低分辨率的显示器上看起来更好。 如果默认情况下未启用此功能，则macOS Mojave会使非Retina显示屏上的文本看起来更薄更模糊。虽然默认情况下禁用子像素字体平滑，但您可以使用terminal命令重新启用它。 有四种可能的设置：0（禁用），1（光平滑），2（中等平滑）和3（重平滑）。 打开 【终端】应用，输入下面命令，全局启用 次像素抗锯齿 渲染： defaults write -g CGFontRenderingFontSmoothingDisabled -bool NO 设置字体 次像素抗锯齿 级别 (类似 Linux 的 hintstyle 微调样式) 的命令： defaults -currentHost write -globalDomain AppleFontSmoothing -int 3 查看设置后的选项值： $ defaults read -g CGFontRenderingFontSmoothingDisabled0$ defaults -currentHost read -globalDomain AppleFontSmoothing3 参考: macOS Mojave 字体渲染由默认的灰度抗锯齿改回之前的次像素抗锯齿 macOS Catalina(10.15)升级到 10.15后要做的: xcode-select --install sudo xcodebuild -license accept brew update &amp;&amp; brew upgrade type reload into Alfred to refresh the application cache APFS 文件系统下, macOS的系统路径有了一些变化, 可能对使用者造成困扰:更新 macOS 10.15 你需要知道的APFS 磁盘格式的变化 - 系统分区独立加密 - 知乎 macOS Big Sur(11)TODO 附录OSX系统目录 OneDrice &amp; Dropbox: ~/Library/CloudStorage 当前用户的软件数据目录: ~/Library/Application\\ Support 系统的软件数据目录: /Library/Application\\ Support iCloud云盘在本地的路径: ~/Library/Mobile\\ Documents/com~apple~CloudDocs App 在 iCloud中的文档路径: Obsidian: ~/Library/Mobile\\ Documents/iCloud~md~obsidian/Documents Surge: ~/Library/Mobile\\ Documents/iCloud~run~surge/Documents MWeb: 新版： ~/Library/Containers/com.coderforart.MWeb3/Data/Library/Application\\ Support/MWebLibrary // CloudKit 旧版： ~/Library/Mobile\\ Documents/iCloud~com~coderforart~iOS~MWeb/Documents 自带TextEdit: ~/Library/Mobile\\ Documents/com~apple~TextEdit/Documents 自带Knote: ~/Library/Mobile\\ Documents/com~apple~Keynote/Documents 自带Page: ~/Library/Mobile\\ Documents/com~apple~Pages/Documents 自带便笺: ~/Library/Containers/com.apple.Stickies/Data/Library/Stickies 自启动程序目录 ~/Library/LaunchAgents/ /Library/LaunchAgents/ /Library/LaunchDaemons/ /Library/StartupItems/ /Library/PrivilegedHelperTools/ 参考: 解剖最近被发现的Mac OS木马 – OSX/Keydnap Disable Microsoft OneDrive AutoUpdateHow to Stop Microsoft AutoUpdate on Mac rm -fr /Library/Application Support/Microsoft/MAU2.0rm -fr /Library/LaunchAgents/com.microsoft.update.agent.plistrm -fr /Library/LaunchDaemons/com.microsoft.autoupdate.helper","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"开发环境","slug":"开发环境","permalink":"https://beefyheisenberg.github.io/tags/开发环境/"},{"name":"OSX","slug":"OSX","permalink":"https://beefyheisenberg.github.io/tags/OSX/"},{"name":"macOS","slug":"macOS","permalink":"https://beefyheisenberg.github.io/tags/macOS/"}]},{"title":"《缮写室》 Quick view","slug":"64.Novel-and-Poesy/《缮写室》 Quick-view","date":"2019-05-02T16:00:00.000Z","updated":"2024-01-24T01:27:54.105Z","comments":true,"path":"64.Novel-and-Poesy/《缮写室》 Quick-view/","link":"","permalink":"https://beefyheisenberg.github.io/64.Novel-and-Poesy/《缮写室》 Quick-view/","excerpt":"原书豆瓣链接：缮写室 (豆瓣) 《缮写室》 Quick view 天堂是缮写室的模样1：缮写士、旷野恐惧症 （ [[../53.Photograph/使用谷歌街景进行街拍]] 中提到了摄影师 Jacqui Kenny 的“广场恐惧症”） 《世界之步: 中世纪地图鸟瞰》某种地图并非为了指路, 而是为了让人迷失在符号和色彩之中：中世纪的【T-O地图】，地图边缘的插画是欧洲版本的《山海经》 《无处流浪的吉普赛人》: gyp词根、罗姆人，大篷车、集体回忆口授之书 《不要在中世纪花园入眠》: 中世纪出现的”梦幻诗”, 可能是在宗教夹缝中 冒出来的对孤独和自恰这种完美状态的渴望的隐喻表达","text":"原书豆瓣链接：缮写室 (豆瓣) 《缮写室》 Quick view 天堂是缮写室的模样1：缮写士、旷野恐惧症 （ [[../53.Photograph/使用谷歌街景进行街拍]] 中提到了摄影师 Jacqui Kenny 的“广场恐惧症”） 《世界之步: 中世纪地图鸟瞰》某种地图并非为了指路, 而是为了让人迷失在符号和色彩之中：中世纪的【T-O地图】，地图边缘的插画是欧洲版本的《山海经》 《无处流浪的吉普赛人》: gyp词根、罗姆人，大篷车、集体回忆口授之书 《不要在中世纪花园入眠》: 中世纪出现的”梦幻诗”, 可能是在宗教夹缝中 冒出来的对孤独和自恰这种完美状态的渴望的隐喻表达 1.S01.博尔赫斯：“关于天赐的诗——天堂应该是图书馆的模样” ↩","categories":[{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"}],"tags":[{"name":"小说摘录","slug":"小说摘录","permalink":"https://beefyheisenberg.github.io/tags/小说摘录/"}]},{"title":"GitBook 使用指北","slug":"50.Farbox-Blog/【效率工具】GitBook使用指北","date":"2018-05-24T16:00:00.000Z","updated":"2024-01-24T01:27:53.078Z","comments":true,"path":"50.Farbox-Blog/【效率工具】GitBook使用指北/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【效率工具】GitBook使用指北/","excerpt":"安装cli: mkdir GitBook &amp;&amp; cd GitBook &amp;&amp; npm install gitbook-cli -g 查看是否安装成功: gitbook -V 创建书籍目录: bookRoot├── 1-FirstChapter // The first chapter，format: &#123;orderNumber or alphabet&#125;-&#123;chapterName&#125;.md├────── 1-FirstDocument.md├────── 5-SecondDocument.md // concentrating solely on the order, not the numbers.├── 3-SecondChapter // Focus only on the order, not the numbers.├────── 1-FirstDocumentOfSecondChapter.md├────── 2-SecondDocumentOfSecondChapter.md├── 7-ThirdChapter├── FourthChapter // May have no order├── README.md // In addition to readme.md, not to put other markdown documents└── book.json // Set up the book 安装SUMMARY.md自动生成插件: npm install -g gitbook-summary","text":"安装cli: mkdir GitBook &amp;&amp; cd GitBook &amp;&amp; npm install gitbook-cli -g 查看是否安装成功: gitbook -V 创建书籍目录: bookRoot├── 1-FirstChapter // The first chapter，format: &#123;orderNumber or alphabet&#125;-&#123;chapterName&#125;.md├────── 1-FirstDocument.md├────── 5-SecondDocument.md // concentrating solely on the order, not the numbers.├── 3-SecondChapter // Focus only on the order, not the numbers.├────── 1-FirstDocumentOfSecondChapter.md├────── 2-SecondDocumentOfSecondChapter.md├── 7-ThirdChapter├── FourthChapter // May have no order├── README.md // In addition to readme.md, not to put other markdown documents└── book.json // Set up the book 安装SUMMARY.md自动生成插件: npm install -g gitbook-summary 执行 book sm , 自动生成 SUMMARY.md 创建 book.json &#123; \"title\": \"xxx\", \"description\": \"\", \"author\": \"\", \"language\": \"zh-hans\", \"ignores\": [ \"_book\", \"node_modules\" ], \"plugins\": [ \"outline\" ]&#125; 生成html: gitbook build ,运行该命令后会生成 _book 文件夹, 里面的内容即为生成的 html 文件 本地预览: gitbook serve，然后在浏览器地址栏中输入 http://localhost:4000 生成pdf:","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://beefyheisenberg.github.io/tags/Git/"},{"name":"Github","slug":"Github","permalink":"https://beefyheisenberg.github.io/tags/Github/"},{"name":"GitBook","slug":"GitBook","permalink":"https://beefyheisenberg.github.io/tags/GitBook/"}]},{"title":"在Macbook上使用Surge","slug":"50.Farbox-Blog/【效率工具】在Macbook上使用surge","date":"2016-09-13T16:00:00.000Z","updated":"2024-01-24T01:27:53.128Z","comments":true,"path":"50.Farbox-Blog/【效率工具】在Macbook上使用surge/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【效率工具】在Macbook上使用surge/","excerpt":"安装surgeSurge for Mac并不提供公开下载, 只对已经在手机上购买过Surge for iPhone的用户提供beta版本,在Surge for iPhone的’More’标签找到Surge Mac, 下载链接会被发送到注册邮箱. 导出Surge iPhone的配置文件Surge iPhone的配置文件是通用的, 可以直接使用在Surge for Mac上.导出方法很多, 可以通过url共享, dropbox, 或者iTunes导出. 配置Surge","text":"安装surgeSurge for Mac并不提供公开下载, 只对已经在手机上购买过Surge for iPhone的用户提供beta版本,在Surge for iPhone的’More’标签找到Surge Mac, 下载链接会被发送到注册邮箱. 导出Surge iPhone的配置文件Surge iPhone的配置文件是通用的, 可以直接使用在Surge for Mac上.导出方法很多, 可以通过url共享, dropbox, 或者iTunes导出. 配置Surge第一次启动Surge会询问配置文件保存在哪里, 我直接选择的”Documents”,进入~/Documents/Surge/目录, 把配置文件覆盖为Default.conf. 状态栏点击surge图标, 有下面几个选项 : Switch configuration: 可以重新选择surge配置的保存路径. Reload configuration: 如果修改了配置文件, 需要reload一下. Set as System Proxy: 选中此选项后, Surge会成为默认的http和socks代理. surge在Macbook本地启动两个端口,6152和6153, 前者是http/https代理端口, 后者是socks5代理端口. 可以通过命令 lsof -i :6152确认这两个端口有没有被打开. 第三方应用的设置 Dropbox: 代理设置为socks, 127.0.0.1:6153 Chrome SwitchyOmega: 设置为”系统代理”","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"OSX","slug":"OSX","permalink":"https://beefyheisenberg.github.io/tags/OSX/"},{"name":"macOS","slug":"macOS","permalink":"https://beefyheisenberg.github.io/tags/macOS/"},{"name":"Surge","slug":"Surge","permalink":"https://beefyheisenberg.github.io/tags/Surge/"},{"name":"Proxy","slug":"Proxy","permalink":"https://beefyheisenberg.github.io/tags/Proxy/"},{"name":"Shadowsocks","slug":"Shadowsocks","permalink":"https://beefyheisenberg.github.io/tags/Shadowsocks/"}]},{"title":"使用fluentd,kafka,mongodb搭建日志处理系统","slug":"50.Farbox-Blog/【架构】使用fluentd,kafka,mongodb搭建日志处理系统","date":"2016-09-04T10:58:00.000Z","updated":"2024-01-24T01:27:53.119Z","comments":true,"path":"50.Farbox-Blog/【架构】使用fluentd,kafka,mongodb搭建日志处理系统/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【架构】使用fluentd,kafka,mongodb搭建日志处理系统/","excerpt":"设计实现 采集: 可选的有fluentd, td-agent(fluentd的稳定版本, 二者区别), Apache flume. 消息持久化队列: http://kafka.apache.org/ (分布式消息队列), 数据源进行topic分流，实现Category 作为一层buffer来适配输入输出的消息速率，解除系统耦合度 作用类似于缓存，即活跃的数据和离线处理系统之间的缓存 kafka是显式分布式架构，producer、broker（Kafka）和consumer都可以有多个。Kafka的作用类似于缓存，即活跃的数据和离线处理系统之间的缓存。几个基本概念： message（消息）是通信的基本单位，每个producer可以向一个topic（主题）发布一些消息。如果consumer订阅了这个主题，那么新发布的消息就会广播给这些consumer。 Kafka是显式分布式的，多个producer、consumer和broker可以运行在一个大的集群上，作为一个逻辑整体对外提供服务。对于consumer，多个consumer可以组成一个group，这个message只能传输给某个group中的某一个consumer. 存储: mongo Fluentd(td-agent)Fluentd内置三种日志采集, file-tail, tcp, http-url, 通过插件可以支持更多的采集方式. Install fluentd(td-agent) by RPM","text":"设计实现 采集: 可选的有fluentd, td-agent(fluentd的稳定版本, 二者区别), Apache flume. 消息持久化队列: http://kafka.apache.org/ (分布式消息队列), 数据源进行topic分流，实现Category 作为一层buffer来适配输入输出的消息速率，解除系统耦合度 作用类似于缓存，即活跃的数据和离线处理系统之间的缓存 kafka是显式分布式架构，producer、broker（Kafka）和consumer都可以有多个。Kafka的作用类似于缓存，即活跃的数据和离线处理系统之间的缓存。几个基本概念： message（消息）是通信的基本单位，每个producer可以向一个topic（主题）发布一些消息。如果consumer订阅了这个主题，那么新发布的消息就会广播给这些consumer。 Kafka是显式分布式的，多个producer、consumer和broker可以运行在一个大的集群上，作为一个逻辑整体对外提供服务。对于consumer，多个consumer可以组成一个group，这个message只能传输给某个group中的某一个consumer. 存储: mongo Fluentd(td-agent)Fluentd内置三种日志采集, file-tail, tcp, http-url, 通过插件可以支持更多的采集方式. Install fluentd(td-agent) by RPM$ curl -L http://toolbelt.treasuredata.com/sh/install-redhat.sh | sh Install plugins参考 http://blog.csdn.net/virusfu/article/details/9023237安装插件: $ /usr/lib64/fluent/ruby/bin/gem install fluent-plugin-kafka查看已安装的插件: $ /usr/lib64/fluent/ruby/bin/gem list | grep fluent-plugin- Setup参考 http://docs.fluentd.org/articles/config-file and http://www.r66r.net/?p=504 编辑 /etc/td-agent/td-agent.conftd-agent和fluent不同之一就是: td配置文件默认输出到Treasure Data, 需要去掉配置文件里这部分.td配置文件里重要的标签有三种: source： 输入源 match ：输出目的地 include：包含其它配置文件等下面是一个采集source(file-tail日志)的例子: &lt;source&gt; type tail format apache path /etc/httpd/logs/access_log pos_file /tmp/td-agent/access_access.pos tag apache.access&lt;/source&gt; 解释: type: tail文件追加, 或者http, forward等, 也可以使用插件输入: type tail_ex format: 使用td-agent内置的apach日志解析规则 patch: 日志文件路径 post_file: 建议使用这个参数, post_file保存读取log的长度, 在下次宕机重启后能继续收集 tag: 用于match td-agent支持三种形式的日志采集, 不同的日志source配置也不同, 上面是file-tail的方式采集日志, 如果用http方式采集日志, 参考 http://docs.fluentd.org/articles/in_http ;source配置如下:&lt;source&gt; type http port 8994 # td-agent采集监听的port tag http8994.access&lt;/source&gt; 测试命令: curl -X POST -d &#39;json={&quot;action&quot;:&quot;login&quot;,&quot;user&quot;:2}&#39; http://10.11.0.9:8994/forum.php match:&lt;match apache.access&gt; type file path /tmp/td-agent/access_access.match&lt;/match&gt; 解释:path输出的文件名, 默认生成名为”$path.日期.xxxx” 的文件. Start up $ /etc/init.d/td-agent start //启动 $ /etc/init.d/td-agent status //状态查看 $ /etc/init.d/td-agent reload //不重启重新载入配置td-agent执行日志在: /var/log/td-agent/td-agent.log 附例:下面是一个输出到mongo的match例子: &lt;match mongo.**&gt;# plugin typetype mongo# mongodb db + collectiondatabase apachecollection access# mongodb host + porthost localhostport 27017# intervalflush_interval 10s&lt;/match&gt; fluent-plugin-kafkahttps://github.com/htgc/fluent-plugin-kafka 例: match使用grep过滤, 并用tag发送到Kafka&lt;source&gt;type tailpath /home/wyyhzc/webApp.logpos_file /home/wyyhzc/webApp.log.postag webappformat /^(?&lt;message&gt;(.*))$/&lt;/source&gt; 过滤一次: &lt;match webapp.**&gt; // 注意&quot;webapp.*&quot;符合&quot;webapp.a&quot;, 但不符合&quot;webapp&quot;和&quot;webapp.a.b&quot;. &quot;webapp.**&quot;符合前面所有type grep // fluent-plugin-grep插件regexp1 code ^4\\d\\d$exclude1 referer ^https?://yourdomain.comadd_tag_prefix webapp_filtered // 为这个match加tag&lt;/match&gt; 发送到kafka&lt;match webapp_filtered.**&gt; // 对应上面的tagtype kafkabrokers hadoopdn1:9092 // kafka-serverdefault_topic webapp_log // topicoutput_data_type json // 可选(json|ltsv|msgpack|attr:&lt;record name&gt;)output_include_tag falseoutput_include_time flase&lt;/match&gt; KafkaApache Kafka是用于发布—订阅消息传递，实现了分布式提交日志，适用于离线和在线消息消费。 消息的发布（publish）称作producer生产者，消息的订阅（subscribe）称作consumer消费者，中间的存储阵列称作broker。生产者将消息发布到Kafka主题，消费者订阅这些主题并消费这些消息。 多个broker协同合作，producer、consumer和broker三者之间通过zookeeper来协调请求和转发 producer产生和推送(push)数据到broker，consumer从broker拉取(pull)数据并进行处理 Install kafka (参考http://kafka.apache.org/documentation.html)安装方式有两种, 自己通过源码编译kafka, 或者直接在apache下载编译好的二进制文件. 编译安装:tar xzf kafka-&lt;VERSION&gt;.tgzcd kafka-&lt;VERSION&gt;sbt updatesbt packagesbt assembly-package-dependencyKafka是用Scala写的，SBT是Simple Build Tool的简称，类似于Java的Maven。 下载二进制文件wget http://apache.mirrors.hoobly.com/kafka/0.8.1.1/kafka_2.8.0-0.8.1.1.tgz通过java -version查看JVM是32bit or 64 bit, 如果安装了32位的HotSpot VM，需要修改/bin/kafka-run-class.sh文件 去掉KAFKA_JVM_PERFORMANCE_OPTS的”-XX:+UseCompressedOops” 参数. 启动zookeeper和kafka进程Kafka需要zookeeper服务, 如果没有安装zookeeper, 可以启动kafka自带的单点zookeeper: 启动zookeeper: $ nohup bin/zookeeper-server-start.sh config/zookeeper.properties &amp; 启动kafka: $ nohup bin/kafka-server-start.sh config/server.properties &amp;停止kafka: bin/kafka-server-stop.sh停止zookeeper: bin/zookeeper-server-stop.sh Zookeeper集群部署参考: http://cn.soulmachine.me/blog/20140207/ http://blog.csdn.net/shirdrn/article/details/7183503 单机测试命令(可略过) 创建topicmessage以topic(主题)为单位, productor可以向某个topic发送消息, consumer可以订阅topic;bin/kafka-topics.sh –create –zookeeper localhost:2181 –replication-factor 1 –partitions 1 –topic test # 连接本机2181端口的zookeeper-servebin/kafka-topics.sh –list –zookeeper localhost:2181 # 查看已创建的topicbin/kafka-topics.sh –describe –zookeeper localhost:2181 –topic test # 查看topic的描述 启动msg消费者bin/kafka-console-consumer.sh –zookeeper localhost:2181 –topic test –from-beginning # 启动msg生产者新启动Terminal输入:bin/kafka-console-producer.sh –broker-list localhost:9092 –topic test然后输入一些测试消息并回车, 可以看到消费者log对msg进行消费.测试完成. kafka和zookeeper集群参考 http://kafka.apache.org/documentation.html修改./config/server.properties下列参数: broker.id=0 # 区分多个Kafkaport=9092 #log.dir=/tmp/kafka-logs #zookeeper.connect=nutch1:2181 # zookeeper集群地址 kafka-server配置文件参考 http://kafka.apache.org/documentation.html // Broker Configs Topic配置参考 http://kafka.apache.org/documentation.html // Topic-level configuration Consumer配置参考: http://kafka.apache.org/documentation.html // Consumer Configs , 重要参数group.id / zookeeper.connect Producer配置参考: http://kafka.apache.org/documentation.html // Producer Configs, 启动kafka : bin/kafka-server-start.sh config/server.properties 当然也可以在一台机器上启动多个kafka-server, 要修改上面的port和log.dir以区分不同的kafka-server, 步骤: cp config/server.properties config/server-1.propertiescp config/server.properties config/server-2.properties 修改上面两个properties文件, 启动:bin/kafka-server-start.sh config/server-1.properties &amp;bin/kafka-server-start.sh config/server-2.properties &amp; 参考: fluentd+kafka+mongo: http://noops.me/?p=1325 Fluentd + MongoDB http://blog.nosqlfan.com/html/3521.html kafka介绍: http://dongxicheng.org/search-engine/kafka/ http://my.oschina.net/ielts0909/blog/92972 http://www.biaodianfu.com/kafka.html kafka部署: http://shift-alt-ctrl.iteye.com/blog/1930791 tdagent: http://www.r66r.net/?p=504 flume-ng+Kafka+Storm+HDFS 实时系统搭建 http://blog.csdn.net/weijonathan/article/details/18301321 flume+kafka+storm+mysql架构设计 http://blog.csdn.net/mylittlered/article/details/20810265 基于Flume的美团日志收集系统(一)架构和设计 http://tech.meituan.com/mt-log-system-arch.html 使用Fluentd + MongoDB构建实时日志收集系统 http://blog.nosqlfan.com/html/3521.html","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://beefyheisenberg.github.io/tags/Linux/"},{"name":"Kafka","slug":"Kafka","permalink":"https://beefyheisenberg.github.io/tags/Kafka/"},{"name":"日志处理","slug":"日志处理","permalink":"https://beefyheisenberg.github.io/tags/日志处理/"},{"name":"Fluentd","slug":"Fluentd","permalink":"https://beefyheisenberg.github.io/tags/Fluentd/"},{"name":"Flume","slug":"Flume","permalink":"https://beefyheisenberg.github.io/tags/Flume/"}]},{"title":"为Eclipse安装 Terminal","slug":"50.Farbox-Blog/【编辑器】为Eclipse安装Remote-System-Explorer","date":"2016-08-23T16:00:00.000Z","updated":"2024-01-24T01:27:53.073Z","comments":true,"path":"50.Farbox-Blog/【编辑器】为Eclipse安装Remote-System-Explorer/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【编辑器】为Eclipse安装Remote-System-Explorer/","excerpt":"","text":"IDEA的Terminal很方便, 但Eclipse没有.还是比较习惯敲命令行. Eclipse工具栏 -&gt; Run -&gt; Extrnal Tools -&gt; Configurations , 新建一个:Location填入C:\\Windows\\System32\\cmd.exe, Working Directory : ${project_loc} 参考Is there an Eclipse plugin to run system shell in the Console?","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"IDE","slug":"IDE","permalink":"https://beefyheisenberg.github.io/tags/IDE/"},{"name":"Eclipse","slug":"Eclipse","permalink":"https://beefyheisenberg.github.io/tags/Eclipse/"}]},{"title":"在 Windows 下使用 vim grep 的正确姿势","slug":"50.Farbox-Blog/【Vim】在Windows下使用vim-grep的正确姿势","date":"2016-08-01T15:53:00.000Z","updated":"2024-01-24T01:27:53.044Z","comments":true,"path":"50.Farbox-Blog/【Vim】在Windows下使用vim-grep的正确姿势/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【Vim】在Windows下使用vim-grep的正确姿势/","excerpt":"首先, 开发环境是Windows,然后, 我又是一个信仰坚定的Vimer,所以就出现了Windows + Gvim这个有些不太协调的组合, 想在盖茨叔叔的视窗OS上稍微正常的使用Gvim还是有些小麻烦, 可是这都难不倒一个有信仰的Vimer. PS 如果你使用Osx or Linux, 大可不必这样折腾, 直接使用ack.vim 或 grep.vim吧, 简单的配置就可以搞定. 在Win上使用grep的可选方案在Windows上使用grep搜索文本有以下几种方案: 使用grep命令, 虽是GNU下的工具, 但也有Win移植版; 使用vim内置的vimgrep命令, 速度最慢但是兼容性相对好; 使用Win下的原生命令findstr; 使用Win移植版的ack, 这种方法我没尝试过, 如果你用过了, 请一定告诉我:P","text":"首先, 开发环境是Windows,然后, 我又是一个信仰坚定的Vimer,所以就出现了Windows + Gvim这个有些不太协调的组合, 想在盖茨叔叔的视窗OS上稍微正常的使用Gvim还是有些小麻烦, 可是这都难不倒一个有信仰的Vimer. PS 如果你使用Osx or Linux, 大可不必这样折腾, 直接使用ack.vim 或 grep.vim吧, 简单的配置就可以搞定. 在Win上使用grep的可选方案在Windows上使用grep搜索文本有以下几种方案: 使用grep命令, 虽是GNU下的工具, 但也有Win移植版; 使用vim内置的vimgrep命令, 速度最慢但是兼容性相对好; 使用Win下的原生命令findstr; 使用Win移植版的ack, 这种方法我没尝试过, 如果你用过了, 请一定告诉我:P 使用 grep.vim虽然grep.vim插件也可以在Windows上使用, 插件也提供了一些Win下使用的选项, 但grep.vim这款插件调用的是grep命令, Win上没有grep, 怎么办?后来找到了grep在Win平台的移植版: GnuWin相关设置选项参考这里: grep.vim : Grep search tools integration with Vim , 在页面上搜索”MS-Windows”就可以看到for Windows的特殊选项.不过,移植版的grep也有很多兼容问题, 略过不表233什么, 你问我为什么不早说, 因为我一写博客就容易啰嗦…好吧. 接下来说另一种使用vimgrep的方案: 使用 EasyGrep之前有过一篇介绍: vim中的杀手级插件: EasyGrep,EasyGrep使用的是vim内置的搜索命令vimgrep, 相比上面说的移植版grep, vimgrep 在Win上兼容性要大大好于上面的grep移植版.不过EasyGrep提供了一个比较友好的搜索选项界面, 就像下面这个样子, 调整搜索选项是不是要比grep.vim直观许多?vimgrep的最大问题是搜索效率, 真的很差, 尤其你要搜索的目录里有成百上千的文件时.这时候可以切到Chrome里刷一会知乎…但刷完知乎后却发现vimgrep仍旧在努力的转动你的硬盘… 所以我又放弃了EasyGrep. 使用 findstr.vimWindows下提供了一个原生命令findstr, 相当于Linux下的grep.如果你想了解一下findstr命令的使用姿势, 可以看这里: Findstr - TechNet - Microsoft在vim.org上也找了一个为findstr写的插件 – findstr.vim : Using MS-Windows findstr utility to search for text with Vim 看来在Windows上用Vim的可怜人儿还不少, 我觉得这款插件的作者就是一个:(不过这插件简直可算得上朴素, 只提供了四个插件命令, 我觉得跟手动敲findstr命令行效率差不多, 可是我懒且健忘, 记不住这么多findstr参数,等等, 刚才聊到的EasyGrep的搜索选项界面不是挺方便的嘛, 所以, 为什么不能把EasyGrep的搜索界面搬到findstr.vim上来?恩, 对于程序员来说这并不难, vimscript似乎有些像shell和php的结合语言. 所以… 改进后的findstr.vim靠着google和勤勉的copy, 一个带有良好人机交互的多功能findstr.vim被提交到了github上(666)Github repository在这里: https://github.com/whatrtos/findstr.vim 在vimrc里新增一行配置:nmap &lt;leader&gt;gg :VimFindstr&lt;CR&gt; 这样, 在普通模式按下\\gg就可以愉快的使用findstr了. 参考 vim中的杀手级插件: EasyGrep Find in files within Vim 附: vimgrep命令vimgrep命令格式如下:vimgrep /搜索字符串/gj 文件 上面的g和j参数都是可选的, /g : 加上g参数的话, 如果一行有多个匹配, 那么这些匹配会都出现在搜索结果里, 所以一般不用加/g参数; /j : 如果不加j参数, 执行完vimgrep会自动跳转到第一个匹配处, 所以一般都会加上/j参数; 比如vimgrep /keyword/j *.php表示仅在当前目录下的所有php文件里搜索”keyword”, 且不自动跳转到搜索结果.如果也要在子目录递归搜索, **表示在当前目录以及子目录递归, 比如**/*.php 一些栗子: 当前目录下递归搜索: vimgrep /字符串/j **/*.php 仅当前目录, 不递归: vimgrep /字符串/g *.php 如果要搜索多个文件扩展名, 用空格分开即可: vimgrep /字符串/j **/*.cpp **/*.php Linux绝对路径, 递归搜索: vimgrep /字符串/j /home/user/**/*.cpp Win绝对路径, 递归搜索: vimgrep /字符串/j D:\\home\\user/**/*.cpp 补充@2016-08-01 发现一个问题, findstr.vim试用的是system(cmd)来执行findstr命令, 正常情况下这是没什么问题的, 但当遇到中文目录的时候, system执行的结果中的中文会变成”“这样的代码. 所以搜索在中文目录会很蛋疼, 在quickfix里跳转不到正确的文件.折中的办法是, 插件新增一个选项, 可以在使用findstr和vimgrep之间切换(最终还是没能摆脱vimgrep), 一般情况下推荐使用效率更高的findstr, 只有当遇到上面的问题时才使用”slowly but compatible”的vimgrep. findstr迭代了几个版本, 修改了一些bug和改进易用性, 欢迎fork, 提交pr和issue:) 讲一个笑话, 从前森林里有只猴子, 为了能更方便的吃到樱桃, 所以这只猴子自己种了一棵樱桃树.","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"开发环境","slug":"开发环境","permalink":"https://beefyheisenberg.github.io/tags/开发环境/"},{"name":"Vim","slug":"Vim","permalink":"https://beefyheisenberg.github.io/tags/Vim/"},{"name":"Windows","slug":"Windows","permalink":"https://beefyheisenberg.github.io/tags/Windows/"}]},{"title":"MarkEditor使用体验","slug":"50.Farbox-Blog/【Markdown】MarkEditor使用体验","date":"2016-07-28T14:47:00.000Z","updated":"2024-01-24T01:27:53.008Z","comments":true,"path":"50.Farbox-Blog/【Markdown】MarkEditor使用体验/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【Markdown】MarkEditor使用体验/","excerpt":"一直用Sublime + Dropbox的组合来写Markdown笔记. 这个组合看起来有点怪异,Sublime是使用体验最好的编辑器(安装了MarkdownEditting和MarkdownPreview插件),Dropbox是使用体验最好的同步工具,但”最佳编辑器”+”最佳同步工具”的组合并非那样无懈可击.相比Evernote,有道云笔记, Sublime+Dropbox的组合在移动端阅读和检索略有不便, 但同步速度和编辑体验简直甩大象有道这两位”全职笔记”几条街. 试用了farbox.com推出的markdown编辑器–MarkEditor使用体验非常棒, 几乎是我使用过的最好的markdown编辑器 支持工作目录和标签, 对于我这种经常要在多个Markdown笔记来回切换的人来说, 非常方便. 漂亮的语法高亮. 方便的TOC导航侧边栏 图片管理 但也有一些Bug和功能上的不完备, 这也是让我最终决定暂不购买MarkEditor付费版的原因:","text":"一直用Sublime + Dropbox的组合来写Markdown笔记. 这个组合看起来有点怪异,Sublime是使用体验最好的编辑器(安装了MarkdownEditting和MarkdownPreview插件),Dropbox是使用体验最好的同步工具,但”最佳编辑器”+”最佳同步工具”的组合并非那样无懈可击.相比Evernote,有道云笔记, Sublime+Dropbox的组合在移动端阅读和检索略有不便, 但同步速度和编辑体验简直甩大象有道这两位”全职笔记”几条街. 试用了farbox.com推出的markdown编辑器–MarkEditor使用体验非常棒, 几乎是我使用过的最好的markdown编辑器 支持工作目录和标签, 对于我这种经常要在多个Markdown笔记来回切换的人来说, 非常方便. 漂亮的语法高亮. 方便的TOC导航侧边栏 图片管理 但也有一些Bug和功能上的不完备, 这也是让我最终决定暂不购买MarkEditor付费版的原因: 在日间/夜间模式切换, 光标君偶尔会消失, 没了闪烁的光标君我真不知道写到哪儿了 缺少整个目录的搜索功能; 偶然的卡顿; 所以, 还是继续用Sublime+Dropbox写笔记吧😁","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"https://beefyheisenberg.github.io/tags/Markdown/"}]},{"title":"关于闪光灯你应该知道的一些事","slug":"53.Photograph/关于闪光灯你应该知道的一些事","date":"2016-04-30T02:45:00.000Z","updated":"2024-01-24T01:27:53.651Z","comments":true,"path":"53.Photograph/关于闪光灯你应该知道的一些事/","link":"","permalink":"https://beefyheisenberg.github.io/53.Photograph/关于闪光灯你应该知道的一些事/","excerpt":"(一) 快门的前帘与后帘单反上的快门都属于焦平面快门(区别镜间快门)，了解闪光同步速度之前，要先了解单反的快门的工作原理。快门的机械部件最高可以在1/200秒内扫过整个感光元件 ，这个1/200s大概是目前单反的快门的极限，也叫闪光同步速度。所以，闪光同步速度是单反机身的性能参数，而不是闪光灯的性能参数。如果单反的同步速度只有1/200秒，那么如若需要更高速度的快门，比如1/4000或更高的快门速度，应该如何实现呢? 如果把快门做成一条狭缝，这个狭缝扫过整个感光元件需要1/200秒，感光元件上每行像素点受到光照时间就可以做到小于1/200秒了，只要狭缝做的足够窄，也可以实现1/4000秒的高速快门。焦平面快门有两个门帘，第一个门帘先移动，第二门帘立刻跟上，就相当于上面的”狭缝”了。 假设机身的快门机械部分扫过整个CMOS的最短需要1/200秒，那么低于1/200的快门速度，我们称之为”低速快门”，高于1/200的快门就需要以前后帘以”狭缝”的方式实现，也叫”高速快门”。 低速快门：前帘落下，快门完全打开，CMOS完全曝光，然后后帘落下。 高速快门：前帘落下，后帘立刻跟上，前后帘之间只有一条狭缝，相当于光线通过狭缝，从上至下扫描过CMOS，这整个扫描过程大约是1/200秒。这里的1/200秒就是单反机身的闪光同步速度。","text":"(一) 快门的前帘与后帘单反上的快门都属于焦平面快门(区别镜间快门)，了解闪光同步速度之前，要先了解单反的快门的工作原理。快门的机械部件最高可以在1/200秒内扫过整个感光元件 ，这个1/200s大概是目前单反的快门的极限，也叫闪光同步速度。所以，闪光同步速度是单反机身的性能参数，而不是闪光灯的性能参数。如果单反的同步速度只有1/200秒，那么如若需要更高速度的快门，比如1/4000或更高的快门速度，应该如何实现呢? 如果把快门做成一条狭缝，这个狭缝扫过整个感光元件需要1/200秒，感光元件上每行像素点受到光照时间就可以做到小于1/200秒了，只要狭缝做的足够窄，也可以实现1/4000秒的高速快门。焦平面快门有两个门帘，第一个门帘先移动，第二门帘立刻跟上，就相当于上面的”狭缝”了。 假设机身的快门机械部分扫过整个CMOS的最短需要1/200秒，那么低于1/200的快门速度，我们称之为”低速快门”，高于1/200的快门就需要以前后帘以”狭缝”的方式实现，也叫”高速快门”。 低速快门：前帘落下，快门完全打开，CMOS完全曝光，然后后帘落下。 高速快门：前帘落下，后帘立刻跟上，前后帘之间只有一条狭缝，相当于光线通过狭缝，从上至下扫描过CMOS，这整个扫描过程大约是1/200秒。这里的1/200秒就是单反机身的闪光同步速度。 图1：低速（左）和高速快门（右）示意图: 图2：看个更直观的不同快门速度拍摄过程的示意图（第一行的是高速快门，第二行是低速快门）： 了解了单反的闪光同步速度，我们再聊闪光系统。 (二) 闪光灯的特性闪光灯并不是一瞬间就能达到最高亮度的，电容充放电需要时间，来看下图中闪光强度和时间的关系，下图中纵坐标是闪光强度，横坐标是持续时间，大约为1/1000秒数量级，远远小于快门的1/200秒 ： 我们在使用闪光灯时经常接触到的一个参数: 闪光持续时间（T=0.5）T=1的时候闪光灯达到最大亮度，T=0.5被称作半峰值。纵坐标第二次到达T=0.5光强度时所需时间，即被称作闪光持续时间（T=0.5）。但是要注意，上面的“闪光持续时间”并不是真正的闪光持续时间，从上图可以看到第二次T=0.5之后，还有相当的光照强度，直到T=0.1剩下的光量才忽略不计。这段时间大约为3倍闪光持续时间（T=0.5） 除了强度上的波形变化，闪光的色温也在随电流能力的高低发生着漂移。所有的闪光灯会在闪光开始的瞬间产生色温相对高的蓝色光，转而是色温低的红色光。高色温是短波蓝光偏多，低色温则反之。若一只闪光灯的闪光持续时间（T=0.5） 整体超越了快门时间（假设快门为1/200），后期的低色温便不能进入相机曝光，闪光在整体上就出现了色温偏高（冷）的现象。 (三) 闪光灯和快门速度的关系上面了解到，单反无论使用低速快门还是高速快门，整个过程都不会小于1/200秒，也就是机械部分的极限。但是要知道，闪光灯发光的持续时间是很短的，大约为1/1000秒。试想一下，如果闪光持续时间不够1/200秒就结束了，机械狭缝还没来得及走完整个感光元件，会导致什么样的情况？ 比如下图：左边两张，快门速度低于1/200秒的情况下，整个画面都能被闪光灯打亮。当快门速度高于1/200以后（右边几张更明显），会出现黑色的欠曝区域。在前帘刚刚打开，狭缝刚刚通过CMOS最左的时候，闪光灯开始闪光，画面左侧被打亮，然后闪光灯结束，剩下的右半边CMOS都没有被闪光灯打到，所以是黑色。 (四) 闪光灯的高速同步如果要使用高速快门，又要闪光灯把整个CMOS区域都照亮，这里就要用到闪光灯的高速同步模式，注意区别上面的“闪光同步速度”。闪光高速同步指的是，前后帘运行期间这1/200秒内，闪光灯以每秒5W次的频率高速闪光，直至后帘完全关闭。 闪光灯正常模式和高速同步的工作模式如下图所示 以上图为例：上面一组是低于1/200快门速度的正常闪光模式。下面一组是闪光灯的高速同步模式，闪光灯发出高频闪光，在快门狭缝扫过整个CMOS期间一直频闪，使整个CMOS都被照亮。因为高频闪光的强度远低于瞬间闪光，所以高速同步模式下闪光强度非常小，远不如第一种普通闪光。 闪光灯高速同步最常见的作用，比如在大晴天的正午下拍摄大光圈的糖水片，这种情况下光线非常充足，又要使用大光圈拍摄（获得浅景深的虚化效果），快门速度会非常快，大约1/4000秒，这个速度高于闪光同步速度（1/200秒），这时候就需要闪光灯的高速同步来补光。 来举个例子：例如一张照片的正确曝光值为：ISO 100， F16， 1/125秒， 闪灯TTL自动补光。如果我们想要得到一定的背景虚化效果，我们可以使用高速同步，将参数设置为: ISO 100， F2.8， 1/4000秒，闪光灯TTL高速模式进行补光。 这时将得到一个正常曝光背景虚化的画面。 注意上面最右边的一张，这张图片非常有意思，明明是在晴朗的户外拍摄，但是背景显得非常昏暗，看起来像是夜晚。如果拍出了这样的照片一定不要惊奇，这是因为你的快门速度太快了，环境光不足以正常曝光，所以背景显得昏暗，但是拍摄主体被闪光灯打亮，所以得到一张背景欠曝，主体正常曝光的图片，这也就是常说的用闪光灯进行“压光”。 所以，关于闪光灯的高速同步，不具备高速同步的闪光灯快门速度一般只能上到200-250的样子，而具备此功能的闪光灯可以同步快门速度至4000-8000甚至更高。 (五) 使用闪光灯拍摄高速运动的物体这种情况下真的不能用高速同步（HSS）了，而要使用闪光灯的高速闪光模式，这种情况下，闪光灯要作为主光源，闪光灯在千分之一秒内完成闪光，闪光的一瞬间水滴被照亮，这样运动的物体就被“凝固”了下来。并且快门速度不能高于1/200秒（相机的闪光同步速度），否则画面边缘会出现未被照亮的黑边。同时要达到暗背景的效果，要使用小光圈和低ISO，闪光灯完全可以把环境光线压下去，并且水滴是正常曝光的。给出一组参考值：ISO 100，F16，320秒。所以，使用闪光灯的情况下拍摄高速运动的物体，并不一定需要1/8000这样的高速快门，而是用“慢速快门”+“闪光灯作为主光源” (六) 闪光灯的前帘同步和后帘同步前帘同步就是指前帘打开的瞬间开始闪光，后帘同步就是后帘快要关闭之前开始闪光。简单粗暴的举个栗子，假设闪光灯能持续1s，设置10s的快门，前帘同步就是第一秒闪，后帘同步就是最后一秒闪。前帘同步和后帘同步都属于慢门同步, 快门速度都低于1/200秒（单反的同步速度），所以前后帘同步只能在夜间或者光线较差的情况下使用，这时候闪光灯是作为主光源。 如果被摄物体在运动，采用前帘同步会使物体的初始位置被照亮，留下清晰的影响，之后移动的轨迹由于曝光不够形成虚影。如果采用后帘同步则正好相反，物体前面移动的轨迹由于曝光不足形成虚影，在最后的位置被照亮，形成清晰的影像，如下图所示： 如果快门速度低于闪光同步速度，比如夜间拍摄时快门大约1/100秒，这个时候快门不是狭缝的，而是整个CMOS完全打开曝光，这个时候应该选择后帘同步，闪光持续时间在整个CMOS在完全打开状态下。如果快门速度高于闪光同步速度，比如白天的逆光拍摄大约1/2000秒快门，这时候快门会以狭缝的方式扫过CMOS，这个时候应该怎么办？ 选购闪光灯时应该注意的参数 TTL功能：通过镜头测量曝光方式自动控制闪光灯功率，打开TTL的闪光过程是2次闪光的过程。第一次，闪光灯预闪一下，预闪的光线照射到被摄物体上，反射回来进入相机。相机的感光元件根据反摄回的光线经过复杂的计算，输出一个指令给闪光灯，闪光灯调整自己的输出强度在闪一次。这一次才是真正的曝光。 高速同步：可以理解为在大太阳下快门速度可以超过1/160或者1/200，比如4000-8000的快门速度（机顶普通闪光灯快门超过1/160或者1/200就没法闪光了），常用的场景是大光圈在大逆光下补光。 闪光指数：简称GN，闪光灯的功率，越大越好，但也越贵。闪光指数 = 摄距 x 光圈，GN也不能单单只看数值的大小，因为闪光指数还要说明焦距和ISO，比如尼康SB-800的闪光指数标着53，实际是”53@85mm ISO 100”，如果在35mm镜头下，GN就变成了38，这是因为越广的镜头要求闪光灯散射面积越大，强度也降低了。 闪光灯的其他知识tips 前帘同步和后帘同步，如果快门够快，拍摄的主体不动，那么拍出来的效果没有什么区别。换句话说，后帘同步总是和慢速快门一起使用的，主体应该是运动中（或者相机晃动），前后帘同步的情况下闪光灯是作为主光源的。 用闪光灯可以极大提高进光量，提高快门速度，这样就可以拍摄凝固水滴这种高速运动，当然这种情况下你不能用高速同步闪光，因为功率太低不够亮。 如果在电灯下拍摄，照片很容易呈现偏黄、红色的暖色调，因为钨丝灯的色温低，而加用闪光灯，就可以有效地调整色温，使被摄物色彩正确还原。 高速同步的意义在于，可以在光线强烈的环境下，使用大光圈拍摄出浅景深的效果，这时候闪光灯不是作为主光源，而是用来给主体补光。 如果在晴天环境下使用大光圈，最好是使用中性密度滤镜，这样可以不必使用高速闪光模式。 能不用高速闪光同步就不用，因为此模式下闪光灯浪费太多能量。特别是，不要想用高速闪光同步来克服较硬的日光，这做不到，因为在高速闪光同步模式下闪光灯的功率是很低的，用大功率外拍灯吧。 在明亮环境下使用闪光灯，可以设置快门速度在最高闪光同步速度或略微比最高闪光同步速度慢一点，这样能发挥闪光灯的最大效率。这是因为更慢的快门速度意味着使用更小的光圈，而更小的光圈导致闪光灯的有效照明距离的更短（闪光指数＝光圈值×照明距离）。 如果没有保护措施，连续使用1/1闪光能把某些闪光灯的灯头透镜（塑料）烧到局部熔化。 关于指数（GN）：不要只看GN的数值，还要看他的测试条件，同一只灯，如果它的灯头能变焦，在长焦端的指数就比广角端要大。按ISO200来测试也比ISO100测试的数值大 闪光灯使用入门 一盏灯的时候，那么闪光灯尽量作为补充光源来使用的，主光一定是环境光。这种闪光方式叫做填充闪光。 填充闪光：先测量环境光线,比如现场光线iso1600 f2.8 1/60,这是个常见的室内拍摄环境。在这个基础上不做锁定曝光。用外闪在这个基础进行-1档TTL闪光。基本就是填充闪光了。-1档经验习惯。让闪光痕迹尽量减少些。填充闪光的原则就是一定要兼顾现场光线，闪光灯只是为了对暗部进行轻微的补光。 平衡闪光是闪光将照亮主体使其达到背景光的水平。这种方法应用于如下情况：主体处于阴影中，并且/或者背景非常明亮。使用闪光灯让主体的光与环境光平衡。 完全闪光：完全闪光通常用在室内狭小空间内，光线非常差的情况下。这种情况也不能使用直接闪光的方式，而应使用常用的“跳灯” 参考 关于电子闪光灯的一些概念 - 色影无忌文章 职业摄影师永远不会告诉你的拍摄技巧 篇三：闪光灯拍摄技巧 NIKON.SCHOOL-Guide-to-Creative-Lighting 摄影闪光教程 大卫·豪比《逐层布光》","categories":[{"name":"53.Photograph","slug":"53-Photograph","permalink":"https://beefyheisenberg.github.io/categories/53-Photograph/"}],"tags":[{"name":"摄影","slug":"摄影","permalink":"https://beefyheisenberg.github.io/tags/摄影/"},{"name":"摄影器材","slug":"摄影器材","permalink":"https://beefyheisenberg.github.io/tags/摄影器材/"},{"name":"闪光灯","slug":"闪光灯","permalink":"https://beefyheisenberg.github.io/tags/闪光灯/"}]},{"title":"在 Windows 和 macOS 之间同步 Sublime 配置文件","slug":"50.Farbox-Blog/【编辑器】在Windows和OSX之间同步Sublime配置文件","date":"2016-02-14T16:00:00.000Z","updated":"2024-01-24T01:27:53.114Z","comments":true,"path":"50.Farbox-Blog/【编辑器】在Windows和OSX之间同步Sublime配置文件/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【编辑器】在Windows和OSX之间同步Sublime配置文件/","excerpt":"下面介绍如何把Windows上的Sublime设置同步到OSX Windows设置 关闭Sublime; 以administrator打开PowerShell, 输入以下命令: cd &quot;%appdata%\\Sublime Text 3\\Packages\\&quot;mkdir &apos;X:\\Dropbox\\SublimeText3&apos;mv User &apos;X:\\Dropbox\\SublimeText3\\&apos;cmd /c mklink /D User &quot;X:\\Dropbox\\SublimeText3\\User&quot; 注意, 根据情况替换上面的X:\\Dropbox\\SublimeText3路径;第三行mv命令只能在相同盘符的目录之间移动, 如果你的Dropbox同步目录不是在C盘, 手动打开%AppData%\\Sublime Text 3\\Packages\\\\, 把下面的User目录移动到Dropbox同步目录中.","text":"下面介绍如何把Windows上的Sublime设置同步到OSX Windows设置 关闭Sublime; 以administrator打开PowerShell, 输入以下命令: cd &quot;%appdata%\\Sublime Text 3\\Packages\\&quot;mkdir &apos;X:\\Dropbox\\SublimeText3&apos;mv User &apos;X:\\Dropbox\\SublimeText3\\&apos;cmd /c mklink /D User &quot;X:\\Dropbox\\SublimeText3\\User&quot; 注意, 根据情况替换上面的X:\\Dropbox\\SublimeText3路径;第三行mv命令只能在相同盘符的目录之间移动, 如果你的Dropbox同步目录不是在C盘, 手动打开%AppData%\\Sublime Text 3\\Packages\\\\, 把下面的User目录移动到Dropbox同步目录中. OSX设置 关闭Sublime; 打开终端, 输入以下命令: cd ~/Library/Application\\ Support/Sublime\\ Text\\ 3/Packages/mv User User.deprecatedln -s ~/Dropbox/SublimeText3/User User 根据情况替换上面的~/Dropbox/SublimeText3路径. 请确保OSX上也安装了Sublime设置中引用的字体. 关于User目录下的文件 User/Package Control.sublime-settings: Package Control的配置文件, 安装的所有插件列表; User/Preferences.sublime-settings: Sublime text的一般配置; 一些bug的解决方法 每次打开sublime弹出提示”the following incompatible dependency was found installed: user”","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://beefyheisenberg.github.io/tags/Windows/"},{"name":"OSX","slug":"OSX","permalink":"https://beefyheisenberg.github.io/tags/OSX/"},{"name":"macOS","slug":"macOS","permalink":"https://beefyheisenberg.github.io/tags/macOS/"},{"name":"Sublime","slug":"Sublime","permalink":"https://beefyheisenberg.github.io/tags/Sublime/"},{"name":"Dropbox","slug":"Dropbox","permalink":"https://beefyheisenberg.github.io/tags/Dropbox/"}]},{"title":"摄影笔记","slug":"53.Photograph/摄影笔记","date":"2015-11-29T10:14:10.000Z","updated":"2024-01-24T01:27:53.632Z","comments":true,"path":"53.Photograph/摄影笔记/","link":"","permalink":"https://beefyheisenberg.github.io/53.Photograph/摄影笔记/","excerpt":"基础概念色调 色彩系列教程(2)：色系和色调色调指的是一幅画中画面色彩的总体倾向, 色调指的是一幅画中画面色彩的总体倾向.比如这样的画面: 不同颜色的物体或被笼罩在一片金色的阳光之中, 或被笼罩在一片轻纱薄雾似的、淡蓝色的月色之中;或被秋天迷人的金黄色所笼罩; 或被统一在冬季银白色的世界之中.这种在不同颜色的物体上, 笼罩着某一种色彩, 使不同颜色的物体都带有同一色彩倾向, 这样的色彩现象就是色调. 色温自然界的色温","text":"基础概念色调 色彩系列教程(2)：色系和色调色调指的是一幅画中画面色彩的总体倾向, 色调指的是一幅画中画面色彩的总体倾向.比如这样的画面: 不同颜色的物体或被笼罩在一片金色的阳光之中, 或被笼罩在一片轻纱薄雾似的、淡蓝色的月色之中;或被秋天迷人的金黄色所笼罩; 或被统一在冬季银白色的世界之中.这种在不同颜色的物体上, 笼罩着某一种色彩, 使不同颜色的物体都带有同一色彩倾向, 这样的色彩现象就是色调. 色温自然界的色温色温的单位是K(开耳文), K值越高色温越高. 色温越高表现为画面偏冷; 色温越低画面偏暖. 自然界常见的色温表 蜡烛光: 1000K, 暖色 钨丝灯: 2000K, 暖色 朝阳夕阳: 3000K, 暖色 闪光灯: 5000K 晴天阳光: 5600K 阴天: 6000K+, 冷 晴天时阴影: 7000K, 冷 雪天: 10000K, 冷 单反的色温标准单反里使用哪个场景, 就是”弥补”该场景下的色温. 比如在单反的”钨丝灯”模式下, 拍出的画面实际是偏冷的, 为了中和钨丝灯的暖色. K值单反里的K值, 与自然界色温标准是”相反”的, 比如选择10000k的K值, 画面实际是偏暖, 为了中和自然界10000K色温场景下(晴空)的冷色. 后期(Lightroom) 快捷键 对比原始和修改后: / 分栏显示修改前后照片: Y 进入”修改照片”模式: D 进入”图库”模式: G 全屏显示: F 直方图直方图左端表示明亮度为 0% 的像素, 右端表示明亮度为 100% 的像素.直方图由三个颜色层组成, 分别表示红色、绿色和蓝色通道.这三个通道发生重叠时将显示灰色；RGB 通道中任两者发生重叠时, 将显示黄色、洋红或青色：黄色相当于“红色”+“绿色”通道, 洋红相当于“红色”+“蓝色”通道, 而青色则相当于“绿色”+“蓝色”通道. 直方图”剪切”的概念直方图左上和右上角各有一个三角按钮, 分别表示”黑色剪切”和”白色剪切”, 这里以黑色剪切为例:点击左上角的”黑色剪切”按钮, 画面上将会把纯黑色的区域用蓝色色块标识出来, 当所有通道中均发生了剪切时, 指示器之一将呈白色. 如果剪切指示器呈彩色, 则表明剪切了一个或两个通道.如果在按下”黑色剪切”后, 发现画面出现很多蓝色色块, 则说明欠曝区域太多.白色剪切同上.调整方法一般为: 调整高光, 让红色色块减少(过曝), 调整阴影, 让蓝色色块减少(欠曝) 基本面板 白平衡: 吸管, 选择灰色部分(最好), 其次是黑/白 对比度: 白色更白, 黑色更黑 白色色阶: 调整画面浅色的部分, 类似高光, 其调整的范围比高光更大, 调整白色色阶会对整个画面影响 黑色色阶: 调整画面深色的部分, 类似阴影, 其调整的范围比阴影更大 色调曲线面板面板左上有一个”在照片中拖动来调整色调曲线”, 比在曲线上调整更形象一点面板右下有一个”点曲线”, 在曲线上设置锚点, 比”拉曲线”更精确. 有两个预设”中度对比”和”强度对比” HSL 色相: 挑出你喜欢的预设, 观察他的HSL是怎么调的 饱和度: 原则: 颜色溢出的,降饱和, 非拍摄主体,降饱和 明亮度: 调整某个颜色的曝光, 比如蓝色负值可以拉蓝天, 也可以拉高阴影部位曝光, 类似阴影补偿. 色调分离面板分离色调是整体调色,而HSL是单独调色. 经验: 扫街作品 高光增加黄色, 阴影增加蓝绿色, 制造”冷暖交替”的氛围, 然后HSL增加黄色饱和度 渐变滤镜新建快捷键M, “反向蒙版”打勾可以选择滤镜范围(以内) 径向滤镜新建快捷键Shift+M, “反向蒙版”打勾可以选择滤镜范围(以内) 肤色调整 HSL/颜色/黑白 提高组成肤色的红色和橙色的明亮度 降低橙色的饱和度 径向滤镜, 降低清晰度, 提曝光, 提高白色色阶 使用手机修图 VSCO滤镜使用指南 拍摄技巧夜间人像 后帘同步 背景正确曝光 缩小光圈,主体对焦 找机位 北京爬楼党: http://cityclimbers.tuchong.com/ 北京自然风光: https://beijingcity.tuchong.com/ 立交桥攻略: https://sramx9.tuchong.com/6077961/ 器材镜头 佳能50mm f1.8 STM: 兰拓科技 —— 佳能、尼康、索尼50（55）mm f/1.8镜头横评 适马50mm f1.8 EX: 光圈收到1.8可用, 5.6中心分辨率最佳, 参考Sigma 50mm F1.4 EX DG HSM review 适马35mm f1.4 ART: 兰拓科技 —— 35mm f/1.4规格自动镜头横评 佳能24-70mm f4 is: 参考微距+防抖 佳能24-70mm f4 IS镜头评测 佳能70-200mm f4 is: Canon EF 70-200mm f/4L IS USM mounted on Canon EOS 5DS R : Measurements 如何看镜头的MTF曲线图 横轴是距镜片中心的距离, x=0处是镜头中心的分辨率, x=20处是距离镜头中心20mm处的分辨率. 纵轴是分辨率高低, 越接近1画质越好. 10线/毫米和30线/毫米: MTF曲线中实线为S方向(水平)测得, 虚线为M方向(竖直)测得, 黑色曲线为最大光圈测得, 蓝色曲线为F8光圈测得, 粗线是空间频率为10线对/毫米时测得, 细线是空间频率为30线对/毫米时测得 MTF最佳光圈 佳能50mm f1.8 STM: 光圈f5.6最好, 参考这里 腾龙35mm f1.8 VC: 光圈f2.8最好, 参考这里 佳能24-70mm f4 is: 每个焦段(24mm,40mm,70mm)均是f5.6最好, 参考这里 佳能70-200mm f4 is: 每个焦段(70mm,135mm,200mm)均是f5.6最好, 参考这里 渣能EOS 5D3被忽视的菜单佳能5D mark iii是我目前使用的设备. 对焦性能基本继承了旗舰1DX还算好, 连拍6张/秒还不错, 高感还可以, 宽容度不太好, 像素偏低属于上一代水准, 没Wifi, 很重, 镜头很多. 拍摄菜单4: 实时拍摄(使用液晶屏拍摄), 自动对焦模式 实时模式: 相当于无反相机的反差式对焦, 但是5D3的反差式对焦特别慢, 能听到镜头里的镜组反复推移的声音. 人脸实时模式: 也是反差式对焦, 增加一个人脸识别. 快速模式: 实际是用反光板下面的对焦模块进行相位对焦, 也是我们最熟悉的单反的对焦模式, 第一次按下快门会放下反光板, 这时液晶屏黑屏并且对焦模块进行对焦, 保持按住快门才会进行拍摄, 所以会听到相机两次响声, 一次是反光板放下的声音一次是快门的声音. 这种模式的对焦速度快于第一种, 但是实际使用体验并不好, 一是拍摄期间液晶屏会黑一次, 二是要听到两次声音, 很多人都误以为第一次声音(反光板放下)时已经拍摄了, 进入照片预览发现并没有拍摄照片-__- 切记这个模式要响两次才算是拍摄完成. 高ISO降噪: SHOOT3 -&gt; 高ISO感光度降噪功能 关于”点测联动”: 5D3没有点测联动, 所以对焦点不在画面中央并且使用点测光的时候, 需要手动: 半按快门对被摄主体测光, 点*锁定曝光, 重新构图后拍摄. 曝光锁定键一直按住, 可以持续按快门拍摄. 包围曝光(AEB): SHOOT2 -&gt; 曝光补偿/AEB, 进入后用前拨轮选择包围步长(最小1/3EV). 如果开启了包围的同时也开启了连拍模式, 按下快门键会连拍三张后停止. 如果是单拍, 需要按快门三次生成三张不同曝光的图片. 开启包围后, 在曝光标尺上有三个标记(注意). 白平衡包围(WB-BKT): SHOOT2 -&gt; 白平衡偏移/包围: 打开后, 按一次快门会生成三张不同白平衡的照片, 连拍数量会减少 焦距包围(景深合成): 5D3没有, 貌似只有奥林巴斯EM1和EM5ii有这种功能, 微距爱好者福音. 以上几种包围拍摄选项均没有快捷按键, 需要进入几层菜单设置, 叹气5D3完全不是专业机身. HDR: SHOOT3 -&gt; HDR模式 , 自动对齐图像仅在手持时打开, 使用三脚架时关闭此选项. HDR的局限性: 不能拍摄移动物体, 快门速度不能过慢, 不能使用闪光灯, 无法在曝光包围, WB包围的情况下使用 多重曝光: 待补充 闪光灯: 待补充 自定义拍摄模式C1: 追焦连拍(伺服自动, 61点, 连拍H, 快门优先1/500起, 评价测光, 画质L), 记录空间需要手动调整到CF卡, 如果设置为SD卡会拖慢连拍速度. 自定义拍摄模式C2: 待补充 器材评测 dpreview样张比较(EM5ii/XT10/A6000/A7) 样张比较(5D3/D810/D750/A7R2) 兰拓科技_佳能、尼康、索尼（FE）24-70mm f/2.8镜头横评 兰拓科技_佳能1DX2 vs 尼康D5全面测评 相机入魔_佳能EOS 1D X Mark II DPReview测评结论 M43镜头选择没错我还玩M43… M4/3镜头群有哪些值得买的？ M43党福利镜头群总结以及简单点评 相机说明书 相机manual.索尼α7m3 相机manual.富士X100F 相机manual.TT350s闪光灯 胶片摄影 film.宾得SPII使用手册 film.胶片测光经验表","categories":[{"name":"53.Photograph","slug":"53-Photograph","permalink":"https://beefyheisenberg.github.io/categories/53-Photograph/"}],"tags":[{"name":"摄影","slug":"摄影","permalink":"https://beefyheisenberg.github.io/tags/摄影/"},{"name":"相机","slug":"相机","permalink":"https://beefyheisenberg.github.io/tags/相机/"},{"name":"佳能","slug":"佳能","permalink":"https://beefyheisenberg.github.io/tags/佳能/"},{"name":"Lightroom","slug":"Lightroom","permalink":"https://beefyheisenberg.github.io/tags/Lightroom/"},{"name":"奥林巴斯","slug":"奥林巴斯","permalink":"https://beefyheisenberg.github.io/tags/奥林巴斯/"},{"name":"M43","slug":"M43","permalink":"https://beefyheisenberg.github.io/tags/M43/"}]},{"title":"Cygwin食用指南","slug":"50.Farbox-Blog/【开发环境】Cygwin食用指南","date":"2015-11-14T16:00:00.000Z","updated":"2024-01-24T01:27:53.069Z","comments":true,"path":"50.Farbox-Blog/【开发环境】Cygwin食用指南/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【开发环境】Cygwin食用指南/","excerpt":"国内镜像网易: http://mirrors.163.com/.help/cygwin.html 选择的包 Archive: bzip2 p7zip zip Base: 全选 Devel: autoconf automake cmake cvs cscope ctags git gdb make Editor: vim vim-common Interpreters: php php-devel python Net: curl openssl ping putty openssh Web: wget 工具","text":"国内镜像网易: http://mirrors.163.com/.help/cygwin.html 选择的包 Archive: bzip2 p7zip zip Base: 全选 Devel: autoconf automake cmake cvs cscope ctags git gdb make Editor: vim vim-common Interpreters: php php-devel python Net: curl openssl ping putty openssh Web: wget 工具 安装完成Cygwin之后, 如果想要再安装新软件, 可以使用官网下载的setup-x86.exe, 命令: setup-x86.exe -q -P packagename1,packagename2 选择之二: apt-cyg , 使用方法类似ubuntu 的apt-get apt-cyg install yourPackage 配置 把windows的盘符链接为/c, /d这样的路径: ln -s /cygdrive/c /c alias: alias ll=&apos;ls -alh&apos;alias ls=&apos;ls --color=tty&apos;alias yum=&apos;apt-cyg&apos; 如何删除Cygwintakeown /f C:\\cygwin /r /d yicacls c:\\cygwin /t /grant everyone:F 删除整个Cygwin安装目录.","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://beefyheisenberg.github.io/tags/Windows/"},{"name":"Cygwin","slug":"Cygwin","permalink":"https://beefyheisenberg.github.io/tags/Cygwin/"}]},{"title":"Github Atom For Windows","slug":"50.Farbox-Blog/【编辑器】Github-Atom-for-Windows","date":"2015-02-07T16:00:00.000Z","updated":"2024-01-24T01:27:53.060Z","comments":true,"path":"50.Farbox-Blog/【编辑器】Github-Atom-for-Windows/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【编辑器】Github-Atom-for-Windows/","excerpt":"本文介绍用 Chocolatey 在 Windows上安装 Atom编辑器. Atom是由GitHub开发的自由及开放源代码的文字与代码编辑器，支持macOS、Windows和Linux操作系统，支持Node.js所写的插件，并内置由Github提供的Git版本控制系统。多数的延伸包皆为开放源代码授权，并由社群建置与维护。 Chocolatey for Windows简单的说, Chocolatey相当于Windows上的yum和apt-get, Chocolatey这套包管理系统目前已经包含了近500 多款常用软件.","text":"本文介绍用 Chocolatey 在 Windows上安装 Atom编辑器. Atom是由GitHub开发的自由及开放源代码的文字与代码编辑器，支持macOS、Windows和Linux操作系统，支持Node.js所写的插件，并内置由Github提供的Git版本控制系统。多数的延伸包皆为开放源代码授权，并由社群建置与维护。 Chocolatey for Windows简单的说, Chocolatey相当于Windows上的yum和apt-get, Chocolatey这套包管理系统目前已经包含了近500 多款常用软件. 安装Chocolatey:以管理员身份打开 PowerShell输入: Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString(&apos;https://chocolatey.org/install.ps1&apos;)) Chocolatey使用方法 列出已安装的包：choco list 安装软件包：choco install 软件包名 升级软件包: choco upgrade 软件包名 卸载软件包: choco uninstall 软件包名 安装Atom打开cmd命令行或者PowerShell, choco install atom 扩展@link: [[AppSolution]] context-menu-manager： 管理Atom的右键，删除无用的item &amp; 也可以查看某个item是哪个插件加上去的 ✔︎highlight-selected ✔︎document-outline ✔︎autocomplete-paths ✔︎autocomplete-python ✔︎vim-mode-plus ✔︎highlight-registered-keyword : 自定义高亮 Keyword ✔︎file-icons: 图标 ✘symbol-gen: 快捷键Ctrl-Cmd-G, 生成项目的符号到.tag文件, 可以使用Cmd+Shift+R搜索项目中的符号(类似VSCOde的Cmd+P) ✘cursor-history: 快捷键 C-O, C-I highlight-registered-keywordThis package highlights registered keyword, regardless of file extension. $ cat ~/.atom/PatternsFilePath&quot;highlight-registered-keyword&quot;: [ &#123; class: &quot;mkdtask-done&quot; pattern: &quot;/✔︎/g&quot; fileTypes:[&quot;md&quot;, &quot;mkd&quot;] &#125; &#123; class: &quot;mkdtask-delay&quot; pattern: &quot;/✘/g&quot; fileTypes:[&quot;md&quot;, &quot;mkd&quot;] &#125; &#123; class: &quot;mkdtask-snooze&quot; pattern: &quot;/→/g&quot; fileTypes:[&quot;md&quot;, &quot;mkd&quot;] &#125; &#123; class: &quot;ISBN&quot; pattern: &quot;/(ISBN-13 ?((978)|(979))-\\\\d&#123;1,9&#125;-\\\\d&#123;1,9&#125;-\\\\d&#123;1,9&#125;-\\\\d)|(ISBN-10 ?\\\\d&#123;1,9&#125;-\\\\d&#123;1,9&#125;-\\\\d&#123;1,9&#125;-\\\\d)/g&quot; &#125;] $ cat ~/.atom/styles.lessatom-text-editor .highlight &#123; &amp;.highlight-registered-keyword &#123; .region &#123; background-color: hsla(180, 60%, 50%, 0.5); &#125; &amp;.mkdtask-done &#123; .region &#123; background-color: hsla(130, 60%, 50%, 0.5); &#125; &#125; &amp;.mkdtask-delay &#123; .region &#123; background-color: hsla(350, 60%, 50%, 0.5); &#125; &#125; &amp;.mkdtask-snooze &#123; .region &#123; background-color: hsla(200, 60%, 50%, 0.5); &#125; &#125; &amp;.ISBN &#123; .region &#123; background-color: hsla(60, 60%, 50%, 0.5); &#125; &#125; &#125;&#125; SunsetSunsetting Atom | The GitHub Blog On June 8, 2022, we announced that we will sunset Atom and archive all projects under the organization on December 15, 2022. 参考 (https://chocolatey.org/packages/Atom) (http://www.oschina.net/p/chocolatey) 更多Choco的工具 其他有用的packages： Easy Install Pip","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"编辑器","slug":"编辑器","permalink":"https://beefyheisenberg.github.io/tags/编辑器/"},{"name":"Windows","slug":"Windows","permalink":"https://beefyheisenberg.github.io/tags/Windows/"},{"name":"Atom","slug":"Atom","permalink":"https://beefyheisenberg.github.io/tags/Atom/"}]},{"title":"Sublime Text 3 扩展和快捷键","slug":"50.Farbox-Blog/【编辑器】Sublime-Text-3快捷键","date":"2015-01-24T16:00:00.000Z","updated":"2024-01-24T01:27:53.064Z","comments":true,"path":"50.Farbox-Blog/【编辑器】Sublime-Text-3快捷键/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【编辑器】Sublime-Text-3快捷键/","excerpt":"安装 Package ControlSublime text 3安装Package Control的方法:View -&gt; Show Console, 输入:import urllib.request,os,hashlib; h = &apos;2deb499853c4371624f5a07e27c334aa&apos; + &apos;bf8c4e67d14fb0525ba4f89698a6d7e1&apos;; pf = &apos;Package Control.sublime-package&apos;; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); by = urllib.request.urlopen( &apos;http://packagecontrol.io/&apos; + pf.replace(&apos; &apos;, &apos;%20&apos;)).read(); dh = hashlib.sha256(by).hexdigest(); print(&apos;Error validating download (got %s instead of %s), please try manual install&apos; % (dh, h)) if dh != h else open(os.path.join( ipp, pf), &apos;wb&apos; ).write(by) 安装插件","text":"安装 Package ControlSublime text 3安装Package Control的方法:View -&gt; Show Console, 输入:import urllib.request,os,hashlib; h = &apos;2deb499853c4371624f5a07e27c334aa&apos; + &apos;bf8c4e67d14fb0525ba4f89698a6d7e1&apos;; pf = &apos;Package Control.sublime-package&apos;; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); by = urllib.request.urlopen( &apos;http://packagecontrol.io/&apos; + pf.replace(&apos; &apos;, &apos;%20&apos;)).read(); dh = hashlib.sha256(by).hexdigest(); print(&apos;Error validating download (got %s instead of %s), please try manual install&apos; % (dh, h)) if dh != h else open(os.path.join( ipp, pf), &apos;wb&apos; ).write(by) 安装插件 SideBarEnhancements : 侧边栏右键增强, 配置参考这里 Emmet: 前身是”Zen Coding”, 可以更高效地编写HTML和CSS, 比如输入html:5然后按 Tab 就能自动产生代码段, 速查表在这里 SublimeLinter: 语法错误检查, 安装完SublimeLinter后还要安装对应语言的扩展, 在Package Control搜索”SublimeLinter-“即可. SublimeLinter-php: 需要安装php SublimeLinter-pep8: SublimeLinter-jshint: 需要安装jshint: npm install -g jshint SublimeLinter-clang: 需要安装clang, Windows用户请安装”mingw with clang” SublimeCodeIntel: 函数定义跳转, 支持Js,Py,PHP等等, 但是不支持C/C++. Ctags: 也是作为函数定义跳转, 快捷键ctrl+t, ctrl+t跳转到定义, ctrl+t, ctrl+b跳转回. 对于有多个相似定义的函数, sublime里默认列出所有的tags, 和vim的g + ]类似. 使用起来感觉Ctags比SublimeCodeIntel跳转的更快, 因为SublimeCodeIntel总是动态的更新索引导致, Ctags不会自动更新tags文件里的索引. Snippets: JsFormat: js格式化, ctrl+alt+f, 或者ctrl + shift + p, 打开控制台输入Format: Javascript phpfmt : php格式化, 在控制台输入phpfmt: format now ConvertToUTF8: SublimeClang: C/C++的代码补全, 现在只支持ST2并且作者好久没更新了, 用ST3的洗洗睡吧. SublimeClang的static analyzer功能需clang的支持, 在Windows上安装clang又是喜闻乐见的困难, so~Windows用户也可以洗洗睡了. 快捷键1. 跳转 Ctrl+P : 快速打开文件 Ctrl+R : 快速搜索函数 Ctrl+G : 跳转到行 Alt + - : Navigate Backwards Alt + Shift + - : Navigate Forwards Ctrl + Left/Right : 类似Vim的w 和 b Ctrl + Shift + Left : 向左单位性地选中文本 Ctrl + Shift + Right : 向右单位性地选中文本 Ctrl+Shift+M : 选择括号 Ctrl+M : 括号跳转 Ctrl+Shift+M : 选中当前括号内容，重复可选着括号本身 2. 编辑 Ctrl+Alt+上下 : 列模式 Ctrl+D : 多处同步编辑, 继续按Ctrl+D可以持续选中下一处. Ctrl + Backspace : 向前删除一个单词 Ctrl + Delete : 向后删除一个单词 Ctrl+L : 选中整行，继续操作则继续选择下一行，效果和Shift + ↓效果一样 Ctrl+Shift+L : 在选中的行每行行尾插入光标，即可同时编辑这些行 Ctrl+X : 删除当前行 Ctrl+Z : 撤消操作, 同Ctrl+U Ctrl+Y : 恢复撤销 Ctrl+Enter : 在下一行插入新行 Ctrl+Shift+Enter : 在上一行插入新行 3. 搜索替换 Ctrl+Shift+F : 搜索状态下Ctrl+E, Ctrl+F : Enter查找下一个, Shift+Enter查找上一个 Ctrl+H : 替换 4. 注释 Ctrl+K+B : 关闭侧边栏 Ctrl+/ : 注释当前行 Ctrl+Alt+/ : 插入注释 5. SublimeCodeIntel: Jump to definition = Control + Windows + Alt + Up or Alt + Click Go back = Control + Windows + Alt + Left Manual Code Intelligence = Control + Shift + space 6. CTags Rebuild ctags = ctrl+t, ctrl+r Jump to definition = ctrl+t, ctrl+t Jump back = ctrl+t, ctrl+b","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"编辑器","slug":"编辑器","permalink":"https://beefyheisenberg.github.io/tags/编辑器/"},{"name":"Sublime","slug":"Sublime","permalink":"https://beefyheisenberg.github.io/tags/Sublime/"}]},{"title":"在树莓派上安装Samba和Ftp服务","slug":"50.Farbox-Blog/【Raspberry】在树莓派上安装Samba和FTP服务","date":"2015-01-07T16:00:00.000Z","updated":"2024-01-24T01:27:53.026Z","comments":true,"path":"50.Farbox-Blog/【Raspberry】在树莓派上安装Samba和FTP服务/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【Raspberry】在树莓派上安装Samba和FTP服务/","excerpt":"Samba 安装: sudo apt-get install samba samba-common-bin 修改配置文件: sudo /etc/samba/smb.conf, 修改如下: workgroup = WORKGROUP # !根据实际情况填写&quot;域名&quot;或者&quot;工作组名&quot;wins support = yes # !打开对Win支持security = user # !每个samba用户对应linux的用户# 找到 Share Definitions 部分, 删除不使用的定义, 并添加:[pi] comment= Raspberry SMB path=/home/raspsmb/share browseable=Yes writeable=Yes write list = root,raspsmb create mask=0777 irectory mask=0777 添加用户, 和samba目录: sudo useradd raspsmb &amp;&amp; sudo mkdir -p /home/raspsmb/share &amp;&amp; sudo chown -R raspsmb:raspsmb /home/raspsmb/ sudo smbpasswd -a raspsmb 设置samba密码 重启samba服务sudo service samba restart 创建链接: sudo ln -s /home/raspsmb/share /smb 在Windows上访问: \\\\ipaddress\\pi, “pi”是在配置文件smb.conf中Share Definitions部分定义的[pi], 用户名是上面创建的”raspsmb”用户. 注意Windows上要保证服务TCP/IP (NetBT) 和Workgroup打卡. 参考: http://raspberrywebserver.com/serveradmin/share-your-raspberry-pis-files-and-folders-across-a-network.html http://www.ttlsa.com/linux/install-samba-on-linux/ FTP","text":"Samba 安装: sudo apt-get install samba samba-common-bin 修改配置文件: sudo /etc/samba/smb.conf, 修改如下: workgroup = WORKGROUP # !根据实际情况填写&quot;域名&quot;或者&quot;工作组名&quot;wins support = yes # !打开对Win支持security = user # !每个samba用户对应linux的用户# 找到 Share Definitions 部分, 删除不使用的定义, 并添加:[pi] comment= Raspberry SMB path=/home/raspsmb/share browseable=Yes writeable=Yes write list = root,raspsmb create mask=0777 irectory mask=0777 添加用户, 和samba目录: sudo useradd raspsmb &amp;&amp; sudo mkdir -p /home/raspsmb/share &amp;&amp; sudo chown -R raspsmb:raspsmb /home/raspsmb/ sudo smbpasswd -a raspsmb 设置samba密码 重启samba服务sudo service samba restart 创建链接: sudo ln -s /home/raspsmb/share /smb 在Windows上访问: \\\\ipaddress\\pi, “pi”是在配置文件smb.conf中Share Definitions部分定义的[pi], 用户名是上面创建的”raspsmb”用户. 注意Windows上要保证服务TCP/IP (NetBT) 和Workgroup打卡. 参考: http://raspberrywebserver.com/serveradmin/share-your-raspberry-pis-files-and-folders-across-a-network.html http://www.ttlsa.com/linux/install-samba-on-linux/ FTP 安装: sudo apt-get install vsftpd 修改配置文件: sudo vim /etc/vsftpd.conf, 修改如下: anonymous_enable=NOlocal_enable=YESwrite_enable=YESlocal_umask=022chroot_local_user=YESuser_sub_token=$USERlocal_root=/home/raspftp/shareallow_writeable_chroot=YES 添加用户, 和samba目录: sudo useradd raspftp &amp;&amp; sudo mkdir -p /home/raspftp/share &amp;&amp; sudo chown -R raspftp:raspftp /home/raspftp/ sudo passwd raspftp 重启ftp服务: sudo service vsftpd restart 创建链接: sudo ln -s /home/raspftp/share /ftp","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"树莓派","slug":"树莓派","permalink":"https://beefyheisenberg.github.io/tags/树莓派/"},{"name":"Samba","slug":"Samba","permalink":"https://beefyheisenberg.github.io/tags/Samba/"},{"name":"FTP","slug":"FTP","permalink":"https://beefyheisenberg.github.io/tags/FTP/"}]},{"title":"在树莓派上安装无线网卡","slug":"50.Farbox-Blog/【Raspberry】在树莓派上安装无线网卡","date":"2015-01-05T16:00:00.000Z","updated":"2024-01-24T01:27:53.030Z","comments":true,"path":"50.Farbox-Blog/【Raspberry】在树莓派上安装无线网卡/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【Raspberry】在树莓派上安装无线网卡/","excerpt":"测试驱动为了省事，我买了EP-N8508GS无线网卡，因为能免去编译驱动的麻烦。确认你的Kernel支持那些无线网卡: $ find /lib/modules/`uname -r`/kernel/drivers/net/wireless -name &quot;*.ko&quot;/lib/modules/3.12.35+/kernel/drivers/net/wireless/rtl8192cu/8192cu.ko/lib/modules/3.12.35+/kernel/drivers/net/wireless/rtl818x/rtl8187/rtl8187.ko 查看识别的usb设备: pi@raspberrypi ~ $ lsusbBus 001 Device 002: ID 0424:9512 Standard Microsystems Corp.Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hubBus 001 Device 003: ID 0424:ec00 Standard Microsystems Corp.Bus 001 Device 004: ID 0bda:8176 Realtek Semiconductor Corp. RTL8188CUS 802.11n WLAN Adapter","text":"测试驱动为了省事，我买了EP-N8508GS无线网卡，因为能免去编译驱动的麻烦。确认你的Kernel支持那些无线网卡: $ find /lib/modules/`uname -r`/kernel/drivers/net/wireless -name &quot;*.ko&quot;/lib/modules/3.12.35+/kernel/drivers/net/wireless/rtl8192cu/8192cu.ko/lib/modules/3.12.35+/kernel/drivers/net/wireless/rtl818x/rtl8187/rtl8187.ko 查看识别的usb设备: pi@raspberrypi ~ $ lsusbBus 001 Device 002: ID 0424:9512 Standard Microsystems Corp.Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hubBus 001 Device 003: ID 0424:ec00 Standard Microsystems Corp.Bus 001 Device 004: ID 0bda:8176 Realtek Semiconductor Corp. RTL8188CUS 802.11n WLAN Adapter 注意最后一行的Realtek设备就是无线网卡. 查看Kernel载入的模块: $ lsmod8192cu 550797 0leds_gpio 2079 0led_class 4118 1 leds_gpio 上面的8192cu就是我的无线网卡的芯片型号. 执行命令: sudo iwlist wlan0 scan , 看看能否手动扫描周围的ESSID. 无线配置修改配置文件: sudo vim /etc/network/interfaces, 如果需要自动IP, 增加如下: # wifi (dhcp config) :auto wlan0allow-hotplug wlan0iface wlan0 inet dhcpwpa-conf /etc/wpa_supplicant/wpa_supplicant.conf 如果需要固定IP, 增加的内容如下: auto wlan0iface wlan0 inet staticwpa-conf /etc/wpa_supplicant/wpa_supplicant.confaddress 192.168.1.12netmask 255.255.255.0gateway 192.168.1.1 编辑/etc/wpa_supplicant/wpa_supplicant.conf, 增加如下几行: network=&#123; ssid=&quot;ssid1&quot; psk=&quot;密码&quot;&#125;network=&#123; ssid=&quot;ssid2&quot; psk=&quot;密码&quot;&#125; 这里存的是明文密码, 如果需要存储加密后的密码, 执行命令wpa_passphrase ssid password, 替换上面的psk密码.wpa_supplicant.conf里面更多参数详情, 请参考man手册链接, 上面的配置能应付大多数路由器了. 重启wlam0重启无线网卡: sudo ifdown wlan0 and then sudo ifup wlan0然后运行ifconfig wlan0 查看无线网卡是否获能够取到了IP. DONE.","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"树莓派","slug":"树莓派","permalink":"https://beefyheisenberg.github.io/tags/树莓派/"},{"name":"无线网卡","slug":"无线网卡","permalink":"https://beefyheisenberg.github.io/tags/无线网卡/"}]},{"title":"使用Xdebug调试PHP","slug":"50.Farbox-Blog/【PHP】使用Xdebug调试PHP","date":"2015-01-04T16:00:00.000Z","updated":"2024-01-24T01:27:53.017Z","comments":true,"path":"50.Farbox-Blog/【PHP】使用Xdebug调试PHP/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【PHP】使用Xdebug调试PHP/","excerpt":"（一） Server端安装xdebug:Windows服务器For windows的xdebug都是预编译好的binary包, 根据PHP版本下载对应的xdebug: 下载地址 Linux服务器(1) 安装最简单的安装方法是通过PECL安装: pecl install xdebug","text":"（一） Server端安装xdebug:Windows服务器For windows的xdebug都是预编译好的binary包, 根据PHP版本下载对应的xdebug: 下载地址 Linux服务器(1) 安装最简单的安装方法是通过PECL安装: pecl install xdebug 如果你的服务器上没有PECL, 可以通过源码编译安装xdebug: 在(http://xdebug.org/download.php#releases)下载source 解压源码包: tar -xzf xdebug-2.2.5.tgz , and cd xdebug-2.2.5 继续终端执行: phpize , and then ./configure --enable-xdebug, make &amp;&amp; make install (2) 配置编辑服务端的php.ini, 增加: zend_extension=&quot;/usr/local/php/modules/xdebug.so&quot;xdebug.remote_autostart = 1xdebug.remote_enable=1xdebug.remote_handler = &quot;dbgp&quot;xdebug.remote_host = &quot;127.0.0.1&quot; # 允许指定IP的调试客户端连接xdebug.remote_port=9000 # 监听的端口xdebug.trace_output_dir = &quot;/tmp/xampp/trace&quot;;xdebug.profiler_enable=1 # 性能分析, 非常占资源, 暂关;xdebug.profiler_output_dir = &quot;/tmp/xampp/profile&quot; (3) 测试xdebug server重启web server, 然后新建一个test.php, 内容&lt;?php phpinfo(); ?&gt;, 如果访问这个test.php能看到xdebug相关, 说明安装完成. （二）PC端安装xdebug client浏览器设置Chrome安装”debug helper”, 火狐安装”The easiest Xdebug”, 并在插件在设置IDE Key为”PHPSTORM” (这里名字随便设, 但是记住要与IDE里的设置一致). IDE设置这里xdebug client根据你的IDE有多个版本可以选择: Eclipse , NetBeans, Vim, 选择自己喜欢的开发环境, 下面是Vim设置xdebug的例子, 其他的IDE可以参考链接: [Xdebug Client for Phpstorm] (https://www.jetbrains.com/phpstorm/help/configuring-xdebug.html) [Xdebug Client for Eclipse] (https://wiki.eclipse.org/Debugging_using_XDebug) [Xdebug Client for vim] (http://thorpesystems.com/blog/debugging-php-in-vim/) 在Vim中安装vdebug 在_vimrc中增加如下配置: Bundle &apos;joonty/vdebug.git&apos;&quot; 以下选项的说明在 https://github.com/joonty/vdebug/blob/master/doc/Vdebug.txtlet g:vdebug_options = &#123; \\ &quot;port&quot; : 9000, \\ &quot;timeout&quot; : 10, \\ &quot;break_on_open&quot; : 0, \\ &quot;ide_key&quot; : &apos;PHPSTORM&apos; \\&#125; 执行:BundleInstall安装vdebug vdebug默认按键: &lt;F5&gt;: start/run (to next breakpoint/end of script) &lt;F2&gt;: step over &lt;F3&gt;: step into &lt;F4&gt;: step out &lt;F6&gt;: stop debugging &lt;F7&gt;: detach script from debugger &lt;F9&gt;: run to cursor &lt;F10&gt;: toggle line breakpoint 在Vim中使用vdebug 在Vim打开test.php并按下F5, 状态栏会提示”Waiting for a connection…”并持续20秒等待, 在20秒之内通过浏览器访问test.php, vdebug会自动定位在test.php第一行. 注: 上面的20秒等待时间是通过timeout参数设置的, break_on_open参数决定是否自动断在脚本第一行 如果按下F5后没有反应, 可以尝试在Vim中执行:python debugger.run(), 看是否有错误提示;","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://beefyheisenberg.github.io/tags/PHP/"},{"name":"Xdebug","slug":"Xdebug","permalink":"https://beefyheisenberg.github.io/tags/Xdebug/"}]},{"title":"Hexo部署和使用指北(Windows)","slug":"50.Farbox-Blog/【Markdown】Hexo部署和使用指北","date":"2014-12-01T16:00:00.000Z","updated":"2024-01-24T01:27:53.004Z","comments":true,"path":"50.Farbox-Blog/【Markdown】Hexo部署和使用指北/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【Markdown】Hexo部署和使用指北/","excerpt":"静态博客对比 Hugo: 基于Golang The world’s fastest framework for building websites | Hugo Jekyll: 基于Ruby / 支持 GitHub Pages 部署 Jekyll • Simple, blog-aware, static sites | Transform your plain text into static websites and blogs Hexo: 基于Node.js / 支持 GitHub Pages 部署 Hexo 安装 Step by Step安装Git客户端和node.js环境, 然后你还要有一个Github帐号.安装完node.js之后, 不要忘记把User/AppData/Roaming/npm添加到PATH. 安装hexo: 打开Git CMD（因为），输入: npm install -g hexo-cli 初始化hexo: hexo init BLOG, 将在当前目录建立”BLOG”为名的目录并在此初始化, Hexo 即会自动在目标文件夹建立网站所需要的所有文件. 安装依赖包: cd BLOG &amp;&amp; npm install, 如果需要把Blog部署到Github上, 还需要安装hexo-git模块: npm install hexo-deployer-git --save (这一步可选); 如果需要Blog主页不显示全文而是摘要, 需要安装npm install --save hexo-excerpt (这一步可选); 本地启动测试: hexo server, 然后访问127.0.0.1:4000查看. Github上新建一个repository, 名字为yoursite.github.io 修改本地的_config.yml文件, 找到#site一栏, 修改博客的title, 然后在最后的deploy:处增加下面几行: type: githubrepository: https://github.com/Your_Github_Account/yoursite.github.io.gitbranch: master 添加评论系统: 国外比较常用的评论系统有disqus等, 这个在hexo中也是默认开启的, 如果我们要添加其他的评论系统, 还需要做一点修改.在国内推荐使用搜狐畅言: .首先需要在配置文件中禁用disqus, 编辑根目录的_config.yml文件: 查找并注释掉disqus_shortname一行.然后编辑 themes\\landscape\\layout\\_partial\\article.ejs文件, 在文件最后找到section id=&quot;comments&quot;一段, 修改为: &lt;% if (!index)&#123; %&gt;&lt;section id=&quot;comments&quot;&gt; &lt;%- partial(&apos;comment&apos;) %&gt;&lt;/section&gt;&lt;% &#125; %&gt; 编辑themes\\landscape\\layout\\_partial\\comment.ejs 并添加畅言的Js代码:","text":"静态博客对比 Hugo: 基于Golang The world’s fastest framework for building websites | Hugo Jekyll: 基于Ruby / 支持 GitHub Pages 部署 Jekyll • Simple, blog-aware, static sites | Transform your plain text into static websites and blogs Hexo: 基于Node.js / 支持 GitHub Pages 部署 Hexo 安装 Step by Step安装Git客户端和node.js环境, 然后你还要有一个Github帐号.安装完node.js之后, 不要忘记把User/AppData/Roaming/npm添加到PATH. 安装hexo: 打开Git CMD（因为），输入: npm install -g hexo-cli 初始化hexo: hexo init BLOG, 将在当前目录建立”BLOG”为名的目录并在此初始化, Hexo 即会自动在目标文件夹建立网站所需要的所有文件. 安装依赖包: cd BLOG &amp;&amp; npm install, 如果需要把Blog部署到Github上, 还需要安装hexo-git模块: npm install hexo-deployer-git --save (这一步可选); 如果需要Blog主页不显示全文而是摘要, 需要安装npm install --save hexo-excerpt (这一步可选); 本地启动测试: hexo server, 然后访问127.0.0.1:4000查看. Github上新建一个repository, 名字为yoursite.github.io 修改本地的_config.yml文件, 找到#site一栏, 修改博客的title, 然后在最后的deploy:处增加下面几行: type: githubrepository: https://github.com/Your_Github_Account/yoursite.github.io.gitbranch: master 添加评论系统: 国外比较常用的评论系统有disqus等, 这个在hexo中也是默认开启的, 如果我们要添加其他的评论系统, 还需要做一点修改.在国内推荐使用搜狐畅言: .首先需要在配置文件中禁用disqus, 编辑根目录的_config.yml文件: 查找并注释掉disqus_shortname一行.然后编辑 themes\\landscape\\layout\\_partial\\article.ejs文件, 在文件最后找到section id=&quot;comments&quot;一段, 修改为: &lt;% if (!index)&#123; %&gt;&lt;section id=&quot;comments&quot;&gt; &lt;%- partial(&apos;comment&apos;) %&gt;&lt;/section&gt;&lt;% &#125; %&gt; 编辑themes\\landscape\\layout\\_partial\\comment.ejs 并添加畅言的Js代码: 附: hexo命令列表hexo new &quot;post title with whitespace&quot;hexo new page --path about/me &quot;About me&quot;hexo generatehexo serverhexo deployhexo clean: 清除缓存文件 (`db.json`) 和已生成的静态文件 (`public`)hexo version 附: npm命令列表npm lsnpm outdatednpm update # npm update [-g] [&lt;pkg&gt;...]npm install [-g] moduleName [--save] # -g 全局安装 , --save将被写入package.json的dependenciesnpm uninstall [&lt;pkg&gt;...]npm cache clean 使用NexT主题下载NexT主题:cd BLOGgit clone https://github.com/iissnan/hexo-theme-next themes/next 修改_config.yml:theme: next 如果使用了NexT主题, 第三方评论系统需要在themes/nextlayout/_partials/comments.swig修改, 增加畅言评论的js 添加/修改文章 打开Git Bash并执行: hexo n 文章名 新建文章, 这将在hexo\\source_posts\\目录下新建同名的Markdown文件, 用你喜欢的markdown编辑器写博客… hexo g : 这将在hexo.deploy目录下生成静态页面. hexo d : 把文章推到到Github上. 部署完成后, 访问yoursite.github.io就能看到自己搭建的博客了. 注意, Hexo解析某些含有 {＃, {％的代码块会有问题, 在执行hexo g的时候会抛错, 折中解决办法就是..用全角字符😁 Front-matterHexo 的 YAML Front-matter 支持的属性： title: 标题 文章的文件名date: 建立日期 文件建立日期updated: 更新日期 文件更新日期comments: 开启文章的评论功能 truetags: 标签（不适用于分页）categories: 分类（不适用于分页）permalink: 覆盖文章网址excerpt: Page excerpt in plain text. Use this plugin to format the text 为Hexo增加更多特性…SEO推广生成sitemapSitemap用于通知搜索引擎网站上有哪些可供抓取的网页，以便搜索引擎可以更加智能地抓取网站。 安装插件hexo-generator-sitemap，用于生成sitemap：npm install hexo-generator-sitemap --save 在 站点配置文件 _config.yml中添加如下字段：sitemap:path: sitemap.xml 如果post标题中有&amp; &gt;等符号，可能会导致sitemap生成有问题，浏览器打开后可看到 “xmlParseEntityRef: no name”的错误提示 添加 robots.txt网站通过Robots协议告诉搜索引擎哪些页面可以抓取，哪些页面不能抓取。robots.txt 通常存放于网站根目录。在source文件夹下新建robots.txt文件，文件内容如下： User-agent: *Allow: /Allow: /archives/Allow: /categories/Allow: /tags/Disallow: /vendors/Disallow: /js/Disallow: /lib/Disallow: /css/Disallow: /fonts/Sitemap: https://your_site.com/sitemap.xml Hexo正文中标题自动编号 安装heading-index: npm install hexo-heading-index --save 修改顶层_config.yml heading_index: enable: true index_styles: &quot;&#123;1&#125; &#123;1&#125; &#123;1&#125; &#123;1&#125; &#123;1&#125; &#123;1&#125;&quot; connector: &quot;.&quot; global_prefix: &quot;&quot; global_suffix: &quot;: &quot; 修改Hexo主题下的_config.yml， 避免侧边栏重复自动生成编号，禁用侧边栏自动编号 toc: enable: true # Automatically add list number to toc. number: false Hexo处理锚点的问题Markdown文章里的锚点,如果是本文内的锚点, 可以用[锚点名称](#章节),如果是章节外的锚点, 可以用https://URI/#章节 但是需要注意的是: 如果标题里带标点符号, 大多数情况下(比如常用的Hexo, Github, Gitlab的解析器)Markdown解析成html锚点后都会把标题里的英文标点符号转换成-, 但中文标题里的标点不会被转换. 英文字母要全部小写. 比如本文中的### 添加 robots.txt标题, 转成html后锚点变成添加-robots-txt: https://whatsrtos.github.io/blog_archive/Hexo部署和使用指北/#添加-robots-txt NexT 主题修改TocNexT主题的Toc列表是在sidebar显示的, 如果在手机或平板等小屏幕设备上不显示sidebar,如何在手机浏览时可以显示sidebar的Toc可以参考:Next主题小屏幕下保留侧边栏 | J.F’s BLOG NexT 主题自定义cssNexT的自定义文件在: source/css/_custom/custom.styl NexT 主题支持数学公式安装:npm install hexo-math --save 在站点配置文件 _config.yml 中添加：math: engine: &apos;mathjax&apos; # or &apos;katex&apos; mathjax: # src: custom_mathjax_source config: # MathJax config 在 next 主题配置文件中 themes/next-theme/_config.yml 添加：# MathJax Supportmathjax: enable: true per_page: false cdn: //cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML 使用:行内公式: $数学公式$行间公式, 独占一行: $$数学公式$$ 自定义post排序主页的post 默认是按创建时间排序，主页文章排序在配置文件： index_generator: path: &apos;&apos; per_page: 0 order_by: -date order_by 可以是 yaml front matter里定义的属性（没测试） 但是 category 页面的 post 排序没有可配置选项，需要直接改代码 node_modules/hexo-generator-category/lib/generator.js： var posts = category.posts.sort(&apos;title&apos;); // 按 yaml front matter 里的title排序 插件列表 [x] hexo-generator-index-pin-top: 增加文章置顶功能, 在文章 front-matter 里增加top: True即可 [ ] hexo-heading-index : 为标题(headings)添加自动编号 [x] hexo-generator-sitemap: 生成sitemap [x] hexo-excerpt: 主页显示文章摘要而不是全文 [ ] hexo-toc: 将markdown代码中的 &lt;!-- toc --&gt; 替换为TOC（Table Of Content） // 已知的问题: 会导致NexT的边栏TOC不可用 [x] hexo-math: mathjax 数学公式渲染 [x] hexo-backlink: 将obsidian的双链[[转换为 mkd 链接，但是不支持相对路径 问题修复node版本导致hexo g生成静态文件size=0降级node: brew uninstall nodebrew install node@12brew link --overwrite --force node@12 参考: MAC上配置Hexo部署GitHub Page | QueinDecim 解决 Hexo 在使用 Node.js 14 时的 Accessing non-existent property ‘xxx’ of module exports inside circular dependency 问题 - 好一则博 hexo-renderer-marked版本导致图片解析问题发现有些博文里的markdown图片没有正常解析, 看起来像是render的问题, 因为最近重新安装过hexo-renderer-marked,我的Hexo还是3.5版本, 在hexo-renderer-marked的github页面看到 0.2+版本适用于Hexo 3,用npm list 查看目前安装的hexo-renderer-marked版本, 已经是2.0.0了,所以试试降低hexo-renderer-marked的版本. 使用npm view hexo-renderer-marked versions命令查看所有已发布版本, 然后使用npm install hexo-renderer-marked@0.2.11 --save安装0.2版本的.ps: hexo-renderer-ejs, hexo-renderer-stylus 也需要降级 npm view hexo-renderer-stylus versionsnpm uninstall hexo-renderer-marked &amp;&amp; npm uninstall hexo-renderer-ejs &amp;&amp; npm uninstall hexo-renderer-stylusnpm install hexo-renderer-marked@0.2.11 --save &amp;&amp; npm install hexo-renderer-stylus@0.2.3 --save &amp;&amp; npm install hexo-renderer-ejs@0.2.0 --save 参考: http://www.jianshu.com/p/05289a4bc8b2 http://segmentfault.com/blog/zhongbaitu/1190000000458953 http://www.wuxubj.cn/2016/08/Hexo-nexT-build-personal-blog/","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"博客","slug":"博客","permalink":"https://beefyheisenberg.github.io/tags/博客/"},{"name":"Markdown","slug":"Markdown","permalink":"https://beefyheisenberg.github.io/tags/Markdown/"},{"name":"Hexo","slug":"Hexo","permalink":"https://beefyheisenberg.github.io/tags/Hexo/"}]},{"title":"EasyGrep使用简介","slug":"50.Farbox-Blog/【Vim】EasyGrep使用介绍","date":"2014-10-22T16:00:00.000Z","updated":"2024-01-24T01:27:53.035Z","comments":true,"path":"50.Farbox-Blog/【Vim】EasyGrep使用介绍/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【Vim】EasyGrep使用介绍/","excerpt":"Linux上使用Vim进行文件搜一般使用grep命令+grep.vim插件完成, 但在Windows上使用grep就有些不方便了, GnuWin32和UnxUtils虽然都提供了Windows移植版本的Grep.exe, 但都有bug, 比如: Gnuwin32 find.exe expands wildcard before performing search UnxUtils: #58 xargs: cannot fork 在Windows上使用grep还有一个折衷的办法: 使用Cygwin环境, 不过今天这里不讨论Cygwin…偶然在这个博客上发现了EasyGrep插件的介绍: vim中的杀手级插件: EasyGrep, 当时我是多么执着于在Windows上移植Grep和ack啊… 浪费了不少时间之后才发现还是使用现成的工具比较好-.- EasyGrep的安装如果你已经使用了Vundle管理Vim插件, 只需要在.vimrc里增加Bundle &#39;EasyGrep&#39;然后使用:BundleInstall安装即可.","text":"Linux上使用Vim进行文件搜一般使用grep命令+grep.vim插件完成, 但在Windows上使用grep就有些不方便了, GnuWin32和UnxUtils虽然都提供了Windows移植版本的Grep.exe, 但都有bug, 比如: Gnuwin32 find.exe expands wildcard before performing search UnxUtils: #58 xargs: cannot fork 在Windows上使用grep还有一个折衷的办法: 使用Cygwin环境, 不过今天这里不讨论Cygwin…偶然在这个博客上发现了EasyGrep插件的介绍: vim中的杀手级插件: EasyGrep, 当时我是多么执着于在Windows上移植Grep和ack啊… 浪费了不少时间之后才发现还是使用现成的工具比较好-.- EasyGrep的安装如果你已经使用了Vundle管理Vim插件, 只需要在.vimrc里增加Bundle &#39;EasyGrep&#39;然后使用:BundleInstall安装即可. How To Use \\vv or :Grep: \\vv命令将在文件中搜索当前光标下的单词, :Grep word将搜索”word”, 如果加叹号:Grep !word表示全词匹配的方式搜索, Grep也可以带参数, 比如:Grep -ir word, r表示递归目录. i表示不区分大小写. \\vV : 全词匹配搜索, 同:Grep !word; \\va : 与vv相似, 搜索结果append在上次搜索结果之后; \\vA : 与vV相似, 搜索结果append在上次搜索结果之后; \\vr or :Replace :替换; \\vo or :GrepOptions: 打开选项菜单; GrepOptions打开的界面: 上方红色的是快捷键help, 比如q是退出GrepOptions, r是开启递归搜索…下方兰色的可以选择搜索范围(回车选择): All表示全部搜索, Buffer表示只搜索当前打开的buff, TrackExt几乎包括所有常见的文件类型, 比如C++, PHP, Lisp等源文件. User是自己制定文件类型. Options Details每个Option的解释可以参考Github上的README &quot; plugin::EasyGrep &#123; let g:EasyGrepCommand = 1 &quot; vimgrep:0, grep:1 #vimgrep搜索较慢, 在Win上无需安装grep.exe let g:EasyGrepMode = 2 &quot; All:0, Open Buffers:1, TrackExt:2 # 1表示在已打开的buff中搜索, 2表示在当前文件相同扩展名的文件中搜索 let g:EasyGrepRecursive = 1 &quot; Recursive searching 递归搜索let g:EasyGrepRoot = cwd &quot; 设置搜索根路径, cwd:current dir let g:EasyGrepRoot = &quot;search:.git,.svn&quot; 设置搜索根路径为git/svn repos的根路径let g:EasyGrepRoot = &quot;search:.project&quot; 设置搜索根路径为包含.project文件的目录,这个文件需手动创建 let g:EasyGrepIgnoreCase = 1 &quot; Not ignore:0, ignore:1 大小写敏感 let g:EasyGrepFilesToExclude = &quot;tags, *.bak, *~, cscope.*, *.a, *.o, *.pyc, *.bak, *.swp&quot; &quot; &#125;","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"Vim","slug":"Vim","permalink":"https://beefyheisenberg.github.io/tags/Vim/"},{"name":"EasyGrep","slug":"EasyGrep","permalink":"https://beefyheisenberg.github.io/tags/EasyGrep/"}]},{"title":"还是告别 Linux Desktop了","slug":"50.Farbox-Blog/【开发环境】还是告别Linux-Desktop了","date":"2014-09-23T16:00:00.000Z","updated":"2024-01-24T01:27:53.136Z","comments":true,"path":"50.Farbox-Blog/【开发环境】还是告别Linux-Desktop了/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【开发环境】还是告别Linux-Desktop了/","excerpt":"用了几年Ubuntu,还有Fedora.曾经认为*nix的一切概念都比Windows更加合理. 但是… 折腾了这么久, 我还是决定换回Windows了. 至于原因,简单的解释就是: 无论哪个桌面OS都只是工具而已,在”折腾工具”上花费太多时间本身已经违背了工具被设计出来的初衷, 无论那个Linux桌面发行版(作为日常使用OS)距离”好用”还是有相当的差距. 比如Chrome for Linux版本播放flash的渣性能; 功耗控制的不完善,就算装了Tlp/Powertop,仍旧比不上Windows上Thinkpad自带的PowerManager; 双显卡虽然有Bumblebee,但性能还是比不上NVIDIA Optimus一半; 多少开源的中文字体, 在Chrome上居然都不如微软的雅黑表现出色… 此外,还有Thinkpad的指纹识别,APS硬盘保护(老朽的HDAPS已经不能支持新款的Tp了). 值得吐槽的地方还有很多很多, 没法一一举例. 当你在google,stackexchange上查了好多答案,折腾了许久,却发现只实现了Windows上同等功能(可能还不及),这是多么败兴的事情-.- 上面提到的,或许有些人不赞同是Linux自身的原因,而是因为”大多数硬件厂商对Linux支持不够”. 唉,说直白一点, 桌面Linux败就败在了生态环境上. 无论Linux在服务器上表现如何, 都救不了Linux Desktop.","text":"用了几年Ubuntu,还有Fedora.曾经认为*nix的一切概念都比Windows更加合理. 但是… 折腾了这么久, 我还是决定换回Windows了. 至于原因,简单的解释就是: 无论哪个桌面OS都只是工具而已,在”折腾工具”上花费太多时间本身已经违背了工具被设计出来的初衷, 无论那个Linux桌面发行版(作为日常使用OS)距离”好用”还是有相当的差距. 比如Chrome for Linux版本播放flash的渣性能; 功耗控制的不完善,就算装了Tlp/Powertop,仍旧比不上Windows上Thinkpad自带的PowerManager; 双显卡虽然有Bumblebee,但性能还是比不上NVIDIA Optimus一半; 多少开源的中文字体, 在Chrome上居然都不如微软的雅黑表现出色… 此外,还有Thinkpad的指纹识别,APS硬盘保护(老朽的HDAPS已经不能支持新款的Tp了). 值得吐槽的地方还有很多很多, 没法一一举例. 当你在google,stackexchange上查了好多答案,折腾了许久,却发现只实现了Windows上同等功能(可能还不及),这是多么败兴的事情-.- 上面提到的,或许有些人不赞同是Linux自身的原因,而是因为”大多数硬件厂商对Linux支持不够”. 唉,说直白一点, 桌面Linux败就败在了生态环境上. 无论Linux在服务器上表现如何, 都救不了Linux Desktop. 据说DELL有一款XPS开发者版本预装Ubuntu,不知道DELL和 Canonical最终合作的如何, 我猜很可能不了了之, 双方都没有动力和理由花费太多的时间和精力把这个做好. 唉. 顺带吐槽几个著名发行版: 因为Ubuntu的淳朴乡村风紫棕配色感到烦恼，并且Unity的Lens Dash让我不胜其烦，除了会让我硬盘转个不停泄露我的隐私之外几乎没任何作用。格了，重装。 Gnome3,又是一个不想多评价的东西, Active简直就是设计中的败笔, 非得按一下Alt+Tab键才能看到正在运行的程序, 或者委屈一下右手里捂着的鼠标不辞千里从屏幕的某个角落飞奔到屏幕右上角。艹，如果我一次开了十个程序，切换一次简直就是灾难。难道非得让我回到石器时代的Gnome Classic ??? OK, No Ubuntu，No Gnome，那就尝试下Fedora 21 KDE, 但Fedora 21仍旧采用上世纪90年代城乡接合范儿金属拉丝style的UIKDE4。并且Fedora的KDE版本大有向Kubuntu靠拢的趋势，从Fedora 21 KDE让我感觉到了KDE正在被Fedora社区渐渐冷落，等到新版本发布时连个像样的KDE Spin都拿不出来，正当我看着几年都无长进的Fedora KDE寻思着要不要继续重装时，KDE挂掉了，，， Gentoo和Arch就是给整天不用上班的重装系统爱好者们折腾消遣的小玩具。 彻底死心透透的，还是回到Windows7吧, 加上Cygwin足够了Linux for Desktop只是一种情怀而已. OS X才是*uix for desktop的最终形态.","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"Linux Desktop","slug":"Linux-Desktop","permalink":"https://beefyheisenberg.github.io/tags/Linux-Desktop/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://beefyheisenberg.github.io/tags/Ubuntu/"}]},{"title":"Shell 的进化 - Zsh","slug":"50.Farbox-Blog/【效率工具】Shell的进化-Zsh","date":"2014-06-15T16:00:00.000Z","updated":"2024-01-24T01:27:53.110Z","comments":true,"path":"50.Farbox-Blog/【效率工具】Shell的进化-Zsh/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【效率工具】Shell的进化-Zsh/","excerpt":"(1) Zsh和Oh-my-zsh的安装(1.1) install zshOSX自带了zsh，不必再安装. 对于Redhat系/Debian系的Linux，使用yum/apt-get工具安装: sudo -c &#39;yum install zsh&#39;. (1.2) install oh-my-zsh方式1 自动安装:wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh方式2 手动安装:git clone git://github.com/robbyrussell/oh-my-zsh.git ~/.oh-my-zshcp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc","text":"(1) Zsh和Oh-my-zsh的安装(1.1) install zshOSX自带了zsh，不必再安装. 对于Redhat系/Debian系的Linux，使用yum/apt-get工具安装: sudo -c &#39;yum install zsh&#39;. (1.2) install oh-my-zsh方式1 自动安装:wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh方式2 手动安装:git clone git://github.com/robbyrussell/oh-my-zsh.git ~/.oh-my-zshcp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc (2) 切换到zsh已经安装完了zsh和oh-my-zsh，接下来在终端里输入zsh就可以进入了.然后输入chsh把默认的bash切换到zsh，chsh的具体用法可以man. (3) zsh的简单体验zsh的自动补全很强大，所有你能想象到的都可以用tab触发补全，甚至kill这样的命令也支持补全了-.-! 比如想kill掉fcitx，直接输入kill fcitx再加tab就可以了，你会看到zsh已经把有关fcitx的进程id都列出来，我觉得时间久了会被zsh的智能补全惯坏，对不对？在.zshrc里加入alias -s c=gvim，就相当于把*.c文件和gvim关联起来了，假如我当前目录下有个test.c文件，在终端直接输入test.c+回车，gvim就自动打开这个文件了，很方便.当然，还支持 alias -s tgz='tar -xzvf'alias -s bz2='tar -xjvf' 这样的关联，你再也不必记住tar的z和j参数了! (4) zsh的主题/插件zsh的配置文件在~/.zshrc，打开后找到”ZSH_THEME”一行: ZSH_THEME=&quot;robbyrussell&quot; 修改这里可以改变zsh的主题.更多的主题可以在~/.oh-my-zsh/themes目录找到. 再找到”plugin”一行:plugins=(git ruby autojump mvn gradle)上面分别启用了git，ruby，autojump等几个插件. 其中git是默认已经安装的，下面介绍autojump: (4.1) 插件之一autojumpautojump提供了一个快速切换当前目录的功能，比如我经常使用的目录是~/workspace，在任何目录下只要输入j wo就能自动跳转到~/workspace了.安装步骤: git clone https://github.com/joelthelion/autojump.gitcd autojumppython ./install.py 不要忘记在.zshrc中启用autojump这个插件，并且在.zshrc里加入一行: [[ -s ~/.autojump/etc/profile.d/autojump.sh ]] &amp;&amp; . ~/.autojump/etc/profile.d/autojump.sh之后你就能用j 目录名快速切换目录了，甚至不用输入完整的目录名，autojump会根据你的使用习惯记录下常用目录，关于目录优先权重可以用autojump -s查看: 22.4: /home/xxx/Dropbox/Fedora One22.4: /home/xxx/Github26.5: /home/xxx/Dropbox (5) bye，bashbash再见了，最后备份一下bash的配置cp ~/.bashrc ~/Dropbox/我的bash里还有一些有用的东西，比如mark-directory，这个工具有些类似autojump，也是方便你在各个常用目录间跳来跳去的，只不过需要在目录下运行一下mark加”书签”，然后j dir_name跳转，当然也是支持tab补全的，食用方式也很简单，在.bashrc加入下面的配置: # mark-directory: provide a quick way to change directory from the command line# github.com/dangoakachan/mark-directoryexport MARKPATH=$HOME/.marksfunction j &#123; cd -P \"$MARKPATH/$1\" 2&gt;/dev/null || echo \"No such mark: $1\"&#125;function mark &#123; mkdir -p \"$MARKPATH\"; ln -s \"$(pwd)\" \"$MARKPATH/$1\"&#125;function unmark &#123; rm -i \"$MARKPATH/$1\"&#125;function marks &#123; ls -l \"$MARKPATH\" | sed 's/ / /g' | cut -d' ' -f9- | sed 's/ -/\\t-/g' &amp;&amp; echo&#125;_completemarks() &#123; local curw=$&#123;COMP_WORDS[COMP_CWORD]&#125; local wordlist=$(find $MARKPATH -type l -printf \"%f\\n\") COMPREPLY=($(compgen -W '$&#123;wordlist[@]&#125;' -- \"$curw\")) return 0&#125;complete -F _completemarks j unmark","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://beefyheisenberg.github.io/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://beefyheisenberg.github.io/tags/Shell/"},{"name":"Zsh","slug":"Zsh","permalink":"https://beefyheisenberg.github.io/tags/Zsh/"}]},{"title":"在 Linux 上安装 BitTorrent Sync","slug":"50.Farbox-Blog/【效率工具】在Linux上安装BitTorrent-Sync","date":"2014-06-04T16:00:00.000Z","updated":"2024-01-24T01:27:53.123Z","comments":true,"path":"50.Farbox-Blog/【效率工具】在Linux上安装BitTorrent-Sync/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【效率工具】在Linux上安装BitTorrent-Sync/","excerpt":"BitTorrent Sync是一款同步工具，和Dropbox/Google Drive这些云存储的区别是，BitTorrent Sync不用连接服务器，而是基于P2P分布式进行设备和设备之间的文件同步，支持PC（Win/Linux/Mac），FreeBSD，Android，iOS设备。用BitTorrent Sync可以方便的在同一局域网里的PC/智能设备之间同步文件。 1.下载&amp;安装：两种安装方式：通过PPA安装，或直接下载二进制文件。 1.1 方式1sudo add-apt-repository ppa:tuxpoldo/btsyncsudo apt-get updatesudo apt-get install btsync-user","text":"BitTorrent Sync是一款同步工具，和Dropbox/Google Drive这些云存储的区别是，BitTorrent Sync不用连接服务器，而是基于P2P分布式进行设备和设备之间的文件同步，支持PC（Win/Linux/Mac），FreeBSD，Android，iOS设备。用BitTorrent Sync可以方便的在同一局域网里的PC/智能设备之间同步文件。 1.下载&amp;安装：两种安装方式：通过PPA安装，或直接下载二进制文件。 1.1 方式1sudo add-apt-repository ppa:tuxpoldo/btsyncsudo apt-get updatesudo apt-get install btsync-user 1.2 方式2在BitTorrent Sync官网下载对应的二进制包，然后解压：cd Downloadstar xvzf btsync_x64.tar.gz -C /opt 2.启动如果用1.2的方式安装，需要把对应路径加入$PATH,然后在终端输入btsync即可启动； 3.配置完整的config可以参考：btsync --dump-sample-config在浏览器内打开：http://127.0.0.1:8888/gui/或者编辑/etc/btsync/下的配置文件 参考：How to run BitTorrent Sync?","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://beefyheisenberg.github.io/tags/Linux/"},{"name":"BitTorrent","slug":"BitTorrent","permalink":"https://beefyheisenberg.github.io/tags/BitTorrent/"}]},{"title":"C语言的编译与链接 - gcc/ld/ar等工具的介绍","slug":"50.Farbox-Blog/【C语言】C语言的编译与链接","date":"2014-05-21T16:00:00.000Z","updated":"2024-01-24T01:27:52.990Z","comments":true,"path":"50.Farbox-Blog/【C语言】C语言的编译与链接/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【C语言】C语言的编译与链接/","excerpt":"这篇半成品已经在硬盘上放了好久了, 今天终于忍无可忍, 熬夜也要写完(▔皿▔)起因是因为一个makefile引起的 undefined reference 问题, 下面贴出出错的makefile: 起因：Makefile错误CC = gccCXX = g++LD = ldd$(CPP_OBJS): $(DIR_OBJ)/%.o: %.cpp $(CXX) $(CFLAGS) -o $@ $&lt; $(INCLUDE)$(OBJS): $(DIR_OBJ)/%.o: %.c $(CC) -c $(CFLAGS) -o $@ $&lt; $(INCLUDE)$(APP): $(OBJS) $(CPP_OBJS) $(CC) $^ -o $(APP) $(LDFLAGS) $(INCLUDE) 这个makefile很简单，g++将.cpp文件编译为 \\.o, gcc将 *.c 文件编译为 *.o, 最后 gcc链接所有的 *.o生成可执行程序.但是上面这个简单的 makefile, 执行make时却报错了: &gt; gcc -o _test_code.o _test_code.c -I./usr/lib/gcc/x86_64-redhat-linux/4.7.2/../../../../lib64/crt1.o: In function &apos;_start&apos;:(.text+0x20): undefined reference to &apos;main&apos;collect2: error: ld returned 1 exit status","text":"这篇半成品已经在硬盘上放了好久了, 今天终于忍无可忍, 熬夜也要写完(▔皿▔)起因是因为一个makefile引起的 undefined reference 问题, 下面贴出出错的makefile: 起因：Makefile错误CC = gccCXX = g++LD = ldd$(CPP_OBJS): $(DIR_OBJ)/%.o: %.cpp $(CXX) $(CFLAGS) -o $@ $&lt; $(INCLUDE)$(OBJS): $(DIR_OBJ)/%.o: %.c $(CC) -c $(CFLAGS) -o $@ $&lt; $(INCLUDE)$(APP): $(OBJS) $(CPP_OBJS) $(CC) $^ -o $(APP) $(LDFLAGS) $(INCLUDE) 这个makefile很简单，g++将.cpp文件编译为 \\.o, gcc将 *.c 文件编译为 *.o, 最后 gcc链接所有的 *.o生成可执行程序.但是上面这个简单的 makefile, 执行make时却报错了: &gt; gcc -o _test_code.o _test_code.c -I./usr/lib/gcc/x86_64-redhat-linux/4.7.2/../../../../lib64/crt1.o: In function &apos;_start&apos;:(.text+0x20): undefined reference to &apos;main&apos;collect2: error: ld returned 1 exit status 错误分析 &amp; 解决要解释上面的问题, 先来回顾下gcc是如何将*.c编译为可执行程序的, 共4个步骤: 预编译: gcc -E test.c -o test.i 生成汇编代码: gcc -S test.i -o test.s 编译 x.s为 x.o: gcc -c test.s -o test.o 当然 x.c也可以用 -c参数一步编译为 x.o 链接为可执行文件: gcc test.o -o test 报错很明确的告诉我: lib64/crt1.o 里的_start函数调用了main()函数, 但main()函数缺少定义.工程中main()函数的定义放在源文件 main.cpp中, 为什么还报 undefined reference to ‘main’呢?看仔细了, 是在将 test_code.cpp编译为 test_code.o的时候报错, test_code.cpp里没有main()的定义,这个 makefile的”本意”是这样的: 第一步 g++将 x.cpp文件编译为 x.o, 第二步 gcc将 x.c文件编译为 x.o, 最后 gcc链接所有的 x.o生成可执行程序.按道理说, 第一步编译只是进行语法分析并生成中间文件, 并不会去找函数有没有定义, 只有在三步链接所有 x.o的时候才可能报出 undefined reference func的错误.再仔细看看上面的 makefile: $(CXX) $(CFLAGS) -o $@ $&lt; $(INCLUDE)是没有加 -c参数的, 相当于让 g++一步编译出最终文件(可执行文件), 当然会报 undefined reference 的错误了.原来是一个笔误🙃 修改也很简单, x.c/x.cpp编译为x.o的过程加上 \b-c参数就可以了, 正确的 makefile如下: $(CPP_OBJS): $(DIR_OBJ)/%.o: %.cpp $(CXX) -c $(CFLAGS) -o $@ $&lt; $(INCLUDE)$(OBJS): $(DIR_OBJ)/%.o: %.c $(CC) -c $(CFLAGS) -o $@ $&lt; $(INCLUDE)$(APP): $(OBJS) $(CPP_OBJS) $(CC) $^ -o $(APP) $(LDFLAGS) $(INCLUDE) 错误日志里的新发现再回头看看上面的报错里有一句: lib64/crt1.o: In function &apos;_start&apos;:(.text+0x20): undefined reference to &apos;main&apos; 这个 crt1.o是什么? 这个function _start 又是什么🤔? 从上面的打印信息可以知道, gcc先编译出 xxx.o然后再做 Link, 这时候 gcc会对 /usr/lib/crt1.o和我们的 main.o做链接 (因为 crt1.o里的_start函数调用了我们的 main()函数).由此可见, 可自行文件真正的”入口”并不是 main(), 而是 ctr1.o里的_start, 事实上这个库的名字里 “crt”就是 “startup routine”的意思.所以, gcc在链接所有的 x.o时, 还会把 /usr/lib/crt1.o也链接进来.此外gcc有一个默认参数-lc, 表示动态链接 libc库. 扩展阅读: crt1.o,crti.o,crtbegin.o,crtend.o ,crtn.o 与libc.so 的关系 - farmwang的专栏 - CSDN博客 编译过程中的链接: ld下面是一个分三步编译出 a.out的例子 $ gcc -S main.c -o main.s$ gcc -c main.s -o main.o$ gcc main.o -o a.out 我们知道在编译汇编程序时, 也是分compile,link两个步骤: as hello.s -o hello.old hello.o -o hello c程序用 gcc链接, 汇编程序用 ld来做链接, 那么这个 ld能不能直接用于 c程序的链接呢?我们可以试一下, 用 ld去链接所有的 x.o : $(LD) $^ -o $(APP) $(LDFLAGS) $(INCLUDE)然后make clean &amp;&amp; make all, 会报错:ld: cannot find -lstdc++ @ref (http://sp1.wikidot.com/gnulinker) 附录 I编译“编译”的概念： 1、利用编译程序从源语言编写的源程序产生目标程序的过程。 2、用编译程序产生目标程序的动作，编译就是把高级语言变成计算机可以识别的2进制语言。 编译程序把一个源程序翻译成目标程序的工作分为5个阶段：词法分析、语法分析、语义检查和中间代码生成、代码优化、目标代码生成。主要是进行词法分析和语法分析。 链接链接就是对.o文件进行符号解析和重定位的过程，链接器就是用来完成不同模块之间的链接问题。 符号解析：当一个模块使用了在该模块中没有没有定义过的函数或者全局变量时，编译器生成的符号表会标记出所有这样的函数或者全局变量。而连接器的责任就是要到别的模块中去查找它们的定义，如果没有找到适合的定义或者找到的合适定义不唯一，符号解析就无法正常完成。 重定位：编译器在编译生成目标文件时，通常都使用从零开始的相对地址。然而，在链接过程中，连接器将从一个指定的地址开始，根据输入的目标文件的顺序以段为单位将它们一个接一个拼接起来。除了目标文件的拼装之外，在重定位的过程中还完成了两个任务：一是生成最终的符号表；二是对代码段的某些位置进行修改，所有需要修改的位置都由编译器生成的重定位表指出。 附录 IIGNU GCC简介：GNU GCC是一套面向嵌入式领域的交叉编译工具，支持多种编程语言、多种优化选项并且能够支持分步编译、支持多种反汇编方式、支持多种调试信息格式，目前支持X86、ARM7、StrongARM、PPC4XX、MPC8XX、MIPS R3000等多种CPU。GNU GCC的基本功能包括： 输出预处理后的C/C++源程序（展开头文件和替换宏） 输出C/C++源程序的汇编代码 输出二进制目标文件 生成静态库 生成可执行程序 转换文件格式 GCC 组成： (1) C/C++交叉编译器gccgcc是编译的前端程序，它通过调用其他程序来实现将程序源文件编译成目标文件的功能。编译时，它首先调用预处理程序(cpp)对输入的源程序进行处理，然后调用 cc1 将预处理后的程序编译成汇编代码，最后由as将汇编代码编译成目标代码。gcc具有丰富的命令选项，可以控制编译的各个阶段，满足用户的各种编译需求。 (2) 汇编器 asas将汇编语言程序转换为ELF (Executable and Linking Format，执行时链接文件格式)格式的可重定位目标代码，这些目标代码同其它目标模块或函数库易于定位和链接。as产生一个交叉参考表和一个标准的符号表，产生的代码和数据能够放在多个区 (Section)中。 as hello.s -o hello.o #这一步将汇编源码*.s编译为*.old hello.o -o hello #这一步将*.o链接, 生成ELF (3) 连接器ldld根据链接定位文件Linkcmds中的代码区、数据区、BSS区和栈区等定位信息，将可重定位的目标模块链接成一个单一的、绝对定位的目标程序。该目标程序是ELF格式，并且可以包含调试信息。ld会产生一个内存映象文件Map.txt,该文件显示所有目标模块、区和符号的绝对定位地址。它也产生交叉参考列表，显示参考每个全局符号的目标模块。ld支持将多个目标模块链接成一个单一的、绝对定位的目标程序，也能够依此对目标模块进行链接，这个特性称为增量链接(Incremental Linking)。假如输入文件是一个函数库，ld会自动从函数库装载被其它目标模块参考的函数模块。ld与其它链接程序相比，能提供更有帮助的诊断信息。许多链接器遇到第一个错误即放弃链接，而ld只要有可能都继续执行，帮助用户识别其它错误，有时甚至能获得输出代码。 (4) 库管理器arar将多个可重定位的目标模块归档为一个函数库文件。采用函数库文件，应用程序能够从该文件中自动装载要参考的函数模块，同时将应用程序中频繁调用的函数放入函数库文件中，易于应用程序的开发管理。ar支持ELF格式的函数库文件. $ gcc -c 1.c 2.c 3.c # 生成1.o, 2.o, 3.o$ ar rs lib123.a 1.o 2.o 3.o # 将所有*.o打包成lib123.a: (5) 工程管理器MAKEMake是用于自动编译、链接程序的实用工具,使用make后就不需要手工的编译每个程序文件。要使用make,首先要编写makefile。Makefile描述程序文件之间的依赖关系，并提供更新文件的命令。在一个程序中，可执行文件依赖于目标文件,而目标文件依赖于源文件。如果makefile文件存在,每次修改完源程序后，用户通常所需要做的事情就是在命令行敲入“make”,然后所有的事情都由make来完成。","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"C/C++","slug":"C-C","permalink":"https://beefyheisenberg.github.io/tags/C-C/"},{"name":"gcc","slug":"gcc","permalink":"https://beefyheisenberg.github.io/tags/gcc/"}]},{"title":"终端复用软件 - tmux","slug":"50.Farbox-Blog/【效率工具】终端复用软件-Tmux","date":"2014-05-20T16:00:00.000Z","updated":"2024-01-24T01:27:53.145Z","comments":true,"path":"50.Farbox-Blog/【效率工具】终端复用软件-Tmux/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【效率工具】终端复用软件-Tmux/","excerpt":"（一）What‘s tmux？”tmux是一个优秀的终端复用软件，类似GNU Screen，但来自于OpenBSD，采用BSD授权。使用它最直观的好处就是，通过一个终端登录远程主机并运行tmux后，在其中可以开启多个控制台而无需再”浪费”多余的终端来连接这台远程主机；当然其功能远不止于此。” （二）一些概念tmux使用C/S模型构建，主要包括以下单元模块：server服务：输入tmux命令时就开启了一个服务器。session会话： 一个服务器可以包含多个会话。window窗口：一个会话可以包含多个窗口。pane面板：一个窗口可以包含多个面板。 （三）命令&amp;快捷键","text":"（一）What‘s tmux？”tmux是一个优秀的终端复用软件，类似GNU Screen，但来自于OpenBSD，采用BSD授权。使用它最直观的好处就是，通过一个终端登录远程主机并运行tmux后，在其中可以开启多个控制台而无需再”浪费”多余的终端来连接这台远程主机；当然其功能远不止于此。” （二）一些概念tmux使用C/S模型构建，主要包括以下单元模块：server服务：输入tmux命令时就开启了一个服务器。session会话： 一个服务器可以包含多个会话。window窗口：一个会话可以包含多个窗口。pane面板：一个窗口可以包含多个面板。 （三）命令&amp;快捷键3.1命令参数：tmux ： 打开tmux，退出是Ctrl+D ；tmux new-session -s &quot;sessionX&quot; -d ： 开启一个名字为”sessionX”会话，-d参数是将此会话放入后台不显示；tmux new-window -n &quot;Win1&quot; -t sessionX &#39;top&#39; ： -t是指定名为”sessionX”的会话，在这个会话上开启一个窗口并将此窗口命名为”Win1”，并在此窗口执行top命令；tmux split-window -h ： 开启一个竖屏tmux split-window -v &quot;top&quot; ： 开启一个横屏,并执行top命令tmux attach -t sessionX ： 重新attach上会话”sessionX” 3.2快捷键：以下列出的所有命令都需要先按下Ctrl+b，如果你不习惯这个绑定，可以在~/.tmux.conf文件中修改，下面会提及。Now， 打开终端输入tmux ：基本快捷键：---------? 列出所有快捷键；按q返回d 脱离当前会话,可暂时返回Shell界面，输入tmux attach能够重新进入之前会话s 选择并切换会话；在同时开启了多个会话时使用D 选择要脱离的会话；在同时开启了多个会话时使用: 进入tmux命令行模式；此时可输入支持的命令，例如kill-server所有tmux会话[ 复制模式，光标移动到复制内容位置，空格键开始，方向键选择复制，回车确认，q/Esc退出] 进入粘贴模式，粘贴之前复制的内容，按q/Esc退出~ 列出提示信息缓存；其中包含了之前tmux返回的各种提示信息t 显示当前的时间Ctrl+z 挂起当前会话窗口操作:--------c 创建新窗口&amp; 关闭当前窗口数字键 切换到指定窗口p 切换至上一窗口n 切换至下一窗口l 前后窗口间互相切换w 通过窗口列表切换窗口, 重命名当前窗口，便于识别. 修改当前窗口编号，相当于重新排序f 在所有窗口中查找关键词，便于窗口多了切换面板操作:-------” 将当前面板上下分屏% 将当前面板左右分屏x 关闭当前分屏方向键 移动光标选择对应面板空格键 可以在默认面板布局中切换，试试就知道了! 将当前面板置于新窗口,即新建一个窗口,其中仅包含当前面板Ctrl+方向键 以1个单元格为单位移动边缘以调整当前面板大小Alt+方向键 以5个单元格为单位移动边缘以调整当前面板大小q 显示面板编号o 选择当前窗口中下一个面板&#123; 向前置换当前面板&#125; 向后置换当前面板Alt+o 逆时针旋转当前窗口的面板Ctrl+o 顺时针旋转当前窗口的面板z tmux 1.8新特性，最大化当前所在面板 粘贴&amp;复制：请参考：Copy &amp; Paste in tmux 滚屏：Ctrl+b，pageUp/pageDown进入翻页模式，此模式下可以用”上下翻页键”or”上下方向键”翻页，q是退出翻页模式。 （四）配置文件用户配置文件在~/.tmux.conf ，下面是一个示例：#此类配置可以在命令行模式中输入show-options -g查询set-option -g base-index 1 #窗口的初始序号；默认为0，这里设置为1set-option -g display-time 5000 #提示信息的持续时间；设置足够的时间以避免看不清提示，单位为毫秒set-option -g repeat-time 1000 #控制台激活后的持续时间；设置合适的时间以避免每次操作都要先激活控制台，单位为毫秒set-option -g status-keys vi #操作状态栏时的默认键盘布局；可以设置为vi或emacsset-option -g status-right &quot;#(date +%H:%M&apos; &apos;)&quot; #状态栏右方的内容；这里的设置将得到类似23:59的显示set-option -g status-right-length 10 #状态栏右方的内容长度；建议把更多的空间留给状态栏左方（用于列出当前窗口）set-option -g status-utf8 on 开启状态栏的UTF-8支持#此类设置可以在命令行模式中输入show-window-options -g查询set-window-option -g mode-keys vi #复制模式中的默认键盘布局；可以设置为vi或emacsset-window-option -g utf8 on #开启窗口的UTF-8支持#将激活控制台的快捷键由Ctrl+b修改为Ctrl+aset-option -g prefix C-aunbind-key C-bbind-key C-a send-prefix#添加自定义快捷键bind-key z kill-session #按z结束当前会话；相当于进入命令行模式后输入kill-sessionbind-key h select-layout even-horizontal #按h将当前面板布局切换为even-horizontal；相当于进入命令行模式后输入select-layout even-horizontalbind-key v select-layout even-vertical #按v将当前面板布局切换为even-vertical；相当于进入命令行模式后输入select-layout even-vertical （五）远程使用tmux例如我已经在树莓派服务器上打开了一个tmux session，然后detach session；当再次SSH登录树莓派的时候可以用下面的命令重新attach上去，以便恢复上次的工作状态。：ssh pi@192.168.1.107 -t &#39;tmux list-session; if [[ $? -eq 0 ]]; then tmux attach; else tmux;fi&#39; 参考： FreeBSDChina Wiki","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://beefyheisenberg.github.io/tags/Linux/"},{"name":"tmux","slug":"tmux","permalink":"https://beefyheisenberg.github.io/tags/tmux/"}]},{"title":"Git 的 SSH KEY 配置","slug":"50.Farbox-Blog/【版本控制】Git的SSH Key配置","date":"2014-05-12T16:00:00.000Z","updated":"2024-01-24T01:27:53.082Z","comments":true,"path":"50.Farbox-Blog/【版本控制】Git的SSH Key配置/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【版本控制】Git的SSH Key配置/","excerpt":"生成SSH Key 生成SSH KEY: ssh-keygen -t rsa -C &quot;your_email@example.com&quot; , 然后会提示输入公钥的名字，如果你需要多个SSH-KEY（比如有多个github帐号）就需要在命名的时候区分一下，这样在/用户HOME目录/.ssh/文件夹下生成两个文件：xxx_rsa.pub和 xxx_rsa，分别是你的公钥和私钥。 生成SSH KEY的时候还要求输入私钥密码 “Enter passphrase (empty for no passphrase):”， 请记住私钥的密码，后面会用到。 将SSH 私钥增加到ssh-agent: ssh-add ~/.ssh/id_rsa， 这里会提示输入一次私钥的密码; 查看已经add的SSH KEY： ssh-add -l； 如果提示 ssh agent没启动: eval ssh-agent -s 非必要步骤: 安装xclip(终端到剪切板的工具): sudo yum install xclip , 将公钥内容拷贝到剪切板: xclip -sel clip &lt; ~/.ssh/id_rsa.pub 浏览器登录自己的github页面，进入”Account Settings”，再点击左边的”SSH Key”可以看到自己上传过的SSH公钥列表。再点击”Add SSH Key”新增一个公钥，把公钥(~/.ssh/id_rsa.pub) 文件内容粘贴过来。 测试SSH Key登录 打开终端, 测试: ssh -T git@github.com;你可能会看到下面的错误信息: Agent admitted failure to sign using the key.debug1: No more authentication methods to try.Permission denied (publickey).","text":"生成SSH Key 生成SSH KEY: ssh-keygen -t rsa -C &quot;your_email@example.com&quot; , 然后会提示输入公钥的名字，如果你需要多个SSH-KEY（比如有多个github帐号）就需要在命名的时候区分一下，这样在/用户HOME目录/.ssh/文件夹下生成两个文件：xxx_rsa.pub和 xxx_rsa，分别是你的公钥和私钥。 生成SSH KEY的时候还要求输入私钥密码 “Enter passphrase (empty for no passphrase):”， 请记住私钥的密码，后面会用到。 将SSH 私钥增加到ssh-agent: ssh-add ~/.ssh/id_rsa， 这里会提示输入一次私钥的密码; 查看已经add的SSH KEY： ssh-add -l； 如果提示 ssh agent没启动: eval ssh-agent -s 非必要步骤: 安装xclip(终端到剪切板的工具): sudo yum install xclip , 将公钥内容拷贝到剪切板: xclip -sel clip &lt; ~/.ssh/id_rsa.pub 浏览器登录自己的github页面，进入”Account Settings”，再点击左边的”SSH Key”可以看到自己上传过的SSH公钥列表。再点击”Add SSH Key”新增一个公钥，把公钥(~/.ssh/id_rsa.pub) 文件内容粘贴过来。 测试SSH Key登录 打开终端, 测试: ssh -T git@github.com;你可能会看到下面的错误信息: Agent admitted failure to sign using the key.debug1: No more authentication methods to try.Permission denied (publickey). 上面的错误在某些Linux发行版（比如我的Fedora 17）是一个已知的错误， 可以忽略。然后会看到打印出公钥的指纹，请确认此指纹和你公钥的一致，然后输入”yes”确认。 “ Hi your_name! You’ve successfully authenticated, but GitHub does not provide shell access.” 如果your_name正确显示你的ID，则说明成功设置了SSH公钥. 一台机器上管理多个SSH Key如果你在一台机器使用两个github账号（比如私人账号和工作账号）, 两个帐号用不同的SSH KEY，还需要编辑一下配置文件~/.ssh/config: Host code.company.com HostName code.company.com PreferredAuthentications publickey IdentityFile ~/.ssh/key_for_companyHost github.com HostName github.com PreferredAuthentications publickey IdentityFile ~/.ssh/key_for_github 解释此配置文件： HostName：比如我工作的git仓储地址是`git@code.company.com:username/repo_name.git, 那么我的HostName就要填code.company.com`; IdentityFile： 所使用的公钥文件; 配置完毕，用下面的命令测试一下： ssh -vT git@github.comHi xyz! You&apos;ve successfully authenticated, but GitHub does not provide shell access. 注： @符号后面的”github.com”就是在~/.ssh/config文件中指定的Host项 (1) 为已经clone下来的repos指定ssh-key：在已经检出的repos目录下执行: git config user.name your_name &amp;&amp; git config user.email your_email 上面git config只对该项目生效 修改.git/config并找到[remote &quot;origin&quot;],修改url的值为： [remote &quot;origin&quot;] url = git@github.com:&lt;user_name&gt;/&lt;repos_name&gt;.git (2) 使用指定ssh-key 重新clone一个reop: 使用指定账号clone:执行git clone git@github.com:user_name/repos_name.git git clone git@github.com:user_name/repos_name.gitCloning into ‘repos_name’… 然后还需要config一下user.name和user.email, 进入本地git仓库目录执行: git config user.name your_name &amp;&amp; git config user.email your_email 以后在此repos下执行git push origin master就是使用指定的用户push. 参考：《Quick Tip: How to Work with GitHub and Multiple Accounts》《Multiple SSH Keys settings for different github account》《多个github帐号的SSH key切换》《GitHub: Generating SSH Keys》","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"SSH","slug":"SSH","permalink":"https://beefyheisenberg.github.io/tags/SSH/"},{"name":"Git","slug":"Git","permalink":"https://beefyheisenberg.github.io/tags/Git/"},{"name":"Github","slug":"Github","permalink":"https://beefyheisenberg.github.io/tags/Github/"}]},{"title":"SSH 协议简介","slug":"50.Farbox-Blog/【效率工具】SSH协议简介","date":"2014-05-10T16:00:00.000Z","updated":"2024-01-24T01:27:53.106Z","comments":true,"path":"50.Farbox-Blog/【效率工具】SSH协议简介/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【效率工具】SSH协议简介/","excerpt":"关于SSH协议:Secure Shell（缩写为SSH）,SSH为一项创建在应用层和传输层基础上的安全协议，为计算机上的Shell（壳层）提供安全的传输和使用环境。传统的网络服务程序，如rsh、FTP、POP和Telnet其本质上都是不安全的；因为它们在网络上用明文传送数据、用户帐号和用户口令，很容易受到中间人（man-in-the-middle）攻击方式的攻击。就是存在另一个人或者一台机器冒充真正的服务器接收用户传给服务器的数据，然后再冒充用户把数据传给真正的服务器。而SSH是目前较可靠，专为远程登录会话和其他网络服务提供安全性的协议。利用SSH协议可以有效防止远程管理过程中的信息泄露问题。通过SSH可以对所有传输的数据进行加密，也能够防止DNS欺骗和IP欺骗。SSH之另一项优点为其传输的数据可以是经过压缩的，所以可以加快传输的速度。SSH有很多功能，它既可以代替Telnet，又可以为FTP、POP、甚至为PPP提供一个安全的“通道”。 以上来自 维基百科:SSH SSH的应用SSH最常见的就是远程登录了，替代了不安全的telnet方式，使用ssh远程登录的方式很简单，在终端输入ssh user@host就可以登录到远程主机了。除了“远程登录”这个基本功能之外，SSH还有端口转发、口令登录、公钥登录等用途。","text":"关于SSH协议:Secure Shell（缩写为SSH）,SSH为一项创建在应用层和传输层基础上的安全协议，为计算机上的Shell（壳层）提供安全的传输和使用环境。传统的网络服务程序，如rsh、FTP、POP和Telnet其本质上都是不安全的；因为它们在网络上用明文传送数据、用户帐号和用户口令，很容易受到中间人（man-in-the-middle）攻击方式的攻击。就是存在另一个人或者一台机器冒充真正的服务器接收用户传给服务器的数据，然后再冒充用户把数据传给真正的服务器。而SSH是目前较可靠，专为远程登录会话和其他网络服务提供安全性的协议。利用SSH协议可以有效防止远程管理过程中的信息泄露问题。通过SSH可以对所有传输的数据进行加密，也能够防止DNS欺骗和IP欺骗。SSH之另一项优点为其传输的数据可以是经过压缩的，所以可以加快传输的速度。SSH有很多功能，它既可以代替Telnet，又可以为FTP、POP、甚至为PPP提供一个安全的“通道”。 以上来自 维基百科:SSH SSH的应用SSH最常见的就是远程登录了，替代了不安全的telnet方式，使用ssh远程登录的方式很简单，在终端输入ssh user@host就可以登录到远程主机了。除了“远程登录”这个基本功能之外，SSH还有端口转发、口令登录、公钥登录等用途。 （一）SSH端口转发SSH 还同时提供了一个非常有用的功能，这就是端口转发。SSH 会自动加密和解密所有 SSH 客户端与服务端之间的网络数据。它能够将其他 TCP 端口的网络数据通过 SSH 链接来转发，并且自动提供了相应的加密及解密服务。这一过程有时也被叫做“隧道”（tunneling），这是因为 SSH 为其他 TCP 链接提供了一个安全的通道来进行传输而得名。例如，Telnet，SMTP，LDAP 这些 TCP 应用均能够从中得益，避免了用户名，密码以及隐私信息的明文传输。SSH 端口转发能够提供两大功能： 加密 SSH Client 端至 SSH Server 端之间的通讯数据。 突破防火墙的限制完成一些之前无法建立的 TCP 连接。 1.1例：使用SSH端口转发翻越GFW首先， 你要现在互联网上申请一个免费的SSH, 我用的是cjb . 申请完成后会得到邮件发来的 SSH主机地址 和 帐号密码 , 然后打开终端输入ssh -D 9999 xxxxx@216.194.70.6： $ ssh -D 9999 xxxxx@216.194.70.6The authenticity of host ‘216.194.70.6 (216.194.70.6)’ can’t be established.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added ‘216.194.70.6’ (RSA) to the list of known hosts.xxxx@216.194.70.6‘s password: 参数-D的意思就是bind，端口绑定。上面ssh -D 9999即是指明将SSH数据转发到端口9999。顺带一提，由于shell.cjb.net的域名被污染, 所以上面SSH登录时没有使用cjb.net的域名只能用ip地址。浏览器以Firefox为例，在代理设置中新增一个SOCKS主机 127.0.0.1，端口9999，类型SOCKS v5。此外开启Firefox的用隧道解析DNS开关：在FF地址栏输入about:config，搜索并设置参数network.proxy.socks_remote_dns的值为true(双击即可改变其值)。现在打开Twitter测试一下吧。 有关SSH端口转发的内容还可以IBM developerworks上的参考:实战 SSH 端口转发 （二）口令登录整个过程简单描述如下：（1）远程主机收到用户的登录请求，把自己的公钥发给用户。（2）用户使用这个公钥，将登录密码加密后，发送回来。（3）远程主机用自己的私钥，解密登录密码，如果密码正确，就同意用户登录。 使用命令ssh user@host 或者ssh -p 指定端口 user@host命令登录, 如果是第一次登录, 会收到下面的警告: The authenticity of host ‘host (12.18.429.21)’ can’t be established.RSA key fingerprint is 98:2e:d7:e0:de:9f:ac:67:28:c2:42:2d:37:16:58:4d.Are you sure you want to continue connecting (yes/no)? 上面一段话的意思是: 无法确认host主机的真实性，只知道它的公钥指纹，是否继续?用户可以从host的网站或者其他公开信息的地方获取其公钥的指纹, 然后自己核对. 当用户接受connect后, 就相当于远程主机host的公钥被接受了，远程主机的公钥就会被保存在本机文件$HOME/.ssh/known_hosts之中。下次再连接这台远程主机就会跳过上面的警告部分，直接提示输入密码。每个SSH用户都有自己的known_hosts文件，此外系统也有一个这样的文件，通常是/etc/ssh/ssh_known_hosts，保存一些对所有用户都可信赖的远程主机的公钥。 （三）公钥登录过程如下:(1)用户将自己的公钥储存在远程主机上。(2)用户登录的时候，远程主机会向用户发送一段验证字符串，(3)用户用自己的私钥加密后，再发回远程主机。远程主机用事先储存的用户的公钥进行解密，如果成功，就证明用户是可信的，直接允许登录shell，不再要求密码。公钥登录的使用也相当广泛，比如Github就使用“公钥登录”的方式, 使用户可以不用输入密码就可以git push代码 参考：阮一峰的博客: SSH原理与运用（一）：远程登录","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"SSH","slug":"SSH","permalink":"https://beefyheisenberg.github.io/tags/SSH/"},{"name":"端口转发","slug":"端口转发","permalink":"https://beefyheisenberg.github.io/tags/端口转发/"}]},{"title":"非对称加密算法 RSA 简介以及 GPG 工具的使用","slug":"50.Farbox-Blog/【效率工具】加密算法RSA简介以及GPG工具的使用","date":"2014-05-08T16:00:00.000Z","updated":"2024-01-24T01:27:53.140Z","comments":true,"path":"50.Farbox-Blog/【效率工具】加密算法RSA简介以及GPG工具的使用/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【效率工具】加密算法RSA简介以及GPG工具的使用/","excerpt":"非对称加密算法RSA简介先来回顾一下”非对称加密算法”的概念, 以下引用自阮一峰的博客: （1）乙方生成两把密钥（公钥和私钥）。公钥是公开的，任何人都可以获得，私钥则是保密的。（2）甲方获取乙方的公钥，然后用它对信息加密。（3）乙方得到加密后的信息，用私钥解密。 如果公钥加密的信息只有私钥解得开，那么只要私钥不泄漏，通信就是安全的。","text":"非对称加密算法RSA简介先来回顾一下”非对称加密算法”的概念, 以下引用自阮一峰的博客: （1）乙方生成两把密钥（公钥和私钥）。公钥是公开的，任何人都可以获得，私钥则是保密的。（2）甲方获取乙方的公钥，然后用它对信息加密。（3）乙方得到加密后的信息，用私钥解密。 如果公钥加密的信息只有私钥解得开，那么只要私钥不泄漏，通信就是安全的。 1977年，三位数学家Rivest、Shamir 和 Adleman 设计了一种算法，可以实现非对称加密。这种算法用他们三个人的名字命名，叫做RSA算法。从那时直到现在，RSA算法一直是最广为使用的”非对称加密算法”。毫不夸张地说，只要有计算机网络的地方，就有RSA算法。 一, 使用GnuPGGnuPG（英文：GNU Privacy Guard，简称：GPG）GnuPG使用用户自行生成的非对称密钥对来加密信息，由此产生的公钥可以同其他用户以各种方式交换，如密钥服务器。GnuPG还可以向信息添加一个加密的数字签名，这样，收件人可以验证信息完整性和发件人。 (来自维基百科) 下面介绍使用GnuPG 实现电子邮件加密和数字签名, 参考了阮一峰的博客, 注意下面关于gpg工具的介绍都是基于命令行的, 其实Gnome和KDE都自带了图形化的密钥管理工具(分别是Seahorse和Kgpg), 这样在新建/管理自己的密钥&amp;&amp; 使用他人的公钥会更加简单, 但是下面我们介绍的还是使用命令行的gpg. 1.1 安装GnuPG在Fedora/CentOS上使用yum安装GnuPG: sudo yum install gnupg如果通过源码编译的方式, 可以在这里获取源码. 编译方式三步: ./configuremakemake install 1.2 生成密钥:输入gpg --gen-key命令生成密钥, 回车后会提示需要生成的密钥类型, 例如: (1) RSA and RSA (default)(2) DSA and Elgamal(3) DSA (仅用于签名)(4) RSA (仅用于签名) 选择第一个, 表示加密和签名都是RSA算法. 然后命令行提示所需密钥的长度(1024~4096位), 我们这里选择2048(默认值). 接着是设定密钥有效期, 这里选择”0”, 表示永不过期. 然后是提供个人信息, 包括 姓名, 邮箱, 注释, 其中前两项姓名 &amp;&amp; 邮箱是必要的, 注释可以不填写, 输入完成之后gpg会生成一个”用户ID”, 下面是一个生成ID的范例: “Heinrich Heine &#104;&#x65;&#105;&#x6e;&#x72;&#105;&#x63;&#104;&#x68;&#x40;&#x64;&#x75;&#x65;&#115;&#115;&#x65;&#x6c;&#x64;&#x6f;&#x72;&#102;&#x2e;&#x64;&#101;“ 确认自己的”用户ID”之后, 系统还会要求输入一个私钥的密码, 防止他人使用自己的私钥. You need a Passphrase to protect your secret key.Enter passphrase: 最后系统开始生成密钥, 期间可能要求你产生一些”随机数”, 解释如下: 我们需要生成大量的随机字节。这个时候您可以多做些琐事(像是敲打键盘、移动鼠标、读写硬盘之类的)，这会让随机数字发生器有更好的机会获得足够的熵数。 几分钟后密钥生成, 然后会提示如下: gpg: key 9A69C57C marked as ultimately trustedpublic and secret key created and signed. 注意上面的字符串”9A69C57C”，这是我的”用户ID”的Hash字符串，可以用来替代”用户ID”。 1.3 管理密钥1.3.1 查看/删除密钥列出系统中存储的密钥: gpg --list-keys删除某个密钥: gpg --delete-key [用户ID] , “用户ID”可以是邮件地址或者Hash字符串. 1.3.2 密钥的导出和存储公钥的二进制文件存储在~/.gnupg/pubring.gpg将公钥以ASCII码显示并存储到文本文件public-key.txt中: gpg --armor --output public-key.txt --export [用户ID] 备份自己的公钥: gpg -o public-key --export [用户ID] , 其中-o参数后面是导出的公钥文件名字.备份自己的私钥 : gpg -oa seckey.asc --export-secret-keys [用户ID] ,其中-oa参数后面就是导出的私钥, 可以在其他机器上通过gpg --import seckey.asc导入. 1.3.3 发布公钥因特网上有很多免费的公钥服务器, 你可以把自己的公钥发布到任意一个服务器, 这些服务器之间会互相同步. 命令gpg --send-keys [用户ID] --keyserver hkp://subkeys.pgp.net 1.3.4 获取他人的公钥通过email地址获取他人的公钥, gpg --keyserver hkp://subkeys.pgp.net --search-keys [用户ID] .由于公钥服务器没有审查机制, 也就是说任何人都能用你的email名义上传公钥, 获取到他人的公钥后, 还要验证下此公钥的指纹: gpg --fingerprint [用户ID], 然后可以通过电话/短信/QQ向对方确认指纹, 如果指纹一致就能确认这个公钥是对方所分发的. 1.4 使用密钥1.4.1 使用公钥加密文件使用对方的公钥加密文件:gpg --recipient [用户ID] --output file.en.txt --encrypt file.txt .参数解释: recipient参数指定接收者的公钥，output参数指定加密后的文件名，encrypt参数指定源文件。 1.4.2 解密文件对方收到加密文件以后用自己的私钥解密:gpg --decrypt file.en.txt --output file.de.txt参数解释: decrypt参数指定需要解密的文件，output参数指定解密后生成的文件。 1.4.3 对文件进行签名签名的意思就是”证明是公钥所有者分发的”, 命令为gpg --sign file.txt . 运行上面的命令后，当前目录下生成file.txt.gpg文件，这就是签名后的文件. 1.4.4 验证签名gpg --verify file.txt.asc file.txt 1.4.4 密钥和邮件客户端的使用使用Gnome邮件客户端Evo对邮件进行加密和签名: 参考使用 GnuPG 实现电子邮件加密和数字签名——PGP 30分钟简明教程第四部分. 以及如何在Thunderbird使用GPG","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"加密算法","slug":"加密算法","permalink":"https://beefyheisenberg.github.io/tags/加密算法/"},{"name":"RSA","slug":"RSA","permalink":"https://beefyheisenberg.github.io/tags/RSA/"},{"name":"GPG","slug":"GPG","permalink":"https://beefyheisenberg.github.io/tags/GPG/"}]},{"title":"树莓派手动玩","slug":"50.Farbox-Blog/【Raspberry】树莓派手动玩","date":"2014-05-07T16:00:00.000Z","updated":"2024-01-24T01:27:53.022Z","comments":true,"path":"50.Farbox-Blog/【Raspberry】树莓派手动玩/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【Raspberry】树莓派手动玩/","excerpt":"半年前败了一个树莓派，因为工作很忙所以没时间折腾一下。最近换工作，确认了offer，赋闲在家，也终于有空摆弄一下树莓派。 （一）启用SSH我的环境为：Thinkpad（Fedora）， TP-Link无线路由，树莓派（debian）一只。树莓派通过网线连接到无线路由器和电脑处于同一网段，没有显示器的情况下如何确定树莓派的IP呢？ 这时候nmap登场： nmap -v -sP 192.168.1.1/10稍等片刻，然后可以看到Raspberry Pi的设备。 或者用手机上的一款应用Fing也可以扫描本网段的端口。","text":"半年前败了一个树莓派，因为工作很忙所以没时间折腾一下。最近换工作，确认了offer，赋闲在家，也终于有空摆弄一下树莓派。 （一）启用SSH我的环境为：Thinkpad（Fedora）， TP-Link无线路由，树莓派（debian）一只。树莓派通过网线连接到无线路由器和电脑处于同一网段，没有显示器的情况下如何确定树莓派的IP呢？ 这时候nmap登场： nmap -v -sP 192.168.1.1/10稍等片刻，然后可以看到Raspberry Pi的设备。 或者用手机上的一款应用Fing也可以扫描本网段的端口。 树莓派默认安装了SSH服务，SSH登录的方式为：ssh pi@树莓派ip地址，默认密码为：raspberry 为了安全, 推荐关闭root用户ssh登录, 方法为修改”/etc/ssh/sshd_config”, 将 PermitRootLogin yes 改为 PermitRootLogin no重启ssh服务: service ssh restart （二）树莓派初始化设置并安装VNC SSH上去之后第一件事就是更新debian: sudo apt-get update, 升级完成后重启一下; 在SSH终端输入sudo raspi-config, 这里需要打开几个选项: expand_rootfs – 将根分区扩展到整张SD卡; change_pass – 默认的用户名是pi，密码是raspberry; change_timezone – 更改时区, 选择Asia – Shanghai; configure_keyboard, 选English（US）; change_locale – 更改语言设置，选择en_US.UTF-8和zh_CN.UTF-8 设置完成后，选择Finish，会提示是否重启，选择Yes 在树莓派上安装vnc服务端（debian）：sudo apt-get install tightvncserver 在PC上安装vnc客户端（fedora）：sudo yum -y install tigervnc 如果你的PC是Windows系统, 可以下载TightVNC 安装其他常用软件: sudo apt-get install -y git build-essential vim tmux curl VNC (Virtual Network Console)是虚拟网络控制台的缩写。它 是一款优秀的远程控制工具软件，由著名的 AT&amp;T 的欧洲研究实验室开发的。VNC 是在基于 UNIX 和 Linux 操作系统的免费的开源软件，远程控制能力强大，高效实用，其性能可以和 Windows 和 MAC 中的任何远程控制软件媲美。 在 Linux 中，VNC 包括以下四个命令：vncserver，vncviewer，vncpasswd，和 vncconnect。大多数情况下用户只需要其中的两个命令：vncserver 和 vncviewer。 2.1 在树莓派上配置VNC 首先要修改vnc密码：SSH终端里执行vncpasswd，然后输入两遍密码。 创建vnc-server配置文件：sudo vi /etc/init.d/tightvncserver ,在这个文件里输入如下内容： ### BEGIN INIT INFO# Provides: tightvncserver# Required-Start: $local_fs# Required-Stop: $local_fs# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: Start/stop tightvncserver### END INIT INFO# More details see:# http://www.penguintutor.com/linux/tightvnc### Customize this entry# Set the USER variable to the name of the user to start tightvncserver underexport USER=&apos;pi&apos;### End customization requiredeval cd ~$USERcase &quot;$1&quot; in start) su $USER -c &apos;/usr/bin/tightvncserver -depth 16 -geometry 800x600 :1&apos; echo &quot;Starting TightVNC server for $USER &quot; ;; stop) su $USER -c &apos;/usr/bin/tightvncserver -kill :1&apos; echo &quot;Tightvncserver stopped&quot; ;; *) echo &quot;Usage: /etc/init.d/tightvncserver &#123;start|stop&#125;&quot; exit 1 ;;esacexit 0 然后给增加执行权限，并启动服务： sudo chmod +x /etc/init.d/tightvncserversudo service tightvncserver stopsudo service tightvncserver start 安装chkconfig， 并将vnc服务设为开机启动： sudo apt-get install chkconfigchkconfig --add tightvncserverchkconfig tightvncserver on 2.2 PC端连接树莓派打开VNC Viewer， 输入“IP地址:1”，（这里冒号后面的1是指终端号，如果不填则是终端0）然后回车输入密码。 注：如果使用终端0，可能会导致下面的错误 unable connect to socket connection refused 111 （三）摄像头树莓派支持两种摄像头，官方的raspberry camera和任何符合UVC标准的USB摄像头。如果要支持摄像头，需要在sudo raspi-config时选择”enable camera”. 测试摄像头: 拍摄一张照片raspistill -o cam.jpg 拍摄视频raspivid -o vid.h264","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"树莓派","slug":"树莓派","permalink":"https://beefyheisenberg.github.io/tags/树莓派/"},{"name":"SSH","slug":"SSH","permalink":"https://beefyheisenberg.github.io/tags/SSH/"},{"name":"VNC","slug":"VNC","permalink":"https://beefyheisenberg.github.io/tags/VNC/"}]},{"title":"Git 简易指北","slug":"50.Farbox-Blog/【版本控制】Git简易使用指北","date":"2014-05-02T16:00:00.000Z","updated":"2024-01-24T01:27:53.087Z","comments":true,"path":"50.Farbox-Blog/【版本控制】Git简易使用指北/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【版本控制】Git简易使用指北/","excerpt":"推荐先阅读一下在线版本Git简明指南 http://rogerdudler.github.io/git-guide/index.zh.html 如果你的一台电脑上管理多个Github帐号的SSH Keys，请参照SSH协议的应用 &amp;为Github配置SSH Key Git工作流的概念你的本地仓库由 git 维护的三棵“树”组成。第一个是你的 工作目录，它持有实际文件；第二个是 暂存区（Index），它像个缓存区域，临时保存你的改动；最后是 HEAD，它指向你最后一次提交的结果。盗用一下别人的图: 1.新建仓库首先在github上创建一个新的repository，然后","text":"推荐先阅读一下在线版本Git简明指南 http://rogerdudler.github.io/git-guide/index.zh.html 如果你的一台电脑上管理多个Github帐号的SSH Keys，请参照SSH协议的应用 &amp;为Github配置SSH Key Git工作流的概念你的本地仓库由 git 维护的三棵“树”组成。第一个是你的 工作目录，它持有实际文件；第二个是 暂存区（Index），它像个缓存区域，临时保存你的改动；最后是 HEAD，它指向你最后一次提交的结果。盗用一下别人的图: 1.新建仓库首先在github上创建一个新的repository，然后$ cd ~/repos_name/$ touch README.md$ git init$ git add .$ git commit -m \"first commit\"$ git remote add origin https://github.com/username/repos_name.git$ git push -u origin master 如果是已有项目:cd existing_git_repogit remote add origin https://git.oschina.net/whatsdjgpp/CodeBox.gitgit push -u origin master 2.提交代码$ git add *$ git commit -m \"代码提交信息\"$ git push origin master 执行git commit之后只是将改提交到了本地的HEAD, 而git push将改动提交到远端仓库, 可以把 master 换成你想要推送的任何分支. 如果你还没有克隆现有仓库，又想将代码改动某个远程服务器，你可以使用如下命令添加：git remote add origin 3.修改默认值$ git config --global user.name \"xxx\"$ git config --global user.email xxx@gmail.com$ git config --global core.editor gvim$ git config --global merge.tool gvimdiff 注意， 这里加了“–global”参数，设置参数会存储在～/.git/config。如果要针对某个仓库进行设置，则是：cd repos_dirgit config user.name &quot;your-id&quot;git config user.email &quot;your-id@gmail.com&quot; 配置会写入“仓库目录/.git/config” 4.从Git上删除文件$ git rm test.txt$ rm 'test.txt'$ git commit -m \"remove test.txt\" 5.从服务器获取最新代码$ git pull 相当于两个命令 Git fetch + Git merge, 从服务器的仓库中获取代码，和本地代码合并. 6.对比代码$ git diff 7.检出别人的仓库执行如下命令以创建一个本地仓库的克隆版本：git clone /path/to/repository 如果是远端服务器上的仓库，你的命令会是这个样子：git clone username@host:/path/to/repository 如何让git忽略某些文件在本地仓库目录新建.gitignore文件并添加以下内容：obj\\*.so*.o*.swp 将会自动忽略目录“obj”，以及.so，.o等类型的文件 如果你手误了…干掉本地的改动, 以服务器上的代码为准:git fetch origingit reset --hard origin/master 分支概念Git在创建仓储的时候, 默认有一个”master”分支, 可以在”master”上拉出分支, 修改完成后再merge到master上.创建一个叫做“feature_x”的分支，并切换过去：git checkout -b feature_x切换回主分支：git checkout master再把新建的分支删掉： git branch -d feature_x除非你将分支推送到远端仓库，不然该分支就是不为他人所见的：git push origin","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"SSH","slug":"SSH","permalink":"https://beefyheisenberg.github.io/tags/SSH/"},{"name":"Git","slug":"Git","permalink":"https://beefyheisenberg.github.io/tags/Git/"},{"name":"Github","slug":"Github","permalink":"https://beefyheisenberg.github.io/tags/Github/"}]},{"title":"Linux 下配置 NFS 服务","slug":"50.Farbox-Blog/【开发环境】Linux下配置NFS服务","date":"2014-03-31T16:00:00.000Z","updated":"2024-01-24T01:27:53.091Z","comments":true,"path":"50.Farbox-Blog/【开发环境】Linux下配置NFS服务/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【开发环境】Linux下配置NFS服务/","excerpt":"环境: Fedora &amp; Ubuntu 安装NFS服务 yum -y install nfs-utils 对于Ubuntu则是: apt-get install nfs-kernel-server nfs-common","text":"环境: Fedora &amp; Ubuntu 安装NFS服务 yum -y install nfs-utils 对于Ubuntu则是: apt-get install nfs-kernel-server nfs-common 以上都需要root权限. 配置NFS编辑 /etc/exports, 添加如下内容:/home/steffan/nfs *(insecure,rw,sync,no_root_squash) 注意星号*表示允许所有ip访问, 可以改为自己的ip. 且*后不能有空格, 带空格的话mount的时候会有错误提示mount.nfs: access denied by server while mounting 编辑 /etc/idmapd.conf搜索并修改为Domain为自己的主机名. 启动NFS为了方便做了一个启动NFS的脚本xNFS(适用于Fedora): touch /usr/local/xNFSchmod a+x /usr/local/xNFS 在xNFS脚本增加以下内容: #!/bin/shecho &quot;start service...&quot;systemctl start rpcbind.servicesystemctl start nfs-server.servicesystemctl start nfs-lock.servicesystemctl start nfs-idmap.serviceecho &quot;enable service...&quot;systemctl enable rpcbind.servicesystemctl enable nfs-server.servicesystemctl enable nfs-lock.servicesystemctl enable nfs-idmap.serviceecho &quot;check service status&quot;systemctl status rpcbind.servicesystemctl status nfs-server.servicesystemctl status nfs-lock.servicesystemctl status nfs-idmap.service 对于Ubuntu,用下面的命令启动NFS服务: sudo /etc/init.d/portmap startsudo /etc/init.d/nfs-kernel-server start 测试NFS以NFS将本地目录挂载到/mnt: mount -t nfs localhost:/home/steffan/nfs /mnt/nfs 测试下/mnt/nfs是否能正常读写. 如果在树莓派等开发板上挂载NFS目录: mount x.x.x.x:/home/steffan/nfs /mnt/nfs 其他内容Fedora上可以安装图形化NFS配置工具: yum search system-config-nfs 如果mount失败, 可以考虑暂时关闭防火墙:开启： service iptables start关闭： service iptables stop或者这样关闭: /etc/init.d/iptables stop 参考:http://www.server-world.info/en/note?os=Fedora_17&amp;p=nfshttp://blog.csdn.net/dos5gw/article/details/5787914","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://beefyheisenberg.github.io/tags/Linux/"},{"name":"NFS","slug":"NFS","permalink":"https://beefyheisenberg.github.io/tags/NFS/"}]},{"title":"Markdown 入门指北","slug":"50.Farbox-Blog/【Markdown】Markdown入门指北","date":"2014-03-25T15:20:00.000Z","updated":"2024-01-24T01:27:53.013Z","comments":true,"path":"50.Farbox-Blog/【Markdown】Markdown入门指北/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【Markdown】Markdown入门指北/","excerpt":"几种不同的Markdown语法标准 原生Markdown GFM（Github Flavored Markdown）: 采用围栏式（Fenced式）区块代码：在代码的上下一行用3个反引号，可选择性定义代码语种，并支持代码高亮。 列表嵌套方法：改为每次嵌套缩进两个空格。 支持任务列表：在每个列表项目加入[ ]，完成任务用 [x] 支持简单表格 PFM（Pandoc Flavored Markdown）: 支持简单表格、多行表格、格框表格和管线表格四种表格样式 支持文件标题区块（类似元数据） 支持上标、下标 支持数字公式 支持内嵌TeX … MultiMarkdown 支持元数据：标题、作者、日期等信息，兼容部分YAML。 支持添加链接和图片的属性。 支持部分复杂表格：兼容PHP Markdown Extra的表格，同时可以——多行表头，单元格横向合并，表格分区，表格下行表格说明等。 支持脚注：同PHP Markdown Extra中的脚注。 支持参考文献（Citations） … 参考: 不同的Markdown语法 - 少数派 GFM(GitHub Flavored Markdown)与标准Markdown的语法区别 - 三十六变 - 博客园 Markdown语法","text":"几种不同的Markdown语法标准 原生Markdown GFM（Github Flavored Markdown）: 采用围栏式（Fenced式）区块代码：在代码的上下一行用3个反引号，可选择性定义代码语种，并支持代码高亮。 列表嵌套方法：改为每次嵌套缩进两个空格。 支持任务列表：在每个列表项目加入[ ]，完成任务用 [x] 支持简单表格 PFM（Pandoc Flavored Markdown）: 支持简单表格、多行表格、格框表格和管线表格四种表格样式 支持文件标题区块（类似元数据） 支持上标、下标 支持数字公式 支持内嵌TeX … MultiMarkdown 支持元数据：标题、作者、日期等信息，兼容部分YAML。 支持添加链接和图片的属性。 支持部分复杂表格：兼容PHP Markdown Extra的表格，同时可以——多行表头，单元格横向合并，表格分区，表格下行表格说明等。 支持脚注：同PHP Markdown Extra中的脚注。 支持参考文献（Citations） … 参考: 不同的Markdown语法 - 少数派 GFM(GitHub Flavored Markdown)与标准Markdown的语法区别 - 三十六变 - 博客园 Markdown语法(0)换行和转义换行: 文字末尾两个或以上的空格.转义: \\ (1)一级/二级题目一级题目和正文之间用”====”分开如果是二级题目，则用“—-”分开 题目 ===== 正文 (2) 标题Atx-风格的标题在每行的开头使用1－6个#号字符，分别对应标题级别1－6 (3) 列表无序列表可使用星号“*”、加号“+”和连字符 “-” * Red * Green * Blue 有序列表用“数字. ”的方式 1. RED 2. GREEN (4)代码块在行内插入一句代码的话，将代码用两个包括起来即可，这是夹杂着一些代码的文字内容。在每行开头，或者段落开头使用&gt;符号也可以引用一个段落，直到遇到空行段落结束。如果是代码块，可以在行首增加Tab，注意除了每行开头都有Tab之外， 每行结束也要有两个及以上空格表示一行结束。 代码块在遇到没有TAB缩进的一行，或者文件末尾时自动结束。除此之外还有使用三个”`”，或者 的方式包围代码块： void bubble_sort(int* a, int size)&#123; _DEBUG_ENTER(bubble_sort); int i,j; for(i=1; i&lt;size-1; i++) for(j=0; j&lt;size-i; j++) &#123; if(a[j]&gt;a[j+1]) &#123; swap_array(&amp;a[j],&amp;a[j+1]); &#125; &#125;&#125; (5)引用只需要在行开头增加&gt;符号+空格即可： 这是一行引用的文字 引用结束前要有包括两个以上空格的“空行”作为引用结束的标记。 (6)强调Markdown 使用星号（*）和底线（_）作为标记强调字词的符号，被 * 或 _ 包围的字词会被转为粗斜体. 例如:强调 或者 _强调_加重强调 或者 加重强调 (7)超链接使用 &lt;&gt; 包括的 URL 或邮箱地址会被自动转换为超链接,例如：[微博](http://weibo.com) 效果是这样的： 微博 (8)图片使用！[]来放置图片， 例如：![sebug.net](http://ssvq5.sinaapp.com/sv4/img/ssv_logo_3ee2.png &quot;sebug.net&quot;) 效果如下 Markdown历史Markdown是一种轻量级标记语言，创始人为John Gruber。它允许人们“使用易读易写的纯文本格式编写文档，然后转换成有效的XHTML（或者HTML）文档”。 自从John Gruber2004年发布Markdown之后，Markdown进入了自由生长的状态，因为创始人John Gruber打自2004年之后就没有更新过Markdown。因为原生Markdown只是一个轻量级的标记语言，很多功能不具备。为了扩充Markdown的功能，很多Markdown拓展语法被开发出来，其中著名的有GFM、PHP Markdown Extra、MultiMarkdown、Pandoc Markdown（PFM）等等: GFM: Github扩展的Markdown语法，这种衍生Markdown叫做Github Flavored Markdown，简称 GFM。与原生Markdown主要区别： 采用围栏式（Fenced式）区块代码：在代码的上下一行用3个反引号 ```，可选择性定义代码语种，并支持代码高亮； 列表嵌套缩进两个空格； 支持任务列表：[x] 支持简单表格 删除线（新增）：用两个波浪号~~ MultiMarkdown: 原生markdown文档只能从纯文本转换HTML。而MultiMarkdown则是扩大了原生markdown的转换范围，让其可以方便的转换成：HTML/XHTML、LaTeX、OPML。与原生Markdown主要区别： 支持YAML元数据 支持脚注 支持部分复杂表格 支持参考文献（Citations） 支持栅栏式区块代码：上下行3到5个反引号包裹代码 支持MathJax公式（区块与行内） 支持上标与下标 支持目录：添加目录 Pandoc’s Markdown（PFM） 围栏式区块代码 区块引用之前一定要预留空行 … 参考: 关于 markdown， pandoc 和 LaTeX 的入门安利 - Towdium’s here | A personal blog","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"https://beefyheisenberg.github.io/tags/Markdown/"}]},{"title":"C语言里面的一些陷阱","slug":"50.Farbox-Blog/【C语言】C语言里面的一些陷阱","date":"2014-03-02T16:00:00.000Z","updated":"2024-01-24T01:27:52.995Z","comments":true,"path":"50.Farbox-Blog/【C语言】C语言里面的一些陷阱/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【C语言】C语言里面的一些陷阱/","excerpt":"C语言里面的陷阱非常多, 多到写了几年C之后还是会不断的踩, 首先, 本文没多少原创内容, 大部分都来自笔记整理.我们先看几个有关Printf函数的坑： 坑: Printf（一）// 下面一段代码的打印是什么？ int64_t a = 1; int b = 2; printf(\"%d %d\",a,b); 运行一下这段代码, 发现打印出来的结果并不是期望的“1 2”, 而是“1 0”, why？这就涉及到 printf 的设计了, printf的第一个参数是字符串, 上面代码中第一个参数是“%d %d”, printf会解析每一个%d这样的结构, 然后将指针做偏移, 偏移的字节数与%后面的类型有关, 例如%d是4字节, %lld是8字节, %c是偏移1字节.所以, 在上面代码中printf(“%d, %d\\n”, a, b)实际两个%d分别取得是 a 的低4字节和高4字节, 从而分别是1和0（测试环境是小端, 所以低地址的是LSB）. 参考 @ref","text":"C语言里面的陷阱非常多, 多到写了几年C之后还是会不断的踩, 首先, 本文没多少原创内容, 大部分都来自笔记整理.我们先看几个有关Printf函数的坑： 坑: Printf（一）// 下面一段代码的打印是什么？ int64_t a = 1; int b = 2; printf(\"%d %d\",a,b); 运行一下这段代码, 发现打印出来的结果并不是期望的“1 2”, 而是“1 0”, why？这就涉及到 printf 的设计了, printf的第一个参数是字符串, 上面代码中第一个参数是“%d %d”, printf会解析每一个%d这样的结构, 然后将指针做偏移, 偏移的字节数与%后面的类型有关, 例如%d是4字节, %lld是8字节, %c是偏移1字节.所以, 在上面代码中printf(“%d, %d\\n”, a, b)实际两个%d分别取得是 a 的低4字节和高4字节, 从而分别是1和0（测试环境是小端, 所以低地址的是LSB）. 参考 @ref printf-小代码, 大问题 从printf谈可变参数函数的实现 坑: Printf（二）// 下面一段代码的打印是什么？ char c1 = 0x70; // 0111 0000 char c2 = 0xe0; // 1111 0000 printf(\"0x%x 0x%x\",c1,c2); 打印出来的结果并不是期望的“0x70 0xe0”, 而是“70 ffffffe0”, 为什么0x70打印正常, 0xe0打印出的数值前面多了很多ffff呢？原因是： 变参函数, 比如printf, 会把所有精度小于int的参数提升为int, char是有符号8位数, 所以被提升为4字节的int,由于c2的最高位是1（负数）, 所以被提升为ffffffe0 所以, 对于用%x 格式打印下面几个char型都会被提升为int： char intc0 -&gt; ffffffc080 -&gt; ffffff8061 -&gt; 00000061 解决方法就是用“位与”截取第8位： char ch = 0xC0;printf(\"%x\", ch &amp; 0xff); 参考 @ref 《Printing hexadecimal characters in C》 《The %x format specifier with an unsigned char in C》 坑: 隐式类型提升 什么是类型提升: 变量由低精度提升到高精度类型, 这个不多解释.整型提升: char/short/enum(无论符号)在可能的情况下会提升为int, 如果int能够完整的表示源类型的所有值, 那么就先提升为int, 如果不能则提升为unsigned int, 需要注意的一点是, 这个提升顺序和有无符号没有关系, unsigned char会先提升到int(有符号), 如果int无法完整表示源数据再尝试unsigned int.从上面可以得知, 整形提升可以看作有两种情况: 1是char/short提升到int, 2是int提升到unsigned int, 有符号int有时候会提升为unsigned int, 例如int型的-1(负数为补码存放1111..110), 提升为无符号int后就变成了4294967295, 最高位符号位也被当作自身的值了…看到下面的代码运行结果请不要惊奇: unsigned int a = 10000;int b = -1;if(a &lt; b) &#123; printf(\"1000 &lt; -1\");&#125; 分析: 上面的例子中的if表达式是int和unsigned int的比较,由于后者精度更高, 导致int类型的-1先被转换位unsigned int类型. 有符号的-1在内存中存储为”1000…01”, 转换为无符号整形是一个很大的数. 在 AnsiC 标准中提出的原则是，优先使用 int，并尽量保证提升后值的含义不变。也就是：如果 int 可以表达转换前的类型，则转换为 int，否则转换为 unsigned int。 在哪些情况下会产生隐式类型提升?有些类型提升是在我们”预料之内”的, 比如char型和int型相加操, 但还有一些”隐式”的类型提升在我们的”预料之外”, 当char、short int或者int（无论signed或unsigned）以及枚举类型出现在”可以使用int或者unsigned int的表达式”中, 则会导致整形提升. if里的表达式: 如果if(char)则括号里的被提升为int, 如果if(a&lt;b)中a和b类型不一致也会自动提升为精度更高的类型. 函数入参: 定义函数void func(unsigned int), 当传入参数是int时. 有size_t类型的形参, 比如memcpy(mybuf, buf, len), 不慎把一个int型的len传入, 长度有可能转成一个很大的整数, 如果mybuf的尺寸不够大则会… 以下摘自The C Programming Language, 第一版, P39 : 在表达式中，每个 char 都被转换为 int ···注意所有位于位于表达式中的 float 都被转换为 double ···由于函数参数也是一个表达式，所以当参数传递给函数时也会发生类型转换。具体地说， char 和 short 转换为 int, 而 float 转换为 double。 比如两个char型相加, 实际上是两个char都转换为int执行加法, 如果相加的结果要作为右值而同时左值是char类型, 则对结果进行剪裁(到char类型),如果两个char相加的结果不会溢出(即不会超过char的范围), 那么可以省略类型提升.char a,b;printf ( \" the size of the result of a+b :%d \" ,sizeof( a+b) ); //输出4 在K&amp;R C中，由于函数的参数也是表达式，所以也会发生类型提升, 在被调用函数内部，提升后的参数被裁剪为原先声明的大小, 这就是为什么单个的printf()格式字符串%d能适用于几个不同类型，short，char或int，而不论实际传递的是上述类型的哪一个。函数从堆栈中取出的参数总是int类型，并在printf或其他或其他被调用的函数里按统一格式处理.char c1 = 0x70; // 0111 0000char c2 = 0xe0; // 1111 0000printf(\"0x%x 0x%x\",c1,c2); // 输出\"70 ffffffe0\" 原因是函数入参会把所有小于int的参数提升为int, char被提升为4字节的int, 由于c2的最高位是1（负数）, 所以被提升为ffffffe0.比如sizeof, sizeof返回类型是size_t, 其实就是unsigned int, 看到unsigned你又腿抖了吧. 坑: 整形(char/short/int/long)溢出unsigned char x = 0xff;printf(\"%d\\n\", ++x); 无符号整型溢出: 对于unsigned整型溢出，C的规范是有定义的——“溢出后的数会以2^(8*sizeof(type))作模运算”，也就是说，如果一个unsigned char（1字符，8bits）溢出了，会把溢出的值与256求模。 有符号整型溢出: 发生溢出后变成什么要看编译器的实现, 大部分编译器的做法是算出什么是什么. 上面的代码会输出：0 （因为0xff + 1是256，与2^8求模后就是0） @ref C语言的整型溢出问题 编程语言中，取余和取模的区别到底是什么？ - 知乎 坑: unsigned类型下溢size_t是标准C库中定义的，在32位系统为unsigned int，在64位系统中为 long unsigned int。分别为4字节和8字节。unsigned类型的0再做–运算，会发生什么？ //例一:size_t num;while(num-- &gt; 0) &#123;...&#125; // 当0--时会产生下溢, 变成4294967294导致死循环 //例二:short len = 0;while(len&lt; MAX_LEN) &#123; len += readFromInput(fd, buf); buf += len;&#125; 坑: 指针和数组的区别先看下面的代码, 在哪一行会coredown ? #include &lt;stdio.h&gt;struct str&#123; int len; char s[0];&#125;;struct foo &#123; struct str *a;&#125;;int main(int argc, char** argv) &#123; struct foo f=&#123;0&#125;; if (f.a-&gt;s) &#123; printf( f.a-&gt;s); &#125; return 0;&#125; 编译一下上面的代码，在VC++和GCC下都会在14行的printf处crash掉你的程序。把源代码中的struct str结构体中的char s[0];改成char *s;试试看，你会发现，在13行if条件的时候，程序因为Cannot access memory就直接挂掉了。为什么声明成char s[0]，程序会在14行挂掉，而声明成char *s，程序会在13行挂掉呢？那么char *s 和 char s[0]有什么差别呢？ 在说明这个事之前，有必要看一下汇编代码，用GDB查看后发现： 对于char s[0]来说，汇编代码用了lea指令，lea 0x04(%rax), %rdx 对于char*s来说，汇编代码用了mov指令，mov 0x04(%rax), %rdx lea全称load effective address，是把地址放进去，而mov则是把地址里的内容放进去。所以，就crash了。 从这里，我们可以看到，访问成员数组名其实得到的是数组的相对地址，而访问成员指针其实是相对地址里的内容（这和访问其它非指针或数组的变量是一样的） 换句话说，对于数组 char s[10]来说，数组名 s 和 &amp;s 都是一样的（不信你可以自己写个程序试试）。在我们这个例子中，也就是说，都表示了偏移后的地址。这样，如果我们访问 指针的地址（或是成员变量的地址），那么也就不会让程序挂掉了。 结论: 指针和数组的区别不仅仅是”指针p定义后可以改变其值, 而数组a[]一旦定义后无法改变a的值”; 不管结构体的实例是什么——访问其成员其实就是加成员的偏移量; int array[], 数组名array和&amp;array是一样的; @ref: C语言结构体里的成员数组和指针 指针和数组名的区别, 用下面的代码再解释一遍:char a[] = \"hello\";char *p = \"world\"; 数组a被定义后, a即为数组名, 其值不能再改变, 而指针p的值可以改变; 在代码中使用a[3]时, 直接从&amp;a[0] 向后寻找3个字节并取出那个字节; 而编译器看到p[3]时, 先生成代码找到p的位置, 取出其中的指针值, 在指针值上+3再取出该字节. a[3]和p[3], 编译器解释不同, 取出字节的方式也不同. 换言之, a[3]是名为a的对象(起始位置)之后的第3个字节, p[3]是p指向的对象向后的第3个字节. 参考: 深入理解C语言 语言的歧义 谁说C语言很简单？ C语言的谜题","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"C/C++","slug":"C-C","permalink":"https://beefyheisenberg.github.io/tags/C-C/"}]},{"title":"Vim入门指北","slug":"50.Farbox-Blog/【Vim】Vim入门指北","date":"2014-02-03T16:00:00.000Z","updated":"2024-01-24T01:27:53.040Z","comments":true,"path":"50.Farbox-Blog/【Vim】Vim入门指北/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【Vim】Vim入门指北/","excerpt":"plugin @2020 C++补全: 仍然是YCM 自动生成tag: vim-gutentags 或 gen_tags.vim 动态检查: ale(替代syntastic) 函数列表: LeaderF(替代 tagbar) 快速打开文件: LeaderF 一些基本概念 operator（操作符）: 例如命令d, y, c等; motion（移动）: 例如移动光标的命令h j k l, w, e, b等; text-objects（文本对象）: 例如s(表示句子sentence)， w表示单词，p表示段落（Paragraphs）等等。","text":"plugin @2020 C++补全: 仍然是YCM 自动生成tag: vim-gutentags 或 gen_tags.vim 动态检查: ale(替代syntastic) 函数列表: LeaderF(替代 tagbar) 快速打开文件: LeaderF 一些基本概念 operator（操作符）: 例如命令d, y, c等; motion（移动）: 例如移动光标的命令h j k l, w, e, b等; text-objects（文本对象）: 例如s(表示句子sentence)， w表示单词，p表示段落（Paragraphs）等等。 除了hjkl这些基本命令之外， 你还要知道“更高级的”组合命令： “operator + motion” 组合的方式，例如： ct. 将字符’.’前面的所有都删除. y^ 复制到行首. “operator + text-objects” 的命令组合方式, 例如: ciw : 剪切光标处单词, 不包括空格 caw : 剪切光标处单词, 包括空格 dip : 删除一段 移动光标下上左右：ＪＫＨＬ移动到上一个单词首b移动到下一个单词首w，移动3个单词3w w / b是在单词首部移动，在单词尾部移动为ge / e 如果是大写的B，W，gE，E，则只将“空格”作为单词分隔符，例如’gloal.member’被当作一个完整的词。 ^ 光标移动到行开头$ 光标移动到行结尾fx 光标移动到下一个x处，3fx移动到第三个x处Fx 光标移动到前面的x处tx，Tx类似，移动到x之前ma 标记当前行， 标签可以是a-z任意字符~a 跳转到a标签 跳转到上次编辑位置: C-O跳转到匹配的括号%移动到文件首gg有趣的命令: 9999k作用也是移动到文件首移动到文件尾G跳转到第33行33G或者输入 :33 也可以跳转如移动到文档1/3处 ，直接输入33%将当前光标所在的行移到屏幕中间 zz当前光标所在的行移到屏幕顶，zt 助记t=top 。当前光标所在的行移到屏幕底，zb 助记b=bottom 。分别为移动到文档的head, middle, last的位置 H, M, L。 向前向后翻页 C-F , C-B Linux 终端( Terminal)中常用的快捷键 ctrl+f 向前移动一个字符ctrl+b 向后移动一个字符alt+f 向前移动一个单词alt+b 向后移动一个单词ctrl+a 移动到当前行首ctrl+e 移动到当前行尾 vim whith ctags 基于tags定义跳转: C-] 在新 Window 打开tag的定义: C-W-] 在新的预览 Window 里打开tag的定义: C-W-} 如果tags找到多个定义, 用 g-] 可以列出所有找到的tag; 跳转回 C-O 或 C-T 或按两下 ～ Ctrl + 左/右键 也可以跳转/返回 CTRL-T is working with tags stackCTRL-O is working with jumplistTag stack and jumplist are different list in vim, but they might have same items when you jumping through tags (eg. using CTRL-] ) 编辑使用c，d和x删除的字符仍然存在寄存器中，用p可以粘贴出来。 c = 替换（change），删除文本并进入插入模式， d =删除（delete），一般组合使用， y =复制（yank）， p = 粘贴（paste）， x = 删除字符； 删除,剪切, 复制一行= ｃｃ，ｄｄ，ｙｙ删除,剪切, 复制多行= ３ｃｃ，４ｄｄ，５ｙｙ删除,剪切, 复制到行尾= ｃ＄，ｄ＄，ｙ＄或者大写C, D, Y, 也是到行尾删除,剪切,复制到行开头= ｃ＾，ｄ＾，ｙ＾ 或者ｃ０，ｄ０，ｙ０ 从光标开始, 删除,剪切,复制到单词尾＝cw，dw，yw删除,剪切,复制整个单词= daw, caw, yaw注意区别yw和yaw, 例如光标在＂test＂ 的e位置, yaw复制整个单词, yw只复制est。 tips: 重复操作的快捷键是”.”, 比如daw删除一个单词后想继续删除下一个单词，就可以按”.” 删除换行符（两行合并为一行）： J撤销上次操作（还原）： u反撤销（重做）： Ctrl+r撤销对一行的所有操作（还原一行）： U，第二次按U会撤销上一次Ｕ的操作。只用u和C-R即可回到任何一个操作状态。可视模式下的U/u是大小写转换。 光标前插入 = i 光标后插入 = a 行首插入 = I 行尾插入 = A 在当前行的下面另起一行，并进入插入状态o在当前行的前面另起一行，并进入插入状态O 外部程序的粘贴&amp;复制GVIM的“+号寄存器”可以与外部程序复制/粘贴: 复制&quot;+y 粘贴&quot;+p 剪切&quot;+x注: 以上快捷键在命令可视模式/模式有效，先按双引号进入寄存器模式,再按加号,然后按y/p/x如果在插入模式, 先按ctrl+R进入寄存器模式（会出现&quot;号）, 再按对应的寄存器编号，系统共享寄存器编号是+号.在VIM正常模式下,ctrl+r 是重做。 &quot; 加入到_vimrc文件中:map &lt;C-c&gt; &quot;+y &quot;加号寄存器-复制map &lt;C-v&gt; &quot;+p &quot;加号寄存器-复制map &lt;CTRL-X&gt; &quot;+x &quot;加号寄存器-复制map &lt;C-s&gt; :w&lt;cr&gt; &quot; 保存 多窗口 关闭分屏窗口: Ctrl+W c 或 Ctrl+W q 上下分割窗口: Ctrl+W s 左右分割窗口: Ctrl+W vCtrl+w Ctrl+] 在新窗口打开定义 多文件buff操作:E 或者:Explore 浏览目录:edit filename 编辑文件；:ls 列出所有buffer；:b 2或:buffer 2将切换到相关的buffer:b2 关闭buff=2的文件；:bn 删除文件缓冲(关闭文件)。zz 将当前编辑的行置于屏幕中间。ZZ 保存退出。:q! 不保存退出, :qa!表示退出所有buff并不保存:wq 保存退出 搜索和替换搜索/include 正向搜索，n下一个，N上一个?include 反向搜索/\\&lt;the\\&gt; 全词匹配搜索单词＂the＂，助记开头\\&lt;，结尾>#号是向后搜索匹配单词，*向前搜索匹配单词, gd类似*号的功能. 正则搜索/^the 搜索the开头的行（针对行，而非单词）/here$ 搜索here结尾的行点号匹配任何单字符，如果要搜索的内容本身包含点号，则用.代替，比如：/the. 搜索＂the＂匹配的内容/the\\. 搜索＂the.＂匹配的内容 正则表达式教程参考： [[../41.Uncategorized/正则表达式-RegExp]] 替换最常用的替换命令就是:%s/1/2/g了, 其中%符号表示范围整个文件, s表示搜索, 最后的g表示全局替换.如果要制定范围内替换, 比如在31~文件尾范围内替换: :31,$s/hello/world/gc, 最后的c参数表示替换过程中需要确认(confirm). 可视模式shift + v: 行选择模式大写V同上所选择区域转换为大写U，转换为小写ux和d在可视模式都是删除&gt;和&lt;在可视模式为右移,左移 列模式Ctrl+v (Windows上是Ctrl+Q)进入列模式,使用方向键或H J K L选择行, 用c或d删除, shift+i插入(大写I键),插入完成后, 按esc后生效. 代码折叠可以zf进行折叠, 用zo打开折叠,也可以方向键向右打开折叠,zc 关闭折叠. SessionSession可以保存此次编辑的状态, 比如已经打开的文件, 当前编辑位置等. 保存Session: mksession session.vim 载入Session: source session.vim 补全 CTRL-X CTRL-N和CTRL-X CTRL-P : 关键字补全 CTRL-X CTRL-K : 字典补全 CTRL-X CTRL-L : 整行补全 CTRL-X CTRL-F : 文件名补全 CTRL-X CTRL-O : OmniComplete [Evernote]https://www.evernote.com/shard/s120/sh/4e8424bf-6c54-4f2e-a9a5-d4641127c615/ed07f657e1eccd05e81947e2e008c8a9 配置文件.vimrc=&gt; 【Vim】我的Vim配置文件","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"Vim","slug":"Vim","permalink":"https://beefyheisenberg.github.io/tags/Vim/"}]},{"title":"我的 Vim 配置文件","slug":"50.Farbox-Blog/【Vim】我的Vim配置文件","date":"2014-01-08T06:31:00.000Z","updated":"2024-01-24T01:27:53.049Z","comments":true,"path":"50.Farbox-Blog/【Vim】我的Vim配置文件/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【Vim】我的Vim配置文件/","excerpt":"插件:UI color: solarized/molokai/phd vim-airline : 状态栏 Nerd_tree : 文件浏览 vim-startify : vim的起始页 编辑 EasyMotion : 快速在代码中移动光标 The-NERD-Commenter : 注释 vim-markdown","text":"插件:UI color: solarized/molokai/phd vim-airline : 状态栏 Nerd_tree : 文件浏览 vim-startify : vim的起始页 编辑 EasyMotion : 快速在代码中移动光标 The-NERD-Commenter : 注释 vim-markdown 搜索 CtrlP（更快的查找文件） grep.vim (Windows下使用findstr.vim) EasyGrep 补全 YouCompleteMe: for Linux users neocomplcache: for Windows users OmniCppComplete: for Windows users Snippets SnipMate + honza/vim-snippets : Just Press Tab! 语法检查 scrooloose-syntastic: 支持C/C++(需要cppcheck或clang),php,Python(需要flake8或python),JavaScript(需要jshint或jslint), 参考:syntastic支持的语言列表 工具 Conque-Shell : 在Vim的buff里执行命令行 安装:Github更新在这里: https://github.com/WhatsDJGPP/ah-my-vim.git 覆盖当前Vim配置: cp ~/ah-my-vim/_vimrc ~/.vimrc &amp;&amp; cp -fr ~/ah-my-vim/* ~/.vim/ 安装 Vundle: mkdir -p ~/.vim/bundle/vundle/ &amp;&amp; git clone https://github.com/gmarik/vundle.git ~/.vim/bundle/vundle 打开Vim并输入:BundleInstall安装插件. 如果在Windows上使用, 还需要下载UnxUtils, 并注释掉g:CygwinToolPath一行; Custom Shortcut Keys : \\fc / F1: Toggle TagList \\bb / F2: Toggle BufExplorer \\ft / F3: Toggle NERDTree \\/ / F4 : Findstring or Rgrep \\co : Open Quickfix \\cx : Close Quickfix \\cc : Comment Lines \\cu : Uncomments Lines \\c&lt;space&gt; : Toggles the comment state &lt;C-\\&gt;c : Find functions calling this function &lt;C-\\&gt;g : Find this definition &lt;C-\\&gt;s : Find this C symbol fold for C/C++: zo and zf% fold fpr Py: zo and zc Shortcut for plugins: NERD-Commenter: \\cc或\\cs添加注释, \\cm多行注释, \\cu取消注释 EasyMotion: \\\\w, if you want find ‘o’, use \\\\fo EasyGrep: \\vv在文件中搜索, \\vV在文件中全词匹配, \\vr 在文件中替换, \\vo打开选项 _VIMRC文件点此查看: github.com/WhatsDJGPP/ah-my-vim","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"开发环境","slug":"开发环境","permalink":"https://beefyheisenberg.github.io/tags/开发环境/"},{"name":"Vim","slug":"Vim","permalink":"https://beefyheisenberg.github.io/tags/Vim/"},{"name":"编辑器","slug":"编辑器","permalink":"https://beefyheisenberg.github.io/tags/编辑器/"}]},{"title":"使用 Vundle 管理 Vim 插件（Windowns 7）","slug":"50.Farbox-Blog/【Vim】使用vundle管理vim插件","date":"2013-11-09T12:41:00.000Z","updated":"2024-01-24T01:27:53.054Z","comments":true,"path":"50.Farbox-Blog/【Vim】使用vundle管理vim插件/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【Vim】使用vundle管理vim插件/","excerpt":"(1)安装win版本的gvim:下载地址 http://www.vim.org/download.php比如安装目录是F:\\Program Files (x86)\\Vim, 并在此目录下新建”bundle\\vundle”目录. (2)安装git安装git命令行: http://git-scm.com/ (已被长城)或者github带GUI的版本: http://windows.github.com/并且把git所在的目录加进环境变量PATH中. (3) 安装vundle","text":"(1)安装win版本的gvim:下载地址 http://www.vim.org/download.php比如安装目录是F:\\Program Files (x86)\\Vim, 并在此目录下新建”bundle\\vundle”目录. (2)安装git安装git命令行: http://git-scm.com/ (已被长城)或者github带GUI的版本: http://windows.github.com/并且把git所在的目录加进环境变量PATH中. (3) 安装vundle打开cmd, 输入以下: git clone https://github.com/gmarik/vundle “F:\\Program Files (x86)\\Vim\\vimfiles\\bundle\\vundle” 保证git.exe在你的环境变量中. (4)在_vimrc添加vundle:打开C:\\Users\\xxx_vimrc, 添加如下配置:set rtp+=$VIM/vimfiles/bundle/vundle/call vundle#rc(&apos;$VIM/vimfiles/bundle/&apos;)Bundle &apos;gmarik/vundle&apos;&quot; original repos on github &#123; &quot; Bundle &apos;tpope/vim-fugitive&apos; &quot; Bundle &apos;Lokaltog/vim-easymotion&apos; &quot; Bundle &apos;rstacruz/sparkup&apos;, &#123;&apos;rtp&apos;: &apos;vim/&apos;&#125; &quot; Bundle &apos;tpope/vim-rails.git&apos; Bundle &apos;kien/ctrlp.vim&apos; Bundle &apos;Lokaltog/vim-powerline&apos; &quot;Bundle &apos;Valloric/YouCompleteMe&apos;&quot; &#125;&quot; vim-scripts repos &#123; Bundle &apos;bufexplorer.zip&apos; Bundle &apos;grep.vim&apos; Bundle &apos;taglist.vim&apos; Bundle &apos;The-NERD-tree&apos; Bundle &apos;Markdown&apos;&quot; &#125;&quot; non github reposo &#123; &quot; Bundle &apos;git://git.wincent.com/command-t.git&apos;&quot; &#125;&quot; Brief help &#123; &quot; :BundleList - list configured bundles &quot; :BundleInstall(!) - install(update) bundles &quot; :BundleSearch(!) foo - search(or refresh cache first) for foo &quot; :BundleClean(!) - confirm(or auto-approve) removal of unused bundles&quot; &#125;filetype plugin indent on &quot; automatically detect file types. (5) 通过vundle 安装vim 插件在git shell 执行gvim, 然后在gvim内执行 :BundleInstalldone!","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"开发环境","slug":"开发环境","permalink":"https://beefyheisenberg.github.io/tags/开发环境/"},{"name":"Vim","slug":"Vim","permalink":"https://beefyheisenberg.github.io/tags/Vim/"},{"name":"编辑器","slug":"编辑器","permalink":"https://beefyheisenberg.github.io/tags/编辑器/"},{"name":"vundle","slug":"vundle","permalink":"https://beefyheisenberg.github.io/tags/vundle/"}]},{"title":"GNU的obj分析工具的使用 - nm/objdump","slug":"50.Farbox-Blog/【C语言】GNU的obj分析工具的使用","date":"2013-11-01T12:41:00.000Z","updated":"2024-01-24T01:27:52.999Z","comments":true,"path":"50.Farbox-Blog/【C语言】GNU的obj分析工具的使用/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【C语言】GNU的obj分析工具的使用/","excerpt":"linux GUN工具链中二进制文件分析工具： nm/objdump用来列出目标文件（object files）的符号表（symbols）； readelf用来分析elf文件； ldd用来分析程序运行时需要依赖的动态库。 先来回顾一下Linux进程内存布局：----高地址----&lt;栈stack&gt; |&lt;堆heap&gt;&lt;.bss&gt; 未初始化的全局变量&lt;.data&gt; 已初始化的全局变量,static变量 &lt;.rodata&gt; 属于.data, 存放const, char*字符串&lt;.txt&gt; 代码段----低地址----","text":"linux GUN工具链中二进制文件分析工具： nm/objdump用来列出目标文件（object files）的符号表（symbols）； readelf用来分析elf文件； ldd用来分析程序运行时需要依赖的动态库。 先来回顾一下Linux进程内存布局：----高地址----&lt;栈stack&gt; |&lt;堆heap&gt;&lt;.bss&gt; 未初始化的全局变量&lt;.data&gt; 已初始化的全局变量,static变量 &lt;.rodata&gt; 属于.data, 存放const, char*字符串&lt;.txt&gt; 代码段----低地址---- 本文中使用的示例代码: #include &lt;stdio.h&gt;char *global_string1 = \"abc\"; // 4字节char *global_string2 = \"Hello World!!!\"; // 15字节const int global_const_int = 0x81; // 129int global_int = 0x3FF; // 1023int global_uninit_int;int main()&#123; int stack_int = 0x1F; // 31 static int stack_uninit_static_int; static int stack_inited_static_int = 0x1B; // 27 char *stack_string1 = \"Hello World!!!\"; // 同global_string2, 15字节 char *stack_string2 = \"Hello\"; // 6字节 // 先看一下环境是多少位 printf(\"sizeof int is %d\\n\", sizeof(int)); // 打印地址, 从低地址到高地址: // 全局定义字符串和函数内定义的字符串: printf(\"addr of global_string1 is 0x%x\\n \\ addr of global_string2 is 0x%x\\n \\ addr of stack_string1 is 0x%x\\n \\ addr of stack_string2 is 0x%x\\n\", global_string1, global_string2, stack_string1, stack_string2); // 全局const常量 printf(\"addr of global_const_int is 0x%x\\n\", &amp;global_const_int); // 已初始化static变量(全局变量默认是static的, 以及函数内static变量) printf(\"addr of global_int is 0x%x\\n \\ addr of stack_inited_static_int is 0x%x\\n\", &amp;global_int, &amp;stack_inited_static_int); // static但未初始化变量(全局的和函数内的) printf(\"addr of global_uninit_int is 0x%x\\n \\ addr of stack_uninit_static_int is 0x%x\\n\", &amp;global_uninit_int, &amp;stack_uninit_static_int); // 栈 printf(\"addr of stack_int is 0x%x\\n\", &amp;stack_int); return 0;&#125; 编译: gcc -g test.c -o test &amp;&amp; ./test ，程序的输出如下, #后面是我的注释：sizeof int is 4addr of global_string1 is 0x9343df2 # 4字节的字符串 addr of global_string2 is 0x9343df6 # 15字节的字符串 addr of stack_string1 is 0x9343df6 # 函数内字符串&quot;Hello World!!!&quot;, 跟全局指向同一个 addr of stack_string2 is 0x9343e05 # global_string2后面15字节就是stack_string2addr of global_const_int is 0x9343f94 # 全局常量在字面量字符串更高一点的位置addr of global_int is 0x9344028 # 全局/局部的static变量 addr of stack_inited_static_int is 0x934402caddr of global_uninit_int is 0x9344034 # 未初始化static addr of stack_uninit_static_int is 0x9344030addr of stack_int is 0x568bc598 “全局变量”默认是static的, 无论加不加static关键字, 全局变量存储在data区“局部定义的static变量”, 跟全局变量都在data区 在内存的布局从大约是(非相邻的有|隔开了, 没有|表示相邻的区域):-- 高地址 ------ [栈区] ----- 函数内定义的非static变量(栈变量) | | |----- [BSS] ----- 未初始化static变量(包括全局定义和函数内定义的)---- [data区] ---- 全局非const变量-- [data.rodata区]-- 全局const常量 字面量的字符串(包括&quot;全局区定义的&quot;以及&quot;在函数内定义的&quot;)-- 低地址 -- 注意：全局字符串char*类型和char[]类型是有区别的，前者的字符不允许被修改，而后者的字符可以被修改。 未初始化的栈变量其值是随机的。而未初始化的全局变量被放入.bss段，被初始化为zero。 Wiki: Data segment: The BSS segment ( Block Started by Symbol), also known as uninitialized data, is usually adjacent to the data segment and contains all global variables and static variables that are initialized to zero or do not have explicit initialization in source code. For instance a variable declared static int i; would be contained in the BSS segment. The data area contains global and static variables used by the program that are explicitly initialized with a non-zero (or non-NULL) value. nm的使用nm用来列出目标文件的符号(symbol)清单: 在当前目录下输入nm hello，返回如下: 0000000000601054 B __bss_start0000000000601054 b completed.6972000000000040063c R const_num // 全局const常量，注意地址0000000000601030 D __data_start0000000000601030 W data_start...0000000000601054 D _edata0000000000601060 B _end...0000000000601050 D global_num //全局int变量，注意地址0000000000601000 d _GLOBAL_OFFSET_TABLE_0000000000601040 D global_string //全局char*字符串，注意地址0000000000601048 D global_string2 //全局charp[]字符串0000000000601058 B global_uninit_num // 全局未初始化...000000000040052d T main U printf@@GLIBC_2.2.500000000004004a0 t register_tm_clones0000000000400440 T _start0000000000601058 D __TMC_END__ 解释下nm返回的格式, 共3列,分别是”符号在文件里的偏移”,”符号的类型”,”符号名称”.其中“符号类型”有下面几种： A :该符号的值是绝对的，在以后的链接过程中，不允许进行改变。B :该符号的值出现在非初始化数据段(.bss)中。例如，比如全局没初始值的变量global_uninit_num;D :该符号放在普通的数据段(.data)中，通常是那些已经初始化的全局变量；R :The symbol is in a read only data section，比如全局的const_num；T :该符号放在代码段中，通常是那些全局非静态函数, 上面可以看到main/_start等都是T类型；U :该符号未定义过，需要自其他对象文件中链接进来, 上面可以看到printf函数是 printf@@GLIBC； 程序打印的变量内存地址（运行时），和可执行文件符号表的地址，并不完全相同。比如全局字符串global_string，（和全局int相比）全局字符串在程序运行时会放到.data段更低的位置。详细的解释见后面readelf的说明。 然后回到上面的一个问题，为什么全局字符串char *global_string = &quot;abc&quot;和全局常量const int const_num =128在内存中的地址比全局变量int global_num = 1024的地址要低很多？ 并且看到上面nm分析的obj符号地址，全局变量/常量在符号表里的地址其实差不多。原因（我猜的）是，编译器在链接时会对“不可改变的”常量做特殊的优化，比如上面的char*类型的字符串，把这些不可改变的常量（.rodata段）存放在代码段（.text段），防止意外改写。 nm的常用参数:-C : 加上此参数, 会让符号变成”适合阅读”的样式；-A 在每个符号信息的前面打印所在对象文件名称；-l 使用对象文件中的调试信息打印出所在源文件及行号, gcc -g参数可以让打印更为详尽； nm可以用来: 判断指定程序中有没有某个符号 (比较常用的方式：nm -C a.out | grep symbol) 解决程序编译时undefined reference的错误，以及mutiple definition的错误 查看某个符号的地址，以及在进程空间的大概位置（bss, data, text区，具体可以通过第二列的类型来判断） 有关nm更详细的说明可以参考 @ref sourceware.org。 objdump的使用objdump命令是Linux下的反汇编目标文件或者可执行文件的命令，可以看作是nm的增强型。objdump -d out :反汇编test中的需要执行指令的那些section；objdump -x out :以某种分类信息的形式把目标文件的数据组成输出；objdump -t out :输出目标文件的符号表；objdump -h out :输出目标文件的所有段概括;objdump -j ./text/.data -S out : 输出指定段的信息（反汇编源代码）;objdump -S out :输出目标文件的符号表（） 当gcc -g时打印更明显；objdump -j .text -Sl stack1 | more:-S 尽可能反汇编出源代码，尤其当编译的时候指定了-g这种调试参数时，效果比较明显。隐含了-d参数。-l 用文件名和行号标注相应的目标代码，仅仅和-d、-D或者-r一起使用。使用-ld和使用-d的区别不是很大，在源码级调试的时候有用，要求编译时使用了-g之类的调试编译选项。 readelf的使用objdump和readelf都可以用来查看二进制文件的一些内部信息. 区别在于: objdump借助BFD而更加通用一些, 可以应付不同文件格式 readelf则并不借助BFD, 而是直接读取ELF格式文件的信息, 按readelf手册页上所说,得到的信息也略细致一些. 用readelf可以很方便的查看elf文件的布局: readelf -ahW hello 详细的介绍请参考, 这里就不再复制粘贴了-.-@ref readelf - GNU Binary Utilities 参数-a表述输出所有elf信息, h表示打印出elf head, W表示打印出的内容太长(&gt;80字)不换行, 方便查看； readelf -ahW test 打印出: [Nr] Name Type Address Off Size ES Flg Lk Inf Al[11] .init PROGBITS 00000000004003e0 0003e0 00001a 00 AX 0 0 4[12] .plt PROGBITS 0000000000400400 000400 000040 10 AX 0 0 16[13] .text PROGBITS 0000000000400440 000440 0001e2 00 AX 0 0 16[14] .fini PROGBITS 0000000000400624 000624 000009 00 AX 0 0 4[15] .rodata PROGBITS 0000000000400630 000630 000165 00 A 0 0 8[24] .data PROGBITS 0000000000601030 001030 000024 00 WA 0 0 8[25] .bss NOBITS 0000000000601054 001054 00000c 00 WA 0 0 4[26] .comment PROGBITS 0000000000000000 001054 000024 01 MS 0 0 1 Key to Flags: W (write), A (alloc), X (execute), M (merge), S (strings), l (large)I (info), L (link order), G (group), T (TLS), E (exclude), x (unknown)O (extra OS processing required) o (OS specific), p (processor specific) 根据上面的打印, 第三列就是elf文件中每段的起始address, 可以看到分别是(地址低-高)： .text: 0x400440,.rodata： 0x400630,.data(已初始化的全局和static变量): 0x601030,.bss(未初始化的全局)：0x601054 “.text”段即为代码段，是存储指令的段，为防止在运行过程中指令被修改，该段是只读的 “.bss段”：未初始化的全局变量。在目标文件中这个段不占据实际的空间，在目标文件中，未初始化变量不需要占据任何实际的磁盘空间。从上面的 readelf输出可以看到，“.data”和“.bss”在加载时合并到一个Segment中，这个Segment是可读可写的。“.bss段”和“.data段”的不同之处在于，.bss段在文件中不占存储空间，在加载时这个段用0填充。 为什么未初始化的数据称为.bss？用术语.bss来表示未初始化的数据是很普遍的。它起始于IBM704汇编语言中的“块存储开始(Block Storage Start)”指令的首字母缩写，并沿用至今，一个记住区分.data和.bss节的简单方法是把“bss”看成是“更好地节省空间(Better Save Space)”的缩写。 Ok, 我们再来看一下readelf -ahW的其他输出: 50: 000000000040064c 4 OBJECT GLOBAL DEFAULT 15 const_num64: 0000000000601048 8 OBJECT GLOBAL DEFAULT 24 global_string265: 0000000000601040 8 OBJECT GLOBAL DEFAULT 24 global_string 可以看到代码里的int const const_num在0x40064c这个地址, 正好处在.rodata区域, 我们用hexdump命令来查看这个段的内容, 发现”hello world”字符串也在这个区域. 在链接时，“.rodata”和“.text”合并到Text Segment中，在加载运行时，操作系统将Text Segment设为只读保存起来，防止意外改写。需要注意的是，象const int A这样的变量在定义时必须进行初始化，因为只有初始化时才有机会给它一个值，一旦定义之后就不能再改写了，也就是不能再赋值了。 ldd的使用ldd工具用来查看程序所依赖的动态库，在命令行输入 ldd hello： linux-vdso.so.1 =&gt; (0x00007fff36450000)libc.so.6 =&gt; /lib64/libc.so.6 (0x000000355d800000)/lib64/ld-linux-x86-64.so.2 (0x000000355d000000) 说明: 上面最后一列十六进制数, 就是库加载的开始地址. @ref 参考 http://akaedu.github.io/post/13/13.1.html","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"C/C++","slug":"C-C","permalink":"https://beefyheisenberg.github.io/tags/C-C/"},{"name":"nm","slug":"nm","permalink":"https://beefyheisenberg.github.io/tags/nm/"},{"name":"objdump","slug":"objdump","permalink":"https://beefyheisenberg.github.io/tags/objdump/"}]},{"title":"Linux下安装 tpacpi-bat 控制 thinkpad 充电阈值","slug":"50.Farbox-Blog/【开发环境】Linux下安装tpacpi-bat控制thinkpad充电阈值","date":"2013-10-17T11:39:00.000Z","updated":"2024-01-24T01:27:53.095Z","comments":true,"path":"50.Farbox-Blog/【开发环境】Linux下安装tpacpi-bat控制thinkpad充电阈值/","link":"","permalink":"https://beefyheisenberg.github.io/50.Farbox-Blog/【开发环境】Linux下安装tpacpi-bat控制thinkpad充电阈值/","excerpt":"tp_smapi 是一套适用于ThinkPad的驱动程序集, 包括了电池阈值设置, 风扇转速控制, 以及HDAPS(类似APS硬盘保护)几个功能. 但是 2013新出的几款Ivy Bridge 平台的thinkpad(X230,T430,T530)上已经无法使用tp_smapi了. 在github上可以看到tp_smapi 项目也有两年多没有更新: tp_smapi地址 所以对于T430等Ivy平台的Thinkpad, 推荐使用tpacpi-bat调整电池充电阈值. 安装过程: (1) 安装acpidump , iasl工具 sudo yum install pmtools iasl","text":"tp_smapi 是一套适用于ThinkPad的驱动程序集, 包括了电池阈值设置, 风扇转速控制, 以及HDAPS(类似APS硬盘保护)几个功能. 但是 2013新出的几款Ivy Bridge 平台的thinkpad(X230,T430,T530)上已经无法使用tp_smapi了. 在github上可以看到tp_smapi 项目也有两年多没有更新: tp_smapi地址 所以对于T430等Ivy平台的Thinkpad, 推荐使用tpacpi-bat调整电池充电阈值. 安装过程: (1) 安装acpidump , iasl工具 sudo yum install pmtools iasl (2) acpidump sudo acpidump -b -t DSDT -o /tmp/dsdt.aml可能会返回Wrong checksum for FADT!错误, 忽略.iasl -d /tmp/dsdt.amlcat /tmp/dsdt.dsl | grep \\\\_SB.PCI.*HKEY -amlo | uniq记住输出的字符串, 我的T430输出是”_SB.PCI0.LPC.EC.HKEY” (3) 编译acpi_call下载代码并编译: https://github.com/mkottman/acpi_call sudo makesudo make installsudo depmod -asudo modprobe acpi_call 最后一步载入acpi_call.ko之后,会多出一个 /proc/acpi/call “文件”, 通过写入参数到这个文件, 实现与acpi_call的交互.tpacpi-bat就是通过这种方式控制电池阈值. 当然也可以通过acpi_call控制独立显卡的关闭(双显卡的机型). (4) 安装tpacpi_call下载代码并编译: https://github.com/teleshoes/tpacpi-bat需要手动编辑一下 vim tpacpi-bat找到 “my $aslBases = …” 并改为自己的配置, 例如我的T430改为:my $aslBases = &#123; &apos;default&apos; =&gt; &apos;\\_SB.PCI0.LPC.EC.HKEY&apos;, &apos;ThinkPad W520&apos; =&gt; &apos;\\_SB.PCI0.LPC.EC.HKEY&apos;, &apos;ThinkPad T430&apos; =&gt; &apos;\\_SB.PCI0.LPC.EC.HKEY&apos;, &apos;ThinkPad T430u&apos; =&gt; &apos;\\_SB.PCI0.LPCB.EC.HKEY&apos;,&#125;; 然后把tpacpi-bat 移动到/usr/local/bin . (5) 增加到开机脚本中编辑/etc/rc.local, 增加两行:/usr/local/bin/tpacpi-bat -s ST 0 70/usr/local/bin/tpacpi-bat -s SP 0 90 上面两行分别将开始充电和停止充电设置为70%和90%. (6) 查询充电阈值tpacpi-bat -v -g ST 1tpacpi-bat -v -g SP 1 参考:http://ubuntuforums.org/showthread.php?t=2148044http://smitran.com/centos-6-thinkpad-t530-prolong-battery-life-with-tpacpi-bat/http://blog.thekondor.net/2012/09/make-new-thinkpads-charge-thresholds.html","categories":[{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"Thinkpad","slug":"Thinkpad","permalink":"https://beefyheisenberg.github.io/tags/Thinkpad/"},{"name":"Linux Desktop","slug":"Linux-Desktop","permalink":"https://beefyheisenberg.github.io/tags/Linux-Desktop/"}]}],"categories":[{"name":"About","slug":"About","permalink":"https://beefyheisenberg.github.io/categories/About/"},{"name":"76.Games","slug":"76-Games","permalink":"https://beefyheisenberg.github.io/categories/76-Games/"},{"name":"74.Foods","slug":"74-Foods","permalink":"https://beefyheisenberg.github.io/categories/74-Foods/"},{"name":"73.Health-and-Medicine","slug":"73-Health-and-Medicine","permalink":"https://beefyheisenberg.github.io/categories/73-Health-and-Medicine/"},{"name":"72.Math-and-Logic","slug":"72-Math-and-Logic","permalink":"https://beefyheisenberg.github.io/categories/72-Math-and-Logic/"},{"name":"71.Science-and-Tech","slug":"71-Science-and-Tech","permalink":"https://beefyheisenberg.github.io/categories/71-Science-and-Tech/"},{"name":"66.History-and-Politics","slug":"66-History-and-Politics","permalink":"https://beefyheisenberg.github.io/categories/66-History-and-Politics/"},{"name":"65.Movies","slug":"65-Movies","permalink":"https://beefyheisenberg.github.io/categories/65-Movies/"},{"name":"64.Novel-and-Poesy","slug":"64-Novel-and-Poesy","permalink":"https://beefyheisenberg.github.io/categories/64-Novel-and-Poesy/"},{"name":"63.Culture-and-Arts","slug":"63-Culture-and-Arts","permalink":"https://beefyheisenberg.github.io/categories/63-Culture-and-Arts/"},{"name":"62.Psychology","slug":"62-Psychology","permalink":"https://beefyheisenberg.github.io/categories/62-Psychology/"},{"name":"61.Philosophy","slug":"61-Philosophy","permalink":"https://beefyheisenberg.github.io/categories/61-Philosophy/"},{"name":"54.Trips-and-Exploration","slug":"54-Trips-and-Exploration","permalink":"https://beefyheisenberg.github.io/categories/54-Trips-and-Exploration/"},{"name":"Drafts","slug":"Drafts","permalink":"https://beefyheisenberg.github.io/categories/Drafts/"},{"name":"53.Photograph","slug":"53-Photograph","permalink":"https://beefyheisenberg.github.io/categories/53-Photograph/"},{"name":"52.Financing","slug":"52-Financing","permalink":"https://beefyheisenberg.github.io/categories/52-Financing/"},{"name":"51.Productivity","slug":"51-Productivity","permalink":"https://beefyheisenberg.github.io/categories/51-Productivity/"},{"name":"41.Uncategorized","slug":"41-Uncategorized","permalink":"https://beefyheisenberg.github.io/categories/41-Uncategorized/"},{"name":"34.Machine-Learning","slug":"34-Machine-Learning","permalink":"https://beefyheisenberg.github.io/categories/34-Machine-Learning/"},{"name":"33.Bigdata","slug":"33-Bigdata","permalink":"https://beefyheisenberg.github.io/categories/33-Bigdata/"},{"name":"32.Database","slug":"32-Database","permalink":"https://beefyheisenberg.github.io/categories/32-Database/"},{"name":"31.Backend","slug":"31-Backend","permalink":"https://beefyheisenberg.github.io/categories/31-Backend/"},{"name":"22.Network-Protocol","slug":"22-Network-Protocol","permalink":"https://beefyheisenberg.github.io/categories/22-Network-Protocol/"},{"name":"21.Operating-System","slug":"21-Operating-System","permalink":"https://beefyheisenberg.github.io/categories/21-Operating-System/"},{"name":"19.Algorithm","slug":"19-Algorithm","permalink":"https://beefyheisenberg.github.io/categories/19-Algorithm/"},{"name":"14.Coding-Pattern","slug":"14-Coding-Pattern","permalink":"https://beefyheisenberg.github.io/categories/14-Coding-Pattern/"},{"name":"12.Java","slug":"12-Java","permalink":"https://beefyheisenberg.github.io/categories/12-Java/"},{"name":"13.JavaEE","slug":"13-JavaEE","permalink":"https://beefyheisenberg.github.io/categories/13-JavaEE/"},{"name":"11.Programming-Language","slug":"11-Programming-Language","permalink":"https://beefyheisenberg.github.io/categories/11-Programming-Language/"},{"name":"99.Journal","slug":"99-Journal","permalink":"https://beefyheisenberg.github.io/categories/99-Journal/"},{"name":"50.FarBox博客备份","slug":"50-FarBox博客备份","permalink":"https://beefyheisenberg.github.io/categories/50-FarBox博客备份/"}],"tags":[{"name":"吃喝的修养","slug":"吃喝的修养","permalink":"https://beefyheisenberg.github.io/tags/吃喝的修养/"},{"name":"药物指南","slug":"药物指南","permalink":"https://beefyheisenberg.github.io/tags/药物指南/"},{"name":"饮食健康","slug":"饮食健康","permalink":"https://beefyheisenberg.github.io/tags/饮食健康/"},{"name":"Gym","slug":"Gym","permalink":"https://beefyheisenberg.github.io/tags/Gym/"},{"name":"健身房","slug":"健身房","permalink":"https://beefyheisenberg.github.io/tags/健身房/"},{"name":"大舰巨炮","slug":"大舰巨炮","permalink":"https://beefyheisenberg.github.io/tags/大舰巨炮/"},{"name":"世界历史","slug":"世界历史","permalink":"https://beefyheisenberg.github.io/tags/世界历史/"},{"name":"欧洲历史","slug":"欧洲历史","permalink":"https://beefyheisenberg.github.io/tags/欧洲历史/"},{"name":"中国历史","slug":"中国历史","permalink":"https://beefyheisenberg.github.io/tags/中国历史/"},{"name":"电影","slug":"电影","permalink":"https://beefyheisenberg.github.io/tags/电影/"},{"name":"俄罗斯","slug":"俄罗斯","permalink":"https://beefyheisenberg.github.io/tags/俄罗斯/"},{"name":"托洛茨基","slug":"托洛茨基","permalink":"https://beefyheisenberg.github.io/tags/托洛茨基/"},{"name":"自传","slug":"自传","permalink":"https://beefyheisenberg.github.io/tags/自传/"},{"name":"苏联","slug":"苏联","permalink":"https://beefyheisenberg.github.io/tags/苏联/"},{"name":"欧洲","slug":"欧洲","permalink":"https://beefyheisenberg.github.io/tags/欧洲/"},{"name":"意大利","slug":"意大利","permalink":"https://beefyheisenberg.github.io/tags/意大利/"},{"name":"文艺复兴","slug":"文艺复兴","permalink":"https://beefyheisenberg.github.io/tags/文艺复兴/"},{"name":"维特根斯坦","slug":"维特根斯坦","permalink":"https://beefyheisenberg.github.io/tags/维特根斯坦/"},{"name":"小说摘录","slug":"小说摘录","permalink":"https://beefyheisenberg.github.io/tags/小说摘录/"},{"name":"契科夫","slug":"契科夫","permalink":"https://beefyheisenberg.github.io/tags/契科夫/"},{"name":"话剧","slug":"话剧","permalink":"https://beefyheisenberg.github.io/tags/话剧/"},{"name":"诗歌","slug":"诗歌","permalink":"https://beefyheisenberg.github.io/tags/诗歌/"},{"name":"纪伯伦","slug":"纪伯伦","permalink":"https://beefyheisenberg.github.io/tags/纪伯伦/"},{"name":"拉美","slug":"拉美","permalink":"https://beefyheisenberg.github.io/tags/拉美/"},{"name":"魔兽世界","slug":"魔兽世界","permalink":"https://beefyheisenberg.github.io/tags/魔兽世界/"},{"name":"游戏","slug":"游戏","permalink":"https://beefyheisenberg.github.io/tags/游戏/"},{"name":"加缪","slug":"加缪","permalink":"https://beefyheisenberg.github.io/tags/加缪/"},{"name":"法国","slug":"法国","permalink":"https://beefyheisenberg.github.io/tags/法国/"},{"name":"里尔克","slug":"里尔克","permalink":"https://beefyheisenberg.github.io/tags/里尔克/"},{"name":"苏州","slug":"苏州","permalink":"https://beefyheisenberg.github.io/tags/苏州/"},{"name":"赛博朋克","slug":"赛博朋克","permalink":"https://beefyheisenberg.github.io/tags/赛博朋克/"},{"name":"智利","slug":"智利","permalink":"https://beefyheisenberg.github.io/tags/智利/"},{"name":"奇怪的东西","slug":"奇怪的东西","permalink":"https://beefyheisenberg.github.io/tags/奇怪的东西/"},{"name":"亚文化","slug":"亚文化","permalink":"https://beefyheisenberg.github.io/tags/亚文化/"},{"name":"流行文化","slug":"流行文化","permalink":"https://beefyheisenberg.github.io/tags/流行文化/"},{"name":"原子朋克","slug":"原子朋克","permalink":"https://beefyheisenberg.github.io/tags/原子朋克/"},{"name":"复古未来主义","slug":"复古未来主义","permalink":"https://beefyheisenberg.github.io/tags/复古未来主义/"},{"name":"蒸汽波","slug":"蒸汽波","permalink":"https://beefyheisenberg.github.io/tags/蒸汽波/"},{"name":"故障艺术","slug":"故障艺术","permalink":"https://beefyheisenberg.github.io/tags/故障艺术/"},{"name":"大卫","slug":"大卫","permalink":"https://beefyheisenberg.github.io/tags/大卫/"},{"name":"日本","slug":"日本","permalink":"https://beefyheisenberg.github.io/tags/日本/"},{"name":"昭和时代","slug":"昭和时代","permalink":"https://beefyheisenberg.github.io/tags/昭和时代/"},{"name":"克苏鲁","slug":"克苏鲁","permalink":"https://beefyheisenberg.github.io/tags/克苏鲁/"},{"name":"希腊神话","slug":"希腊神话","permalink":"https://beefyheisenberg.github.io/tags/希腊神话/"},{"name":"北京","slug":"北京","permalink":"https://beefyheisenberg.github.io/tags/北京/"},{"name":"建筑","slug":"建筑","permalink":"https://beefyheisenberg.github.io/tags/建筑/"},{"name":"希腊","slug":"希腊","permalink":"https://beefyheisenberg.github.io/tags/希腊/"},{"name":"罗马","slug":"罗马","permalink":"https://beefyheisenberg.github.io/tags/罗马/"},{"name":"哲学","slug":"哲学","permalink":"https://beefyheisenberg.github.io/tags/哲学/"},{"name":"存在主义","slug":"存在主义","permalink":"https://beefyheisenberg.github.io/tags/存在主义/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://beefyheisenberg.github.io/tags/读书笔记/"},{"name":"认知偏误","slug":"认知偏误","permalink":"https://beefyheisenberg.github.io/tags/认知偏误/"},{"name":"幸存者偏差","slug":"幸存者偏差","permalink":"https://beefyheisenberg.github.io/tags/幸存者偏差/"},{"name":"巴纳姆效应","slug":"巴纳姆效应","permalink":"https://beefyheisenberg.github.io/tags/巴纳姆效应/"},{"name":"知识的诅咒","slug":"知识的诅咒","permalink":"https://beefyheisenberg.github.io/tags/知识的诅咒/"},{"name":"心理学","slug":"心理学","permalink":"https://beefyheisenberg.github.io/tags/心理学/"},{"name":"弗洛伊德","slug":"弗洛伊德","permalink":"https://beefyheisenberg.github.io/tags/弗洛伊德/"},{"name":"心理测评","slug":"心理测评","permalink":"https://beefyheisenberg.github.io/tags/心理测评/"},{"name":"MBTI","slug":"MBTI","permalink":"https://beefyheisenberg.github.io/tags/MBTI/"},{"name":"荣格","slug":"荣格","permalink":"https://beefyheisenberg.github.io/tags/荣格/"},{"name":"克利夫顿优势","slug":"克利夫顿优势","permalink":"https://beefyheisenberg.github.io/tags/克利夫顿优势/"},{"name":"社会心理学","slug":"社会心理学","permalink":"https://beefyheisenberg.github.io/tags/社会心理学/"},{"name":"哲学主义","slug":"哲学主义","permalink":"https://beefyheisenberg.github.io/tags/哲学主义/"},{"name":"虚无主义","slug":"虚无主义","permalink":"https://beefyheisenberg.github.io/tags/虚无主义/"},{"name":"叔本华","slug":"叔本华","permalink":"https://beefyheisenberg.github.io/tags/叔本华/"},{"name":"尼采","slug":"尼采","permalink":"https://beefyheisenberg.github.io/tags/尼采/"},{"name":"哲学史","slug":"哲学史","permalink":"https://beefyheisenberg.github.io/tags/哲学史/"},{"name":"先验","slug":"先验","permalink":"https://beefyheisenberg.github.io/tags/先验/"},{"name":"价值","slug":"价值","permalink":"https://beefyheisenberg.github.io/tags/价值/"},{"name":"意义","slug":"意义","permalink":"https://beefyheisenberg.github.io/tags/意义/"},{"name":"实用主义","slug":"实用主义","permalink":"https://beefyheisenberg.github.io/tags/实用主义/"},{"name":"马基雅维利主义","slug":"马基雅维利主义","permalink":"https://beefyheisenberg.github.io/tags/马基雅维利主义/"},{"name":"斯多葛","slug":"斯多葛","permalink":"https://beefyheisenberg.github.io/tags/斯多葛/"},{"name":"海德格","slug":"海德格","permalink":"https://beefyheisenberg.github.io/tags/海德格/"},{"name":"萨特","slug":"萨特","permalink":"https://beefyheisenberg.github.io/tags/萨特/"},{"name":"分析哲学","slug":"分析哲学","permalink":"https://beefyheisenberg.github.io/tags/分析哲学/"},{"name":"罗素","slug":"罗素","permalink":"https://beefyheisenberg.github.io/tags/罗素/"},{"name":"康德","slug":"康德","permalink":"https://beefyheisenberg.github.io/tags/康德/"},{"name":"黑格尔","slug":"黑格尔","permalink":"https://beefyheisenberg.github.io/tags/黑格尔/"},{"name":"城市探索","slug":"城市探索","permalink":"https://beefyheisenberg.github.io/tags/城市探索/"},{"name":"旅行","slug":"旅行","permalink":"https://beefyheisenberg.github.io/tags/旅行/"},{"name":"HongKong","slug":"HongKong","permalink":"https://beefyheisenberg.github.io/tags/HongKong/"},{"name":"天津","slug":"天津","permalink":"https://beefyheisenberg.github.io/tags/天津/"},{"name":"上海","slug":"上海","permalink":"https://beefyheisenberg.github.io/tags/上海/"},{"name":"摄影","slug":"摄影","permalink":"https://beefyheisenberg.github.io/tags/摄影/"},{"name":"街拍","slug":"街拍","permalink":"https://beefyheisenberg.github.io/tags/街拍/"},{"name":"相机","slug":"相机","permalink":"https://beefyheisenberg.github.io/tags/相机/"},{"name":"Fujifilm","slug":"Fujifilm","permalink":"https://beefyheisenberg.github.io/tags/Fujifilm/"},{"name":"摄影器材","slug":"摄影器材","permalink":"https://beefyheisenberg.github.io/tags/摄影器材/"},{"name":"索尼","slug":"索尼","permalink":"https://beefyheisenberg.github.io/tags/索尼/"},{"name":"索尼A7","slug":"索尼A7","permalink":"https://beefyheisenberg.github.io/tags/索尼A7/"},{"name":"X100","slug":"X100","permalink":"https://beefyheisenberg.github.io/tags/X100/"},{"name":"闪光灯","slug":"闪光灯","permalink":"https://beefyheisenberg.github.io/tags/闪光灯/"},{"name":"胶片","slug":"胶片","permalink":"https://beefyheisenberg.github.io/tags/胶片/"},{"name":"宾得","slug":"宾得","permalink":"https://beefyheisenberg.github.io/tags/宾得/"},{"name":"说明书","slug":"说明书","permalink":"https://beefyheisenberg.github.io/tags/说明书/"},{"name":"VSCO","slug":"VSCO","permalink":"https://beefyheisenberg.github.io/tags/VSCO/"},{"name":"宏观经济","slug":"宏观经济","permalink":"https://beefyheisenberg.github.io/tags/宏观经济/"},{"name":"股市","slug":"股市","permalink":"https://beefyheisenberg.github.io/tags/股市/"},{"name":"财经历史数据","slug":"财经历史数据","permalink":"https://beefyheisenberg.github.io/tags/财经历史数据/"},{"name":"量化交易","slug":"量化交易","permalink":"https://beefyheisenberg.github.io/tags/量化交易/"},{"name":"交易策略","slug":"交易策略","permalink":"https://beefyheisenberg.github.io/tags/交易策略/"},{"name":"阻力位","slug":"阻力位","permalink":"https://beefyheisenberg.github.io/tags/阻力位/"},{"name":"支撑位","slug":"支撑位","permalink":"https://beefyheisenberg.github.io/tags/支撑位/"},{"name":"经济周期","slug":"经济周期","permalink":"https://beefyheisenberg.github.io/tags/经济周期/"},{"name":"基本面","slug":"基本面","permalink":"https://beefyheisenberg.github.io/tags/基本面/"},{"name":"PE","slug":"PE","permalink":"https://beefyheisenberg.github.io/tags/PE/"},{"name":"市盈率","slug":"市盈率","permalink":"https://beefyheisenberg.github.io/tags/市盈率/"},{"name":"PEG","slug":"PEG","permalink":"https://beefyheisenberg.github.io/tags/PEG/"},{"name":"PB","slug":"PB","permalink":"https://beefyheisenberg.github.io/tags/PB/"},{"name":"市净率","slug":"市净率","permalink":"https://beefyheisenberg.github.io/tags/市净率/"},{"name":"ROE","slug":"ROE","permalink":"https://beefyheisenberg.github.io/tags/ROE/"},{"name":"净利率","slug":"净利率","permalink":"https://beefyheisenberg.github.io/tags/净利率/"},{"name":"毛利率","slug":"毛利率","permalink":"https://beefyheisenberg.github.io/tags/毛利率/"},{"name":"量化回测","slug":"量化回测","permalink":"https://beefyheisenberg.github.io/tags/量化回测/"},{"name":"K线","slug":"K线","permalink":"https://beefyheisenberg.github.io/tags/K线/"},{"name":"技术分析","slug":"技术分析","permalink":"https://beefyheisenberg.github.io/tags/技术分析/"},{"name":"资产配置","slug":"资产配置","permalink":"https://beefyheisenberg.github.io/tags/资产配置/"},{"name":"投资","slug":"投资","permalink":"https://beefyheisenberg.github.io/tags/投资/"},{"name":"期权","slug":"期权","permalink":"https://beefyheisenberg.github.io/tags/期权/"},{"name":"期货","slug":"期货","permalink":"https://beefyheisenberg.github.io/tags/期货/"},{"name":"期指","slug":"期指","permalink":"https://beefyheisenberg.github.io/tags/期指/"},{"name":"金融衍生品","slug":"金融衍生品","permalink":"https://beefyheisenberg.github.io/tags/金融衍生品/"},{"name":"债券","slug":"债券","permalink":"https://beefyheisenberg.github.io/tags/债券/"},{"name":"可转债","slug":"可转债","permalink":"https://beefyheisenberg.github.io/tags/可转债/"},{"name":"美联储","slug":"美联储","permalink":"https://beefyheisenberg.github.io/tags/美联储/"},{"name":"国债","slug":"国债","permalink":"https://beefyheisenberg.github.io/tags/国债/"},{"name":"收益率","slug":"收益率","permalink":"https://beefyheisenberg.github.io/tags/收益率/"},{"name":"利率","slug":"利率","permalink":"https://beefyheisenberg.github.io/tags/利率/"},{"name":"信用债","slug":"信用债","permalink":"https://beefyheisenberg.github.io/tags/信用债/"},{"name":"利率债","slug":"利率债","permalink":"https://beefyheisenberg.github.io/tags/利率债/"},{"name":"SmartBeta","slug":"SmartBeta","permalink":"https://beefyheisenberg.github.io/tags/SmartBeta/"},{"name":"神奇公式","slug":"神奇公式","permalink":"https://beefyheisenberg.github.io/tags/神奇公式/"},{"name":"基金","slug":"基金","permalink":"https://beefyheisenberg.github.io/tags/基金/"},{"name":"ETF","slug":"ETF","permalink":"https://beefyheisenberg.github.io/tags/ETF/"},{"name":"同业存单","slug":"同业存单","permalink":"https://beefyheisenberg.github.io/tags/同业存单/"},{"name":"_Index","slug":"Index","permalink":"https://beefyheisenberg.github.io/tags/Index/"},{"name":"社融","slug":"社融","permalink":"https://beefyheisenberg.github.io/tags/社融/"},{"name":"M2","slug":"M2","permalink":"https://beefyheisenberg.github.io/tags/M2/"},{"name":"A股","slug":"A股","permalink":"https://beefyheisenberg.github.io/tags/A股/"},{"name":"债市","slug":"债市","permalink":"https://beefyheisenberg.github.io/tags/债市/"},{"name":"剩余流动性","slug":"剩余流动性","permalink":"https://beefyheisenberg.github.io/tags/剩余流动性/"},{"name":"择时","slug":"择时","permalink":"https://beefyheisenberg.github.io/tags/择时/"},{"name":"股市估值","slug":"股市估值","permalink":"https://beefyheisenberg.github.io/tags/股市估值/"},{"name":"股债利差","slug":"股债利差","permalink":"https://beefyheisenberg.github.io/tags/股债利差/"},{"name":"风险溢价","slug":"风险溢价","permalink":"https://beefyheisenberg.github.io/tags/风险溢价/"},{"name":"左侧择时","slug":"左侧择时","permalink":"https://beefyheisenberg.github.io/tags/左侧择时/"},{"name":"巴菲特指数","slug":"巴菲特指数","permalink":"https://beefyheisenberg.github.io/tags/巴菲特指数/"},{"name":"美股","slug":"美股","permalink":"https://beefyheisenberg.github.io/tags/美股/"},{"name":"宏观调控","slug":"宏观调控","permalink":"https://beefyheisenberg.github.io/tags/宏观调控/"},{"name":"汇率","slug":"汇率","permalink":"https://beefyheisenberg.github.io/tags/汇率/"},{"name":"离岸人民币","slug":"离岸人民币","permalink":"https://beefyheisenberg.github.io/tags/离岸人民币/"},{"name":"在岸人民币","slug":"在岸人民币","permalink":"https://beefyheisenberg.github.io/tags/在岸人民币/"},{"name":"央行","slug":"央行","permalink":"https://beefyheisenberg.github.io/tags/央行/"},{"name":"MLF","slug":"MLF","permalink":"https://beefyheisenberg.github.io/tags/MLF/"},{"name":"FED","slug":"FED","permalink":"https://beefyheisenberg.github.io/tags/FED/"},{"name":"量化宽松","slug":"量化宽松","permalink":"https://beefyheisenberg.github.io/tags/量化宽松/"},{"name":"量化紧缩","slug":"量化紧缩","permalink":"https://beefyheisenberg.github.io/tags/量化紧缩/"},{"name":"加息","slug":"加息","permalink":"https://beefyheisenberg.github.io/tags/加息/"},{"name":"缩表","slug":"缩表","permalink":"https://beefyheisenberg.github.io/tags/缩表/"},{"name":"美林时钟","slug":"美林时钟","permalink":"https://beefyheisenberg.github.io/tags/美林时钟/"},{"name":"入门101","slug":"入门101","permalink":"https://beefyheisenberg.github.io/tags/入门101/"},{"name":"理财","slug":"理财","permalink":"https://beefyheisenberg.github.io/tags/理财/"},{"name":"习惯","slug":"习惯","permalink":"https://beefyheisenberg.github.io/tags/习惯/"},{"name":"富兰克林","slug":"富兰克林","permalink":"https://beefyheisenberg.github.io/tags/富兰克林/"},{"name":"毕达哥拉斯","slug":"毕达哥拉斯","permalink":"https://beefyheisenberg.github.io/tags/毕达哥拉斯/"},{"name":"生产力","slug":"生产力","permalink":"https://beefyheisenberg.github.io/tags/生产力/"},{"name":"知识管理","slug":"知识管理","permalink":"https://beefyheisenberg.github.io/tags/知识管理/"},{"name":"PKM","slug":"PKM","permalink":"https://beefyheisenberg.github.io/tags/PKM/"},{"name":"笔记","slug":"笔记","permalink":"https://beefyheisenberg.github.io/tags/笔记/"},{"name":"分类法","slug":"分类法","permalink":"https://beefyheisenberg.github.io/tags/分类法/"},{"name":"SQ3R","slug":"SQ3R","permalink":"https://beefyheisenberg.github.io/tags/SQ3R/"},{"name":"康奈尔笔记法","slug":"康奈尔笔记法","permalink":"https://beefyheisenberg.github.io/tags/康奈尔笔记法/"},{"name":"学习法","slug":"学习法","permalink":"https://beefyheisenberg.github.io/tags/学习法/"},{"name":"论文","slug":"论文","permalink":"https://beefyheisenberg.github.io/tags/论文/"},{"name":"IMRAD","slug":"IMRAD","permalink":"https://beefyheisenberg.github.io/tags/IMRAD/"},{"name":"项目管理","slug":"项目管理","permalink":"https://beefyheisenberg.github.io/tags/项目管理/"},{"name":"文献管理","slug":"文献管理","permalink":"https://beefyheisenberg.github.io/tags/文献管理/"},{"name":"GTD","slug":"GTD","permalink":"https://beefyheisenberg.github.io/tags/GTD/"},{"name":"卡片笔记","slug":"卡片笔记","permalink":"https://beefyheisenberg.github.io/tags/卡片笔记/"},{"name":"开源","slug":"开源","permalink":"https://beefyheisenberg.github.io/tags/开源/"},{"name":"如何阅读源码","slug":"如何阅读源码","permalink":"https://beefyheisenberg.github.io/tags/如何阅读源码/"},{"name":"前端","slug":"前端","permalink":"https://beefyheisenberg.github.io/tags/前端/"},{"name":"Html","slug":"Html","permalink":"https://beefyheisenberg.github.io/tags/Html/"},{"name":"Javascript","slug":"Javascript","permalink":"https://beefyheisenberg.github.io/tags/Javascript/"},{"name":"NodeJS","slug":"NodeJS","permalink":"https://beefyheisenberg.github.io/tags/NodeJS/"},{"name":"博客","slug":"博客","permalink":"https://beefyheisenberg.github.io/tags/博客/"},{"name":"Hugo","slug":"Hugo","permalink":"https://beefyheisenberg.github.io/tags/Hugo/"},{"name":"Markdown","slug":"Markdown","permalink":"https://beefyheisenberg.github.io/tags/Markdown/"},{"name":"开发环境","slug":"开发环境","permalink":"https://beefyheisenberg.github.io/tags/开发环境/"},{"name":"IDE","slug":"IDE","permalink":"https://beefyheisenberg.github.io/tags/IDE/"},{"name":"Vim","slug":"Vim","permalink":"https://beefyheisenberg.github.io/tags/Vim/"},{"name":"Vimdiff","slug":"Vimdiff","permalink":"https://beefyheisenberg.github.io/tags/Vimdiff/"},{"name":"IDEA","slug":"IDEA","permalink":"https://beefyheisenberg.github.io/tags/IDEA/"},{"name":"Jetbrains","slug":"Jetbrains","permalink":"https://beefyheisenberg.github.io/tags/Jetbrains/"},{"name":"screen","slug":"screen","permalink":"https://beefyheisenberg.github.io/tags/screen/"},{"name":"tmux","slug":"tmux","permalink":"https://beefyheisenberg.github.io/tags/tmux/"},{"name":"git","slug":"git","permalink":"https://beefyheisenberg.github.io/tags/git/"},{"name":"机器学习","slug":"机器学习","permalink":"https://beefyheisenberg.github.io/tags/机器学习/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://beefyheisenberg.github.io/tags/Machine-Learning/"},{"name":"推荐系统","slug":"推荐系统","permalink":"https://beefyheisenberg.github.io/tags/推荐系统/"},{"name":"Recommend","slug":"Recommend","permalink":"https://beefyheisenberg.github.io/tags/Recommend/"},{"name":"深度学习","slug":"深度学习","permalink":"https://beefyheisenberg.github.io/tags/深度学习/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://beefyheisenberg.github.io/tags/Deep-Learning/"},{"name":"后端技术","slug":"后端技术","permalink":"https://beefyheisenberg.github.io/tags/后端技术/"},{"name":"大数据","slug":"大数据","permalink":"https://beefyheisenberg.github.io/tags/大数据/"},{"name":"流式计算","slug":"流式计算","permalink":"https://beefyheisenberg.github.io/tags/流式计算/"},{"name":"Storm","slug":"Storm","permalink":"https://beefyheisenberg.github.io/tags/Storm/"},{"name":"Spark","slug":"Spark","permalink":"https://beefyheisenberg.github.io/tags/Spark/"},{"name":"Hive","slug":"Hive","permalink":"https://beefyheisenberg.github.io/tags/Hive/"},{"name":"Apache","slug":"Apache","permalink":"https://beefyheisenberg.github.io/tags/Apache/"},{"name":"批处理计算","slug":"批处理计算","permalink":"https://beefyheisenberg.github.io/tags/批处理计算/"},{"name":"Hadoop","slug":"Hadoop","permalink":"https://beefyheisenberg.github.io/tags/Hadoop/"},{"name":"HDFS","slug":"HDFS","permalink":"https://beefyheisenberg.github.io/tags/HDFS/"},{"name":"MapReduce","slug":"MapReduce","permalink":"https://beefyheisenberg.github.io/tags/MapReduce/"},{"name":"后端架构","slug":"后端架构","permalink":"https://beefyheisenberg.github.io/tags/后端架构/"},{"name":"数据库","slug":"数据库","permalink":"https://beefyheisenberg.github.io/tags/数据库/"},{"name":"MySQL","slug":"MySQL","permalink":"https://beefyheisenberg.github.io/tags/MySQL/"},{"name":"乐观锁","slug":"乐观锁","permalink":"https://beefyheisenberg.github.io/tags/乐观锁/"},{"name":"悲观锁","slug":"悲观锁","permalink":"https://beefyheisenberg.github.io/tags/悲观锁/"},{"name":"两段锁","slug":"两段锁","permalink":"https://beefyheisenberg.github.io/tags/两段锁/"},{"name":"事务","slug":"事务","permalink":"https://beefyheisenberg.github.io/tags/事务/"},{"name":"ACID","slug":"ACID","permalink":"https://beefyheisenberg.github.io/tags/ACID/"},{"name":"MVCC","slug":"MVCC","permalink":"https://beefyheisenberg.github.io/tags/MVCC/"},{"name":"LBCC","slug":"LBCC","permalink":"https://beefyheisenberg.github.io/tags/LBCC/"},{"name":"隔离级别","slug":"隔离级别","permalink":"https://beefyheisenberg.github.io/tags/隔离级别/"},{"name":"索引","slug":"索引","permalink":"https://beefyheisenberg.github.io/tags/索引/"},{"name":"SQL语句","slug":"SQL语句","permalink":"https://beefyheisenberg.github.io/tags/SQL语句/"},{"name":"NoSQL","slug":"NoSQL","permalink":"https://beefyheisenberg.github.io/tags/NoSQL/"},{"name":"Mongo","slug":"Mongo","permalink":"https://beefyheisenberg.github.io/tags/Mongo/"},{"name":"OLTP","slug":"OLTP","permalink":"https://beefyheisenberg.github.io/tags/OLTP/"},{"name":"OLAP","slug":"OLAP","permalink":"https://beefyheisenberg.github.io/tags/OLAP/"},{"name":"TSDB","slug":"TSDB","permalink":"https://beefyheisenberg.github.io/tags/TSDB/"},{"name":"资源调度","slug":"资源调度","permalink":"https://beefyheisenberg.github.io/tags/资源调度/"},{"name":"YARN","slug":"YARN","permalink":"https://beefyheisenberg.github.io/tags/YARN/"},{"name":"Mesos","slug":"Mesos","permalink":"https://beefyheisenberg.github.io/tags/Mesos/"},{"name":"k8s","slug":"k8s","permalink":"https://beefyheisenberg.github.io/tags/k8s/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://beefyheisenberg.github.io/tags/Kubernetes/"},{"name":"反向代理","slug":"反向代理","permalink":"https://beefyheisenberg.github.io/tags/反向代理/"},{"name":"Nginx","slug":"Nginx","permalink":"https://beefyheisenberg.github.io/tags/Nginx/"},{"name":"消息队列","slug":"消息队列","permalink":"https://beefyheisenberg.github.io/tags/消息队列/"},{"name":"Kafka","slug":"Kafka","permalink":"https://beefyheisenberg.github.io/tags/Kafka/"},{"name":"容器化","slug":"容器化","permalink":"https://beefyheisenberg.github.io/tags/容器化/"},{"name":"Docker","slug":"Docker","permalink":"https://beefyheisenberg.github.io/tags/Docker/"},{"name":"缓存","slug":"缓存","permalink":"https://beefyheisenberg.github.io/tags/缓存/"},{"name":"Memcached","slug":"Memcached","permalink":"https://beefyheisenberg.github.io/tags/Memcached/"},{"name":"LRU","slug":"LRU","permalink":"https://beefyheisenberg.github.io/tags/LRU/"},{"name":"LFU","slug":"LFU","permalink":"https://beefyheisenberg.github.io/tags/LFU/"},{"name":"分布式","slug":"分布式","permalink":"https://beefyheisenberg.github.io/tags/分布式/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://beefyheisenberg.github.io/tags/Zookeeper/"},{"name":"Paxos","slug":"Paxos","permalink":"https://beefyheisenberg.github.io/tags/Paxos/"},{"name":"ZAB","slug":"ZAB","permalink":"https://beefyheisenberg.github.io/tags/ZAB/"},{"name":"CAP","slug":"CAP","permalink":"https://beefyheisenberg.github.io/tags/CAP/"},{"name":"并发","slug":"并发","permalink":"https://beefyheisenberg.github.io/tags/并发/"},{"name":"性能测试","slug":"性能测试","permalink":"https://beefyheisenberg.github.io/tags/性能测试/"},{"name":"C10K","slug":"C10K","permalink":"https://beefyheisenberg.github.io/tags/C10K/"},{"name":"C100K","slug":"C100K","permalink":"https://beefyheisenberg.github.io/tags/C100K/"},{"name":"ulimit","slug":"ulimit","permalink":"https://beefyheisenberg.github.io/tags/ulimit/"},{"name":"架构","slug":"架构","permalink":"https://beefyheisenberg.github.io/tags/架构/"},{"name":"System Design","slug":"System-Design","permalink":"https://beefyheisenberg.github.io/tags/System-Design/"},{"name":"高可用","slug":"高可用","permalink":"https://beefyheisenberg.github.io/tags/高可用/"},{"name":"高性能","slug":"高性能","permalink":"https://beefyheisenberg.github.io/tags/高性能/"},{"name":"负载均衡","slug":"负载均衡","permalink":"https://beefyheisenberg.github.io/tags/负载均衡/"},{"name":"限流","slug":"限流","permalink":"https://beefyheisenberg.github.io/tags/限流/"},{"name":"分库分表","slug":"分库分表","permalink":"https://beefyheisenberg.github.io/tags/分库分表/"},{"name":"Redis","slug":"Redis","permalink":"https://beefyheisenberg.github.io/tags/Redis/"},{"name":"K-V","slug":"K-V","permalink":"https://beefyheisenberg.github.io/tags/K-V/"},{"name":"RPC","slug":"RPC","permalink":"https://beefyheisenberg.github.io/tags/RPC/"},{"name":"SOA","slug":"SOA","permalink":"https://beefyheisenberg.github.io/tags/SOA/"},{"name":"微服务","slug":"微服务","permalink":"https://beefyheisenberg.github.io/tags/微服务/"},{"name":"服务治理","slug":"服务治理","permalink":"https://beefyheisenberg.github.io/tags/服务治理/"},{"name":"Motan","slug":"Motan","permalink":"https://beefyheisenberg.github.io/tags/Motan/"},{"name":"IaaS","slug":"IaaS","permalink":"https://beefyheisenberg.github.io/tags/IaaS/"},{"name":"PaaS","slug":"PaaS","permalink":"https://beefyheisenberg.github.io/tags/PaaS/"},{"name":"SaaS","slug":"SaaS","permalink":"https://beefyheisenberg.github.io/tags/SaaS/"},{"name":"网络协议","slug":"网络协议","permalink":"https://beefyheisenberg.github.io/tags/网络协议/"},{"name":"HTTP","slug":"HTTP","permalink":"https://beefyheisenberg.github.io/tags/HTTP/"},{"name":"Restful","slug":"Restful","permalink":"https://beefyheisenberg.github.io/tags/Restful/"},{"name":"TCP","slug":"TCP","permalink":"https://beefyheisenberg.github.io/tags/TCP/"},{"name":"IP","slug":"IP","permalink":"https://beefyheisenberg.github.io/tags/IP/"},{"name":"Linux命令行","slug":"Linux命令行","permalink":"https://beefyheisenberg.github.io/tags/Linux命令行/"},{"name":"sed","slug":"sed","permalink":"https://beefyheisenberg.github.io/tags/sed/"},{"name":"awk","slug":"awk","permalink":"https://beefyheisenberg.github.io/tags/awk/"},{"name":"grep","slug":"grep","permalink":"https://beefyheisenberg.github.io/tags/grep/"},{"name":"Linux","slug":"Linux","permalink":"https://beefyheisenberg.github.io/tags/Linux/"},{"name":"sysctl","slug":"sysctl","permalink":"https://beefyheisenberg.github.io/tags/sysctl/"},{"name":"系统性能分析","slug":"系统性能分析","permalink":"https://beefyheisenberg.github.io/tags/系统性能分析/"},{"name":"网络","slug":"网络","permalink":"https://beefyheisenberg.github.io/tags/网络/"},{"name":"CPU","slug":"CPU","permalink":"https://beefyheisenberg.github.io/tags/CPU/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://beefyheisenberg.github.io/tags/数据结构与算法/"},{"name":"动态规划","slug":"动态规划","permalink":"https://beefyheisenberg.github.io/tags/动态规划/"},{"name":"二分查找","slug":"二分查找","permalink":"https://beefyheisenberg.github.io/tags/二分查找/"},{"name":"优先队列","slug":"优先队列","permalink":"https://beefyheisenberg.github.io/tags/优先队列/"},{"name":"平衡树","slug":"平衡树","permalink":"https://beefyheisenberg.github.io/tags/平衡树/"},{"name":"线段树","slug":"线段树","permalink":"https://beefyheisenberg.github.io/tags/线段树/"},{"name":"并查集","slug":"并查集","permalink":"https://beefyheisenberg.github.io/tags/并查集/"},{"name":"BFS","slug":"BFS","permalink":"https://beefyheisenberg.github.io/tags/BFS/"},{"name":"DFS","slug":"DFS","permalink":"https://beefyheisenberg.github.io/tags/DFS/"},{"name":"欧几里得算法","slug":"欧几里得算法","permalink":"https://beefyheisenberg.github.io/tags/欧几里得算法/"},{"name":"拓扑排序","slug":"拓扑排序","permalink":"https://beefyheisenberg.github.io/tags/拓扑排序/"},{"name":"最小生成树","slug":"最小生成树","permalink":"https://beefyheisenberg.github.io/tags/最小生成树/"},{"name":"排序","slug":"排序","permalink":"https://beefyheisenberg.github.io/tags/排序/"},{"name":"贪心","slug":"贪心","permalink":"https://beefyheisenberg.github.io/tags/贪心/"},{"name":"分治","slug":"分治","permalink":"https://beefyheisenberg.github.io/tags/分治/"},{"name":"回溯","slug":"回溯","permalink":"https://beefyheisenberg.github.io/tags/回溯/"},{"name":"KMP","slug":"KMP","permalink":"https://beefyheisenberg.github.io/tags/KMP/"},{"name":"二叉树","slug":"二叉树","permalink":"https://beefyheisenberg.github.io/tags/二叉树/"},{"name":"BST","slug":"BST","permalink":"https://beefyheisenberg.github.io/tags/BST/"},{"name":"AVL","slug":"AVL","permalink":"https://beefyheisenberg.github.io/tags/AVL/"},{"name":"红黑树","slug":"红黑树","permalink":"https://beefyheisenberg.github.io/tags/红黑树/"},{"name":"B-Tree","slug":"B-Tree","permalink":"https://beefyheisenberg.github.io/tags/B-Tree/"},{"name":"设计模式","slug":"设计模式","permalink":"https://beefyheisenberg.github.io/tags/设计模式/"},{"name":"Design Pattern","slug":"Design-Pattern","permalink":"https://beefyheisenberg.github.io/tags/Design-Pattern/"},{"name":"Golang","slug":"Golang","permalink":"https://beefyheisenberg.github.io/tags/Golang/"},{"name":"Java","slug":"Java","permalink":"https://beefyheisenberg.github.io/tags/Java/"},{"name":"JUnit","slug":"JUnit","permalink":"https://beefyheisenberg.github.io/tags/JUnit/"},{"name":"单元测试","slug":"单元测试","permalink":"https://beefyheisenberg.github.io/tags/单元测试/"},{"name":"Maven","slug":"Maven","permalink":"https://beefyheisenberg.github.io/tags/Maven/"},{"name":"Gradle","slug":"Gradle","permalink":"https://beefyheisenberg.github.io/tags/Gradle/"},{"name":"构建工具","slug":"构建工具","permalink":"https://beefyheisenberg.github.io/tags/构建工具/"},{"name":"JavaEE","slug":"JavaEE","permalink":"https://beefyheisenberg.github.io/tags/JavaEE/"},{"name":"Tomcat","slug":"Tomcat","permalink":"https://beefyheisenberg.github.io/tags/Tomcat/"},{"name":"Spring MVC","slug":"Spring-MVC","permalink":"https://beefyheisenberg.github.io/tags/Spring-MVC/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://beefyheisenberg.github.io/tags/Spring-Boot/"},{"name":"Servlet","slug":"Servlet","permalink":"https://beefyheisenberg.github.io/tags/Servlet/"},{"name":"JSP","slug":"JSP","permalink":"https://beefyheisenberg.github.io/tags/JSP/"},{"name":"ORM","slug":"ORM","permalink":"https://beefyheisenberg.github.io/tags/ORM/"},{"name":"MyBatis","slug":"MyBatis","permalink":"https://beefyheisenberg.github.io/tags/MyBatis/"},{"name":"Hibernate","slug":"Hibernate","permalink":"https://beefyheisenberg.github.io/tags/Hibernate/"},{"name":"JCL","slug":"JCL","permalink":"https://beefyheisenberg.github.io/tags/JCL/"},{"name":"SLF4J","slug":"SLF4J","permalink":"https://beefyheisenberg.github.io/tags/SLF4J/"},{"name":"Log4J","slug":"Log4J","permalink":"https://beefyheisenberg.github.io/tags/Log4J/"},{"name":"Logback","slug":"Logback","permalink":"https://beefyheisenberg.github.io/tags/Logback/"},{"name":"日志","slug":"日志","permalink":"https://beefyheisenberg.github.io/tags/日志/"},{"name":"JTS","slug":"JTS","permalink":"https://beefyheisenberg.github.io/tags/JTS/"},{"name":"JMS","slug":"JMS","permalink":"https://beefyheisenberg.github.io/tags/JMS/"},{"name":"JMX","slug":"JMX","permalink":"https://beefyheisenberg.github.io/tags/JMX/"},{"name":"JTA","slug":"JTA","permalink":"https://beefyheisenberg.github.io/tags/JTA/"},{"name":"JPA","slug":"JPA","permalink":"https://beefyheisenberg.github.io/tags/JPA/"},{"name":"JNDI","slug":"JNDI","permalink":"https://beefyheisenberg.github.io/tags/JNDI/"},{"name":"EJB","slug":"EJB","permalink":"https://beefyheisenberg.github.io/tags/EJB/"},{"name":"JDBC","slug":"JDBC","permalink":"https://beefyheisenberg.github.io/tags/JDBC/"},{"name":"Java并发","slug":"Java并发","permalink":"https://beefyheisenberg.github.io/tags/Java并发/"},{"name":"JMM","slug":"JMM","permalink":"https://beefyheisenberg.github.io/tags/JMM/"},{"name":"JUC","slug":"JUC","permalink":"https://beefyheisenberg.github.io/tags/JUC/"},{"name":"集合","slug":"集合","permalink":"https://beefyheisenberg.github.io/tags/集合/"},{"name":"CAS","slug":"CAS","permalink":"https://beefyheisenberg.github.io/tags/CAS/"},{"name":"JVM","slug":"JVM","permalink":"https://beefyheisenberg.github.io/tags/JVM/"},{"name":"MetaSpace","slug":"MetaSpace","permalink":"https://beefyheisenberg.github.io/tags/MetaSpace/"},{"name":"指针","slug":"指针","permalink":"https://beefyheisenberg.github.io/tags/指针/"},{"name":"内存泄漏","slug":"内存泄漏","permalink":"https://beefyheisenberg.github.io/tags/内存泄漏/"},{"name":"编程语言快速入门","slug":"编程语言快速入门","permalink":"https://beefyheisenberg.github.io/tags/编程语言快速入门/"},{"name":"Objective-C","slug":"Objective-C","permalink":"https://beefyheisenberg.github.io/tags/Objective-C/"},{"name":"响应式编程","slug":"响应式编程","permalink":"https://beefyheisenberg.github.io/tags/响应式编程/"},{"name":"Reactive","slug":"Reactive","permalink":"https://beefyheisenberg.github.io/tags/Reactive/"},{"name":"Actor","slug":"Actor","permalink":"https://beefyheisenberg.github.io/tags/Actor/"},{"name":"RxJava","slug":"RxJava","permalink":"https://beefyheisenberg.github.io/tags/RxJava/"},{"name":"Akka","slug":"Akka","permalink":"https://beefyheisenberg.github.io/tags/Akka/"},{"name":"Bash","slug":"Bash","permalink":"https://beefyheisenberg.github.io/tags/Bash/"},{"name":"Shell","slug":"Shell","permalink":"https://beefyheisenberg.github.io/tags/Shell/"},{"name":"命令行","slug":"命令行","permalink":"https://beefyheisenberg.github.io/tags/命令行/"},{"name":"PHP","slug":"PHP","permalink":"https://beefyheisenberg.github.io/tags/PHP/"},{"name":"沉思录","slug":"沉思录","permalink":"https://beefyheisenberg.github.io/tags/沉思录/"},{"name":"可视化","slug":"可视化","permalink":"https://beefyheisenberg.github.io/tags/可视化/"},{"name":"Windows","slug":"Windows","permalink":"https://beefyheisenberg.github.io/tags/Windows/"},{"name":"OSX","slug":"OSX","permalink":"https://beefyheisenberg.github.io/tags/OSX/"},{"name":"macOS","slug":"macOS","permalink":"https://beefyheisenberg.github.io/tags/macOS/"},{"name":"VSCode","slug":"VSCode","permalink":"https://beefyheisenberg.github.io/tags/VSCode/"},{"name":"Dropbox","slug":"Dropbox","permalink":"https://beefyheisenberg.github.io/tags/Dropbox/"},{"name":"新裤子","slug":"新裤子","permalink":"https://beefyheisenberg.github.io/tags/新裤子/"},{"name":"Git","slug":"Git","permalink":"https://beefyheisenberg.github.io/tags/Git/"},{"name":"Github","slug":"Github","permalink":"https://beefyheisenberg.github.io/tags/Github/"},{"name":"GitBook","slug":"GitBook","permalink":"https://beefyheisenberg.github.io/tags/GitBook/"},{"name":"Surge","slug":"Surge","permalink":"https://beefyheisenberg.github.io/tags/Surge/"},{"name":"Proxy","slug":"Proxy","permalink":"https://beefyheisenberg.github.io/tags/Proxy/"},{"name":"Shadowsocks","slug":"Shadowsocks","permalink":"https://beefyheisenberg.github.io/tags/Shadowsocks/"},{"name":"日志处理","slug":"日志处理","permalink":"https://beefyheisenberg.github.io/tags/日志处理/"},{"name":"Fluentd","slug":"Fluentd","permalink":"https://beefyheisenberg.github.io/tags/Fluentd/"},{"name":"Flume","slug":"Flume","permalink":"https://beefyheisenberg.github.io/tags/Flume/"},{"name":"Eclipse","slug":"Eclipse","permalink":"https://beefyheisenberg.github.io/tags/Eclipse/"},{"name":"Sublime","slug":"Sublime","permalink":"https://beefyheisenberg.github.io/tags/Sublime/"},{"name":"佳能","slug":"佳能","permalink":"https://beefyheisenberg.github.io/tags/佳能/"},{"name":"Lightroom","slug":"Lightroom","permalink":"https://beefyheisenberg.github.io/tags/Lightroom/"},{"name":"奥林巴斯","slug":"奥林巴斯","permalink":"https://beefyheisenberg.github.io/tags/奥林巴斯/"},{"name":"M43","slug":"M43","permalink":"https://beefyheisenberg.github.io/tags/M43/"},{"name":"Cygwin","slug":"Cygwin","permalink":"https://beefyheisenberg.github.io/tags/Cygwin/"},{"name":"编辑器","slug":"编辑器","permalink":"https://beefyheisenberg.github.io/tags/编辑器/"},{"name":"Atom","slug":"Atom","permalink":"https://beefyheisenberg.github.io/tags/Atom/"},{"name":"树莓派","slug":"树莓派","permalink":"https://beefyheisenberg.github.io/tags/树莓派/"},{"name":"Samba","slug":"Samba","permalink":"https://beefyheisenberg.github.io/tags/Samba/"},{"name":"FTP","slug":"FTP","permalink":"https://beefyheisenberg.github.io/tags/FTP/"},{"name":"无线网卡","slug":"无线网卡","permalink":"https://beefyheisenberg.github.io/tags/无线网卡/"},{"name":"Xdebug","slug":"Xdebug","permalink":"https://beefyheisenberg.github.io/tags/Xdebug/"},{"name":"Hexo","slug":"Hexo","permalink":"https://beefyheisenberg.github.io/tags/Hexo/"},{"name":"EasyGrep","slug":"EasyGrep","permalink":"https://beefyheisenberg.github.io/tags/EasyGrep/"},{"name":"Linux Desktop","slug":"Linux-Desktop","permalink":"https://beefyheisenberg.github.io/tags/Linux-Desktop/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://beefyheisenberg.github.io/tags/Ubuntu/"},{"name":"Zsh","slug":"Zsh","permalink":"https://beefyheisenberg.github.io/tags/Zsh/"},{"name":"BitTorrent","slug":"BitTorrent","permalink":"https://beefyheisenberg.github.io/tags/BitTorrent/"},{"name":"C/C++","slug":"C-C","permalink":"https://beefyheisenberg.github.io/tags/C-C/"},{"name":"gcc","slug":"gcc","permalink":"https://beefyheisenberg.github.io/tags/gcc/"},{"name":"SSH","slug":"SSH","permalink":"https://beefyheisenberg.github.io/tags/SSH/"},{"name":"端口转发","slug":"端口转发","permalink":"https://beefyheisenberg.github.io/tags/端口转发/"},{"name":"加密算法","slug":"加密算法","permalink":"https://beefyheisenberg.github.io/tags/加密算法/"},{"name":"RSA","slug":"RSA","permalink":"https://beefyheisenberg.github.io/tags/RSA/"},{"name":"GPG","slug":"GPG","permalink":"https://beefyheisenberg.github.io/tags/GPG/"},{"name":"VNC","slug":"VNC","permalink":"https://beefyheisenberg.github.io/tags/VNC/"},{"name":"NFS","slug":"NFS","permalink":"https://beefyheisenberg.github.io/tags/NFS/"},{"name":"vundle","slug":"vundle","permalink":"https://beefyheisenberg.github.io/tags/vundle/"},{"name":"nm","slug":"nm","permalink":"https://beefyheisenberg.github.io/tags/nm/"},{"name":"objdump","slug":"objdump","permalink":"https://beefyheisenberg.github.io/tags/objdump/"},{"name":"Thinkpad","slug":"Thinkpad","permalink":"https://beefyheisenberg.github.io/tags/Thinkpad/"}]}